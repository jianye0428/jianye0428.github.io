<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>ML - 分类 - yejian's blog</title><link>https://jianye0428.github.io/categories/ml/</link><description>ML - 分类 - yejian's blog</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>18817571704@163.com (Jian YE)</managingEditor><webMaster>18817571704@163.com (Jian YE)</webMaster><lastBuildDate>Mon, 31 Jul 2023 15:57:07 +0800</lastBuildDate><atom:link href="https://jianye0428.github.io/categories/ml/" rel="self" type="application/rss+xml"/><item><title>Diffusion 扩散模型（DDPM）</title><link>https://jianye0428.github.io/posts/ddpm/</link><pubDate>Mon, 31 Jul 2023 15:57:07 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/ddpm/</guid><description><![CDATA[<h2 id="一引入">一、引入</h2>
<p></p>
<p>近年AIGC的爆火离不开人工智能在图像生成、文本生成以及多模态等领域的不断累积，其中<strong>生成模型</strong>的发展占据了很大功劳，如：<mark>生成对抗网络 GAN</mark> 及其一系列变体、<mark>变分自编码器 VAE</mark> 及其一系列变体、<mark>自回归模型 AR</mark>、<mark>流模型 flow</mark> ，以及近年大火的<strong>扩散模型 Diffusion Model</strong> 等。</p>
<p>扩散模型的大火并非横空出世，早在2015年就有人提出了类似的想法，直到2020年才提出了经典的 <strong>Denoising Diffusion Probabilistic Models（DDPM）</strong>，像OpenAI、NovelAI、NVIDIA和Google成功的训练了大规模模型之后，它们吸引了很多人注意，后续有了很多基于扩散模型的变体，比如有：GLIDE、DALLE-2、Imagen和年底爆火的完全开源的稳定扩散模型（Stable Diffusion）。</p>
<p>扩散模型与之前所有的生成方法有着本质的区别：</p>
<p></p>
<p>直观的说它是<mark>将图像生成过程（采样）分解为许多小的去噪步骤</mark>，其实 Diffusion 的含义本质上就是一个迭代过程，实线箭头用于扩散步骤中添加随机噪声，虚线箭头代表的是通过学习逆向扩散过程<mark>从噪声中重构所需的数据样本</mark>。<strong>引入噪声导致了信息的衰减，再通过噪声尝试还原原始数据，多次迭代最小化损失后，能够使模型在给定噪声输入的情况下学习生成新图像。</strong></p>
<p>所以Diffusion模型和其它生成模型的区别是，它不是直接的<strong>图像-&gt;潜变量、潜变量-&gt;图像</strong>的一步到位，它是一步一步的<mark><font color=red><strong>逐渐分解、逐渐去噪</strong></font></mark>的过程。</p>
<p>当然有关Diffusion的理解和变体有很多，但是扩散模型从本质上讲就是DDPM，所以本文主要对DDPM的原理进行讲解，并给出DDPM的扩散过程、去噪过程、训练损失的详细推导，对于掌握Diffusion算法原理只需要抓住以下四点即可：</p>
<ul>
<li>前向过程（扩散）；</li>
<li>反向过程（去噪、采样）；</li>
<li>如何训练；</li>
<li>如何推断。</li>
</ul>
<h2 id="二扩散原理阐述">二、扩散原理阐述</h2>
<p>扩散模型包括 <strong>前向扩散过程</strong> 和 <strong>反向去噪过程(采样)</strong>，前向阶段对图像逐步施加噪声，直至图像被破坏变成完全的高斯噪声，然后在反向阶段学习从高斯噪声还原为原始图像的过程。</p>
<h3 id="21直观理解">2.1、直观理解</h3>
<ul>
<li>扩散模型的目的是什么？
<ul>
<li>学习从纯噪声生成图片的方法。</li>
</ul>
</li>
<li>扩散模型是怎么做的？
<ul>
<li>训练一个UNet，接受一系列加了噪声的图片，学习预测所加的噪声。</li>
</ul>
</li>
<li>前向过程在干什么？
<ul>
<li>逐步向真实图片添加噪声最终得到一个纯噪声；</li>
<li>对于训练集中的每张图片，都能生成一系列的噪声程度不同的加噪图片；</li>
<li>在训练时，这些 【不同程度的噪声图片 + 生成它们所用的噪声】 是实际的训练样本。</li>
</ul>
</li>
<li>反向过程在干什么？
<ul>
<li>训练好模型后，采样、生成图片。</li>
</ul>
</li>
</ul>
<h3 id="22前向过程扩散">2.2、前向过程（扩散）</h3>
<p></p>
<p>前向过程在原始输入图像$x_0$上逐步添加随机噪声，这个噪声服从高斯分布$N(0, 1)$，每一步得到的图像$x_t$只和上一步的加噪结果$x_{t-1}$相关，逐步添加噪声至$T$步，可以得到趋向于纯粹噪声的图像，如下图所示：
</p>
<blockquote>
<p>后面有详细的推导，公式比较多，这里先提前把主要的列一下方便阐述。</p>
</blockquote>
<p>对于将一张图片，从$x_{t-1}\rightarrow x_{t}$的逐步加噪破坏的公式为：</p>
<p>$$x_t=\sqrt{\alpha_t}\left.x_{t-1}+\sqrt{1-\alpha_t}\right.\varepsilon_t\quad\quad\quad\quad\quad\quad(1)$$</p>
<p>其中:</p>
<ul>
<li>$x_t$表示第$t$步的图像；</li>
<li>$\varepsilon$ 是一个满足正态分布的随机噪声，$\varepsilon \sim N(0, 1)$；</li>
<li>$\sqrt{\alpha_{t}}$ 是图片的权重，$\sqrt{1 - \alpha_{t}}$ 是噪声的权重；</li>
</ul>
<p>定义：</p>
<ul>
<li>$\alpha_t=1-\beta_t$</li>
<li>$\overline{\alpha}=\prod_{s=1}^t\alpha_s$</li>
</ul>
<p>随着$t$的增加，<strong>噪声的占比会越来越大</strong>，所以添加的<strong>噪声强度也会越来越大</strong>，也就是说图片的权重要越来越小，噪声的权重要越来越大。因为随着扩散过程的增加，图像中噪声的占比也会越来越大，我们想要进一步破坏它的结构，就需要添加更多的噪声。</p>
<blockquote>
<p>换句话说，一开始图像比较清晰，这个时候添加的噪声小一些，随着图像的噪声越来越多，这个时候再加一点噪声的话，对原来的图像就没什么影响了，因为它本身就有好多噪声了，所以随着图像的噪声越来越多，后面的步骤就要加更多的噪声。</p>
</blockquote>
<p>实际训练过程中会比较大（DDPM原文中为1000），所以会有从$x_0$递推到$x_t$的公式：</p>
<p>$$x_t=\sqrt{\overline{\alpha}_t}\left.x_0+\sqrt{1-\overline{\alpha}_t}\right.\varepsilon\quad\quad\quad\quad(2)$$</p>
<p>其中：</p>
<ul>
<li>$\alpha_t$、$\beta_t$ 有一个固定的已知函数，是可以直接进行计算的；</li>
<li>$\varepsilon$ 为随机产生的噪声；</li>
</ul>
<p>所以整个式子是已知的，式 $(1)$、$(2)$ 就可以描述前向过程了，$(1)$ 用于将一张图片的逐步破坏，$(2)$ 用于一步到位的破坏。</p>
<h3 id="23反向过程去噪">2.3、反向过程（去噪）</h3>
<p>反向过程则是不断去除噪声的过程，给定一个噪声图片 $x_T$，对它一步步的去噪还原，直至最终将原始图像 $x_0$ 给恢复出来，如下图所示：</p>
<p></p>
<p>去噪的过程，$x_t$、$\alpha_t$、$\beta_t$ 都是已知的，只有公式 $(2)$ 中的真实噪声是未知的，因为它是随机采样的。所以需要一个神经网络把 $\varepsilon$ 给学出来，也就是说训练一个由 $x_t$ 和 $t$ 估测噪声的模型:</p>
<p>$$x_{t-1}=\frac{1}{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\overline{\alpha}<em>t}}\varepsilon</em>\theta(x_t,t))$$</p>
<p>其中 $\theta$ 就是模型的参数，通常使用UNet作为预估噪声的模型。</p>
<h3 id="24模型训练">2.4、模型训练</h3>
<p>所以说反向过程其实就是<strong>训练网络去学习分解过程每一步的噪声</strong>，当网络训练好之后，输入一张噪声图片，通过网络就能把加的噪声给求出来，噪声有了代入公式，就能把 $x_{t-1}$ 步的比较清晰的图给求出来了，一步步往前迭代就行了。</p>
<p>采用L2距离刻画相近程度就可以，DDPM的关键是训练 $\varepsilon_{\theta}(x_t, t)$，目的就是使预测的噪声与真实用于破坏的噪声相近：</p>
<p>$$Loss=\mid\mid\varepsilon-\varepsilon_\theta(x_t,t)\mid\mid^2=\mid\mid\varepsilon-\varepsilon_\theta(\sqrt{\overline{\alpha}_t}~x_0+\sqrt{1-\overline{\alpha}_t}~\varepsilon_t,t)\mid\mid^2$$</p>
<p></p>
<p>模型训练完后，只要给定随机高斯噪声，就可以生成一张从未见过的图像。</p>
<p>UNet本文不做介绍，结构图为：</p>
<p></p>
<blockquote>
<p>额外强调的是：Unet里有一个位置编码，是关于时间步的，每个时间步是有一个线性调度器的，每个时间添加的噪声的方差是不一样的，所以将时间步作为编码嵌入的话，可以将模型预测的噪声更加的准确。</p>
</blockquote>
<h2 id="三算法流程概述">三、算法流程概述</h2>
<p></p>
<p>再次总结，扩散模型两个步骤如下：</p>
<ul>
<li>一个固定的（预先定义好的）前向扩散过程 $q(x_t | x_{t-1})$：逐步向图片增加噪声直到最终得到一张纯粹的噪声图；</li>
<li>一个学习得到的去噪过程 $p_{\theta}(x_{t-1} | x_t)$：训练一个神经网络去逐渐的从一张纯噪声中消除噪声，直到得到一张真正的图片。</li>
</ul>
<p></p>
<p>算法1 为训练流程：</p>
<ul>
<li>line2：从数据中采样 $x_0$，$q(x_0)$ 的意思是给 $x_0$ 加上噪声；</li>
<li>line3：随机选取 time step $t$；
<ul>
<li>真实训练过程中我们不可能一步步的从 $t$ 到 $T$，因为会很大，这就意味着每输入一张图片 $x$，就会产生张噪声图像，也就是一张图像的网络要训练 $T$ 个噪声样本，非常耗时。</li>
<li>所以对 $T$ 进行了采样，$t$ 就是从 $T$ 里采集若干个的意思。</li>
<li>举个例子：假设采集 $t$ 的分别为100、20、3，对应的 $x$ 为 $x_{100}$、$x_{20}$、$x_{3}$，对应噪声为 $\varepsilon_{100}$、$\varepsilon_{20}$、$\varepsilon_{3}$，对于的预测噪声为 $\hat{\varepsilon}<em>{100}$、$\hat{\varepsilon}</em>{20}$、$\hat{\varepsilon}_{3}$, 只需要将 $\varepsilon$ 和 $\hat{\varepsilon}$ 代入MSE公式即可（相减、平方、最小化）。</li>
</ul>
</li>
<li>line 4：生成随机高斯噪声；</li>
<li>line 5：调用模型估计 $\varepsilon_{\theta}(\sqrt{\overline{\alpha}_t}~x_0+\sqrt{1-\overline{\alpha}_t}~\varepsilon_t,t)$ ，计算真实噪声与估计噪声之间的MSE Loss，反向传播更新模型。
<ul>
<li>网络的作用是预测噪声，随着的增加，噪声强度会越来越大，因此预测的噪声是和迭代是直接相关的，所以要把作为参数送入到网络当中。</li>
</ul>
</li>
<li>直到收敛。</li>
</ul>
<p>算法2 为采样流程：</p>
<ul>
<li>line 1：从高斯分布采样 $x_T$；</li>
<li>line 2：按照 $T, &hellip;, 1$ 的顺序进行迭代；</li>
<li>line 3：如果 $t = 1$ 令 $z = 0$；如果 $t &gt; 1$ ，从高斯分布中采样；</li>
<li>line 4：利用公式求出均值和方差，进而求得 $x_{t-1}$；</li>
<li>经过上述迭代，恢复 $x_0$。</li>
</ul>
<h2 id="四数学描述">四、数学描述</h2>
<p>我们来推导如何从原始图像直接到第t时刻的图像 $(X_0 - X_t)$。</p>
<p>首先回顾 2.1小节 的两个定义：</p>
<ul>
<li>$\alpha_t = 1 - \beta_{t}$, $\beta_t$ 要越大越好，论文中从0.0001到0.02;</li>
<li>$\overline{\alpha}=\prod_{s=1}^t\alpha_s$累乘，下面会用到；</li>
<li>$x_t=\sqrt{\alpha_t}x_{t-1}+\sqrt{1-\alpha_t}\varepsilon_t\text{,}\varepsilon_t\sim N(0,1)$ 每一时刻添加的噪声均独立；</li>
</ul>
<p>我们要求$x_t$时刻的图像，它需要一步步的加噪迭代，这样太慢了。因为每一步添加的噪声独立且服从正太分布，我们可以做如下推导：</p>
<blockquote>
<p>为了不混淆，只需要记住：<strong>下标越小，噪声越小</strong>，即 $x_{t-1}$ 的噪声是小于 $x_t$ 的。</p>
</blockquote>
<p>$$
\begin{aligned}
q(x_{t}\mid x_{t-1})&amp; =N(x_t;\sqrt{\alpha_t}x_{t-1},(1-\alpha_t)I)  \cr
&amp;=\underbrace{\sqrt{\alpha_t}x_{t-1}}<em>{x</em>{t-2}\text{来表示}x_{t-1}}+\sqrt{1-\alpha_t}\varepsilon_t \cr
&amp;=\sqrt{\alpha_t}\left(\sqrt{\alpha_{t-1}}\right.x_{t-2}+\sqrt{1-\alpha_{t-1}}\left.\varepsilon_{t-1}\right)+\sqrt{1-\alpha_t}\left.\varepsilon_t\right. \cr
&amp;=\sqrt{\alpha_t\alpha_{t-1}}x_{t-2}+\underbrace{\sqrt{\alpha_t-\alpha_t\alpha_{t-1}}\varepsilon_{t-1}+\sqrt{1-\alpha_t}\varepsilon_t}<em>{\text{两个独立正太分布相加}} \cr
&amp;=\sqrt{\alpha_t\alpha</em>{t-1}}\left.x_{t-2}+\sqrt{1-\alpha_t\alpha_{t-1}}\right.\varepsilon  \cr
&amp;\text{&hellip;} \
&amp;=\sqrt{\overline{\alpha}_t}\left.x_0+\sqrt{1-\overline{\alpha}_t}\right.\varepsilon  \cr
&amp;\therefore q(x_t\mid x_0)=N(x_t;\sqrt{\overline{\alpha}_t}x_0,\sqrt{1-\overline{\alpha}_t}I)
\end{aligned}
$$</p>
<blockquote>
<p>上述用的就是重参数化技巧。</p>
</blockquote>
<p>方差参数 $\beta_{t}$ 可以固定为一个常数，也可以选择作为 $T$ 时间段的一个时间表。事实上，人们可以定义一个方差表，它可以是线性的、二次的、余弦的等等。最初的DDPM作者利用了一个从 $\beta_1 = 10^{-4}$ 到$\beta_T = 0.02$增加的线性时间表。Nichol等人2021年的研究表明，采用余弦时间表效果更好。</p>
<p></p>
<h3 id="42反向过程去噪">4.2、反向过程（去噪）</h3>
<p>接下来是反向过程的推导：
$$p(x_{t-1}\mid x_t)=N(x_{t-1};\underbrace{\mu_\theta(x_t,t)}<em>\text{要反预测这个},\overbrace{\Sigma</em>\theta(x_t,t)}^{fixed})$$</p>
<p>给定$x_t$要预测 $x_{t-1}$，它是一个高斯分布，$x_t$和$t$的方差是固定的，论文作者使用原始的噪声调度器作为方差，也就是说噪声调度器一旦确立，方差的大小也就固定了。所以我们只需要预测这个均值就好了，下面给出具体的推导过程：</p>
<p>我们先看整个损失函数，是个<strong>负对数似然</strong>：</p>
<p>$$-\log{p_{\theta}(x_0)}$$</p>
<p>希望神经网络的参数 $\theta$，可以使得生成 $x_0$的概率越大越好。</p>
<p>但问题在于 $x_0$ 的概率不好计算，因为它依赖于 $x_0$ 之前的所有步长，从 $x_T$ 开始。作为一种解决方案，我们可以计算这个目标的<strong>变分下界</strong>，并得到一个更易于计算的公式：</p>
<p>$$-log(p_\theta(x_0))\leq-log(p_\theta(x_0))+D_{KL}(q(x_{1:T}\mid x_0)\parallel p_\theta(x_{1:T}\mid x_0))$$</p>
<p>其中：</p>
<ul>
<li>$x_{1:T}$ 指的是 $x_1, &hellip;, x_T$ 整个序列。</li>
</ul>
<p>现在依然无法计算，我们继续推导：</p>
<p>$$
\begin{gathered}
-log(p_\theta(x_0)) \leq-log(p_\theta(x_0))+D_{KL}(q(x_{1:T}\mid x_0)\mid\mid p_\theta(x_{1:T}\mid x_0)) \cr
\leq-log(p_\theta(x_0))+log(\frac{q(x_{1:T}\mid x_0)}{p_\theta(x_{1:T}\mid x_0)})
\end{gathered}
$$</p>
<p>我们将 KL divergence 改写后，再利用贝叶斯公式进行变形，即分母可以改写为：</p>
<p>$$
\begin{aligned}
p_\theta(x_{1:T}\mid x_0) &amp;=\frac{p_\theta(x_0\mid x_{1:T})\mathrm{~}p_\theta(x_{1:T})}{p_\theta(x_0)} \cr
&amp;=\frac{p_\theta(x_0,x_{1:T})}{p_\theta(x_0)} \cr
&amp;=\frac{p_\theta(x_{0:T})}{p_\theta(x_0)}
\end{aligned}
$$</p>
<p>将其代回原式：</p>
<p>$$
\begin{aligned}
log(\frac{q(x_{1:T}\mid x_0)}{p_\theta(x_{1:T}\mid x_0)})&amp; =log(\frac{q(x_{1:T}\mid x_0)}{\frac{p_\theta(x_{0:T})}{p_\theta(x_0)}})  \cr
&amp;=log(\frac{q(x_{1:T}\mid x_0)}{p_\theta(x_{0:T})})+log(p_\theta(x_0))
\end{aligned}
$$</p>
<p>所以原式可简化为：</p>
<p>$$-log(p_\theta(x_0))\leq\underbrace{log(\frac{q(x_{1:T}\mid x_0)}{p_\theta(x_{0:T})})}_{\text{变分下界,可以优化它}}$$</p>
<ul>
<li>
<p>分子，就是前向过程，它是固定的，从 $x_0$ 到 $x_{1:T}$ 的采样，换句话说就是从我们数据中的一些图像开始；</p>
</li>
<li>
<p>分母，$p_\theta(x_{0:T})=p(x_T)\prod_{t=1}^Tp_\theta(x_{t-1}\mid x_t)$；</p>
<ul>
<li>将 $p(x_T)$ 提出来，是因为 $p(x_T)$ 是指当前图像，它是不依赖于网络参数 $\theta$ 的.</li>
</ul>
<p>$$
\begin{aligned}
log(\frac{q(x_{1:T}\mid x_0)}{p_{\theta}(x_{0:T})})&amp; =log(\frac{\prod_{t=1}^Tq(x_t\mid x_{t-1})}{p(x_T)\prod_{t=1}^Tp_\theta(x_{t-1}\mid x_t)})  \cr
&amp;=-log(p(x_T))+log(\frac{\prod_{t=1}^Tq(x_t\mid x_{t-1})}{\prod_{t=1}^Tp_\theta(x_{t-1}\mid x_t)}) \cr
&amp;=-log(p(x_T))+\sum_{t=1}^Tlog(\frac{q(x_t\mid x_{t-1})}{p_\theta(x_{t-1}\mid x_t)}) \cr
&amp;=-log(p(x_T))+\sum_{t=2}^Tlog(\frac{q(x_t\mid x_{t-1})}{p_\theta(x_{t-1}\mid x_t)})+\underbrace{log(\frac{q(x_1\mid x_0)}{p_\theta(x_0\mid x_1)})}_{t=1}
\end{aligned}
$$</p>
</li>
</ul>
<p></p>
<p>$q(x_t|x_{t-1})$ 根据贝叶斯公式可以变换如下：</p>
<p>$$q(x_t\mid x_{t-1})=\frac{q(x_{t-1}\mid x_t)q(x_t)}{q(x_{t-1})}$$</p>
<p>$q(x_{t-1}|x_{t})$具有比较高的方差，因为根据这张照片，我们无法确定它来自哪里，但是引入 $x_0$，我们就可以容易的预测出 $x_{t-1}$，</p>
<p></p>
<p>因此我们使用：</p>
<p>$$\frac{q(x_{t-1}\mid x_t,x_0)\mathrm{~}q(x_t\mid x_0)}{q(x_{t-1}\mid x_0)}$$</p>
<p>替换贝叶斯重写后的式子，我们得到：</p>
<p>$$
\begin{aligned}
log(\frac{q(x_{1:T}\mid x_0)}{p_{\theta}(x_{0:T})})&amp; =-log(p(x_T))+\sum_{t=2}^Tlog(\frac{q(x_{t-1}\mid x_t,x_0)q(x_t\mid x_0)}{p_\theta(x_{t-1}\mid x_t)q(x_{t-1}\mid x_0)})+log(\frac{q(x_1\mid x_0)}{p_\theta(x_0\mid x_1)})  \cr
&amp;=-log(p(x_T))+\sum_{t=2}^Tlog(\frac{q(x_{t-1}\mid x_t,x_0)}{p_\theta(x_{t-1}\mid x_t)})+\underbrace{\sum_{t=2}^Tlog(\frac{q(x_t\mid x_0)}{q(x_{t-1}\mid x_0)})}+log(\frac{q(x_1\mid x_0)}{p_\theta(x_0\mid x_1)})
\end{aligned}
$$</p>
<p>上述标记的式子，也可以简化，我们假设 $t=4$：</p>
<p>$$
\begin{gathered}
\begin{aligned}\sum_{t=2}^{T=4}log(\frac{q(x_t\mid x_0)}{q(x_{t-1}\mid x_0)})\end{aligned} =log(\frac{q(x_2\mid x_0)}{q(x_1\mid x_0)}\cdot\frac{q(x_3\mid x_0)}{q(x_2\mid x_0)}\cdot\frac{q(x_4\mid x_0)}{q(x_3\mid x_0)}) \
=log(\frac{q(x_4\mid x_0)}{q(x_1\mid x_0)})
\end{gathered}
$$</p>
<p>因此我们可以简化为：</p>
<p>$$
\begin{aligned}
&amp;=-log(p(x_T))+\sum_{t=2}^Tlog(\frac{q(x_{t-1}\mid x_t,x_0)}{p_\theta(x_{t-1}\mid x_t)})+log(\frac{q(x_t\mid x_0)}{q(x_1\mid x_0)})+log(\frac{q(x_1\mid x_0)}{p_\theta(x_0\mid x_1)}) \cr
&amp;=-log(p(x_T))+\sum_{t=2}^Tlog(\frac{q(x_{t-1}\mid x_t,x_0)}{p_\theta(x_{t-1}\mid x_t)})+log(q(x_t\mid x_0))-log(p_\theta(x_0\mid x_1)) \cr
&amp;=log(\frac{q(x_t\mid x_0)}{p(x_T)})+\sum_{t=2}^Tlog(\frac{q(x_{t-1}\mid x_t,x_0)}{p_\theta(x_{t-1}\mid x_t)})-log(p_\theta(x_0\mid x_1))\cr
&amp;=\overbrace{\underbrace{D_{KL}(q(x_t\mid x_0)\mid\mid p(x_T))}<em>{q\text{只是个正向过程没有可学习参数}}}^{\text{可以忽略}} + \sum</em>{t=2}^TD_{KL}(q(x_{t-1}\mid x_t,x_0)\mid\mid p_\theta(x_{t-1}\mid x_t))-log(p_\theta(x_0\mid x_1))
\end{aligned}
$$</p>
<ul>
<li>第一项KL散度可以忽略，因为$q$只是个正向过程，没有可学习参数，换句话说就是它是固定的。</li>
<li>第二项KL散度，左边和右边都是正太分布，分别服从 $N(x_{t-1};\tilde{\mu_t}(x_t,x_0),\tilde{\mathsf{\beta}<em>t}I)$ 、$N(x</em>{t-1};\mu_\theta(x_t,t),\text{β}I)$：</li>
</ul>
<p>$$
\sum_{t=2}^TD_{KL}(\underbrace{q(x_{t-1}\mid x_t,x_0)}<em>{N(x</em>{t-1};\tilde{\mu}<em>t(x_t,x_0),\tilde{\mathsf{\beta}}<em>tI)}\mid\mid\overbrace{p</em>\theta(x</em>{t-1}\mid x_t)}^{N(x_{t-1};\mu_\theta(x_t,t),\mathsf{\beta}I})
$$</p>
<p>第一项的 $\tilde{\mu_{t}}(x_{t},x_{0})$、$\tilde{\beta_{t}}$ 就是我们要求的值，这里省略了这部分的推导，不影响算法的理解，</p>
<p>$$
\begin{gathered}\tilde{\mu}<em>t(x_t,x_0)=\frac{\sqrt{\alpha_t}(1-\overline{\alpha}</em>{t-1})}{1-\overline{\alpha}<em>t}x_t+\frac{\sqrt{\alpha}</em>{t-1}\beta_t}{1-\overline{\alpha}_t}x_0\\tilde{\mathsf{\beta}}<em>t=\frac{1-\overline{\alpha}</em>{t-1}}{1-\overline{\alpha}_t}\beta_t\end{gathered}
$$</p>
<blockquote>
<p>凡是涉及到 $\alpha_t$ 的，就是学习调度器的，我们不需要关注它</p>
</blockquote>
<p>我们可以化简 $\tilde{\mu}_{t}$，我们知道 $x_t=\sqrt{\overline{\alpha}_t}x_0+\sqrt{1-\overline{\alpha}_t}\varepsilon $, 即:</p>
<p>$$
x_0=\frac1{\sqrt{\overline{\alpha}_t}}(x_t-\sqrt{1-\overline{\alpha}_t}\left.\varepsilon\right)
$$</p>
<p>还知道: $\overline{\alpha}=\prod_{s=1}^t\alpha_s$、$\alpha_t=1-\beta_t$:</p>
<p>代入 $\tilde{\mu}_{t}$ 得到：</p>
<p>$$
\begin{aligned}
\underbrace{\tilde{\mu}<em>t(x_t,x_0)}</em>{\text{不再依赖}x_0}&amp; =\frac{\sqrt{\alpha_{t}}(1-\overline{\alpha}<em>{t-1})}{1-\overline{\alpha}</em>{t}}x_{t}+\frac{\sqrt{\overline{\alpha}<em>{t-1}}\beta</em>{t}}{1-\overline{\alpha}<em>{t}}\frac{1}{\sqrt{\overline{\alpha}</em>{t}}}(x_{t}-\sqrt{1-\overline{\alpha}<em>{t}}\varepsilon)  \cr
&amp;=\frac{\alpha_t(1-\overline{\alpha}</em>{t-1})x_t}{\sqrt{\alpha_t}(1-\overline{\alpha}_t)}+\frac{\beta_t}{\sqrt{\alpha_t}(1-\overline{\alpha}_t)}(x_t-\sqrt{1-\overline{\alpha}_t}\left.\varepsilon\right) \cr
&amp;=\frac{\alpha_tx_t-\overline{\alpha}_tx_t+(1-\alpha_t)x_t-(1-\alpha_t)\sqrt{1-\overline{\alpha}_t}\varepsilon}{\sqrt{\alpha_t}(1-\overline{\alpha}_t)} \cr
&amp;=\frac{x_t(1-\overline{\alpha}_t)-(1-\alpha_t)\sqrt{1-\overline{\alpha}_t}\varepsilon}{\sqrt{\alpha_t}(1-\overline{\alpha}_t)} \cr
&amp;=\frac{x_t}{\sqrt{\alpha_t}}-\frac{(1-\alpha_t)\varepsilon}{\sqrt{\alpha_t}\sqrt{(1-\overline{\alpha}_t)}} \cr
&amp;=\frac1{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\overline{\alpha}_t}}\left.\varepsilon\right)
\end{aligned}
$$</p>
<p>代入之后我们发现它就不再依赖于 $x_0$ 了，它就是和 $x_t$ 的一个关系式，式中的 $\alpha_t$、$\beta_t$、$\varepsilon$都是已知的，最后的本质就是我们只是从中减去缩放的随机噪声。</p>
<p>$$\therefore x_{t-1}=N(x_{t-1};\frac1{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\overline{\alpha}<em>t}}\left.\varepsilon</em>\theta(x_t,t)\right),\Sigma_\theta(x_t,t))$$</p>
<p>这样一来，DDPM的每一步推断可以总结为：</p>
<ul>
<li>每个时间步通过 $x_t$ 和 $t$ 来预测高斯噪声，图中用 $z$ 表示，根据上述公式计算得到均值 $\mu$；</li>
<li>得到方差 $\Sigma_\theta(x_t,t)$</li>
<li>入公式得到 $q(x_{t-1}\mid x_t)$ ，利用重参数化得到 $x_{t-1}$ 。</li>
</ul>
<p></p>
<h3 id="43训练损">4.3、训练损</h3>
<p>下面我们来看损失的推导，我们来回顾第二项：</p>
<p></p>
<p>我们需要减小KL散度，由于<mark>方差是固定的，我们无法优化，所以需要将它们的均值之差减小</mark>，原论文中使用的是简单的均方误差：</p>
<p>将$\mu$表达式代入：</p>
<p>$$
\begin{aligned}
L_{t}&amp; =\frac1{2\sigma_t^2}\mid|\tilde{\mu}<em>t(x_t,x_0)-\mu</em>\theta(x_t,t)||^2  \cr
&amp;=\frac1{2\sigma_t^2}\mid\mid\frac1{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\overline{\alpha}<em>t}}\left.\varepsilon\right)-\frac1{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\overline{\alpha}<em>t}}\left.\varepsilon</em>\theta(x_t,t)\right)\mid\mid^2 \cr
&amp;=\frac{\beta_t^2}{2\sigma_t^2\alpha_t(1-\overline{\alpha}<em>t)}\underbrace{\mid\mid\varepsilon-\varepsilon</em>\theta(x_t,t)\mid\mid^2}</em>{mse} \cr
&amp;-&gt;\mid\mid\varepsilon-\varepsilon_\theta(x_t,t)\mid\mid^2=\mid\mid\varepsilon-\varepsilon_\theta(\sqrt{\overline{\alpha}_t}\left.x_0+\sqrt{1-\overline{\alpha}_t}\left.\varepsilon_t,t\right)\mid\mid^2\right.
\end{aligned}
$$</p>
<p>研究人员发现，忽略前面的系数项会变得更简单，采样质量也会得到提高，所以前面这个系数项我们直接忽略，它是和噪声调度器有关的，我们加噪的话也会使计算复杂。</p>
<p>我们最小化 $\mid\mid\varepsilon-\varepsilon_\theta(x_t, t)\mid\mid^2$ 也就是<strong>最小化了KL散度</strong>，KL散度变小了也就是变分上限优化到最小，所以那个负对数似然也会变小。</p>
<p>上面还剩了最后一项 $-log(p_\theta(x_0\mid x_1))$ ，这个作者决定去掉它，即在 $t=1$ 时，我们不添加噪声。也就是下面横线的地方，只有 $t&gt;1$ 的时候才服从高斯分布，如果 $t\leq {1}$，直接让 $z=0$，即噪声设置为0。</p>
<p></p>
<p>回顾上面整个推导过程：我们从<strong>负对数似然 -&gt; 优化下界 -&gt; 简化下界 -&gt; 预测噪声</strong>。</p>
<h2 id="五torch复现">五、torch复现</h2>
<p><a href="https://wangguisen.blog.csdn.net/article/details/128821008"target="_blank" rel="external nofollow noopener noreferrer">https://wangguisen.blog.csdn.net/article/details/128821008<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<p>ref:
[1]. <a href="https://arxiv.org/abs/2006.11239"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/abs/2006.11239<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[2]. <a href="https://kexue.fm/archives/9119"target="_blank" rel="external nofollow noopener noreferrer">https://kexue.fm/archives/9119<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[3]. <a href="https://zhuanlan.zhihu.com/p/576475987"target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/576475987<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[4]. <a href="https://zhuanlan.zhihu.com/p/525106459"target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/525106459<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[5]. <a href="https://www.bilibili.com/video/BV1b541197HX"target="_blank" rel="external nofollow noopener noreferrer">https://www.bilibili.com/video/BV1b541197HX<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[6]. <a href="https://www.bilibili.com/video/BV1WD4y1E7X5"target="_blank" rel="external nofollow noopener noreferrer">https://www.bilibili.com/video/BV1WD4y1E7X5<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[7]. <a href="https://huggingface.co/blog/annotated-diffusion"target="_blank" rel="external nofollow noopener noreferrer">https://huggingface.co/blog/annotated-diffusion<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[8]. <a href="https://www.datalearner.com/blog/1051664857725795"target="_blank" rel="external nofollow noopener noreferrer">https://www.datalearner.com/blog/1051664857725795<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[9]. <a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models"target="_blank" rel="external nofollow noopener noreferrer">https://lilianweng.github.io/posts/2021-07-11-diffusion-models<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[10]. <a href="https://mp.weixin.qq.com/s?__biz=Mzk0MzIzODM5MA==&amp;mid=2247486128&amp;idx=1&amp;sn=7ffef5d8c1bbf24565d0597eb5eaeb16&amp;chksm=c337b729f4403e3f4ca4fcc1bc04704f72c1dc02876a2bf83c330e7857eba567864da6a64e18&amp;scene=21#wechat_redirect"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s?__biz=Mzk0MzIzODM5MA==&mid=2247486128&idx=1&sn=7ffef5d8c1bbf24565d0597eb5eaeb16&chksm=c337b729f4403e3f4ca4fcc1bc04704f72c1dc02876a2bf83c330e7857eba567864da6a64e18&scene=21#wechat_redirect<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
[11]. <a href="https://arxiv.org/pdf/2006.11239.pdf"target="_blank" rel="external nofollow noopener noreferrer">paper link<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
]]></description></item><item><title>变分自编码器 VAE 详解</title><link>https://jianye0428.github.io/posts/vae_1/</link><pubDate>Thu, 27 Jul 2023 10:53:41 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/vae_1/</guid><description><![CDATA[<!-- <div class="details admonition quote">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-quote-right fa-fw" aria-hidden="true"></i>quote<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">note abstract info tip success question warning failure danger bug example quote</div>
    </div>
  </div> -->
<h2 id="引入">引入</h2>
<p></p>
<div class="details admonition Notes open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Notes<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">本文也是为写 Stable Diffusion 相关文章做的铺垫，主要参考了李宏毅老师的视频课以及B站的白板推导系列。有关GMM、蒙特卡洛、ELBO、变分推断、重参数化的细节本文不做详细介绍，主要围绕VAE的结构以及loss优化推导做讲解。</div>
    </div>
  </div>
<p>我们先来简单的引入一下：</p>
<ul>
<li>V：变分推断，它的意思来自于概率图模型，本文会给出变分下界的详细推导；</li>
<li>AE：Auto-Encoder，自编码器；</li>
<li>VAE：Variational Auto-Encoder，<strong>变分自编码器</strong>，将概率图模型和神经网络相结合的模型；</li>
</ul>
<h2 id="一ae">一、AE</h2>
<p></p>
<p>先来介绍一下自编码器（Auto-Encoder），它是一种无监督学习方法，如上图所示，原理可概述为：</p>
<ul>
<li>将高维原始数据（如图片）送入 Encoder，利用 Encoder 将高维数据映射到一个低维空间，将n维压缩到m维($m&laquo;n$)，我们用隐变量来表示；</li>
<li>然后将低维空间的特征送入 Decoder 进行解码，以此来重建原始输入数据。</li>
</ul>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">Encoder、Decoder网络可以为普通的全连接、也可以为CNN、或者类似于Unet都可以，没有固定的要求。</div>
    </div>
  </div>
<p>这里为和后文的推导联系起来，我们将 Encoder 网络的映射函数定义为 $q_{\phi}$ 、Decoder 网络定义为 $p_{\theta}$，其中 $\phi$、$\theta$ 皆为网络参数。</br>
那么对于输入 $x$，我们可以通过Encoder得到 <code>Latent Variable</code>：$z = q_{\phi}(x)$，然后Decoder可以从隐变量z中对原始数据进行重建：$x&rsquo; = p_{\theta}(z) = p_{\theta}(q_{\phi}(x))$。</p>
<p>我们希望重建的数据和原来的数据近似一致，即最小化输入和输出之间的重构误差，那么AE的训练损失可以采用简单的MSE：</p>
<p>$$L_{\text{AE}}(\theta, \phi) = \frac{1}{n}\sum_{i=1}^{n} (x^{(i)} - x&rsquo;^{(i)})^2 =\frac{1}{n}\sum_{i=1}^{n} (x^{(i)} - p_{\theta}(q_{\phi}(x^{(i)})))^2$$</p>
<div class="details admonition Note">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">可以理解为比较输入和重构输入的像素点的误差。</div>
    </div>
  </div>
<h2 id="二ae-存在的问题">二、AE 存在的问题</h2>
<p>上面我们通过AE可以<font color=lightseablue><strong>构建一个重构图像的模型</strong></font>，但是这个模型并不能满足要求，或者说它并不是真正意义上的生成模型。对于一个生成模型而言，它满足：</p>
<ul>
<li><strong>Encoder 和 Decoder 可以独立拆分（类比 GAN 的 Generator 和 Discriminator）；</strong></li>
<li><strong>固定维度下<font color=red>任意采样</font>出来的编码，都应该能通过 Decoder 产生一张清晰且逼真的图片。</strong></li>
</ul>
<p>当然对于第一点它是满足的，我们主要分析第二点，也就是AE存在的问题，从而引出VAE。</p>
<p></p>
<p>如上图所示，用一张全月图和一张半月图去训练一个AE，经过训练模型是能够很好的还原出这两张图片。</p>
<p>接下来，我们在 latent code 中任取一点，将其交给 Decoder 进行解码，直觉上我们会得到一张介于全月和半月之前的图片（比如阴影面积覆盖的样子）。然而<font color=red>实际上的输出图片不仅模糊而且还是乱码的</font>。</p>
<p>对于这个现象，一个直观的解释就是AE的 Encoder 和 Decoder 都用了DNN，那么NN只会干一件事情：学习、记住、用记住的东西预测，我们<u>从 latent space 中采样的点，编码器都没有学习过</u>，怎么能够指望它生成希望的值呢?</p>
<p>换句话说，<font color=red><strong>NN只记住了左边全月图片的隐向量和右边半月图片的隐向量，并不能泛化到中间就是$\frac{3}{4}$月亮的图片</strong></font>。</p>
<p>为了解决这个问题，一个最直接的思想就是<strong>引入噪声</strong>，扩大图片的编码区域，从而能够覆盖到失真的空白编码区，如下图所示：</p>
<p></p>
<p>其实说白了就是<strong>通过增加输入的多样性从而增强输出的鲁棒性</strong>。</p>
<p>当我们给输入图片进行编码之前引入一点噪声，使得每张图片的编码点出现在绿色箭头范围内，这样一来所得到的 latent space 就能覆盖到更多的编码点。此时我们再从中间点抽取还原便可以得到一个比较希望的输出。</p>
<p>虽然我们给输入的图片增加了一些噪声，使得 latent space 能够覆盖到比较多的区域，但是还有不少地方没有覆盖到，比如上图的黄色点位置。</p>
<p>因此，我们是不是可以尝试利用更多的噪声，使得对于每一个输入样本，它的编码都能够覆盖到整个编码空间？只不过我们这里需要保证的是：<font color=red>对于编码附近的我们应该给定一个高的概率值，对于距离原编码点远的应该给定一个低的概率值</font>。</p>
<p>这样总体来说，我们就是要将原先的一个单点拉伸到整个编码空间，即将离散的编码点拉伸为一条连续的接近正太分布的编码曲线，如下图所示：</p>
<p></p>
<p>这个其实就是VAE的思想，熟悉GMM的同学应该知道，它是K个高斯分布（Gaussian Distribution）的混合，其实**<font color=green>VAE可以说是无限个高斯分布的混合</font>**。</p>
<h2 id="三vae-结构预览">三、VAE 结构预览</h2>
<p></p>
<p>如上图所示VAE的结构，我们可以看到VAE里的编码器不是输出隐向量$z$，而是一个概率分布，分布的均值为$m$、方差为$\sigma$，$e$ 即为给编码添加的噪声，来自于正态分布。</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>tips<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">VAE的Encoder的输出不是隐向量，而是均值为$m$, 方差为$\sigma$的正态分布。</div>
    </div>
  </div>
<p>公式怎么得到的后面会给出推导，我们先来描述一下这个过程：</p>
<p>$$z_{i} = c_{i} = \exp(\sigma_i) * e_i + m_i$$</p>
<ul>
<li>Encoder会计算出两组编码，一组为均值m、一组为控制噪声干扰程度的方差$\sigma$；</li>
<li>方差$\sigma$主要用来为噪声编码 $e$ 分配权重；</li>
<li>取指数主要是为了保证分配到的权重是正值；</li>
<li>也就是说数据分布会在 $\exp(\sigma_i) * e$ 方差范围内采样一个值，得到一个偏移量，就是相当于把原始的样本加上了一个噪声。从结构图中我们可以看到，损失除了AE的 重构损失（reconstruction error）外，还多出了下面这一项：
$$c = (c_1, c_2, c_3) = \sum_{i=1}^{3} (e^{\sigma_i} - (1 + \sigma_i) + (m_i)^2)$$</li>
</ul>
<p>这个辅助loss可以认为是一个约束，也就是说生成的 $\sigma$ 要满足这个约束。</p>
<p><strong>为什么要加这个辅助loss？</strong></p>
<ul>
<li>我们最小化了 reconstruction error，如果不加这个辅助loss的话，Encoder肯定希望噪声对自身生成的图片干扰越小越好，为了保证生成图片的质量，于是分配给噪声的权重也就是越低。如果不加这个约束的话，网络只需要将方差设置为接近负无穷大的值 $\exp ^ {-\infty} = 0$，即可消除噪声带来的影响，这样必然会过拟合导致鲁棒性不佳。</li>
</ul>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>tips<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">添加辅助loss是为了防止过拟合，提高模型的鲁棒性。</div>
    </div>
  </div>
<p><strong>为什么加这个辅助loss有用？</strong></p>
<ul>
<li>我们对 $\sigma$ 求导可得 $c = e^{\sigma} - 1$，令其等于0可求出 $\sigma = 0$ 时取得极小值，这样一来便可以约束方差不会一路走向负无穷，从而起到正则化约束的作用；</li>
<li>如下图所示，$e^{\sigma}$ 是蓝色曲线，$1 + \sigma$ 是红色线条，那么 $e^{\sigma} - (1 + \sigma)$就是蓝色曲线减去红色直线，得到绿色曲线，显而易见的可以发现它的最小值为0。</li>
</ul>
<p></p>
<h2 id="四数学描述">四、数学描述</h2>
<h3 id="41作者的-intuition">4.1、作者的 Intuition</h3>
<p>
</p>
<p>借用作者原文的表述，我们来引入定义。如上图所示，首先我们会有一个高维的随机变量，与之相关联的我们叫它隐变量 $z$，$z$ 的维度一般要比 $x$ 低很多，用来描述 $x$ 中所包含的信息。</p>
<p>我们假设 $z$ 满足分布 $p_{\theta}(z)$，$x$ 也是一个条件概率，也就是说：</p>
<ul>
<li>在已知 $z$ 的情况下，$p_{\theta}(z)$能生成一个sample $x$ ；</li>
<li>给定一个sample $x$，$q_{\phi}(x)$ 就可以尝试推测出这个来。</li>
</ul>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content"><p>因为假设$z$满足一定分布，所以也有从$\theta$到$z$的箭头；</p>
<p>之后提到的$z$都是Decoder里的参数。</p>
</div>
    </div>
  </div>
<p>这么说可能有点抽象，我们举个例子：</p>
<p></p>
<p>如上图所示，假设有一个图像，里面有3个颜色不一致的形状，这个就是我们的输入$x$。通过右图的参数，可以控制$x$，这就是隐变量$z$。</p>
<p>那么回到实际的应用场景，我们想要通过$x$获得$z$，又想通过$z$得到相应的$x$，也就是图中的双箭头就是我们想要做的事情。</p>
<p>那么对于生成模型而言，VAE的数据产生包括两个过程：</p>
<ul>
<li>从一个先验分布 $p_{\theta}(z)$ 中采样一个 $z^{(i)}$；</li>
<li>根据条件分布 $p_{\theta}(x|z)$，用 $z^{(i)}$ 生成 $x^{(i)}$。</li>
</ul>
<p>我们希望找到一个参数 $\theta^*$ 来<strong>最大化生成真实数据的概率</strong>：</p>
<p>$$\theta^*=\argmax_{\theta} \prod_{i=1}^{n}p_{\theta}(x^{(i)})$$</p>
<p>这里 $p_{\theta}(x^{(i)})$ 可以通过对 $z$ 积分得到：</p>
<p>$$p_{\theta}(x^{(i)}) = \int_{z} p_{\theta}(x, z) \mathrm{d}{z} = \int_{z} p_{\theta}(z) p_{\theta}(x^{(i)}|z)\mathrm{d}{z}$$</p>
<p>实际上我们要根据上述积分是不可能实现的，先验分布 $p_{\theta}(z)$ 是未知的，而且如果分布比较复杂且高维，对其穷举计算也是不现实的。</p>
<p><strong>变分推断引入后验概率来联合建模</strong>，即given $x$ 想要得到它的 $z$，根据贝叶斯公式表示为：</p>
<p>$$p_{\theta}(z | x) = \frac{p_{\theta}(x|z) p_{\theta}(z)}{p_{\theta}(x)}$$</p>
<p>我们又回到最上面的图：</p>
<p></p>
<ul>
<li>实线箭头就是我们要得到的生成模型 $p_{\theta}(z) p_{\theta}(x|z)$，这里 $p_{\theta} (z)$ 往往是事先定义好的，比如标准正态分布，而 $p_{\theta}(x|z)$ 可以用一个网络来学习，它就可以看成是 <strong>Probabilistic Decoder</strong>。</li>
<li>虚线箭头代表对后验分布 $p_{\theta}(z|x)$ 的变分估计，它也可以用一个网络去近似，我们记为 $q_{\phi}(z|x)$，则这个网络称为 <strong>Probabilistic Encoder</strong>。</li>
</ul>
<p>所以VAE的优化目标就有了，为了<strong>达到从x估计z的过程</strong>，对于估计的后验 $q_{\phi}(z|x)$，我们希望它<strong>接近</strong>真实的后验分布 $p_{\theta}(z|x)$ ，即：</p>
<p>$$p_{\theta}(z|x) \cong q_{\phi}(z|x)$$</p>
<p>说白了就是使用另一个模型，参数由 $\phi$ 表示，在参数 $\phi$ 的帮助下，有了一个分布 $q$ ，现在希望分布 $q$ 能够尽量接近 $p$，从而达到从 $x$ 估计 $z$ 的过程。</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content"><p>可以看到VAE和AE架构上还是相似的，VAE的最终目标是得到生成模型即Decoder，Encoder只是辅助建模。</p>
<p>而AE常常是为了得到Encoder来进行特征提取或压缩。</p>
</div>
    </div>
  </div>
<h3 id="42变分下界">4.2、变分下界</h3>
<p>为了衡量两个 distribution 的相似程度，我们应该很自然的想到了KL divergence，因为我们实际上计算的是分布 $q$ ，所以我们从 $q$ 的视角来计算它到 $p$ 的KL散度：</p>
<p>$$q_{\phi}(z|x) \cong p_{\theta}(z|x) \rightarrow D_{\text{KL}}(q_{\phi}(z|x) || p_{\theta}(z|x))$$</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content"><p>需要再次强调的是：</p>
<p>$\theta$ 为 decoder 的参数；</p>
<p>$\phi$ 为 encoder 的参数。</p>
</div>
    </div>
  </div>
<p>根据定义我们将KL divergence展开，对 $z$ 求和，表示如下：</p>
<p>$$
\begin{align}
D_{\text{KL}}(q_{\phi}(z|x) || p_{\theta}(z|x)) &amp;= \sum_{z} q_{\phi}(z | x) \log (\frac{q_{\phi}(z | x)}{p_{\theta}(z | x)}) \cr
&amp;= - \sum_{z} q_{\phi}(z | x) \log (\frac{p_{\theta}(z | x)}{q_{\phi}(z | x)})\cr
&amp;= - \sum_{z} q_{\phi}(z | x) \log (\frac{\frac{p_{\theta}(z,x)}{p_{\theta}(x)}}{q_{\phi}(z | x)})\cr
&amp;= - \sum_{z} q_{\phi}(z | x) [\log({\frac{p_{\theta}(x, z)}{p_{\theta}(x)}}) - \log({q_{\phi}(z | x)})]\cr
&amp;= - \sum_{z} q_{\phi}(z | x) [\log({\frac{p_{\theta}(x, z)}{q_{\phi}(z|x)}}) - \log({p_{\theta}(x)})]\cr
\end{align}
$$</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">$p_{\theta}(z | x)$ 是根据条件概率公式拆开的。</div>
    </div>
  </div>
<p>这个时候我们注意到 $\log(p_{\theta}(x))$ 是和 $z$ 没有关系的，并且log项是常数，所以在乘求和的时候直接提到 $\sum$ 外面去就可以了，并且 $q_{\phi} (z | x)$ 对 $z$ 求和的结果是1，那所以 $-\sum_{z}(q_{\phi}(z|x))(-\log(p_{\theta}(x)))$ 的结果就是 $\log(p_{\theta}(x))$，它是个const。</p>
<p>我们将它移到等式的左边，表示如下：</p>
<p>$$
\begin{align}
\log(p_{\theta}(x)) &amp;= D_{KL}(q_{\phi}(z|x) || p_{\theta}(z|x)) + \sum_{z}q_{\phi}(z|x)\log(\frac{p_{\theta}(x, z)}{q_{\phi}(z|x)}) \cr
&amp;= D_{KL}(q_{\phi}(z|x) || p_{\theta}(z|x)) + L(\theta, \phi; x)
\end{align}
$$</p>
<p>我们将 $\sum_{z}q_{\phi}(z|x)\log(\frac{p_{\theta}(x, z)}{q_{\phi}(z|x)})$ 写成 $L(\theta, \phi; x)$ ，等式左边是一个const，也就是说不管 $x$ 的分布是什么样，它对 $\theta$ 来说没什么影响。等式右边，KL divergence是一个非负的，所以我们只要把 $L(\theta, \phi; x)$ 的值尽可能的拉大，那么KL divergence的值就会随之缩小。</p>
<p><strong>想要最大化的$L(\theta, \phi; x)$，就被称为变分下界（Variational lower bound）。</strong></p>
<h3 id="43loss-function">4.3、Loss Function</h3>
<p>现在我们只要想办法将这个 lower bound 提升就可以了，那么这个 lower bound 就可以作为我们的 loss function：</p>
<p>$$
\begin{aligned}
L(\theta, \phi; x) &amp;= \sum_{z}q_{\phi}(z|x)\log(\frac{p_{\theta}(x, z)}{q_{\phi}(z|x)}) \cr
&amp;= \sum_{z}q_{\phi}(z|x)\log(\frac{p_{\theta}(x|z) p_{\theta}(z)}{q_{\phi}(z|x)}) \cr
&amp;= \sum_{z}q_{\phi}(z|x)[\log(p_{\theta}(x|z)) + \log(\frac{p_{\theta}(z)}{q_{\phi}(z | x)})] \cr
&amp;= {E}<em>{q</em>{\phi}(z|x)}[\log(p_{\theta}(x|z))] - D_{KL}(q_{\theta}(z | x) || p_{\theta}(z))
\end{aligned}
$$</p>
<p>上述等式，我们将 lower bound 再展开，将 $p_{\theta}(x, z)$ 展成条件概率，然后再将log拆分。</p>
<p>第三行中括号内，左边的可以写成期望的形式，右边的因为都有 $q_{\phi}$ 和 $p_{\theta}$ 所以符合KL divergence的公式。</p>
<ul>
<li>我们将 ${E}<em>{q</em>{\phi}(z|x)}[\log(p_{\theta}(x|z))]$ 称为<strong>Reconstruction Loss</strong>，</li>
<li>将 $-D_{KL}(q_{\theta}(z | x) || p_{\theta}(z))$ 称为 <strong>Regularization Loss</strong>。</li>
</ul>
<p>所以我们只需要估计出这两项的梯度来，就可以对 lower bound 进行优化了。</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">我们的目的是想让 Probabilistic Encoder 接近于 $p_{\theta}(z)$，因为两个损失，这样KL divergence就越大越好，实际-KL才是训练用的loss。</div>
    </div>
  </div>
<h3 id="44蒙特卡洛法求梯度">4.4、蒙特卡洛法求梯度</h3>
<p>接下来讲如何求出这两项的导数，来优化提升 lower bound。我们看到想要优化的这个loss，其实是可以写成期望的形式的，假定期望里的这一项是 $f(z)$，对于估计这种期望它的导数，最直接的我们就想到了蒙特卡洛的方法。</p>
<p></p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">虽然这里有个 $\phi$，但我们假定这个 $f(z)$ 和 $\phi$ 是没有关系的。(假设！！！！)</div>
    </div>
  </div>
<p>使用蒙特卡洛方法，对 $f(z)$ 在 $q_{\phi}$ 上的期望，对 $\phi$ 求导数，表示如下：</p>
<p>$$
\begin{aligned}
\eta &amp;= \triangle_{\phi} E_{q_{\phi}(z)}[f(z)]\cr
&amp;= \triangle_{\phi} \int {q_{\phi}(z)}f(z) \mathrm{d}z\cr
&amp;= \int \triangle_{\phi}{q_{\phi}(z)}f(z) \mathrm{d}z\cr
&amp;= \int {q_{\phi}(z)}f(z)\triangle_{\phi} \log {q_{\phi}(z)}\mathrm{d}z\cr
&amp;= E_{q_{\phi}(z)}[f(z)\triangle_{\phi} \log {q_{\phi}(z)}]
\end{aligned}
$$</p>
<ul>
<li>$line 1 \sim 2:$ 根据期望的定义展开，因为我们假设 $f(z)$ 和 $\phi$ 没有关系，所以可以将导数符号拿进来；</li>
<li>$line 3: $ 根据变换 $\triangle_{\phi} \log q_{\phi}(z) = \frac{\triangle_{\phi}q_{\phi}(z)}{q_{\phi}(z)}$ 带入可得;</li>
</ul>
<p>套用蒙特卡洛公式，最终表示如下：</p>
<p>$$
\begin{aligned}
\triangle_{\phi}E_{q_{\phi}(z)}[f(z)] &amp;= E_{q_{\phi}(z)}[f(z) \triangle_{q_{\phi}(z)} \log{q_{\phi}(z)}] \cr
&amp;\cong \frac{1}{L}\sum_{l=1}^{L} f(z) \triangle_{q_{\phi}(z^{(l)})} \log{q_{\phi}(z^{(l)})}, where z^{(l)} \sim q_{\phi}(z|x^{(i)})
\end{aligned}
$$</p>
<p>但是作者实验发现使用这个 estimator 是有很高的 variance 的，就是直观上来说会导致训练很不稳定。</p>
<p>在此基础上作者提出了 Generic Stochastic Gradient Variational Bayes (<strong>SGVB</strong>) estimator，并使用**重参数化(Reparameterization)**trick，我们先来说下重参数化。</p>
<h3 id="45重参数化-trick">4.5、重参数化 Trick</h3>
<p>上面我们用蒙特卡洛的时候，有一个非常强的假设，那就是假设 $f(z)$ 和 $\phi$ 是没有关系的，但实际表达式中：
</p>
<p>我们可以看到它还是有关系的，所以我们得考虑它们之间存在的关系、这个关系会带来什么样的问题。</p>
<p>我们把它打开来看：</p>
<p>$$
\begin{aligned}
\triangle_{\phi}E_{q_{\phi}}[f(z)] &amp;= \triangle_{\phi}\int q_{\phi}(z)f(z) \mathrm{d}z \cr
&amp;= \int \triangle_{\phi}[q_{\phi}(z)f(z)] \mathrm{d}z\cr
&amp;= \int f(z) \triangle_{\phi}q_{\phi}(z) \mathrm{d}z + \int q_{\phi}(z)\triangle_{\phi}f(z) \mathrm{d}z\cr
&amp;= \underbrace{\int f(z) \triangle_{\phi}q_{\phi}(z) \mathrm{d}z}<em>{what \ about \ this \ ?} + E</em>{q_{\phi}(z)}[\triangle_{\phi}f(z)]
\end{aligned}
$$</p>
<p>分别求导之后，后面一项可以写成期望的形式，但是前面这一项就无法处理了，为了解决这个问题，作者使用了<strong>重参数化技巧（Reparameterization Trick）</strong>。</p>
<p>核心思想就是引入一个辅助的随机变量 $\epsilon$，$\epsilon \in p(\epsilon)$，这个随机变量和其它变量没有关系，它是一个独立的随机变量，用来表示产生 $z$ 的过程中所有的随机性。也就是说抽样产生 $z$ 的过程中，所有的随机性都是由这个 $\epsilon \in p(\epsilon)$ 产生的。</p>
<p>这样我们就可以把 $z$ 写成这种形式： $z = g_{\phi}(\epsilon, x)$，从而可以把 $q_{\phi}(z)$ 这个概率分布转移到 $p_{\epsilon}$ 上，而 $\epsilon$ 有一个非常好的特性，那就是和 $\phi$ 是没有关系的。</p>
<p>这种 trick 就是重参数化，得到新的变形后重新对 $\phi$ 求导：</p>
<p>$$
\begin{aligned}
E_{q_{\phi(z)}}[f(z^{(i)})] &amp;= E_{p(\epsilon)}[f(g_{\phi}(\epsilon, x^i))] \cr
\triangle_{\phi}E_{q_{\phi(z)}}[f(z^{(i)})] &amp;= \triangle_{\phi}E_{p(\epsilon)}[f(g_{\phi}(\epsilon, x^i)]\cr
&amp;=E_{p(\epsilon)}[\triangle_{\phi}f(g_{\phi}(\epsilon, x^i)]\cr
&amp;\approx \frac{1}{L} \sum_{l=1}^{L} \triangle_{\phi}f(g_{\phi}(\epsilon^{(l)}, x^{(i)}))
\end{aligned}
$$</p>
<p>估计这个期望也是采样然后求平均得到最后的式子，这样就可以把loss的梯度给估计出来了。</p>
<p>以上是从数学角度来分析的重参数化技巧，这里作者给出了一个更加直观的表达：</p>
<p></p>
<ul>
<li>左图为原来的形式，我们使用 $\phi$ 和 $x$ 产生一个distribution，然后在这个distribution中抽样产生一个z，然后再得到最终的 $f$ 。但是在传递梯度的时候，怎么把梯度通过抽样这个过程传递回来呢？这个是没法传递梯度的。
在使用了重参数化trick后，随机性移动到了 $\epsilon$ 上，之前所有抽样的过程包括的随机性，都让 $\epsilon$ 包括了，这样就可以顺利地将梯度通过 $z$ 传递到 $\phi$，这是一个非常巧妙的方法.</li>
</ul>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">可以理解成用多余参数逼近抽样的过程。</div>
    </div>
  </div>
<h3 id="46-generic-sgvb">4.6 Generic SGVB</h3>
<p>简单说完重参数化，我们回到SGVB:
</p>
<p>这里是想求这一串期望，它就是我们的 $f(z)$ ，根据之前的 Reparameterization Trick，我们把 $z$ 写成这样的形式：</p>
<p>$$z^{(i, l)} = g_{\phi} (\epsilon^{(i,l)}, x^{(i)}) \ and \ \epsilon^{(l)} \sim p(\epsilon)$$</p>
<p>让 $\epsilon$ 从这个 distribution 中抽样产生，$\epsilon$ 是一个与 $\phi$ 、$\theta$ 都没有关系的随机变量，然后 loss 就变成：</p>
<p>$$L(\theta, \phi, x^{(i)}) = \frac{1}{L} \sum_{l=1}^{L} \log p_{\theta}(x^{(i)}, z^{(i,l)}) - \log q_{\phi}(z^{(i,l)} | x^{(i)})$$</p>
<p>想要求它对 $\phi$ 的导数，只需要两边同时求导即可。</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">因为期望这个积分已经被替换成了 $\epsilon$ 的distribution，它跟 $\phi$ 是没有关系的，所以我们在估计整个loss的导数的时候，我们直接对 $\phi$ 求导就可以了。</div>
    </div>
  </div>
<p>这个就是作者提出的第一种估计梯度的方法。</p>
<h3 id="47another-sgvb">4.7、Another SGVB</h3>
<p>在此基础上作者还发现，有一些好的性质可以直接拿来利用，比如期望的一些性质。</p>
<p>在 4.3 节中我们讲到原来的 loss 可以写成 KL散度 + 期望 的形式：</p>
<p>$$L(\theta, \phi, x^{(i)}) = -D_{KL}(q_{\phi}(z|x^{(i)})||p_{\theta}(z)) + E_{q_{\phi}(z|x)}[\log(p_{\theta}(x^{(i)}|z))]$$</p>
<p>这里我们假设这两个distribution：$q_{\phi}$ 、$p_{\theta}$ 都是 Gaussian distribution，说白了就是0均值1方差，根据定义：</p>
<p>$$
\begin{cases}
D_{KL}(P||Q) = E_{x \sim P}[\log(\frac{P(x)}{Q(x)})]\cr
E_{x\sim P(x)} = \int P(x)Q(x)\mathrm{d}x
\end{cases}
$$</p>
<p>我们根据上述定义打开这个KL divergence：</p>
<p>$$-D_{KL}(q_{\phi}(z|x)||p_{\theta}(z)) = \int q_{\phi}(z|x)(\log p_{\theta}(z)) - \log q_{\phi}(z|x) \mathrm{d}z$$</p>
<p>我们先来看 $\int q_{\phi}(z|x)\log p_{\theta}(z) \mathrm{d}z$:</p>
<p>$$
\begin{align}
\int q_{\phi}(z|x)\log p_{\theta}(z) \mathrm{d}z &amp;= \int N(z; \mu, \sigma^2) \log N(z; 0, 1)\mathrm{d}z\cr
&amp;= \int N(z; \mu, \sigma^2) (-\frac{1}{2}z^2 - \frac{1}{2}\log(2\pi))\mathrm{d}z\cr
&amp;= -\frac{1}{2} \int N(z; \mu, \sigma^2) z^2\mathrm{d}z - \frac{J}{2}\log(2\pi) \cr
&amp;= -\frac{J}{2} \log (2\pi) - \frac{1}{2}(E_{z \sim N(z;\mu, \sigma^2)}[z]^2 + Var(z))\cr
&amp;= -\frac{J}{2} \log (2\pi) - \frac{1}{2}\sum_{J}^{j=1}(\mu^2 + \sigma_j^2)
\end{align}
$$</p>
<ul>
<li>$line 1\sim 2:$ 我们让左面分布 $N(z; \mu, \sigma^2)$ 保持不动，将 normal distribution 的PDF带进去；
<ul>
<li>normal distribution 的PDF为:
</li>
<li>将常数项直接拿出来，指数的部分也通过log直接拿下来了；</li>
</ul>
</li>
<li>$line 3:$ 因为 $\frac{1}{2}\log(2\pi)$ 是个常数、$N(z; \mu, \sigma^2)$ 这个分布积分之后是1，所以可以直接把常数项拿到积分外面；但是因为 $z$ 是一个向量，我们假设 $z$ 有 $J$ 个元素element，那么每个元素都会积出一个值来，所以要乘上 $J$，即 $\frac{J}{2}\log(2\pi)$;</li>
<li>$line 4:$ 对于积分 $\int N(z;\mu,\sigma^2) z^2\mathrm{d}z$ 我们可以换个角度理解它：这里我们把它就当成一个概率分布，所以整个这个积分其实也是一个期望的形式，不过它是对 $z^2$ 的期望，经过变形可以写成 $-\frac{1}{2} E_{z \sim N(z; \mu, \sigma^2)}[z]^2$
。在这个基础上我们使用期望的性质 $E[z^2] = E[z]^2 + variance(z)$，即 $z^2$ 的期望等于期望的平方加上 $z$ 的方差；</li>
<li>那么对于一个 normal distribution 来说它的期望和方差是显而易见的：$\mu$ 和 $\sigma$，对于 $z$ 里的每个元素（脚标是 $j$）都加起来就好了，这样最开始的积分就可以简化成最后的形式。</li>
</ul>
<p>我们再来看 $\int q_{\phi}(z|x)\log q_{\phi}(z|x)\mathrm{d}z$:</p>
<p>$$
\begin{aligned}
\int q_{\phi}(z|x)\log q_{\phi}(z|x)\mathrm{d}z &amp;=\int N(z; \mu, \sigma^2)\log N(z;\mu,\sigma^2)\mathrm{d}z\cr
&amp;= \int N(z; \mu, \sigma^2)(-\frac{1}{2}(\frac{z - \mu}{\sigma})^2- \frac{1}{2}\log (2 \pi) - \frac{1}{2}\log(\sigma^2))\mathrm{d}z\cr
&amp;=-\frac{1}{2}\int N(z;\mu,\sigma^{2})(\frac{z-\mu}{\sigma})^{2}\mathrm{d}z-\frac{J}{2}log(2\pi)-\frac{1}{2}\sum_{j=1}^{J}log(\sigma_{j}^{2}) \cr
&amp;=-\frac J2log(2\pi)-\frac12\sum_{j=1}^{J}log(\sigma_{j}^{2})-\frac12E_{z\sim N(z;\mu,\sigma^{2})}[(\frac{z-\mu}\sigma)^{2}] \cr
&amp;=-\frac{J}{2}log(2\pi)-\frac{1}{2}\sum_{j=1}^{J}log(\sigma_{j}^{2})-\frac{1}{2}(E_{z\sim N(z;\mu,\sigma^{2})}[\frac{z-\mu}{\sigma}]^{2}+Var(\frac{z-\mu}{\sigma})) \cr
&amp;=-\frac{J}{2}log(2\pi)-\frac{1}{2}\sum_{j=1}^{J}(1+log(\sigma_j^2))
\end{aligned}
$$</p>
<p>同样的还是把它的PDF带进来，展成上面相似的形式，但是这个地方的常数项和变量要显得复杂一点，相似的是我们一样可以把常数部分拿到积分外面去，然后对于前面这项积分也把它理解成期望的形式，同样利用期望的性质将平方化简，就可以得到最后的结果。</p>
<p>随后我们把 KL散度 这两项给合并起来：
$$
\begin{aligned}
-D_{KL}(q_{\phi}(z\mid x)\mid\mid p_{\theta}(z))&amp; =\int q_\phi(z\mid x)(logp_\theta(z))-logq_\phi(z\mid x))\mathrm{d}z  \cr
&amp;=\frac12\sum_{j=1}^J(1+log((\sigma_j)^2)-(\mu_j)^2-(\sigma_j)^2)
\end{aligned}
$$</p>
<p>把刚刚上面的结果带进来做减法即可得到这个等式，也就是说可以通过这个式子来估计出KL散度。</p>
<p>对于另一部分的loss $E_{q_{\phi}(z|x)}[\log(p_{\theta}(x^{(i)} | z))]$，就像我们上面说的，这部分的概率我们希望given $z$ 产生的 $x$ 尽量的接近输入 $x$，为了实现这个逼近，我们使用MSE来让$f(z)$逼近这个x，就可以最大化这个loss：</p>
<p></p>
<p>以上就是最终使用的SGVB，作者通过 KL散度 的性质和 Regularization Loss 的近似，给我们提供了一种相对稳定的估计loss和梯度的方法。</p>
<h2 id="五vae-结构回顾">五、VAE 结构回顾</h2>
<p></p>
<p>总的来看 Variational Auto-Encoder 的model就是：</p>
<ul>
<li>输入一个 $x$，进了Encoder，这个 Encoder 是由参数来决定的，Encoder 会产生 $μ$和 $σ$；</li>
<li>$μ$和 $σ$首先被我们用来计算 KL divergence，作为<strong>辅助损失</strong>；</li>
<li>同时在 $μ$ 和 $σ$之后我们对它抽样产生一个 $z$，加上 $\epsilon$ 帮我们产生随机的项；</li>
<li>得到隐变量 $z$后，放到 Decoder 里，它是由参数 $\theta$ 来决定的；</li>
<li>经过这个 Decoder 之后，我们重建出了一个 $x$；</li>
<li>对比重建后的 $x$ 和输入 $x$ 之间的 MSE 就构成了loss的另一部分，</li>
<li>两个loss加起来就是最终的loss。</li>
</ul>
<p>这个就是最经典的 Variational Auto-Encoder。</p>
<p>对比第一大节AE的图，可以画成一下形式：</p>
<p></p>
<h2 id="六原文实验">六、原文实验</h2>
<p>作者基于MNIST 和 Frey Face做了实验验证，看下原文的结果图：</p>
<p></p>
<p>首先作者说了使用不同的学习方法能把这个 lower bound 提升多少，lower bound 的提升越大，说明 Encoder 和我们想要逼近的这个Distruction，它的KL散度是越来越小。</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">由图中可以看出AEVB与wake-sleep算法的比较，可以看出AEVB训练效果更好。且随着隐变量维度增大，并未出现过拟合现象。</div>
    </div>
  </div>
<p>
</p>
<p>图4是限定2个维度的隐变量 $z$，并调节两个维度的值，生成的图片。</p>
<p>图5是不同维度的隐变量随机采样的图片。</p>
<h2 id="七torch复现-aevae">七、torch复现 AE、VAE</h2>
<p><a href="https://wangguisen.blog.csdn.net/article/details/128476638"target="_blank" rel="external nofollow noopener noreferrer">https://wangguisen.blog.csdn.net/article/details/128476638<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<h2 id="references">References</h2>
<p>[1]. <a href="https://arxiv.org/abs/1312.6114"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/abs/1312.6114<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[2]. <a href="http://www.gwylab.com/note-vae.html"target="_blank" rel="external nofollow noopener noreferrer">http://www.gwylab.com/note-vae.html<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[3]. <a href="https://zhuanlan.zhihu.com/p/452743042"target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/452743042<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[4]. <a href="https://www.bilibili.com/video/BV1q64y1y7J2/"target="_blank" rel="external nofollow noopener noreferrer">https://www.bilibili.com/video/BV1q64y1y7J2/<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[5]. <a href="https://www.bilibili.com/video/av15889450/?p=33"target="_blank" rel="external nofollow noopener noreferrer">https://www.bilibili.com/video/av15889450/?p=33<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[6]. <a href="https://gregorygundersen.com/blog/2018/04/29/reparameterization/"target="_blank" rel="external nofollow noopener noreferrer">https://gregorygundersen.com/blog/2018/04/29/reparameterization/<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
</br>
[7]. <a href="https://mp.weixin.qq.com/s?__biz=Mzk0MzIzODM5MA==&amp;mid=2247486014&amp;idx=1&amp;sn=2ff34f72c869907408ed1b08bec1a238&amp;chksm=c337b7a7f4403eb14a1b5cdc3e1a1b11dca6f957591957cc29a4c270f0ace0a4674a7ae33214&amp;scene=21#wechat_redirect"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s?__biz=Mzk0MzIzODM5MA==&mid=2247486014&idx=1&sn=2ff34f72c869907408ed1b08bec1a238&chksm=c337b7a7f4403eb14a1b5cdc3e1a1b11dca6f957591957cc29a4c270f0ace0a4674a7ae33214&scene=21#wechat_redirect<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>]]></description></item><item><title>生成对抗网络GAN</title><link>https://jianye0428.github.io/posts/gan_1/</link><pubDate>Wed, 26 Jul 2023 10:03:45 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/gan_1/</guid><description><![CDATA[<!-- <div class="details admonition quote">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-quote-right fa-fw" aria-hidden="true"></i>quote<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">note abstract info tip success question warning failure danger bug example quote</div>
    </div>
  </div> -->
<h2 id="一gan的引入">一、GAN的引入</h2>
<p></p>
<p>GAN（Generative Adversarial Networks）是一种无监督的深度学习模型，提出于2014年，被誉为“近年来复杂分布上无监督学习最具前景的方法之一”。</p>
<div class="details admonition quote">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-quote-right fa-fw" aria-hidden="true"></i>quote<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content"><p>Yann Lecun对其的评价是：对抗式训练是迄今为止最酷的一件事情。</p>
<p>Adversarial training is the coolest thing since sliced bread.</p>
</div>
    </div>
  </div>
<p>我们来看下原文的标题：</p>
<ul>
<li>Generative：我们知道机器学习模型有两大类，第一个是分辨模型：对于一个数据去分辨它的类别，或者是预测一个实数值；另一类是生成模型，意思是怎么样生成这个数据本身。显然GAN是属于生成模型。</li>
<li>Adversarial：对抗的，这里指的是GAN提出的这种 framework 采用对抗训练的方式来work。</li>
<li>Nets：Network的简写。</li>
</ul>
<h2 id="二gan的应用举例">二、GAN的应用举例</h2>
<ul>
<li>数据生成：生成一些假的图像数据，比如海报中的人脸、文本生成图像等；</br></li>
<li>数据增强：从分割图生成假的真实街景，比如可以方便训练无人汽车等；</br></li>
<li>风格化和艺术的图像创造：比如转换图像风格、AI换脸、修补图像等；</br></li>
<li>声音的转换：比如一个人的声音转为另一个的声音、去除噪声等；</br></li>
<li>&hellip;&hellip;</br></li>
</ul>
<h2 id="三gan的快速概述">三、GAN的快速概述</h2>
<p>比如人脸检测、图像识别、语音识别等，<strong>机器总是在现有事物的基础上，做出描述和判断</strong>。能不能创造这个世界不存在的东西？</p>
<p>GAN就是为此而来，它包含三个部分：<strong>生成</strong>、<strong>判别</strong>、<strong>对抗</strong>。其中 <u>生成</u> 和 <u>判别</u> 是它的结构组成，<u>对抗</u>则是它的训练过程。</p>
<ul>
<li>生成：<strong>生成</strong> 和 <strong>判别</strong> 指的是两个独立的模型，生成器会根据随机向量产生假数据，这些假数据既可以是图片、也可以是文本，并<strong>试图</strong><font color=red>欺骗判别网络</font>；</li>
<li>判别：<strong>判别器</strong>负责判断接受到的数据是否是真实的，即对生成数据进行<font color=red>真伪鉴别</font>，试图正确识别所有假数据，它其实是一个二分类问题，会给出一个概率，代表着内容的真实程度；两者使用哪种网络并没有明确的规定，所以原文中作者称其为framework。比如可以使用擅长处理图片的CNN、常见的全连接等等，只要能够完成相应的功能就可以了。</li>
<li>对抗：这指的是 GAN 的交替训练过程。以图片生成为例，先让<font color=green><strong>生成器</strong></font>产生一些假图片，和收集到的真图片一起交给辨别器，让它学习区分两者，给真的高分，给假的低分，当判别器能够熟练判断现有数据后；再让 <font color=green><strong>生成器</strong></font> 以从 <font color=green><strong>判别器</strong></font> 处获得高分为目标，不断生成更好的假图片，直到能骗过判别器，重复进行这个过程，直到辨别器对任何图片的预测概率都接近0.5，也就是无法分辨图片的真假，就停止训练。</li>
</ul>
<p>也就是说在训练迭代的过程中，两个网络持续地进化和对抗，直到到达一个平衡状态，即判别网络无法识别真假。虽说是对抗，但是生成器和辨别器的关系更像是朋友，最初大家都是“无名之辈”，随着不断的训练“切磋”，共同成为“一代高手”。</p>
<p>我们<font color=red><strong>训练GAN的最终目标</strong></font>是获得好用的生成器，也就是生成足够以假乱真的内容，能完成类似功能的还有波尔斯曼机、变分自编码器等，它们被称为生成模型。</p>
<h2 id="四原文的摘要">四、原文的摘要</h2>
<p></p>
<div class="details admonition quote">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-quote-right fa-fw" aria-hidden="true"></i>quote<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">到底什么是GAN？</div>
    </div>
  </div>
<p>首先作者提出一个新的framework，通过一个<strong>对抗过程</strong>来估计一个生成模型。</p>
<p>同时会训练两个模型：</p>
<ul>
<li>第一个模型叫做 <mark><strong>生成模型G</strong></mark>，用来捕获整个数据的分布，其实就是通过 <font color=red>生成器</font> 去拟合和逼近真实的数据分布；</li>
<li>第二个是 <mark><strong>辨别模型D</strong></mark>，它是用来估计一个样本是来自真正的数据、还是来自于<strong>G</strong>生成的。</li>
</ul>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">这里稍微解释一下：<strong>生成模型</strong> 它就是对整个数据的分布进行建模，使得能够生成各种分布。这里“分布”是一个很一般化的词，比如生成图片、生成文本、生成视频等。在统计学眼里，整个世界是通过采样不同的分布来得到的，所以想要生成东西，目的就是要抓住整个数据的一个分布。</div>
    </div>
  </div>
<p>生成模型的任务是尽量的想<strong>让辨别模型犯错</strong>，这个过程是一个<strong>最大最小的博弈</strong>。在任何函数空间的<strong>G</strong>和<strong>D</strong>里面，存在一个独一无二的解，这个解是代表：<strong>G</strong>能够找出训练数据的真实分布（生成的数据分布趋向于真实数据分布），此时辨别器就判别不出来了，所以概率值为$\frac{1}{2}$。</p>
<p>如果<strong>G</strong>和<strong>D</strong>是一个MLP的话，那么整个系统就可以通过误差反向传播来进行训练。作者说这里不需要使用任何的马尔科夫链，或者说是对一个近似的推理过程展开（说白了意思好像就是和别人的方法比比较简单一点），最后就是说实验的效果非常好。</p>
<h2 id="五原文的例子">五、原文的例子</h2>
<p></p>
<p>在对抗网络的框架里有两类模型：一个是<mark><strong>生成模型</strong></mark>、一个是<mark><strong>判别模型</strong></mark>：</p>
<ul>
<li>生成模型比喻成造假的人，它要去产生假币；</li>
<li>判别模型比喻成警察，警察的任务就是很好的鉴别假币和真币；</li>
</ul>
<p>造假者和警察会不断的学习，造假者会提升自己的造假技能，警察也会提升自己判别真币和假币的性能。最后希望造假者能够赢，就是说造的假钱和真钱一模一样，然后警察没有能力去区分真币和假币，那么这个时候就可以使用生成器生成和真实数据一样的数据了。</p>
<h2 id="六gan模型结构--训练gan的目的">六、GAN模型结构 &amp; 训练GAN的目的</h2>
<p>摘要说的已经很清楚了，GAN由两部分组成：</p>
<ul>
<li>生成器G（Generator）；</li>
<li>判别器D（Discriminator）；</li>
</ul>
<p>我们的最终目的是希望生成器<strong>G</strong>，能够<font color=purple>学习到样本的真实分布$P_{\text{data}}(x)$</font>，那么就能生成之前不存在的、但是却又很真实的样本。</p>
<p>那再啰嗦的说明白一点就是：</p>
<ul>
<li>我们把随机向量（随机噪声）定义为 $z$，$z \in F$，可以是任意分布，比如正态分布、均匀分布。</li>
<li>将随机噪声输入到 <strong>生成器G</strong> 中，<strong>G</strong>其实看成一个函数就可以，它可以是任意的一个神经网络，因为神经网络可以逼近任何形式的函数。</li>
<li>随机噪声 $z$ 经过<strong>生成器G</strong>后会产生一个 $G(z)$，生成的这个新的向量 $G(z)$，它可以记为服从$P_G(x)$。但是$P_G(x)$这个分布不是我们想要的，我们想要的是<strong>生成器G</strong>生成一个满足于真实分布$P_{\text{data}}(x)$的数据。</li>
<li>通过不断的训练迭代，更新调整生成器G的参数，使得$P_G(x)$近似于 $P_{\text{data}}(x)$。</li>
</ul>
<p>通过调整 <strong>生成器G</strong> 的参数，使得<font color=violet>它生成的分布和真实的分布尽可能的像</font>，这个就是最终要达到的目的，可以通过 生成器G 生成一些满足真实分布，但又不是真实存在的数据。</p>
<p>我们以手写数字识别为例，图例如下：</p>
<p></p>
<p>GAN模型结构图如下示例：</p>
<p></p>
<ul>
<li>我们将随机噪声输入到<strong>生成器G</strong>中，产生 $G(z)$，我们把它叫做$x_{\text{fake}}$，$x_{\text{fake}}$为生成的图片，就是假的图片；</li>
<li>我们还有满足于真实分布$P_{\text{data}}(x)$的数据，记为$x_{\text{real}}$；</li>
<li>我们把 $x_{\text{real}}$ 和 $x_{\text{fake}}$ 同时送到<strong>判别器D</strong>中去训练，做一个二分类任务，判断是真还是假；</li>
</ul>
<h2 id="七举例理解gan的原理">七、举例理解GAN的原理</h2>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">因为原文举的例子比较敏感，我们以李宏毅老师的例子（中央电视台鉴宝节目：一槌定音）来进行GAN原理的阐述。</div>
    </div>
  </div>
<p></p>
<p>假设现在有一个人，我们称它为小王，小王是一个收藏家，它的收藏室里收藏了很多“国宝”。但是小王不想只做一个收藏家，他还想高仿这些“国宝”，我们这里将高仿的赝品定义为“工艺品”。</p>
<p>基于GAN的目标，我们知道：</p>
<ul>
<li>小王最终想成为一个水平很高的“工艺品大师”；</li>
</ul>
<p>但是如果想成为一个“工艺品”方面的专家，小王自己在家闭门造车肯定是行不通的，因为我们的总目标是想让小王成为一个高水平的、可以以假乱真的工艺品大师。为了达到这个目标，首先需要一个高水平的鉴赏专家（高水平的对手），其次小王本身就要是个高水平的工艺品大师。所以小王还需要找一个水平很高的国宝鉴赏专家。鉴赏专家负责辨别出真的“国宝”和小王的“工艺品”，小王负责高仿生产“工艺品”。</p>
<p></p>
<p>概述来说：<strong>小王需要先有一个高水平的专家，然后才可能成为一个高水平的大师。高水平的专家可以看成一种手段，成为高水平的大师才是我们的目标。</strong></p>
<h2 id="八数学描述">八、数学描述</h2>
<h3 id="81-相关符号">8.1 相关符号</h3>
<p>基于上述鉴宝例子，我们来看一下GAN的数学描述，首先需要强调的是：</p>
<ul>
<li>工艺品经过鉴赏专家判断后，是会受到一个 feedback 的；</li>
<li>对于鉴赏专家而言，它也会从工艺品受到一个 feedback ，当然这是潜在的；</li>
</ul>
<p>我们就来看一下，这个例子如何用数学符号去表示：</p>
<ul>
<li>
<p>&ldquo;国宝&quot;是静态的，它相当于我们的真实样本 ${x_{\text{real}<em>i}}^N</em>{i=1}$ ，这里我们以 $P_{data}$ 表示；</p>
</li>
<li>
<p>工艺品也是从一个概率分布里抽样出来的，我们将工艺品记作 ${x_{\text{fake}<em>i}}^N</em>{i=1}$ ，我们把这个概率分布称作 $P_g(x;\theta_{g})$，g就代表Generator的意思；</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">注意我们并不直接对 $P_g$ 建模，即不直接对生成模型本身进行建模，我们用一个神经网络去逼近这个分布，纯粹的神经网络它是不具备随机性的，所以我们会假设它有一个 $z$，就是前面提到的随机噪声，是来自于一个简单的分布，比如高斯分布： $z \sim P_Z(z)$ ；</div>
    </div>
  </div>
</li>
<li>
<p>原始的GAN里，神经网络就用NN表示，它本身就是一个确定性变换，即是一个复杂函数，表示为 $G(z;\theta_{g})$；</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">$\theta_g$ 在NN里就是表示权重参数，在 $P_g$ 里就是代表概率分布参数。</div>
    </div>
  </div>
</li>
<li>
<p>鉴赏专家也可以看成一个概率分布，我们也用一个NN来描述它：$D(x; \theta_{d})$，代表 $x$ 是国宝的概率</p>
</li>
</ul>
<p></p>
<p>对于鉴赏专家 <strong>(判别器D)</strong> 接收到的来说：</p>
<ul>
<li>可以是来自国宝、也可以是来自于工艺品，是无所谓的，重要的是本身是代表是国宝的概率。</li>
</ul>
<p>对于判别器D的输出来说：</p>
<ul>
<li>$D(x)$ 的值越趋近于1，说明它是国宝的概率就越大；越趋近于0，说明它是工艺品的概率就越大。</li>
</ul>
<p>上图又可简化为：</p>
<p></p>
<p>一方面是从 $P_{data}$ 里来的 $x_{real}$，一方面是 $z$ 输入到生成器后的输出 $x_{fake}$，$z$ 为噪声。</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">换句话说, $z$ 是从简单分布中采样，经过生成器后变成 $x$，此时生成的由的先验分布和生成器共同决定。</div>
    </div>
  </div>
<h3 id="82高专家的目标函数">8.2、“高专家”的目标函数</h3>
<p>符号描述表述清楚后，我们看一下GAN的目标函数，首先回顾一下GAN的目标：<u><strong>成为一个高水平的、可以以假乱真的大师</strong></u>。为了达到这个目标，我们又可以分为一个手段和一个目标：</p>
<ul>
<li>手段：<strong>需要一个高水平的鉴别专家</strong>；</li>
<li>目标：<strong>成为高水平的工艺品大师</strong>。</li>
</ul>
<p>也就是说我们需要<u><strong>先成就一个高水平的专家，才有可能成就一个高水平的大师</strong></u>，所以它们的关系是：(高大师(高专家))。</p>
<p>首先看高专家，高专家水平高体现在：国宝判别为真、工艺品判别为假：</p>
<p>$$
高专家：
\begin{equation}
\left{
\begin{aligned}
%\nonumber
if \ x \ is \ from \ P_{data}, \ then D(x) \uparrow\
if \ x \ is \ from \ P_{g}, \ then D(x) \downarrow\
(z \ is \ from \ P_{z}) \
\end{aligned}
\right.
\end{equation}
$$</p>
<p>为了将式子统一起来，我们改写为：</p>
<p>$$
高专家：
\begin{equation}
\left{
\begin{aligned}
%\nonumber
if \ x \ is \ from \ P_{data}, \ then D(x) \uparrow\
if \ x \ is \ from \ P_{g}, \ then \ 1-D(x) \uparrow\
(z \ is \ from \ P_{z}) \
\end{aligned}
\right.
\end{equation}
$$</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">因为 $D(x)$ 是一个概率值分布，范围是0~1， $D(x)$ 偏小， $1-D(x)$ 则相应的就偏大。</div>
    </div>
  </div>
<p>对于工艺品，$x$ 是从<strong>生成器G</strong>来的，所以可以表示成 $G(z)$：</p>
<p>$$
高专家：
\begin{equation}
\left{
\begin{aligned}
%\nonumber
if \ x \ is \ from \ P_{data}, \ then D(x) \uparrow\
if \ x \ is \ from \ P_{g}, \ then \ 1 - D(G(z)) \uparrow\
(z \ is \ from \ P_{z}) \
\end{aligned}
\right.
\end{equation}
$$</p>
<p>为了使目标函数更容易表达，或者说计算更加方便，我们加上，所以进一步表达为：
$$
高专家：
\begin{equation}
\left{
\begin{aligned}
%\nonumber
if \ x \ is \ from \ P_{data}, \ then \ \log{D(x)} \uparrow\
if \ x \ is \ from \ P_{g}, \ then \ \log{(1 - D(G(z)))} \uparrow\
(z \ is \ from \ P_{z}) \
\end{aligned}
\right.
\end{equation}
$$</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">$\log$ 为增函数，$\log(x)$ 与 $x$ 的增减性保持一致，在极大化参数的时候，与原始求解是一样的。</div>
    </div>
  </div>
<p>所以对于成就一个高专家来说，目标函数如下：</p>
<p>$$\max_{D} E_{x \sim P_{data}}[\log{D(x)}] + E_{z \sim P_{z}}[\log (1 - D(G(z)))]$$</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content"><p>可能有同学不明白为什么原文这里用期望，其实很简单，我们假设数据分布总共有个样本，那么它的期望可以表示为：</p>
<p>$$E_{x \sim P_{data}}[\log(D(x))] = \frac{1}{N} \sum_{i=1}^{N} \log(D(x_i)), x_i \sim P_{data}$$</p>
</div>
    </div>
  </div>
<h3 id="83高大师的目标函数">8.3、“高大师”的目标函数</h3>
<p>我们再来看高大师的目标函数，<strong>高大师是建立在高专家的水平之上</strong>，对于高大师来讲，希望高专家将所有的工艺品都判断为真：</p>
<p>$$高大师: if \ x \ from \ P_g,\ then \ D(G(z)) \uparrow $$</p>
<p>为了统一起来，我们改写为:</p>
<p>$$高大师: if \ x \ from \ P_g,\ then \ (1 - D(G(z))) \downarrow $$</p>
<p>所以对于高大师来讲，目标函数为:</p>
<p>$$\min_{G} E_{z \sim P_z}[\log (1 - D(G(z)))]$$</p>
<h3 id="84总目标函数">8.4、总目标函数</h3>
<p>本着<strong>先成就 高专家, 再成就 高大师</strong>的原则，GAN的目标函数为：</p>
<p>$$\min_{G} \max_{D} V(D, G) = \mathbb{E_{x\sim p_{data}(x)}}[\log(D(x))] + \mathbb{E_{z\sim p_{z}(z)}}[\log(1 - D(G(z)))]$$</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">通过目标函数我们也能看出，GAN模型的复杂度，不在于模型的定义，而在于模型的traning，也就是D和G的学习。</div>
    </div>
  </div>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">还有一点需要强调的是，自始至终我们都没有去直接面对 $P_g$，我们实际上使用一个可微神经网络 $G(z)$ 去逼近这个 $P_g$ ，而且是从采样的角度去逼近，换句话说，对于生成网络 $P_g$，GAN是绕过了它，并没有直接去解决 $P_g$，而是从采样的角度去逼近它。所以GAN又被称做：Implicit Density Model.</div>
    </div>
  </div>
<p>公式比较多，所以对目标函数再啰嗦的介绍下：</p>
<p>我们可以得出，它实际上就要对价值函数 $V(D, G)$ 进行min、max的博弈，还有需要注意的是：$D(x)$ 是判别器的输出，它要做二分类，所以经过sigmoid之后 $D(x) \in [0, 1]$；</p>
<p>我们来看一下它是怎么工作的：</p>
<ul>
<li>首先固定住G不动，通过调整D的参数，来最大化价值函数 $V(D, G)$：
<ul>
<li>要想最大化 $V$ ，左边的 $D(x)$ 要趋近于1（这样才能保证log的值尽可能大），同时要让右边的 $D(G(z))$ 趋近于0（这样才能保证 $log(1-D(G(z)))$ 尽可能大）；</li>
<li>$\max V(D, G)$ 其实就是把真实数据和假数据区分的一个过程.
$$\min_{G} \max_{D} V(D, G) = \mathbb{E_{x\sim p_{data}(x)}}[\log(D(x))] + \mathbb{E_{z\sim p_{z}(z)}}[\log(1 - D(G(z)))]$$</li>
</ul>
</li>
<li>然后固定住D不动，此时公式的左部分已经是个定值了，我们<strong>调整G的参数</strong>，来最小化价值函数 $V(D, G)$：
<ul>
<li>要让 $V(D, G)$ 最小，那么就要让 $D(G(z))$ 趋近于1，只有 $V(G(z))$ 趋近于1的时候，定义域里的值才能趋近于0，也就是log会变得越来越小，达到最小化 $V$ 的过程；</li>
<li>这个过程就是想让 $D(G(z))$ 趋近于1，z满足生成数据的分布，它是假的，那么 $min_G$ 的过程就是想要调整生成器，来骗过判别器，从而<strong>使得假数据被判别为真</strong>。
$$\min_{G} \max_{D} V(D, G) = \mathbb{E_{x\sim p_{data}(x)}}[\log(D(x))] + \mathbb{E_{z\sim p_{z}(z)}}[\log(1 - D(G(z)))]$$</li>
</ul>
</li>
</ul>
<p>总结如下：</p>
<ul>
<li>固定G, 调整D, 最大化 $V(D, G)$, 导致 $D(x) \rightarrow 1, D(G(z)) \rightarrow 0$</li>
<li>固定D, 调整G, 最小化 $\max_{D}V(D, G)$, 导致 $D(G(z)) \rightarrow 1$</li>
</ul>
<p>想必肯定有同学会发现这里出现的一个矛盾：上面的趋近于0，下面的趋近于1，这个矛盾、冲突，就理解为GAN中的<strong>对抗</strong>的意思。</p>
<h2 id="九全局最优解推导">九、全局最优解推导</h2>
<p>因为公式多、篇幅长，所以在推导最优解之前，我们先回顾一下GAN里的三个角色：</p>
<ul>
<li>真实样本分布$P_{data}$；</li>
<li><strong>生成器 Generator</strong> 对应概率分布为:$P_g$，即代表生成器生成数据的概率分布；</li>
<li><strong>判别器 Discriminator</strong> 对应的条件概率分布是离散的，就是0-1分布（伯努利分布），给定x的情况下，1代表正品、0代表工艺品（赝品）；</li>
</ul>
<p>我们的最终目标，就<strong>是想让生成器生成的样本的概率分布$P_g$无限的接近于$P_{data}$</strong>，即：$P_g \rightarrow P_{data}$；</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content"><p>我们常规的生成模型（不是GAN），是直接对$P_g$进行建模: $P_g \rightarrow \theta_{g}$, 极大似然估计表示如下：</p>
<p>$$\theta_g = \argmax_{\theta_g} \sum_{i=1}^N \log{P_g}(x_i) = \argmin KL(P_{data} || P_g)$$</p>
<p>从距离的角度讲，是最小化KL散度，最终想让$P_{data} = P_g$，这就是原先如何把参数求出来的策略。</p>
</div>
    </div>
  </div>
<h3 id="91关于-d-的最大值">9.1、关于 D 的最大值</h3>
<p>GAN从<strong>对抗学习</strong>的角度去构造目标函数，我们上面构造的目标函数，只是从逻辑上觉得它没有问题，那么我们可能会考虑：</p>
<ul>
<li>这个最大最小问题，它的最优解存在不存在？</li>
<li>如果最优解 $P_g$（就是G）存在，那么全局最优的情况下，$P_g$是否等于$P_{data}$？</li>
</ul>
<p>如果这个不成立的话，那么其实这个目标函数是没有意义的，我们来看一下，方便记作，直接用论文中的符号来描述：</p>
<p></p>
<p>我们记：</p>
<p>$$V(D, G) = \mathbb{E}<em>{x\sim p</em>{data}(x)}[\log{D(x)}] + \mathbb{E}<em>{z\sim p</em>{z}}[\log{1 - D(G(z))}]$$</p>
<p>我们先求max，根据期望的定义：$E_{x \sim P(x)} = \int_x p(x)f(x)dx$，将其展为积分的形式：</p>
<p>$\quad For \quad fixed \quad G, 求： \max_D(V(D, G))$
$$
\begin{align}
\max_D V(D, G) &amp;= \int P_{data} \cdot \log D dx + \int P_g \cdot \log (1 - D) dx \
&amp;= \int {[P_{data} \cdot \log D + P_g \cdot \log(1 - D)]} dx
\end{align}
$$</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">这里两个积分中的x确实是不同的变量，但是积分微元的符号可以做任意变换，不用纠结这里。</div>
    </div>
  </div>
<p>我们要求里面函数关于x积分的最大值，那么就看一下它的导数：</p>
<p>$$
\begin{align}
\frac{\partial}{\partial{D}}(\max V(D, G)) &amp;= \frac{\partial}{\partial D}\int {[P_{data} \cdot \log D + P_g \cdot \log(1 - D)]} \
&amp;= \int \frac{\partial}{\partial D} {[P_{data} \cdot \log D + P_g \cdot \log(1 - D)]} \
&amp;= \int {[P_{data} \cdot \frac{1}{D} + P_g \cdot \frac{-1}{\log(1 - D)}]} \Longleftrightarrow 0\
\end{align}
$$</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content"><p>因为积分是对x积的，求导是对D求的，两者互不干扰可以交换词序。</p>
<p>最优的时候导数为0。</p>
</div>
    </div>
  </div>
<p>$$\therefore P_{data} \cdot \frac{1}{D} = P_g \cdot \frac{1}{1-D}$$</p>
<p>所以当固定G时，最优的D为:</p>
<p>$$D^*<em>G = \frac{P</em>{data}}{P_{data} + P_g}$$</p>
<h3 id="92-关于-g-的最小值">9.2 关于 G 的最小值</h3>
<p>最大值求出来之后，我们再来看关于G的最小值，我们将$D^*$带进去：</p>
<p>$$
\begin{align}
\min_G \max_D V(D, G) &amp;= \min_G V(D^*<em>G, G) \
&amp;= \min_G E</em>{x \sim P_{data}}[\log(\frac{P_{data}}{P_{data} + P_g})] + E_{x \sim P_{g}}[\log(1 - \frac{P_{data}}{P_{data} + P_g})] \
&amp;= \min_G E_{x \sim P_{data}}[\log(\frac{P_{data}}{P_{data} + P_g})] + E_{x \sim P_{g}}[\log(\frac{P_{g}}{P_{data} + P_g})]\
\end{align}
$$</p>
<p>这里 $P_{data}$ 和 $P_g$，和KL散度的定义非常类似，KL divergence定义：</p>
<p>$$KL(P||Q) = E_{x \sim P}[\log(\frac{P(x)}{Q(x)})]$$</p>
<p>但是我们不能直接这么写，我们需要保证分子和分母必须同时为两个概率分布，但是分母是$P_{data} + P_g$，是两个概率分布相加，那它的取值就变成[0, 2]了。</p>
<p>所以我们给它再除以个2就可以了，取值范围就又变成[0, 1]了。换句话说，可以把它看成概率密度函数，具体什么样子无所谓，它的取值在[0, 1]之间，并且是连续的。</p>
<p>$$
\begin{align}
\min_G \max_D V(D, G) &amp;= \min_G V(D^*<em>G, G) \
&amp;= \min_G E</em>{x \sim P_{data}}[\log(\frac{P_{data}}{P_{data} + P_g})] + E_{x \sim P_{g}}[\log(1 - \frac{P_{data}}{P_{data} + P_g})] \
&amp;= \min_G E_{x \sim P_{data}}[\log(\frac{P_{data}}{P_{data} + P_g})] + E_{x \sim P_{g}}[\log(\frac{P_{g}}{P_{data} + P_g})]\
&amp;= \min_G E_{x \sim P_{data}}[\log(\frac{P_{data}}{(P_{data} + P_g)/2} \cdot\frac{1}{2})] + E_{x \sim P_{g}}[\log(\frac{P_{g}}{(P_{data} + P_g)/2}\cdot\frac{1}{2})]\
&amp;= \min_{G} KL (P_{data} || \frac{P_{data} + P_g}{2}) + KL (P_{g} || \frac{P_{data} + P_g}{2}) - \log4\
\end{align}
$$</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>tips<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">将两个$\log(\frac{1}{2})$拿出去，$\log(\frac{1}{2}) = \log1 - \log2 = -\log2,$，$-\log2$的期望就是它自己，两个就是$-\log2-\log2 = -\log4$</div>
    </div>
  </div>
<p>我们得出上式，发现它又满足 JS divergence 的定义：</p>
<p>$$JSD(P||Q) = \frac{1}{2} KL(P || M) + \frac{1}{2} KL (Q||M), 其中 M = \frac{P + Q}{2}$$</p>
<p>所以上式又可写成：</p>
<p>$$\min_G - \log 4 + 2 JSP(P_{data}||P_g)$$</p>
<p>JS divergence是衡量两个分布之间的距离，所以只有当这两个分布越来越相等的时候，就找到这个式子的最小值了，故：</p>
<p>当$P_g(x) = P_{data}(x)$时，上式可得最小值。</p>
<p>所以我们只需要优化：</p>
<p>$$\min_G\max_D V(D, G) = \mathbb{E}<em>{x\sim{p</em>{data}(x)}}[\log D(x)] + \mathbb{E}<em>{z\sim{p</em>{z}(z)}}[1 - \log D(G(z))]$$</p>
<p>就可以得到$P_g(x) = P_{data}(x)$.</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>tips<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">另外，当 $P_g(x) = P_{data}(x)$ 时，又因为 $D^<em><em>G = \frac{P</em>{data}}{P_{data} + P_g}$， 所以此时 $D^</em> = \frac{1}{2}$ 。意思是，在最优的情况下，鉴赏专家已经没有分辨真假的能力了，概率都0.5，这个时候判别器对于生成器而言，已经没有继续学习的必要了。</div>
    </div>
  </div>
<h2 id="十原文给出的训练步骤">十、原文给出的训练步骤</h2>
<p></p>
<ul>
<li>在每一个step里先采样m个噪音样本；</li>
<li>再采样m个来自于真实数据的样本；这样就组成了一个大小为2m的小批量；</li>
<li>将样本分别放到 <strong>生成器</strong> 和 <strong>辨别器</strong> 去求梯度，更新 <strong>辨别器</strong> 参数；</li>
</ul>
<p>做完之后：</p>
<ul>
<li>再采样m个噪音样本，放到公式的第二项里面（因为我们要<strong>更新生成器</strong>，生成器与第一项无关），算出它的梯度；</li>
<li>然后对生成器进行参数更新。</li>
</ul>
<p>这样就完成了一次迭代，可以看到每次迭代里，我们是<strong>先更新辨别器，再更新生成器</strong>。</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>tips<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content"><p>k是一个超参数，不能太小也不能太大，要保证辨别器有足够的更新，但也不要更新太好了。如果没有足够好的更新，就是生成器变换了之后，没有把辨别器更新的足够好，</p>
<p>
G已经做了变化，但是D没有做什么改变，再更新G来糊弄D，其实意义不大。</p>
<p>反过来讲，如果一更新就把D训练到完美，那么1-D就会变成0，对一个0的东西求导，那么就会在生成模型上更新有困难。</p>
<p>回到原文的例子，辨别器是警察，生成器就是造假者，假设警察特别厉害，造假者产一点假钞出来就被连锅端了，那造假者就没能力改进和提升自己了，但反过来讲，如果警察无力，造假者随便造点东西，警察也看不出来，那造假者就不会有动力去改进和提升自己。</p>
<p>所以最好是两者实力相当、相爱相杀，大家一起进步。所以k的调参，要使得D的更新和G的更新进度都差不多。</p>
</div>
    </div>
  </div>
<h2 id="十一gan原理及训练过程总结">十一、GAN原理及训练过程总结</h2>
<h3 id="111gan原理总结">11.1、GAN原理总结</h3>
<p>GAN主要包括了两部分：</p>
<ul>
<li><mark>生成器（Generator）</mark>：生成器主要用来学习真实数据的分布，从而让自身生成的数据更加真实，骗过判别器；</li>
<li><mark>判别器（Discriminator）</mark>：判别器则需要对接受的数据进行真假判断。</li>
</ul>
<p>在训练过程中，生成器努力地让生成的数据更加真实，而判别器则努力地去识别出数据的真假，这个过程相当于一个二人博弈，随着时间的推移，生成器和判别器在不断的进行对抗，这就是它对抗的含义。</p>
<p>最终两个网络达到了一个动态均衡：生成器生成的数据接近于真实数据分布，而判别器识别不出真假数据，对于给定数据的预测为真的概率基本接近0.5（相当于随机猜测类别）。</p>
<p>GAN设计的关键在于损失函数的处理：</p>
<ul>
<li>对于判别模型，损失函数是容易定义的，判断一张图片是真实的还是生成的，显然是一个二分类问题。</li>
<li>对于生成模型，损失函数的定义就不是那么容易，我们希望生成器可以生成接近于真实的图片，对于生成的图片是否像真实的，我们人类肉眼容易判断，但具体到代码中，是一个抽象的，难以数学公里化定义的范式。</li>
</ul>
<p>针对这个问题，我们不妨把生成模型的输出，交给判别模型处理，让判别器判断这是一个真实的图像还是假的图像，因为深度学习模型很适合做分类，这样就将生成器和判别器紧密地联合在了一起。</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>tips<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">假如我们直接用生成器训练，它的训练结果并不会得到一个真实的图像，而会得到一个比较模糊的图像，因为我们无法构建一个合适的损失去判断它是否像真实图片，所以它会将所有训练样本做平均，产生一个比较糊的图片。这就是为什么要将生成器的样本交给判别器来构建损失。</div>
    </div>
  </div>
<h3 id="112gan算法流程总结">11.2、GAN算法流程总结</h3>
<ul>
<li>$G$ 是一个生成图片的网络，它接收一个随机的噪声z，通过这个噪声生成图片$G(z)$，记作；</li>
<li>$D$ 是一个判别网络，判别一张图片是不是“真实的”，它的输入参数是x，x代表一张图片，输出$D(x)$，代表x为真实图片的概率，如果为1，就代表100%是真实的图片，输出为0，就代表不是真实图片。</li>
</ul>
<p>在训练过程中，将随机噪声输入生成网络G，得到生成的图片；判别器接受生成的图片和真实的图片，并尽量将两者区分开来。在这个计算过程中，能否正确区分生成的图片和真实的图片将作为判别器的损失；而能否生成近似真实的图片、并使得判别器将生成的图片判定为真，将作为生成器的损失。</p>
<p>生成器的损失是通过判别器的输出来计算的，而判别器的输出是一个概率值，我们可以通过交叉熵来计算。</p>
<h2 id="十二torch复现">十二、torch复现</h2>
<p><a href="https://wangguisen.blog.csdn.net/article/details/127820071"target="_blank" rel="external nofollow noopener noreferrer">https://wangguisen.blog.csdn.net/article/details/127820071<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
ref:</br>
[1]. <a href="https://arxiv.org/abs/1406.2661"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/abs/1406.2661<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[2]. <a href="https://www.bilibili.com/video/BV1eE411g7xc"target="_blank" rel="external nofollow noopener noreferrer">https://www.bilibili.com/video/BV1eE411g7xc<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[3]. <a href="https://www.bilibili.com/video/BV1rb4y187vD"target="_blank" rel="external nofollow noopener noreferrer">https://www.bilibili.com/video/BV1rb4y187vD<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[4]. <a href="https://www.bilibili.com/video/BV1HD4y1S7Pe"target="_blank" rel="external nofollow noopener noreferrer">https://www.bilibili.com/video/BV1HD4y1S7Pe<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br></p>]]></description></item><item><title>详解最大似然估计(MLE)、最大后验概率估计(MAP)，以及贝叶斯公式的理解</title><link>https://jianye0428.github.io/posts/mleandmap/</link><pubDate>Sun, 16 Jul 2023 13:28:44 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/mleandmap/</guid><description><![CDATA[<p>最大似然估计（Maximum likelihood estimation, 简称MLE）和最大后验概率估计（Maximum a posteriori estimation, 简称MAP）是很常用的两种参数估计方法，如果不理解这两种方法的思路，很容易弄混它们。下文将详细说明MLE和MAP的思路与区别。</p>
<p>但别急，我们先从概率和统计的区别讲起。</p>
<h1 id="概率和统计是一个东西吗">概率和统计是一个东西吗？</h1>
<p>概率(probabilty)和统计(statistics)看似两个相近的概念，其实研究的问题刚好相反。</p>
<p>概率研究的问题是，已知一个模型和参数，怎么去预测这个模型产生的结果的特性(例如均值，方差，协方差等等)。 举个例子，我想研究怎么养猪(模型是猪)，我选好了想养的品种、喂养方式、猪棚的设计等等(选择参数)，我想知道我养出来的猪大概能有多肥，肉质怎么样(预测结果)。</p>
<p>统计研究的问题则相反。统计是，有一堆数据，要利用这堆数据去预测模型和参数。仍以猪为例。现在我买到了一堆肉，通过观察和判断，我确定这是猪肉(这就确定了模型。在实际研究中，也是通过观察数据推测模型是／像高斯分布的、指数分布的、拉普拉斯分布的等等)，然后，可以进一步研究，判定这猪的品种、这是圈养猪还是跑山猪还是网易猪，等等(推测模型参数)。</p>
<p>一句话总结：<strong>概率是已知模型和参数，推数据。统计是已知数据，推模型和参数。</strong></p>
<p>显然，本文解释的MLE和MAP都是统计领域的问题。它们都是用来推测参数的方法。为什么会存在着两种不同方法呢？ 这需要理解贝叶斯思想。我们来看看贝叶斯公式。</p>
<h1 id="贝叶斯公式到底在说什么">贝叶斯公式到底在说什么？</h1>
<p>学习机器学习和模式识别的人一定都听过贝叶斯公式(Bayes’ Theorem)：
式[1]
$P(A|B)=\frac{P(B|A)P(A)}{P(B)}$</p>
<p>贝叶斯公式看起来很简单，无非是倒了倒条件概率和联合概率的公式。</p>
<p>把B展开，可以写成:
式[2]
$P(A|B)=\frac{P(B|A)P(A)}{P(B|A)P(A) + P(B|\sim A)P(\sim A)}$</p>
<p>这个式子就很有意思了。</p>
<p>想想这个情况。一辆汽车(或者电瓶车)的警报响了，你通常是什么反应？有小偷？撞车了？ 不。。 你通常什么反应都没有。因为汽车警报响一响实在是太正常了！每天都要发生好多次。本来，汽车警报设置的功能是，出现了异常情况，需要人关注。然而，由于虚警实在是太多，人们渐渐不相信警报的功能了。</p>
<p><strong>贝叶斯公式就是在描述，你有多大把握能相信一件证据？（how much you can trust the evidence）</strong></p>
<p>我们假设响警报的目的就是想说汽车被砸了。把$A$计作“汽车被砸了”，$B$计作“警报响了”，带进贝叶斯公式里看。我们想求等式左边发生$A∣B$的概率，这是在说警报响了，汽车也确实被砸了。汽车被砸**引起(trigger)**警报响，即B∣A。但是，也有可能是汽车被小孩子皮球踢了一下、被行人碰了一下等其他原因(统统计作$\sim A$)，其他原因引起汽车警报响了，即 $B|\sim A$。那么，现在突然听见警报响了，这时汽车已经被砸了的概率是多少呢(这即是说，警报响这个证据有了，多大把握能相信它确实是在报警说汽车被砸了)想一想，应当这样来计算。用警报响起、汽车也被砸了这事件的数量，除以响警报事件的数量(这即[式1])。进一步展开，即警报响起、汽车也被砸了的事件的数量，除以警报响起、汽车被砸了的事件数量加上警报响起、汽车没被砸的事件数量(这即[式2])。</p>
<p>再思考[式2]。想让$P(A∣B)=1$，即警报响了，汽车一定被砸了，该怎么做呢？让$P(B|\sim A)P(\sim A) = 0$即 可 。很容易想清楚，假若让$P(\sim A)=0$,即杜绝了汽车被球踢、被行人碰到等等其他所有情况，那自然，警报响了，只剩下一种可能——汽车被砸了。这即是提高了响警报这个证据的说服力。</p>
<p>**从这个角度总结贝叶斯公式：做判断的时候，要考虑所有的因素。**老板骂你，不一定是你把什么工作搞砸了，可能只是他今天出门前和太太吵了一架。</p>
<p>再思考[式2]。观察【式2】右边的分子，$P(B∣A)$为汽车被砸后响警报的概率。姑且认为这是1吧。但是，若$P(A)$很小，即汽车被砸的概率本身就很小，则$P(B∣A)P(A)$仍然很小，即【式2】右边分子仍然很小，$P(A|B)$还是大不起来。 这里，$​P(A)$ 即是常说的先验概率，如果A的先验概率很小，就算$P(B∣A)$较大，可能A的后验概率$P(A∣B)$还是不会大(假设$P(B∣\sim A)P(\sim A)$不变的情况下)。</p>
<p><strong>从这个角度思考贝叶斯公式：一个本来就难以发生的事情，就算出现某个证据和他强烈相关，也要谨慎。证据很可能来自别的虽然不是很相关，但发生概率较高的事情。</strong></p>
<h1 id="似然函数">似然函数</h1>
<p>似然(likelihood)这个词其实和概率(probability)是差不多的意思，Colins字典这么解释:The likelihood of something happening is how likely it is to happen. 你把likelihood换成probability，这解释也读得通。但是在统计里面，似然函数和概率函数却是两个不同的概念(其实也很相近就是了)。</p>
<p>对于这个函数:</p>
<p>$$P(x|\theta)$$</p>
<p>输入有两个: $x$表示某一个具体的数据；$\theta$表示模型的参数。</p>
<p>如果$\theta$是已知确定的，$x$是变量，这个函数叫做<font color=red>概率函数(probability function)</font>，它描述对于不同的样本点x，其出现概率是多少。</p>
<p>如果$x$是已知确定的，$\theta$是变量，这个函数叫做<font color=red>似然函数(likelihood function)</font>, 它描述对于不同的模型参数，出现$x$这个样本点的概率是多少。</p>
<h1 id="最大似然估计mle">最大似然估计(MLE)</h1>
<p>假设有一个造币厂生产某种硬币，现在我们拿到了一枚这种硬币，想试试这硬币是不是均匀的。即想知道抛这枚硬币，正反面出现的概率（记为$\theta$）各是多少？</p>
<p>这是一个统计问题，回想一下，解决统计问题需要什么？ 数据！</p>
<p>于是我们拿这枚硬币抛了10次，得到的数据($x_0$)是：反正正正正反正正正反。我们想求的正面概率$\theta$是模型参数，而抛硬币模型我们可以假设是二项分布。</p>
<p>那么，出现实验结果$x_0$(即反正正正正反正正正反)的似然函数是多少呢？</p>
<p>$$f(x_0 ,\theta) = (1-\theta)\times\theta\times\theta\times\theta\times\theta\times(1-\theta)\times\theta\times\theta\times\theta\times(1-\theta) = \theta ^ 7(1 - \theta)^3 = f(\theta)$$
​
注意，这是个只关于$\theta$的函数。而最大似然估计，顾名思义，就是要最大化这个函数。我们可以画出$f(\theta)$的图像：</p>
<p></p>
<p>可以看出，在$\theta = 0.7$时，似然函数取得最大值。</p>
<p>这样，我们已经完成了对$\theta$的最大似然估计。即，抛10次硬币，发现7次硬币正面向上，最大似然估计认为正面向上的概率是0.7。（ummm…这非常直观合理，对吧？）</p>
<p>且慢，一些人可能会说，硬币一般都是均匀的啊！ 就算你做实验发现结果是“反正正正正反正正正反”，我也不信$\theta = 0.7$。</p>
<p>这里就包含了贝叶斯学派的思想了——要考虑先验概率。 为此，引入了最大后验概率估计。</p>
<h1 id="最大后验概率估计map">最大后验概率估计(MAP)</h1>
<p>最大似然估计是求参数$\theta$, 使似然函数$P(x_0 | \theta)$最 大 。 最大后验概率估计则是想求$\theta$使$P(x_0|\theta)$ 最大。求得的$\theta$不单单让似然函数大，不单单让似然函数大，$\theta$自己出现的先验概率也得大。(这有点像正则化里加惩罚项的思想，不过正则化里是利用加法，而MAP里是利用乘法).</p>
<p>MAP其实是在最大化$P(\theta|x_0) = \frac{P(x_0|\theta)P(\theta)}{P(x_0)}$，不过因为$x_0$是确定的(即投出的“反正正正正反正正正反”)，$P(x_0)$是一个已知值，所以去掉了分母$P(x_0)$(假设“投10次硬币”是一次实验，实验做了1000次，“反正正正正反正正正反”出现了n次，则$P(x_0) = n/1000$)。总之，这是一个可以由数据集得到的值）。最大化$P(\theta | x_0)$的意义也很明确，$x_0$已经出现了，要求$\theta$取什么值使$P(\theta | x_0)$最大。顺带一提，$P(\theta | x_0)$, ​即后验概率，这就是“最大后验概率估计”名字的由来。</p>
<p>对于投硬币的例子来看，我们认为（”先验地知道“$\theta$取0.5的概率很大，取其他值的概率小一些。我们用一个高斯分布来具体描述我们掌握的这个先验知识，例如假设$P(\theta)$为均值0.5，方差0.1的高斯函数，如下图：</p>
<p></p>
<p>则$P(x_0 | \theta)$的函数图像为：</p>
<p></p>
<p>注意，此时函数取最大值时，θ \thetaθ取值已向左偏移，不再是0.7。实际上，在$\theta = 0.558$时函数取得了最大值。即，用最大后验概率估计，得到$\theta = 0.558$</p>
<p>最后，那要怎样才能说服一个贝叶斯派相信$\theta = 0.7$呢？你得多做点实验。。</p>
<p>如果做了1000次实验，其中700次都是正面向上，这时似然函数为:</p>
<p></p>
<p>如果仍然假设$P(\theta)$为均值0.5，方差0.1的高斯函数，$P(x_0 | \theta) P(\theta)$的函数图像为:</p>
<p></p>
<p>在$\theta = 0.696$处，$P(x_0 | \theta) P(\theta)$取得最大值。</p>
<p>这样，就算一个考虑了先验概率的贝叶斯派，也不得不承认得把θ \thetaθ估计在0.7附近了。</p>
<p>PS. 要是遇上了顽固的贝叶斯派，认为$P(\theta = 0.5) = 1$，那就没得玩了。。 无论怎么做实验，使用MAP估计出来都是$\theta = 0.5$。这也说明，一个合理的先验概率假设是很重要的。（通常，先验概率能从数据中直接分析得到）</p>
<h1 id="最大似然估计和最大后验概率估计的区别">最大似然估计和最大后验概率估计的区别</h1>
<p>相信读完上文，MLE和MAP的区别应该是很清楚的了。MAP就是多个作为因子的先验概率$P(\theta)$。或者，也可以反过来，认为MLE是把先验概率$P(\theta)$认为等于1，即认为$\theta$是均匀分布。</p>
<p>ref：https://blog.csdn.net/u011508640/article/details/72815981</p>
]]></description></item><item><title>Classification and Regression Metrics</title><link>https://jianye0428.github.io/posts/metrics/</link><pubDate>Sat, 15 Jul 2023 17:47:13 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/metrics/</guid><description><![CDATA[<p>ref:</br>
[1] <a href="https://www.cnblogs.com/rushup0930/p/13359513.html"target="_blank" rel="external nofollow noopener noreferrer">https://www.cnblogs.com/rushup0930/p/13359513.html<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[2] <a href="https://blog.csdn.net/u013250861/article/details/123029585#t12"target="_blank" rel="external nofollow noopener noreferrer">https://blog.csdn.net/u013250861/article/details/123029585#t12<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[3] <a href="https://blog.csdn.net/wf592523813/article/details/95202448"target="_blank" rel="external nofollow noopener noreferrer">https://blog.csdn.net/wf592523813/article/details/95202448<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[4] <a href="https://zhuanlan.zhihu.com/p/69101372"target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/69101372<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br></p>
<h1 id="classification-分类">classification 分类</h1>
<p>主要涉及的知识点：</p>
<ul>
<li>混淆矩阵、Precision(精准率)、Recall(召回率)、Accuracy(准确率)、F1-score    （包括二分类和多分类问题）</li>
<li>ROC、AUC</li>
</ul>
<blockquote>
<p>最常见的指标Accuracy到底有哪些不足？
解: Accuracy是分类问题中最常用的指标，它计算了分类正确的预测数与总预测数的比值。但是，<font color=red>对于不平衡数据集而言，Accuracy并不是一个好指标</font>。
假设我们有100张图片，其中91张图片是「狗」，5张是「猫」，4张是「猪」，我们希望训练一个三分类器，能正确识别图片里动物的类别。其中，狗这个类别就是大多数类 (majority class)。当大多数类中样本（狗）的数量远超过其他类别（猫、猪）时，如果采用Accuracy来评估分类器的好坏，那么即便模型性能很差 (如无论输入什么图片，都预测为「狗」)，也可以得到较高的Accuracy Score (如91%)。此时，虽然Accuracy Score很高，但是意义不大。当数据异常不平衡时，Accuracy评估方法的缺陷尤为显著。</p>
</blockquote>
<h2 id="二分类模型的常见指标">二分类模型的常见指标</h2>
<p>在二分类问题中，假设该样本一共有两种类别：Positive和Negative。当分类器预测结束，我们可以绘制出混淆矩阵（confusion matrix）。其中分类结果分为如下几种：</p>
<p></p>
<ul>
<li>True Positive (TP): 把正样本成功预测为正。</li>
<li>True Negative (TN)：把负样本成功预测为负。</li>
<li>False Positive (FP)：把负样本错误地预测为正。</li>
<li>False Negative (FN)：把正样本错误的预测为负。</li>
</ul>
<blockquote>
<p>一个小技巧， <font color=red>第一个字母表示划分正确与否</font>， T 表示判定正确（判定正确）， F表示判定错误(False)； <font color=red>第二个字母表示分类器判定结果</font>， P表示判定为正例， N表示判定为负例。</p>
</blockquote>
<p>在二分类模型中，Accuracy，Precision，Recall和F1 score的定义如下：</p>
<p>$$\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}$$</p>
<blockquote>
<blockquote>
<p>Accuracy 能够清晰的判断我们模型的表现，但有一个严重的缺陷： 在正负样本不均衡的情况下，占比大的类别往往会成为影响 Accuracy 的最主要因素，此时的 Accuracy 并不能很好的反映模型的整体情况。</p>
</blockquote>
</blockquote>
<p>$$\text{Precision} = \frac{TP}{TP + FP}$$</p>
<blockquote>
<blockquote>
<p>Precision着重评估在预测为Positive的所有数据中，真实Positve的数据到底占多少？</p>
</blockquote>
</blockquote>
<p>精确率高，意味着分类器要尽量在 “更有把握” 的情况下才将样本预测为正样本， 这意味着精确率能够很好的体现模型对于负样本的区分能力，精确率越高，则模型对负样本区分能力越强。</p>
<p>$$\text{Recall} = \frac{TP}{TP + FN}$$</p>
<blockquote>
<blockquote>
<p>Recall着重评估：在所有的Positive数据中，到底有多少数据被成功预测为Positive</p>
</blockquote>
</blockquote>
<p>召回率高，意味着分类器尽可能将有可能为正样本的样本预测为正样本，这意味着<font color=red>召回率能够很好的体现模型对于正样本的区分能力，召回率越高，则模型对正样本的区分能力越强</font>。</p>
<p><strong>举例</strong>:</p>
<p>一个医院新开发了一套癌症AI诊断系统，想评估其性能好坏。我们把病人得了癌症定义为Positive，没得癌症定义为Negative。那么， 到底该用什么指标进行评估呢？</p>
<ul>
<li>如用Precision对系统进行评估，那么其回答的问题就是：
<blockquote>
<p>在诊断为癌症的一堆人中，到底有多少人真得了癌症？</p>
</blockquote>
</li>
<li>如用Recall对系统进行评估，那么其回答的问题就是：
<blockquote>
<p>在一堆得了癌症的病人中，到底有多少人能被成功检测出癌症？</p>
</blockquote>
</li>
<li>如用Accuracy对系统进行评估，那么其回答的问题就是：
<blockquote>
<p>在一堆癌症病人和正常人中，有多少人被系统给出了正确诊断结果（患癌或没患癌）？</p>
</blockquote>
</li>
</ul>
<p><font color=red>那啥时候应该更注重Recall而不是Precision呢？</font></p>
<blockquote>
<p>当False Negative (FN)的成本代价很高 (后果很严重)，希望尽量避免产生FN时，应该着重考虑提高Recall指标。</p>
</blockquote>
<p><font color=red>那啥时候应该更注重Precision而不是Recall呢？</font></p>
<blockquote>
<p>当False Positive (FP)的成本代价很高 (后果很严重)时，即期望尽量避免产生FP时，应该着重考虑提高Precision指标。</p>
</blockquote>
<p>$$\text{F1-score} = \frac{2 \times Precision \times Recall}{Precision + Recall}$$</p>
<p>而F1-score是Precision和Recall两者的综合。</p>
<p>举个更有意思的例子（我拍脑袋想出来的，绝对原创哈），假设检察机关想将罪犯捉拿归案，需要对所有人群进行分析，以判断某人犯了罪（Positive），还是没犯罪（Negative）。显然，检察机关希望不漏掉一个罪人（提高recall），也不错怪一个好人（提高precision），所以就需要同时权衡recall和precision两个指标。</p>
<p>尤其在上个世纪，中国司法体制会更偏向Recall，即「天网恢恢，疏而不漏，任何罪犯都插翅难飞」。而西方司法系统会更偏向Precision，即「绝不冤枉一个好人，但是难免有罪犯成为漏网之鱼，逍遥法外」。到底是哪种更好呢？显然，极端并不可取。Precision和Recall都应该越高越好，也就是F1应该越高越好。</p>
<p><strong><font color=green>如何通俗的解释召回率与精确率？</font></strong></p>
<blockquote>
<p>例：公园里有50只皮卡丘和10只臭臭泥。有正常审美的人都会想要用精灵球把尽可能多的皮卡丘抓回来，同时尽可能少地抓住臭臭泥。 最终我们的精灵球成功抓回来了45只皮卡丘和10只臭臭泥。
我们就可以说50只皮卡丘中有45只被召唤 (call) 回来 (re) 了，所以 recall = 45 / 50。
但同时，这台机器还误把5只臭臭泥识别为皮卡丘，在它抓回来的所有55只神奇宝贝中，精灵球对皮卡丘判断的精准性 (precision)  = 45 / 55。
在上面的例子中，精灵球=预测模型，皮卡丘=正样本，臭臭泥=负样本。
总结这两个概念的用处：描述模型对正样本的预测性能
1、recall描述模型“把正样本叫 (call) 回来(re)”的能力。
2、precision描述模型“叫回来的正样本”有多少是精确的。</p>
</blockquote>
<h2 id="aoc--auc">AOC / AUC</h2>
<p>混淆矩阵中有着Positive、Negative、True、False的概念，其意义如下：</p>
<ul>
<li>称预测类别为1的为Positive（阳性），预测类别为0的为Negative（阴性）。</li>
<li>预测正确的为True（真），预测错误的为False（伪）。</li>
</ul>
<p>对上述概念进行组合，就产生了如下的混淆矩阵:</p>
<p></p>
<p>然后，由此引出True Positive Rate（真阳率）、False Positive（伪阳率）两个概念：</p>
<p>$$TP Rate = \frac{TP}{TP + FN}$$
$$FP Rate = \frac{FP}{FP + TN}$$</p>
<p>仔细看这两个公式，发现其实TPRate就是TP除以TP所在的列，FPRate就是FP除以FP所在的列，二者意义如下：</p>
<ul>
<li>TPRate的意义是所有真实类别为1的样本中，预测类别为1的比例。</li>
<li>FPRate的意义是所有真实类别为0的样本中，预测类别为1的比例。</li>
</ul>
<p>如果上述概念都弄懂了，那么ROC曲线和AUC就so easy了：</p>
<p>按照定义，AUC即ROC曲线下的面积，而ROC曲线的横轴是FPRate，纵轴是TPRate，当二者相等时，即y=x，如下图:</p>
<p></p>
<p>表示的意义是：对于不论真实类别是1还是0的样本，分类器预测为1的概率是相等的。</p>
<p>换句话说，分类器对于正例和负例毫无区分能力，和抛硬币没什么区别，一个抛硬币的分类器是我们能想象的最差的情况，因此一般来说我们认为AUC的最小值为0.5（当然也存在预测相反这种极端的情况，AUC小于0.5，这种情况相当于分类器总是把对的说成错的，错的认为是对的，那么只要把预测类别取反，便得到了一个AUC大于0.5的分类器）。</p>
<p>而我们希望分类器达到的效果是：对于真实类别为1的样本，分类器预测为1的概率（即TPRate），要大于真实类别为0而预测类别为1的概率（即FPRate），即y＞x，因此大部分的ROC曲线长成下面这个样子：</p>
<p></p>
<p>说了这么多还是不够直观，不妨举个简单的例子。</p>
<p>首先对于硬分类器（例如SVM，NB），预测类别为离散标签，对于8个样本的预测情况如下：</p>
<p></p>
<p>得到混淆矩阵如下：</p>
<p></p>
<p>进而算得TPRate=3/4，FPRate=2/4，得到ROC曲线：</p>
<p></p>
<p>最终得到AUC为0.625。</p>
<p>对于LR等预测类别为概率的分类器，依然用上述例子，假设预测结果如下：</p>
<p></p>
<p>这时，需要设置阈值来得到混淆矩阵，不同的阈值会影响得到的TPRate，FPRate，如果阈值取0.5，小于0.5的为0，否则为1，那么我们就得到了与之前一样的混淆矩阵。其他的阈值就不再啰嗦了。依次使用所有预测值作为阈值，得到一系列TPRate，FPRate，描点，求面积，即可得到AUC。</p>
<p>最后说说AUC的优势，AUC的计算方法同时考虑了分类器对于正例和负例的分类能力，在样本不平衡的情况下，依然能够对分类器作出合理的评价。</p>
<p>例如在反欺诈场景，设欺诈类样本为正例，正例占比很少（假设0.1%），如果使用准确率评估，把所有的样本预测为负例，便可以获得99.9%的准确率。</p>
<p>但是如果使用AUC，把所有样本预测为负例，TPRate和FPRate同时为0（没有Positive），与(0,0) (1,1)连接，得出AUC仅为0.5，成功规避了样本不均匀带来的问题。</p>
<h2 id="多分类模型的常见指标详细解析">多分类模型的常见指标详细解析</h2>
<p>在多分类（大于两个类）问题中，假设我们要开发一个动物识别系统，来区分输入图片是猫，狗还是猪。给定分类器一堆动物图片，产生了如下结果混淆矩阵。</p>
<p></p>
<p>在混淆矩阵中，正确的分类样本（Actual label = Predicted label）分布在左上到右下的对角线上。其中，Accuracy的定义为分类正确（对角线上）的样本数与总样本数的比值。<strong>Accuracy度量的是全局样本预测情况。而对于Precision和Recall而言，每个类都需要单独计算其Precision和Recall。</strong>
classify_multiclass_prediction
</p>
<p>比如，对类别「猪」而言，其Precision和Recall分别为:</p>
<p>$$\text{Precision} = \frac{TP}{TP + FP} = \frac{20}{20 + 50} = \frac{2}{7}$$</p>
<p>$$\text{Recall} = \frac{TP}{TP + FN} = \frac{20}{10} = \frac{2}{3}$$</p>
<p>也就是:
$$P_{cat} = \frac{8}{15}, P_{dog} = \frac{17}{23}, P_{pig} = \frac{2}{7}, (P代表Precision) $$
$$R_{cat} = \frac{4}{7}, R_{dog} = \frac{17}{32}, R_{pig} = \frac{2}{3}, (R代表Recall) $$</p>
<p>如果想评估该识别系统的总体功能，必须考虑猫、狗、猪三个类别的综合预测性能。那么，到底要怎么综合这三个类别的Precision呢？是简单加起来做平均吗？通常来说， 我们有如下几种解决方案（<a href="https://link.zhihu.com/?target=https%3A//scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html"target="_blank" rel="external nofollow noopener noreferrer">也可参考scikit-learn官网<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>）：</p>
<p><strong>1. Macro-average方法</strong>
该方法最简单，直接将不同类别的评估指标（Precision/ Recall/ F1-score）加起来求平均，给所有类别相同的权重。该方法能够平等看待每个类别，但是它的值会受<strong>稀有类别</strong>影响。</p>
<p>$$\text{Macro-Precision} = \frac{P_{cat} + P_{dog} + P_{pig}}{3} = 0.5194$$
$$\text{Macro-Recall} = \frac{R_{cat} + R_{dog} + R_{pig}}{3} = 0.5898$$</p>
<p><strong>2. Weighted-average方法</strong></p>
<p>该方法给不同类别不同权重（权重根据该类别的真实分布比例确定），每个类别乘权重后再进行相加。该方法考虑了类别不平衡情况，它的值更容易受到常见类（majority class）的影响。</p>
<p>$$W_{cat} : W_{dog} : W_{pig} = N_{cat} : N_{dog} : N_{pig} = \frac{7}{26} : \frac{16}{26} : \frac{3}{26} (W代表权重，N代表样本在该类别下的真实数目)$$
$$\text{Weighted-Precision} = P_{cat} \times W_{cat} + P_{dog} \times W_{dog} + P_{pig} \times W_{pig} = 0.6314$$
$$\text{Weighted-Recall} = {R_{cat} \times W_{cat} + R_{dog} \times W_{dog} + R_{pig} \times W_{pig}}= 0.5577$$</p>
<p><strong>3. Micro-average方法</strong></p>
<p>该方法把每个类别的TP, FP, FN先相加之后，在根据二分类的公式进行计算。</p>
<p>$$\text{Micro-Precision} = \frac{TP_{cat} + TP_{dog} + TP_{pig}}{TP_{cat} + TP_{dog} + TP_{pig} + FP_{cat} + FP_{dog} + FP_{pig}} = 0.5577$$
$$\text{Micro-Recall} = \frac{TP_{cat} + TP_{dog} + TP_{pig}}{TP_{cat} + TP_{dog} + TP_{pig} + FN_{cat} + FN_{dog} + FN_{pig}} = 0.5577$$</p>
<p>其中，特别有意思的是，<u>Micro-precision 和 Micro-recall竟然始终相同！</u>这是为啥呢？</p>
<p>这是因为在某一类中的False Positive样本，一定是其他某类别的False Negative样本。听起来有点抽象？举个例子，比如说系统错把「狗」预测成「猫」，那么对于狗而言，其错误类型就是False Negative，对于猫而言，其错误类型就是False Positive。于此同时，Micro-precision和Micro-recall的数值都等于Accuracy，因为它们计算了对角线样本数和总样本数的比值，总结就是</p>
<p>$$\text{Micro-Precision} = \text{Micro-Recall} = \text{Micro-F1 score} = \text{Accuracy}$$</p>
<p>demo示例:</p>
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">average_precision_score</span><span class="p">,</span><span class="n">precision_score</span><span class="p">,</span><span class="n">f1_score</span><span class="p">,</span><span class="n">recall_score</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># create confusion matrix</span>
</span></span><span class="line"><span class="cl"><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">70</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">160</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">30</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">40</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">20</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">20</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">                  <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">30</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">80</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">30</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">                  <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">5</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="mi">15</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">20</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">conf_matrix</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Cat&#39;</span><span class="p">,</span><span class="s1">&#39;Dog&#39;</span><span class="p">,</span><span class="s1">&#39;Pig&#39;</span><span class="p">],</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Cat&#39;</span><span class="p">,</span><span class="s1">&#39;Dog&#39;</span><span class="p">,</span><span class="s1">&#39;Pig&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># plot size setting</span>
</span></span><span class="line"><span class="cl"><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mf">4.5</span><span class="p">,</span><span class="mf">3.5</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">conf_matrix</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">annot_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&#34;size&#34;</span><span class="p">:</span> <span class="mi">19</span><span class="p">},</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&#34;Blues&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;True label&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Predicted label&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;confusion.pdf&#39;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;------Weighted------&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Weighted precision&#39;</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Weighted recall&#39;</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Weighted f1-score&#39;</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;weighted&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;------Macro------&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Macro precision&#39;</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Macro recall&#39;</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Macro f1-score&#39;</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;------Micro------&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Micro precision&#39;</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Micro recall&#39;</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Micro f1-score&#39;</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;micro&#39;</span><span class="p">))</span></span></span></code></pre></td></tr></table>
</div>
</div><h1 id="regression-回归">Regression 回归</h1>
<p>回归算法的评价指标就是MSE，RMSE，MAE、R-Squared。</p>
<p>　　MSE和MAE适用于误差相对明显的时候，大的误差也有比较高的权重，RMSE则是针对误差不是很明显的时候；MAE是一个线性的指标，所有个体差异在平均值上均等加权，所以它更加凸显出异常值，相比MSE；</p>
<p>　　RMSLE: 主要针对数据集中有一个特别大的异常值，这种情况下，data会被skew，RMSE会被明显拉大，这时候就需要先对数据log下，再求RMSE，这个过程就是RMSLE。对低估值（under-predicted）的判罚明显多于估值过高(over-predicted)的情况（RMSE则相反）</p>
]]></description></item><item><title>Maching Learning Notes 1</title><link>https://jianye0428.github.io/posts/notes_1/</link><pubDate>Sat, 15 Jul 2023 16:27:34 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/notes_1/</guid><description><![CDATA[<h2 id="用pickle保存和加载模型">用pickle保存和加载模型</h2>
<ul>
<li>保存模型
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pickle</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
</span></span><span class="line"><span class="cl"><span class="n">model_dir</span> <span class="o">=</span> <span class="s1">&#39;./model.pkl&#39;</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">model_dir</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span> <span class="c1"># 注意:保存完模型之后要关闭文件</span></span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>加载模型
<div class="highlight" id="id-2"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pickle</span>
</span></span><span class="line"><span class="cl"><span class="n">model_dir</span> <span class="o">=</span> <span class="s1">&#39;./model.pkl&#39;</span>
</span></span><span class="line"><span class="cl"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">model_dir</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">pickel</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">mode</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">))</span></span></span></code></pre></td></tr></table>
</div>
</div></li>
</ul>
<h2 id="逻辑回归-logistic-regression">逻辑回归 Logistic Regression</h2>
<ul>
<li>LR Implementation code snippets
<div class="highlight" id="id-3"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">  <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
</span></span><span class="line"><span class="cl">  <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</span></span><span class="line"><span class="cl">  <span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
</span></span><span class="line"><span class="cl">  <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl">  <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl">  <span class="kn">import</span> <span class="nn">pickle</span>
</span></span><span class="line"><span class="cl">  <span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="n">data_path</span> <span class="o">=</span> <span class="s1">&#39;./data/merged_data/data.npy&#39;</span>
</span></span><span class="line"><span class="cl">  <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">allow_pickle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">model_l1_path</span><span class="o">=</span><span class="s1">&#39;./model/logistic_reg_l1.pickle&#39;</span>
</span></span><span class="line"><span class="cl">  <span class="n">model_l2_path</span><span class="o">=</span><span class="s1">&#39;./model/logictic_reg_l2.pickle&#39;</span>
</span></span><span class="line"><span class="cl">  <span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">35</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">  <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="n">X_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1"># lr_l1 = LogisticRegression(penalty=&#34;l1&#34;, C=0.5, solver=&#39;sag&#39;, multi_class=&#34;auto&#34;)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># lr_l2 = LogisticRegression(penalty=&#34;l2&#34;, C=0.5, solver=&#39;sag&#39;, multi_class=&#34;auto&#34;)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1"># # train model</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># lr_l1.fit(X_train, Y_train)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># lr_l2.fit(X_train, Y_train)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1"># model performence on train set</span>
</span></span><span class="line"><span class="cl">  <span class="n">l1_train_predict</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">  <span class="n">l2_train_predict</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1"># model performence on test set</span>
</span></span><span class="line"><span class="cl">  <span class="n">l1_test_predict</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">  <span class="n">l2_test_predict</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">50</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># lr_l1 = LogisticRegression(penalty=&#34;l1&#34;, C=c, solver=&#39;liblinear&#39;, max_iter=1000)</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># lr_l2 = LogisticRegression(penalty=&#39;l2&#39;, C=c, solver=&#39;liblinear&#39;, max_iter=1000)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="n">lr_l1</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s2">&#34;l1&#34;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">c</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">lr_l2</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">c</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">multi_class</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="c1"># 训练模型，记录L1正则化模型在训练集测试集上的表现</span>
</span></span><span class="line"><span class="cl">      <span class="n">lr_l1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">l1_train_predict</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">lr_l1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">Y_train</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">      <span class="n">l1_test_predict</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">lr_l1</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">),</span> <span class="n">y_test</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="c1"># 记录L2正则化模型的表现</span>
</span></span><span class="line"><span class="cl">      <span class="n">lr_l2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">l2_train_predict</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">lr_l2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">Y_train</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">      <span class="n">l2_test_predict</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">lr_l2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">),</span> <span class="n">y_test</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="k">if</span> <span class="n">c</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">          <span class="n">pred_y_test</span> <span class="o">=</span> <span class="n">lr_l2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">          <span class="n">mask</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">pred_y_test</span><span class="o">-</span><span class="n">y_test</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">5</span>
</span></span><span class="line"><span class="cl">          <span class="n">neg_test</span> <span class="o">=</span> <span class="n">pred_y_test</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">          <span class="n">res</span> <span class="o">=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">neg_test</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">pred_y_test</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">          <span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">          <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">model_l1_path</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">              <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">lr_l1</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">          <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">model_l2_path</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f2</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">              <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">lr_l2</span><span class="p">,</span> <span class="n">f2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">l1_train_predict</span><span class="p">,</span> <span class="n">l2_train_predict</span><span class="p">,</span> <span class="n">l1_test_predict</span><span class="p">,</span> <span class="n">l2_test_predict</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">  <span class="n">label</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;l1_train&#39;</span><span class="p">,</span> <span class="s1">&#39;l2_train&#39;</span><span class="p">,</span> <span class="s1">&#39;l1_test&#39;</span><span class="p">,</span> <span class="s2">&#34;l2_test&#34;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">  <span class="n">color</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="s1">&#39;orange&#39;</span><span class="p">,</span> <span class="s1">&#39;blue&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span> <span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">50</span><span class="p">),</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="n">color</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s2">&#34;best&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></span></span></code></pre></td></tr></table>
</div>
</div></li>
</ul>
<h2 id="支持向量机-support-vector-machine">支持向量机 Support Vector Machine</h2>
<ul>
<li>Using GridSearch to find the best parameters [code snippets]
<div class="highlight" id="id-4"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">  <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl">  <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl">  <span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Perceptron</span><span class="p">,</span> <span class="n">LogisticRegression</span>
</span></span><span class="line"><span class="cl">  <span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
</span></span><span class="line"><span class="cl">  <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</span></span><span class="line"><span class="cl">  <span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
</span></span><span class="line"><span class="cl">  <span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
</span></span><span class="line"><span class="cl">  <span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
</span></span><span class="line"><span class="cl">  <span class="kn">import</span> <span class="nn">pickle</span>
</span></span><span class="line"><span class="cl">  <span class="n">merged_data_dir</span> <span class="o">=</span> <span class="s1">&#39;../data/merged_data/merged_data.npy&#39;</span>
</span></span><span class="line"><span class="cl">  <span class="n">model_dir</span><span class="o">=</span><span class="s1">&#39;./svm.pkl&#39;</span>
</span></span><span class="line"><span class="cl">  <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">merged_data_dir</span><span class="p">,</span> <span class="n">allow_pickle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1">#labeling</span>
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="n">ele</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="k">if</span> <span class="n">ele</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">20</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">          <span class="n">ele</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">      <span class="k">elif</span> <span class="n">ele</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span><span class="mi">20</span> <span class="ow">and</span> <span class="n">ele</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">40</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">          <span class="n">ele</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">      <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">          <span class="n">ele</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">34</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">  <span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">  <span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># Create training and test split</span>
</span></span><span class="line"><span class="cl">  <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># feature scaling</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># sc = StandardScaler()</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># sc.fit(X_train)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># X_train_std = sc.transform(X_train)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># X_test_std = sc.transform(X_test)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1">##################################</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># # Instantiate the Support Vector Classifier (SVC)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># svc = SVC(C=10, random_state=1, kernel=&#39;rbf&#39;, gamma=0.3)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1"># # Fit the model</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># svc.fit(X_train, y_train)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1"># # Make the predictions</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># y_predict = svc.predict(X_test)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1"># # Measure the performance</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># print(&#34;Accuracy score %.3f&#34; %metrics.accuracy_score(y_test, y_predict))</span>
</span></span><span class="line"><span class="cl">  <span class="c1">#############################################</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="nf">svm_cross_validation</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">      <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
</span></span><span class="line"><span class="cl">      <span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
</span></span><span class="line"><span class="cl">      <span class="n">model</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">probability</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">],</span> <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">]}</span>
</span></span><span class="line"><span class="cl">      <span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">best_parameters</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">      <span class="k">for</span> <span class="n">para</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">best_parameters</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
</span></span><span class="line"><span class="cl">          <span class="nb">print</span><span class="p">(</span><span class="n">para</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">model</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">best_parameters</span><span class="p">[</span><span class="s1">&#39;C&#39;</span><span class="p">],</span> <span class="n">gamma</span><span class="o">=</span><span class="n">best_parameters</span><span class="p">[</span><span class="s1">&#39;gamma&#39;</span><span class="p">],</span> <span class="n">probability</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="k">return</span> <span class="n">model</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="n">svm_model</span> <span class="o">=</span> <span class="n">svm_cross_validation</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">model_dir</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">svm_model</span><span class="p">,</span> <span class="n">f1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">f1</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">  <span class="nb">print</span><span class="p">(</span><span class="n">svm_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">  <span class="n">y_predict</span> <span class="o">=</span> <span class="n">svm_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="nb">print</span><span class="p">(</span><span class="n">y_predict</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div></li>
</ul>
]]></description></item></channel></rss>