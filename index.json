[{"categories":["Math"],"content":"1. 点到直线的距离 第一种: 本文默认情况下，直线的方程为 $l:Ax+By+C=0$，$A$, $B$ 均不为0，斜率为 $k_l$，点的坐标为P(x0, y0)，点 $P$ 到 $l$ 的距离为 $d$ 。 则距离为: $$d=\\frac{|Ax_0+By_0+C|}{\\sqrt{A^2+B^2}}$$ 推导过程如下: https://zhuanlan.zhihu.com/p/26307123 第二种: 直线的方程为 $l: y = ax + b$，$a$, $b$ 均不为0，斜率为 $a$，点的坐标为P(x0, y0)，点 $P$ 到直线 $l$ 的距离为 $d$ 。 $$d=\\frac{|ax_{0} - y_{0} + b|}{\\sqrt{a^2+b^2}}$$ ","date":"2024-05-12","objectID":"/posts/pointlineplane/:1:0","tags":["平面几何"],"title":"点、线、面之间的关系","uri":"/posts/pointlineplane/"},{"categories":["Math"],"content":"2. 如何判断两点在直线的两侧 判断点在直线的一侧: 方法一: 已知 $P(0,0)$, $Q(3,2)$ 两点，试判断 $P$ , $Q$是否在直线 $2x+3y=4$ 的同一侧。 解：直线2x+3y=4, 即直线2x+3y-4=0, 把P、Q代入2x+3y-4得到: $$2 \\times 0 + 3 \\times 0-4=-4\u003c0$$ $$2 {\\times} 3+3 {\\times} 2 - 4 = 8 \u003e 0$$ 所以，在两侧。 方法2: 怎么判断坐标为(xp,yp)的点P是在直线的哪一侧呢? 设直线是由其上两点 $(x_1,y_1)$，$(x_2,y_2)$ 确定的，直线方向是由 $(x_1,y_1)$ 到 $(x_2,y_2)$ 的方向。 假设直线方程为：$Ax+By+C=0$，则有: $A=y2-y1$; $B=x1-x2$; $C=x2y1-x1y2$; $$\\left\\{\\begin{aligned} A\u0026=y_2-y_1\\\\ B\u0026=x_1-x_2\\\\ C\u0026=x_2y_1-x_1y_2 \\end{aligned}\\right.$$ 这时可以通过计算D,来判断点P是在直线的哪一侧: $$D=Ax_p+By_p+C$$ 若D\u003c0, 则点P在直线的左侧; 若D\u003e0, 则点P在直线的右侧; 若D=0, 则点P在直线上。 注：这里的直线是有方向性的！ 方法3： 利用矢量计算快速判定一点在直线的哪一侧! 例如矢量A×矢量B=矢量C 设想矢量A沿小于180度的角度转向矢量B 将右手的四指指向矢量A的方向，右手的四指弯曲代表上述旋转方向，则伸直的拇指指向它们的叉乘得到的矢量C 如果矢量C的方向相同，则在同侧；否则在两侧。 注：叉乘计算公式！ 若将向量用坐标表示（三维向量），向量 $a=(x_1,y_1,z_1)$，向量 $b=(x_2,y_2,z_2)$，则： 点乘，也叫向量的内积、数量积。 $$向量a·向量b = |a||b|cos\\theta$$ $$向量a·向量b = x_1 * x_2 + y_1 * y_2 + z_1 * z_2$$ 叉乘，也叫向量的外积、向量积。 $$|向量c| = |向量a×向量b| = |a||b|sin \\theta$$ 向量c的方向与a,b所在的平面垂直，且方向要用“右手法则”判断（用右手的四指先表示向量a的方向，然后手指朝着手心的方向\u003c180摆动到向量b的方向，大拇指所指的方向就是向量c的方向）； $$a\\times b=\\begin{vmatrix}\\mathrm{i}\u0026\\mathrm{j}\u0026\\mathrm{k}\\\\x_{1}\u0026y_{1}\u0026z_{1}\\\\x_{2}\u0026y_{2}\u0026z_{2}\\end{vmatrix}=(y_{1}z_{2}-y_{2}z_{1})i-(x_{1}z_{2}-x_{2}z_{1})j+(x_{1}y_{2}-x_{2}y_{1})k$$ （i、j、k分别为空间中相互垂直的三条坐标轴的单位向量） ref: [1]. Cross Product叉乘速查手册 [2].叉乘几何意义 [3].https://blog.csdn.net/wzyaiwl/article/details/106310705 ","date":"2024-05-12","objectID":"/posts/pointlineplane/:2:0","tags":["平面几何"],"title":"点、线、面之间的关系","uri":"/posts/pointlineplane/"},{"categories":["Math"],"content":"3. 判断点是否在矩形、多边形中 方法一: 只要判断该点的横坐标和纵坐标是否夹在矩形的左右边和上下边之间。 例如: 判断一个点是否在两条线段之间夹着就转化成，判断一个点是否在某条线段的一边上，就可以利用叉乘的方向性，来判断夹角是否超过了180度 如下图: BP Network 只要判断 $(AB \\times AE ) * (CD \\times CE) \u003e= 0$ 就说明E在AD和BC中间夹着，同理 $ (DA \\times DE ) * (BC \\times BE) \u003e= 0 $ 计算另两边AB,CD就可以了。(备注可进一步学习：向量点乘，叉乘的意义和几何意义) 最后就是只需要判断 $$(AB \\times AE ) * (CD \\times CE) \u003e= 0 \\text{且} (DA \\times DE ) * (BC \\times BE) \u003e= 0$$ 。 参考代码: // 计算 |p1 p2| X |p1 p| function GetCross(p1: Point, p2: Point, p: Point) { return (p2.x - p1.x) * (p.y - p1.y) - (p.x - p1.x) * (p2.y - p1.y); } //判断点p是否在p1p2p3p4的正方形内 function IsPointInMatrix(p1: Point, p2: Point, p3: Point, p4: Point, p: Point) { let isPointIn = GetCross(p1, p2, p) * GetCross(p3, p4, p) \u003e= 0 \u0026\u0026 GetCross(p2, p3, p) * GetCross(p4, p1, p) \u003e= 0; return isPointIn; } 举例: https://www.cnblogs.com/fangsmile/p/9306510.html 方法2： 采用点是否包含在多边形中判断 以该点为顶点，做一条射线，使得矩形四个顶点中任意一点都不在射线上。 若该射线与矩形有且仅有一个交点，则在矩形内；若有零个或两个焦点，则在矩形外。 至于射线，可以通过选择肯定在矩形外的一点和已知点练成线段来构成。 References: [1] 二维计算几何基础 ","date":"2024-05-12","objectID":"/posts/pointlineplane/:3:0","tags":["平面几何"],"title":"点、线、面之间的关系","uri":"/posts/pointlineplane/"},{"categories":["Math"],"content":"4. 判断一个点是否在三角形的内部 方法一：面积比较 判断△ABO+△BOC+△COA的面积与△ABC是否相等。若相等则O在内部，反之则在外部。 BP Network 如何计算三角形的面积呢？通过坐标，很容易计算三角形的边长。 再由海伦公式计算面积。 $$S=\\sqrt{p(p-a)(p-b)(p-c)}$$ 其中，a,b,c为三边长度, $p=\\frac{a+b+c}{2}$ 代码实现: #include \u003ciostream\u003e #include \u003cmath.h\u003e using namespace std; struct Point { double x; double y; }; double getDist(Point p1,Point p2) { //两点之间计算距离公式 return sqrt(pow(p1.x-p2.x,2) + pow(p1.y-p2.y,2)); } double getArea(Point p1,Point p2,Point p3) { double a = getDist(p1, p2); double b = getDist(p2, p3); double c = getDist(p1, p3); double p = (a + b + c) / 2; return sqrt(p * (p - a) * (p - b) * (p - c)); } bool isInTriangle(Point p1,Point p2,Point p3,Point o) { double s1 = getArea(p1,p2,o); double s2 = getArea(p2,p3,o); double s3 = getArea(p3,p1,o); double s = getArea(p1,p2,p3); return s1+s2+s3 == s; //此处没有用fabs(a-b)\u003ceps比较，是方便大家理解思路 } int main() { Point p1,p2,p3,o; cin \u003e\u003e p1.x \u003e\u003e p1.y; cin \u003e\u003e p2.x \u003e\u003e p2.y; cin \u003e\u003e p3.x \u003e\u003e p3.y; cin \u003e\u003e o.x \u003e\u003e o.y; bool flag = isInTriangle(p1,p2,p3,o); if(flag) puts(\"Yes\"); else puts(\"No\"); } 方法二：向量叉乘 若点O在三角形内部，则沿着三角形的边逆时针走，点O一定保持在边的左侧。如图示，点在逆时针行走时，在AB，BC，CA的左侧。 BP Network 如何判断点在一个边的左侧呢？ 可以借助向量叉乘来判断O是否在向量AB的哪一侧。通过计算向量AO与向量AB的叉乘的值为正，则表示O在AB的左侧，反之为右侧。 (理解最好，理解不了也不要纠结，把叉乘公式记一下就ok) 向量 $\\overrightarrow{a}$ 是 $(m,n)$ , $\\vec{b}$ 是 $(p,q)$ $$\\vec{a} \\times \\vec{b} = mq-np$$ 本题的核心思路就是这样。如果要让手撕代码，题目可能没有说输入的3个点是逆时针顺序的。比如，上图中如果依次输入的是A,C,B的坐标，那就不行了。 怎么解决呢？假设依次输入的点分别是p1,p2,p3。 我们判断若p3在 $\\vec{p1} \\vec{p2}$的右侧！则表示输入的点的顺序是顺时针的，即A,C,B式的输入，将p2,p3调换位置即可保证顺序是逆时针。 BP Network 参考代码: #include \u003ciostream\u003e #include \u003cmath.h\u003e using namespace std; struct Point { double x; double y; }; double crossproduct(Point p1,Point p2,Point p3) { //首先根据坐标计算p1p2和p1p3的向量，然后再计算叉乘 //p1p2 向量表示为 (p2.x-p1.x,p2.y-p1.y) //p1p3 向量表示为 (p3.x-p1.x,p3.y-p1.y) return (p2.x-p1.x)*(p3.y-p1.y) - (p2.y-p1.y)*(p3.x-p1.x); } bool isInTriangle(Point p1,Point p2,Point p3,Point o) { //保证p1，p2，p3是逆时针顺序 if(crossproduct(p1, p2, p3)\u003c0) return isInTriangle(p1,p3,p2,o); if(crossproduct(p1, p2, o)\u003e0 \u0026\u0026 crossproduct(p2, p3, o)\u003e0 \u0026\u0026 crossproduct(p3, p1, o)\u003e0) return true; return false; } int main() { Point p1,p2,p3,o; cin \u003e\u003e p1.x \u003e\u003e p1.y; cin \u003e\u003e p2.x \u003e\u003e p2.y; cin \u003e\u003e p3.x \u003e\u003e p3.y; cin \u003e\u003e o.x \u003e\u003e o.y; bool flag = isInTriangle(p1,p2,p3,o); if(flag) puts(\"Yes\"); else puts(\"No\"); } https://leetcode.cn/circle/discuss/7OldE4/ ","date":"2024-05-12","objectID":"/posts/pointlineplane/:4:0","tags":["平面几何"],"title":"点、线、面之间的关系","uri":"/posts/pointlineplane/"},{"categories":["AV","Robotics"],"content":"0. 基于采样的运动规划算法-RRT(Rapidly-exploring Random Trees) RRT是Steven M. LaValle和James J. Kuffner Jr.提出的一种通过随机构建Space Filling Tree实现对非凸高维空间快速搜索的算法。该算法可以很容易的处理包含障碍物和差分运动约束的场景，因而广泛的被应用在各种机器人的运动规划场景中。 BP Network ","date":"2024-05-09","objectID":"/posts/rrt/:0:0","tags":["RRT"],"title":"RRT (Rapidly-Exploring Random Tree) 算法详解","uri":"/posts/rrt/"},{"categories":["AV","Robotics"],"content":"1、 Basic RRT算法 原始的RRT算法中将搜索的起点位置作为根节点，然后通过随机采样增加叶子节点的方式，生成一个随机扩展树，当随机树的叶子节点进入目标区域，就得到了从起点位置到目标位置的路径。 伪代码如下： BP Network 上述伪代码中，M是地图环境，$x_{init}$是起始位置，$x_{goal}$是目标位置。路径空间搜索的过程从起点开始，先随机撒点$x_rand$;然后查找距离 $x_rand$ 最近的节点 $x_{near}$;然后沿着 $x_{near}$ 到 $x_{rand}$方向前进stepsize的距离得到$x_{new}$; CollisionFree(M, $E_i$) 方法检测Edge $(x_{new},x_{near})$ 是否与地图环境中的障碍物有碰撞，如果没有碰撞，则将成功完成一次空间搜索拓展。重复上述过程，直至达到目标位置。 BP Network 图片来源:https://www.researchgate.net/profile/Burak_Boyacioglu/publication/306404973/figure/fig1/AS:398553223581697@1472033901892/Basic-RRT-algorithm.png ","date":"2024-05-09","objectID":"/posts/rrt/:1:0","tags":["RRT"],"title":"RRT (Rapidly-Exploring Random Tree) 算法详解","uri":"/posts/rrt/"},{"categories":["AV","Robotics"],"content":"2、基于概率的RRT算法 为了加快随机树收敛到目标位置的速度，基于概率的RRT算法在随机树的扩展的步骤中引入一个概率 $p$，根据概率 $p$ 的值来选择树的生长方向是随机生长($x_{rand}$) 还是朝向目标位置 $x_{goal}$ 生长。引入向目标生长的机制可以加速路径搜索的收敛速度。 基于概率的RRT算法 ","date":"2024-05-09","objectID":"/posts/rrt/:2:0","tags":["RRT"],"title":"RRT (Rapidly-Exploring Random Tree) 算法详解","uri":"/posts/rrt/"},{"categories":["AV","Robotics"],"content":"3、RRT Connect算法 RRT Connect算法从初始状态点和目标状态点同时扩展随机树从而实现对状态空间的快速搜索。 BP Network 图片来源:https://www.cs.cmu.edu/~motionplanning/lecture/lec20.pdf ","date":"2024-05-09","objectID":"/posts/rrt/:3:0","tags":["RRT"],"title":"RRT (Rapidly-Exploring Random Tree) 算法详解","uri":"/posts/rrt/"},{"categories":["AV","Robotics"],"content":"4、RRT*算法 RRT*算法的目标在于解决RRT算法难以求解最优的可行路径的问题，它在路径查找的过程中持续的优化路径，随着迭代次数和采样点的增加，得到的路径越来越优化。迭代的时间越久，就越可以得到相对满意的规划路径。 BP Network 图片来源：https://blog.csdn.net/gophae/article/details/103231053 RRT*算法与RRT算法的区别主要在于两点： rewrite的过程。即为 $x_{new}$ 重新选择父节点的过程； 随机树重布线的过程； ","date":"2024-05-09","objectID":"/posts/rrt/:4:0","tags":["RRT"],"title":"RRT (Rapidly-Exploring Random Tree) 算法详解","uri":"/posts/rrt/"},{"categories":["AV","Robotics"],"content":"4.1 Rewrite 下面我们看看Rewrite是如何实现的。RRT*在找到距离 $x_{rand}$ 最近的节点 $x_{nearest}$ 并通过CollisionFree检测之后，并不立即将 Edge(x_{nearest},x_{rand}) 加入扩展树中。 BP Network 图片来源：https://blog.csdn.net/weixin_43795921/article/details/88557317 而是以 $x_{rand}$ 为中心，$r$ 为半径，找到所有潜在的父节点集合，并与 $x_{nearest}$ 父节点的Cost对比，看是否存在更优Cost的父节点。 BP Network 图片来源：https://blog.csdn.net/weixin_43795921/article/details/88557317 如下图所示，我们会计算路径 $x_{init} \\rightarrow x_{parent} \\rightarrow x_{child}$ 的Cost=$cost1$，再计算 $x_{init} \\rightarrow x_{potential_parent} \\rightarrow x_{child}$ 的Cost=$cost2$，比较 $cost1$和 $cost2$ 的大小。此处由于 $x_{potential_parent}$ 与 $ {x_child} $ 之间存在障碍物导致二者的直接连线不可达，所以 $cost \u003e cost1$ ，不需改变 $ x_{child} $ 的父节点。 BP Network 图片来源：https://blog.csdn.net/weixin_43795921/article/details/88557317 如下图所示，当路径 ${x_{init} \\rightarrow x_{parent}-\u003ex_{child}} $的Cost大于 ${x_{init} \\rightarrow x_{potential_parent} \\rightarrow x_{child}}$的Cost时，RRT^*算法会将Edge${ x_{parent} \\rightarrow x_{child}}$剔 除 , 并 新 增 Edge${ x_{potential_parent} \\rightarrow x_{child}} $。 BP Network 图片来源：https://blog.csdn.net/weixin_43795921/article/details/88557317 至此我们就完成了一次Rewrite的过程，新生成的随机树如下。 BP Network 图片来源：https://blog.csdn.net/weixin_43795921/article/details/88557317 ","date":"2024-05-09","objectID":"/posts/rrt/:5:0","tags":["RRT"],"title":"RRT (Rapidly-Exploring Random Tree) 算法详解","uri":"/posts/rrt/"},{"categories":["AV","Robotics"],"content":"4.2 随机树重布线的过程 BP Network 图片来源：https://blog.csdn.net/weixin_43795921/article/details/88557317 在为 $x_{new}$ 重新选择父节点之后，重布线使得生成新节点后的随机树减少冗余通路，减小路径代价。 如上图所示，$x_{new}$ 为新生成的节点，4、6、8是 $x_{new}$ 的近邻节点，0、 4、 5分别为近邻节点的父节点。 路径{0-\u003e4}的Cost为: 10 路径{0-\u003e4-\u003e6}的Cost为： 10 + 5 = 15 路径{0-\u003e1-\u003e5-\u003e8}的Cost为: 3 + 5 + 1 = 9 先尝试将节点4的父节点改为 $x_{new}$，到达节点4的路径变为{0-\u003e1-\u003e5-\u003e9-\u003e4}，新路径的Cost=3+5+3+4=15，新路径的Cost大于原路径Cost，所以不改变节点4的父节点。 再尝试改变节点8的父节点为 $x_{new}$，到达节点8的路径变为{0-\u003e1-\u003e5-\u003e9-\u003e8},新路径的Cost=3+5+3+3=14，新路径的Cost大于原路径Cost，随意不改变节点8的父节点。 再尝试改变节点6的父节点为 $x_{new}$，到达路径6的路径变为{0-\u003e1-\u003e5-\u003e9-\u003e6},新的Cost=3+5+3+1=12,新路径的Cost小于原路径Cost，因此将节点6的父节点更新为节点9。 重布线后的随机树如上右图所示。 ","date":"2024-05-09","objectID":"/posts/rrt/:6:0","tags":["RRT"],"title":"RRT (Rapidly-Exploring Random Tree) 算法详解","uri":"/posts/rrt/"},{"categories":["AV","Robotics"],"content":"4.3 RRT*算法效果 从RRT与RRT的效果可以看出，RRT的路径规划的结果优于RRT算法。 BP Network RRT^* VS RRT。图片来源：https://www.cc.gatech.edu/~dellaert/11S-AI/Topics/Entries/2011/2/21_PRM,_RRT,_and_RRT__files/06-RRT.pdf BP Network RRT^* VS RRT With Obstacles。图片来源：https://www.cc.gatech.edu/~dellaert/11S-AI/Topics/Entries/2011/2/21_PRM,_RRT,_and_RRT__files/06-RRT.pdf RRT^*算法+赛车动力学实现车辆180度转弯。图片来源：https://www.youtube.com/watch?v=KSB_9KE6fWI ","date":"2024-05-09","objectID":"/posts/rrt/:7:0","tags":["RRT"],"title":"RRT (Rapidly-Exploring Random Tree) 算法详解","uri":"/posts/rrt/"},{"categories":["AV","Robotics"],"content":"参考链接 1、基于RRT的运动规划算法综述(https://wenku.baidu.com/view/8de40fafbdeb19e8b8f67c1cfad6195f312be80a.html) 2、RRT维基百科(https://en.wikipedia.org/wiki/Rapidly-exploring_random_tree) 3、PRM, RRT, and RRT*，Frank Dellaer (https://www.cc.gatech.edu/~dellaert/11S-AI/Topics/Entries/2011/2/21_PRM,_RRT,_and_RRT__files/06-RRT.pdf) 4、路径规划——改进RRT算法(https://zhuanlan.zhihu.com/p/51087819) 5、运动规划RRT*算法图解(https://blog.csdn.net/weixin_43795921/article/details/88557317) 6、全局路径规划：图搜索算法介绍4(RRT/RRT*)(https://blog.csdn.net/gophae/article/details/103231053) ref: [1]. https://zhuanlan.zhihu.com/p/133224593 [2]. https://blog.csdn.net/gophae/article/details/103231053 [3]. https://xwlu.github.io/wiki/path-planning/rrt/ [4]. ※ https://dlonng.com/posts/rrt ","date":"2024-05-09","objectID":"/posts/rrt/:8:0","tags":["RRT"],"title":"RRT (Rapidly-Exploring Random Tree) 算法详解","uri":"/posts/rrt/"},{"categories":["RL"],"content":"深度解读Soft Actor-Critic 算法 ","date":"2024-05-04","objectID":"/posts/sac/:0:0","tags":["SAC"],"title":"强化学习 | 深度解读Soft Actor-Critic 算法","uri":"/posts/sac/"},{"categories":["RL"],"content":"1 前言 机器人学习Robot Learning正在快速的发展，其中深度强化学习deep reinforcement learning（DRL），特别是面向连续控制continous control的DRL算法起着重要的作用。在这一领域中，目前可以说有三类行之有效的model free DRL算法： TRPO,PPO DDPG及其拓展（D4PG,TD3等） Soft Q-Learning, Soft Actor-Critic PPO 算法是目前最主流的DRL算法，同时面向离散控制和连续控制，在OpenAI Five上取得了巨大成功。但是PPO是一种on-policy的算法，也就是PPO面临着严重的sample inefficiency，需要巨量的采样才能学习，这对于真实的机器人训练来说，是无法接受的。 DDPG 及其拓展则是DeepMind开发的面向连续控制的off policy算法，相对PPO 更sample efficient。DDPG训练的是一种确定性策略deterministic policy，即每一个state下都只考虑最优的一个动作。DDPG的拓展版D4PG从paper中的结果看取得了非常好的效果，但是并没有开源，目前github上也没有人能够完全复现Deepmind的效果。 Soft Actor-Critic (SAC) 是面向Maximum Entropy Reinforcement learning 开发的一种off policy算法，和DDPG相比，Soft Actor-Critic使用的是随机策略stochastic policy，相比确定性策略具有一定的优势（具体后面分析）。Soft Actor-Critic在公开的benchmark中取得了非常好的效果，并且能直接应用到真实机器人上。最关键的是，Soft Actor-Critic是完全开源的，因此，深入理解Soft Actor-Critic 算法具有非常重要的意义，也是本篇blog的目的。 Soft Actor-Critic算法相关链接： Paper： Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor Soft Actor-Critic Algorithms and Applications Reinforcement Learning with Deep Energy-Based Policies (Soft Q-Learning) Codes: rail-berkeley/softlearning (原作者实现） vitchyr/rlkit openai/spinningup hill-a/stable-baselines 下面我们来详细解读一下SAC的算法及其具体实现。本文的阅读需要有基本的DRL算法基础知识。 ","date":"2024-05-04","objectID":"/posts/sac/:1:0","tags":["SAC"],"title":"强化学习 | 深度解读Soft Actor-Critic 算法","uri":"/posts/sac/"},{"categories":["RL"],"content":"2 为什么研究 Maximum Entropy Reinforcement Learning？ 对于一般的DRL，学习目标很直接，就是学习一个policy使得累加的reward期望值最大： $$\\pi^*=\\arg\\max_\\pi\\mathbb{E}_{(s_t,a_t)\\sim\\rho_\\pi}[\\sum_tR(s_t,a_t)]\\tag{1}$$ 而最大熵RL，除了上面的基本目标，还要求policy的每一次输出的action 熵entropy最大： $$\\pi^*=\\arg\\max_\\pi\\mathbb{E}_{(s_t,a_t)\\sim\\rho_\\pi}[\\sum_t\\underbrace{R(s_t,a_t)}_{reward}+\\alpha\\underbrace{H(\\pi(\\cdot|s_t))}_{entropy}]\\tag{2}$$ 这样做的基本目的是什么呢？让策略随机化，即输出的每一个action的概率尽可能分散，而不是集中在一个action上。不了解entropy的同学可以看这里：wiki-信息熵 我们知道DDPG训练得到的是一个deterministic policy确定性策略，也就是说这个策略对于一种状态state只考虑一个最优的动作。所以，stochastic policy相对deterministic policy有什么优势呢？ Stochastic policy随机策略在实际机器人控制上往往是更好的做法。比如我们让机器人抓取一个水杯，机器人是有无数条路径去实现这个过程的，而并不是只有唯一的一种做法。因此，我们就需要drl算法能够给出一个随机策略，在每一个state上都能输出每一种action的概率，比如有3个action都是最优的，概率一样都最大，那么我们就可以从这些action中随机选择一个做出action输出。最大熵maximum entropy的核心思想就是不遗落到任意一个有用的action，有用的trajectory。对比DDPG的deterministic policy的做法，看到一个好的就捡起来，差一点的就不要了，而最大熵是都要捡起来，都要考虑。 基于最大熵的RL算法有什么优势？ 以前用deterministic policy的算法，我们找到了一条最优路径，学习过程也就结束了。现在，我们还要求熵最大，就意味着神经网络需要去explore探索所有可能的最优路径，这可以产生以下多种优势： 1）学到policy可以作为更复杂具体任务的初始化。因为通过最大熵，policy不仅仅学到一种解决任务的方法，而是所有all。因此这样的policy就更有利于去学习新的任务。比如我们一开始是学走，然后之后要学朝某一个特定方向走。 2）更强的exploration能力，这是显而易见的，能够更容易的在多模态reward （multimodal reward）下找到更好的模式。比如既要求机器人走的好，又要求机器人节约能源 3）更robust鲁棒，更强的generalization。因为要从不同的方式来探索各种最优的可能性，也因此面对干扰的时候能够更容易做出调整。（干扰会是神经网络学习过程中看到的一种state，既然已经探索到了，学到了就可以更好的做出反应，继续获取高reward） 既然最大熵RL算法这么好，我们当然应该研究它了。而实际上，在之前的DRL算法A3C中，我们其实已经用了一下最大熵： BP Network 在训练policy的时候，A3C加了entropy项，作为一个regularizer，让policy更随机。不过A3C这么做主要是为了更好做exploration，整体的训练目标依然只考虑reward。这和Soft Actor-Critic的设定还是不一样的，Soft Actor-Critic是真正最大熵DRL算法。 ","date":"2024-05-04","objectID":"/posts/sac/:2:0","tags":["SAC"],"title":"强化学习 | 深度解读Soft Actor-Critic 算法","uri":"/posts/sac/"},{"categories":["RL"],"content":"3 Maximum Entropy Reinforcement Learning的Bellman方程 我们先回顾一下dynamic programming中Bellman backup equation，参考http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/MDP.pdf BP Network $$q_\\pi(s,a)=r(s,a)+\\gamma\\sum_{s^{\\prime}\\in\\mathcal{S}}\\mathcal{P}_{ss^{\\prime}}^a\\sum_{a^{\\prime}\\in\\mathcal{A}}\\pi(a^{\\prime}|s^{\\prime})q_\\pi(s^{\\prime},a^{\\prime})\\tag{3}$$ 那么对于最大熵（MaxEnt)的目标，其实可以把熵也作为reward的一部分，我们在计算q值时（记住q是累加reward的期望，传统rl的目标等价于让q最大），就需要计算每一个state的熵entropy (entropy的公式如下图所示）： BP Network BP Network 因此我们就可以得到Soft Bellman Backup equation (Entropy项)额外乘上 $\\alpha$ 系数： $$q_\\pi(s,a)=r(s,a)+\\gamma\\sum_{s^{\\prime}\\in\\mathcal{S}}\\mathcal{P}_{ss^{\\prime}}^a\\sum_{a^{\\prime}\\in\\mathcal{A}}\\pi(a^{\\prime}|s^{\\prime})(q_\\pi(s^{\\prime},a^{\\prime})-\\alpha\\log(\\pi(a^{\\prime}|s^{\\prime}))\\quad(4)$$ Recall一下Dynamic Programming Backup： BP Network 对应Q值的公式是 $$Q(s_t,a_t)=r(s_t,a_t)+\\gamma\\mathbb{E}_{s_{t+1},a_{t+1}}[Q(s_{t+1},a_{t+1})]\\tag{5}$$ 根据公式（4），我们可以得到Soft Bellman Backup的 更新公式： $$Q_{soft}(s_t,a_t)=r(s_t,a_t)+\\gamma\\mathbb{E}_{s_{t+1},a_{t+1}}[Q_{soft}(s_{t+1},a_{t+1})-\\alpha\\log(\\pi(a_{t+1}|s_{t+1}))]\\tag{6}$$ 上面公式（6）是直接使用dynamic programming，将entropy嵌入计算得到的结果。我们可以反过来先直接把entropy作为reward的一部分： $$r_{soft}(s_t,a_t)=r(s_t,a_t)+\\gamma\\alpha\\mathbb{E}_{s_{t+1}\\sim\\rho}H(\\pi(\\cdot|s_{t+1}))\\tag{7}$$ 我们将（7）带入到公式（5）： $$\\begin{aligned} {Q_{soft}(s_{t},a_{t})} \u0026=r(s_t,a_t)+\\gamma\\alpha\\mathbb{E}_{s_{t+1}\\sim\\rho}H(\\pi(\\cdot|s_{t+1}))+\\gamma\\mathbb{E}_{s_{t+1},a_{t+1}}[Q_{soft}(s_{t+1},a_{t+1})]\\\\ \u0026=r(s_t,a_t)+\\gamma\\mathbb{E}_{s_{t+1}\\sim\\rho,a_{t+1}\\sim\\pi}[Q_{soft}(s_{t+1},a_{t+1})]+\\gamma\\alpha\\mathbb{E}_{s_{t+1}\\sim\\rho}H(\\pi(\\cdot|s_{t+1}))\\\\ \u0026=r(s_t,a_t)+\\gamma\\mathbb{E}_{s_{t+1}\\sim\\rho,a_{t+1}\\sim\\pi}[Q_{soft}(s_{t+1},a_{t+1})]+\\gamma\\mathbb{E}_{s_{t+1}\\sim\\rho}\\mathbb{E}_{a_{t+1}\\sim\\pi}[-\\alpha\\log\\pi(a_{t+1}|s_{t+1})]\\\\ \u0026=r(s_t,a_t)+\\gamma\\mathbb{E}_{s_{t+1}\\sim\\rho}[\\mathbb{E}_{a_{t+1}\\sim\\pi}[Q_{soft}(s_{t+1},a_{t+1})-\\alpha\\log(\\pi(a_{t+1}|s_{t+1}))]]\\\\\u0026=r(s_t,a_t)+\\gamma\\mathbb{E}_{s_{t+1},a_{t+1}}[Q_{soft}(s_{t+1},a_{t+1})-\\alpha\\log(\\pi(a_{t+1}|s_{t+1}))]\\end{aligned}$$ 可以得到一样的结果。 与此同时，我们知道: $$Q(s_t,a_t)=r(s_t,a_t)+\\gamma\\mathbb{E}_{s_{t+1}\\sim\\rho}[V(s_{t+1})]\\tag{9}$$ 因此，我们有： $$V_{soft}(s_t)=\\mathbb{E}_{a_t\\sim\\pi}[Q_{soft}(s_t,a_t)-\\alpha\\log\\pi(a_t|s_t)]\\tag{10}$$ 至此我们理清楚了SAC paper原文中的公式(2)和(3)： BP Network BP Network 并且（7）的做法直接证明了Lemma 1 Soft Policy Evaluation (这个lemma为下一部分的soft policy iteration提供支撑）: BP Network 但是，我们注意到上面的整个推导过程都是围绕maximum entropy，和soft 好像没有什么直接关系。所以， 为什么称为soft？哪里soft了？以及为什么soft Q function能够实现maximum entropy？ 理解清楚这个问题是理解明白soft q-learning及sac的关键！ SAC这篇paper直接跳过了soft Q-function的定义问题，因此，要搞清楚上面的问题，我们从Soft Q-Learning的paper来寻找答案。 参考Learning Diverse Skills via Maximum Entropy Deep Reinforcement Learning BP Network 上面的曲线很明显的说明了stochastic policy的重要性，面对多模的（multimodal）的Q function，传统的RL只能收敛到一个选择（左图），而更优的办法是右图，让policy也直接符合Q的分布。这里，最直接的一种办法就是定义这样的energy-based policy： \\pi(a_t|s_t)\\propto exp(-\\mathcal{E}(s_t,a_t)) （11） 其中 \\mathcal{E} 是能量函数，上面的形式就是Boltzmann Distribution 玻尔兹曼分布 。下图的 -f(x)=\\mathcal{E} BP Network https://deepgenerativemodels.github.io/assets/slides/cs236_lecture13.pdf 为了连接soft Q function，我们可以设定 $$\\mathcal{E}(s_t,a_t)=-\\frac{1}{\\alpha}Q_{soft}(s_t,a_t)\\tag{12}$$ 因此，我们有 $$\\pi(a_t|s_t)\\propto exp(Q_{soft}(s_t,a_t))\\tag{13}$$ 这样的policy能够为每一个action赋值一个特定的概率符合Q值的分布，也就满足了stochastic policy的需求。 下面我们要发现(13)的形式正好就是最大熵RL的optimal policy最优策略的形式，而这实现了soft q function和maximum entropy的连接。 BP Network 实际上我们理解Soft Q-Learning及Soft Actor Critic，要清楚上图三者的关系。在Soft Q-Learning那篇paper中，他是从Soft Value Function的定义出发去连接Energy-Based Policy 和Maximum Entropy Objective的关系。而在本blog中，我们从Maximum Entropy Objective出发，来连接其他两部分。 前面我们已经推导得到了公式（10），那么根据公式（10），我们可以直接推导得到policy的形式： $$\\begin{aligned}\\pi(s_{t},a_{t})\u0026=\\exp(\\frac1\\alpha(Q_{soft}(s_t,a_t)-V_{soft}(s_t)))\\\\\u0026\u0026\\text{(14)}\\\\\u0026=\\frac{\\exp(\\frac1\\alpha Q_{soft}(s_t,a_t))}{\\exp(\\frac1\\alpha V_{soft}(s_t))}\\end{aligned}$$ （14）符合了（13）， $\\frac{1}{\\alpha}V_{soft}(s_t)$ 可以看做是对应的log partition function. 由此，就连接了Maximum En","date":"2024-05-04","objectID":"/posts/sac/:3:0","tags":["SAC"],"title":"强化学习 | 深度解读Soft Actor-Critic 算法","uri":"/posts/sac/"},{"categories":["RL"],"content":"4 Policy Iteration 理清楚了上面的基本定义和联系，我们就可以研究怎么更新policy了，也就是policy iteration。 回顾一下一般的Policy Iteration： BP Network 在两步中进行循环迭代（我们直接使用Q值来说明）： Policy evaluation：固定policy，使用Bellman方程更新Q值直到收敛： $$Q_\\pi(s,a)=r(s,a)+\\lambda\\mathbb{E}_{s^{\\prime},a^{\\prime}}Q_\\pi(s^{\\prime},a^{\\prime})\\tag{20}$$ Policy improvement: 更新policy： $$\\pi^{\\prime}(s)=\\arg\\max_aQ_\\pi(s,a)\\tag{21}$$ 基于同样的方法，我们有Soft Policy Iteration： Soft policy evaluation:固定policy，使用Bellman方程更新Q值直到收敛: $$\\begin{aligned}\u0026Q_{soft}^\\pi(s_t,a_t)=r(s_t,a_t)+\\lambda\\mathbb{E}_{s_{t+1},a_{t+1}}\\left[Q_{soft}^\\pi(s_{t+1},a_{t+1})-\\alpha\\log(\\pi(a_{t+1}|s_{t+1}))\\right]\\tag{22}\\end{aligned}$$ Soft policy improvement: 更新policy： $$\\pi^{\\prime}=\\arg\\min_{\\pi_k\\in\\Pi}D_{KL}(\\pi_k(\\cdot|s_t)||\\frac{\\exp(\\frac{1}{\\alpha}Q_{soft}^{\\pi}(s_t,\\cdot))}{Z_{soft}^{\\pi}(s_t)}) \\tag{23}$$ (22)基于上一部分说的Lemma 1 Soft Policy Evaluation, 可收敛。 (23)则基于上一部分的Theorem 4 Policy Improvement Theorem。只是这里的做法不是直接赋值，而是通过KL divergence来趋近 $\\exp(Q^{\\pi}_{soft}(s_t,\\cdot))$ 。在SAC的paper原文中，我们可以看到这么做的原因是为了限制policy在一定范围的policies $\\Pi$ 中从而tractable，policy的分布可以是高斯分布。 BP Network 同样的，作者也专门证明了采用KL divergence的方法一样能够保证policy improvement，也就是Lemma 2： BP Network 最后，就是证明上面的Soft Policy Iteration过程能保证policy收敛到最优，即Theorem 1： BP Network 由此，基本的理论建设也就结束了，下面进入Soft Actor-Critic的算法设计。 ","date":"2024-05-04","objectID":"/posts/sac/:4:0","tags":["SAC"],"title":"强化学习 | 深度解读Soft Actor-Critic 算法","uri":"/posts/sac/"},{"categories":["RL"],"content":"5 Soft Actor-Critic SAC算法的构建首先是神经网络化，我们用神经网络来表示Q和Policy： $Q_{\\theta}(s_t,a_t)$ 和 $\\pi_{\\phi}(a_t|s_t)$ 。Q网络比较简单，几层的MLP最后输出一个单值表示Q就可以了，Policy网络需要输出一个分布，一般是输出一个Gaussian 包含mean和covariance。下面就是构建神经网络的更新公式。 对于Q网络的更新，我们根据（10）可以得到： $$\\begin{aligned} J_{Q}(\\theta)\u0026 =\\mathbb{E}_{(s_t,a_t,s_{t+1})\\sim\\mathcal{D}}[\\frac{1}{2}(Q_\\theta(s_t,a_t)-(r(s_t,a_t)+\\gamma V_{\\bar{\\theta}}(s_{t+1})))^2] \\\\ \u0026=\\mathbb{E}_{(s_t,a_t,s_{t+1})\\sim\\mathcal{D},a_{t+1}\\sim\\pi_\\phi}[\\frac12(Q_\\theta(s_t,a_t)-(r(s_t,a_t)+\\gamma(Q_{\\bar{\\theta}}(s_{t+1},a_{t+1})-\\alpha\\log(\\pi_\\phi(a_{t+1}|s_{t+1})))))^2] \\tag{24} \\end{aligned}$$ 这里和DDPG一样，构造了一个target soft Q 网络带参数 $\\overline{\\theta}$ ，这个参数通过exponentially moving average Q网络的参数 $\\theta$ 得到。(ps:在第一个版本的SAC中，他们单独定义了V网络进行更新，说是更稳定，到新版的SAC中，由于自动更新temperature $\\alpha$ 就直接使用Q网络更新） 对于Policy 网络参数的更新，就是最小化KL divergence： $$\\begin{aligned} J_{\\pi}(\\phi)\u0026 =D_{\\mathrm{KL}}\\left(\\pi_\\phi(.\\left|s_t\\right)|\\exp(\\frac1\\alpha Q_\\theta(s_t,.)-\\log Z(s_t))\\right) \\\\ \u0026=\\mathbb{E}_{s_t\\sim\\mathcal{D},a_t\\sim\\pi_\\phi}\\Big[\\log\\big(\\frac{\\pi_\\phi(a_t|s_t)}{\\exp(\\frac{1}{\\alpha}Q_\\theta(s_t,a_t)-\\log Z(s_t))}\\big)\\Big] \\\\ \u0026=\\mathbb{E}_{s_t\\sim\\mathcal{D},a_t\\sim\\pi_\\phi}[\\log\\pi_\\phi(a_t|s_t)-\\frac1\\alpha Q_\\theta(s_t,a_t)+\\log Z(s_t)] \\tag{25} \\end{aligned}$$ 这里的action我们采用reparameterization trick来得到，即 $$a_t=f_\\phi(\\varepsilon_t;s_t)=f_\\phi^\\mu(s_t)+\\varepsilon_t\\odot f_\\phi^\\sigma(s_t)\\tag{26}$$ f函数输出平均值和方差，然后 $\\varepsilon$ 是noise，从标准正态分布采样。使用这个trick，整个过程就是完全可微的(loss 乘以 $\\alpha$ 并去掉不影响梯度的常量log partition function Z(s_t)) ： $$J_\\pi(\\phi)=\\mathbb{E}_{s_t\\sim\\mathcal{D},\\varepsilon\\sim\\mathcal{N}}[\\alpha\\log\\pi_\\phi(f_\\phi(\\varepsilon_t;s_t)|s_t)-Q_\\theta(s_t,f_\\phi(\\varepsilon_t;s_t))] \\tag{27}$$ 这样基本的Soft Actor-Critic的更新方法也就得到了。 ","date":"2024-05-04","objectID":"/posts/sac/:5:0","tags":["SAC"],"title":"强化学习 | 深度解读Soft Actor-Critic 算法","uri":"/posts/sac/"},{"categories":["RL"],"content":"6 Temperature Hyperparameter Auto-Adjustment 前面的SAC中，我们只是人为给定一个固定的temperature $\\alpha$ 作为entropy的权重，但实际上由于reward的不断变化，采用固定的temperature并不合理，会让整个训练不稳定，因此，有必要能够自动调节这个temperature。当policy探索到新的区域时，最优的action还不清楚，应该调整temperature $\\alpha$ 去探索更多的空间。当某一个区域已经探索得差不多，最优的action基本确定了，那么这个temperature就可以减小。 这里，SAC的作者构造了一个带约束的优化问题，让平均的entropy权重是有限制的，但是在不同的state下entropy的权重是可变的，即 $$\\max_{\\pi_0,\\ldots,\\pi_T}\\mathbb{E}\\bigg[\\sum_{t=0}^Tr(s_t,a_t)\\bigg]\\mathrm{s.t.~}\\forall t, \\mathcal{H}(\\pi_t)\\geq\\mathcal{H}_0\\tag{28}$$ 对于这部分内容，Policy Gradient Algorithms 这个openai小姐姐的blog介绍得极其清楚，大家可以参考，最后得到temperature的loss： $$J(\\alpha)=\\mathbb{E}_{a_t\\sim\\pi_t}[-\\alpha\\log\\pi_t(a_t\\mid\\pi_t)-\\alpha\\mathcal{H}_0]\\tag{29}$$ 由此，我们可以得到完整的Soft Actor-Critic算法： BP Network 为了更快速稳定的训练，作者引入了两个Q网络，然后每次选择Q值小的一个作为target Q值。更新Q，Policy及 \\alpha 使用上文的（24）（27）（29）三个公式。 ","date":"2024-05-04","objectID":"/posts/sac/:6:0","tags":["SAC"],"title":"强化学习 | 深度解读Soft Actor-Critic 算法","uri":"/posts/sac/"},{"categories":["RL"],"content":"7 神经网络结构 虽然上面把算法流程确定了，但是如何构造policy的神经网络还是比较复杂的。下图是带V网络的神经网络结构图： BP Network https://nervanasystems.github.io/coach/components/agents/policy_optimization/sac.html 我们主要来探究一下Policy网络的设计。 见上图右上角的Policy网络，前面的input embedder和Middleware不用说，就是几层的MLP。然后，接下来神经网络分成两个分支，分别输出平均值mean $\\mu$ 和log 标准差 log std 。然后使用exp得到std。 $$\\pi_\\phi(s_t) = \\mu_t,\\log \\sigma_t \\tag{30}$$ $$\\sigma_t = \\exp(\\log \\sigma_t)$$ 正常输出这样的高斯分布作为action 的分布distribution是OK的，但是在实际中，这个action需要限定在一定范围内。因此，这里作者使用了squashing function tanh，将action限制在（-1,1）之间，即 $$\\mathbf{u}_t =\\mu_t + \\varepsilon_t \\odot \\sigma_t $$ $$a_t = \\tanh (\\mathbf{u}) \\tag{31}$$ 这里和上文的公式（26）对应，多了一个tanh。 那么这会导致分布的变化，从而影响log likelihood的计算，而这是我们计算SAC的loss必须的。作者在paper中给出了计算方法如下： $$\\log \\pi(a|s)=\\log \\mu(\\mathbf{u}|s)-\\sum_{i=1}^{D}{\\log(1-\\tanh^2(u_i))} \\tag{32}$$ 其中 u_i 是 $\\mathbf{u}$ 的第i个元素。这里的 $\\mu(\\mathbf{u}|s)$ 是没有加限制时的likelihood function也就是高斯分布的likelihood function似然函数。高斯分布的log likelihood直接使用pytorch的Normal class就可以获得。 ","date":"2024-05-04","objectID":"/posts/sac/:7:0","tags":["SAC"],"title":"强化学习 | 深度解读Soft Actor-Critic 算法","uri":"/posts/sac/"},{"categories":["RL"],"content":"8 其他细节 1）SAC里的target entropy 设计为 $$\\mathcal{H}_0 = -\\dim (\\mathcal{A}) \\tag{33}$$ 即-动作数量。 2）SAC paper里完全没有说明的训练时的episode设置。SAC设置为每一个episode采样1000次然后训练1000次。 3）在代码中SAC使用 log alpha作为更新的参数，而不是直接使用alpha如公式（25），这和输出log std是一样的，使用log有很大的正负范围，更方便网络输出。否则alpha或者std都是正值。 4）SAC有一个很大的问题，它的policy的目的是趋近于玻尔兹曼分布，但是实际实现的时候，为了能够tractable，选择了输出一个高斯，也就是让高斯趋近于玻尔兹曼分布。这意味着SAC本质上还是unimodal的算法，而不是soft q-learning的multi-modal。这使得SAC的创新性打了很大的折扣。但是算法效果确实还是不错的。 ","date":"2024-05-04","objectID":"/posts/sac/:8:0","tags":["SAC"],"title":"强化学习 | 深度解读Soft Actor-Critic 算法","uri":"/posts/sac/"},{"categories":["RL"],"content":"9 小结 本文从理论到具体实现层面剖析了Soft Actor-Critic这一目前极强的DRL算法，基本上理解了本文的分析，对于代码的实现也就可以了然一胸了。 由于本人水平有限，前面的理论分析恐有错误，望批评指正！ ref: [1]. https://zhuanlan.zhihu.com/p/70360272 ","date":"2024-05-04","objectID":"/posts/sac/:9:0","tags":["SAC"],"title":"强化学习 | 深度解读Soft Actor-Critic 算法","uri":"/posts/sac/"},{"categories":["LLM"],"content":"0. 引言 BP Network 最近火出圈的🚀 ChatGPT 中 RLHF 主要采用了就是 PPO 进行强化学习训练 主要运用在微调阶段（微调整个 10B～100B+ 参数的成本其实也非常高 ）使用策略梯度强化学习 (Policy Gradient RL) 算法、近端策略优化 (PPO) 微调初始 LM 的部分或全部参数。 BP Network 以下主要参考台大李宏毅的推导过程 ","date":"2024-05-04","objectID":"/posts/chatgpt_rlhf/:1:0","tags":["RLHF","ChatGPT"],"title":"一文详解 ChatGPT RLHF 背后的 PPO 强化学习训练","uri":"/posts/chatgpt_rlhf/"},{"categories":["LLM"],"content":"01. Vanilla policy gradient 动作/环境/奖励之间的关系： BP Network 轨迹可表示为集合 $$\\begin{aligned}p_{\\theta}(\\tau)\u0026=p(s_1)p_\\theta(a_1|s_1)p(s_2|s_1,a_1)p_\\theta(a_1|s_1)p(s_3|s_2,a_2)\\ldots\\\\\u0026=p(s_1)\\prod_{t=1}^Tp_\\theta(a_t|s_t)p(s_{t+1}|s_t,a_t)\\end{aligned}$$ BP Network 一个轨迹的奖励总和为： $$R(\\tau)=\\sum_{t=1}^Tr_t$$ 则奖励的期望为： $$\\bar{R}_\\theta=\\sum_\\tau R(\\tau)p_\\theta(\\tau)=E_{\\tau\\sim p_\\theta(\\tau)}[R(\\tau)]$$ 将 $R(\\tau)$ 看成常量，对其求微分： $$\\begin{aligned} \\nabla\\bar{R}_{\\theta}\u0026 =\\sum_{\\tau}R(\\tau)\\nabla p_{\\theta}(\\tau) \\\\ \u0026=\\sum_{\\tau}R(\\tau)p_{\\theta}(\\tau)\\frac{\\nabla p_{\\theta}(\\tau)}{p_{\\theta}(\\tau)} \\\\ \u0026=\\sum_{\\tau}R(\\tau)p_{\\theta}(\\tau)\\nabla\\log p_{\\theta}(\\tau)\\quad\\nabla f(x)=f(x)\\nabla\\log f(x) \\\\ \u0026=E_{\\tau\\sim p_{\\theta}(\\tau)}[R(\\tau)\\nabla\\log p_{\\theta}(\\tau)]\u0026 \\left(2\\right) \\\\ \u0026\\approx\\frac1N\\sum_{n=1}^{N}R(\\tau^{n})\\nabla\\log p_{\\theta}(\\tau^{n}) \\\\ \u0026=\\frac1N\\sum_{n=1}^N\\sum_{t=1}^{T_n}R(\\tau^n)\\nabla\\log p_\\theta(a_t^n|s_t^n) \\end{aligned}$$ 策略网络梯度更新： BP Network 可以看成一个分类问题（游戏中通过键盘输入来互动，分类类别为所有可操作的键位）： BP Network 理想情况下， 并不一直为正数，增加一个 baseline: $$\\nabla\\bar{R}_{\\theta}=\\frac{1}{N}\\sum_{n=1}^{N}\\sum_{t=1}^{{T_{n}}}(R(\\tau^{n})-b)\\nabla\\log p_{\\theta}(a_{t}^{n}|s_{t}^{n})b\\approx E[R(\\tau)]$$ 在电子游戏中，奖励值常常为正（通常为游戏分数）。这时需要增加一个偏置来保证同时有正样本和负样本 分配合适的学分 一个高分的游戏轨迹中也可能存在错误的动作，同样的，一个低分的游戏轨迹也可能存在正确的动作，而上文中的计算将最后的奖励值（最后的游戏分数）都一视同仁视为该游戏轨迹每个动作的学分。 为了更准确地描述每个动作所得到的学分，将一个动作执行后对应的学分为后续的所有奖励值的总和 BP Network $$\\begin{aligned} \\nabla\\bar{R}_\\theta\u0026 =\\frac1N\\sum_{n=1}^N\\sum_{t=1}^{T_n}(R(\\tau^n)-b)\\nabla\\log p_\\theta(a_t^n|s_t^n) \\Downarrow\\nabla\\bar{R}_\\theta \\\\ \u0026= \\frac1N\\sum_{n=1}^N\\sum_{t=1}^{T_n}(\\sum_{t^{\\prime}=t}^{T_n}r_{t^{\\prime}}^n-b)\\nabla\\log p_\\theta(a_t^n|s_t^n) \\end{aligned}$$ 当某个动作执行以后，其对后续的奖励分数的影响在慢慢减少，再增加一个衰减因子： $$\\begin{aligned} \\nabla\\bar{R}_\\theta\u0026 =\\frac1N\\sum_{n=1}^N\\sum_{t=1}^{T_n}(\\sum_{t^{\\prime}=t}^{T_n}r_{t^{\\prime}}^n)\\nabla\\log p_\\theta(a_t^n|s_t^n)\\Downarrow\\nabla\\bar{R}_\\theta \\\\ \u0026 = \\frac{1}{N}\\sum_{n=1}^{N}\\sum_{t=1}^{T_{n}}(\\sum_{t^{\\prime}=t}^{T_{n}}\\gamma^{t^{\\prime}-t}r_{t^{\\prime}}^{n}-b)\\nabla\\log p_{\\theta}(a_{t}^{n}|s_{t}^{n}),\\gamma\u003c1 \\end{aligned}$$ ","date":"2024-05-04","objectID":"/posts/chatgpt_rlhf/:2:0","tags":["RLHF","ChatGPT"],"title":"一文详解 ChatGPT RLHF 背后的 PPO 强化学习训练","uri":"/posts/chatgpt_rlhf/"},{"categories":["LLM"],"content":"02. 从on-policy到off-policy 两者区别: On-policy: 学习到的 agent 和与环境交互的 agent 是相同的，每一次梯度更新都需要重新采样 Off-policy: 学习到的 agent 和与环境交互的 agent 是不同的，每次梯度更新不需要重新采样 重新看看 的表达式： $$\\nabla\\bar{R}_\\theta=E_{\\tau\\sim p_\\theta(\\tau)}[R(\\tau)\\nabla\\log p_\\theta(\\tau)]$$ 使用策略网络 收集数据。当 更新后，则需要重新收集训练样本 目标：使用相同的样本（通过 采样）训练 。其中 为固定的，因此我们可以重复使用其样本数据 ","date":"2024-05-04","objectID":"/posts/chatgpt_rlhf/:3:0","tags":["RLHF","ChatGPT"],"title":"一文详解 ChatGPT RLHF 背后的 PPO 强化学习训练","uri":"/posts/chatgpt_rlhf/"},{"categories":["LLM"],"content":"2.1 重要性采样（Importance Sampling） 考虑一个场景，假如正在尝试计算函数 $f(x)$ 的期望值，其中 $x \\sim f(x)$ 服从某种分布。则对 $E(f(x))$ 有以下估计： $$E_{x\\sim p}[f(x)]=\\int f(x)p(x)dx\\approx\\frac{1}{n}\\sum_{i}f(x_{i})$$ 蒙特卡洛抽样方法是简单地从分布 $p(x)$ 中抽出 ，然后取所有样本的平均值来得到期望值的估计。那么问题来了，如果 $p(x)$ 非常难取样怎么办？是否能够根据一些已知的、容易抽样的分布来估计期望值？ 答案是肯定的。公式的一个简单转换就可以做到 $$E_{x\\sim p}[f(x)]=\\int f(x)p(x)dx=\\int f(x)\\frac{p(x)}{q(x)}q(x)dx=E_{x\\sim q}[f(x)\\frac{p(x)}{q(x)}]$$ 其中$x$从分布$q(x)$中采样，$q(x)$不应为 0。通过这种方式，估计期望能够从另一个分布$q(x)$中采样，$p(x)/q(x)$是称为采样率或采样权重，它作为校正权重以抵消来自不同分布的概率采样。 重要性采样的缺陷 虽然重要性采样保证了期望的一致，但是这里来计算一下方差是否一致 方差的计算： $$Var[X]=E[X^2]-(E[X])^2$$ 分别计算方差： $$\\begin{aligned}Var_{x\\sim p}[f(x)]\u0026=E_{x\\sim p}[f(x)^2]-(E_{x\\sim p}[f(x)])^2\\\\Var_{x\\sim q}[f(x)\\frac{p(x)}{q(x)}]\u0026=E_{x\\sim q}[(f(x)\\frac{p(x)}{q(x)})^2]-(E_{x\\sim q}[f(x)\\frac{p(x)}{q(x)}])^2\\\\\u0026=E_{x\\sim p}[f(x)^2\\frac{p(x)}{q(x)}]-(E_{x\\sim p}[f(x)])^2\\end{aligned}$$ 可以发现两者虽然期望相等但方差并不一致 ","date":"2024-05-04","objectID":"/posts/chatgpt_rlhf/:3:1","tags":["RLHF","ChatGPT"],"title":"一文详解 ChatGPT RLHF 背后的 PPO 强化学习训练","uri":"/posts/chatgpt_rlhf/"},{"categories":["LLM"],"content":"2.2 从 on-policy 到 off-policy 我们使用重要性采样将 on-policy 调整为 off-policy $$\\nabla\\bar{R}_\\theta=E_{\\tau\\sim p_{\\theta^{\\prime}}(\\tau)}[\\frac{p_\\theta(\\tau)}{p_{\\theta^{\\prime}}(\\tau)}R(\\tau)\\nabla\\log p_\\theta(\\tau)]$$ 从 $\\theta’$ 采样得到数据集 使用该 数据集多次训练 $\\theta$ 梯度更新过程： $$\\begin{aligned} \u0026=E_{(s_t,a_t)\\sim\\pi_\\theta}[A^\\theta(s_t,a_t)\\nabla\\log p_\\theta(a_t^n|s_t^n)] \\\\ \u0026=E_{(s_t,a_t)\\sim\\pi_{\\theta^{\\prime}}}[\\frac{p_\\theta(s_t,a_t)}{p_{\\theta^{\\prime}}(s_t,a_t)}A^{\\theta^{\\prime}}(s_t,a_t)\\nabla\\log p_\\theta(a_t^n|s_t^n)] \\\\ \u0026=E_{(s_t,a_t)\\sim\\pi_{\\theta^{\\prime}}}[\\frac{p_\\theta(a_t|s_t)}{p_{\\theta^{\\prime}}(a_t|s_t)}\\frac{p_\\theta(s_t)}{p_{\\theta^{\\prime}}(s_t)}A^{\\theta^{\\prime}}(s_t,a_t)\\nabla\\log p_\\theta(a_t^n|s_t^n)]\u0026 \\text{(4)} \\\\ \u0026=E_{(s_t,a_t)\\sim\\pi_{\\theta^{\\prime}}}[\\frac{p_\\theta(a_t|s_t)}{p_{\\theta^{\\prime}}(a_t|s_t)}A^{\\theta^{\\prime}}(s_t,a_t)\\nabla\\log p_\\theta(a_t^n|s_t^n)] \\end{aligned}$$ 其中 $A^\\theta(s_t,a_t)$ 指的是 advantage 函数,其计算方式为加上衰减机制后的奖励值并减去基线。 由于 $\\frac{p_\\theta(s_t)}{p_{\\theta’}(s_t)}$ 的值难以计算，将其设置为 1，简化计算 目标函数可以表示为： 由于 $\\nabla f(x)=f(x)\\nabla\\log f(x)$ 再结合不定积分，目标函数可以表示为: $$J^{\\theta’}(\\theta)=E_{(s_t,a_t)\\sim\\pi_{\\theta’}}[\\frac{p_\\theta(a_t|s_t)}{p_{\\theta’}(a_t|s_t)}A^{\\theta’}(s_t,a_t)]$$ ","date":"2024-05-04","objectID":"/posts/chatgpt_rlhf/:3:2","tags":["RLHF","ChatGPT"],"title":"一文详解 ChatGPT RLHF 背后的 PPO 强化学习训练","uri":"/posts/chatgpt_rlhf/"},{"categories":["LLM"],"content":"03. PPO/TRPO 为了消除重要性采样的缺陷的影响，以下为两种方式 PPO（Proximal Policy Optimization） 初始化策 略网络参数 在每次迭代过程中: 目标函数: 使用 与环境互动以收集 ，并计算出 advantage 值 更新 优化 算法: $$\\begin{aligned} PPO algorithm: \\\\ J_{PPO}^{\\theta^k}(\\theta) \u0026 = J^{\\theta^k}(\\theta)-\\beta KL(\\theta,\\theta^k)J^{\\theta^k}(\\theta) \\\\ \u0026 = E_{(s_{t},a_{t})\\sim\\pi_{\\theta^{k}}}[\\frac{p_{\\theta}(a_{t}|s_{t})}{p_{\\theta^{k}}(a_{t}|s_{t})}A^{\\theta^{k}}(s_{t},a_{t})] \\\\ \u0026 \\approx \\sum_{(s_{t},a_{t})}\\frac{p_{\\theta}(a_{t}|s_{t})}{p_{\\theta^{k}}(a_{t}|s_{t})}A^{\\theta^{k}}(s_{t},a_{t}) \\end{aligned}$$ 自适应 KL 惩罚：如果 $KL(\\theta,\\theta^k)\u003eKL_{\\max}$ ,增大 $\\beta$; 如果 $KL(\\theta,\\theta^k) \u003cKL_{\\min}$,减小 $\\beta$。 BP Network TRPO（Trust Region Policy Optimizatio） $$J_{TRPO}^{\\theta’}(\\theta)=E_{(s_t,a_t)\\sim\\pi_{\\theta’}}[\\frac{p_\\theta(a_t|s_t)}{p_{\\theta’}(a_t|s_t)}A^{\\theta’}(s_t,a_t)]KL(\\theta,\\theta’)\u003c\\delta $$ TRPO 和 PPO 在各个测试上性能差不多。但相比 PPO ，TRPO 计算要更复杂 参考文献: [1] https://spinningup.openai.com/en/latest/algorithms/ppo.html [2] https://openai.com/research/openai-baselines-ppo [3] https://huggingface.co/blog/deep-rl-ppo [4] https://huggingface.co/blog/rlhf [5] https://mp.weixin.qq.com/s/zhkNDNDEJV3BEdcgeuHkOA ","date":"2024-05-04","objectID":"/posts/chatgpt_rlhf/:4:0","tags":["RLHF","ChatGPT"],"title":"一文详解 ChatGPT RLHF 背后的 PPO 强化学习训练","uri":"/posts/chatgpt_rlhf/"},{"categories":["LLM"],"content":"0. 引言 在ChatGPT引领的大型语言模型时代，国内外的大模型呈现爆发式发展，尤其是以年初的LLaMA模型为首的开源大模型和最近百川智能的baichuan模型，但无一例外，都使用了「基于人类反馈的强化学习」（RLHF）来提升语言模型的性能，并在模型重注入了人类的偏好，以提高模型的有用性和安全性。不过RLHF也早已更新换代，我们以如下目录进行详细讲述RLHF及其变种： LLM的经典预训练Pipeline Llama 2中的RLHF RLHF替代方案 ","date":"2024-05-04","objectID":"/posts/pretrain_rlhf_one/:1:0","tags":["RLHF"],"title":"LLM预训练之RLHF（一）：RLHF及其变种","uri":"/posts/pretrain_rlhf_one/"},{"categories":["LLM"],"content":"一、LLM的经典预训练Pipeline ​ 目前基于Transformer decoder的LLM，比如ChatGPT、LLaMA、baichuan等，通常都会有基于预训练的base模型和在base模型至少使用RLHF微调的Chat模型，Chat模型的训练一般都包括如下三个步骤：预训练，有监督微调和对齐。 ​ 在预训练阶段，模型会从大量无标注文本数据集中学习通用知识，然后使用「有监督微调」（SFT）优化模型以更好地遵守特定指令，最后使用对齐技术使LLM可以更有用且更安全地响应用户提示。 ","date":"2024-05-04","objectID":"/posts/pretrain_rlhf_one/:2:0","tags":["RLHF"],"title":"LLM预训练之RLHF（一）：RLHF及其变种","uri":"/posts/pretrain_rlhf_one/"},{"categories":["LLM"],"content":"1.1 预训练（Pre-training） 预训练阶段通常需要包含数十亿到数万亿个token的庞大文本语料库，但训练目标是模型需要根据提供的文本来预测「下一个单词」。 BP Network 1.2 有监督微调（Supervised Finetuning） ​SFT的训练过程类似Pre-training阶段，也是预测「下一个单词」，但是需要人工标注的指令数据集，其中模型的输入是一个指令（根据任务的不同，也可能包含一段输入文本），输出为模型的预期回复内容。 BP Network 数据形式类似于： Instruction: “Write a limerick about a pelican.” 指令：“写一首关于鹈鹕的打油诗。“ Output: “There once was a pelican so fine…” 输出：“从前有一只鹈鹕很好…“ 模型会把“Write a limerick about a pelican”作为输入，逐个token进行预测，输出“There once was a pelican so fine…” 虽然两个阶段都采用类似的训练目标，但有监督微调数据集通常比预训练数据小得多，指令数据集需要人类（或其他高质量的LLM）提供标注结果，所以无法大规模应用。 1.3 对齐（Alignment） 第三阶段依然是微调，不过其主要目标在于将语言模型与人类的偏好、价值观进行对齐，这也是RLHF机制发挥的地方。 BP Network ","date":"2024-05-04","objectID":"/posts/pretrain_rlhf_one/:2:1","tags":["RLHF"],"title":"LLM预训练之RLHF（一）：RLHF及其变种","uri":"/posts/pretrain_rlhf_one/"},{"categories":["LLM"],"content":"二、Reinforcement Learning with Human Feedback (RLHF) 上节，我们讨论了现代LLM的三个训练过程；本小节，我们重点讨论「上述两个微调阶段」（Supervised Tinetuning和Alignment）中使用的RLHF技术。 RLHF主要包括三步： 在预训练好的模型上进行「有监督微调」（SFT）； 在有监督微调模型基础上创建一个reward model（RM）模型； 基于RM模型使用PPO算法微调SFT模型； ","date":"2024-05-04","objectID":"/posts/pretrain_rlhf_one/:3:0","tags":["RLHF"],"title":"LLM预训练之RLHF（一）：RLHF及其变种","uri":"/posts/pretrain_rlhf_one/"},{"categories":["LLM"],"content":"2.1 在预训练好的模型上进行有监督微调** 先收集一个Prompts集合，并要求标注人员写出高质量的回复，然后使用该数据集以监督的方式微调预训练的基础模型。 BP Network ​该步骤与上小节的Supervised Finetuning类似，但这是RLHF不可或缺的一个步骤。 ","date":"2024-05-04","objectID":"/posts/pretrain_rlhf_one/:3:1","tags":["RLHF"],"title":"LLM预训练之RLHF（一）：RLHF及其变种","uri":"/posts/pretrain_rlhf_one/"},{"categories":["LLM"],"content":"2.2 在有监督微调模型基础上创建一个RM模型 对于每个Prompt，要求有监督微调后的LLM生成四到九个回复，再由标注人员根据个人偏好对所有回复进行排序。虽然排序过程很耗时，但工作量还是比第一步的有监督数据集构建要少一些。 BP Network 在处理排序数据时，使用了一个奖励模型RM，RM来自RLHF第一步的「有监督微调语言模型」（SFT），SFT的输出通过一个回归层（单个输出节点）转换为奖励分数，即可称为RM模型。 ","date":"2024-05-04","objectID":"/posts/pretrain_rlhf_one/:3:2","tags":["RLHF"],"title":"LLM预训练之RLHF（一）：RLHF及其变种","uri":"/posts/pretrain_rlhf_one/"},{"categories":["LLM"],"content":"2.3 基于RM模型使用PPO算法微调SFT模型 基于RM模型使用proximal policy optimization (PPO)算法微调SFT模型 BP Network PPO的具体技术细节可以参考InstructGPT或下面的论文列表。 Asynchronous Methods for Deep Reinforcement Learning (2016) ，https://arxiv.org/abs/1602.01783 Proximal Policy Optimization Algorithms (2017)，https://arxiv.org/abs/1707.06347 Fine-Tuning Language Models from Human Preferences (2020)，https://arxiv.org/abs/1909.08593 Learning to Summarize from Human Feedback (2022) ，https://arxiv.org/abs/2009.01325 ","date":"2024-05-04","objectID":"/posts/pretrain_rlhf_one/:3:3","tags":["RLHF"],"title":"LLM预训练之RLHF（一）：RLHF及其变种","uri":"/posts/pretrain_rlhf_one/"},{"categories":["LLM"],"content":"三、LLaMA 2的RLHF** Meta AI在创建Llama-2-chat模型时也使用了RLHF技术，不过与ChatGPT相比还是有些细微区别。 BP Network 简单来说，Llama-2-chat在第一步RLHF微调上使用相同的指令数据，但在第二步使用了两个奖励模型；通过多个阶段的不断进化，奖励模型也会根据Llama-2-chat模型出现的错误进行更新；并且增加了拒绝采样（rejection sampling）步骤。 ","date":"2024-05-04","objectID":"/posts/pretrain_rlhf_one/:4:0","tags":["RLHF"],"title":"LLM预训练之RLHF（一）：RLHF及其变种","uri":"/posts/pretrain_rlhf_one/"},{"categories":["LLM"],"content":"3.1 Margin Loss ​在标准InstructGPT中使用的RLHF PPO方法，研究人员需要收集同一个提示下的4-9个模型输出并进行排序，比如四个回复的排序结果为A\u003cC\u003c D\u003cB，那么就可以得到六个对比结果：A \u003c C，A \u003c D ，A \u003c B，C \u003c D，C \u003c B，D \u003c B。 ​Llama 2的数据集也采用类似的方式，不过标注人员每次只能看到两个（而非4-9个）回复并进行对比，但新增了一个边际（margin）标签，对比结果可以为「显著更好」（significantly better）和「好的不明显」（negligibly better）。 在排序训练时中，Llama 2相比InstructGPT增加了边际损失： $$\\mathcal{L}{\\mathrm{ranking}}=-\\log\\left(\\sigma\\left(r\\theta\\left(x,y_c\\right)-r_\\theta\\left(x,y_r\\right)-m(r)\\right)\\right)$$ 其中，$r_θ(x，y)$是提示x和生成的回复y的标量分数输出; θ为模型权重; σ是将层输出转换为范围从0到1的分数的逻辑S形函数; $y_c$是由标注人员选择的更优回复; $y_r$是较差的回复。$m(r)$可以调节两个回复之间的差值，如果对比结果为「显著更好」，则会增加梯度值，加快更新速度。 ","date":"2024-05-04","objectID":"/posts/pretrain_rlhf_one/:4:1","tags":["RLHF"],"title":"LLM预训练之RLHF（一）：RLHF及其变种","uri":"/posts/pretrain_rlhf_one/"},{"categories":["LLM"],"content":"3.2 两个RM模型 ​Llama 2中的两个奖励模型分别侧重「有用性」（helpfulness）和「安全性」（safety），用于模型优化的最终奖励函数会将两个分数进行线性组合。 BP Network ","date":"2024-05-04","objectID":"/posts/pretrain_rlhf_one/:4:2","tags":["RLHF"],"title":"LLM预训练之RLHF（一）：RLHF及其变种","uri":"/posts/pretrain_rlhf_one/"},{"categories":["LLM"],"content":"3.3 拒绝采样 ​Llama 2的作者使用了一个训练流水线，同时使用PPO和拒绝采样算法，迭代地产生多个RLHF模型（从RLHF-V1到RLHF-V5），模型在拒绝采样时会得到K个输出，并使用最高奖励的输出更新梯度，而PPO每次只基于单样本进行更新。 BP Network 在监督微调的初始阶段之后，模型只使用拒绝采样进行训练，然后再结合拒绝采样和PPO。 从实验结果来看，RLHF微调模型在无害性和有用性上都得到了改善，并且在最后阶段RLHF-v5使用PPO算法的性能最好。 BP Network ","date":"2024-05-04","objectID":"/posts/pretrain_rlhf_one/:4:3","tags":["RLHF"],"title":"LLM预训练之RLHF（一）：RLHF及其变种","uri":"/posts/pretrain_rlhf_one/"},{"categories":["LLM"],"content":"四、RLHF的替代方案 BP Network RLHF在InstructGPT和Llama 2论文中被证明是有效的，但是RLHF的过程是比较复杂的，下面将介绍一下最近RLHF的替代方案： ","date":"2024-05-04","objectID":"/posts/pretrain_rlhf_one/:5:0","tags":["RLHF"],"title":"LLM预训练之RLHF（一）：RLHF及其变种","uri":"/posts/pretrain_rlhf_one/"},{"categories":["LLM"],"content":"4.1 Constitutional AI: Harmlessness from AI Feedback (Dec 2022, https://arxiv.org/abs/2212.08073) 研究人员提出了一种 基于人类提供的规则列表的自我训练机制。与前面提到的InstructGPT论文类似，也使用了强化学习方法。 BP Network 上图中的「红队」（Red Team）指的是测试目标系统的防御能力，即外部或内部专家模拟潜在对手的过程，通过模仿现实世界攻击者的战术、技术和程序来挑战、测试并最终改进系统。 ","date":"2024-05-04","objectID":"/posts/pretrain_rlhf_one/:5:1","tags":["RLHF"],"title":"LLM预训练之RLHF（一）：RLHF及其变种","uri":"/posts/pretrain_rlhf_one/"},{"categories":["LLM"],"content":"4.2 The Wisdom of Hindsight Makes Language Models Better Instruction Followers (Feb 2023, https://arxiv.org/abs/2302.05206) 研究人员提出了一种**基于重新标记的监督微调方法HIR**，该方法在12个BigBench任务上优于RLHF。 ​HIR是如何工作的？简而言之，HIR方法包括两个步骤，即采样和训练。在采样步骤中，Prompt和指令输入给LLM来获取答案，根据对齐得分，在训练阶段适当的地方重新标注指令；然后，重新标记的指令和原始的Prompt用于微调LLM。使用这种重新标记的方法，研究人员有效地将失败案例（LLM创建的输出与原始指令不匹配的案例）转化为有用的训练数据，用于监督学习。 BP Network ","date":"2024-05-04","objectID":"/posts/pretrain_rlhf_one/:5:2","tags":["RLHF"],"title":"LLM预训练之RLHF（一）：RLHF及其变种","uri":"/posts/pretrain_rlhf_one/"},{"categories":["LLM"],"content":"4.3 Direct Preference Optimization: Your Language Model is Secretly a Reward Model (https://arxiv.org/abs/2305.18290, May 2023) 直接偏好优化（DPO）是具有PPO的RLHF的替代方案，其中研究人员表明，在RLHF中拟合奖励模型的交叉熵损失可以直接用于微调LLM。根据他们的基准，使用DPO更有效，而且在响应质量方面通常也优于RLHF/PPO。 BP Network ","date":"2024-05-04","objectID":"/posts/pretrain_rlhf_one/:5:3","tags":["RLHF"],"title":"LLM预训练之RLHF（一）：RLHF及其变种","uri":"/posts/pretrain_rlhf_one/"},{"categories":["LLM"],"content":"4.4 Reinforced Self-Training (ReST) for Language Modeling (Aug 2023, https://arxiv.org/abs/2308.08998) ReST是人类反馈强化学习（RLHF）的一种替代方案，它使LLM与人类偏好保持一致。 ReST使用采样方法创建改进的数据集，在质量越来越高的子集上迭代训练，以完善其奖励函数。根据作者的说法，与标准的在线RLHF方法（如具有近端策略优化的RLHF，PPO）相比，ReST通过离线生成训练数据集实现了更高的效率，但缺少与InstructGPT或Llama 2中使用的标准RLHF PPO方法的全面比较。 BP Network ","date":"2024-05-04","objectID":"/posts/pretrain_rlhf_one/:5:4","tags":["RLHF"],"title":"LLM预训练之RLHF（一）：RLHF及其变种","uri":"/posts/pretrain_rlhf_one/"},{"categories":["LLM"],"content":"4.5 RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback (Sep 2023, https://arxiv.org/abs/2309.00267) 最近的人工智能反馈强化学习（RLAIF）研究表明，RLHF中奖励模型训练的评级不一定必须由人类提供，而是可以由LLM生成（此处：PaLM 2）。标注人员在一半的案例中更喜欢RLAIF模型，也就意味着两个模型的差距并不大，RLHF和RLAIF都大大优于纯通过监督指令微调训练的模型。 BP Network 这项研究的结果非常有用和有趣，因为它基本上意味着我们可能能够使基于RLHF的训练更加高效和容易。然而，这些RLAIF模型在专注于信息内容的安全性和真实性的定性研究中的表现还有待观察，而人类偏好研究仅部分捕捉到了这一点。 参考文献： [1] https://magazine.sebastianraschka.com/p/llm-training-rlhf-and-its-alternatives [2] https://mp.weixin.qq.com/s/3Ff6C5zT7fXggQ1FwxvWAQ ","date":"2024-05-04","objectID":"/posts/pretrain_rlhf_one/:5:5","tags":["RLHF"],"title":"LLM预训练之RLHF（一）：RLHF及其变种","uri":"/posts/pretrain_rlhf_one/"},{"categories":["LLM"],"content":"万字长文，CVer 转 LLM 学习笔记之大模型GPT 系列 ","date":"2024-05-03","objectID":"/posts/survey/:0:0","tags":["GPT"],"title":"大模型学习笔记 | GPT 系列","uri":"/posts/survey/"},{"categories":["LLM"],"content":"导读 本文是作者对 GPT 系列文章的学习笔记，从个人角度梳理了 GPT 系列的迭代逻辑，从技术的逻辑连续性和关联性都有很好的讲解，篇幅较长，建议大家点赞收藏。 这个系列的笔记主要面向像我一样已经具备一定的深度学习基础，但是新接触 NLP 和大模型领域的读者，目的是能提纲挈领地快速把握这个领域的一系列关键工作节点。 这篇笔记涵盖的内容有： GPT-1 论文 GPT-2 论文 GPT-3 论文 InstructGPT 论文（GPT-3.5 背后的技术） GPT-4 技术报告 GPT-4 微软评测报告 GPT-4V 微软评测报告 作为一个从 CV 转到 LLM 的新人，难免犯一些常见或低级的错误，欢迎任何读者及时指出和斧正，也欢迎任何留言讨论。 ","date":"2024-05-03","objectID":"/posts/survey/:1:0","tags":["GPT"],"title":"大模型学习笔记 | GPT 系列","uri":"/posts/survey/"},{"categories":["LLM"],"content":"要点 (TL;DL) 注重能力，而非过程：预训练任务其实形式不重要，可以是 classification，可以是预测 next token，真正重要的是 model 和 data 的 scaling up，以此快速高效地得到一个有优异泛化能力的特征提取器: data: 找到/设计一个能把海量的数据用起来的任务，能用的数据越多越好，训练越快越好 model: 模型性能可以随着参数量巨量地提升而不会快速饱和，一个优秀的模型架构是 scaling up 的基础保障 三种范式： 我们可以将专属任务上微调得到的模型，看成一种用户输入 0 个特殊 token，解决 1 种任务的范式，所以第一范式下的每个模型只能用于解决一个专属任务。 第二范式的模型是为每一种任务准备 1 个特殊 token，因此通过改变输入 token，就能用一个模型解决不同的任务。 第三范式的模型把特殊 token 替换成了特殊 token 序列，而自然语言正好就是一种最符合人类习惯和直觉的特殊 token 序列。 RLHF： SFT 模型(16 epoch) RM PPO 继续训练出来的最终模型 SFT 数据(13k 条): 人工设计的问题，人工标注答案 Feedback 数据(33k 条): 针对上面人工设计的问题，模型输出的几份答案的排序（打分） PPO 使用的数据(31k 条): 人工设计的问题(上面的模型没见过的新问题)，用 RM 的评分来继续训练，这份数据不需要人工标注答案 对 GPT-4 的全面探索： 心理学角度：人类思维是快思考与慢思考两个系统的混合体，而 GPT-4 目前更类似于单纯的快思考 GPT-4 还有哪些局限性，以及哪些可以改进的地方（见 GPT-4 微软报告） GPT-4V 的全面探索： 支持哪些输入和工作模式 在不同领域和任务上的能力质量和通用性如何 有效使用和提示方法 未来方向 ","date":"2024-05-03","objectID":"/posts/survey/:2:0","tags":["GPT"],"title":"大模型学习笔记 | GPT 系列","uri":"/posts/survey/"},{"categories":["LLM"],"content":"1. Improving Language Understanding by Generative Pre-Training (2018.06) GPT 系列的第一篇论文，定下了纯 Transformer-Decoder 路线。 深度学习的早期突破很多来自于 CV 领域，其中很重要的一个原因是 CV 有 ImageNet 这个百万量级的有标注数据集，在 ImageNet 上训练分类任务得到的模型 Backbone 天然就是一个优秀的图片特征提取器，基于这个特征提取器在任意的子任务上做 fine-tuning 效果都不会太差（至少能展现出一定的泛化能力）。而 NLP 领域缺少这样大的数据集，因此，一直以来 NLP 模型发力卡在了特征提取器的构筑上，GPT 提出用训练语言模型的方式来得到这个特征提取器，然后用它来做子任务上的微调。 语言模型由于做的是“预测下一个词”这样的一个任务，因此不依赖于人工标注，可以实现海量数据的预训练和泛化。 GPT 工作是在 BERT 之前的，很多的 setting 都被 BERT 直接沿用了，比如 12 层 Transformer，768 的维度，800M 的 BookCorpus 数据集 等。 文章剩余部分介绍了如何在 NLP 四大主流任务类型上运用 GPT，即如何把不同形式的任务都表示成一个序列+对应的标签的形式。 对笔者的启示: 注重能力，而非过程：预训练任务其实形式不重要，可以是 classification，可以是预测 next token，真正重要的是 model 和 data 的 scaling up，以此快速高效地得到一个有优异泛化能力的特征提取器: data: 找到/设计一个能把海量的数据用起来的任务，能用的数据越多越好，训练越快越好 model: 模型性能可以随着参数量巨量地提升而不会快速饱和，一个优秀的模型架构是 scaling up 的基础保障 ","date":"2024-05-03","objectID":"/posts/survey/:3:0","tags":["GPT"],"title":"大模型学习笔记 | GPT 系列","uri":"/posts/survey/"},{"categories":["LLM"],"content":"2. Language Models are Unsupervised Multitask Learners (2019.02) GPT 系列的第二篇工作。 参数量提升到了 1.5B，也用了更大量的数据。GPT-2 最大的贡献是把研究的重点从单个任务上的针对性调参刷榜，转向了 zero-shot，即， 训练好的模型不再需要微调就能去做不同任务了，尽管性能上距离每个任务的 SOTA 都还有距离，但方案的可行性已经验证了。要实现这一点，原来为特殊任务准备特殊 token 的做法就不合适了，因为预训练阶段模型是没见过这些 token 的，毕竟语言模型预训练阶段只见过自然语言，所以非常自然地就引出了 prompt 的概念，用自然语言来替代原本的任务 token，实现不同任务的 zero-shot。 可以看到，在这个时候 GPT-2 就已经初具 ChatGPT 的雏形了，只不过用户的输入还不完全是任意自然语言，而是类似于这样的模板输入。： 翻译任务： (translate to french, english text, french text) QA 任务： (answer the question, document, question, answer) ","date":"2024-05-03","objectID":"/posts/survey/:4:0","tags":["GPT"],"title":"大模型学习笔记 | GPT 系列","uri":"/posts/survey/"},{"categories":["LLM"],"content":"3. Language Models are Few-Shot Learners (2005.14165) GPT 系列的第三篇工作。 GPT-3 的参数量来到了 175B，训练数据从一开始 GPT-1 的几千本书的数据集，开始进入到了网站爬虫数据和清洗的模式。 其实在 GPT-2 中就已经提到了一个叫 Common Crawl 的公开网络数据，但是因为他们觉得这份数据实在太脏了所以放弃了，而现在为了训练更大的模型也不得不用起来，因此清洗数据是免不了的。 数据清洗经历了两个过程： 过滤：他们将原来 GPT-2 训练用的数据作为正样本，Common Crawl 作为负样本训练了一个二分类器，然后用这个分类器来做数据筛选，过滤掉一些特别显著的脏数据。 去重：用经典的 LSH 算法进行去重 另一方面，GPT-3 也正式提出了“in-context learning”的概念，在模型参数不进行更新的情况下，通过输入的上下文来帮助模型提升表现。 对于笔者而言，这张图相当形象: BP Network 这揭示了模型学习的另一个维度，提升模型表现并不只有 SGD 梯度更新这一个优化方向。结合 GPT-2 中 prompt 的由来，prompt 的前身是语言模型做多任务 zero-shot 时，针对不同任务给的特殊 token，因此一个更加富有信息量的“特殊 token 序列”能提升模型表现似乎是一件非常符合直觉的事情。 相比于过去使用一个特殊 token 来代表某一种特定的任务，GPT-3 的 few-shot prompt，或者说 in-context learning 形式，在笔者看来是一种推广，用户输入的自然语言和 few-shot 样例可以看成是一组特殊 token 的序列，因为自然语言的 token 具有语义和逻辑关联性，一个强大的预训练模型做到了“特殊 token”之间的泛化。 通过实验我们也可以观察到，随着给出的示例样本数变多，模型的表现也在提升： BP Network 从笔者个人的角度来总结： 我们可以将专属任务上微调得到的模型，看成一种用户输入 0 个特殊 token，解决 1 种任务的范式，所以第一范式下的每个模型只能用于解决一个专属任务。 第二范式的模型是为每一种任务准备 1 个特殊 token，因此通过改变输入 token，就能用一个模型解决不同的任务。 第三范式的模型把特殊 token 替换成了特殊 token 序列，而自然语言正好就是一种最符合人类习惯和直觉的特殊 token 序列。 ","date":"2024-05-03","objectID":"/posts/survey/:5:0","tags":["GPT"],"title":"大模型学习笔记 | GPT 系列","uri":"/posts/survey/"},{"categories":["LLM"],"content":"4. Training language models to follow instructions with human feedback (2203.02155) InstructGPT 被认为是 ChatGPT（GPT3.5） 背后的技术，核心点是把 RLHF，即基于人类反馈的强化学习，用到了语言模型上来进行人类喜好对齐。经过 RLHF 的 1.3B GPT 模型能在人类主观评分上超过 175B 的 GPT-3. BP Network 这篇工作里将模型输出与人类意愿不一致的这个现象称为“misaligned”，并分析原因在于语言模型的训练目标只是预测下一个 token，这跟我们希望模型“follow the user’s instructions helpfully and safely”的目标之间显然是存在差距的。 用 Anthropic 的工作里的话来说，大模型应该遵循 3H 原则，即： helpful：帮助用户解决问题 honest：不能伪造信息或误导用户 harmless：不能对人或环境造成身体、心理或社会伤害 语言模型之所以存在这个问题，原因也很简单，因为使用的是无监督学习，本身的学习目标里就没有人为控制，所以很直观地可以想到用**监督微调（SFT）**的方式来把缺失的人类监督信号加进来。 但是前面 GPT 三篇工作好不容易才把模型做到 175B 这么大，现在又重新开始标数据做监督学习显然是有点不聪明的，而且模型大了以后也更容易过拟合，对于人类偏好这一类的问题标注起来难度又很大，简单地全靠 SFT 肯定是行不通的。所以很自然地，OpenAI 想到了用他们家的拿手好戏强化学习，要知道 OpenAI 本身就是做强化学习起家的，本文使用的强化学习方法 PPO 也全是之前他们已经提出的算法，没有任何新的算法被提出，甚至论文里都没有对已有的算法进行太多的解释和铺垫，需要你感兴趣自己去翻他们的论文。 BP Network 他们的方法整体可以概括如下： 人工标一批 SFT 数据（包含问题和回答），对 GPT-3 模型（在强化学习里对应 Policy）进行微调 用 SFT 得到的模型，针对每个问题生成几份回答，然后人工给这些回答质量打分（排序） 用这份打分数据训练一个奖励模型（Reward Model, RM），让奖励模型代替人工打分 采用 PPO 算法，基于奖励模型的评分来继续训练 GPT-3 模型 换言之，他们一共造了三份数据： SFT 数据（13k 条）：人工设计的问题，人工标注答案 Feedback 数据（33k 条）：针对上面人工设计的问题，模型输出的几份答案的排序（打分） PPO 使用的数据（31k 条）：人工设计的问题（上面的模型没见过的新问题），用 RM 的评分来继续训练，这份数据不需要人工标注答案 训练三个模型： SFT 模型（16 epoch） RM (Reward Model 奖励模型) PPO 继续训练出来的最终模型 他们甚至对问题类型进行了一些分类： BP Network 模型训练部分，个人觉得值得注意的点有： SFT 阶段，在训了 1 epoch 后模型就已经过拟合了，但他们发现继续训练过拟合的模型依然可以提升 RM 性能，所以他们训练了 16 epoch RM 的权重是直接用 SFT 模型初始化的，因为评分模型也需要语言能力，直接拷贝一份权重是比较省事的。RM 的输入是问题+几份答案，输出是排序。 RM 模型只有 6B，因为 175B 的 RM 很难训 强化学习阶段加了一个逐 token 的 KL 散度，用来让最终模型跟第一版 SFT 模型的要输出分布尽量保持一致，因为 RM 是在训练 SFT 模型的数据上训的，如果分布差异太大，RM 的评分就不准了 强化学习的目标函数如下： BP Network 简单翻译一下： $$损失 = RM 评分 + 新旧模型输出token分布的KL散度 + 旧问题上SFT的损失$$ 其中： RM 评分是 RM 对当前正在训练的模型在新问题（第三份数据）上的输出的评分 KL 散度是当前模型跟旧的 SFT 模型输出之间计算的 旧问题 SFT 损失是用第一份数据集继续按 SFT 方法训当前模型得到的 另外，关于训练数据和评测方面的取舍也有所不同，训练中他们更看重 helpful，而评测阶段则更看重 honest 和 harmless。 ","date":"2024-05-03","objectID":"/posts/survey/:6:0","tags":["GPT"],"title":"大模型学习笔记 | GPT 系列","uri":"/posts/survey/"},{"categories":["LLM"],"content":"5. GPT-4 Technical Report (2303.08774) 多模 基于上面笔者三种模型范式的思路，多模态的模型可以看成是让特殊 token 的类型从文本 token 拓宽到了视觉 token，将模型解决的任务从 NLP 任务拓宽到了 CV 任务，而两种模态 token 对齐的技术也早被 OpenAI 研究过了，也就是大名鼎鼎的 CLIP。因此，GPT-4 具备多模能力本身并不是一件意外的事情。 RLHF 在笔者看来，RLHF 等技术更多地是在不限制输入 token 序列的情况下，去约束模型输出的技术，当然从某种意义上，也可以看成是在监督 prompts -\u003e task 的映射关系的技术（其实发展到现在，task 这个词已经不太准确了，可以意会一下）。 GPT-4 的报告中明确指出，RLHF 并不能提升模型解决任务的质量（不会增加知识），甚至很多时候调的不好还会损害各个任务上的指标。RLHF 更多地是在构建一些明确的 prompts -\u003e task 映射关系，因为自然语言是具有歧义性的，尤其是在输入信息较少的情况下，模型根据 prompts “理解”到的那个 task，并不一定是人类真正心里的那个意图，RLHF 实现了一种定制化的映射搭建，或者说，人类喜好对齐。 Predictable scaling 由于大模型实验的成本日渐高昂，我们不再能像小模型那样随便起实验调参了。因此 OpenAI 的大部分实验应该是在一个比 GPT-4 小很多倍的模型上进行的，然后通过这个小模型的训练 loss，来预测大模型最终训练出来的 loss BP Network 同样的， predictable scaling laws 也在很多 HumanEval 集上得到了观察。当然，在一部分的任务上也还无法被拟合的性能曲线，因此 OpenAI 说后续还会进一步优化他们模型性能预测的方法。 ","date":"2024-05-03","objectID":"/posts/survey/:7:0","tags":["GPT"],"title":"大模型学习笔记 | GPT 系列","uri":"/posts/survey/"},{"categories":["LLM"],"content":"6. Sparks of Artifificial General Intelligence: Early experiments with GPT-4 (2303.12712) 智能（Intelligence）是一个多方面且难以捉摸的概念，长期以来缺乏一个共识性的定义。1994 年 52 名 心理学家组成的公式小组出版的关于智力科学的社论中，将只能定义为一种非常普遍的心理能力，包括推理、计划、解决问题、抽象思考、理解复杂想法、快速学习和从经验中学习的能力。 这篇是微软关于 GPT-4 的研究报告，长达 55 页，文中的实验都是在 早期的文本单一模态版的 GPT-4 上进行的（而不是后面更新的多模态版本）, 其目标是生成一些新颖而困难的任务和问题，来证明 GPT-4 的能力并不是单纯的记忆，并且它对概念、技能和领域有深刻而灵活的理解。另外还旨在探索 GPT-4 的响应和行为，以验证其一致性、连贯性和正确性，揭示其局限性和偏差。 如何衡量 GPT-4 的智能 传统机器学习的标准做法是准备一组标准评测数据集，确保它们独立于训练数据之外，覆盖一系列的任务和领域。 但这种方法并不太适用于 GPT-4，因为 GPT-4 是闭源模型，相关的训练数据集信息不公开，并且可以预见地非常庞大，因此我们不能保证目前公开的基准测试集不在它的训练数据里。也正因为此，本文采用的研究方法更接近于传统心理学，而不是机器学习方法。 多模态与跨学科整合 智能的一个重要衡量指标是综合不同领域信息的能力，以及跨学科地应用知识和技能的能力。这一节中作者举了四个例子来说明 GPT-4 具有很强的多模态与跨学科整合能力： 写 JavaScript 代码来生成画家 Wassily Kandinsky 风格的作品。图一是该画家的原作，后面分别是 GPT-4 和 ChatGPT 写的代码画出的。 BP Network 用莎士比亚的文风来证明素数无穷定理 BP Network 以圣雄甘地的口吻写一封信给他的妻子，内容是支持“电子”成为美国总统候选人 BP Network 写 Python 代码，以年龄、性别、体重、身高和血液测试结果向量作为输入，来预测用户是否有患糖尿病的风险 这些对比可以体现 GPT-4 能创新性地整合不同领域的概念，并且显著强于 ChatGPT。除此之外作者也测试了 GPT-4 在音乐、绘图、空间理解方面的能力。 代码 除了常见的 leetcode 刷题，作者测试了 GPT-4 生成逆向工程代码、解释已有代码、用自然语言模拟代码执行过程、运行伪代码等能力。 数学 在一系列的分析实验后，作者从以下三方面总结了GPT-4的数学能力： 创造性推理：识别每个阶段可能相关的参数、中间步骤、计算或代数操作的能力。该组件通常基于启发式猜测或直觉，通常被认为是数学解决问题的最实质性和最深刻的方面 技术熟练程度：执行遵循指定步骤集的常规计算或操作的能力 批判性推理：批判性地检查论点的每个步骤的能力，将其分解为其子组件，解释它需要的内容，它与其余论点相关以及为什么是正确的 这一节作者发现 GPT-4 的很多缺陷，如： 在执行一些很常规且机械的计算时经常算错和混淆 GPT-4 由于是自回归模型，因此是实时线性输出的，而没有办法“打腹稿” 与世界的交互 智能的另一重要方面是交互能力，即跟外界环境和智能体进行交互的能力，作者主要通过工具调用和具身交互两个维度来评估。 工具调用这里不多赘述了，具身交互方面测试了文字跑团游戏，以及交互式地指导人员找到天花板漏水的地方并进行修补，逐步根据人类的每一步反馈，给出行动建议和指示。 与人类的交互 GPT-4 在推理他人心理状态方面表现非常突出，特别是在模拟现实场景中，它的解释能力也很强，能对自己的判断和言论进行自我解释。 判别能力 判别能力主要指模型区别不同事物、概念和情景的能力。比如，区分两个食物哪个是可以安全食用，哪个是有毒的。 这一节的测试里，揭示出当前的评测指标存在的缺陷：对于语句相似度捕捉不够，依然严重依赖单词和短句的相似度，因此在很多时候参考答案很短，而 GPT-4 生成的答案很长，会被 ROUGE 这样的指标判定为答案不匹配，而人工检查后发现 GPT-4 的答案更加高质量和具有说服力。 另一方面作者也测试了用 GPT-4 作为评分员，对回答进行打分，实验现实尽管距离人类打分还存在一些差距，但在一些强约束的场景下已经很具有竞争力了。 自回归结构的局限性 自回归结构的输出是实时进行的，因此不存在“打草稿”的机会，因此无法“step-by-step”地处理问题，而引入思维链则可以显著地提升模型准确度。 对于一些依赖递归回溯的问题，比如一步一步输出汉诺塔问题的解法，GPT-4 表现非常差，在解决不能以连续方式处理的复杂或创造性问题时，都暴露出了严重的局限性。 比如要求 GPT-4 修改“9 * 4 + 6 * 6 = 72”这个等式左边的一个数字，来让等式计算结果变成 99，这就是一个无法简单“step-by-step”推理得到答案的问题，GPT-4 最后的准确率也非常低。 这一节的讨论中，作者指出，理解这些局限性的一个方法是类比诺奖作者卡尼曼提出的“快思考”和“慢思考”的概念。卡尼曼认为人类思维分成快、慢两个系统，快思考是一种自动的、直观的、不需要花费精力的思考方式，速度快但是容易出错和偏见。慢思考是一种受控的、理性的、耗费精力的思考方式，虽然速度慢但是准确可靠。 当前的 GPT-4 很大程度上可以看成是在执行快思考，但缺少慢思考能力。 未来方向 作者在这一节总结了未来 GPT-4 可以研究和改进的方向： 置信度校验：模型的输出缺乏置信度，既会编造训练集中没有的内容（open-domain 幻觉），也会生成与 Prompt 不一致的内容（close-domain 幻觉） BP Network 长期记忆：即长的上下文 持续学习：当前微调和自我更新成本过高、缺乏有效且稳定的手段（保持已有能力不丢失和遗忘） 个性化：根据应用和需求进行定制、扮演、调整风格等 提前规划和概念性跳跃：推理过程过于线性，在需要思维跳跃性的任务上表现不佳 透明度、可解释性和一致性 认知谬误和非理性：数据中存在的偏见、成见或错误引入了认知偏差和非理性 对输入的敏感性：对于 Prompt 过于敏感，鲁棒性不够 这些局限性均指向一个核心问题：哪些缺陷是自回归架构的先天缺陷，哪些是在已有架构上可以通过处理数据、增加外挂的组件和增大参数量解决的。 ","date":"2024-05-03","objectID":"/posts/survey/:8:0","tags":["GPT"],"title":"大模型学习笔记 | GPT 系列","uri":"/posts/survey/"},{"categories":["LLM"],"content":"7. The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision) (2309.17421) 微软发布的 166 页的 GPT-4V 报告，主要围绕以下四个点进行展开研究： GPT-4V 支持哪些输入和工作模式？ GPT-4V 在不同领域和任务上的能力质量和通用性如何？ GPT-4V 有效使用和提示方法有哪些？ 未来有哪些有前途的方向？ GPT-4V 的输入模式 纯文本 单个图像-文本对 图像文本交替输入 前两种相对来说比较简单，第三种交替输入的情况，已经非常接近于人的聊天模式了。 BP Network GPT-4V 的工作模式和提示技术 实验证明，在 LLM 上研究出来上各种提示技术，在 GPT-4V 上也是好使的，比如思维链、few-shot 提示等。 这一节提到了一个“LLMs don’t want to succeed”的理论，貌似是来自于 Andrej Karpathy 的某次演讲，里面展示了一种类似于催眠一样的提示技术，即，你想要你的 LLM 表现更出色，你就要用直接的提示词说“你是xxx方面的专家”，否则它之后表现出一般普通人水平的能力。 BP Network 完整的 PPT 可以看这里：https://karpathy.ai/stateofgpt.pdf 在论文中作者是举了一个数苹果的案例，让 GPT-4V 来数一下画面中有几个苹果。一开始 GPT-4V 并不能轻易得到正确答案，但经过一系列我们已知的 LLM Prompt 技巧加强后，GPT-4V 变得可靠，能够正确计数： BP Network 在日常的人和人交互中，在图片中画圈、画箭头来指向关键信息是一种很自然且常见的方式， 经实验 GPT-4V 在这方面的理解能力非常强大。 BP Network 作者实验了一些很有挑战性的 case，发现基本上难不倒它： BP Network 在 In-context few-shot learning 方面，作者也用一个很有代表性的例子说明了提供示例样本的重要性。作者给了一张仪表的图，让 GPT-4V 读出当前仪表指针指向的数值，一开始不论如何改良 prompt 都无法得到正确的结果。 BP Network 甚至在给出一个示例的情况下模型仍然表现不佳，但当示例增加到两个后，GPT-4V 就突然能成功读数了，可见提供上下文示例对于提升大模型性能至关重要。 BP Network BP Network 视觉语言能力 在大部分已有的 CV 子任务上，GPT-4V 都表现出了不错的能力，常见的场景描述等更是表现出色，在相对小众的领域，如医学图像上，同样让人印象深刻，GPT-4V 可以根据 CT 图判断出智齿和骨折等。 BP Network 当然，在一些已经被做得非常深入的子任务上，GPT-4V 相较于 SOTA 模型还有不小的差距，但还是那句话，潜力大于绝对精度，目前 GPT-4V 已经展现出了让人鼓舞的性能，优化个别任务上的表现只是时间问题。 BP Network GPT-4V 甚至能看懂梗图，解释其中的笑点： BP Network 借助 GPT-4V 强大的推理能力和具备的常识，我们甚至可以“假如你是一名侦探，你可以从图中推理出哪些线索？” BP Network 时间序列和视频理解 作者实验了多图像序列，GPT-4V 能够识别出这是一组动态图像序列，并且能结合起来判断画面中的人正在做俯卧撑： BP Network 情商测试 在这一节，GPT-4V 可以基于予以内容和图像样式解释视觉情感，如满意、愤怒、敬畏和恐惧等： BP Network 甚至可以一张图片让 GPT-4V 用两种不同方式来描述，分别让人感到不安和感到舒适（新闻学让它玩明白了）： BP Network 新兴应用亮点 行业： 缺陷检测 安全检查 杂货结账 医疗 汽车保险 损害评估 保险报告 定制化 照片组织 密集标注与分割 图像生成 生成图像的评估 图像编辑的提示生成 具象化智能体 操作机器 导航 GUI 导航（软件层面的交互和导航） 整篇报告篇幅较多，并且举了大量详细的例子，在这里就不一一展开了，感兴趣的同学可以自行翻阅。 至此，我总结了 GPT 系列工作里一些我关注到的点，从中可以感受到 OpenAI 的工作之间都有着很深的逻辑链条，很多推广都似乎是最符合直觉的。OpenAI 早期公开的论文里各种细节还是很丰富的，不仅细致地告诉你如何清洗和构造数据，甚至还教你如何找到一个合适的标注员给你标数据。 作为一个从 CV 转到 LLM 的新人，难免犯一些常见或低级的错误，欢迎任何读者及时指出和斧正，也欢迎任何留言讨论。 本篇笔记的写作参考了沐神的几期 B 站视频，以及知乎@苏打的文章，特此感谢 ","date":"2024-05-03","objectID":"/posts/survey/:8:1","tags":["GPT"],"title":"大模型学习笔记 | GPT 系列","uri":"/posts/survey/"},{"categories":["DL"],"content":"1、⭐softmax如何防止指数上溢 原softmax公式： 工程化实现，防止指数上溢： ，使a等于x中最大值。 ","date":"2024-04-26","objectID":"/posts/dl_basics_one/:0:1","tags":["DL"],"title":"Index","uri":"/posts/dl_basics_one/"},{"categories":["DL"],"content":"2、⭐Transformer中的positional encoding 为什么需要PE: 因为transfomer是同时处理所有输入的，失去了位置信息。 编码应该满足的条件：a、对于每个位置词语，编码是唯一的 b、词语之间的间隔对于不同长度句子是一致的 c、能适应任意长度句子 公式：每个词语位置编码为不同频率的余弦函数，从1到1/10000。如下将每个词语位置编码为d维向量–\u003e 可理解为一种二进制编码，二进制的不同位变化频率不一样，PE的不同位置变化频率也不一样 如何获取相对位置关系：两个位置编码进行点积。 ","date":"2024-04-26","objectID":"/posts/dl_basics_one/:0:2","tags":["DL"],"title":"Index","uri":"/posts/dl_basics_one/"},{"categories":["DL"],"content":"3、⭐求似然函数步骤 定义：概率是给定参数，求某个事件发生概率；似然则是给定已发生的事件，估计参数。 写出似然函数 对似然函数取对数并整理 求导数，导数为0处为最佳参数 解似然方程 ","date":"2024-04-26","objectID":"/posts/dl_basics_one/:0:3","tags":["DL"],"title":"Index","uri":"/posts/dl_basics_one/"},{"categories":["DL"],"content":"4、⭐HMM和CRF区别 CRF是判别模型，对问题的条件概率分布建模；HMM是生成模型，对联合概率分布建模 HMM是概率有向图，CRF是概率无向图 HMM求解过程可能是局部最优，CRF是全局最优 ","date":"2024-04-26","objectID":"/posts/dl_basics_one/:0:4","tags":["DL"],"title":"Index","uri":"/posts/dl_basics_one/"},{"categories":["DL"],"content":"5、⭐空洞卷积实现 相比于常规卷积多了dilation rate超参数，例如dilation rate=2代表相邻两个卷积点距离为2，如图(b)。 存在问题：gridding effect, 由于卷积的像素本质上是采样得到的，所以图像的局部相关性丢失了，同时远距离卷积得到的信息也没有相关性。 ","date":"2024-04-26","objectID":"/posts/dl_basics_one/:0:5","tags":["DL"],"title":"Index","uri":"/posts/dl_basics_one/"},{"categories":["DL"],"content":"6、⭐汉明距离 两个字符串对应位置的不同字符的个数。 ","date":"2024-04-26","objectID":"/posts/dl_basics_one/:0:6","tags":["DL"],"title":"Index","uri":"/posts/dl_basics_one/"},{"categories":["DL"],"content":"7、⭐训练过程中发现loss快速增大应该从哪些方面考虑? 学习率过大 训练样本中有坏数据 ","date":"2024-04-26","objectID":"/posts/dl_basics_one/:0:7","tags":["DL"],"title":"Index","uri":"/posts/dl_basics_one/"},{"categories":["DL"],"content":"8、⭐Pytorch和TensorFlow区别 图生成：pytorch动态图，tensorflow静态图 设备管理：pytorch cuda，tensorflow 自动化 ","date":"2024-04-26","objectID":"/posts/dl_basics_one/:0:8","tags":["DL"],"title":"Index","uri":"/posts/dl_basics_one/"},{"categories":["DL"],"content":"9、⭐model.eval vs和torch.no_grad区别 model.eval: 依然计算梯度，但是不反传；dropout层保留概率为1；batchnorm层使用全局的mean和var with torch.no_grad: 不计算梯度 ","date":"2024-04-26","objectID":"/posts/dl_basics_one/:0:9","tags":["DL"],"title":"Index","uri":"/posts/dl_basics_one/"},{"categories":["DL"],"content":"10、⭐每个卷积层的FLOPS计算 即计算feature map每个点需要的乘法和加法运算量，定义一个乘法和加法为一次flop，则FLOPS计算如下： ","date":"2024-04-26","objectID":"/posts/dl_basics_one/:0:10","tags":["DL"],"title":"Index","uri":"/posts/dl_basics_one/"},{"categories":["DL"],"content":"11、⭐PCA(主成分分析) ⭐PCA是一种降维方法，用数据里面最主要的方面来代替原始数据，例如将$m$个$n$维数据降维到$n’$维，希望这$m$个$n’$维数据尽可能地代表原数据。 ⭐两个原则：最近重构性–\u003e样本点到这个超平面的距离足够近；最大可分性–\u003e样本点在这个超平面的投影尽可能的分开。 ⭐流程：基于特征值分解协方差矩阵和基于奇异值分解SVD分解协方差矩阵。 （1）对所有样本进行中心化 （2）计算样本的协方差矩阵$XX^T$ （3）对协方差矩阵进行特征值分解 （4）取出最大的$n’$个特征值对应的特征向量，将所有特征向量标准化，组成特征向量矩阵W （5）对样本集中的每一个样本$x^(i)$转化为新的样本$z^(i)=W^T x^(i)$，即将每个原数据样本投影到特征向量组成的空间上 （6）得到输出的样本集$z^(1)、z^(2)…$ ⭐意义：a、使得结果容易理解 b、数据降维，降低算法计算开销 c、去除噪声 ","date":"2024-04-26","objectID":"/posts/dl_basics_one/:0:11","tags":["DL"],"title":"Index","uri":"/posts/dl_basics_one/"},{"categories":["DL"],"content":"12、⭐k-means如何改进？ ⭐缺点：1、k个初始化的质心对最后的聚类效果有很大影响 2、对离群点和孤立点敏感 3、K值人为设定 ⭐改进： K-means++：从数据集随机选择一个点作为第一个聚类中心，对于数据集中每一个点计算和该中心的距离，选择下一个聚类中心，优先选择和上一个聚类中心距离较大的点。重复上述过程，得到k个聚类中心。 K-medoids：计算质心时，质心一定是某个样本值的点。距离度量：每个样本和所有其他样本的曼哈顿距离$((x,y), |x|+|y|)$。 ISODATA，又称为迭代自组织数据分析法，是为了解决K值需要人为设定的问题。核心思想：当属于某个类别的样本数过少时或者类别之间靠得非常近就将该类别去除；当属于某个类别的样本数过多时，把这个类别分为两个子类别。 ⭐和分类问题的区别：分类的类别已知，且需要监督；k-means是聚类问题，类别未知，不需要监督。 ⭐终止条件：a、相邻两轮迭代过程中，非质心点所属簇发生改变的比例小于某个阈值 b、所有簇的质心均未改变 c、达到最大迭代次数 ⭐时间复杂度：$O(迭代次数 \\ast 数据个数 \\ast k \\ast 数据维度)$，k为k个类别中心 ⭐空间复杂度：$O(数据个数 \\ast 数据维度+k \\ast 数据维度)$ ","date":"2024-04-26","objectID":"/posts/dl_basics_one/:0:12","tags":["DL"],"title":"Index","uri":"/posts/dl_basics_one/"},{"categories":["DL"],"content":"13、⭐Dropout实现 以p的概率使神经元失效，即使其激活函数输出值为0： 为了使训练和测试阶段输出值期望相同，需要在训练时将输出值乘以1/(1-p)或者在测试时将权重值乘以(1-p)。 Dropout和Batch norm能否一起使用？ 可以，但是只能将Dropout放在Batch norm之后使用。因为Dropout训练时会改变输入X的方差，从而影响Batch norm训练过程中统计的滑动方差值；而测试时没有Dropout，输入X的方差和训练时不一致，这就导致Batch norm测试时期望的方差和训练时统计的有偏差。 ","date":"2024-04-26","objectID":"/posts/dl_basics_one/:0:13","tags":["DL"],"title":"Index","uri":"/posts/dl_basics_one/"},{"categories":["DL"],"content":"14、⭐梯度消失和梯度爆炸 梯度消失的原因和解决办法 （1）隐藏层的层数过多 反向传播求梯度时的链式求导法则，某部分梯度小于1，则多层连乘后出现梯度消失 （2）采用了不合适的激活函数 如sigmoid函数的最大梯度为1/4，这意味着隐藏层每一层的梯度均小于1（权值小于1时），出现梯度消失。 解决方法：1、relu激活函数，使导数衡为1 2、batch norm 3、残差结构 梯度爆炸的原因和解决办法 （1）隐藏层的层数过多，某部分梯度大于1，则多层连乘后，梯度呈指数增长，产生梯度爆炸。 （2）权重初始值太大，求导时会乘上权重 解决方法：1、梯度裁剪 2、权重L1/L2正则化 3、残差结构 4、batch norm ","date":"2024-04-26","objectID":"/posts/dl_basics_one/:0:14","tags":["DL"],"title":"Index","uri":"/posts/dl_basics_one/"},{"categories":["DL"],"content":"15、⭐YOLOV1-YOLOV4改进 ⭐YOLOV1: one-stage开山之作，将图像分成S*S的单元格，根据物体中心是否落入某个单元格来决定哪个单元格来负责预测该物体，每个单元格预测两个框的坐标、存在物体的概率（和gt的IoU）、各类别条件概率。 损失函数：均采用均方误差。 优点：速度快。 缺点：1、每个单元格预测两个框，并且只取和gt IoU最大的框，相当于每个单元格只能预测一个物体，无法处理密集物体场景。2、输出层为全连接层，只能输入固定分辨率图片 3、计算IoU损失时，将大小物体同等对待，但同样的小误差，对大物体来说是微不足道的，而对小物体来说是很严重的，这会导致定位不准的问题。4、没有密集锚框、没有RPN，导致召回率低 ⭐YOLOV2: 改进点： (1)、Batch normalization替代dropout，防止过拟合 (2)、去掉全连接层，使用类似RPN的全卷积层 (3)、引入Anchor，并使用k-means聚类确定anchor大小、比例，提高了recall (4)、高分辨率预训练backbone (5)、限定预测框的中心点只能在cell内，具体通过预测相对于cell左上角点的偏移实现，这样网络收敛更稳定 (6)、添加passthrough层，相当于多尺度特征融合，$1 \\ast 1$卷积将$26 \\ast 26 \\ast 512$ feature map降维成$26 \\ast 26 \\ast 64$, 然后将特征重组，拆分为4份$13 \\ast 13 \\ast 64$，concate得到$13 \\ast 13 \\ast 256$ feature map，和低分辨率的$13 \\ast 13 \\ast 1024$ feature map进行concate (7)、提出Darknet进行特征提取，参数更少，速度更快 (8)、提出YOLO9000，建立层级分类的World Tree结构，可以进行细粒度分类 ⭐YOLOV3: (1)、使用sigmoid分类器替代softmax分类器，可以处理多标签分类问题 (2)、引入残差结构，进一步加深网络深度 (3)、多尺度预测，每个尺度预测3个bbox ⭐YOLOV4: (1)、Mosaic data augmentation：四张图片拼接成一张图片 (2)、DropBlock：drop out只丢弃单个像素，而因为二维图像中相邻特征强相关，所以丢弃后网络依然可以推断出丢失区域信息，导致过拟合；所以dropblock选择丢弃一块连续区域。 (3)、label smoothing (4)、CIoU loss CIoU = IoU + bbox中心距离/对角线距离+长宽比例之差 -1\u003c=CIoU\u003c=1 (5)、YOLO with SPP：就是用不同大小的卷积核对特征图进行卷积，得到不同感受野的特征，然后concate到一起。 ","date":"2024-04-26","objectID":"/posts/dl_basics_one/:0:15","tags":["DL"],"title":"Index","uri":"/posts/dl_basics_one/"},{"categories":["DL"],"content":"16、⭐AP计算 ⭐AP是对每一类先计算AP，再将所有类平均得到最终AP。 以COCO中AP计算为例。先选定用来判断TP和FP的IoU阈值，如0.5，则代表计算的是AP0.5，然后对每类做计算，例如对于class1: class1 box1 score1 box2 score2 box3 score3 若box1与某gt的IoU大于指定阈值（如0.5)，记为Positive；若有多个bbox与gt的IoU大于指定阈值，选择其中score最大的记为Positive，其它记为Negative。可理解为确定box1对应的label。box2、box3同理。 而后要得到PR曲线，需要先对box1,2,3按score从高到低排序，假设排序结果如下： True class class1 box2 Positive score2 box1 Negative score1 box3 Positive score3 然后逐行计算score阈值为score2、score1、score3的Precision和Recall，score大于阈值的box才算做模型预测的Positive（TP+FP)。假设共有三个gt box，则计算结果如下： True class class1 Precision=TP/(TP+FP) Recall box2 Positive score2 1/1 1/3 box1 Negative score1 1/2 1/3 box3 Positive score3 2/3 2/3 这样得到一个个PR曲线上的点，然后利用插值法计算PR曲线的面积，得到class1的AP。 具体插值方法：COCO中是均匀取101个recall值即0,0.01,0.02,…,1，对于每个recall值r，precision值取所有recall\u003e=r中的最大值$p_{interp(r)}$。 然后每个recall值区间（0-0.01，0.01-0.02，…）都对应一个矩形，将所有矩形面积加起来即为PR曲线面积，得到一个类别的AP，如下图所示。对所有类别（如COCO中80类）、所有IoU阈值（例如0.5:0.95）的AP取均值即得到最终AP。 AR计算 计算过程同AP，也是在所有IoU阈值和类别上平均。 每给定一个IoU阈值和类别，得到一个P_R曲线，当P不为0时最大的Recall作为当前Recall。 ","date":"2024-04-26","objectID":"/posts/dl_basics_one/:0:16","tags":["DL"],"title":"Index","uri":"/posts/dl_basics_one/"},{"categories":["DL"],"content":"17、⭐IoU变种合集 IoU GIoU $Ac$为bbox A和bbox B的最小凸集面积，U为A U B的面积，即第二项为不属于A和B的区域占最小闭包的比例。 -1\u003c=GIoU\u003c=1，当A和B不重合，仍可以计算损失，因此可作为损失函数。 ✒️优点：在不重叠的情况下，能让预测框向gt框接近。 ✒️缺点：遇到A框被B框包含的情况下，GIoU相同。 DIoU 其中， $b$和$b^{gt}$分别代表了预测框和真实框的中心点，且$ρ$代表的是计算两个中心点间的欧式距离。$c$代表的是能够同时包含预测框和真实框的最小闭包区域的对角线距离。 $-1 \u003c DIoU \\leq 1$, 将目标与anchor之间的距离，重叠率以及尺度都考虑进去，使得目标框回归变得更加稳定 ✒️优点：直接优化距离，解决GIoU包含情况。 CIoU 在DIoU的基础上考虑bbox的长宽比： $-1 \\leq CIoU \\leq 1$ ✒️优点：考虑bbox长宽比 ","date":"2024-04-26","objectID":"/posts/dl_basics_one/:0:17","tags":["DL"],"title":"Index","uri":"/posts/dl_basics_one/"},{"categories":["DL"],"content":"18、⭐depth-wise separable conv (深度可分离卷积) 例如$5 \\ast 5 \\ast 3$图片要编码为$5 \\ast 5 \\ast 4$ feature map，则depth-wise conv分为两步： 先是depth wise卷积，利用3个$3 \\ast 3$ conv对每个通道单独进行卷积，这一步只能改变feature map长宽，不能改变通道数： 参数量： 计算量： 然后是point wise卷积，利用4个$1 \\ast 1 \\ast 3$ conv对depth wise生成的feature map进行卷积，这一步只能改变通道数，不能改变feature map长宽： 参数量： 计算量： 所以与一般卷积对比，总参数量和计算量： 总参数量：常规卷积–\u003e ， 深度可分离卷积–\u003e 总计算量：常规卷积–\u003e , 深度可分离卷积–\u003e ","date":"2024-04-26","objectID":"/posts/dl_basics_one/:0:18","tags":["DL"],"title":"Index","uri":"/posts/dl_basics_one/"},{"categories":["DL"],"content":"19、⭐检测模型里为啥用smoothL1去回归bbox 首先，对于L2 loss，其导数包含了(f(x)-Y)，所以当预测值与gt差异过大时，容易梯度爆炸； 而对于L1 loss，即使训练后期预测值和gt差异较小，梯度依然为常数，损失函数将在稳定值附近波动，难以收敛到更高精度。 所以SmoothL1 loss结合了两者的优势，当预测值和gt差异较大时使用L1 loss；差异较小时使用L2 loss： ","date":"2024-04-26","objectID":"/posts/dl_basics_one/:0:19","tags":["DL"],"title":"Index","uri":"/posts/dl_basics_one/"},{"categories":["DL"],"content":"20、⭐Deformable conv如何实现梯度可微？ 指的是对offset可微，因为offset后卷积核所在位置可能是小数，即不在feature map整数点上，所以无法求导；Deformable conv通过双线性插值实现了offset梯度可微。 用如下表达式表达常规CNN: 则Deformable conv可表达为： $x(p_0+p_n+\\Delta p_n)$可能不是整数，需要进行插值，任意点p（周围四个整数点为q）的双线性插值可表达为下式： 其中$g(a, b) = max(0, 1 − |a − b|)$。 则offest delta_pn求导公式为： 从而实现对offset的梯度可微。 ","date":"2024-04-26","objectID":"/posts/dl_basics_one/:0:20","tags":["DL"],"title":"Index","uri":"/posts/dl_basics_one/"},{"categories":["DL"],"content":"21、⭐Swin Transformer (1)⭐motivation 高分辨率图像作为序列输入计算量过大问题；和nlp不同，cv里每个物体的尺度不同，而nlp里每个物体的单词长度都差不多。 (2)⭐idea 问题一：一张图分成多个窗口，每个窗口分成多个patch，每个窗口内的多个patch相互计算自注意力；问题二：模仿CNN pooling操作，将浅层尺度patch进行path merging得到一个小的patch，实现降采样，从而得到多尺度特征。 (3)⭐method 整体结构很像CNN，卷积被窗口自注意力代替，pooling被patch merging代替。 ✒️method 1: shifted window 目的是让不重叠窗口区域也能有交互，操作本质是将所有窗口往右下角移动2个patch。 窗口数从4个变成了9个，计算量增大，为减小计算量，使用cyclic shift，将窗口拼接成4个窗口，另外因为拼接后A、B、C相较于原图发生了相对位置变化，所以A、B、C和其他区域是不可以进行交互的，因此引入了Mask操作。 Mask操作： 以3、6所在窗口的自注意力计算为例，将7*7=49个像素展平得到长度为49的一维向量，做矩阵乘法即Q*K。 又因为3和6是不可以交互的，所以矩阵左下角和右上角应该被mask掉，Swin采用的方法是加上左下角和右上角为-100，其余位置为0的模板，这样得到的attention矩阵在softmax后就变成0了。 ✒️method2: patch merging 就是间隔采样，然后在通道维度上拼接 (4)⭐SwinTransformer位置编码实现 👉核心思想就是建了一个相对位置编码embedding字典，使得相同的相对位置编码成相同的embedding。👈 例如2*2的patch之间的相对位置关系矩阵为2*2*2，相对位置范围为[-1,1]： 则x，y相对位置关系可用3*3 (-1,0,1三种相对位置)的table存储所有可能的相对位置关系，并用3*3*embed_n表示所有相对位置对应的embedding。为了使得索引为整数，需要将所有相对位置变为正值： 可以通过简单的x,y相对位置相加将相对位置映射为一维，但是会出现(0,2)和(2,0)无法区分的问题，所以需要使得x,y相对位置编码不同： 然后将x和y相对位置相加： 从而每个相对位置对应一个一维的值，作为相对位置embedding table的索引，获取对应位置的embedding。 ","date":"2024-04-26","objectID":"/posts/dl_basics_one/:0:21","tags":["DL"],"title":"Index","uri":"/posts/dl_basics_one/"},{"categories":["DL"],"content":"22、⭐YOLOX核心改进： (1)✒️Decoupled head：就是anchor free方法里最常用的cls head和reg head (2)✒️Anchor-free: 即类似FCOS，不同的是预测的是中心点相对于grid左上角坐标的offset值，以及bbox的长宽，将物体中心的某个区域内的点定义为正样本，并且每个尺度预测不同大小物体。 (3)✒️Label assignment(SimOTA): 将prediction和gt的匹配过程建模为运输问题，使得cost最小。 cost表示：$pred_i$和$gt_j$的cls和reg loss。 对每个gt，选择落在指定中心区域的top-k least cost predictions当作正样本，每个gt的k值不同。 最佳正锚点数量估计：某个gt的适当正锚点数量应该与该gt回归良好的锚点数量正相关，所以对于每个gt，我们根据IoU值选择前q个预测。这些IoU值相加以表示此gt的正锚点估计数量。 ","date":"2024-04-26","objectID":"/posts/dl_basics_one/:0:22","tags":["DL"],"title":"Index","uri":"/posts/dl_basics_one/"},{"categories":["DL"],"content":"23、⭐L1、L2正则化的区别 ✒️L1正则化容易得到稀疏解，即稀疏权值矩阵，L2正则化容易得到平滑解（权值很小）。 ✒️原因：a、解空间角度：二维情况，L1正则化：||w1||+||w2||，则函数图像为图中方框，显然方框的角点容易是最优解，而这些最优解都在坐标轴上，权值为0. b、梯度下降角度 添加正则项 $\\lambda \\theta^2_j$，则L对$\\theta_j$的导数为$2\\lambda \\theta_j$，梯度更新时$\\theta_j=\\theta_j-2 \\lambda \\theta_j=(1-2 \\lambda) \\theta_j$，相当于每次都会乘以一个小于1的数，使得$\\theta_j$越来越小。 ","date":"2024-04-26","objectID":"/posts/dl_basics_one/:0:23","tags":["DL"],"title":"Index","uri":"/posts/dl_basics_one/"},{"categories":["DL"],"content":"24、⭐深度学习花式归一化之Batch/Layer/Instance/Group Normalization ✒️Batch Normalization ⭐核心过程：顾名思义，对一个batch内的数据计算均值和方差，将数据归一化为均值为0、方差为1的正态分布数据，最后用对数据进行缩放和偏移来还原数据本身的分布，如下图所示。 Batch Norm 1d 输入是b*c, 输出是b*c，即在每个维度上进行normalization。 Batch Norm 2d 例如输入是b*c*h*w，则计算normlization时是对每个通道，求bhw内的像素求均值和方差，输出是1*c*1*1。 BN测试时和训练时不同，测试时使用的是全局训练数据的滑动平均的均值和方差。 作用：a、防止过拟合 b、加速网络的收敛，internal covariate shift导致上层网络需要不断适应底层网络带来的分布变化 c、缓解梯度爆炸和梯度消失 局限：依赖于batch size，适用于batch size较大的情况 ✒️改进： Layer normalization: 对每个样本的所有特征进行归一化，如N*C*H*W，对每个C*H*W进行归一化，得到N个均值和方差。 Instance normalization: 对每个样本的每个通道特征进行归一化，如N*C*H*W，对每个H*W进行归一化，得到N*C个均值和方差。 Group normalization：每个样本按通道分组进行归一化，如N*C*H*W，对每个C*H*W，在C维度上分成g组，则共有N*g个均值和方差。 ","date":"2024-04-26","objectID":"/posts/dl_basics_one/:0:24","tags":["DL"],"title":"Index","uri":"/posts/dl_basics_one/"},{"categories":["DL"],"content":"25、⭐深度学习常用优化器介绍 参考https://zhuanlan.zhihu.com/p/261695487，修正了其中的一些错误。 (1)⭐SGD a. ✒️公式 其中$\\alpha$是学习率，$g_t$是当前参数的梯度。 b. ✒️优点：每次只用一个样本更新模型参数，训练速度快。 c. ✒️缺点：容易陷入局部最优；沿陡峭方向振荡，而沿平缓维度进展缓慢，难以迅速收敛 (2) ⭐SGD with momentum a. ✒️公式 其中$m_t$为动量。 b. ✒️优点：可借助动量跳出局部最优点。 c. ✒️缺点：容易在局部最优点里来回振荡。 (3) ⭐AdaGrad：经常更新的参数已经收敛得比较好了，应该减少对它的关注，即降低其学习率；对于不常更新的参数，模型学习的信息过少，应该增加对它的关注，即增大其学习率。 a. ✒️公式 $$w_{t+1}=w_t-\\alpha \\cdot g_t / \\sqrt{V_t}=w_t-\\alpha \\cdot g_t / \\sqrt{\\sum_{\\tau=1}^t g_\\tau^2}$$ 其中Vt是二阶动量，为累计梯度值的平方和，与参数更新频繁程度成正比。 b. ✒️优点：稀疏数据场景下表现好；自适应调节学习率。 c. ✒️缺点：Vt单调递增，使得学习率单调递减为0，从而使得训练过程过早结束。 (4) ⭐RMSProp：AdaGrad的改进版，不累计所有历史梯度，而是过去一段时间窗口内的历史梯度。 a. ✒️公式 $$\\begin{aligned} w_{t+1} \u0026 =w_t-\\alpha \\cdot g_t / \\sqrt{V_t} \\ \u0026 =w_t-\\alpha \\cdot g_t / \\sqrt{\\beta_2 \\cdot V_{t-1}+\\left(1-\\beta_2\\right) g_t^2}\\end{aligned}$$ 即把Vt换成指数移动平均。 b. ✒️优点：避免了二阶动量持续累积、导致训练过程提前结束的问题了。 (5) ⭐Adam：=Adaptive + momentum，即结合了momentum一阶动量+RMSProp二阶动量。 a. ✒️公式 $$\\begin{aligned} w_{t+1} \u0026 =w_t-\\alpha \\cdot m_t / \\sqrt{V_t} \\ \u0026 =w_t-\\alpha \\cdot\\left(\\beta_1 \\cdot m_{t-1}+\\left(1-\\beta_1\\right) \\cdot g_t\\right) / \\sqrt{\\beta_2 \\cdot V_{t-1}+\\left(1-\\beta_2\\right) g_t^2}\\end{aligned}$$ b. ✒️优点：通过一阶动量和二阶动量，有效控制学习率步长和梯度方向，防止梯度的振荡和在鞍点的静止。 c. ✒️缺点：二阶动量是固定历史时间窗口的累积，窗口的变化可能导致Vt振荡，而不是单调变化，从而导致训练后期学习率的振荡，模型不收敛，可通过 来修正，保证学习率单调递减；自适应学习率算法可能会对前期出现的特征过拟合，后期才出现的特征很难纠正前期的拟合效果，从而错过全局最优解。 整理这篇文章不易，喜欢的话可以关注我–\u003e无名氏，某乎和小红薯同名，WX：无名氏的胡言乱语。 定期分享算法笔试、面试干货。 ","date":"2024-04-26","objectID":"/posts/dl_basics_one/:0:25","tags":["DL"],"title":"Index","uri":"/posts/dl_basics_one/"},{"categories":["RL"],"content":"0. 引言 在强化学习(十八) 基于模拟的搜索与蒙特卡罗树搜索(MCTS)中，我们讨论了MCTS的原理和在棋类中的基本应用。这里我们在前一节MCTS的基础上，讨论下DeepMind的AlphaGo Zero强化学习原理。 本篇主要参考了AlphaGo Zero的论文, AlphaGo Zero综述和AlphaGo Zero Cheat Sheet。 1. AlphaGo Zero模型基础 AlphaGo Zero不需要学习人类的棋谱，通过自我对弈完成棋力提高。主要使用了两个模型，第一个就是我们上一节介绍MCTS树结构，另一个是一个神经网络。MCTS上一篇已经有基本介绍了，对于神经网络，它的输入是当前的棋局状态，输出两部分，第一部分输出是在当前棋局状态下各个可能的落子动作对应的获胜概率p，可以简单理解为Actor-Critic策略函数部分。另一部分输出为获胜或者失败的评估[-1,1]，可以简单理解为Actor-Critic价值函数部分。 AlphaGo Zero的行棋主要是由MCTS指导完成的，但是在MCTS搜索的过程中，由于有一些不在树中的状态需要仿真，做局面评估，因此需要一个简单的策略来帮助MCTS评估改进策略，这个策略改进部分由前面提到的神经网络完成。 这两部分的关系如下图所示： AlphaGo Zero 中的MCTS和NN 具体AlphaGo Zero的MCTS如何搜索，神经网络如何训练，如何指导MCTS搜索我们在后面再讲。 2. AlphaGo Zero的训练过程简介 在讨论AlphaGo Zero的MCTS如何搜索，神经网络如何训练等细节之前，我们先看看AlphaGo Zero的训练过程是什么样的。 AlphaGo Zero训练过程主要分为三个阶段：自我对战学习阶段，训练神经网络阶段和评估网络阶段。 自我对战学习阶段主要是AlphaGo Zero自我对弈，产生大量棋局样本的过程，由于AlphaGo Zero并不使用围棋大师的棋局来学习，因此需要自我对弈得到训练数据用于后续神经网络的训练。在自我对战学习阶段，每一步的落子是由MCTS搜索来完成的。在MCTS搜索的过程中，遇到不在树中的状态，则使用神经网络的结果来更新MCTS树结构上保存的内容。在每一次迭代过程中，在每个棋局当前状态 $s$ 下，每一次移动使用1600次MCTS搜索模拟。最终MCTS给出最优的落子策略 $π$ ,这个策略 $π$ 和神经网络的输出 $p$ 是不一样的。当每一局对战结束后，我们可以得到最终的胜负奖励 $z$ ,1或者-1. 这样我们可以得到非常多的样本 $(s,π,z)$,这些数据可以训练神经网络阶段。 在训练神经网络阶段，我们使用自我对战学习阶段得到的样本集合(s,π,z)(�,�,�),训练我们神经网络的模型参数。训练的目的是对于每个输入 $s$, 神经网络输出的 $p,v$和我们训练样本中的 $π$, $z$差距尽可能的少。这个损失函数 $L$ 其实是很简单的： $$L=(z-v)^2-\\pi^Tlog(p)+c||\\theta||^2$$ 损失函数由三部分组成，第一部分是均方误差损失函数，用于评估神经网络预测的胜负结果和真实结果之间的差异。第二部分是交叉熵损失函数，用于评估神经网络的输出策略和我们MCTS输出的策略的差异。第三部分是L2正则化项。 通过训练神经网络，我们可以优化神经网络的参数 $θ$,用于后续指导我们的MCTS搜索过程。 当神经网络训练完毕后，我们就进行了评估阶段，这个阶段主要用于确认神经网络的参数是否得到了优化，这个过程中，自我对战的双方各自使用自己的神经网络指导MCTS搜索，并对战若干局，检验AlphaGo Zero在新神经网络参数下棋力是否得到了提高。除了神经网络的参数不同，这个过程和第一阶段的自我对战学习阶段过程是类似的。 3. AlphaGo Zero的神经网络结构 在第二节我们已经讨论了AlphaGo Zero的主要训练过程，但是还有两块没有讲清楚，一是AlphaGo Zero的MCTS搜索过程是怎么样的，二是AlphaGo Zero的神经网络的结构具体是什么样的。这一节我们来看看AlphaGo Zero的神经网络的细节。 首先我们看看AlphaGo Zero的输入，当前的棋局状态。由于围棋是19x19的361个点组成的棋局，每个点的状态有二种：如果当前是黑方行棋，则当前有黑棋的点取值1，有白棋或者没有棋子的位置取值为0，反过来，如果当前是白方行棋，则当前有白棋的点取值1，有黑棋或者没有棋子的位置取值为0。同时，为了提供更多的信息，输入的棋局状态不光只有当前的棋局状态，包括了黑棋白棋各自前8步对应的棋局状态。除了这16个棋局状态，还有一个单独的棋局状态用于标识当前行棋方，如果是当前黑棋行棋，则棋局状态上标全1，白棋则棋局状态上标全0。如下图所示： Game State 最终神经网络的输入是一个19x19x17的张量。里面包含黑棋和白棋的最近8步行棋状态和当前行棋方的信息。 接着我们看看神经网络的输出，神经网络的输出包括策略部分和价值部分。对于策略部分，它预测当前各个行棋点落子的概率。由于围棋有361个落子点，加上还可以Pass一手，因此一共有362个策略端概率输出。对于价值端，输出就简单了，就是当前局面胜负的评估值，在[-1,1]之间。 看完了神经网络的输入和输出，我们再看看神经网络的结构，主要是用CNN组成的深度残差网络。如下图所示： 在19x19x17的张量做了一个基本的卷积后，使用了19层或者39层的深度残差网络，这个是ResNet的经典结构。理论上这里也可以使用DenseNet等其他流行的网络结构。神经网络的损失函数部分我们在第二节已经将了。整个神经网络就是为了当MCTS遇到没有见过的局面时，提供的当前状态下的局面评估和落子概率参考。这部分信息会被MCTS后续综合利用。 4. AlphaGo Zero的MCTS搜索 现在我们来再看看AlphaGo Zero的MCTS搜索过程，在强化学习(十八) 基于模拟的搜索与蒙特卡罗树搜索(MCTS)里，我们已经介绍了MCTS的基本原理，和4个主要的搜索阶段：选择，扩展，仿真和回溯。和上一篇的内容相比，这里MCTS的不同主要体现在树结构上保存的信息不同，进而UCT的计算公式也稍有不同。最后MCTS搜索完毕后，AlphaGo Zero也有自己选择真正落子点的策略。 在上一篇里，我们的MCTS上保存的数据很简单，就是下的总盘数和赢的总盘数。在AlphaGo Zero这里，我们保存的信息会多一些。主要包括下面的4部分： $N(s,a)$:记录边的访问次数 $W(s,a)$: 合计行动价值 $Q(s,a)$:平均行动价值 $P(s,a)$:选择该条边的先验概率 其中 $s$ 为当前棋局状态，$a$ 为某一落子选择对应的树分支。 有了MCTS上的数据结构，我们看看AlphaGo Zero的MCTS搜索的4个阶段流程： 首先是选择，在MCTS内部，出现过的局面，我们会使用UCT选择子分支。子分支的UCT原理和上一节一样。但是具体的公式稍有不同，如下： $$\\begin{gathered} U(s,a)=c_{puct}P(s,a)\\frac{\\sqrt{\\sum_bN(s,b)}}{1+N(s,a)} \\\\ a_t=\\arg\\max_a(Q(s_t,a)+U(s_t,a)) \\end{gathered}$$ 最终我们会选择 $Q+U$最大的子分支作为搜索分支，一直走到棋局结束，或者走到了没有到终局MCTS的叶子节点。$c_{puct}$是决定探索程度的一个系数,上一篇已讲过。 如果到了没有到终局的MCTS叶子节点，那么我们就需要进入MCTS的第二步，扩展阶段,以及后续的第三步仿真阶段。我们这里一起讲。对于叶子节点状态s�，会利用神经网络对叶子节点做预测，得到当前叶子节点的各个可能的子节点位置sL��落子的概率p�和对应的价值v�,对于这些可能的新节点我们在MCTS中创建出来，初始化其分支上保存的信息为： $$\\{N(s_L,a)=0,W(s_L,a)=0,Q(s_L,a)=0,P(s_L,a)=P_a\\}$$ 这个过程如下图所示： 这样扩展后，之前的叶子节点 $s$，现在就是内部节点了。做完了扩展和仿真后，我们需要进行回溯，将新叶子节点分支的信息回溯累加到祖先节点分支上去。这个回溯的逻辑也是很简单的，从每个叶子节点 $L$ 依次向根节点回溯，并依次更新上层分支数据结构如下： $$\\begin{gathered} N(s_t,a_t)=N(s_t,a_t)+1 \\\\ W(s_t,a_t)=W(s_t,a_t)+v \\\\ Q(s_t,a_t)=\\frac{W(s_t,a_t)}{N(s_t,a_t)} \\end{gathered}$$ 这个MCTS搜索过程在一次真正行棋前，一般会进行约1600次搜索，每次搜索都会进行上述4个阶段。 这上千次MCTS搜索完毕后，AlphaGo Zero就可以在MCTS的根节点 $s$ 基于以下公式选择行棋的MCTS分支了: $$\\pi(a|s)=\\frac{N(s,a)^{1/\\tau}}{\\sum_bN(s,b)^{1/\\tau}}$$ 其中，$τ$ 为温度参数，控制探索的程度，$τ$ 越大，不同走法间差异变小，探索比例增大，反之，则更多选择当前最优操作。每一次完整的自我对弈的前30步，参数 $τ=1$，这是早期鼓励探索的设置。游戏剩下的步数，该参数将逐渐降低至0。如果是比赛，则直接为0. 同时在随后的时间步中，这个MCTS搜索树将会继续使用，对应于实际所采取的行为的","date":"2024-02-25","objectID":"/posts/rl_learning_note_19/:0:0","tags":["RL"],"title":"强化学习笔记 [19] | AlphaGo Zero强化学习原理","uri":"/posts/rl_learning_note_19/"},{"categories":["RL"],"content":" 0. 引言 在强化学习(十七) 基于模型的强化学习与Dyna算法框架中，我们讨论基于模型的强化学习方法的基本思路，以及集合基于模型与不基于模型的强化学习框架Dyna。本文我们讨论另一种非常流行的集合基于模型与不基于模型的强化学习方法：基于模拟的搜索(Simulation Based Search)。 本篇主要参考了UCL强化学习课程的第八讲，第九讲部分。 1. 基于模拟的搜索概述 什么是基于模拟的搜索呢？当然主要是两个点：一个是模拟，一个是搜索。模拟我们在上一篇也讨论过，就是基于强化学习模型进行采样，得到样本数据。但是这是数据不是基于和环境交互获得的真实数据，所以是“模拟”。对于搜索，则是为了利用模拟的样本结果来帮我们计算到底应该采用什么样的动作，以实现我们的长期受益最大化。 那么为什么要进行基于模拟的搜索呢？在这之前我们先看看最简单的前向搜索(forward search)。前向搜索算法从当前我们考虑的状态节点 $S_t$ 开始考虑，怎么考虑呢？对该状态节点所有可能的动作进行扩展，建立一颗以 $S_t$ 为根节点的搜索树，这个搜索树也是一个MDP，只是它是以当前状态为根节点，而不是以起始状态为根节点，所以也叫做sub-MDP。我们求解这个sub-MDP问题，然后得到 $S_t$状态最应该采用的动作 $A_t$。前向搜索的sub-MDP如下图： forward search sub-MDP 前向搜索建立了一个sub-MDP来求解，这很精确，而且这在状态动作数量都很少的时候没有问题，但是只要稍微状态动作数量多一点，每个状态的选择就都特别慢了，因此不太实用，此时基于模拟的搜索就是一种比较好的折衷。 2. 简单蒙特卡罗搜索 首先我们看看基于模拟的搜索中比较简单的一种方法：简单蒙特卡罗搜索。 简单蒙特卡罗搜索基于一个强化学习模型 $M_v$ 和一个模拟策略 $π$.在此基础上，对于当前我们要选择动作的状态 $S_t$, 对每一个可能采样的动作 $a∈A$,都进行 $K$ 轮采样，这样每个动作 $a$ 都会得到 $K$ 组经历完整的状态序列(episode)。即： $$\\{S_t,a,R_{t+1}^k,S_{t+1}^k,A_{t+1}^k,\\ldots\\ldots S_T^k\\}_{k=1}^K\\sim M_v,\\pi $$ 现在对于每个 $(S_t,a)$ 组合，我们可以基于蒙特卡罗法来计算其动作价值函数并选择最优的动作了。 $$\\begin{gathered}Q(S_t,a)=\\frac1K\\sum_{k=1}^KG_t\\\\a_t=\\arg\\max_{a\\in A}Q(S_t,a)\\end{gathered}$$ 简单蒙特卡罗搜索和起前向搜索比起来，对于状态动作数量的处理能力上了一个数量级,可以处理中等规模的问题。但是假如我们的状态动作数量达到非常大的量级，比如围棋的级别,那么简单蒙特卡罗搜索也太慢了。同时，由于使用蒙特卡罗法计算其动作价值函数，模拟采样得到的一些中间状态和对应行为的价值就被忽略了，这部分数据能不能利用起来呢？ 下面我们看看蒙特卡罗树搜索(Monte-Carlo Tree Search，以下简称MCTS)怎么优化这个问题的解决方案。 3. MCTS的原理 MCTS摒弃了简单蒙特卡罗搜索里面对当前状态 $S_t$ 每个动作都要进行K次模拟采样的做法，而是总共对当前状态 $S_t$进行K次采样，这样采样到的动作只是动作全集 $A$ 中的一部分。这样做大大降低了采样的数量和采样后的搜索计算。当然，代价是可能动作全集中的很多动作都没有采样到，可能错失好的动作选择，这是一个算法设计上的折衷。 在MCTS中，基于一个强化学习模型 $M_v$和一个模拟策略$π$，当前状态 $S_t$ 对应的完整的状态序列(episode)是这样的: $$\\{S_t,A_t^k,R_{t+1}^k,S_{t+1}^k,A_{t+1}^k,\\ldots\\ldots S_T^k\\}_{k=1}^K\\sim M_v,\\pi $$ 采样完毕后，我们可以基于采样的结果构建一颗MCTS的搜索树，然后近似计算 $Q(st,a)$和最大 $Q(s_t,a)$对应的动作。 $$\\begin{gathered}Q(S_t,a)=\\frac1{N(S_t,a)}\\sum_{k=1}^K\\sum_{u=t}^T1(S_{uk}=S_t,A_{uk}=a)G_u\\\\a_t=\\arg\\max_{a\\in A}Q(S_t,a)\\end{gathered}$$ MCTS搜索的策略分为两个阶段：第一个是树内策略(tree policy)：为当模拟采样得到的状态存在于当前的MCTS时使用的策略。树内策略可以使 $ϵ−$贪婪策略，随着模拟的进行策略可以得到持续改善，还可以使用上限置信区间算法UCT，这在棋类游戏中很普遍；第二个是默认策略(default policy)：如果当前状态不在MCTS内，使用默认策略来完成整个状态序列的采样，并把当前状态纳入到搜索树中。默认策略可以使随机策略或基于目标价值函数的策略。 这里讲到的是最经典的强化学习终MCTS的用户，每一步都有延时奖励，但是在棋类之类的零和问题中，中间状态是没有明确奖励的，我们只有在棋下完后知道输赢了才能对前面的动作进行状态奖励，对于这类问题我们的MCTS需要做一些结构上的细化。 4. 上限置信区间算法UCT 在讨论棋类游戏的MCTS搜索之前，我们先熟悉下上限置信区间算法(Upper Confidence Bound Applied to Trees, 以下简称UCT)。它是一种策略算法，我们之前最常用的是 $ϵ−$贪婪策略。但是在棋类问题中，UCT更常使用。 在棋类游戏中，经常有这样的问题，我们发现在某种棋的状态下，有2个可选动作，第一个动作历史棋局中是0胜1负，第二个动作历史棋局中是8胜10负，那么我们应该选择哪个动作好呢？如果按 $ϵ−$贪婪策略，则第二个动作非常容易被选择到。但是其实虽然第一个动作胜利0%，但是很可能是因为这个动作的历史棋局少，数据不够导致的，很可能该动作也是一个不错的动作。那么我们如何在最优策略和探索度达到一个选择平衡呢？ $ϵ−$贪婪策略可以用，但是UCT是一个更不错的选择。 UCT首先计算每一个可选动作节点对应的分数，这个分数考虑了历史最优策略和探索度吗，一个常用的公式如下： $$\\text{score}=\\left.\\frac{w_i}{n_i}+c\\sqrt{\\frac{\\ln N_i}{n_i}}\\right.$$ 其中，$w_i$ 是 i 节点的胜利次数，$n_i$ 是i节点的模拟次数，$N_i$ 是所有模拟次数，c 是探索常数，理论值为$√2$，可根据经验调整，$c$ 越大就越偏向于广度搜索，$c$ 越小就越偏向于深度搜索。最后我们选择分数最高的动作节点。 比如对于下面的棋局，对于根节点来说，有3个选择，第一个选择7胜3负，第二个选择5胜3负，第三个选择0胜3负。 如果我们取c=10,则第一个节点的分数为：$$score(7,10)=7/10+C\\cdot\\sqrt{\\frac{\\log(21)}{10}}\\approx6.2$$ 第二个节点的分数为：$$score(5,8)=5/8+C\\cdot\\sqrt{\\frac{\\log(21)}8}\\approx6.8$$ 第三个节点的分数为：$$score(0,3)=0/3+C\\cdot\\sqrt{\\frac{\\log(21)}3}\\approx10$$ 可见，由于我们把探索率 $c$ 设置的比较大，第三个节点是被UCT选中要执行的动作节点。当然如果我们把c设置的比较小的话，第一个或者第二个可能就变成最大的分数了。 5. 棋类游戏MCTS搜索 在像中国象棋，围棋这样的零和问题中，一个动作只有在棋局结束才能拿到真正的奖励，因此我们对MCTS的搜索步骤和树结构上需要根据问题的不同做一些细化。 对于MCTS的树结构，如果是最简单的方法，只需要在节点上保存状态对应的历史胜负记录。在每条边上保存采样的动作。这样MCTS的搜索需要走4步，如下图(图来自维基百科)： BP Network 第一步是选择(Selection):这一步会从根节点开始，每次都选一个“最值得搜索的子节点”，一般使用UCT选择分数最高的节点，直到来到一个“存在未扩展的子节点”的节点，如图中的 3/3 节点。之所以叫做“存在未扩展的子节点”，是因为这个局面存在未走过的后续着法，也就是MCTS中没有后续的动作可以参考了。这时我们进入第二步。 第二步是扩展(Expansion)，在这个搜索到的存在未扩展的子节点，加上一个0/0的子节点，表示没有历史记录参考。这时我们进入第三步。 第三步是仿真(simulation)，从上面这个没有试过的着法开始，用一个简单策略比如快速走子策略（Rollout policy）走到底，得到一个胜负结果。快速走子策略一般适合选择走子很快可能不是很精确的策略。因为如果这个策略走得慢，结果虽然会更准确，但由于耗时多了，在单位时间内的模拟次数就少了，所以不一定会棋力更强，有可能会更弱。这也是为什么我们一般只模拟一次，因为如果模拟多次，虽然更准确，但更慢。 第四步是回溯(backpropagation), 将我们最后得到的胜负结果回溯加到MCTS树结构上。注意除了之前的MCTS树要回溯外，新加入的节点也要加上一次胜负历史记录，如上图最右边所示。 以上就是MCTS搜索的整个过程。这4步一般是通用的，但是MCTS树结构上保存的内容而一般根据要解决的问题和建模的复杂度而不同。 6. MCTS小结","date":"2024-02-25","objectID":"/posts/rl_learning_note_18/:0:0","tags":["RL"],"title":"强化学习笔记 [18] | 基于模拟的搜索与蒙特卡罗树搜索(MCTS)","uri":"/posts/rl_learning_note_18/"},{"categories":["RL"],"content":"强化学习(十七) 基于模型的强化学习与Dyna算法框架 在前面我们讨论了基于价值的强化学习(Value Based RL)和基于策略的强化学习模型(Policy Based RL)，本篇我们讨论最后一种强化学习流派，基于模型的强化学习(Model Based RL)，以及基于模型的强化学习算法框架Dyna。 本篇主要参考了UCL强化学习课程的第8讲和Dyna-2的论文。 1. 基于模型的强化学习简介 基于价值的强化学习模型和基于策略的强化学习模型都不是基于模型的，它们从价值函数，策略函数中直接去学习，不用学习环境的状态转化概率模型，即在状态 $s$ 下采取动作 $a$,转到下一个状态 $s’$ 的概率 $P^a_{ss’}$。 而基于模型的强化学习则会尝试从环境的模型去学习，一般是下面两个相互独立的模型： 一个是状态转化预测模型，输入当前状态 $s$和动作 $a$，预测下一个状态 $s’$。 另一个是奖励预测模型，输入当前状态 $s$和动作 $a$，预测环境的奖励 $r$。 即模型可以描述为下面两个式子： $$\\begin{gathered}S_{t+1}\\sim P(S_{t+1}|S_t,A_t)\\\\R_{t+1}\\sim R(R_{t+1}|S_t,A_t)\\end{gathered}$$ 如果模型 $P$, $R$ 可以准确的描述真正的环境的转化模型，那么我们就可以基于模型来预测，当有一个新的状态 $S$ 和动作 $A$到来时，我们可以直接基于模型预测得到新的状态和动作奖励，不需要和环境交互。当然如果我们的模型不好，那么基于模型预测的新状态和动作奖励可能错的离谱。 从上面的描述我们可以看出基于模型的强化学习和不基于模型的强化学习的主要区别：即基于模型的强化学习是从模型中学习，而不基于模型的强化学习是从和环境交互的经历去学习。 下面这张图描述了基于模型的强化学习的思路： Model-based RL 2. 基于模型的强化学习算法训练流程 这里我们看看基于模型的强化学习算法训练流程，其流程和我们监督学习算法是非常类似的。 假设训练数据是若干组这样的经历： $$S_1,A_1,R_2,S_2,A_2,R_2,\\ldots,S_T$$ 对于每组经历，我们可以将其转化为 $T−1$ 组训练样本，即： $$\\begin{gathered} S_1,A_1\\to S_2,S_1,A_1\\to R_2 \\\\ S_2,A_2\\to S_3,S_2,A_2\\to R_3 \\\\ …… \\\\ S_{T-1},A_{T-1}\\rightarrow S_T,~S_{T_1},A_{T-1}\\rightarrow R_T \\end{gathered}$$ 右边的训练样本一起组成了一个分类模型或密度估计模型，输入状态和动作，输出下一个状态。 右边的训练样本一起组成了一个回归模型训练集，输入状态和动作，输出动作奖励值。 至此我们的强化学习求解过程和传统的监督学习算法没有太多区别了，可以使用传统的监督学习算法来求解这两个模型。 当然还可以更简单，即通过对训练样本进行查表法进行统计，直接得到 $P(S_{t+1}|S_t,A_t)$ 的概率和 $R(R_{t+1}|S_t,A_t)$ 的平均值，这样就可以直接预测。比使用模型更简单。 此外，还有其他的方法可以用来得到 $P(S_{t+1}|S_t,A_t)$和 $R(R_{t+1}|S_t,A_t)$，这个我们后面再讲。 虽然基于模型的强化学习思路很清晰，而且还有不要和环境持续交互优化的优点，但是用于实际产品还是有很多差距的。主要是我们的模型绝大多数时候不能准确的描述真正的环境的转化模型，那么使用基于模型的强化学习算法得到的解大多数时候也不是很实用。那么是不是基于模型的强化学习就不能用了呢？也不是，我们可以将基于模型的强化学习和不基于模型的强化学习集合起来，取长补短，这样做最常见的就是Dyna算法框架。 3. Dyna算法框架 Dyna算法框架并不是一个具体的强化学习算法，而是一类算法框架的总称。Dyna将基于模型的强化学习和不基于模型的强化学习集合起来，既从模型中学习，也从和环境交互的经历去学习，从而更新价值函数和（或）策略函数。如果用和第一节类似的图，可以表示如下图，和第一节的图相比，多了一个“Direct RL“的箭头，这正是不基于模型的强化学习的思路。 Dyna算法示意图 Dyna算法框架和不同的具体的不基于模型的强化学习一起，可以得到具体的不同算法。如果我们使用基于价值函数的Q-Learning，那么我们就得到了Dyna-Q算法。我们基于Dyna-Q来看看Dyna算法框架的一般流程. 4. Dyna-Q算法流程 这里我们给出基于价值函数的Dyna-Q算法的概要流程。假设模型使用的是查表法。 (1). 初始化任意一个状态 $s$,和任意一个动作 $a$ 对应的状态价值 $Q(s,a)$, 初始化奖励模型 $R(s,a)$和状态模型 $P(s,a)$ (2). for $i=1$ to 最大迭代次数T： (a) $S \\leftarrow \\text{current state}$ (b) $A \\leftarrow \\text{ϵ−greedy(S,Q)}$ (c) 执行动作 $A$,得到新状态 $S’$ 和奖励 $R$ (d) 使用Q-Learning更新价值函数：$Q(S,A)=Q(S,A)+\\alpha[R+\\gamma\\max_aQ(S^{\\prime},a)-Q(S,A)]$ (e) 使用 $S,A,S^{\\prime}$ 更新状态模型 $P(s,a)$，使用 $S,A,R$ 更新状态模型 $R(s,a)$ (f) $\\text{for} \\space \\space j=1 \\space \\space \\text{to} \\text{最大次数}n$： (i) 随机选择一个之前出现过的状态 $S$ , 在状态 $S$ 上出现过的动作中随机选择一个动作 $A$ (ii) 基于模型 $P(S,A)$ 得到 $S’$, 基于模型 $R(S,A)$ 得到 $R$ (iii) 使用Q-Learning更新价值函数: $Q(S,A)=Q(S,A)+\\alpha[R+\\gamma\\max_aQ(S^{\\prime},a)-Q(S,A)]$ 从上面的流程可以看出，Dyna框架在每个迭代轮中，会先和环境交互，并更新价值函数和（或）策略函数，接着进行n次模型的预测，同样更新价值函数和（或）策略函数。这样同时利用上了和环境交互的经历以及模型的预测。 5. Dyna-2算法框架 在Dyna算法框架的基础上后来又发展出了Dyna-2算法框架。和Dyna相比，Dyna-2将和和环境交互的经历以及模型的预测这两部分使用进行了分离。还是以Q函数为例，Dyna-2将记忆分为永久性记忆（permanent memory）和瞬时记忆（transient memory）, 其中永久性记忆利用实际的经验来更新，瞬时记忆利用模型模拟经验来更新。 永久性记忆的Q函数定义为： $$Q(S,A)=\\phi(S,A)^T\\theta $$ 瞬时记忆的Q函数定义为： $$Q^{\\prime}(S,A)=\\overline{\\phi}(S,A)^T\\overline{\\theta}$$ 组合起来后记忆的Q函数定义为： $$\\overline{Q}(S,A)=\\phi(S,A)^T\\theta+\\overline{\\phi}(S,A)^T\\overline{\\theta}$$ Dyna-2的基本思想是在选择实际的执行动作前，智能体先执行一遍从当前状态开始的基于模型的模拟，该模拟将仿真完整的轨迹，以便评估当前的动作值函数。智能体会根据模拟得到的动作值函数加上实际经验得到的值函数共同选择实际要执行的动作。价值函数的更新方式类似于 $SARSA(λ)$ 以下是Dyna-2的算法流程： Dyna-2 算法流程 6. 基于模型的强化学习总结 基于模型的强化学习一般不单独使用，而是和不基于模型的强化学习结合起来，因此使用Dyna算法框架是常用的做法。对于模型部分，我们可以用查表法和监督学习法等方法，预测或者采样得到模拟的经历。而对于非模型部分，使用前面的Q-Learning系列的价值函数近似，或者基于Actor-Critic的策略函数的近似都是可以的。 除了Dyna算法框架，我们还可以使用基于模拟的搜索(simulation-based search)来结合基于模型的强化学习和不基于模型的强化学习,并求解问题。这部分我们在后面再讨论。 ","date":"2024-02-25","objectID":"/posts/rl_learning_note_17/:0:0","tags":["RL"],"title":"强化学习笔记 [17] | 基于模型的强化学习与Dyna算法框架","uri":"/posts/rl_learning_note_17/"},{"categories":["RL"],"content":"0. 引言 在强化学习(十五) A3C中，我们讨论了使用多线程的方法来解决Actor-Critic难收敛的问题，今天我们不使用多线程，而是使用和DDQN类似的方法：即经验回放和双网络的方法来改进Actor-Critic难收敛的问题，这个算法就是是深度确定性策略梯度(Deep Deterministic Policy Gradient，以下简称DDPG)。 本篇主要参考了DDPG的论文和ICML 2016的deep RL tutorial。 1. 从随机策略到确定性策略 从DDPG这个名字看，它是由D（Deep）+D（Deterministic ）+ PG(Policy Gradient)组成。PG(Policy Gradient)我们在强化学习(十三) 策略梯度(Policy Gradient)里已经讨论过。那什么是确定性策略梯度(Deterministic Policy Gradient，以下简称DPG)呢？ 确定性策略是和随机策略相对而言的，对于某一些动作集合来说，它可能是连续值，或者非常高维的离散值，这样动作的空间维度极大。如果我们使用随机策略，即像DQN一样研究它所有的可能动作的概率，并计算各个可能的动作的价值的话，那需要的样本量是非常大才可行的。于是有人就想出使用确定性策略来简化这个问题。 作为随机策略，在相同的策略，在同一个状态处，采用的动作是基于一个概率分布的，即是不确定的。而确定性策略则决定简单点，虽然在同一个状态处，采用的动作概率不同，但是最大概率只有一个，如果我们只取最大概率的动作，去掉这个概率分布，那么就简单多了。即作为确定性策略，相同的策略，在同一个状态处，动作是唯一确定的，即策略变成： $$\\pi_\\theta(s)=a$$ 2. 从DPG到DDPG 在看确定性策略梯度DPG前，我们看看基于Q值的随机性策略梯度的梯度计算公式： $$\\nabla_\\theta J(\\pi_\\theta)=E_{s\\sim\\rho^\\pi,a\\sim\\pi_\\theta}[\\nabla_\\theta log\\pi_\\theta(s,a)Q_\\pi(s,a)]$$ 其中状态的采样空间为$\\rho^\\pi$, $\\nabla_\\theta log\\pi_\\theta(s,a)$是分值函数，可见随机性策略梯度需要在整个动作的空间$\\pi_\\mathrm{\\theta}$进行采样。 而DPG基于Q值的确定性策略梯度的梯度计算公式是： $$\\nabla_\\theta J(\\pi_\\theta)=E_{s\\sim\\rho^\\pi}[\\nabla_\\theta\\pi_\\theta(s)\\nabla_aQ_\\pi(s,a)|{a=\\pi\\theta(s)}]$$ 跟随机策略梯度的式子相比，少了对动作的积分，多了回报Q函数对动作的导数。 而从DPG到DDPG的过程，完全可以类比DQN到DDQN的过程。除了老生常谈的经验回放以外，我们有了双网络，即当前网络和目标网络的概念。而由于现在我们本来就有Actor网络和Critic两个网络，那么双网络后就变成了4个网络，分别是：Actor当前网络，Actor目标网络，Critic当前网络，Critic目标网络。2个Actor网络的结构相同，2个Critic网络的结构相同。那么这4个网络的功能各自是什么呢？ 3. DDPG的原理 DDPG有4个网络，在了解这4个网络的功能之前，我们先复习DDQN的两个网络：当前Q网络和目标Q网络的作用。可以复习强化学习（十）Double DQN (DDQN)。 DDQN的当前Q网络负责对当前状态 $S$ 使用 $ϵ$−贪婪法选择动作 $A$，执行动作 $A$,获得新状态 $S’$和奖励$R$,将样本放入经验回放池，对经验回放池中采样的下一状态 $S’$使用贪婪法选择动作 $A’$，供目标Q网络计算目标Q值，当目标Q网络计算出目标Q值后，当前Q网络会进行网络参数的更新，并定期把最新网络参数复制到目标Q网络。 DDQN的目标Q网络则负责基于经验回放池计算目标Q值, 提供给当前Q网络用，目标Q网络会定期从当前Q网络复制最新网络参数。 现在我们回到DDPG，作为DDPG，Critic当前网络，Critic目标网络和DDQN的当前Q网络，目标Q网络的功能定位基本类似，但是我们有自己的Actor策略网络，因此不需要 $ϵ$−贪婪法这样的选择方法，这部分DDQN的功能到了DDPG可以在Actor当前网络完成。而对经验回放池中采样的下一状态 $S’$ 使用贪婪法选择动作 $A’$，这部分工作由于用来估计目标Q值，因此可以放到Actor目标网络完成。 基于经验回放池和目标Actor网络提供的 $S’$, $A’$ 计算目标Q值的一部分，这部分由于是评估，因此还是放到Critic目标网络完成。而Critic目标网络计算出目标Q值一部分后，Critic当前网络会计算目标Q值，并进行网络参数的更新，并定期将网络参数复制到Critic目标网络。 此外，Actor当前网络也会基于Critic当前网络计算出的目标Q值，进行网络参数的更新，并定期将网络参数复制到Actor目标网络。 有了上面的思路，我们总结下DDPG 4个网络的功能定位： (1). Actor当前网络: 负责策略网络参数 $θ$的迭代更新，负责根据当前状态 $S$选择当前动作 $A$，用于和环境交互生成 $S’$, $R$。 (2). Actor目标网络: 负责根据经验回放池中采样的下一状态 $S’$ 选择最优下一动作$A’$。网络参数 $θ’$定期从 $θ$复制。 (3). Critic当前网络: 负责价值网络参数 $w$的迭代更新，负责计算负责计算当前Q值 $Q(S,A,w)$。目标Q值$y_i=R+γQ’(S’,A’,w’)$ (4). Critic目标网络: 负责计算目标Q值中的 $Q’(S’,A’,w’)$部分。网络参数 $w’$ 定期从 $w$复制。 DDPG除了这4个网络结构，还用到了经验回放，这部分用于计算目标Q值，和DQN没有什么区别，这里就不展开了。 此外，DDPG从当前网络到目标网络的复制和我们之前讲到了DQN不一样。回想DQN，我们是直接把将当前Q网络的参数复制到目标Q网络，即$w$′=$w$, DDPG这里没有使用这种硬更新，而是使用了软更新，即每次参数只更新一点点，即： $$\\begin{gathered} w’\\leftarrow\\tau w+(1-\\tau)w’ \\ \\theta’\\leftarrow\\tau\\theta+(1-\\tau)\\theta' \\end{gathered}$$ 其中 $τ$是更新系数，一般取的比较小，比如0.1或者0.01这样的值。 同时，为了学习过程可以增加一些随机性，增加学习的覆盖，DDPG对选择出来的动作 $A$会增加一定的噪声 $N$, 即最终和环境交互的动作 $A$ 的表达式是： $$A=\\pi_\\theta(S)+\\mathcal{N}$$ 最后，我们来看看DDPG的损失函数。对于Critic当前网络，其损失函数和DQN是类似的，都是均方误差，即： $$J(w)=\\frac1m\\sum_{j=1}^m(y_j-Q(\\phi(S_j),A_j,w))^2$$ 而对于 Actor当前网络，其损失函数就和之前讲的PG，A3C不同了，这里由于是确定性策略，原论文定义的损失梯度是： $$\\nabla_J(\\theta)=\\frac1m\\sum_{j=1}^m[\\nabla_aQ_(s_i,a_i,w)|{s=s_i,a=\\pi\\theta(s)}\\nabla_\\theta\\pi_{\\theta(s)}|_{s=s_i}]$$ 这个可以对应上我们第二节的确定性策略梯度，看起来比较麻烦，但是其实理解起来很简单。假如对同一个状态，我们输出了两个不同的动作 $a_1$和$a_2$，从Critic当前网络得到了两个反馈的 $Q$ 值，分别是 $Q_1$,$Q_2$，假设 $Q_1\u003eQ_2$,即采取动作1可以得到更多的奖励，那么策略梯度的思想是什么呢，就是增加 $a_1$的概率，降低$a_2$的概率，也就是说，Actor想要尽可能的得到更大的Q值。所以我们的Actor的损失可以简单的理解为得到的反馈Q值越大损失越小，得到的反馈Q值越小损失越大，因此只要对状态估计网络返回的Q值取个负号即可，即： $$J(\\theta)=-\\frac1m\\sum_{j=1}^mQ_(s_i,a_i,w)$$ 4. DDPG算法流程 这里我们总结下DDPG的算法流程 输入：Actor当前网络，Actor目标网络，Critic当前网络，Critic目标网络,参数分别为 $θ$,$θ’$,$w$,$w’$,衰减因子 $γ$, 软更新系数 $τ$, 批量梯度下降的样本数 $m$,目标Q网络参数更新频率 $C$。最大迭代次数 $T$。随机噪音函数 $\\mathcal{N}$ 输出：最优Actor当前网络参数 $θ$,Critic当前网络参数 $w$ (1). 随机初始化$θ$,$w$, $w$′=$w$,$θ$′=$θ$。清空经验回放的集合$D$ (2). for i from 1 to T，进行迭代。 a) 初始化 $S$为当前状态序列的第一个状态, 拿到其特征向量 $ϕ(S)$ b) 在Actor当前网络基于状态 $S$ 得到动作 $A=π_θ(ϕ(S))+\\mathcal{N}$ c) 执行动作$A$,得到新状态$S$′,奖励$R$,是否终止状态%is_end$ d) 将 ${ϕ(S), A, R, ϕ(S’), is_end}$","date":"2024-02-25","objectID":"/posts/rl_learning_note_16/:0:0","tags":["RL"],"title":"强化学习笔记 [16] | 深度确定性策略梯度(DDPG)","uri":"/posts/rl_learning_note_16/"},{"categories":["RL"],"content":"0. 引言 在强化学习(十四) Actor-Critic中，我们讨论了Actor-Critic的算法流程，但是由于普通的Actor-Critic算法难以收敛，需要一些其他的优化。而Asynchronous Advantage Actor-critic(以下简称A3C)就是其中比较好的优化算法。本文我们讨论A3C的算法原理和算法流程。 本文主要参考了A3C的论文，以及ICML 2016的deep RL tutorial。 1. A3C的引入 上一篇Actor-Critic算法的代码，其实很难收敛，无论怎么调参，最后的CartPole都很难稳定在200分，这是Actor-Critic算法的问题。但是我们还是有办法去有优化这个难以收敛的问题的。 回忆下之前的DQN算法，为了方便收敛使用了经验回放的技巧。那么我们的Actor-Critic是不是也可以使用经验回放的技巧呢？当然可以！不过A3C更进一步，还克服了一些经验回放的问题。经验回放有什么问题呢？ 回放池经验数据相关性太强，用于训练的时候效果很可能不佳。举个例子，我们学习下棋，总是和同一个人下，期望能提高棋艺。这当然没有问题，但是到一定程度就再难提高了，此时最好的方法是另寻高手切磋。 A3C的思路也是如此，它利用多线程的方法，同时在多个线程里面分别和环境进行交互学习，每个线程都把学习的成果汇总起来，整理保存在一个公共的地方。并且，定期从公共的地方把大家的齐心学习的成果拿回来，指导自己和环境后面的学习交互。 通过这种方法，A3C避免了经验回放相关性过强的问题，同时做到了异步并发的学习模型。 2. A3C的算法优化 现在我们来看看相比Actor-Critic，A3C到底做了哪些具体的优化。 相比Actor-Critic，A3C的优化主要有3点，分别是异步训练框架，网络结构优化，Critic评估点的优化。其中异步训练框架是最大的优化。 我们首先来看这个异步训练框架，如下图所示： 异步训练框架 图中上面的Global Network就是上一节说的共享的公共部分，主要是一个公共的神经网络模型，这个神经网络包括Actor网络和Critic网络两部分的功能。下面有n个worker线程，每个线程里有和公共的神经网络一样的网络结构，每个线程会独立的和环境进行交互得到经验数据，这些线程之间互不干扰，独立运行。 每个线程和环境交互到一定量的数据后，就计算在自己线程里的神经网络损失函数的梯度，但是这些梯度却并不更新自己线程里的神经网络，而是去更新公共的神经网络。也就是n个线程会独立的使用累积的梯度分别更新公共部分的神经网络模型参数。每隔一段时间，线程会将自己的神经网络的参数更新为公共神经网络的参数，进而指导后面的环境交互。 可见，公共部分的网络模型就是我们要学习的模型，而线程里的网络模型主要是用于和环境交互使用的，这些线程里的模型可以帮助线程更好的和环境交互，拿到高质量的数据帮助模型更快收敛。 现在我们来看看第二个优化，网络结构的优化。之前在强化学习(十四) Actor-Critic中，我们使用了两个不同的网络Actor和Critic。在A3C这里，我们把两个网络放到了一起，即输入状态 $S$,可以输出状态价值 $V$,和对应的策略 $π$, 当然，我们仍然可以把Actor和Critic看做独立的两块，分别处理，如下图所示： 把Actor和Critic看做独立的两块，分别处理 第三个优化点是Critic评估点的优化，在强化学习(十四) Actor-Critic第2节中，我们讨论了不同的Critic评估点的选择，其中d部分讲到了使用优势函数 $A$ 来做Critic评估点，优势函数 $A$ 在时刻t不考虑参数的默认表达式为： $$A(S,A,t)=Q(S,A)-V(S)$$ $Q(S,A)$的值一般可以通过单步采样近似估计，即： $$Q(S,A)=R+\\gamma V(S^{\\prime})$$ 这样优势函数去掉动作可以表达为： $$A(S,t)=R+\\gamma V(S^{\\prime})-V(S)$$ 其中 $V(S)$的值需要通过Critic网络来学习得到。 在A3C中，采样更进一步，使用了N步采样，以加速收敛。这样A3C中使用的优势函数表达为： $$A(S,t)=R_t++\\gamma R_{t+1}+\\ldots\\gamma^{n-1}R_{t+n-1}+\\gamma^nV(S^{\\prime})-V(S)$$ 对于Actor和Critic的损失函数部分，和Actor-Critic基本相同。有一个小的优化点就是在Actor-Critic策略函数的损失函数中，加入了策略 $π$ 的熵项,系数为 $c$, 即策略参数的梯度更新和Actor-Critic相比变成了这样： $$\\theta=\\theta+\\alpha\\nabla_\\theta log\\pi_\\theta(s_t,a_t)A(S,t)+c\\nabla_\\theta H(\\pi(S_t,\\theta))$$ 以上就是A3C和Actor-Critic相比有优化的部分。下面我们来总价下A3C的算法流程。 3. A3C算法流程 这里我们对A3C算法流程做一个总结，由于A3C是异步多线程的，我们这里给出任意一个线程的算法流程。 输入：公共部分的A3C神经网络结构，对应参数位 $θ$ , $w$，本线程的A3C神经网络结构，对应参数 $θ’$, $w’$, 全局共享的迭代轮数 $T$，全局最大迭代次数 $T_{max}$, 线程内单次迭代时间序列最大长度 $T_{local}$,状态特征维度 $n$, 动作集 $A$, 步长 $α$, $β$，熵系数 $c$, 衰减因子 $γ$ 输出：公共部分的A3C神经网络参数 $θ$, $w$ (1). 更新时间序列 $t=1$ (2). 重置Actor和Critic的梯度更新量: $dθ←0$,$dw←0$ (3). 从公共部分的A3C神经网络同步参数到本线程的神经网络：$θ’=θ,w’=w$ (4). $t_{start}=t$，初始化状态 $s_t$ (5). 基于策略 $π(at|st;θ)$ 选择出动作 $a_t$ (6). 执行动作 $a_t$得到奖励 $r_t$ 和新状态 $s_{t+1}$ (7). $t←t+1$, $T←T+1$ (8). 如果 $s_t$是终止状态，或 $t − t_{start}==t_{local}$,则进入步骤(9)，否则回到步骤(5) (9). 计算最后一个时间序列位置 $s_t$的 $Q(s,t)$: $$\\left.Q(s,t)=\\left\\{\\begin{array}{ll}0\u0026terminal~state\\\\V(s_t,w^{\\prime})\u0026none~terminal~state,bootstrapping\\end{array}\\right.\\right.$$ (10). for $i∈(t−1,t−2,…t_{start})$: 1). 计算每个时刻的$Q(s,i)$： $Q(s,i)=r_i+\\gamma Q(s,i+1)$ 2). 累计Actor的本地梯度更新： $$d\\theta\\leftarrow d\\theta+\\nabla_{\\theta^{\\prime}}log\\pi_{\\theta^{\\prime}}(s_i,a_i)(Q(s,i)-V(S_i,w^{\\prime}))+c\\nabla_{\\theta^{\\prime}}H(\\pi(s_i,\\theta^{\\prime}))$$ 3). 累计Critic的本地梯度更新： $$\\begin{aligned}dw\u0026\\leftarrow dw+\\frac{\\partial(Q(s,i)-V(S_i,w^{\\prime}))^2}{\\partial w^{\\prime}}\\end{aligned}$$ (11). 更新全局神经网络的模型参数： $$\\theta=\\theta+\\alpha d\\theta,~w=w-\\beta dw$$ (12). 如果 $T\u003eT_{max}$,则算法结束，输出公共部分的A3C神经网络参数 $θ$, $w$,否则进入步骤(3) 以上就是A3C算法单个线程的算法流程。 4. A3C算法实例 下面我们基于上述算法流程给出A3C算法实例。仍然使用了OpenAI Gym中的CartPole-v0游戏来作为我们算法应用。CartPole-v0游戏的介绍参见这里。它比较简单，基本要求就是控制下面的cart移动使连接在上面的pole保持垂直不倒。这个任务只有两个离散动作，要么向左用力，要么向右用力。而state状态就是这个cart的位置和速度， pole的角度和角速度，4维的特征。坚持到200分的奖励则为过关。 算法代码大部分参考了莫烦的A3C代码，增加了模型测试部分的代码并调整了部分模型参数。完整的代码参见我的Github：https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/a3c.py 整个算法的Actor和Critic的网络结构都定义在这里， 所有的线程中的网络结构，公共部分的网络结构都在这里定义。 def _build_net(self, scope): w_init = tf.random_normal_initializer(0., .1) with tf.variable_scope('actor'): l_a = tf.layers.dense(self.s, 200, tf.nn.rel","date":"2024-02-25","objectID":"/posts/rl_learning_note_15/:0:0","tags":["RL"],"title":"强化学习笔记 [15] | A3C","uri":"/posts/rl_learning_note_15/"},{"categories":["RL"],"content":" 0. 引言 在强化学习(十三) 策略梯度(Policy Gradient)中，我们讲到了基于策略(Policy Based)的强化学习方法的基本思路，并讨论了蒙特卡罗策略梯度reinforce算法。但是由于该算法需要完整的状态序列，同时单独对策略函数进行迭代更新，不太容易收敛。 在本篇我们讨论策略(Policy Based)和价值(Value Based)相结合的方法：Actor-Critic算法。 本文主要参考了Sutton的强化学习书第13章和UCL强化学习讲义的第7讲。 1. Actor-Critic算法简介 Actor-Critic从名字上看包括两部分，演员(Actor)和评价者(Critic)。其中Actor使用我们上一节讲到的策略函数，负责生成动作(Action)并和环境交互。而Critic使用我们之前讲到了的价值函数，负责评估Actor的表现，并指导Actor下一阶段的动作。 回想我们上一篇的策略梯度，策略函数就是我们的Actor，但是那里是没有Critic的，我们当时使用了蒙特卡罗法来计算每一步的价值部分替代了Critic的功能，但是场景比较受限。因此现在我们使用类似DQN中用的价值函数来替代蒙特卡罗法，作为一个比较通用的Critic。 也就是说在Actor-Critic算法中，我们需要做两组近似，第一组是策略函数的近似： $$ \\pi_\\theta(s,a)=P(a|s,\\theta)\\approx\\pi(a|s) $$ 第二组是价值函数的近似，对于状态价值和动作价值函数分别是： $$ \\hat{v}(s,w)\\approx v_\\pi(s) $$ $$ \\hat{q}(s,a,w)\\approx q_\\pi(s,a) $$ 对于我们上一节讲到的蒙特卡罗策略梯度reinforce算法，我们需要进行改造才能变成Actor-Critic算法。首先，在蒙特卡罗策略梯度reinforce算法中，我们的策略的参数更新公式是： $$ \\theta=\\theta+\\alpha\\nabla_\\theta log\\pi_\\theta(s_t,a_t)v_t $$ 梯度更新部分中，$\\nabla_\\theta log\\pi_\\theta(s_t,a_t)$是我们的分值函数，不用动，要变成Actor的话改动的是$v_t$，这块不能再使用蒙特卡罗法来得到，而应该从Critic得到。 而对于Critic来说，这块是新的，不过我们完全可以参考之前DQN的做法，即用一个Q网络来做为Critic，这个Q网络的输入可以是状态，而输出是每个动作的价值或者最优动作的价值。 现在我们汇总来说，就是Critic通过Q网络计算状态的最优价值$v_t$,而Actor利用$v_t$这个最优价值迭代更新策略函数的参数$\\theta$,进而选择动作，并得到反馈和新的状态，Critic使用反馈和新的状态更新Q网络参数$w$,在后面Critic会使用新的网络参数$w$来帮Actor计算状态的最优价值$v_{te}$ 2. Actor-Critic算法可选形式 在上一节我们已经对Actor-Critic算法的流程做了一个初步的总结，不过有一个可以注意的点就是，我们对于Critic评估的点选择是和上一篇策略梯度一样的状态价值 $v_t$实际上，我们还可以选择很多其他的指标来做为Critic的评估点。而目前可以使用的Actor-Critic评估点主要有： a) 基于状态价值：这是我们上一节使用的评估点，这样Actor的策略函数参数更新的法公式是： $$\\theta=\\theta+\\alpha\\nabla_\\theta log\\pi_\\theta(s_t,a_t)V(s,w)$$ b) 基于动作价值：在DQN中，我们一般使用的都是动作价值函数Q来做价值评估，这样Actor的策略函数参数更新的法公式是： $$\\theta=\\theta+\\alpha\\nabla_\\theta log\\pi_\\theta(s_t,a_t)Q(s,a,w)$$ c) 基于TD误差：在强化学习（五）用时序差分法（TD）求解中，我们讲到了TD误差，它的表达式是 $\\delta(t)=R_{t+1}+\\gamma V(S_{t+1})-V(S_t)$ 或者 $\\delta(t)=R_{t+1}+\\gamma Q(S_{t+1}\\text{,}A_{t+1})-Q(S_t,A_t)$, 这样Actor的策略函数参数更新的法公式是： $$\\theta=\\theta+\\alpha\\nabla_\\theta log\\pi_\\theta(s_t,a_t)\\delta(t)$$ d) 基于优势函数：在强化学习(十二) Dueling DQN中，我们讲到过优势函数A的定义：$A(S,A,w,\\beta)=Q(S,A,w,\\alpha,\\beta)-V(S,w,\\alpha)$, 即动作价值函数和状态价值函数的差值。这样Actor的策略函数参数更新的法公式是： $$\\theta=\\theta+\\alpha\\nabla_\\theta log\\pi_\\theta(s_t,a_t)A(S,A,w,\\beta)$$ e) 基于 $TD(λ)$ 误差：一般都是基于后向 $TD(λ)$误差, 在强化学习（五）用时序差分法（TD）求解中也有讲到，是TD误差和效用迹E的乘积。这样Actor的策略函数参数更新的法公式是： $\\theta=\\theta+\\alpha\\nabla_\\theta log\\pi_\\theta(s_t,a_t)\\delta(t)E(t)$ 对于Critic本身的模型参数 $w$ ，一般都是使用均方误差损失函数来做做迭代更新，类似之前DQN系列中所讲的迭代方法. 如果我们使用的是最简单的线性Q函数，比如 $Q(s,a,w)=ϕ(s,a)^Tw$,则Critic本身的模型参数 $w$的更新公式可以表示为： $$\\begin{gathered} \\delta=R_{t+1}+\\gamma Q(S_{t+1}\\text{,}A_{t+1})-Q(S_t,A_t) \\\\ w=w+\\beta\\delta\\phi(s,a) \\end{gathered}$$ 通过对均方误差损失函数求导可以很容易的得到上式。当然实际应用中，我们一般不使用线性Q函数，而使用神经网络表示状态和Q值的关系。 3. Actor-Critic算法流程 这里给一个Actor-Critic算法的流程总结，评估点基于TD误差，Critic使用神经网络来计算TD误差并更新网络参数，Actor也使用神经网络来更新网络参数　算法输入：迭代轮数 $T$，状态特征维度 $n$, 动作集 $A$, 步长 $α$, $β$，衰减因子 $γ$, 探索率 $ϵ$, Critic网络结构和Actor网络结构。 输出：Actor 网络参数 $θ$, Critic网络参数 $w$ (1). 随机初始化所有的状态和动作对应的价值Q�. 随机初始化Critic网络的所有参数$w$。随机初始化Actor网络的所有参数$\\theta$。 (2). for i from 1 to T，进行迭代。 a) 初始化 $S$ 为当前状态序列的第一个状态, 拿到其特征向量 $ϕ(S)$ b) 在Actor网络中使用 $ϕ(S)$ 作为输入，输出动作 $A$,基于动作 $A$得到新的状态 $S’$,反馈 $R$。 c) 在Critic网络中分别使用 $ϕ(S)$，$ϕ(S’)$ 作为输入，得到Q值输出 $V(S)$，$V(S’)$ d) 计算TD误差 $\\delta=R+\\gamma V(S^{\\prime})-V(S)$ e) 使用均方差损失函数 $\\sum(R+\\gamma V(S^{\\prime})-V(S,w))^2$ 作Critic网络参数 $w$的梯度更新 f) 更新Actor网络参数 $θ$: $$\\theta=\\theta+\\alpha\\nabla_\\theta log\\pi_\\theta(S_t,A)\\delta $$ 对于Actor的分值函数 $∇_θlogπ_θ(S_t,A)$,可以选择softmax或者高斯分值函数。 上述Actor-Critic算法已经是一个很好的算法框架，但是离实际应用还比较远。主要原因是这里有两个神经网络，都需要梯度更新，而且互相依赖。但是了解这个算法过程后，其他基于Actor-Critic的算法就好理解了。 4. Actor-Critic算法实例 下面我们用一个具体的例子来演示上面的Actor-Critic算法。仍然使用了OpenAI Gym中的CartPole-v0游戏来作为我们算法应用。CartPole-v0游戏的介绍参见这里。它比较简单，基本要求就是控制下面的cart移动使连接在上面的pole保持垂直不倒。这个任务只有两个离散动作，要么向左用力，要么向右用力。而state状态就是这个cart的位置和速度， pole的角度和角速度，4维的特征。坚持到200分的奖励则为过关。 算法流程可以参考上面的第三节，这里的分值函数我们使用的是softmax函数，和上一片的类似。完整的代码参见Github：https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/actor_critic.py 代码主要分为两部分，第一部分是Actor，第二部分是Critic。对于Actor部分，大家可以和上一篇策略梯度的代码对比，改动并不大，主要区别在于梯度更新部分，策略梯度使用是蒙特卡罗法计算出的价值 $v","date":"2024-02-25","objectID":"/posts/rl_learning_note_14/:0:0","tags":["RL"],"title":"强化学习笔记 [14] | Actor-Critic","uri":"/posts/rl_learning_note_14/"},{"categories":["RL"],"content":"0. 引言 在前面讲到的DQN系列强化学习算法中，我们主要对价值函数进行了近似表示，基于价值来学习。这种Value Based强化学习方法在很多领域都得到比较好的应用，但是Value Based强化学习方法也有很多局限性，因此在另一些场景下我们需要其他的方法，比如本篇讨论的策略梯度(Policy Gradient)，它是Policy Based强化学习方法，基于策略来学习。 本文参考了Sutton的强化学习书第13章和策略梯度的论文。 1. Value Based强化学习方法的不足 DQN系列强化学习算法主要的 问题 主要有三点。 第一点是对连续动作的处理能力不足。DQN之类的方法一般都是只处理离散动作，无法处理连续动作。虽然有NAF DQN之类的变通方法，但是并不优雅。比如我们之前提到的经典的冰球世界(PuckWorld) 强化学习问题，具体的动态demo见这里。环境由一个正方形区域构成代表着冰球场地，场地内大的圆代表着运动员个体，小圆代表着目标冰球。在这个正方形环境中，小圆会每隔一定的时间随机改变在场地的位置，而代表个体的大圆的任务就是尽可能快的接近冰球目标。大圆可以操作的行为是在水平和竖直共四个方向上施加一个时间乘时长的力，借此来改变大圆的速度。假如此时这个力的大小和方向是可以灵活选择的，那么使用普通的DQN之类的算法就不好做了。因为此时策略是一个有具体值有方向的力，我们可以把这个力在水平和垂直方向分解。那么这个力就是两个连续的向量组成，这个策略使用离散的方式是不好表达的，但是用Policy Based强化学习方法却很容易建模。 第二点是对受限状态下的问题处理能力不足。在使用特征来描述状态空间中的某一个状态时，有可能因为个体观测的限制或者建模的局限，导致真实环境下本来不同的两个状态却再我们建模后拥有相同的特征描述，进而很有可能导致我们的value Based方法无法得到最优解。此时使用Policy Based强化学习方法也很有效。 第三点是无法解决随机策略问题。Value Based强化学习方法对应的最优策略通常是确定性策略，因为其是从众多行为价值中选择一个最大价值的行为，而有些问题的最优策略却是随机策略，这种情况下同样是无法通过基于价值的学习来求解的。这时也可以考虑使用Policy Based强化学习方法。 由于上面这些原因，Value Based强化学习方法不能通吃所有的场景，我们需要新的解决上述类别问题的方法，比如Policy Based强化学习方法。 2. Policy Based强化学习方法引入 回想我们在Value Based强化学习方法里，我们对价值函数进行了近似表示，引入了一个动作价值函数 $\\hat{q}$，这个函数由参数 $w$ 描述，并接受状态 $s$ 与动作 $a$ 作为输入，计算后得到近似的动作价值，即： $$\\hat{q}\\left(s,a,w\\right)\\approx q_\\pi(s,a)$$ 在Policy Based强化学习方法下，我们采样类似的思路，只不过这时我们对策略进行近似表示。此时策略 $π$可以被被描述为一个包含参数 $θ$ 的函数,即： $$\\pi_\\theta(s,a)=P(a|s,\\theta)\\approx\\pi(a|s)$$ 将策略表示成一个连续的函数后，我们就可以用连续函数的优化方法来寻找最优的策略了。而最常用的方法就是梯度上升法了，那么这个梯度对应的优化目标如何定义呢？ 3. 策略梯度的优化目标 我们要用梯度上升来寻找最优的梯度，首先就要找到一个可以优化的函数目标。 最简单的优化目标就是初始状态收获的期望，即优化目标为： $$J_1(\\theta)=V_{\\pi_\\theta}(s_1)=\\mathbb{E}_{\\pi_\\theta}(G_1)$$ 但是有的问题是没有明确的初始状态的，那么我们的优化目标可以定义平均价值，即： $$J_{avV}(\\theta)=\\sum_sd_{\\pi_\\theta}(s)V_{\\pi_\\theta}(s)$$ 其中，$d_πθ(s)$ 是基于策略 $π_θ$生成的马尔科夫链关于状态的静态分布。 或者定义为每一时间步的平均奖励，即： $$J_{avR}(\\theta)==\\sum_sd_{\\pi_\\theta}(s)\\sum_a\\pi_\\theta(s,a)R_s^a$$ 无论我们是采用 $J_1$, $J_{av}V$, 还是 $J_{av}R$ 来表示优化目标，最终对 $θ$求导的梯度都可以表示为： $$\\nabla_\\theta J(\\theta)=\\mathbb{E}_{\\pi_\\theta}[\\nabla_\\theta log\\pi_\\theta(s,a)Q_\\pi(s,a)]$$ 具体的证明过程这里就不再列了，如果大家感兴趣，可以去看策略梯度的论文的附录1，里面有详细的证明。 当然我们还可以采用很多其他可能的优化目标来做梯度上升，此时我们的梯度式子里面的 $\\nabla_\\theta log\\pi_\\theta(s,a)$ 部分并不改变，变化的只是后面的 $Q_\\pi(s,a)$ 部分。对于 $\\nabla_\\theta log\\pi_\\theta(s,a)$,我们一般称为分值函数(score function)。 现在梯度的式子已经有了，后面剩下的就是策略函数 $\\pi_\\theta(s,a)$的设计了。 4. 策略函数的设计 现在我们回头看一下策略函数 $\\pi_\\theta(s,a)$ 的设计，在前面它一直是一个数学符号。 最常用的策略函数就是softmax策略函数了，它主要应用于离散空间中，softmax策略使用描述状态和行为的特征 $ϕ(s,a)$ 与参数 $θ$的线性组合来权衡一个行为发生的几率,即: $$\\pi_\\theta(s,a)=\\frac{e^{\\phi(s,a)^T\\theta}}{\\sum_be^{\\phi(s,b)^T\\theta}}$$ 则通过求导很容易求出对应的分值函数为： $$\\nabla_\\theta log\\pi_\\theta(s,a)=\\phi(s,a)-\\mathbb{E}_{\\pi_\\theta}[\\phi(s,.)]$$ 另一种高斯策略则是应用于连续行为空间的一种常用策略。该策略对应的行为从高斯分布 $\\mathbb{N}(\\phi(\\mathrm{s})^{\\mathbb{T}}\\theta,\\sigma^2)$中产生。高斯策略对应的分值函数求导可以得到为: $$\\nabla_\\theta log\\pi_\\theta(s,a)==\\frac{(a-\\phi(s)^T\\theta)\\phi(s)}{\\sigma^2}$$ 有策略梯度的公式和策略函数，我们可以得到第一版的策略梯度算法了。 5. 蒙特卡罗策略梯度reinforce算法 这里我们讨论最简单的策略梯度算法，蒙特卡罗策略梯度reinforce算法, 使用价值函数 $v(s)$ 来近似代替策略梯度公式里面的 $Q_π(s,a)$。算法的流程很简单，如下所示: 输入：N个蒙特卡罗完整序列,训练步长 $α$ 输出：策略函数的参数 $θ$ (1). for 每个蒙特卡罗序列: a. 用蒙特卡罗法计算序列每个时间位置t的状态价值 $v_t$ b. 对序列每个时间位置t，使用梯度上升法，更新策略函数的参数 $θ$： $$\\theta=\\theta+\\alpha\\nabla_\\theta log\\pi_\\theta(s_t,a_t)v_t$$ (2).返回策略函数的参数 $θ$ 这里的策略函数可以是softmax策略，高斯策略或者其他策略。 6. 策略梯度实例 这里给出第5节的蒙特卡罗策略梯度reinforce算法的一个实例。仍然使用了OpenAI Gym中的CartPole-v0游戏来作为我们算法应用。CartPole-v0游戏的介绍参见这里。它比较简单，基本要求就是控制下面的cart移动使连接在上面的pole保持垂直不倒。这个任务只有两个离散动作，要么向左用力，要么向右用力。而state状态就是这个cart的位置和速度， pole的角度和角速度，4维的特征。坚持到200分的奖励则为过关。 完整的代码参见我的github：https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/policy_gradient.py 这里我们采用softmax策略作为我们的策略函数，同时，softmax的前置部分，也就是我们的策略模型用一个三层的softmax神经网络来表示。这样好处就是梯度的更新可以交给神经网络来做。 我们的softmax神经网络的结构如下，注意这个网络不是价值Q网络，而是策略网络： def create_softmax_network(self): # network weights W1 = self.weight_variable([self.state_dim, 20]) b1 = self.bias_variable([20]) W2 = self.weight_variable([20, self.action_dim]) b2 = self.bias_variable([self.action_dim]) # input layer self.state_input = tf.placeholder(\"float\", [None, self.state_dim]) self.tf_acts = tf.placeholder(tf.int32","date":"2024-02-25","objectID":"/posts/rl_learning_note_13/:0:0","tags":["RL"],"title":"强化学习笔记 [13] | 策略梯度(Policy Gradient)","uri":"/posts/rl_learning_note_13/"},{"categories":["RL"],"content":"0. 引言 在强化学习(十一) Prioritized Replay DQN中，我们讨论了对DQN的经验回放池按权重采样来优化DQN算法的方法，本文讨论另一种优化方法，Dueling DQN。本章内容主要参考了ICML 2016的deep RL tutorial和Dueling DQN的论文(Dueling Network Architectures for Deep Reinforcement Learning)(ICML 2016)。 1. Dueling DQN的优化点考虑 在前面讲到的DDQN中，我们通过优化目标Q值的计算来优化算法，在Prioritized Replay DQN中，我们通过优化经验回放池按权重采样来优化算法。而在Dueling DQN中，我们尝试通过优化神经网络的结构来优化算法。 具体如何优化网络结构呢？Dueling DQN考虑将Q网络分成两部分，第一部分是仅仅与状态 $S$有关，与具体要采用的动作 $A$无关，这部分我们叫做价值函数部分，记做 $V(S,w,α)$,第二部分同时与状态状态 $S$ 和动作 $A$有关，这部分叫做**优势函数(Advantage Function)**部分,记为 $A(S,A,w,β)$,那么最终我们的价值函数可以重新表示为： $$Q(S,A,w,\\alpha,\\beta)=V(S,w,\\alpha)+A(S,A,w,\\beta)$$ 其中，$w$ 是公共部分的网络参数，而 $α$ 是价值函数独有部分的网络参数，而 $β$ 是优势函数独有部分的网络参数。 2. Dueling DQN网络结构 由于Q网络的价值函数被分为两部分，因此Dueling DQN的网络结构也和之前的DQN不同。为了简化算法描述，这里不使用原论文的CNN网络结构，而是使用前面文中用到的最简单的三层神经网络来描述。是否使用CNN对Dueling DQN算法本身无影响。 在前面讲到的DDQN等DQN算法中，我使用了一个简单的三层神经网络：一个输入层，一个隐藏层和一个输出层。如下左图所示： 神经网络与Dueling DQN 而在Dueling DQN中，我们在后面加了两个子网络结构，分别对应上面上到价格函数网络部分和优势函数网络部分。对应上面右图所示。最终Q网络的输出由价格函数网络的输出和优势函数网络的输出线性组合得到。 我们可以直接使用上一节的价值函数的组合公式得到我们的动作价值，但是这个式子无法辨识最终输出里面 $V(S,w,α)$ 和 $A(S,A,w,β)$各自的作用，为了可以体现这种可辨识性(identifiability),实际使用的组合公式如下： $$Q(S,A,w,\\alpha,\\beta)=V(S,w,\\alpha)+(A(S,A,w,\\beta)-\\frac1{\\mathcal{A}}\\sum_{a^{\\prime}\\in\\mathcal{A}}A(S,a^{\\prime},w,\\beta))$$ 其实就是对优势函数部分做了中心化的处理。以上就是Dueling DQN的主要算法思路。由于它仅仅涉及神经网络的中间结构的改进，现有的DQN算法可以在使用Duel DQN网络结构的基础上继续使用现有的算法。由于算法主流程和其他算法没有差异，这里就不单独讲Duel DQN的算法流程了。 3. Dueling DQN实例 下面我们用一个具体的例子来演示Dueling DQN的应用。仍然使用了OpenAI Gym中的CartPole-v0游戏来作为我们算法应用。CartPole-v0游戏的介绍参见这里。它比较简单，基本要求就是控制下面的cart移动使连接在上面的pole保持垂直不倒。这个任务只有两个离散动作，要么向左用力，要么向右用力。而state状态就是这个cart的位置和速度， pole的角度和角速度，4维的特征。坚持到200分的奖励则为过关。 这个实例代基于Nature DQN，并将网络结构改为上图中右边的Dueling DQN网络结构，完整的代码参见github: https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/duel_dqn.py 这里我们重点关注Dueling DQN和Nature DQN的代码的不同之处。也就是网络结构定义部分，主要的代码如下，一共有两个相同结构的Q网络，每个Q网络都有状态函数和优势函数的定义，以及组合后的Q网络输出，如代码红色部分： def create_Q_network(self): # input layer self.state_input = tf.placeholder(\"float\", [None, self.state_dim]) # network weights with tf.variable_scope('current_net'): W1 = self.weight_variable([self.state_dim,20]) b1 = self.bias_variable([20]) # hidden layer 1 h_layer_1 = tf.nn.relu(tf.matmul(self.state_input,W1) + b1) # hidden layer for state value with tf.variable_scope('Value'): W21= self.weight_variable([20,1]) b21 = self.bias_variable([1]) self.V = tf.matmul(h_layer_1, W21) + b21 # hidden layer for action value with tf.variable_scope('Advantage'): W22 = self.weight_variable([20,self.action_dim]) b22 = self.bias_variable([self.action_dim]) self.A = tf.matmul(h_layer_1, W22) + b22 # Q Value layer self.Q_value = self.V + (self.A - tf.reduce_mean(self.A, axis=1, keep_dims=True)) with tf.variable_scope('target_net'): W1t = self.weight_variable([self.state_dim,20]) b1t = self.bias_variable([20]) # hidden layer 1 h_layer_1t = tf.nn.relu(tf.matmul(self.state_input,W1t) + b1t) # hidden layer for state value with tf.variable_scope('Value'): W2v = self.weight_variable([20,1]) b2v = self.bias_variable([1]) self.VT = tf.matmul(h_layer_1t, W2v) + b2v # hidden layer for action value with tf.variable_scope('Advantage'): W2a = self.weight_variable([20,self.action_dim]) b2a = self.bias_variable([self.action_dim]) self.AT = tf.matmul(h_layer_1t, W2a) + b2a # Q Value layer self.target_Q_value = self.VT + (self.AT - tf.reduce_mean(self.AT, axis=1, keep_dims=True)) 其余部分代码和Nature DQN基本相同。当然，我们可以也在前面DDQN，Prioritized Replay DQN代码的基础上，把网络结构改成上面的定义，这样Dueling DQN也可以起作用。 4. DQN总结 DQN系列我花了5篇来讲解，一共5个前后有关联的算法：DQN(NIPS2013), Nature DQN, DDQN, Prioritized Replay DQN和Dueling DQN。目前使用的比较主流的是后面三种算法思路，这三种算法思路也是可以混着一起使用的，相互并不排斥。 当然DQN家族的算法远远不止这些，还有一些其他的DQN算法我没有详细介绍，比如使用一些较复杂的CNN和RNN网络来提高DQN的表达能力，又比如改进探索状态空间的方法等，主要是在DQN的基础上持续优化。 DQN算是深度强化学习的中的主流流派，代表了Value-Based这一大类深度强化学习算法。但是它也有自己的一些问题，就是绝大多数DQN只能处理离散的动作集合，不能处理连续的动作集合。虽然NAF DQN可以解决这个问题，但是方法过于复杂了。而深度强化学习的另一个主流流派Policy-Based而可以较好的解决这个问题，从下一篇我们开始讨论Policy-Based深度强化学习。 ","date":"2024-02-25","objectID":"/posts/rl_learning_note_12/:0:0","tags":["RL"],"title":"强化学习笔记 [12] | Dueling DQN","uri":"/posts/rl_learning_note_12/"},{"categories":["RL"],"content":"0. 引言 在强化学习（十）Double DQN (DDQN)中，我们讲到了DDQN使用两个Q网络，用当前Q网络计算最大Q值对应的动作，用目标Q网络计算这个最大动作对应的目标Q值，进而消除贪婪法带来的偏差。今天我们在DDQN的基础上，对经验回放部分的逻辑做优化。对应的算法是Prioritized Replay DQN。 本章内容主要参考了ICML 2016的deep RL tutorial和Prioritized Replay DQN的论文(Prioritized Experience Replay)(ICLR 2016)。 1. Prioritized Replay DQN之前算法的问题 在Prioritized Replay DQN之前，我们已经讨论了很多种DQN，比如Nature DQN， DDQN等，他们都是通过经验回放来采样，进而做目标Q值的计算的。在采样的时候，我们是一视同仁，在经验回放池里面的所有的样本都有相同的被采样到的概率。 但是注意到在经验回放池里面的不同的样本由于TD误差的不同，对我们反向传播的作用是不一样的。TD误差越大，那么对我们反向传播的作用越大。而TD误差小的样本，由于TD误差小，对反向梯度的计算影响不大。在Q网络中，TD误差就是目标Q网络计算的目标Q值和当前Q网络计算的Q值之间的差距。 这样如果TD误差的绝对值 $|δ(t)|$较大的样本更容易被采样，则我们的算法会比较容易收敛。下面我们看看Prioritized Replay DQN的算法思路。 2. Prioritized Replay DQN算法的建模 Prioritized Replay DQN根据每个样本的TD误差绝对值 $|δ(t)|$，给定该样本的优先级正比于 $|δ(t)|$，将这个优先级的值存入经验回放池。回忆下之前的DQN算法，我们仅仅只保存和环境交互得到的样本状态，动作，奖励等数据，没有优先级这个说法。 由于引入了经验回放的优先级，那么Prioritized Replay DQN的经验回放池和之前的其他DQN算法的经验回放池就不一样了。因为这个优先级大小会影响它被采样的概率。在实际使用中，我们通常使用SumTree这样的二叉树结构来做我们的带优先级的经验回放池样本的存储。 具体的SumTree树结构如下图： sum_tree 结构图 所有的经验回放样本只保存在最下面的叶子节点上面，一个节点一个样本。内部节点不保存样本数据。而叶子节点除了保存数据以外，还要保存该样本的优先级，就是图中的显示的数字。对于内部节点每个节点只保存自己的儿子节点的优先级值之和，如图中内部节点上显示的数字。 这样保存有什么好处呢？主要是方便采样。以上面的树结构为例，根节点是42，如果要采样一个样本，那么我们可以在[0,42]之间做均匀采样，采样到哪个区间，就是哪个样本。比如我们采样到了26， 在（25-29）这个区间，那么就是第四个叶子节点被采样到。而注意到第三个叶子节点优先级最高，是12，它的区间13-25也是最长的，会比其他节点更容易被采样到。 如果要采样两个样本，我们可以在[0,21],[21,42]两个区间做均匀采样，方法和上面采样一个样本类似。 类似的采样算法思想我们在word2vec原理(三) 基于Negative Sampling的模型第四节中也有讲到。 除了经验回放池，现在我们的Q网络的算法损失函数也有优化，之前我们的损失函数是： $$\\frac1m\\sum_{j=1}^m(y_j-Q(\\phi(S_j),A_j,w))^2$$ 现在我们新的考虑了样本优先级的损失函数是 $$\\frac1m\\sum_{j=1}^mw_j(y_j-Q(\\phi(S_j),A_j,w))^2$$ 其中 $w_j$是第j个样本的优先级权重，由TD误差 $|δ(t)|$归一化得到。 第三个要注意的点就是当我们对Q网络参数进行了梯度更新后，需要重新计算TD误差，并将TD误差更新到SunTree上面。 除了以上三个部分，Prioritized Replay DQN和DDQN的算法流程相同。 3. Prioritized Replay DQN算法流程 下面我们总结下Prioritized Replay DQN的算法流程，基于上一节的DDQN，因此这个算法我们应该叫做Prioritized Replay DDQN。主流程参考论文(Prioritized Experience Replay)(ICLR 2016)。 算法输入：迭代轮数 $T$，状态特征维度 $n$, 动作集 $A$, 步长 $α$，采样权重系数 $β$，衰减因子 $γ$, 探索率 $ϵ$, 当前Q网络 $Q$，目标Q网络 $Q’$, 批量梯度下降的样本数 $m$,目标Q网络参数更新频率 $C$, SumTree的叶子节点数 $S$。 输出：Q网络参数。 随机初始化所有的状态和动作对应的价值 $Q$. 随机初始化当前Q网络的所有参数 $w$,初始化目标Q网络 $Q’$的参数 $w’=w$。初始化经验回放SumTree的默认数据结构，所有SumTree的S个叶子节点的优先级 $p_j$为1。 for i from 1 to T，进行迭代。 a) 初始化S为当前状态序列的第一个状态, 拿到其特征向量 $ϕ(S)$ b) 在Q网络中使用 $ϕ(S)$ 作为输入，得到Q网络的所有动作对应的Q值输出。用 $ϵ−$贪婪法在当前Q值输出中选择对应的动作 $A$ c) 在状态 $S$ 执行当前动作 $A$,得到新状态 $S’$ 对应的特征向量 $ϕ(S’)$和奖励 $R$,是否终止状态 is_end d) 将 ${ϕ(S),A,R,ϕ(S’),is_end}$这个五元组存入SumTree e) $S=S'$ f) 从SumTree中采样 $m$ 个样本 ${ϕ(S_j),A_j,R_j,ϕ(S’_j),is_end_j},j=1,2.,,,m$，每个样本被采样的概率基于 $P(j)=\\frac{p_j}{\\sum_i(p_i)}$，损失函数权重 $w_j=(N*P(j))^{-\\beta}/\\max_i(w_i)$，计算当前目标Q值 $y_j$: $$\\left.y_j=\\left\\\\{\\begin{matrix}R_j\u0026is_end_j\\textit{is true}\\\\\\\\R_j+\\gamma Q^{\\prime}(\\phi(S_j^{\\prime}),\\arg\\max_{a^{\\prime}}Q(\\phi(S_j^{\\prime}),a,w),w^{\\prime})\u0026is_end_j\\textit{is false}\\end{matrix}\\right.\\right.$$ g) 使用均方差损失函数$\\begin{aligned}\\frac{1}{m}\\sum_{j=1}^mw_j(y_j-Q(\\phi(S_j),A_j,w))^2\\end{aligned}$，通过神经网络的梯度反向传播来更新Q网络的所有参数 $w$ h) 重新计算所有样本的TD误差 $\\delta_j=y_j-Q(\\phi(S_j),A_j,w)$，更新SumTree中所有节点的优先级 $p_j=|\\delta_j|$ i) 如果i%C=1,则更新目标Q网络参数 $w’=w$ j) 如果 $S’$是终止状态，当前轮迭代完毕，否则转到步骤b) 注意，上述第二步的f步和g步的Q值计算也都需要通过Q网络计算得到。另外，实际应用中，为了算法较好的收敛，探索率$ϵ$需要随着迭代的进行而变小。 4. Prioritized Replay DDQN算法流程 下面我们给出Prioritized Replay DDQN算法的实例代码。仍然使用了OpenAI Gym中的CartPole-v0游戏来作为我们算法应用。CartPole-v0游戏的介绍参见这里。它比较简单，基本要求就是控制下面的cart移动使连接在上面的pole保持垂直不倒。这个任务只有两个离散动作，要么向左用力，要么向右用力。而state状态就是这个cart的位置和速度， pole的角度和角速度，4维的特征。坚持到200分的奖励则为过关。 完整的代码参见我的github: https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/ddqn_prioritised_replay.py， 代码中的SumTree的结构和经验回放池的结构参考了morvanzhou的github代码。 这里重点讲下和第三节中算法描述不同的地方，主要是 $w_j$的计算。注意到： $$w_j=\\frac{(NP(j))^{-\\beta}}{\\max_i(w_i)}=\\frac{(NP(j))^{-\\beta}}{\\max_i((N*P(i))^{-\\beta})}=\\frac{(P(j))^{-\\beta}}{\\max_i((P(i))^{-\\beta})}=(\\frac{P_j}{\\min_iP(i)})^{-\\beta}$$ 因此代码里面$w_j$，即ISWeights的计算代码是这样的： def sample(self, n): b_idx, b_memory, ISWeights = np.empty((n,), dtype=np.int32), np.empty((n, self.tree.data[0].size)), np.empty((n, 1)) pri_seg = self.tree.total_p / n # priority segment","date":"2024-02-25","objectID":"/posts/rl_learning_note_11/:0:0","tags":["RL"],"title":"强化学习笔记 [11] | Prioritized Replay DQN","uri":"/posts/rl_learning_note_11/"},{"categories":["RL"],"content":"0. 引言 在强化学习（九）Deep Q-Learning进阶之Nature DQN中，我们讨论了Nature DQN的算法流程，它通过使用两个相同的神经网络，以解决数据样本和网络训练之前的相关性。但是还是有其他值得优化的点，文本就关注于Nature DQN的一个改进版本: Double DQN算法（以下简称DDQN）。 本章内容主要参考了ICML 2016的deep RL tutorial和DDQN的论文(Deep Reinforcement Learning with Double Q-learning)。 1. DQN的目标Q值计算问题 在DDQN之前，基本上所有的目标Q值都是通过贪婪法直接得到的，无论是Q-Learning， DQN(NIPS 2013)还是 Nature DQN，都是如此。比如对于Nature DQN,虽然用了两个Q网络并使用目标Q网络计算Q值，其第j个样本的目标Q值的计算还是贪婪法得到的，计算如下式: $$\\left.y_j=\\left{\\begin{array}{ll}R_j\u0026is_end_j\\textit{ is true}\\R_j+\\gamma\\max_{a^{\\prime}}Q^{\\prime}(\\phi(S_j^{\\prime}),A_j^{\\prime},w^{\\prime})\u0026is_end_j\\textit{ is false}\\end{array}\\right.\\right.$$ 使用max虽然可以快速让Q值向可能的优化目标靠拢，但是很容易过犹不及，导致过度估计(Over Estimation)，所谓过度估计就是最终我们得到的算法模型有很大的偏差(bias)。为了解决这个问题， DDQN通过解耦目标Q值动作的选择和目标Q值的计算这两步，来达到消除过度估计的问题。 2. DDQN的算法建模 DDQN和Nature DQN一样，也有一样的两个Q网络结构。在Nature DQN的基础上，通过解耦目标Q值动作的选择和目标Q值的计算这两步，来消除过度估计的问题。 在上一节里，Nature DQN对于非终止状态，其目标Q值的计算式子是： $$y_j=R_j+\\gamma\\max_{a^{\\prime}}Q^{\\prime}(\\phi(S_j^{\\prime}),A_j^{\\prime},w^{\\prime})$$ 在DDQN(Double DQN)这里，不再是直接在目标Q网络里面找各个动作中最大Q值，而是先在当前Q网络中先找出最大Q值对应的动作，即: $$a^{max}(S_j^{\\prime},w)=\\arg\\max_{a^{\\prime}}Q(\\phi(S_j^{\\prime}),a,w)$$ 然后利用这个选择出来的动作 $\\begin{aligned}\u0026a^{max}(S_j^{\\prime},w)\\end{aligned}$ 在目标网络里面去计算目标Q值。即： $$y_j=R_j+\\gamma Q^{\\prime}(\\phi(S_j^{\\prime}),a^{max}(S_j^{\\prime},w),w^{\\prime})$$ 综合起来写就是： $$y_j=R_j+\\gamma Q^{\\prime}(\\phi(S_j^{\\prime}),\\arg\\max_{a^{\\prime}}Q(\\phi(S_j^{\\prime}),a,w),w^{\\prime})$$ 除了目标Q值的计算方式以外，DDQN算法和Nature DQN的算法流程完全相同。 3. DDQN算法流程 这里我们总结下DDQN的算法流程，和Nature DQN的区别仅仅在步骤2.f中目标Q值的计算。 算法输入：迭代轮数 $T$，状态特征维度 $n$, 动作集 $A$, 步长 $α$，衰减因子 $γ$, 探索率 $ϵ$, 当前Q网络 $Q$，目标Q网络 $Q’$, 批量梯度下降的样本 $m$,目标Q网络参数更新频 $C$。 输出：Q网络参数 随机初始化所有的状态和动作对应的价值 $Q$. 随机初始化当前Q网络的所有参数 $w$,初始化目标Q网络 $Q’的参数 $w′=w$ 。清空经验回放的集合 $D$。 for i from 1 to T，进行迭代。 a) 初始化 $S$为当前状态序列的第一个状态, 拿到其特征向量 $ϕ(S)$ b) 在Q网络中使用 $ϕ(S)$作为输入，得到Q网络的所有动作对应的Q值输出。用 $ϵ−$贪婪法在当前Q值输出中选择对应的动作 $A$ c) 在状态 $S$执行当前动作 $A$,得到新状态 $S’$对应的特征向量 $ϕ(S’)$ 和奖励 $R$,是否终止状态 is_end d) 将 ${ϕ(S),A,R,ϕ(S′),is_end} $,这个五元组存入经验回放集合 $D$ e) $S=S'$ f) 从经验回放集合 $D$ 中采样 $m$ 个样本 ${ϕ(S_j),A_j,R_j,ϕ(S’_j),is_end_j},j=1,2.,,,m$, 计算当前目标Q值 $y_j$: $$\\left.y_j=\\left{\\begin{array}{ll}R_j\u0026is_end_j\\textit{ is true}\\R_j+\\gamma Q^{\\prime}(\\phi(S_j^{\\prime}),\\arg\\max_{a^{\\prime}}Q(\\phi(S_j^{\\prime}),a,w),w^{\\prime})\u0026is_end_j\\textit{ is false}\\end{array}\\right.\\right.$$ g) 使用均方差损失函数$\\frac1m\\sum_{j=1}^m(y_j-Q(\\phi(S_j),A_j,w))^2$，通过神经网络的梯度反向传播来更新Q网络的所有参数w� h) 如果 $i%C=1$,则更新目标Q网络参数 $w’=w$ i) 如果 $S’$是终止状态，当前轮迭代完毕，否则转到步骤b) 注意，上述第二步的f步和g步的Q值计算也都需要通过Q网络计算得到。另外，实际应用中，为了算法较好的收敛，探索率 $ϵ$需要随着迭代的进行而变小。 4. DDQN算法实例　下面我们用一个具体的例子来演示DQN的应用。仍然使用了OpenAI Gym中的CartPole-v0游戏来作为我们算法应用。CartPole-v0游戏的介绍参见这里。它比较简单，基本要求就是控制下面的cart移动使连接在上面的pole保持垂直不倒。这个任务只有两个离散动作，要么向左用力，要么向右用力。而state状态就是这个cart的位置和速度， pole的角度和角速度，4维的特征。坚持到200分的奖励则为过关。 完整的代码参见github: https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/ddqn.py 这里我们重点关注DDQN和上一节的Nature DQN的代码的不同之处。代码只有一个地方不一样，就是计算目标Q值的时候，如下： # Step 2: calculate y y_batch = [] current_Q_batch = self.Q_value.eval(feed_dict={self.state_input: next_state_batch}) max_action_next = np.argmax(current_Q_batch, axis=1) target_Q_batch = self.target_Q_value.eval(feed_dict={self.state_input: next_state_batch}) for i in range(0,BATCH_SIZE): done = minibatch[i][4] if done: y_batch.append(reward_batch[i]) else : target_Q_value = target_Q_batch[i, max_action_next[i]] y_batch.append(reward_batch[i] + GAMMA * target_Q_value) 而之前的Nature DQN这里的目标Q值计算是如下这样的： # Step 2: calculate y y_batch = [] Q_value_batch = self.target_Q_value.eval(feed_dict={self.state_input:next_state_batch}) for i in range(0,BATCH_SIZE): done = minibatch[i][4] if done: y_batch.append(reward_batch[i]) else : y_batch.append(reward_batch[i] + GAMMA * np.max(Q_value_batch[i])) 除了上面这部分的区别，两个算法的代码完全相同。 5. DDQN小结 DDQN算法出来以后，取得了比较好的效果，因此得到了比较广泛的应用。不过我们的DQN仍然有其他可以优化的点，如上一篇最后讲到的: 随机采样的方法好吗？按道理经验回放里不同样本的重要性是不一样的，TD误差大的样本重要程度应该高。针对这个问题，我们在下一节的Prioritised Replay DQN中讨论。 ","date":"2024-02-23","objectID":"/posts/rl_learning_note_10/:0:0","tags":["RL"],"title":"强化学习笔记 [10] | Double DQN (DDQN)","uri":"/posts/rl_learning_note_10/"},{"categories":["RL"],"content":"0. 引言 在强化学习（八）价值函数的近似表示与Deep Q-Learning中，我们讲到了Deep Q-Learning（NIPS 2013）的算法和代码，在这个算法基础上，有很多Deep Q-Learning(以下简称DQN)的改进版，今天我们来讨论DQN的第一个改进版Nature DQN(NIPS 2015)。 本章内容主要参考了ICML 2016的deep RL tutorial和Nature DQN的论文。 1. DQN(NIPS 2013)的问题 在上一篇我们已经讨论了DQN(NIPS 2013)的算法原理和代码实现，虽然它可以训练像CartPole这样的简单游戏，但是有很多问题。这里我们先讨论第一个问题。 注意到DQN(NIPS 2013)里面，我们使用的目标 $Q$值的计算方式： $$\\left.y_j=\\left\\\\{\\begin{array}{ll}R_j\u0026is_end_j\\textit{ is true}\\\\\\\\R_j+\\gamma\\max_{a^{\\prime}}Q(\\phi(S_j^{\\prime}),A_j^{\\prime},w)\u0026is_end_j\\textit{ is false}\\end{array}\\right.\\right.$$ 这里目标Q值的计算使用到了当前要训练的Q网络参数来计算$Q(\\phi(S_j^{\\prime}),A_j^{\\prime},w)$，而实际上，我们又希望通过 $y_j$来后续更新 $Q$网络参数。这样两者循环依赖，迭代起来两者的相关性就太强了。不利于算法的收敛。 因此，一个改进版的DQN: Nature DQN尝试用两个Q网络来减少目标Q值计算和要更新Q网络参数之间的依赖关系。下面我们来看看Nature DQN是怎么做的。 2. Nature DQN的建模 Nature DQN的两个Q网络分别命名为当前Q网络和目标Q网络。 Nature DQN使用了两个Q网络，一个当前Q网络$Q$用来选择动作，更新模型参数，另一个目标Q网络 $Q’$用于计算目标Q值。目标Q网络的网络参数不需要迭代更新，而是每隔一段时间从当前Q网络$Q$复制过来，即延时更新，这样可以减少目标Q值和当前的Q值相关性。 要注意的是，两个Q网络的结构是一模一样的。这样才可以复制网络参数。 Nature DQN和上一篇的DQN相比，除了用一个新的相同结构的目标Q网络来计算目标Q值以外，其余部分基本是完全相同的。 3. Nature DQN的算法流程 下面我们来总结下Nature DQN的算法流程， 基于DQN NIPS 2015： 算法输入：迭代轮数 $T$，状态特征维度 $n$, 动作集 $A$, 步长 $α$，衰减因子 $γ$, 探索率 $ϵ$, 当前Q网络 $Q$，目标Q网络 $Q’$, 批量梯度下降的样本数 $m$,目标Q网络参数更新频率$C$。 输出：$Q$网络参数 随机初始化所有的状态和动作对应的价值 $Q$. 随机初始化当前Q网络的所有参数 $w$,初始化目标Q网络 $Q’$的参数 $w’=w$。清空经验回放的集合 $D$。 for i from 1 to T，进行迭代。 a) 初始化S为当前状态序列的第一个状态, 拿到其特征向量 $ϕ(S)$ b) 在Q网络中使用 $ϕ(S)$作为输入，得到Q网络的所有动作对应的Q值输出。用 $ϵ−$贪婪法在当前Q值输出中选择对应的动作 $A$ c) 在状态 $S$ 执行当前动作 $A$,得到新状态 $S’$ 对应的特征向量 $ϕ(S’)$ 和奖励 $R$,是否终止状态is_end d) 将 $\\\\{ϕ(S),A,R,ϕ(S′),is_end\\\\}$这个五元组存入经验回放集合 $D$ e) $S=S'$ f) 从经验回放集合 $D$ 中采样 $m$ 个样本 ${ϕ(S_j),A_j,R_j,ϕ(S’_j),is_end_j},j=1,2.,,,m$，计算当前目标Q值 $y_j$： $$\\left.y_j=\\left\\\\{\\begin{array}{ll}R_j\u0026is_end_j\\textit{ is true}\\\\\\\\R_j+\\gamma\\max_{a^{\\prime}}Q^{\\prime}(\\phi(S_j^{\\prime}),A_j^{\\prime},w^{\\prime})\u0026is_end_j\\textit{ is false}\\end{array}\\right.\\right.$$ g) 使用均方差损失函数 $\\frac1m\\sum_{j=1}^m(y_j-Q(\\phi(S_j),A_j,w))^2$，通过神经网络的梯度反向传播来更新Q网络的所有参数 $w$ h) 如果 $i%C=1$, 则更新目标Q网络参数 $w’=w$ i) 如果 $S’$是终止状态，当前轮迭代完毕，否则转到步骤b) 注意，上述第二步的f步和g步的Q值计算也都需要通过Q网络计算得到。另外，实际应用中，为了算法较好的收敛，探索率 $ϵ$ 需要随着迭代的进行而变小。 4. Nature DQN算法实例 下面我们用一个具体的例子来演示DQN的应用。仍然使用了OpenAI Gym中的CartPole-v0游戏来作为我们算法应用。CartPole-v0游戏的介绍参见这里。它比较简单，基本要求就是控制下面的cart移动使连接在上面的pole保持垂直不倒。这个任务只有两个离散动作，要么向左用力，要么向右用力。而state状态就是这个cart的位置和速度， pole的角度和角速度，4维的特征。坚持到200分的奖励则为过关。 完整的代码参见github: https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/nature_dqn.py 这里我们重点关注Nature DQN和上一节的NIPS 2013 DQN的代码的不同之处。 首先是Q网络，上一篇的DQN是一个三层的神经网络，而这里我们有两个一样的三层神经网络，一个是当前Q网络，一个是目标Q网络，网络的定义部分如下： def create_Q_network(self): # input layer self.state_input = tf.placeholder(\"float\", [None, self.state_dim]) # network weights with tf.variable_scope('current_net'): W1 = self.weight_variable([self.state_dim,20]) b1 = self.bias_variable([20]) W2 = self.weight_variable([20,self.action_dim]) b2 = self.bias_variable([self.action_dim]) # hidden layers h_layer = tf.nn.relu(tf.matmul(self.state_input,W1) + b1) # Q Value layer self.Q_value = tf.matmul(h_layer,W2) + b2 with tf.variable_scope('target_net'): W1t = self.weight_variable([self.state_dim,20]) b1t = self.bias_variable([20]) W2t = self.weight_variable([20,self.action_dim]) b2t = self.bias_variable([self.action_dim]) # hidden layers h_layer_t = tf.nn.relu(tf.matmul(self.state_input,W1t) + b1t) # Q Value layer self.target_Q_value = tf.matmul(h_layer,W2t) + b2t 对于定期将目标Q网络的参数更新的代码如下面两部分： t_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='target_net') e_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='current_net') with tf.variable_scope('soft_replacement'): self.target_replace_op = [tf.assign(t, e) for t, e in zip(t_params, e_params)] def update_target_q_network(self, episode): # update target Q netowrk if episode % REPLACE_TARGET_FREQ == 0: self.session.run(self.target_replace_op) #print('episode '+str(episode) +', target Q network params replaced!') 此外，注意下我们计算目标Q值的部分，这里使用的目标Q网络的参数，而不是当前Q网络的参数： # Step 2: calculate y y_batch = [] Q_value_batch = self.targe","date":"2024-02-23","objectID":"/posts/rl_learning_note_9/:0:0","tags":["RL"],"title":"强化学习笔记 [9] | Deep Q-Learning进阶之Nature DQN","uri":"/posts/rl_learning_note_9/"},{"categories":["RL"],"content":"0. 引言 在强化学习系列的前七篇里，我们主要讨论的都是规模比较小的强化学习问题求解算法。今天开始我们步入深度强化学习。这一篇关注于价值函数的近似表示和Deep Q-Learning算法。 Deep Q-Learning这一篇对应Sutton书的第11章部分和UCL强化学习课程的第六讲。 1. 为何需要价值函数的近似表示 在之前讲到了强化学习求解方法，无论是动态规划DP，蒙特卡罗方法MC，还是时序差分TD，使用的状态都是离散的有限个状态集合 $S$。此时问题的规模比较小，比较容易求解。但是假如我们遇到复杂的状态集合呢？甚至很多时候，状态是连续的，那么就算离散化后，集合也很大，此时我们的传统方法，比如Q-Learning，根本无法在内存中维护这么大的一张Q表。　比如经典的冰球世界(PuckWorld)强化学习问题，具体的动态demo见这里。环境由一个正方形区域构成代表着冰球场地，场地内大的圆代表着运动员个体，小圆代表着目标冰球。在这个正方形环境中，小圆会每隔一定的时间随机改变在场地的位置，而代表个体的大圆的任务就是尽可能快的接近冰球目标。大圆可以操作的行为是在水平和竖直共四个方向上施加一个时间步时长的一个大小固定的力，借此来改变大圆的速度。环境会在每一个时间步内告诉个体当前的水平与垂直坐标、当前的速度在水平和垂直方向上的分量以及目标的水平和垂直坐标共6项数据，奖励值为个体与目标两者中心距离的负数，也就是距离越大奖励值越低且最高奖励值为0。 在这个问题中，状态是一个6维的向量，并且是连续值。没法直接用之前离散集合的方法来描述状态。当然，你可以说，我们可以把连续特征离散化。比如把这个冰球场100x100的框按1x1的格子划分成10000个格子，那么对于运动员的坐标和冰球的坐标就有$10^4∗10^4=10^8$次种，如果再加上个体速度的分量就更是天文数字了，此时之前讲过的强化学习方法都会因为问题的规模太大而无法使用。怎么办呢？必须要对问题的建模做修改了，而价值函数的近似表示就是一个可行的方法。 2. 价值函数的近似表示方法 由于问题的状态集合规模大，一个可行的建模方法是价值函数的近似表示。方法是我们引入一个状态价值函数 $\\hat{v}$, 这个函数由参数 $w$ 描述，并接受状态 $s$ 作为输入，计算后得到状态 $s$ 的价值，即我们期望： $$\\hat{v}(s,w)\\approx v_\\pi(s)$$ 类似的，引入一个动作价值函数 $\\hat{q}$，这个函数由参数 $w$ 描述，并接受状态 $s$ 与动作 $a$ 作为输入，计算后得到动作价值，即我们期望： $$\\hat{q}(s,a,w)\\approx q_\\pi(s,a)$$ 价值函数近似的方法很多，比如最简单的线性表示法，用 $ϕ(s)$表示状态 $s$ 的特征向量，则此时我们的状态价值函数可以近似表示为： $$\\hat{v}(s,w)=\\phi(s)^Tw$$ 当然，除了线性表示法，我们还可以用决策树，最近邻，傅里叶变换，神经网络来表达我们的状态价值函数。而最常见，应用最广泛的表示方法是神经网络。因此后面我们的近似表达方法如果没有特别提到，都是指的神经网络的近似表示。 对于神经网络，可以使用DNN，CNN或者RNN。没有特别的限制。如果把我们计算价值函数的神经网络看做一个黑盒子，那么整个近似过程可以看做下面这三种情况： 神经网络拟合价值函数 对于状态价值函数，神经网络的输入是状态s的特征向量，输出是状态价值 $\\hat{v}(s,w)$。对于动作价值函数，有两种方法，一种是输入状态 $s$ 的特征向量和动作 $a$，输出对应的动作价值 $\\hat{q}(s,a,w)$，另一种是只输入状态 $s$ 的特征向量，动作集合有多少个动作就有多少个输出 $\\hat{q}(s,ai,w)$。这里隐含了我们的动作是有限个的离散动作。 对于我们前一篇讲到的Q-Learning算法，我们现在就价值函数的近似表示来将其改造，采用上面右边的第三幅图的动作价值函数建模思路来做，现在我们叫它Deep Q-Learning。 3. Deep Q-Learning算法思路 Deep Q-Learning算法的基本思路来源于Q-Learning。但是和Q-Learning不同的地方在于，它的Q值的计算不是直接通过状态值s和动作来计算，而是通过上面讲到的Q网络来计算的。这个Q网络是一个神经网络，我们一般简称Deep Q-Learning为DQN。 DQN的输入是我们的状态s对应的状态向量 $ϕ(s)$， 输出是所有动作在该状态下的动作价值函数Q。Q网络可以是DNN，CNN或者RNN，没有具体的网络结构要求。 DQN主要使用的技巧是经验回放(experience replay), 即将每次和环境交互得到的奖励与状态更新情况都保存起来，用于后面目标Q值的更新。为什么需要经验回放呢？我们回忆一下Q-Learning，它是有一张Q表来保存所有的Q值的当前结果的，但是DQN是没有的，那么在做动作价值函数更新的时候，就需要其他的方法，这个方法就是经验回放。 通过经验回放得到的目标Q值和通过Q网络计算的Q值肯定是有误差的，那么我们可以通过梯度的反向传播来更新神经网络的参数 $w$，当 $w$ 收敛后，我们的就得到的近似的Q值计算方法，进而贪婪策略也就求出来了。 下面我们总结下DQN的算法流程，基于NIPS 2013 DQN。　算法输入：迭代轮数 $T$，状态特征维度 $n$, 动作集 $A$, 步长 $α$，衰减因子 $γ$, 探索率 $ϵ$, Q网络结构, 批量梯度下降的样本数 $m$。 输出：Q网络参数 随机初始化$Q$网络的所有参数 $w$，基于 $w$初始化所有的状态和动作对应的价值 $Q$。清空经验回放的集合 $D$。 for i from 1 to T，进行迭代。 a) 初始化S为当前状态序列的第一个状态, 拿到其特征向量 $ϕ(S)$ b) 在Q网络中使用 $ϕ(S)$ 作为输入，得到Q网络的所有动作对应的Q值输出。用 $ϵ−$贪婪法在当前Q值输出中选择对应的动作 $A$ c) 在状态 $S$执行当前动作 $A$,得到新状态 $S’$对应的特征向量 $ϕ(S’)$和奖励 $R$,是否终止状态is_end d) 将 $\\\\{ϕ(S),A,R,ϕ(S’),is_end\\\\}$这个五元组存入经验回放集合D e) $S=S'$ f) 从经验回放集合 $D$ 中采样 $m$ 个样本 ${ϕ(Sj),Aj,Rj,ϕ(S′j),is_endj},j=1,2.,,,m$，计算当前目标Q值$y_j$： $$\\left.y_j=\\left\\\\{\\begin{array}{ll}R_j\u0026is_end_j\\mathrm{~}is\\mathrm{~}true\\\\\\\\R_j+\\gamma\\max_{a^{\\prime}}Q(\\phi(S_j^{\\prime}),A_j^{\\prime},w)\u0026is_end_j\\mathrm{~}is\\mathrm{~}false\\end{array}\\right.\\right.$$ g) 使用均方差损失函数$\\frac1m\\sum_{i=1}^m(y_j-Q(\\phi(S_j),A_j,w))^2$，通过神经网络的梯度反向传播来更新Q网络的所有参数 $w$ h) 如果$S’$是终止状态，当前轮迭代完毕，否则转到步骤b) 注意，上述第二步的 $f$步和 $g$步的 $Q$值计算也都需要通过 $Q$网络计算得到。另外，实际应用中，为了算法较好的收敛，探索率 $ϵ$需要随着迭代的进行而变小。 4. Deep Q-Learning实例 下面我们用一个具体的例子来演示DQN的应用。这里使用了OpenAI Gym中的CartPole-v0游戏来作为我们算法应用。CartPole-v0游戏的介绍参见这里。它比较简单，基本要求就是控制下面的cart移动使连接在上面的pole保持垂直不倒。这个任务只有两个离散动作，要么向左用力，要么向右用力。而state状态就是这个cart的位置和速度， pole的角度和角速度，4维的特征。坚持到200分的奖励则为过关。 完整的代码参见github: https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/dqn.py 代码参考了知乎上的一个DQN实例，修改了代码中的一些错误，并用最新的Python3.6+Tensorflow1.8.0运行。要跑代码需要安装OpenAI的Gym库，使用pip install gym即可。 代码使用了一个三层的神经网络，输入层，一个隐藏层和一个输出层。下面我们看看关键部分的代码。 算法第2步的步骤b通过$ϵ−$贪婪法选择动作的代码如下，注意每次我们$ϵ−$贪婪法后都会减小$ϵ$值。 def egreedy_action(self,state): Q_value = self.Q_value.eval(feed_dict = { self.state_input:[state] })[0] if random.random() \u003c= self.epsilon: self.epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) / 10000 return random.randint(0,self.action_dim - 1) else: self.epsilon -= (INITIAL_EPSILON - FINAL_EPSILON) ","date":"2024-02-23","objectID":"/posts/rl_learning_note_8/:0:0","tags":["RL"],"title":"强化学习笔记 [8] | 价值函数的近似表示与Deep Q-Learning","uri":"/posts/rl_learning_note_8/"},{"categories":["RL"],"content":"0. 引言 在强化学习（六）时序差分在线控制算法SARSA中我们讨论了时序差分的在线控制算法SARSA，而另一类时序差分的离线控制算法还没有讨论，因此本文我们关注于时序差分离线控制算法，主要是经典的Q-Learning算法。 Q-Learning这一篇对应Sutton书的第六章部分和UCL强化学习课程的第五讲部分。 1. Q-Learning算法的引入　Q-Learning算法是一种使用时序差分求解强化学习控制问题的方法，回顾下此时我们的控制问题可以表示为：给定强化学习的5个要素：状态集 $S$, 动作集 $A$, 即时奖励 $R$，衰减因子 $γ$, 探索率 $ϵ$, 求解最优的动作价值函数 $q∗$和最优策略 $π∗$。 这一类强化学习的问题求解不需要环境的状态转化模型，是不基于模型的强化学习问题求解方法。对于它的控制问题求解，和蒙特卡罗法类似，都是价值迭代，即通过价值函数的更新，来更新策略，通过策略来产生新的状态和即时奖励，进而更新价值函数。一直进行下去，直到价值函数和策略都收敛。 再回顾下时序差分法的控制问题，可以分为两类，一类是在线控制，即一直使用一个策略来更新价值函数和选择新的动作，比如我们上一篇讲到的SARSA, 而另一类是离线控制，会使用两个控制策略，一个策略用于选择新的动作，另一个策略用于更新价值函数。这一类的经典算法就是Q-Learning。 对于Q-Learning，我们会使用 $ϵ−$贪婪法来选择新的动作，这部分和SARSA完全相同。但是对于价值函数的更新，Q-Learning使用的是贪婪法，而不是SARSA的 $ϵ−$贪婪法。这一点就是SARSA和Q-Learning本质的区别。 2. Q-Learning算法概述 Q-Learning算法的拓扑图如下图所示： Q Learning 拓扑图 首先我们基于状态 $S$，用 $ϵ−$贪婪法选择到动作 $A$, 然后执行动作$A$，得到奖励 $R$，并进入状态 $S’$，此时，如果是SARSA，会继续基于状态 $S’$，用 $ϵ−$贪婪法选择 $A’$,然后来更新价值函数。但是Q-Learning则不同。 对于Q-Learning，它基于状态 $S’$，没有使用 $ϵ−$贪婪法选择 $A$，而是使用贪婪法选择 $A’$，也就是说，选择使 $Q(S’,a)$ 最大的 $a$ 作为 $A’$来更新价值函数。用数学公式表示就是： $$Q(S,A)=Q(S,A)+\\alpha(R+\\gamma\\max_aQ(S^{\\prime},a)-Q(S,A))$$ 对应到上图中就是在图下方的三个黑圆圈动作中选择一个使 $Q(S’,a)$最大的动作作为 $A’$。 此时选择的动作只会参与价值函数的更新，不会真正的执行。价值函数更新后，新的执行动作需要基于状态 $S’$，用 $ϵ−$贪婪法重新选择得到。这一点也和SARSA稍有不同。对于SARSA，价值函数更新使用的 $A’$ 会作为下一阶段开始时候的执行动作。 下面我们对Q-Learning算法做一个总结。 3. Q-Learning算法流程 下面我们总结下Q-Learning算法的流程。 算法输入：迭代轮数 $T$，状态集 $S$, 动作集 $A$, 步长 $α$，衰减因子 $γ$, 探索率 $ϵ$, 输出: 所有的状态和动作对应的价值 $Q$ 随机初始化所有的状态和动作对应的价值Q�. 对于终止状态其Q�值初始化为0. for i from 1 to T，进行迭代。 a) 初始化 $S$ 为当前状态序列的第一个状态。 b) 用 $ϵ−$贪婪法在当前状态 $S$ 选择出动作 $A$ c) 在状态 $S$执行当前动作 $A$,得到新状态 $S’$和奖励 $R$ d) 更新价值函数 $Q(S,A)$: $$Q(S,A)+\\alpha(R+\\gamma\\max_aQ(S^{\\prime},a)-Q(S,A))$$ e) $S=S'$ f) 如果$S’$是终止状态，当前轮迭代完毕，否则转到步骤b) 4. Q-Learning算法实例：Windy GridWorld 我们还是使用和SARSA一样的例子来研究Q-Learning。如果对windy gridworld的问题还不熟悉，可以复习强化学习（六）时序差分在线控制算法SARSA第4节的第二段。 完整的代码参见github: https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/q_learning_windy_world.py 绝大部分代码和SARSA是类似的。这里我们可以重点比较和SARSA不同的部分。区别都在episode()这个函数里面。 首先是初始化的时候，我们只初始化状态 $S$,把 $A$ 的产生放到了while循环里面, 而回忆下SARSA会同时初始化状态 $S$ 和动作 $A$，再去执行循环。下面这段Q-Learning的代码对应我们算法的第二步步骤a和b： # play for an episode def episode(q_value): # track the total time steps in this episode time = 0 # initialize state state = START while state != GOAL: # choose an action based on epsilon-greedy algorithm if np.random.binomial(1, EPSILON) == 1: action = np.random.choice(ACTIONS) else: values_ = q_value[state[0], state[1], :] action = np.random.choice([action_ for action_, value_ in enumerate(values_) if value_ == np.max(values_)]) 接着我们会去执行动作 $A$,得到 $S’$， 由于奖励不是终止就是-1，不需要单独计算。,这部分和SARSA的代码相同。对应我们Q-Learning算法的第二步步骤c： next_state = step(state, action) def step(state, action): i, j = state if action == ACTION_UP: return [max(i - 1 - WIND[j], 0), j] elif action == ACTION_DOWN: return [max(min(i + 1 - WIND[j], WORLD_HEIGHT - 1), 0), j] elif action == ACTION_LEFT: return [max(i - WIND[j], 0), max(j - 1, 0)] elif action == ACTION_RIGHT: return [max(i - WIND[j], 0), min(j + 1, WORLD_WIDTH - 1)] else: assert False 后面我们用贪婪法选择出最大的 $Q(S’,a)$,并更新价值函数，最后更新当前状态 $S$。对应我们Q-Learning算法的第二步步骤d,e。注意SARSA这里是使用ϵ−�−贪婪法，而不是贪婪法。同时SARSA会同时更新状态S�和动作A�,而Q-Learning只会更新当前状态S�。 values_ = q_value[next_state[0], next_state[1], :] next_action = np.random.choice([action_ for action_, value_ in enumerate(values_) if value_ == np.max(values_)]) # Sarsa update q_value[state[0], state[1], action] += \\ ALPHA * (REWARD + q_value[next_state[0], next_state[1], next_action] - q_value[state[0], state[1], action]) state = next_state 跑完完整的代码，大家可以很容易得到这个问题的最优解，进而得到在每个格子里的最优贪婪策略。 5. SARSA vs Q-Learning 现在SARSA和Q-Learning算法我们都讲完了，那么作为时序差分控制算法的两种经典方法吗，他们都有说明特点，各自适用于什么样的场景呢？ Q-Learning直接学习的是 最优策略，而SARSA在学习最优策略的同时还在做探索。这导致我们在学习最优策略的时候，如果用SARSA，为了保证收敛，需要制定一个策略，使 $ϵ−$贪婪法的超参数 $ϵ$在迭代的过程中逐渐变小。Q-Learning没有这个烦恼。 另外一个就是Q-Learning直接学习最优策略，但是最优策略会依赖于训练中产生的一系列数据，所以受样本数据的影响较大，因此受到训练数据方差的影响很大，甚至会影响Q函数的收敛。Q-Learning的深度强化学习版Deep Q-Learning也有这个问题。 在学习过程中，SARSA在收敛的过程中鼓励探索，这样学习过程会比较平滑，不至于过于激进，导致出现像Q-Learning可能遇到一些特殊的最优“陷阱”。比如经典的强化学习问题\"Cliff Wa","date":"2024-02-23","objectID":"/posts/rl_learning_note_7/:0:0","tags":["RL"],"title":"强化学习笔记 [7] | 时序差分离线控制算法Q-Learning","uri":"/posts/rl_learning_note_7/"},{"categories":["draft"],"content":"0 引言 在强化学习（四）用蒙特卡罗法（MC）求解中，我们讲到了使用蒙特卡罗法来求解强化学习问题的方法，虽然蒙特卡罗法很灵活，不需要环境的状态转化概率模型，但是它需要所有的采样序列都是经历完整的状态序列。如果我们没有完整的状态序列，那么就无法使用蒙特卡罗法求解了。本文我们就来讨论可以不使用完整状态序列求解强化学习问题的方法：时序差分(Temporal-Difference, TD)。 时序差分这一篇对应Sutton书的第六章部分和UCL强化学习课程的第四讲部分，第五讲部分。 1. 时序差分TD简介 时序差分法和蒙特卡罗法类似，都是不基于模型的强化学习问题求解方法。所以在上一篇定义的不基于模型的强化学习控制问题和预测问题的定义，在这里仍然适用。 预测问题：即给定强化学习的5个要素：状态集 $S$, 动作集 $A$, 即时奖励 $R$，衰减因子 $γ$, 给定策略 $π$， 求解该策略的状态价值函数 $v(π)$ 控制问题：也就是求解最优的价值函数和策略。给定强化学习的5个要素：状态集 $S$, 动作集 $A$, 即时奖励 $R$，衰减因子 $γ$, 探索率 $ϵ$, 求解最优的动作价值函数 $q∗$ 和最优策略 $π∗$　回顾蒙特卡罗法中计算状态收获的方法是： $$G_t=R_{t+1}+\\gamma R_{t+2}+\\gamma^2R_{t+3}+\\ldots\\gamma^{T-t-1}R_T$$ 而对于时序差分法来说，我们没有完整的状态序列，只有部分的状态序列，那么如何可以近似求出某个状态的收获呢？回顾强化学习（二）马尔科夫决策过程(MDP)中的贝尔曼方程： $$v_\\pi(s)=\\mathbb{E}_\\pi(R_{t+1}+\\gamma v_\\pi(S_{t+1})|S_t=s)$$ 这启发我们可以用 $R_{t+1}+\\gamma v(S_{t+1})$ 来近似的代替收获 $G_t$,一般我们把 $R_{t+1}+\\gamma V(S_{t+1})$ 称为TD目标值。$R_{t+1}+\\gamma V(S_{t+1})-V(S_t)$ 称为TD误差，将用TD目标值近似代替收获 $G(t)$ 的过程称为引导(bootstrapping)。这样我们只需要两个连续的状态与对应的奖励，就可以尝试求解强化学习问题了。 现在我们有了自己的近似收获 $G_t$ 的表达式，那么就可以去求解时序差分的预测问题和控制问题了。 2. 时序差分TD的预测问题求解 时序差分的预测问题求解和蒙特卡罗法类似，但是主要有两个不同点。一是收获 $G_t$ 的表达式不同，时序差分 $G(t)$ 的表达式为： $$G(t)=R_{t+1}+\\gamma V(S_{t+1})$$ 二是迭代的式子系数稍有不同，回顾蒙特卡罗法的迭代式子是： $$V(S_t)=V(S_t)+\\frac1{N(S_t)}(G_t-V(S_t))$$ 由于在时序差分我们没有完整的序列，也就没有对应的次数 $N(S_t)$ ,一般就用一个[0,1]的系数 $α$ 代替。这样时序差分的价值函数迭代式子是： $$V(S_t)=V(S_t)+\\alpha(G_t-V(S_t)) \\\\\\\\ Q(S_t,A_t)=Q(S_t,A_t)+\\alpha(G_t-Q(S_t,A_t)) $$ 这里我们用一个简单的例子来看看蒙特卡罗法和时序差分法求解预测问题的不同。 假设我们的强化学习问题有A,B两个状态，模型未知，不涉及策略和行为。只涉及状态转化和即时奖励。一共有8个完整的状态序列如下： ① A,0,B,0 ②B,1 ③B,1 ④ B,1 ⑤ B,1 ⑥B,1 ⑦B,1 ⑧B,0 只有第一个状态序列是有状态转移的，其余7个只有一个状态。设置衰减因子 $γ=1$。 首先我们按蒙特卡罗法来求解预测问题。由于只有第一个序列中包含状态A，因此A的价值仅能通过第一个序列来计算，也就等同于计算该序列中状态A的收获： $$V(A)=G(A)=R_A+\\gamma R_B=0$$ 对于B，则需要对其在8个序列中的收获值来平均，其结果是6/8。 再来看看时序差分法求解的过程。其收获是在计算状态序列中某状态价值时是应用其后续状态的预估价值来计算的，对于B来说，它总是终止状态，没有后续状态，因此它的价值直接用其在8个序列中的收获值来平均，其结果是6/8。 对于A，只在第一个序列出现，它的价值为： $$V(A)=R_A+\\gamma V(B)=\\frac68$$ 从上面的例子我们也可以看到蒙特卡罗法和时序差分法求解预测问题的区别。 一是时序差分法在知道结果之前就可以学习，也可以在没有结果时学习，还可以在持续进行的环境中学习，而蒙特卡罗法则要等到最后结果才能学习，时序差分法可以更快速灵活的更新状态的价值估计，这在某些情况下有着非常重要的实际意义。 二是时序差分法在更新状态价值时使用的是TD 目标值，即基于即时奖励和下一状态的预估价值来替代当前状态在状态序列结束时可能得到的收获，是当前状态价值的有偏估计，而蒙特卡罗法则使用实际的收获来更新状态价值，是某一策略下状态价值的无偏估计，这一点蒙特卡罗法占优。 三是虽然时序差分法得到的价值是有偏估计，但是其方差却比蒙特卡罗法得到的方差要低，且对初始值敏感，通常比蒙特卡罗法更加高效。 从上面的描述可以看出时序差分法的优势比较大，因此现在主流的强化学习求解方法都是基于时序差分的。后面的文章也会主要基于时序差分法来扩展讨论。 3. n步时序差分 在第二节的时序差分法中，我们使用了用 $R_{t+1}+\\gamma v(S_{t+1})$ 来近似的代替收获 $G_t$。即向前一步来近似我们的收获 $G_{t}$,那么能不能向前两步呢？当然可以，这时我们的收获 $G_t$ 的近似表达式为： $$G_t^{(2)}=R_{t+1}+\\gamma R_{t+2}+\\gamma^2V(S_{t+2})$$ 从两步，到三步，再到n步，我们可以归纳出n步时序差分收获 $G^{(n)}_t$表达式为：$$G_t^{(n)}=R_{t+1}+\\gamma R_{t+2}+\\ldots+\\gamma^{n-1}R_{t+n}+\\gamma^nV(S_{t+n})$$ 当n越来越大，趋于无穷，或者说趋于使用完整的状态序列时，n步时序差分就等价于蒙特卡罗法了。 对于n步时序差分来说，和普通的时序差分的区别就在于收获的计算方式的差异。那么既然有这个n步的说法，那么n到底是多少步好呢？如何衡量n的好坏呢？我们在下一节讨论。 4. TD(λ) n步时序差分选择多少步数作为一个较优的计算参数是需要尝试的超参数调优问题。为了能在不增加计算复杂度的情况下综合考虑所有步数的预测，我们引入了一个新[0,1]的参数 $\\lambda$,定义入—收获是 $n$ 从 $1$ 到 $\\infty$ 所有步的收获乘以权重的和。每一步的权重是 $(1-\\lambda)\\lambda^{n-1}$,这样 $\\lambda-$收获的计算公式表示为: $$G_t^\\lambda=(1-\\lambda)\\sum_{n=1}^\\infty\\lambda^{n-1}G_t^{(n)}$$ 进而我们可以得到 $TD(λ)$ 的价值函数的迭代公式： $$V(S_t)=V(S_t)+\\alpha(G_t^\\lambda-V(S_t)) \\\\\\\\ Q(S_t,A_t)=Q(S_t,A_t)+\\alpha(G_t^\\lambda-Q(S_t,A_t)) $$ 每一步收获的权重定义为 $(1−λ)λ^{n−1}$ 的原因是什么呢？其图像如下图所示，可以看到随着n的增大，其第n步收获的权重呈几何级数的衰减。当在T时刻到达终止状态时，未分配的权重全部给予终止状态的实际收获值。这样可以使一个完整的状态序列中所有的n步收获的权重加起来为1，离当前状态越远的收获其权重越小。 TD(λ) 从前向来看 $TD(λ)$， 一个状态的价值 $V(St)$由 $G_t$得到，而Gt��又间接由所有后续状态价值计算得到，因此可以认为更新一个状态的价值需要知道所有后续状态的价值。也就是说，必须要经历完整的状态序列获得包括终止状态的每一个状态的即时奖励才能更新当前状态的价值。这和蒙特卡罗法的要求一样，因此TD(λ)��(�)有着和蒙特卡罗法一样的劣势。当 $λ=0$ 时,就是第二节讲到的普通的时序差分法，当 $λ=1$ 时,就是蒙特卡罗法。 从反向来看 $TD(λ)$，它可以分析我们状态对后续状态的影响。比如老鼠在依次连续接受了3 次响铃和1 次亮灯信号后遭到了电击，那么在分析遭电击的原因时，到底是响铃的因素较重要还是亮灯的因素更重要呢？如果把老鼠遭到电击的原因认为是之前接受了较多次数的响铃，则称这种归因为频率启发(frequency heuristic) 式；而把电击归因于最近少数几次状态的影响，则称为就近启发(recency heuristic) 式。 如果给每一个状态引入一个数值：效用(eligibility, E) 来表示该状态对后续状态的影响，就可以同时利用到上述两个启发。而所有状态的效用值总称为效用迹(eligibility traces,ES)。定义为： $$ E_0(s)=0 \\\\\\\\ \\left.E_t(s)=\\gamma\\lambda E_{t-1}(s)+1(S_t=s)=\\left\\\\{\\begin{array}{ll}0\u0026t\u003ck\\\\\\\\(\\gamma\\lambda)^{t-k}\u0026t\\geq k\\end{array}\\right.\\right.,\\quad s.t.\\quad\\lambda,\\","date":"2024-02-22","objectID":"/posts/rl_learning_note_5/:0:0","tags":["draft"],"title":"RL学习笔记 [5] | 用时序差分法（TD）求解","uri":"/posts/rl_learning_note_5/"},{"categories":["RL"],"content":"0. 引言 在强化学习（五）用时序差分法（TD）求解中，我们讨论了用时序差分来求解强化学习预测问题的方法，但是对控制算法的求解过程没有深入，本文我们就对时序差分的在线控制算法SARSA做详细的讨论。 SARSA这一篇对应Sutton书的第六章部分和UCL强化学习课程的第五讲部分。 1. SARSA算法的引入 SARSA算法是一种使用时序差分求解强化学习控制问题的方法，回顾下此时我们的控制问题可以表示为：给定强化学习的5个要素：状态集 $S$, 动作集 $A$, 即时奖励 $R$，衰减因子 $γ$, 探索率 $ϵ$, 求解最优的动作价值函数 $q∗$ 和最优策略 $π∗$。 这一类强化学习的问题求解不需要环境的状态转化模型，是不基于模型的强化学习问题求解方法。对于它的控制问题求解，和蒙特卡罗法类似，都是价值迭代，即通过价值函数的更新，来更新当前的策略，再通过新的策略，来产生新的状态和即时奖励，进而更新价值函数。一直进行下去，直到价值函数和策略都收敛。 再回顾下时序差分法的控制问题，可以分为两类，一类是在线控制，即一直使用一个策略来更新价值函数和选择新的动作。而另一类是离线控制，会使用两个控制策略，一个策略用于选择新的动作，另一个策略用于更新价值函数。 我们的SARSA算法，属于在线控制这一类，即一直使用一个策略来更新价值函数和选择新的动作，而这个策略是 $ϵ−$贪婪法，在强化学习（四）用蒙特卡罗法（MC）求解中，我们对于 $ϵ−$贪婪法有详细讲解，即通过设置一个较小的 $ϵ$ 值，使用 $1−ϵ$ 的概率贪婪地选择目前认为是最大行为价值的行为，而用 $ϵ$ 的概率随机的从所有 m 个可选行为中选择行为。用公式可以表示为： $$\\left.\\pi(a|s)=\\left\\\\{\\begin{array}{ll}\\epsilon/m+1-\\epsilon\u0026if\\mathrm{~}a^*=\\arg\\max_{a\\in A}Q(s,a)\\\\\\\\\\epsilon/m\u0026else\\end{array}\\right.\\right.$$ π(a|s)={ϵ/m+1−ϵifa∗=argmaxa∈AQ(s,a)ϵ/melse�(�|�)={�/�+1−����∗=arg⁡max�∈��(�,�)�/����� 2. SARSA算法概述 作为SARSA算法的名字本身来说，它实际上是由 $S,A,R,S,A$ 几个字母组成的。而 $S,A,R$ 分别代表状态（State），动作(Action),奖励(Reward)，这也是我们前面一直在使用的符号。这个流程体现在下图： SARSA Transition 在迭代的时候，我们首先基于 $ϵ−$贪婪法在当前状态 $S$ 选择一个动作 $A$ ，这样系统会转到一个新的状态 $S′$, 同时给我们一个即时奖励 $R$ , 在新的状态 $S′$，我们会基于 $ϵ−$贪婪法在状态 $S′$ 选择一个动作 $A′$，但是注意这时候我们并不执行这个动作 $A′$，只是用来更新的我们的价值函数，价值函数的更新公式是： $$Q(S,A)=Q(S,A)+\\alpha(R+\\gamma Q(S^{\\prime},A^{\\prime})-Q(S,A))$$ 其中，$γ$ 是衰减因子，$α$ 是迭代步长。这里和蒙特卡罗法求解在线控制问题的迭代公式的区别主要是，收获 $G_t$的表达式不同，对于时序差分，收获 $G_t$的表达式是 $R+\\gamma Q(S’,A’)$ 。这个价值函数更新的贝尔曼公式我们在强化学习（五）用时序差分法（TD）求解第2节有详细讲到。 除了收获 $G_t$的表达式不同，SARSA算法和蒙特卡罗在线控制算法基本类似。 3. SARSA算法流程 下面我们总结下SARSA算法的流程。 算法输入：迭代轮数 $T$，状态集 $S$, 动作集 $A$, 步长 $α$，衰减因子 $γ$, 探索率 $ϵ$, 输出：所有的状态和动作对应的价值 $Q$ 随机初始化所有的状态和动作对应的价值Q�. 对于终止状态其Q�值初始化为0. for i from 1 to T，进行迭代。 a) 初始化 $S$ 为当前状态序列的第一个状态。设置 $A$ 为 $ϵ−$贪婪法在当前状态$S$ 选择的动作。 b) 在状态 $S$ 执行当前动作 $A$ ,得到新状态 $S′$ 和 奖励 $R$ c) 用 $\\epsilon-$贪婪法在状态 $S’$ 选择新的动作 $A'$ d) 更新价值函数 $Q(S,A)$: $$Q(S,A)=Q(S,A)+\\alpha(R+\\gamma Q(S^{\\prime},A^{\\prime})-Q(S,A))$$ e) $S=S′$, $A=A′$ f) 如果 $S′$ 是终止状态，当前轮迭代完毕，否则转到步骤b) 这里有一个要注意的是，步长 $α$一般需要随着迭代的进行逐渐变小，这样才能保证动作价值函数 $Q$ 可以收敛。当 $Q$ 收敛时，我们的策略 $ϵ−$贪婪法也就收敛了。 4. SARSA算法实例：Windy GridWorld 下面我们用一个著名的实例Windy GridWorld来研究SARSA算法。 如下图一个10×7的长方形格子世界，标记有一个起始位置 S 和一个终止目标位置 G，格子下方的数字表示对应的列中一定强度的风。当个体进入该列的某个格子时，会按图中箭头所示的方向自动移动数字表示的格数，借此来模拟世界中风的作用。同样格子世界是有边界的，个体任意时刻只能处在世界内部的一个格子中。个体并不清楚这个世界的构造以及有风，也就是说它不知道格子是长方形的，也不知道边界在哪里，也不知道自己在里面移动移步后下一个格子与之前格子的相对位置关系，当然它也不清楚起始位置、终止目标的具体位置。但是个体会记住曾经经过的格子，下次在进入这个格子时，它能准确的辨认出这个格子曾经什么时候来过。格子可以执行的行为是朝上、下、左、右移动一步，每移动一步只要不是进入目标位置都给予一个 -1 的惩罚，直至进入目标位置后获得奖励 0 同时永久停留在该位置。现在要求解的问题是个体应该遵循怎样的策略才能尽快的从起始位置到达目标位置。 Windy GridWorld 逻辑并不复杂，完整的代码在我的github。这里我主要看一下关键部分的代码。 算法中第2步步骤a,初始化 $S$,使用 $ϵ−$贪婪法在当前状态 $S$ 选择的动作的过程： # initialize state state = START # choose an action based on epsilon-greedy algorithm if np.random.binomial(1, EPSILON) == 1: action = np.random.choice(ACTIONS) else: values_ = q_value[state[0], state[1], :] action = np.random.choice([action_ for action_, value_ in enumerate(values_) if value_ == np.max(values_)]) 算法中第2步步骤b,在状态S�执行当前动作A�,得到新状态S′�′的过程，由于奖励不是终止就是-1，不需要单独计算： def step(state, action): i, j = state if action == ACTION_UP: return [max(i - 1 - WIND[j], 0), j] elif action == ACTION_DOWN: return [max(min(i + 1 - WIND[j], WORLD_HEIGHT - 1), 0), j] elif action == ACTION_LEFT: return [max(i - WIND[j], 0), max(j - 1, 0)] elif action == ACTION_RIGHT: return [max(i - WIND[j], 0), min(j + 1, WORLD_WIDTH - 1)] else: assert False 算法中第2步步骤c,用 $ϵ−$贪婪法在状态 $S’$选择新的动作 $A′$的过程： next_state = step(state, action) if np.random.binomial(1, EPSILON) == 1: next_action = np.random.choice(ACTIONS) else: values_ = q_value[next_state[0], next_state[1], :] next_action = np.random.choice([action_ for action_, value_ in enumerate(values_) if value_ == np.max(values_)]) 算法中第2步步骤d,e, 更新价值函数 $Q(S,A)$ 以及更新当前状态动作的过程： # Sarsa update q_value[state[0], state[1], action] += \\ ALPHA * (REWARD + q_value[next_state[0], next_state[1], next_action] - q_value[state[0], state[1], action]) state = next_state action = next_action 代码很简单，相信大家对照算法，跑跑代码，可以很容易得到这个","date":"2024-02-22","objectID":"/posts/rl_learning_note_6/:0:0","tags":["RL"],"title":"RL学习笔记 [6] | 时序差分在线控制算法SARSA","uri":"/posts/rl_learning_note_6/"},{"categories":["RL"],"content":"0. 引言 在强化学习（三）用动态规划（DP）求解中，我们讨论了用动态规划来求解强化学习预测问题和控制问题的方法。但是由于动态规划法需要在每一次回溯更新某一个状态的价值时，回溯到该状态的所有可能的后续状态。导致对于复杂问题计算量很大。同时很多时候，我们连环境的状态转化模型 $P$ 都无法知道，这时动态规划法根本没法使用。这时候我们如何求解强化学习问题呢？本文要讨论的蒙特卡罗(Monte-Calo, MC)就是一种可行的方法。 蒙特卡罗法这一篇对应Sutton书的第五章和UCL强化学习课程的第四讲部分，第五讲部分。 1. 不基于模型的强化学习问题定义 在动态规划法中，强化学习的两个问题是这样定义的: 预测问题，即给定强化学习的6个要素：状态集 $S$, 动作集 $A$, 模型状态转化概率矩阵 $P$, 即时奖励 $R$，衰减因子 $γ$, 给定策略 $π$， 求解该策略的状态价值函数 $v(π)$ 控制问题，也就是求解最优的价值函数和策略。给定强化学习的5个要素：状态集 $S$, 动作集 $A$, 模型状态转化概率矩阵 $P$, 即时奖励 $R$，衰减因子 $γ$, 求解最优的状态价值函数 $v∗$ 和最优策略 $π∗$　可见, 模型状态转化概率矩阵 $P$ 始终是已知的，即MDP已知，对于这样的强化学习问题，我们一般称为基于模型的强化学习问题。 不过有很多强化学习问题，我们没有办法事先得到模型状态转化概率矩阵 $P$ ，这时如果仍然需要我们求解强化学习问题，那么这就是不基于模型的强化学习问题了。它的两个问题一般的定义是： 预测问题，即给定强化学习的5个要素：状态集 $S$, 动作集 $A$, 即时奖励 $R$，衰减因子 $γ$ , 给定策略 $π$， 求解该策略的状态价值函数 $v(π)$ 控制问题，也就是求解最优的价值函数和策略。给定强化学习的5个要素：状态集 $S$, 动作集 $A$, 即时奖励 $R$，衰减因子 $γ$, 探索率 $ϵ$, 求解最优的动作价值函数 $q∗$ 和最优策略 $π∗$　本文要讨论的蒙特卡罗法就是上述不基于模型的强化学习问题。 2. 蒙特卡罗法求解特点 蒙特卡罗这个词之前的博文也讨论过，尤其是在之前的MCMC系列中。它是一种通过采样近似求解问题的方法。这里的蒙特卡罗法虽然和MCMC不同，但是采样的思路还是一致的。那么如何采样呢？ 蒙特卡罗法通过采样若干经历完整的状态序列(episode)来估计状态的真实价值。所谓的经历完整，就是这个序列必须是达到终点的。比如下棋问题分出输赢，驾车问题成功到达终点或者失败。有了很多组这样经历完整的状态序列，我们就可以来近似的估计状态价值，进而求解预测和控制问题了。 从特卡罗法法的特点来说，一是和动态规划比，它不需要依赖于模型状态转化概率。二是它从经历过的完整序列学习，完整的经历越多，学习效果越好。 3. 蒙特卡罗法求解强化学习预测问题 这里我们先来讨论蒙特卡罗法求解强化学习预测问题的方法，即策略评估。一个给定策略 $π$ 的完整有T个状态的状态序列如下： $$S_1,A_1,R_2,S_2,A_2,\\ldots S_t,A_t,R_{t+1},\\ldots R_T,S_T$$ 回忆下强化学习（二）马尔科夫决策过程(MDP)中对于价值函数 $v_π(s)$的定义: $$v_\\pi(s)=\\mathbb{E}_\\pi(G_t|S_t=s)=\\mathbb{E}_\\pi(R_{t+1}+\\gamma R_{t+2}+\\gamma^2R_{t+3}+\\ldots|S_t=s)$$ 可以看出每个状态的价值函数等于所有该状态收获的期望，同时这个收获是通过后续的奖励与对应的衰减乘积求和得到。那么对于蒙特卡罗法来说，如果要求某一个状态的状态价值，只需要求出所有的完整序列中该状态出现时候的收获再取平均值即可近似求解，也就是： $$G_t=R_{t+1}+\\gamma R_{t+2}+\\gamma^2R_{t+3}+\\ldots\\gamma^{T-t-1}R_T$$ $$v_\\pi(s)\\approx average(G_t),s.t.S_t=s$$ 可以看出，预测问题的求解思路还是很简单的。不过有几个点可以优化考虑。 第一个点是: 同样一个状态可能在一个完整的状态序列中重复出现，那么该状态的收获该如何计算？有两种解决方法。第一种是仅把状态序列中第一次出现该状态时的收获值纳入到收获平均值的计算中；另一种是针对一个状态序列中每次出现的该状态，都计算对应的收获值并纳入到收获平均值的计算中。两种方法对应的蒙特卡罗法分别称为：首次访问(first visit) 和每次访问(every visit) 蒙特卡罗法。第二种方法比第一种的计算量要大一些，但是在完整的经历样本序列少的场景下会比第一种方法适用。 第二个点是累进更新平均值(incremental mean)。在上面预测问题的求解公式里，我们有一个average的公式，意味着要保存所有该状态的收获值之和最后取平均。这样浪费了太多的存储空间。一个较好的方法是在迭代计算收获均值，即每次保存上一轮迭代得到的收获均值与次数，当计算得到当前轮的收获时，即可计算当前轮收获均值和次数。通过下面的公式就很容易理解这个过程： $$\\mu_k=\\frac1k\\sum_{j=1}^kx_j=\\frac1k(x_k+\\sum_{j=1}^{k-1}x_j)=\\frac1k(x_k+(k-1)\\mu_{k-1})=\\mu_{k-1}+\\frac1k(x_k-\\mu_{k-1})$$ 这样上面的状态价值公式就可以改写成： $$N(S_t)=N(S_t)+1$$ $$V(S_t)=V(S_t)+\\frac1{N(S_t)}(G_t-V(S_t))$$ 这样我们无论数据量是多还是少，算法需要的内存基本是固定的 。 有时候，尤其是海量数据做分布式迭代的时候，我们可能无法准确计算当前的次数 $N(S_t)$,这时我们可以用一个系数 $α$ 来代替，即： $$V(S_t)=V(S_t)+\\alpha(G_t-V(S_t))$$ 对于动作价值函数 $Q(S_t,A_t)$,也是类似的，比如对上面最后一个式子，动作价值函数版本为： $$Q(S_t,A_t)=Q(S_t,A_t)+\\alpha(G_t-Q(S_t,A_t))$$ 以上就是蒙特卡罗法求解预测问题的整个过程，下面我们来看控制问题求解。 4. 蒙特卡罗法求解强化学习控制问题 蒙特卡罗法求解控制问题的思路和动态规划价值迭代的的思路类似。回忆下动态规划价值迭代的的思路， 每轮迭代先做策略评估，计算出价值 $v_k(s)$ ，然后基于据一定的方法（比如贪婪法）更新当前策略 $π$。最后得到最优价值函数 $v∗$ 和最优策略 $π∗$。 和动态规划比，蒙特卡罗法不同之处体现在三点: 一是预测问题策略评估的方法不同，这个第三节已经讲了。 第二是蒙特卡罗法一般是优化最优动作价值函数 $q∗$，而不是状态价值函数 $v∗$。 三是动态规划一般基于贪婪法更新策略。而蒙特卡罗法一般采用 $ϵ−$贪婪法更新。这个 $ϵ$ 就是我们在强化学习（一）模型基础中讲到的第8个模型要素 $ϵ$。$ϵ−$贪婪法通过设置一个较小的 $ϵ$ 值，使用 $1−ϵ$ 的概率贪婪地选择目前认为是最大行为价值的行为，而用 $ϵ$ 的概率随机的从所有 $m$ 个可选行为中选择行为。用公式可以表示为： $$\\left.\\pi(a|s)=\\left\\\\{\\begin{array}{ll}\\epsilon/m+1-\\epsilon\u0026if\\mathrm{~}a^*=\\arg\\max_{a\\in A}Q(s,a)\\\\\\\\\\epsilon/m\u0026else\\end{array}\\right.\\right.$$ 在实际求解控制问题时，为了使算法可以收敛，一般 $ϵ$会随着算法的迭代过程逐渐减小，并趋于0。这样在迭代前期，我们鼓励探索，而在后期，由于我们有了足够的探索量，开始趋于保守，以贪婪为主，使算法可以稳定收敛。这样我们可以得到一张和动态规划类似的图： Mento Carlo 搜索过程示意 5. 蒙特卡罗法控制问题算法流程 在这里总结下蒙特卡罗法求解强化学习控制问题的算法流程，这里的算法是在线(on-policy)版本的,相对的算法还有离线(off-policy)版本的。在线和离线的区别我们在后续的文章里面会讲。同时这里我们用的是every-visit,即个状态序列中每次出现的相同状态，都会计算对应的收获值。 在线蒙特卡罗法求解强化学习控制问题的算法流程如下: 输入：状态集 $S$, 动作集 $A$, 即时奖励 $R$，衰减因子 $γ$, 探索率$ϵ$ 输出：最优的动作价值函数 $q∗$ 和最优策略 $π∗$ 初始化所有的动作价值 $Q(s,a)=0$ ， 状态次数 $N(s,a)=0$，采样次数 $k=0$，随机初始化一个策略 $π$ $k=k+1$, 基于策略 $π$ 进行第k次蒙特卡罗采样，得到一个完整的状态序列: $$S_1,A_1,R_2,S_2,A_2,\\ldots S_t,A_t,R_{t+1},\\ldots R_T,S_T$$ 对于该状态序列里出现的每一状态行为对 $(S_t,A_t)$，计算其收获 $G_t$, 更新其计数 $N(s,a)$ 和行为价值函数 $Q(s,a)$： $$\\begin{gathered} G_t=R_{t+1}+\\gamma R_{t+2}+\\gamma^2R_{t+3}+\\ldots\\gamma^{T-t-1}R_T \\\\\\\\ N(S_t,A_t)=N(S_t,","date":"2024-02-22","objectID":"/posts/rl_learning_note_4/:0:0","tags":["RL"],"title":"RL学习笔记 [4] | 用蒙特卡罗法（MC）求解","uri":"/posts/rl_learning_note_4/"},{"categories":["RL"],"content":"0. 引言 在强化学习（二）马尔科夫决策过程(MDP)中，我们讨论了用马尔科夫假设来简化强化学习模型的复杂度，这一篇我们在马尔科夫假设和贝尔曼方程的基础上讨论使用动态规划(Dynamic Programming, DP)来求解强化学习的问题。 动态规划这一篇对应Sutton书的第四章和UCL强化学习课程的第三讲。 1. 动态规划和强化学习问题的联系 对于动态规划，相信大家都很熟悉，很多使用算法的地方都会用到。就算是机器学习相关的算法，使用动态规划的也很多，比如之前讲到的隐马尔科夫模型HMM（二）前向后向算法评估观察序列概率，隐马尔科夫模型HMM（四）维特比算法解码隐藏状态序列， 都是动态规划的典型例子。 动态规划的关键点有两个：一是问题的最优解可以由若干小问题的最优解构成，即通过寻找子问题的最优解来得到问题的最优解。第二是可以找到子问题状态之间的递推关系，通过较小的子问题状态递推出较大的子问题的状态。而强化学习的问题恰好是满足这两个条件的。 我们先看看强化学习的两个基本问题。 第一个问题是预测，即给定强化学习的6个要素：状态集 $S$, 动作集$A$, 模型状态转化概率矩阵$P$, 即时奖励$R$，衰减因子$γ$, 给定策略$π$， 求解该策略的状态价值函数$v(π)$ 第二个问题是控制，也就是求解最优的价值函数和策略。给定强化学习的5个要素：状态集$S$, 动作集$A$, 模型状态转化概率矩阵$P$, 即时奖励$R$，衰减因子$γ$, 求解最优的状态价值函数 $v∗$ 和最优策略 $π∗$　那么如何找到动态规划和强化学习这两个问题的关系呢？ 回忆一下上一篇强化学习（二）马尔科夫决策过程(MDP)中状态价值函数的贝尔曼方程： $$v_\\pi(s)=\\sum_{a\\in A}\\pi(a|s)(R_s^a+\\gamma\\sum_{s’ \\in S}P_{ss’}^av_\\pi(s’))$$ 从这个式子我们可以看出，我们可以定义出子问题求解每个状态的状态价值函数，同时这个式子又是一个递推的式子, 意味着利用它，我们可以使用上一个迭代周期内的状态价值来计算更新当前迭代周期某状态 $s$ 的状态价值。可见，使用动态规划来求解强化学习问题是比较自然的。 2. 策略评估求解预测问题 首先，我们来看如何使用动态规划来求解强化学习的预测问题，即求解给定策略的状态价值函数的问题。这个问题的求解过程我们通常叫做策略评估(Policy Evaluation)。 策略评估的基本思路是从任意一个状态价值函数开始，依据给定的策略，结合贝尔曼期望方程、状态转移概率和奖励同步迭代更新状态价值函数，直至其收敛，得到该策略下最终的状态价值函数。 假设我们在第k轮迭代已经计算出了所有的状态的状态价值，那么在第 $k+1$ 轮我们可以利用第k轮计算出的状态价值计算出第k+1+1轮的状态价值。这是通过贝尔曼方程来完成的，即： $$v_{k+1}(s)=\\sum_{a\\in A}\\pi(a|s)(R_s^a+\\gamma\\sum_{s’ \\in S}P_{ss’}^av_k(s’))$$ 和上一节的式子唯一的区别是由于我们的策略 $π$ 已经给定，我们不再写出，对应加上了迭代轮数的下标。我们每一轮可以对计算得到的新的状态价值函数再次进行迭代，直至状态价值的值改变很小(收敛)，那么我们就得出了预测问题的解，即给定策略的状态价值函数 $v(π)$。 下面我们用一个具体的例子来说明策略评估的过程。 3. 策略评估求解实例 这是一个经典的Grid World的例子。我们有一个4x4的16宫格。只有左上和右下的格子是终止格子。该位置的价值固定为0，个体如果到达了该2个格子，则停止移动，此后每轮奖励都是0。个体在16宫格其他格的每次移动，得到的即时奖励R都是-1。注意个体每次只能移动一个格子，且只能上下左右4种移动选择，不能斜着走, 如果在边界格往外走，则会直接移动回到之前的边界格。衰减因子我们定义为γ=1=1。由于这里每次移动，下一格都是固定的，因此所有可行的的状态转化概率P=1=1。这里给定的策略是随机策略，即每个格子里有25%的概率向周围的4个格子移动。 Grid World 首先我们初始化所有格子的状态价值为0，如上图 $k=0$ 的时候。现在我们开始策略迭代了。由于终止格子的价值固定为0，我们可以不将其加入迭代过程。在 $k=1$ 的时候，我们利用上面的贝尔曼方程先计算第二行第一个格子的价值： $$v_1^{(21)}=\\frac14[(-1+0)+(-1+0)+(-1+0)+(-1+0)]=-1$$ 第二行第二个格子的价值是： $$v_1^{(22)}=\\frac14[(-1+0)+(-1+0)+(-1+0)+(-1+0)]=-1$$ 其他的格子都是类似的，第一轮的状态价值迭代的结果如上图 $k=1$ 的时候。现在我们第一轮迭代完了。开始动态规划迭代第二轮了。还是看第二行第一个格子的价值： $$v_2^{(21)}=\\frac14[(-1+0)+(-1-1)+(-1-1)+(-1-1)]=-1.75$$ 第二行第二个格子的价值是： $$v_2^{(22)}=\\frac14[(-1-1)+(-1-1)+(-1-1)+(-1-1)]=-2$$ 最终得到的结果是上图 $k=2$ 的时候。第三轮的迭代如下： $$v_3^{(21)}=\\frac14[(-1-1.7)+(-1-2)+(-1-2)+(-1+0)]=-2.425$$ $$v_3^{(22)}=\\frac14[(-1-1.7)+(-1-1.7)+(-1-2)+(-1-2)]=-2.85$$ 最终得到的结果是上图 $k=3$ 的时候。就这样一直迭代下去，直到每个格子的策略价值改变很小为止。这时我们就得到了所有格子的基于随机策略的状态价值。 可以看到，动态规划的策略评估计算过程并不复杂，但是如果我们的问题是一个非常复杂的模型的话，这个计算量还是非常大的。 4. 策略迭代求解控制问题 上面我们讲了使用策略评估求解预测问题，现在我们再来看如何使用动态规划求解强化学习的第二个问题控制问题。一种可行的方法就是根据我们之前基于任意一个给定策略评估得到的状态价值来及时调整我们的动作策略，这个方法我们叫做策略迭代(Policy Iteration)。 如何调整呢？最简单的方法就是贪婪法。考虑一种如下的贪婪策略：个体在某个状态下选择的行为是其能够到达后续所有可能的状态中状态价值最大的那个状态。还是以第三节的例子为例，如上面的图右边。当我们计算出最终的状态价值后，我们发现，第二行第一个格子周围的价值分别是0,-18,-20，此时我们用贪婪法，则我们调整行动策略为向状态价值为0的方向移动，而不是随机移动。也就是图中箭头向上。而此时第二行第二个格子周围的价值分别是-14,-14,-20,-20。那么我们整行动策略为向状态价值为-14的方向移动，也就是图中的向左向上。 如果用一副图来表示策略迭代的过程的话，如下图： Policy Iteration 在策略迭代过程中，我们循环进行两部分工作，第一步是使用当前策略 $π∗$ 评估计算当前策略的最终状态价值 $v∗$，第二步是根据状态价值 $v∗$ 根据一定的方法（比如贪婪法）更新策略 $π∗$，接着回到第一步，一直迭代下去，最终得到收敛的策略 $π∗$ 和状态价值 $v∗$。 5. 价值迭代求解控制问题 观察第三节的图发现，我们如果用贪婪法调整动作策略，那么当k=3=3的时候，我们就已经得到了最优的动作策略。而不用一直迭代到状态价值收敛才去调整策略。那么此时我们的策略迭代优化为价值迭代。 还是以第三节的例子为例，如上面的图右边。比如当k=2=2时，第二行第一个格子周围的价值分别是0,-2,-2，此时我们用贪婪法，则我们调整行动策略为向状态价值为0的方向移动，而不是随机移动。也就是图中箭头向上。而此时第二行第二个格子周围的价值分别是-1.7,-1.7,-2, -2。那么我们整行动策略为向状态价值为-1.7的方向移动，也就是图中的向左向上。 和上一节相比，我们没有等到状态价值收敛才调整策略，而是随着状态价值的迭代及时调整策略, 这样可以大大减少迭代次数。此时我们的状态价值的更新方法也和策略迭代不同。现在的贝尔曼方程迭代式子如下： $$v_{k+1}(s)=\\max_{a\\in A}(R_s^a+\\gamma\\sum_{s’ \\in S}P_{ss’}^av_k(s’))$$ 可见由于策略调整，我们现在价值每次更新倾向于贪婪法选择的最优策略对应的后续状态价值，这样收敛更快。 6. 异步动态规划算法 在前几节我们讲的都是同步动态规划算法，即每轮迭代我会计算出所有的状态价值并保存起来，在下一轮中，我们使用这些保存起来的状态价值来计算新一轮的状态价值。 另一种动态规划求解是异步动态规划算法，在这些算法里，每一次迭代并不对所有状态的价值进行更新，而是依据一定的原则有选择性的更新部分状态的价值，这类算法有自己的一些独特优势，当然有额会有一些额外的代价。 常见的异步动态规划算法有三种： 第一种是原位动态规划 (in-place dynamic programming)， 此时我们不会另外保存一份上一轮计算出的状态价值。而是即时计算即时更新。这样可以减少保存的状态价值的数量，节约内存。代价是收敛速度可能稍慢。 第二种是优先级动态规划 (prioritised sweeping)：该算法对每一个状态进行优先级分级，优先级越高的状态其状态价值优先得到更新。通常使用贝尔曼误差来评估状态的优先级，贝尔曼误差即新状态价值与前次计算得到的状态价值差的绝对","date":"2024-02-22","objectID":"/posts/rl_learning_note_3/:0:0","tags":["RL"],"title":"RL学习笔记 [3] | 用动态规划(DP)求解","uri":"/posts/rl_learning_note_3/"},{"categories":["RL"],"content":"0. 引言 在强化学习（一）模型基础中，我们讲到了强化学习模型的8个基本要素。但是仅凭这些要素还是无法使用强化学习来帮助我们解决问题的, 在讲到模型训练前，模型的简化也很重要，这一篇主要就是讲如何利用马尔科夫决策过程(Markov Decision Process，以下简称MDP)来简化强化学习的建模。 MDP这一篇对应Sutton书的第三章和UCL强化学习课程的第二讲。 1. 强化学习引入MDP的原因 对于马尔科夫性本身，我之前讲过的隐马尔科夫模型HMM（一）HMM模型，条件随机场CRF(一)从随机场到线性链条件随机场以及MCMC(二)马尔科夫链都有讲到。它本身是一个比较简单的假设，因此这里就不专门对“马尔可夫性”做专门的讲述了。 除了对于环境的状态转化模型这个因素做马尔科夫假设外，我们还对强化学习第四个要素个体的策略(policy) $π$ 也做了马尔科夫假设。即在状态 $s$ 时采取动作 $a$ 的概率仅与当前状态 $s$ 有关，与其他的要素无关。用公式表示就是 $$\\pi(a\\mid s)=P(A_{t}=a\\mid S_{t}=s)$$ 对于第五个要素，价值函数 $v_π(s)$ 也是一样, $v_π(s)$ 现在仅仅依赖于当前状态了，那么现在价值函数 $v_π(s)$ 表示为: $$v_{\\pi}(s)=\\mathrm{E}_{\\pi}(G_{t}|S_{t}=s)=\\mathrm{E}_{\\pi}(R_{t+1}+\\gamma R_{t+2}+\\gamma^{2}R_{t+3}+\\ldots\\mid S_{t}=s)$$ 其中，$G_t$ 代表收获(return), 是一个MDP中从某一个状态 $S_t$ 开始采样直到终止状态时所有奖励的有衰减的之和。 2. MDP的价值函数与贝尔曼方程 对于MDP，我们在第一节里已经讲到了它的价值函数 $v_π(s)$ 的表达式。但是这个表达式没有考虑到所采用的动作$a$带来的价值影响，因此我们除了 $v_π(s)$ 这个状态价值函数外，还有一个动作价值函数 $q_π(s,a)$，即： $$q_{\\pi}(s,a)=\\operatorname{E}_{\\pi}(G_{t}|S_{t}=s,A_{t}=a)=\\operatorname{E}_{\\pi}(R_{t+1}+\\gamma R_{t+2}+\\gamma^{2}R_{t+3}+\\ldots\\mid S_{t}=s,A_{t}=a)$$ 根据价值函数的表达式，我们可以推导出价值函数基于状态的递推关系，比如对于状态价值函数 $v_π(s)$，可以发现： $$\\begin{aligned} V_{\\pi}(s)\u0026 =\\mathrm{E}_{\\pi}(R_{t+1}+\\gamma R_{t+2}+\\gamma^{2}R_{t+3}+\\ldots\\mid S_{t}=s) \\ \u0026=\\mathrm{E}_{\\pi}(R_{t+1}+\\gamma(R_{t+2}+\\gamma R_{t+3}+\\ldots)|S_{t}=s) \\ \u0026=\\mathrm{E}_{\\pi}(R_{t+1}+\\gamma G_{t+1}|S_{t}=s) \\ \u0026=\\mathrm{E}_{\\pi}(R_{t+1}+\\gamma v_{\\pi}(S_{t+1})|S_{t}=s) \\end{aligned}$$ 也就是说，在 $t$ 时刻的状态 $S_t$ 和 $t+1$ 时刻的状态 $S_{t+1}$ 是满足递推关系的，即： $$v_{\\pi}(s)=\\mathrm{E}_{\\pi}(R_{t+1}+\\gamma\\nu_{\\pi}(S_{t+1})\\mid S_{t}=s)$$ 这个递推式子我们一般将它叫做贝尔曼方程。这个式子告诉我们，一个状态的价值由该状态的奖励以及后续状态价值按一定的衰减比例联合组成。 同样的方法，我们可以得到动作价值函数 $q_π(s,a)$ 的贝尔曼方程： $$q_{\\pi}(s,a)=\\mathrm{E}_{\\pi}(R_{t+1}+\\gamma q_{\\pi}(S_{t+1},A_{t+1})\\mid S_{t}=s,A_{t}=a)$$ 3. 状态价值函数与动作价值函数的递推关系 根据动作价值函数 $q_π(s,a)$ 和状态价值函数 $v_π(s)$ 的定义，我们很容易得到他们之间的转化关系公式： $$\\nu_{\\pi}(s)=\\sum_{a\\in A}\\pi(a|s)q_{\\pi}(s,a)$$ 也就是说，状态价值函数是所有动作价值函数基于策略 $π$ 的期望。通俗说就是某状态下所有状态动作价值乘以该动作出现的概率，最后求和，就得到了对应的状态价值。 反过来，利用上贝尔曼方程，我们也很容易从状态价值函数 $v_π(s)$ 表示动作价值函数 $q_π(s,a)$，即： $$q_{\\pi}(s,a)=R_{s}^{a}+\\gamma\\sum_{s^{\\prime}\\in S}P_{ss’}^{a}\\nu_{\\pi}(s’)$$ 通俗说就是状态动作价值有两部分相加组成，第一部分是即时奖励，第二部分是环境所有可能出现的下一个状态的概率乘以该下一状态的状态价值，最后求和，并加上衰减。 这两个转化过程也可以从下图中直观的看出： 状态价值函数 动作价值函数 把上面两个式子互相结合起来，我们可以得到： $$\\nu_{\\pi}(s)=\\sum_{a\\in A}\\pi(a\\mid s)(R_{s}^{a}+\\gamma\\sum_{s’ \\in S}P_{ss’}^{a}\\nu_{\\pi}(s^{’}))$$ $$q_\\pi(s,a)=R_s^a+\\gamma\\sum_{s’ \\in S}P_{ss’}^a\\sum_{a’ \\in A}\\pi(a’ \\mid s’)q_\\pi(s’,a’)$$ 4. 最优价值函数 解决强化学习问题意味着要寻找一个最优的策略让个体在与环境交互过程中获得始终比其它策略都要多的收获，这个最优策略我们可以用 $π^*$表示。一旦找到这个最优策略$π^∗$，那么我们就解决了这个强化学习问题。一般来说，比较难去找到一个最优策略，但是可以通过比较若干不同策略的优劣来确定一个较好的策略，也就是局部最优解。 如何比较策略的优劣呢？一般是通过对应的价值函数来比较的，也就是说，寻找较优策略可以通过寻找较优的价值函数来完成。可以定义最优状态价值函数是所有策略下产生的众多状态价值函数中的最大者，即： $$v^{\\ast}(s)=\\max_{\\pi} v_{\\pi}(s)$$ 同理也可以定义最优动作价值函数是所有策略下产生的众多动作状态价值函数中的最大者，即： $$q^{\\ast}(s,a)=\\max_\\pi q_\\pi(s,a)$$ 对于最优的策略，基于动作价值函数我们可以定义为： $$\\pi ^{\\ast} (a|s)=\\begin{cases}1\u0026\\mathrm{if~}a=\\mathrm{arg~}\\max_{a\\in A}q*(s,a)\\\\\\\\0\u0026\\mathrm{else}\u0026\\end{cases}$$ 只要我们找到了最大的状态价值函数或者动作价值函数，那么对应的策略 $π^*$ 就是我们强化学习问题的解。同时，利用状态价值函数和动作价值函数之间的关系，我们也可以得到: $$v^{\\ast}(s)=\\max_a q ^{\\ast} (s,a)$$ 反过来的最优价值函数关系也很容易得到： $$q_{}(s,a)=R_{s}^{a}+\\gamma\\sum_{s’ \\in S}P_{ss}^{a}{}_{}(\\mathrm{s’})$$ 利用上面的两个式子也可以得到和第三节末尾类似的式子： $$v_(s)=\\max_a(R_s^a+\\gamma\\sum_{s^{\\prime}\\in S}P_{ss’}^a\\nu_(s’))$$ $$q_(s,a)=R_s^a+\\gamma\\sum_{s’ \\in S}P_{ss’}^a\\max_{a’}q_(s’,a’)$$ 5. MDP实例 上面的公式有点多，需要一些时间慢慢消化，这里给出一个UCL讲义上实际的例子，首先看看具体我们如何利用给定策略来计算价值函数。 MDP 举例 例子是一个学生学习考试的MDP。里面左下那个圆圈位置是起点，方框那个位置是终点。上面的动作有study, pub, facebook, quit, sleep，每个状态动作对应的即时奖励R已经标出来了。我们的目标是找到最优的动作价值函数或者状态价值函数，进而找出最优的策略。 为了方便，我们假设衰减因子 $γ=1$, $π(a|s)=0.5$。 对于终点方框位置，由于其没有下一个状态，也没有当前状态的动作，因此其状态价值函数为0。对于其余四个状态，我们依次定义其价值为v1,v2,v3,v4， 分别对应左上，左下，中下，右下位置的圆圈。我们基于$\\nu_{\\pi}(s)=\\sum_{a\\in A}\\pi(a|s)(R_{s}^{a}+\\gamma\\sum_{s’ \\in S}P_{ss’}^{a}v_{\\pi}(s’))$计算所有的状态价值函数。可以列出一个方程组。 对于v1位置，我们有：$v_1=0.5*(-1+v_1)+0.5*(0+v_2)$ 对于v2位置，我们有：$v_2=0.5*(-1+v_1)+0.5*(-2+v_3)$ 对于v3位置，我们有：$v_3=0.5*(0+0)+0.5*(-2+v_4)$ 对于v4位置，我们有：$v_4=0.5*(10+0)+0.5*(1+0.2v_2+0.4v_3+0.4*v_4)$ 解出这个方程组可以得到 $v_1=","date":"2024-02-21","objectID":"/posts/rl_learning_note_2/:0:0","tags":["RL"],"title":"RL学习笔记 [2] | 马尔科夫决策过程(MDP)","uri":"/posts/rl_learning_note_2/"},{"categories":["RL"],"content":"0. 引言 从今天开始整理强化学习领域的知识，主要参考的资料是Sutton的强化学习书和UCL强化学习的课程。这个系列大概准备写10到20篇，希望写完后自己的强化学习碎片化知识可以得到融会贯通，也希望可以帮到更多的人，毕竟目前系统的讲解强化学习的中文资料不太多。 第一篇会从强化学习的基本概念讲起，对应Sutton书的第一章和UCL课程的第一讲。 1. 强化学习在机器学习中的位置 强化学习的学习思路和人比较类似，是在实践中学习，比如学习走路，如果摔倒了，那么我们大脑后面会给一个负面的奖励值，说明走的姿势不好。然后我们从摔倒状态中爬起来，如果后面正常走了一步，那么大脑会给一个正面的奖励值，我们会知道这是一个好的走路姿势。那么这个过程和之前讲的机器学习方法有什么区别呢？ 强化学习是和监督学习，非监督学习并列的第三种机器学习方法，从下图我们可以看出来。 RL、SL、UL与ML的区别联系 与监督学习相比，强化学习最大的区别是它没有监督学习已经准备好的训练数据输出值。强化学习只有奖励值，但是这个奖励值和监督学习的输出值不一样，它不是事先给出的，而是延后给出的，比如上面的例子里走路摔倒了才得到大脑的奖励值。同时，强化学习的每一步与时间顺序前后关系紧密。而监督学习的训练数据之间一般都是独立的，没有这种前后的依赖关系。 再来看看强化学习和非监督学习的区别。也还是在奖励值这个地方。非监督学习是没有输出值也没有奖励值的，它只有数据特征。同时和监督学习一样，数据之间也都是独立的，没有强化学习这样的前后依赖关系。 2. 强化学习的建模 我们现在来看看强化学习这样的问题我们怎么来建模，简单的来说，是下图这样的： 大脑与环境的交互 上面的大脑代表我们的算法执行个体，我们可以操作个体来做决策，即选择一个合适的动作（Action）$A_t$。下面的地球代表我们要研究的环境,它有自己的状态模型，我们选择了动作 $A_t$ 后，环境的状态(State)会变，我们会发现环境状态已经变为 $S_{t+1}$,同时我们得到了我们采取动作 $A_t$ 的延时奖励(Reward) $R_{t+1}$。然后个体可以继续选择下一个合适的动作，然后环境的状态又会变，又有新的奖励值…这就是强化学习的思路。 那么我们可以整理下这个思路里面出现的强化学习要素。 第一个是环境的状态 $S$, $t$ 时刻环境的状态 $S_t$ 是它的环境状态集中某一个状态。 第二个是个体的动作 $A$, $t$ 时刻个体采取的动作 $A_t$ 是它的动作集中某一个动作。 第三个是环境的奖励 $R$, $t$ 时刻个体在状态 $S_t$ 采取的动作 $A_t$ 对应的奖励 $R_{t+1}$ 会在 $t+1$ 时刻得到。 第四个是个体的策略(policy) $π$,它代表个体采取动作的依据，即个体会依据策略 $π$ 来选择动作。最常见的策略表达方式是一个条件概率分布 $π(a|s)$, 即在状态 $s$ 时采取动作 $a$ 的概率。即 $π(a|s)=P(A_t=a|S_t=s)$.此时概率大的动作被个体选择的概率较高。 第五个是个体在策略 $π$ 和状态 $s$ 时，采取行动后的价值(value)，一般用 $v_π(s)$ 表示。这个价值一般是一个期望函数。虽然当前动作会给一个延时奖励 $R_{t+1}$,但是光看这个延时奖励是不行的，因为当前的延时奖励高，不代表到了 $t+1$, $t+2$,…时刻的后续奖励也高。比如下象棋，我们可以某个动作可以吃掉对方的车，这个延时奖励是很高，但是接着后面我们输棋了。此时吃车的动作奖励值高但是价值并不高。因此我们的价值要综合考虑当前的延时奖励和后续的延时奖励。价值函数 $v_{\\pi}(s)$ 一般可以表示为下式，不同的算法会有对应的一些价值函数变种，但思路相同。 $$v_{\\pi}(s)=\\mathbb{E}_π(R_{t+1}+γR_{t+2}+γ^2R_{t+3}+…|S_t=s)$$ 其中 $γ$ 是第六个模型要素，即奖励衰减因子，在[0，1]之间。如果为0，则是贪婪法，即价值只由当前延时奖励决定，如果是1，则所有的后续状态奖励和当前奖励一视同仁。大多数时候，我们会取一个0到1之间的数字，即当前延时奖励的权重比后续奖励的权重大。 第七个是环境的状态转化模型，可以理解为一个概率状态机，它可以表示为一个概率模型，即在状态 $s$ 下采取动作 $a$,转到下一个状态 $s’$ 的概率，表示为 $P^a_{ss’}$。 第八个是探索率 $ϵ$，这个比率主要用在强化学习训练迭代过程中，由于我们一般会选择使当前轮迭代价值最大的动作，但是这会导致一些较好的但我们没有执行过的动作被错过。因此我们在训练选择最优动作时，会有一定的概率 $ϵ$ 不选择使当前轮迭代价值最大的动作，而选择其他的动作。 以上8个就是强化学习模型的基本要素了。当然，在不同的强化学习模型中，会考虑一些其他的模型要素，或者不考虑上述要素的某几个，但是这8个是大多数强化学习模型的基本要素。 3. 强化学习的简单实例 这里给出一个简单的强化学习例子Tic-Tac-Toe。这是一个简单的游戏，在一个3x3的九宫格里，两个人轮流下，直到有个人的棋子满足三个一横一竖或者一斜，赢得比赛游戏结束，或者九宫格填满也没有人赢，则和棋。 这个例子的完整代码在github。例子只有一个文件，很简单，代码首先会用两个电脑选手训练模型，然后可以让人和机器对战。当然，由于这个模型很简单，所以只要你不乱走，最后的结果都是和棋，当然想赢电脑也是不可能的。 我们重点看看这个例子的模型，理解上面第二节的部分。如何训练强化学习模型可以先不管。代码部分大家可以自己去看，只有300多行。 首先看第一个要素环境的状态 $S$。这是一个九宫格，每个格子有三种状态，即没有棋子(取值0)，有第一个选手的棋子(取值1)，有第二个选手的棋子(取值-1)。那么这个模型的状态一共有$3^9=19683$个。 接着我们看个体的动作 $A$，这里只有9个格子，每次也只能下一步，所以最多只有9个动作选项。实际上由于已经有棋子的格子是不能再下的，所以动作选项会更少。实际可以选择动作的就是那些取值为0的格子。 第三个是环境的奖励 $R$，这个一般是我们自己设计。由于我们的目的是赢棋，所以如果某个动作导致的改变到的状态可以使我们赢棋，结束游戏，那么奖励最高，反之则奖励最低。其余的双方下棋动作都有奖励，但奖励较少。特别的，对于先下的棋手，不会导致结束的动作奖励要比后下的棋手少。 # give reward to two players def giveReward(self): if self.currentState.winner == self.p1Symbol: self.p1.feedReward(1) self.p2.feedReward(0) elif self.currentState.winner == self.p2Symbol: self.p1.feedReward(0) self.p2.feedReward(1) else: self.p1.feedReward(0.1) self.p2.feedReward(0.5) 第四个是个体的策略(policy) $π$，这个一般是学习得到的，我们会在每轮以较大的概率选择当前价值最高的动作，同时以较小的概率去探索新动作，在这里AI的策略如下面代码所示。里面的exploreRate就是我们的第八个要素探索率 $ϵ$。即策略是以 $1−ϵ$ 的概率选择当前最大价值的动作，以 $ϵ$ 的概率随机选择新动作。 # determine next action def takeAction(self): state = self.states[-1] nextStates = [] nextPositions = [] for i in range(BOARD_ROWS): for j in range(BOARD_COLS): if state.data[i, j] == 0: nextPositions.append([i, j]) nextStates.append(state.nextState(i, j, self.symbol).getHash()) if np.random.binomial(1, self.exploreRate): np.random.shuffle(nextPositions) # Not sure if truncating is the best way to deal with exploratory step # Maybe it's better to only skip this step rather than forget all the history self.states = [] action = nextPositions[0] action.append(self.symbol) return action values = [] for hash, pos in zip(nextStates, nextPositions): values.append((self.estimations[hash], pos)) np.random.shuffle(values) values.sort(key=lambda x: x[0], reverse=True) action = values[0][1] action.append(self.symbol) return action 第五","date":"2024-02-21","objectID":"/posts/rl_learning_note_1/:0:0","tags":["RL"],"title":"RL学习笔记 [1] | 模型基础","uri":"/posts/rl_learning_note_1/"},{"categories":["AD"],"content":"0. 描述 Dubins和RS曲线都是路径规划的经典算法，其中车辆运动学利用RS曲线居多，因此简单介绍Dubins并引出RS曲线。 花了点时间看了二者的论文，并阅读了一个开源的代码。 ","date":"2024-02-20","objectID":"/posts/dubinsandrs/:1:0","tags":["Planning"],"title":"车辆路径规划之Dubins曲线与RS曲线简述","uri":"/posts/dubinsandrs/"},{"categories":["AD"],"content":"1. Dubins曲线 Dubins曲线是在满足曲率约束和规定的始端和末端的切线（进入方向）的条件下，连接两个二维平面的最短路径。它满足给定的运动曲率约束，即转弯半径大于等于给定的半径。 假设顺时针圆周运动为R，逆时针圆周运动为L，直线运动为S。求出Dubins曲线，用任务来表达就是 给了车辆起始位置 $(x_{start},y_{start})$ ，车辆的朝向 $\\theta_{start}$ ，再给一个车辆的目标位置 $(x_{end},y_{end})$ ，车辆的目标朝向为 $\\theta_{end}$ 。车辆最多能实现的曲率为 $K_{max}$ 。车辆不可以做后退运动，只能向前开。 规划的曲线分三段，第一段是绕固定圆心的L或R，第二段是L/R/S，第三段是L/R。用这三段曲线可以使车辆从初始位姿连续的移动到目标位姿。 三段曲线可以组成的集合有6种={LSL、RSR、RSL、LSR、RLR、LRL}。这六种可能中最短的路径就是Dubins曲线。 网上有很多关于Dubins曲线的文章，都很简单。先把初始位姿和目标位姿做一下差值，得到一个更简单的坐标系。再通过画圆和直线，求解一些方程，就可以计算出不同选择路径的长度值。再从中取最小的，就可以得到Dubins曲线了。这里不多介绍。 有关Dubins的文章有很多，对于6种不同的路径，都有对应的公式去计算每段的长度值。 ","date":"2024-02-20","objectID":"/posts/dubinsandrs/:2:0","tags":["Planning"],"title":"车辆路径规划之Dubins曲线与RS曲线简述","uri":"/posts/dubinsandrs/"},{"categories":["AD"],"content":"2. Reeds-Shepp曲线 1. 原理 “利用倒挡的RS曲线可以比Dubins曲线更优” 论文《Optimal paths for a car that goes both forwards and backwards》提出了Reeds-Shepp曲线。这篇论文由Reeds和Shepp在1990年发表。他们提出了一种能够计算出车辆以固定转弯半径，由一个姿态向另一个姿态运动的最短路径的曲线，即Reeds-Shepp曲线，简称为RS曲线。 对于Dubins曲线，当我们需要车辆位置不变原地掉头时，有如下图的情况： Dubins曲线 图A和图B都可以达到目标。根据Dubins曲线的定义，我们知道图B是最优的路线，同时存在另外一条曲线图C，也能达到相同的效果。但这和我们平时开车显然不同，因为我们的车辆是可以挂倒挡的。我们选择图D代表的路径，可以更快达到目标。 相较于Dubins曲线，RS曲线有了进一步的约束条件：要求每个点的曲率半径都大于1，同时允许车辆可以后退。当车辆可以倒退时，路径有可能被缩短变得更优，而此时Dubins曲线将不能满足要求。作者对RS曲线的所有可能进行了简化表示，在文中做出了一系列定义，我按照文章的顺序进行讲解。 2. 定义 •C代表左转（L）或右转（R），S代表沿直线行驶。C^+和C^-的上标代表前进和后退（在车辆里就是换档）。因此，CC代表的就是LR或者RL。 • $C^+{\\pi/2}$ 代表前进方向弧长走 $\\pi/2$，C^-{-\\pi/2}代表后退方向弧长走\\pi/2。所以再通用一些，C^\\pm_t表达式中的C可以代表L、R或者S，上标代表前进方向，下标t是和上标正负号相同的代表弧长的值。 •C_uC_u这两个需要连在一起出现，代表两段弧长相等。 在诸如C^+_tC^-_uC^-_vv^+_w这样的路径族（由四段组成的路径，同样的还有C^-_tC^+_uC^+_vv^-_w……等）中，自由参数t,u,v,w一共有4个参数，比条件的数量（目标位置和角度）多了1个，因此对于给定的终点条件通常存在多个解。我们对族中的路径进行优化，能够得到一个额外的方程，结果就是 v = u，或v = π/2。这样看参数仍然是三个。 作者在后面会证明，确实还有类似于C^+C^-C^+C^-C^+C^-这样的路径存在，这样的路径并不在作者提到的形式之中。但是这种路径往往在我们的形式中有相同的替代路径。对于不在作者集合中的路径，将不会出现在简单的前向场景中。 作者提出了两种描述方式，一种是用\\pm代表的正负方向 另一种是用 | 代表的档位变化 BP Network 以车辆为例，如果用真实的左打轮和右打轮，加上档位变化，一共会有48种不同的路径，如下图。由于有一些路径会有多个公式来表达，所以这48种路径最多会有68个公式。 BP Network Dubins曲线和我们的证明方式不同。Dubins证明了任何终点条件下都会存在路径，即问题的下限被确定了。同时，任何路径长度小于 \\pi/8的路径一定是一个CSC类型的路径。然后容易得到，每个路径必须由有限的C和S组成，最终路径简化为了CSC和CCC两种可能。作者没有能够用Dubins的方法来解决本文章提到的车辆反向运动问题。作者在第7节证明了在不增加路径长度的情况下，最多5段就能表示路径，证明方法与Dubins类似。 作者除了用数学公式来推导证明，还用计算机来做了验证：设置了一个包含很多条子路径的集合W，随机出起始条件和终止条件，如果在集合W中找到了两条路径就能连接起点终点，那么集合W显然就是不充分的，就要对集合W进行一些修剪。最终用这种方式得到了一个最小的有效集合W。一旦猜测出了W，作者再次使用计算机来帮助进行大量情况下的广泛代数运算，以验证上述方法可以给出严格的证明。最后，作者发现证明可以简化为上图，这样普通人可以在没有计算机检查细节的情况下轻松理解。但作者认为，如果没有使用计算机，他们永远不可能找到正确的子路径集。（这实际上表明作者是在计算机辅助下，成功地找到了RS曲线的解，并通过广泛的代数运算验证了他们的方法。最终，他们再反过来简化证明过程，最终让RS曲线更易于理解。） ","date":"2024-02-20","objectID":"/posts/dubinsandrs/:3:0","tags":["Planning"],"title":"车辆路径规划之Dubins曲线与RS曲线简述","uri":"/posts/dubinsandrs/"},{"categories":["AD"],"content":"3. 等效运算 作者提到，并不是每次都需要计算48种路径，因为存在一些基本变换规则可以简化计算 第一种等效运算：”timeflip”——时间变换 路径 $l^+ r^- s^- l^-$ 和路径 l^-r^+s^+l^+ 之间的关系就是时间变换，可以看出其实就是前进和后退动作替换了一下 当我们想求沿路径 l^-r^+s^+l^+ 从 [0,0,0] 到 [x,y,\\phi] 时 ，我们可以求沿路径 l^+r^-s^-l^-从 [0,0,0] 到 [-x,y,-\\phi]，求出的路径 l^+r^-s^-l^-中每段走的弧长，就是待求路径 l^-r^+s^+l^+ 的弧长结果 第二种等效运算：“reflect”——反射变换 路径 l^+r^-s^-l^- 和路径 r^+l^-s^-r^- 之间的关系就是反射变换，可以看出其实就是向左和向右替换了一下 当我们想求沿路径 r^+l^-s^-r^- 从 [0,0,0] 到 [x,y,\\phi] 时 ，我们可以求沿路径 l^+r^-s^-l^-从 [0,0,0] 到 [x,-y,-\\phi]，求出的路径 l^+r^-s^-l^-中每段走的弧长，就是待求路径 r^+l^-s^-r^- 的弧长结果 第三种等效运算：“backwards”——反向变换 路径 l^+r^-s^-l^- 和路径 l^-s^-r^-l^+ 之间的关系就是反向变换，可以看出其实两条路径前后顺序颠倒了一下 当我们想求沿路径 l^-s^-r^-l^+ 从 [0,0,0] 到 [x,y,\\phi] 时 ，我们可以求沿路径 l^+r^-s^-l^-从 [0,0,0] 到 [xcos\\phi+ysin\\phi,xsin\\phi-ycos\\phi,\\phi]，求出的路径 l^+r^-s^-l^-中每段走的弧长，就是待求路径 l^-s^-r^-l^+ 的弧长结果 上面提到了三种变换关系来简化运算，简单理解一下就是： 从 [0,0,0] 到 [x,y,\\phi] 需要求解的三个路径 l^-r^+s^+l^+、r^+l^-s^-r^- 、l^-s^-r^-l^+，通过分别改变终点的坐标，均可以通过求解路径 l^+r^-s^-l^- 得到每段轨迹的弧长或前进距离 ","date":"2024-02-20","objectID":"/posts/dubinsandrs/:4:0","tags":["Planning"],"title":"车辆路径规划之Dubins曲线与RS曲线简述","uri":"/posts/dubinsandrs/"},{"categories":["AD"],"content":"4. 流程与代码 与Dubins曲线一致，RS曲线每种路径也有对应的公式可以计算。 第一步：起始点坐标变换，令起点坐标变为(0,0,0)，终点的坐标转换为起点坐标系下的坐标，从而简化后续计算 q0 = [sx, sy, syaw] # 起点:x,y,yaw q1 = [gx, gy, gyaw] # 终点:x,y,yaw dx = q1[0] - q0[0] dy = q1[1] - q0[1] dth = q1[2] - q0[2] c = math.cos(q0[2]) s = math.sin(q0[2]) x = (c * dx + s * dy) * max_curvature y = (-s * dx + c * dy) * max_curvature # 起点变成了(0,0,0),终点坐标变成了(x, y, dth) 第二步：计算路径 利用三种基本定理，计算全部的路径 第三步：选择路径 选择最优的路径，并对生成的路径进行差值，得到路径上的每一个路径点 ","date":"2024-02-20","objectID":"/posts/dubinsandrs/:5:0","tags":["Planning"],"title":"车辆路径规划之Dubins曲线与RS曲线简述","uri":"/posts/dubinsandrs/"},{"categories":["AD"],"content":"5. 总结 原理基本上很清楚，暂时对可选路径计算的优化没有深究，之后再说。 ref: https://mp.weixin.qq.com/s/RfAEnFtUW7KkG7cSPqmWUw ","date":"2024-02-20","objectID":"/posts/dubinsandrs/:6:0","tags":["Planning"],"title":"车辆路径规划之Dubins曲线与RS曲线简述","uri":"/posts/dubinsandrs/"},{"categories":["Git"],"content":"Git 常用命令汇总 ","date":"2024-02-02","objectID":"/posts/commandsheet/:0:0","tags":["Git"],"title":"Git 命令查询","uri":"/posts/commandsheet/"},{"categories":["Git"],"content":"常规操作 git push origin test 推送本地分支到远程仓库 git rm -r --cached 文件/文件夹名字 取消文件被版本控制 git reflog 获取执行过的命令 git log --graph 查看分支合并图 git merge --no-ff -m '合并描述' 分支名 不使用Fast forward方式合并，采用这种方式合并可以看到合并记录 git check-ignore -v 文件名 查看忽略规则 git add -f 文件名 强制将文件提交 ","date":"2024-02-02","objectID":"/posts/commandsheet/:1:0","tags":["Git"],"title":"Git 命令查询","uri":"/posts/commandsheet/"},{"categories":["Git"],"content":"Git 创建项目仓库 git init 初始化 git remote add origin url 关联远程仓库 git pull git fetch 获取远程仓库中所有的分支到本地 ","date":"2024-02-02","objectID":"/posts/commandsheet/:1:1","tags":["Git"],"title":"Git 命令查询","uri":"/posts/commandsheet/"},{"categories":["Git"],"content":"忽略已加入到版本库中的文件 git update-index --assume-unchanged file 忽略单个文件 git rm -r --cached 文件/文件夹名字 (. 忽略全部文件) ","date":"2024-02-02","objectID":"/posts/commandsheet/:1:2","tags":["Git"],"title":"Git 命令查询","uri":"/posts/commandsheet/"},{"categories":["Git"],"content":"取消忽略文件 git update-index --no-assume-unchanged file ","date":"2024-02-02","objectID":"/posts/commandsheet/:1:3","tags":["Git"],"title":"Git 命令查询","uri":"/posts/commandsheet/"},{"categories":["Git"],"content":"拉取、上传免密码 git config --global credential.helper store ","date":"2024-02-02","objectID":"/posts/commandsheet/:1:4","tags":["Git"],"title":"Git 命令查询","uri":"/posts/commandsheet/"},{"categories":["Git"],"content":"分支操作 git branch 创建分支 git branch -b 创建并切换到新建的分支上 git checkout 切换分支 git branch 查看分支列表 git branch -v 查看所有分支的最后一次操作 git branch -vv 查看当前分支 git branch -b 分支名 origin/分支名 创建远程分支到本地 git branch --merged 查看别的分支和当前分支合并过的分支 git branch --no-merged 查看未与当前分支合并的分支 git branch -d 分支名 删除本地分支 git branch -D 分支名 强行删除分支 git push origin --delete 分支名 删除远程仓库分支 git merge 分支名 合并分支到当前分支上 git push -u \u003cremote\u003e \u003clocal_branch\u003e 关联本地分支到远程分支 git push --set-upstream \u003cremote\u003e \u003clocal_branch\u003e 关联本地分支到远程分支 ","date":"2024-02-02","objectID":"/posts/commandsheet/:2:0","tags":["Git"],"title":"Git 命令查询","uri":"/posts/commandsheet/"},{"categories":["Git"],"content":"暂存操作 git stash 暂存当前修改 git stash apply 恢复最近的一次暂存 git stash pop 恢复暂存并删除暂存记录 git stash list 查看暂存列表 git stash drop 暂存名(例：stash@{0}) 移除某次暂存 git stash clear 清除暂存 ","date":"2024-02-02","objectID":"/posts/commandsheet/:3:0","tags":["Git"],"title":"Git 命令查询","uri":"/posts/commandsheet/"},{"categories":["Git"],"content":"回退操作 git reset --hard HEAD^ 回退到上一个版本 git reset --hard commitId 回退到某个版本 git checkout -- file撤销修改的文件(如果文件加入到了暂存区，则回退到暂存区的，如果文件加入到了版本库，则还原至加入版本库之后的状态) git reset HEAD file 撤回暂存区的文件修改到工作区 ","date":"2024-02-02","objectID":"/posts/commandsheet/:4:0","tags":["Git"],"title":"Git 命令查询","uri":"/posts/commandsheet/"},{"categories":["Git"],"content":"标签操作 git tag 标签名 添加标签(默认对当前版本) git tag 标签名 commitId 对某一提交记录打标签 git tag -a 标签名 -m '描述' 创建新标签并增加备注 git tag 列出所有标签列表 git show 标签名 查看标签信息 git tag -d 标签名 删除本地标签 git push origin 标签名 推送标签到远程仓库 git push origin --tags 推送所有标签到远程仓库 git push origin :refs/tags/标签名 从远程仓库中删除标签 ","date":"2024-02-02","objectID":"/posts/commandsheet/:5:0","tags":["Git"],"title":"Git 命令查询","uri":"/posts/commandsheet/"},{"categories":["Git"],"content":"远程仓库 git remote -v查看远程仓库地址 git remote show origin查看远程仓库详情信息 ","date":"2024-02-02","objectID":"/posts/commandsheet/:6:0","tags":["Git"],"title":"Git 命令查询","uri":"/posts/commandsheet/"},{"categories":["Git"],"content":"查看某个 commit 提交属于哪个分支 git branch -l --contains \u003ccommit_id\u003e 本地分支 git branch -r --contains \u003ccommit_id\u003e 远程分支 git branch --all --contains \u003ccommit_id\u003e 所有分支 ","date":"2024-02-02","objectID":"/posts/commandsheet/:7:0","tags":["Git"],"title":"Git 命令查询","uri":"/posts/commandsheet/"},{"categories":["Git"],"content":"Git核心知识总结 Git 总览 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:0:0","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"1.什么是Git 在了解Git之前，我们先了解一下版本控制这个概念。 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:1:0","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"1.1 什么是版本控制 版本控制是一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统。 除了项目源代码，你可以对任何类型的文件进行版本控制。 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:1:1","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"1.2 为什么需要版本控制 有了它你就可以将某个文件回溯到之前的状态，甚至将整个项目都回退到过去某个时间点的状态，你可以比较文件的变化细节，查出最后是谁修改了哪个地方，从而找出导致项目问题出现的原因，又是谁在何时报告了某个功能缺陷等等。 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:1:2","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"1.3 本地版本控制系统 许多人习惯用复制整个项目目录的方式来保存不同的版本，或许还会改名加上备份时间以示区别。 这么做唯一的好处就是简单，但是特别容易犯错。 有时候会混淆所在的工作目录，一不小心会写错文件或者覆盖意想外的文件。 为了解决这个问题，人们很久以前就开发了许多种本地版本控制系统，大多都是采用某种简单的数据库来记录文件的历次更新差异。 Git是当前最先进、最主流的分布式版本控制系统，免费、开源！核心能力就是版本控制。再具体一点，就是面向代码文件的版本控制，代码的任何修改历史都会被记录管理起来，意味着可以恢复到到以前的任意时刻状态。支持跨区域多人协作编辑，是团队项目开发的必备基础，所以Git也就成了程序员的必备技能。 本地版本控制系统 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:1:3","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"2.Git的来源 Git是一种分布式版本控制系统，它的设计和开发最初由林纳斯·托瓦兹（Linus Torvalds）领导，他也是Linux操作系统的创始人。Git的开发始于2005年，其背景和初始目的与Linux开发社区的需求密切相关。 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:2:0","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"2.1 背景和初始动机 在Git之前，Linux内核的开发使用的是一个名为BitKeeper的商业版本控制系统。这个系统对Linux社区是免费的，但在2005年，由于一些争议和许可问题，Linux社区失去了对BitKeeper的免费许可。这促使托瓦兹寻找一个新的工具来管理Linux内核的开发。 托瓦兹对版本控制系统有几个明确的需求和目标： 「性能」：由于Linux内核的庞大和复杂性，性能成为一个关键因素。Git需要高效地处理大型项目。 「分布式架构」：Git被设计为分布式系统，意味着每个开发者的计算机上都有整个代码库的完整历史记录，这样可以减少对中央服务器的依赖。 「数据完整性」：Git强调数据的完整性。它通过对文件内容和目录结构使用SHA-1哈希来确保代码历史不被篡改。 「简单的分支和合并」：在Linux开发中，分支和合并操作非常频繁。Git被设计为使这些操作尽可能简单和高效。 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:2:1","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"2.2 Git的发展 Git最初是作为一个命令行工具发布的，但随着时间的推移，围绕Git开发了大量的图形界面工具和增强功能，使其更加用户友好。Git迅速在开源社区中获得了广泛的接受，并逐渐成为世界上最流行的版本控制系统。 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:2:2","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"2.3 GitHub和Git的普及 Git的普及也与GitHub这样的平台紧密相关。GitHub是一个基于Web的Git版本库托管服务，它提供了图形界面，并增加了如分叉、拉取请求和社交网络功能等特性，这些都极大地促进了Git的普及和开源文化的发展。 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:2:3","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"3.Git的特点 开源免费，使用广泛。 强大的文档（代码）的历史版本管理，直接记录完整快照（完整内容，而非差异），支持回滚、对比。 分布式多人协作的的代码协同开发，几乎所有操作都是本地执行的，支持代码合并、代码同步。 简单易用的分支管理，支持高效的创建分支、合并分支。 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:3:0","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"4.Git的基本概念 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:4:0","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"4.1 概念汇总 概念名称 描述 工作区（Workspace） 就是在电脑里能看到的代码库目录，是我们搬砖的地方，新增、修改的文件会提交到暂存区 暂存区（stage 或 index） 用于临时存放文件的修改，实际上上它只是一个文件（.git/index），保存待提交的文件列表信息。 版本库/仓库（Repository） Git的管理仓库，管理版本的数据库，记录文件/目录状态的地方，所有内容的修改记录（版本）都在这里。 服务端/远程仓库（origin 或 remote） 服务端的版本库，专用的Git服务器，为多人共享提供服务，承担中心服务器的角色。本地版本库通过push指令把代码推送到服务端版本库。 本地仓库 用户机器上直接使用的版本库 分支（Branch） 分支是从主线分离出去的“副本”，可以独立操作而互不干扰，仓库初始化就有一个默认主分支master。 头（HEAD） HEAD类似一个“指针”，指向当前活动分支的最新版本。 提交（Commit） 把暂存区的所有变更的内容提交到当前仓库的活动分支。 推送（Push） 将本地仓库的版本推送到服务端（远程）仓库，与他人共享。 拉取（Pull） 从服务端（远程）仓库获取更新到本地仓库，获取他人共享的更新。 获取（Fetch） 从服务端（远程）仓库更新，作用同拉取（Pull），区别是不会自动合并。 冲突（Conflict） 多人对同一文件的工作副本进行更改，并将这些更改合并到仓库时就会面临冲突，需要人工合并处理。 合并（Merge） 对有冲突的文件进行合并操作，Git会自动合并变更内容，无法自动处理的冲突内容会提示人工处理。 标签（Tags） 标签指的是某个分支某个特定时间点的状态，可以理解为提交记录的别名，常用来标记版本。 master（或main） 仓库的“master”分支，默认的主分支，初始化仓库就有了。Github上创建的仓库默认名字为“main” origin/master 表示远程仓库（origin）的“master”分支 origin/HEAD 表示远程仓库（origin）的最新提交的位置，一般情况等于“origin/master” ","date":"2024-02-02","objectID":"/posts/gitnotes2/:4:1","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"4.2 工作区/暂存区/仓库 工作区（Workspace）就是在电脑里能看到的代码库目录，是我们搬砖的地方，新增、修改的文件会提交到暂存区。 在这里新增文件、修改文件内容，或删除文件。 暂存区（stage或index）用于临时存放文件的修改，实际上上它只是一个文件（.git/index），保存待提交的文件列表信息。 用git add 命令将工作区的修改保存到暂存区。 版本库/仓库（Repository仓库）Git的管理仓库，管理版本的数据库，记录文件/目录状态的地方，所有内容的修改记录（版本）都在这里。就是工作区目录下的隐藏文件夹.git，包含暂存区、分支、历史记录等信息。 用git commit 命令将暂存区的内容正式提交到版本库。 master 为仓库的默认分支master，HEAD是一个“指针”指向当前分支的最新提交，默认指向最新的master。 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:4:2","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"4.3 Git的基本流程 Git的工作流程核心就下面几个步骤。 准备仓库：创建或从服务端克隆一个仓库。 编写代码：在工作目录中添加、修改代码。 暂存（git add）：将需要进行版本管理的文件放入暂存区域。 提交（git commit）：将暂存区域的文件提交到Git仓库。 推送（git push）：将本地仓库推送到远程仓库，同步版本库。 获取更新（fetch/pull）：从服务端更新到本地，获取他人推送的更新，与他人协作、共享。 Git 工作 流程 git commit -a 指令省略了add到暂存区的步骤，直接提交工作区的修改内容到版本库，不包括新增的文件。 git fetch、git pull 都是从远程服务端获取最新记录，区别是git pull多了一个步骤，就是自动合并更新工作区。 git checkout . 、git checkout [file] 会清除工作区中未添加到暂存区的修改，用暂存区内容替换工作区。 git checkout HEAD .、 git checkout HEAD [file] 会清除工作区、暂存区的修改，用HEAD指向的当前分支最新版本替换暂存区、工作区。 git diff 用来对比不同部分之间的区别，如暂存区、工作区，最新版本与未提交内容，不同版本之间等。 git reset 是专门用来撤销修改、回退版本的指令，替代上面checkout的撤销功能。 「基本的 Git 工作流程如下：」 在工作目录中修改文件。 暂存文件，将文件的快照放入暂存区域。 提交更新，找到暂存区域的文件，将快照永久性存储到 Git 仓库目录。 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:4:3","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"4.4 Git的状态 Git在执行提交的时候，不是直接将工作区的修改保存到仓库，而是将暂存区域的修改保存到仓库。要提交文件，首先需要把文件加入到暂存区域中。因此，Git管理的文件有三（+2）种状态： 「未跟踪(untracked)：」 新添加的文件，或被移除跟踪的文件，未建立跟踪，通过git add添加暂存并建立跟踪。 「未修改：」 从仓库签出的文件默认状态，修改后就是“已修改”状态了。 「已修改(modified)：」 文件被修改后的状态。 「已暂存(staged)：」 修改、新增的文件添加到暂存区后的状态。 「已提交(committed)：」 从暂存区提交到版本库。 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:4:4","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"5.Git的安装 Git官网：https://www.git-scm.com/ 下载安装包进行安装。Git的使用有两种方式： 「命令行」：Git的命令通过系统命令行工具，或Git提供的命令行工具运行（C:\\Program Files\\Git\\git-bash.exe） 「GUI工具」：Windows(GUI)、Mac(GUI)工具，需单独安装，使用更简单、更易上手。 「下一步傻瓜式安装即可。」 指令git --version查看安装版本号 $ git --version git version 2.39.2.windows.1 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:5:0","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"6.Git快速入门 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:6:0","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"6.1 创建仓库 创建仓库的方式有两种。 一种是创建全新的仓库，基于git init命令来，会在当前目录初始化创建仓库。 一种是通过git clone + 仓库地址的方式，一般叫做克隆远程仓库。 首先准备一个本地的工作目录：GitRepo 新建本地仓库 然后gitbash打开，初始化为git仓库。 $ git init Initialized empty Git repository in D:/IDEA Workplace/GitRepo/.git/ 创建完多出了一个被隐藏的.git目录，这就是本地仓库Git的工作目录。 生成.git文件夹 克隆远程仓库，如在gitee上创建的仓库 https://gitee.com/gaoziman/vue3-doc.git 通过以下命令进行克隆： git clone https://gitee.com/gaoziman/vue3-doc.git 拉取远程代码 可以看到远程仓库就出现在我们的本地工作空间 远程代码出现在本地仓库 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:6:1","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"6.2 暂存区add git add命令就是把要提交的所有修改放到 「暂存区（Stage）」，然后，执行git commit就可以一次性把暂存区的所有修改提交到仓库。 「指令」 「描述」 git add [file1] [file2] 添加文件到暂存区，包括修改的文件、新增的文件 git add [dir] 同上，添加目录到暂存区，包括子目录 git add . 同上，添加**「所有」**修改、新增文件（未跟踪）到暂存区 git rm [file] 删除工作区文件，并且将这次删除放入暂存区 # 查看仓库状态 $ git status On branch master Your branch is up to date with 'origin/master'. Changes not staged for commit: (use \"git add \u003cfile\u003e...\" to update what will be committed) (use \"git restore \u003cfile\u003e...\" to discard changes in working directory) modified: Nodejs.md no changes added to commit (use \"git add\" and/or \"git commit -a\") Administrator@WIN-20231112VVY MINGW64 /d/IDEA Workplace/GitRepo/vue3-doc/01-环境 (master) # 添加到指定文件到暂存区 $ git add Nodejs.md Administrator@WIN-20231112VVY MINGW64 /d/IDEA Workplace/GitRepo/vue3-doc/01-环境 (master) # 继续查看仓库状态 $ git status On branch master Your branch is up to date with 'origin/master'. Changes to be committed: (use \"git restore --staged \u003cfile\u003e...\" to unstage) modified: Nodejs.md 修改之后通过 git add 文件名 即可把文件提交至暂存区 把文件提交至暂存区 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:6:2","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"6.3 commit提交 git commit提交是以时间顺序排列被保存到数据库中的，就如游戏关卡一样，每一次提交（commit）就会产生一条记录：id + 描述 + 快照内容。 「commit id」：根据修改的文件内容采用摘要算法（SHA1）计算出不重复的40位字符，这么长是因为Git是分布式的，要保证唯一性、完整性，一般本地指令中可以只用前几位（6）。即使多年以后，依然可通过id找到曾经的任何内容和变动，再也不用担心丢失了。 「描述」：针对本次提交的描述说明，建议**「准确」**填写，就跟代码中的注释一样，很重要。 「快照」：就是完整的版本文件，以对象树的结构存在仓库下\\.git\\objects目录里，这也是Git效率高的秘诀之一。 我们可以通过 git reflog 查看所有的提交记录包括回退记录。 查看回退记录 我们可以通过提交所有的指令到仓库。 git commit -a -m'修改README的版权信息' 有时候我们提交完了才发现漏掉了几个文件没有添加，或者提交信息写错了。 此时，可以运行带有 --amend 选项的提交命令尝试重新提交： 如果代码没有任何新变化，则用来改写上一次commit的提交信息 $ git commit --amend -m [message] 取消暂存的文件 git reset filename 撤消对文件的修改: git checkout -- filename 用参数 --oneline 可以让日志输出更简洁（一行） git log --oneline 输出 「🔥指令：」 「指令」 「描述」 git commit -m ‘说明’ 提交变更，参数-m设置提交的描述信息，应该正确提交，不带该参数会进入说明编辑模式 git commit -a 参数-a，表示直接从工作区提交到版本库，略过了git add步骤，不包括新增的文件 git commit [file] 提交暂存区的指定文件到仓库区 git commit –amend -m 使用一次新的commit，替代上一次提交，会修改commit的hash值（id） git log -n20 查看日志(最近20条)，不带参数-n则显示所有日志 git log -n20 –oneline 参数“--oneline”可以让日志输出更简洁（一行） git log -n20 –graph 参数“--graph”可视化显示分支关系 git log –follow [file] 显示某个文件的版本历史 git blame [file] 以列表形式显示指定文件的修改记录 git 「reflog」 查看所有可用的历史版本记录（实际是HEAD变更记录），包含被回退的记录（「重要」） git status 查看本地仓库状态，比较常用的指令，加参数-s简洁模式 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:6:3","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"6.4 提交的唯一标识ID 每一个提交都有一个唯一标识，主要就是提交的hash值commit id，在很多指令中会用到，如版本回退、拣选提交等，需要指定一个提交。那标识唯一提交有两种方式： 首先就是commit id，一个40位编码，指令中使用的时候可以只输入前几位（6位）即可。 还有一种就是HEAD~n，是基于当前HEAD位置的一个相对坐标。 HEAD 表示当前分支的最新版本，是比较常用的参数。 HEAD^上一个版本，HEAD^^ 上上一个版本。 HEAD~ 或HEAD~1 表示上一个版本，以此类推，HEAD^10 为最近第10个版本。 HEAD@{2}在git reflog日志中标记的提交记录索引。 通过git log、git reflog可以查看历史日志，可以看每次提交的唯一编号（hash）。区别是git reflog可以查看所有操作的记录（实际是HEAD变更记录），包括被撤销回退的提交记录。 $ git reflog -n10 5acc914 (HEAD -\u003e main) HEAD@{0}: reset: moving to HEAD~ 738748b (dev) HEAD@{1}: reset: moving to HEAD~ 9312c3e HEAD@{2}: reset: moving to HEAD~ db03fcb HEAD@{3}: reset: moving to HEAD~ 1b81fb3 HEAD@{4}: reset: moving to HEAD~ 41ea423 HEAD@{5}: reset: moving to HEAD~ d3e15f9 HEAD@{6}: reset: moving to d3e15f9 1b81fb3 HEAD@{7}: reset: moving to HEAD~1 41ea423 HEAD@{8}: reset: moving to HEAD~ d3e15f9 HEAD@{9}: reset: moving to HEAD~ 查看变更记录 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:6:4","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"6.5 diff比较 git diff用来比较不同文件版本之间的差异。 「指令」 「描述」 「git diff」 查看暂存区和工作区的差异 git diff [file] 同上，指定文件 git diff –cached 查看已暂存的改动，就是暂存区与新版本HEAD进行比较 git diff –staged 同上 git diff –cached [file] 同上，指定文件 git diff HEAD 查看已暂存的+未暂存的所有改动，就是与最新版本HEAD进行比较 git diff HEAD~ 同上，与上一个版本比较。HEAD~表示上一个版本，HEAD~10为最近第10个版本 git diff [id] [id] 查看两次提交之间的差异 git diff [branch] 查看工作区和分支直接的差异 # 查看文件的修改 $ git diff README.md # 查看两次提交的差异 $ git diff 8f4244 1da22 # 显示今天你写了多少行代码：工作区+暂存区 $ git diff --shortstat \"@{10 day ago}\" ","date":"2024-02-02","objectID":"/posts/gitnotes2/:6:5","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"7.远程仓库 Git作为分布式的版本管理系统，我们每个本地终端都有属于自己的Git仓库。但团队协作还需一个中间仓库，作为控制中心，同步各个仓库。于是服务端（远程）仓库就来承担这个职责，服务端不仅有仓库，还配套相关管理功能，这就是所谓的 「远程仓库」 。 远程仓库 远程仓库有好几种，大致分为下面几种。 公共Git服务器，如Github、码云Gitee、腾讯Coding等。 搭建私有Git服务器，如开源的Gitlab、Gitea、等。 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:7:0","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"7.1 远程仓库指令 「指令」 「描述」 git clone [git地址] 从远程仓库克隆到本地（当前目录） git remote -v 查看所有远程仓库，不带参数-v只显示名称 git remote show [remote] 显示某个远程仓库的信息 git remote add [name] [url] 增加一个新的远程仓库，并命名 git remote rename [old] [new] 修改远程仓库名称 「git pull [remote] [branch]」 取回远程仓库的变化，并与本地版本合并 「git pull」 同上，针对当前分支 git fetch [remote] 获取远程仓库的所有变动到本地仓库，不会自动合并！需要手动合并 「git push」 推送当前分支到远程仓库 git push [remote] [branch] 推送本地当前分支到远程仓库的指定分支 git push [remote] –force/-f 强行推送当前分支到远程仓库，即使有冲突，⚠️很危险！ git push [remote] –all 推送所有分支到远程仓库 git push –u 参数–u表示与远程分支建立关联，第一次执行的时候用，后面就不需要了 git remote rm [remote-name] 删除远程仓库 git pull –rebase 使用rebase的模式进行合并 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:7:1","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"7.2 push和pull git push、git pull是团队协作中最常用的指令，用于同步本地、服务端的更新，与他人协作。 「🔸推送」（push）：推送本地仓库到远程仓库。 如果推送的更新与服务端存在冲突，则会被拒绝，push失败。一般是有其他人推送了代码，导致文件冲突，可以先pull代码，在本地进行合并，然后再push。 「🔸拉取」（pull）：从服务端（远程）仓库更新到本地仓库。 git pull：拉取服务端的最新提交到本地，并与本地合并，合并过程同分支的合并。 git fetch：拉取服务端的最新提交到本地，不会自动合并，也不会更新工作区。 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:7:2","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"7.4 fetch和pull有什么区别 1. Git Fetch git fetch命令用于从另一个仓库（例如，远程仓库）下载新的分支和数据，但不会自动合并或修改你当前工作目录下的文件或分支。fetch 命令会把远程仓库的所有信息拉取到本地仓库，但这些改动不会反映在你的当前工作分支上，除非你明确地进行合并。 换句话说，git fetch是一种安全的方式来查看别人已经做了哪些工作，而这些变更在你用git fetch之后不会影响你当前的工作状态。如果你想要让这些变更影响你的当前分支，你需要用git merge手动合并，如git merge origin/master（如果你是从master分支上fetch的）。 2. Git Pull git pull命令实际上是git fetch加上git merge命令的组合。当你执行git pull，Git会从远程仓库获取最新的版本信息，然后尝试自动合并到你当前的分支。通常情况下，这意味着它将远程的更新内容合并到你当前分支的本地副本中。 在简单的情况下，git pull会顺利地将远程变更合并到你的本地分支，你的工作流程可以无缝继续。然而，如果在fetch的数据与你本地的修改存在冲突时，你可能需要手动解决这些冲突。 3. 使用场景对比 在不清楚远程分支的情况下，你可能更倾向于首先使用git fetch来查看有哪些更新，待检查完更新内容后再决定是否合并到当前分支。这是一种更为谨慎的做法，尤其适用于复杂的合并操作，或者当你不希望自动将更改应用到本地仓库时使用。 另一方面，如果你相信远程的变更不会引起任何问题，并且希望你的本地分支保持与远程分支的同步，可以直接使用git pull。 4.案例 获取远程仓库的更新数据，但不合并到当前分支： git fetch origin 获取远程仓库的更新数据并自动合并到当前分支： git pull origin master # 拉取origin远程仓库的master分支并合并到当前分支 git fetch用于安全地查看远程变更，而git pull则用于获取并立刻应用这些变更。两者合适的使用取决于你想如何管理远程数据和本地分支的关系。 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:7:3","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"8.分支 几乎每一种版本控制系统都以某种形式支持分支，一个分支代表一条独立的开发线。 使用分支意味着你可以从开发主线上分离开来，然后在不影响主线的同时继续工作。 分支示意 Git 分支实际上是指向更改快照的指针。 有人把 Git 的分支模型称为**「必杀技特性」**，而正是因为它，将 「Git」 从版本控制系统家族里区分出来。 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:8:0","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"8.1 branch 加入，准备1月份发布新版本，要新开发一些新功能，占领市场。你和小伙伴 「张三」 一起负责开发一个新功能A，开发周期2周，在这两周你们的代码不能影响其他人，不影响主分支。这个时候就可以为这个新功能创建一个分支，你们两在这个分支上干活，2周后代码开发完了、测试通过，就可以合并进要发版的开发分支了。安全、高效，不影响其他人工作，完美！ 实际开发中，我们可能会有多个分支进行开发。 「master」：作为主分支，存放稳定的代码，就是开发后测试通过的代码，不允许随便修改和合并。 「开发分支」：用于团队日常开发用，比如团队计划12月份开发10个功能并发版，则在此分支上进行，不影响主分支的稳定，如果我们开发到一个成熟阶段，依然可以合并到master主分支。 ❝ **「分支」**就是指向某一个提交记录的“指针”引用，因此创建分支是非常快的，不管仓库多大。当我们运行git branch dev创建了一个名字为dev的分支，Git实际上是在.git\\refs\\heads下创建一个dev的引用文件（没有扩展名）。 ❞ ","date":"2024-02-02","objectID":"/posts/gitnotes2/:8:1","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"8.2 分支命令 我这里讲这些命令总结为思维导图，大家可以参考一下。 branch 分支示意导图 列出了当前的所有分支，星号“*”开头的“main”为当前活动分支。 列出当前的所有分支 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:8:2","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"8.3 分支冲突 把两个分支的修改内容合并到一起，常用的合并指令git merge [branch]，将分支[branch]合并到当前分支。根据要合并的内容的不同，具体合并过程就会有多种情况。 首先我们准备一个案例项目，我已经在gitee准备好了，非常简单，只有三个简单的文件。 gitee 代码 1. 快速合并 合并dev到master，注意要先切换到master分支，然后执行git merge dev，把dev合并到当前分支。 首先创建dev分支并切换到dev分支上去。 创建dev分支 然后再dev分支上面创建一个b.txt文件，随之提交到远程仓库中。 BP Network 可以看到我们远程仓库的dev分支上面已经有了b.txt这个文件。 BP Network 然后切换到master分支上面，把dev分支合并到我们的master主分支上面。 BP Network 同时可以看到我们远程仓库中master分支也同步到了dev分支的b.txt文件。 BP Network 2. 普通合并 如果master有变更，存在分支交叉，则会把两边的变更合并成一个提交。 如果两边变更的文件不同，没有什么冲突，就自动合并了。 如果有修改同一个文件，则会存在冲突，到底该采用哪边的，程序无法判断，就换产生冲突。冲突内容需要人工修改后再重新提交，才能完成最终的合并。 我们在远程仓库master分支中手动更改a.txt文件来演示。 1. 第一种情况 BP Network 此时我们在本地仓库中更改其他文件，只要不是a.txt即可，然后push到远程。 BP Network 此时发现我们当前本地仓库的版本号与远程仓库master分支的版本号不一致，导致提交不上去。 这种情况还是比较简单的，只需要通过 git pull 命令将本地版本与远程版本同步即可 BP Network 此时会进行自动合并到本地分支，并当做一次提交，提交信息大家也可以进行更改，我这里默认即可。 BP Network 此时再次提交即可成功提交到远程仓库中。 2. 第二种情况 上面那种方式处理起来比较简单，因为是处理不同的文件。 下面我来演示一下对于同一个文件冲突情况进行解决。 我们在远程仓库手动添加了以下这句话进行对b.txt文件的修改。(可以理解为程序员A修改了b.txt文件并提交到远程仓库中去。) BP Network 此时程序员B也在本地修改了b.txt文件。 BP Network 然后通过一系列命令提交至远程仓库。 可以发现出现冲突之后，我们立即通过git pull 命令进行了同步，但是初始我们的这里发生了很多变化，变成了**「master | MENERGING」**。 BP Network 此时这种情况就是因为在自动合并的时候出现了冲突，git无法帮助我们解决，需要我们自己手动解决冲突。 然后我们在本地打开b.txt文件。 可以看到确实也把远程更改的内容同步过来了，这里就需要我们手动解决，由我们和另外一个程序员协商到底是保留谁的内容或者是都保留。 BP Network 此时我们觉得都进行保留，然后删除其他多余内容。 然后进行代码提交。 BP Network 此时可以发现远程仓库b.txt文件内容已经发现了改变，并且是由我们手动解决并提交的。 BP Network 大功告成!! ","date":"2024-02-02","objectID":"/posts/gitnotes2/:8:3","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"9.Git的版本回退 如果发现我们编写代码中写错了要怎么办，但又分好几种情况，我们依次往下看。 ❓还没提交的怎么撤销？ – checkout 还未提交的修改（工作区、暂存区）不想要了，用签出指令（checkout）进行撤销清除。 或者用checkout的新版回滚指令reset。 ❓「已提交但么有push的提交如何撤销？」—— reset、revert ❓「已push的提交如何撤销？」—— 同上，先本地撤销，然后强制推送git push origin -f，「⚠️注意慎用！」 记得先pull获取更新。 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:9:0","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"9.1 版本回退命令 「指令」 「描述」 git checkout . 撤销工作区的（未暂存）修改，把暂存区恢复到工作区。不影响暂存区，如果没暂存，则撤销所有工作区修改 git checkout [file] 同上，file指定文件 git checkout HEAD . 撤销工作区、暂存区的修改，用HEAD指向的当前分支最新版本替换工作区、暂存区 git checkout HEAD [file] 同上，file指定文件 git reset 撤销暂存区状态，同git reset HEAD，不影响工作区 git reset HEAD [file] 同上，指定文件file，HEAD可省略 git reset [commit] 回退到指定版本，清空暂存区，不影响工作区。工作区需要手动git checkout签出 git reset –soft [commit] 移动分支master、HEAD到指定的版本，不影响暂存区、工作区，需手动git checkout签出更新 git reset –hard HEAD 撤销工作区、暂存区的修改，用当前最新版 git reset –hard HEAD~ 回退到上一个版本，并重置工作区、暂存区内容。 git reset –hard [commit] 回退到指定版本，并重置工作区、暂存区内容。 git 「revert」[commit] 撤销一个提交，会用一个新的提交（原提交的逆向操作）来完成撤销操作，如果已push则重新push即可 git checkout .、git checkout [file] 会清除工作区中未添加到暂存区的修改，用暂存区内容替换工作区。 git checkout HEAD .、git checkout HEAD [file] 会清除工作区、暂存区的修改，用HEAD指向的当前分支最新版本替换暂存区、工作区。 1. 只撤销工作区的修改（未暂存） 撤销工作区的（未暂存）修改，把暂存区恢复到工作区。不影响暂存区，如果没暂存，则撤销所有工作区修改。 BP Network 2. 撤销工作区、暂存区的修改 撤销工作区、暂存区的修改，用HEAD指向的当前分支最新版本替换工作区、暂存区 BP Network ","date":"2024-02-02","objectID":"/posts/gitnotes2/:9:1","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"9.2 reset reset是专门用来撤销修改、回退版本的指令，支持的场景比较多，多种撤销姿势，所以参数组合也比较多。简单理解就是移动master分支、HEAD的“指针”地址，理解这一点就基本掌握reset了。 reset有三种模式，对应三种参数：mixed（默认模式）、soft、hard。三种参数的主要区别就是对工作区、暂存区的操作不同。 mixed为默认模式，参数可以省略。 只有hard模式会重置工作区、暂存区，一般用这个模式会多一点。 BP Network 模式名称 「描述」 「HEAD的位置」 「暂存区」 「工作区」 「soft」 回退到某一个版本，工作区不变，需手动git checkout 修改 不修改 不修改 「mixed」(默认) 撤销暂存区状态，不影响工作区，需手动git checkout 修改 修改 不修改 「hard」 重置未提交修改（工作区、暂存区） 修改 修改 修改 穿梭前，用git log可以查看提交历史，以便确定要回退到哪个版本。要重返未来，用git reflog查看命令历史，以便确定要回到未来的哪个版本。 1. 撤销暂存区 这个其实跟刚刚的 git checkout HEAD .是一样的。 2. 撤销工作区、暂存区修改 $ git reset --hard HEAD 3. 回退版本库到上一个版本，并重置工作区、暂存 $ git reset --hard HEAD~ 可以看到他已经回到了我们上一个版本。 BP Network 通过git log 日志查看也没有了之前的记录，而是被HEAD指向到上一个版本。 BP Network 4. 回到原来的版本，并重置工作区、暂存 $ git reset --hard 891350d 可以看到他又回到上上一步，也就是对上一步操作进行撤销。 BP Network 5. 查看所有历史提交记录 git reflog BP Network ","date":"2024-02-02","objectID":"/posts/gitnotes2/:9:2","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"10.IDEA集成Git 通过以上内容，我们对Git整个工作流程有了一些认识，以及知道如何使用Git进行平时的开发。 但是在真实的开发中，我们可能并不是使用命令行进行操作，而是在IDEA中进行图形化操作，我们写完代码即可进行提交。 我们打开IDEA，依次在settings —》Version Control —》 Git。 选择自己的Git安装路径，然后进行测试看是否成功。 BP Network 点击Test之后看到自己对应的Git版本号之后即可说明我们初步测试成功。 BP Network 然后就可以在IDEA中进行代码的编写。 BP Network 然后讲代码push到远程仓库。 BP Network 相比于命令行，IDEA的图形化操作是不是让人更省心，简单易上手。 ","date":"2024-02-02","objectID":"/posts/gitnotes2/:10:0","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["Git"],"content":"11.参考文献 https://git-scm.com/book/zh/v2 https://www.yuque.com/kanding/ktech/ccgylqhnb94ug4bu#LlJg3 https://javaguide.cn/tools/git/git-intro.html https://www.yiibai.com/git ","date":"2024-02-02","objectID":"/posts/gitnotes2/:11:0","tags":["Git"],"title":"Git 核心知识点总结","uri":"/posts/gitnotes2/"},{"categories":["C++"],"content":"一、导言 导言 文档在所有的软件项目都是有必要的： 对于用户来说，了解如何获得并构建代码，并且如何有效地使用源代码或库； 对于开发人员来说，文档可用来描述你源码细节，并帮助其他程序员参与其中为该项目作出贡献。 Doxygen是非常流行的源代码文档工具。可以在代码中添加文档标记作为注释，而后运行Doxygen提取这些注释，并以Doxyfile配置文件中定义的格式创建文档。Doxygen可以输出HTML、XML，甚至LaTeX或PDF。本篇，将使用CMake来构建Doxygen文档。 ","date":"2024-02-01","objectID":"/posts/cmake_note_45/:1:0","tags":["CMake"],"title":"CMake 笔记 | [45] 使用Doxygen构建文档","uri":"/posts/cmake_note_45/"},{"categories":["C++"],"content":"二、项目结构 . ├── cmake │ └── UseDoxygenDoc.cmake ├── CMakeLists.txt ├── docs │ ├── Doxyfile.in │ └── front_page.md └── src ├── CMakeLists.txt ├── hello_world.cpp ├── message.cpp └── message.hpp 项目地址 https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter10/01 ","date":"2024-02-01","objectID":"/posts/cmake_note_45/:2:0","tags":["CMake"],"title":"CMake 笔记 | [45] 使用Doxygen构建文档","uri":"/posts/cmake_note_45/"},{"categories":["C++"],"content":"三、相关源码 CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(example LANGUAGES CXX) set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_EXTENSIONS OFF) set(CMAKE_CXX_STANDARD_REQUIRED ON) include(GNUInstallDirs) set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_LIBDIR}) set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_LIBDIR}) set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_BINDIR}) list(APPEND CMAKE_MODULE_PATH \"${CMAKE_SOURCE_DIR}/cmake\") include(UseDoxygenDoc) add_subdirectory(src) add_doxygen_doc( BUILD_DIR ${CMAKE_CURRENT_BINARY_DIR}/_build DOXY_FILE ${CMAKE_CURRENT_SOURCE_DIR}/docs/Doxyfile.in TARGET_NAME docs COMMENT \"HTML documentation\" ) 引用 add_doxygen_doc( BUILD_DIR ${CMAKE_CURRENT_BINARY_DIR}/_build DOXY_FILE ${CMAKE_CURRENT_SOURCE_DIR}/docs/Doxyfile.in TARGET_NAME docs COMMENT \"HTML documentation\" ) 这是一个自定义函数，该函数在cmake/UseDoxygenDox.cmake中被定义。有四个参数：BUILD_DIR,DOXY_FILE,TARGET_NAME以及COMMENT。具体使用方法，请参考下面的介绍。 当然，为了能够使用Doxygen需要事先执行以下命令安装： sudo apt install doxygen cmake/UseDoxygenDoc.cmake find_package(Perl REQUIRED) find_package(Doxygen REQUIRED) function(add_doxygen_doc) set(options) set(oneValueArgs BUILD_DIR DOXY_FILE TARGET_NAME COMMENT) set(multiValueArgs) cmake_parse_arguments(DOXY_DOC \"${options}\" \"${oneValueArgs}\" \"${multiValueArgs}\" ${ARGN} ) configure_file( ${DOXY_DOC_DOXY_FILE} ${DOXY_DOC_BUILD_DIR}/Doxyfile @ONLY ) add_custom_target(${DOXY_DOC_TARGET_NAME} COMMAND ${DOXYGEN_EXECUTABLE} Doxyfile WORKING_DIRECTORY ${DOXY_DOC_BUILD_DIR} COMMENT \"Building ${DOXY_DOC_COMMENT} with Doxygen\" VERBATIM ) message(STATUS \"Added ${DOXY_DOC_TARGET_NAME} [Doxygen] target to build documentation\") endfunction() set(options): 定义一个变量options，在这里没有列出任何选项，表示该函数没有不带值的选项参数。 set(oneValueArgs BUILD_DIR DOXY_FILE TARGET_NAME COMMENT): 定义了接受单个值的参数。这里列出了四个参数：BUILD_DIR是文档构建的目录，DOXY_FILE是Doxygen的配置文件，TARGET_NAME是CMake目标的名字，COMMENT是构建时显示的注释。 set(multiValueArgs): 定义了接受多个值的参数，但在此脚本中未使用。 cmake_parse_arguments(DOXY_DOC ...): 用于解析调用函数时传入的参数，并将解析后的值存储到DOXY_DOC变量中。 configure_file(...): 用于处理配置文件。它将DOXY_DOC_DOXY_FILE参数指定的Doxygen配置文件复制到DOXY_DOC_BUILD_DIR参数指定的构建目录，并替换其中的变量。 add_custom_target(...): 添加了一个自定义的目标到CMake，执行这个目标时，它会在DOXY_DOC_BUILD_DIR目录下运行Doxygen来生成文档。 COMMAND ${DOXYGEN_EXECUTABLE} Doxyfile: 这是实际调用Doxygen命令的部分。 WORKING_DIRECTORY ${DOXY_DOC_BUILD_DIR}: 指定了Doxygen命令运行的工作目录。 COMMENT \"Building ${DOXY_DOC_COMMENT} with Doxygen\": 设置了当执行这个CMake目标时显示的注释。 VERBATIM: 保证了命令行在所有平台上以字面意义执行，没有任何变化。 message(STATUS \"Added ${DOXY_DOC_TARGET_NAME} [Doxygen] target to build documentation\"): 这行打印一条状态消息，告诉用户已经添加了一个名为${DOXY_DOC_TARGET_NAME}的目标，用于构建文档。 docs/Doxyfile.in # Doxyfile 1.8.14 #--------------------------------------------------------------------------- # Project related configuration options #--------------------------------------------------------------------------- DOXYFILE_ENCODING = UTF-8 PROJECT_NAME = recipe-01 PROJECT_NUMBER = PROJECT_BRIEF = PROJECT_LOGO = OUTPUT_DIRECTORY = CREATE_SUBDIRS = NO OUTPUT_LANGUAGE = English BRIEF_MEMBER_DESC = YES REPEAT_BRIEF = YES ABBREVIATE_BRIEF = \"The $name class\" \\ \"The $name widget\" \\ \"The $name file\" \\ is \\ provides \\ specifies \\ contains \\ represents \\ a \\ an \\ the ALWAYS_DETAILED_SEC = NO INLINE_INHERITED_MEMB = NO FULL_PATH_NAMES = YES STRIP_FROM_PATH = STRIP_FROM_INC_PATH = SHORT_NAMES = NO JAVADOC_AUTOBRIEF = NO QT_AUTOBRIEF = NO MULTILINE_CPP_IS_BRIEF = NO INHERIT_DOCS = YES SEPARATE_MEMBER_PAGES = NO TAB_SIZE = 4 ALIASES = TCL_SUBST = OPTIMIZE_OUTPUT_FOR_C = NO OPTIMIZE_OUTPUT_JAVA = NO OPTIMIZE_FOR_FORTRAN = NO OPTIMIZE_OUTPUT_VHDL = NO EXTENSION_MAPPING = MARKDOWN_SUPPORT = YES AUTOLINK_SUPPORT = YES BUILTIN_STL_SUPPORT = NO CPP_CLI_SUPPORT = NO SIP_SUPPORT = NO IDL_PROPERTY_SUPPORT = YES DISTRIBUTE_GROUP_DOC = NO SUBGROUPING = YES INLINE_GROUPED_CLASSES = NO INLINE_SIMPLE_STRUCTS = NO TYPEDEF_HIDES_STRUCT = NO LOOKUP_CACHE_SIZE = 0 #--------------------------------------------------------------------------- # Build related co","date":"2024-02-01","objectID":"/posts/cmake_note_45/:3:0","tags":["CMake"],"title":"CMake 笔记 | [45] 使用Doxygen构建文档","uri":"/posts/cmake_note_45/"},{"categories":["C++"],"content":"四、结果展示 mkdir build \u0026 cd build cmake .. cmake --build . --target docs doxygen 文档 ![Image](data:image/svg+xml,%3C%3Fxml version=‘1.0’ encoding=‘UTF-8’%3F%3E%3Csvg width=‘1px’ height=‘1px’ viewBox=‘0 0 1 1’ version=‘1.1’ xmlns=‘http://www.w3.org/2000/svg' xmlns:xlink=‘http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke=‘none’ stroke-width=‘1’ fill=‘none’ fill-rule=‘evenodd’ fill-opacity=‘0’%3E%3Cg transform=‘translate(-249.000000, -126.000000)’ fill=’%23FFFFFF’%3E%3Crect x=‘249’ y=‘126’ width=‘1’ height=‘1’%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E) ![Image](data:image/svg+xml,%3C%3Fxml version=‘1.0’ encoding=‘UTF-8’%3F%3E%3Csvg width=‘1px’ height=‘1px’ viewBox=‘0 0 1 1’ version=‘1.1’ xmlns=‘http://www.w3.org/2000/svg' xmlns:xlink=‘http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke=‘none’ stroke-width=‘1’ fill=‘none’ fill-rule=‘evenodd’ fill-opacity=‘0’%3E%3Cg transform=‘translate(-249.000000, -126.000000)’ fill=’%23FFFFFF’%3E%3Crect x=‘249’ y=‘126’ width=‘1’ height=‘1’%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E) cmake45 cmake · 目录 上一篇CMake:验证自己生成的库 People who liked this content also liked CMake:超级构建模式 Hope Hut 不喜欢 不看的原因 OK 内容质量低 不看此公众号 值得苦练的100道Python经典练手题，（附详细答案）建议收藏 编程课代表 不喜欢 不看的原因 OK 内容质量低 不看此公众号 Deno 1.40、Shikiji 0.10、Mantine 7.5、Bun for Windows、Rsdoctor、Zed 前端仓库 不喜欢 不看 ","date":"2024-02-01","objectID":"/posts/cmake_note_45/:4:0","tags":["CMake"],"title":"CMake 笔记 | [45] 使用Doxygen构建文档","uri":"/posts/cmake_note_45/"},{"categories":["C++"],"content":"一、导言 引用 经过上一篇（CMake:输出库（像其他优秀的库一样优雅）），我们已经构建出了优雅的库。本篇，我们将基于上一篇的内容，写一个简单的使用demo进行验证！ ","date":"2024-02-01","objectID":"/posts/cmake_note_44/:1:0","tags":["CMake"],"title":"CMake 笔记 | [44] 验证自己生成的库","uri":"/posts/cmake_note_44/"},{"categories":["C++"],"content":"二、项目结构 . ├── CMakeLists.txt └── use_message.cpp 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter9/04 ","date":"2024-02-01","objectID":"/posts/cmake_note_44/:2:0","tags":["CMake"],"title":"CMake 笔记 | [44] 验证自己生成的库","uri":"/posts/cmake_note_44/"},{"categories":["C++"],"content":"三、相关源码 CMakeLists.txt cmake_minimum_required(VERSION 3.5 FATAL_ERROR) project(use-message LANGUAGES CXX ) set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_EXTENSIONS OFF) set(CMAKE_CXX_STANDARD_REQUIRED ON) set(CMAKE_PREFIX_PATH /home/jiangli/repo/tutorials/cmake-tutorial/chapter9/03/output/share/cmake/example) find_package(message REQUIRED CONFIG) if(message_FOUND) message(STATUS \"Found message: (found version ${message_VERSION})\") endif() include_directories(/home/jiangli/repo/tutorials/cmake-tutorial/chapter9/03/output/include) add_executable(use_message use_message.cpp) target_link_libraries(use_message message::message-shared) 引用 这里，我们没有对我们的库添加到环境变量中，所以为了使find_package命令能够找到我们的库，需要在find_package命令前设置库所在的cmake文件路径。 set(CMAKE_PREFIX_PATH /home/jiangli/repo/tutorials/cmake-tutorial/chapter9/03/output/share/cmake/example) 如果我们把生成的库设置到环境变量中，那么我们就可以省略掉这一步骤！ use_message.cpp #include \u003ccstdlib\u003e #include \u003ciostream\u003e #include \u003cmessage/message.hpp\u003e int main() { Message say_hello(\"Hello, CMake World!\"); std::cout \u003c\u003c say_hello \u003c\u003c std::endl; Message say_goodbye(\"Goodbye, CMake World\"); std::cout \u003c\u003c say_goodbye \u003c\u003c std::endl; return EXIT_SUCCESS; } ","date":"2024-02-01","objectID":"/posts/cmake_note_44/:3:0","tags":["CMake"],"title":"CMake 笔记 | [44] 验证自己生成的库","uri":"/posts/cmake_note_44/"},{"categories":["C++"],"content":"四、结果展示 mkdir build \u0026 cd build cmake .. make . ./use_message 验证生成的库 ![Image](data:image/svg+xml,%3C%3Fxml version=‘1.0’ encoding=‘UTF-8’%3F%3E%3Csvg width=‘1px’ height=‘1px’ viewBox=‘0 0 1 1’ version=‘1.1’ xmlns=‘http://www.w3.org/2000/svg' xmlns:xlink=‘http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke=‘none’ stroke-width=‘1’ fill=‘none’ fill-rule=‘evenodd’ fill-opacity=‘0’%3E%3Cg transform=‘translate(-249.000000, -126.000000)’ fill=’%23FFFFFF’%3E%3Crect x=‘249’ y=‘126’ width=‘1’ height=‘1’%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E) ![Image](data:image/svg+xml,%3C%3Fxml version=‘1.0’ encoding=‘UTF-8’%3F%3E%3Csvg width=‘1px’ height=‘1px’ viewBox=‘0 0 1 1’ version=‘1.1’ xmlns=‘http://www.w3.org/2000/svg' xmlns:xlink=‘http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke=‘none’ stroke-width=‘1’ fill=‘none’ fill-rule=‘evenodd’ fill-opacity=‘0’%3E%3Cg transform=‘translate(-249.000000, -126.000000)’ fill=’%23FFFFFF’%3E%3Crect x=‘249’ y=‘126’ width=‘1’ height=‘1’%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E) cmake45 cmake · 目录 上一篇CMake:输出库（像其他优秀的库一样优雅）下一篇CMake:使用Doxygen构建文档 People who liked this content also liked CMake:超级构建模式 Hope Hut 不喜欢 不看的原因 OK 内容质量低 不看此公众号 CMake:使用函数和宏重用代码 Hope Hut 不喜欢 不看的原因 OK 内容质量低 不看此公众号 CMake:使用Doxygen构建文档 Hope Hut 不喜欢 不看的原因 OK 内容质量低 不看此公众号 Scan to Follow people underline ","date":"2024-02-01","objectID":"/posts/cmake_note_44/:4:0","tags":["CMake"],"title":"CMake 笔记 | [44] 验证自己生成的库","uri":"/posts/cmake_note_44/"},{"categories":["C++"],"content":"一、导言 引用 前面的笔记中（CMake：静态库和动态库的详解(Linux/Windows)），展示了如何输出动态库和静态库，但是存在一些问题，如只输出了其头文件、符号表和库文件，但实际我们希望，当其他人编译并安装了我们的库，库就能更容易找到，如配置完环境变换或者指定库的路径。这篇笔记将展示CMake如何让我们导出目标，以便其他使用CMake的项目可以轻松地获取它们。 ","date":"2024-02-01","objectID":"/posts/cmake_note_43/:1:0","tags":["CMake"],"title":"CMake 笔记 | [43] 输出库","uri":"/posts/cmake_note_43/"},{"categories":["C++"],"content":"二、项目结构 . ├── cmake │ └── messageConfig.cmake.in ├── CMakeLists.txt ├── src │ ├── CMakeLists.txt │ ├── hello_world.cpp │ ├── message.cpp │ └── message.hpp └── test └── CMakeLists.txt 项目地址 https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter9/03 ","date":"2024-02-01","objectID":"/posts/cmake_note_43/:2:0","tags":["CMake"],"title":"CMake 笔记 | [43] 输出库","uri":"/posts/cmake_note_43/"},{"categories":["C++"],"content":"三、相关源码 CMakeLists.txt # CMake 3.6 needed for IMPORTED_TARGET option # to pkg_search_module cmake_minimum_required(VERSION 3.6 FATAL_ERROR) project(example LANGUAGES CXX VERSION 1.0.0 ) # \u003c\u003c\u003c General set up \u003e\u003e\u003e set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_EXTENSIONS OFF) set(CMAKE_CXX_STANDARD_REQUIRED ON) # 检查是否已经设置了安装前缀 if(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT) # 设置安装目录为项目源目录下的output文件夹 set(CMAKE_INSTALL_PREFIX \"${CMAKE_SOURCE_DIR}/output/\" CACHE PATH \"...\" FORCE) endif() message(STATUS \"Project will be installed to ${CMAKE_INSTALL_PREFIX}\") if(NOT CMAKE_BUILD_TYPE) set(CMAKE_BUILD_TYPE Release CACHE STRING \"Build type\" FORCE) endif() message(STATUS \"Build type set to ${CMAKE_BUILD_TYPE}\") include(GNUInstallDirs) set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${PROJECT_BINARY_DIR}/${CMAKE_INSTALL_LIBDIR}) set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${PROJECT_BINARY_DIR}/${CMAKE_INSTALL_LIBDIR}) set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${PROJECT_BINARY_DIR}/${CMAKE_INSTALL_BINDIR}) # Offer the user the choice of overriding the installation directories set(INSTALL_LIBDIR ${CMAKE_INSTALL_LIBDIR} CACHE PATH \"Installation directory for libraries\") set(INSTALL_BINDIR ${CMAKE_INSTALL_BINDIR} CACHE PATH \"Installation directory for executables\") set(INSTALL_INCLUDEDIR ${CMAKE_INSTALL_INCLUDEDIR} CACHE PATH \"Installation directory for header files\") if(WIN32 AND NOT CYGWIN) set(DEF_INSTALL_CMAKEDIR CMake) else() set(DEF_INSTALL_CMAKEDIR share/cmake/${PROJECT_NAME}) endif() set(INSTALL_CMAKEDIR ${DEF_INSTALL_CMAKEDIR} CACHE PATH \"Installation directory for CMake files\") # Report to user foreach(p LIB BIN INCLUDE CMAKE) file(TO_NATIVE_PATH ${CMAKE_INSTALL_PREFIX}/${INSTALL_${p}DIR} _path ) message(STATUS \"Installing ${p} components to ${_path}\") unset(_path) endforeach() add_subdirectory(src) enable_testing() add_subdirectory(test) 上述cmake在上一篇cmake:导出头文件相关代码详细分析过了，请移步到上一篇参考。 cmake/messageConfig.cmake.in @PACKAGE_INIT@ include(\"${CMAKE_CURRENT_LIST_DIR}/messageTargets.cmake\") check_required_components( \"message-shared\" \"message-static\" \"message-hello-world_wDSO\" \"message-hello-world_wAR\" ) # Remove dependency on UUID if on Windows if(NOT WIN32) if(NOT TARGET PkgConfig::UUID) find_package(PkgConfig REQUIRED QUIET) pkg_search_module(UUID REQUIRED uuid IMPORTED_TARGET) endif() endif() 引用 @PACKAGE_INIT@ 占位符将使用configure_package_config_file命令进行替换。如果项目成功构建，那么将在messageConfig.cmake文件中进行替换： get_filename_component(PACKAGE_PREFIX_DIR \"${CMAKE_CURRENT_LIST_DIR}/../../../\" ABSOLUTE) macro(set_and_check _var _file) set(${_var} \"${_file}\") if(NOT EXISTS \"${_file}\") message(FATAL_ERROR \"File or directory ${_file} referenced by variable ${_var} does not exist !\") endif() endmacro() macro(check_required_components _NAME) foreach(comp ${${_NAME}_FIND_COMPONENTS}) if(NOT ${_NAME}_${comp}_FOUND) if(${_NAME}_FIND_REQUIRED_${comp}) set(${_NAME}_FOUND FALSE) endif() endif() endforeach() endmacro() 引用 include(\"${CMAKE_CURRENT_LIST_DIR}/messageTargets.cmake\") 包含为目标自动生成的导出文件。 引用 check_required_components( \"message-shared\" \"message-static\" \"message-hello-world_wDSO\" \"message-hello-world_wAR\" ) 检查静态库和动态库，以及两个Hello, World可执行文件是否带有CMake提供的check_required_components函数。 引用 if(NOT WIN32) if(NOT TARGET PkgConfig::UUID) find_package(PkgConfig REQUIRED QUIET) pkg_search_module(UUID REQUIRED uuid IMPORTED_TARGET) endif() endif() 检查目标PkgConfig::UUID是否存在。如果没有，再次搜索UUID库(只在非Windows操作系统下有效)。 src/CMakeLists.txt # Search for pkg-config and UUID find_package(PkgConfig QUIET) if(PKG_CONFIG_FOUND) pkg_search_module(UUID uuid IMPORTED_TARGET) if(TARGET PkgConfig::UUID) message(STATUS \"Found libuuid\") set(UUID_FOUND TRUE) endif() endif() # \u003c\u003c\u003c Build targets \u003e\u003e\u003e # SHARED library add_library(message-shared SHARED \"\") include(GenerateExportHeader) generate_export_header(message-shared BASE_NAME \"message\" EXPORT_MACRO_NAME \"MESSAGE_LIB_API\" EXPORT_FILE_NAME \"${CMAKE_BINARY_DIR}/${INSTALL_INCLUDEDIR}/message_export.h\" STATIC_DEFINE \"MESSAGE_STATIC_DEFINE\" DEFINE_NO_DEPRECATED ) target_sources(message-shared PRIVATE ${C","date":"2024-02-01","objectID":"/posts/cmake_note_43/:3:0","tags":["CMake"],"title":"CMake 笔记 | [43] 输出库","uri":"/posts/cmake_note_43/"},{"categories":["C++"],"content":"四、结果展示 $ mkdir -p build $ cd build $ cmake .. $ cmake --build . --target install 安装树结构： output ├── bin │ ├── hello-world_wAR │ └── hello-world_wDSO ├── include │ └── message │ ├── message_export.h │ └── message.hpp ├── lib │ ├── libmessage_s.a │ ├── libmessage.so -\u003e libmessage.so.1 │ └── libmessage.so.1 └── share └── cmake └── example ├── messageConfig.cmake ├── messageConfigVersion.cmake ├── messageTargets.cmake └── messageTargets-release.cmake ","date":"2024-02-01","objectID":"/posts/cmake_note_43/:4:0","tags":["CMake"],"title":"CMake 笔记 | [43] 输出库","uri":"/posts/cmake_note_43/"},{"categories":["C++"],"content":"一、导言 引用 其实，本篇的相关内容已经在CMake：静态库和动态库的详解(Linux/Windows)笔记中已经详细介绍了具体使用方法，且展示了CMake提供了与平台无关的方式实现的功能。但是，没有处理符号可见性的问题。关于符号的可见性的最佳方式是规定动态库只公开最小的符号，从而限制代码中定义的对象和函数对外的可见性。 我们希望在默认情况下，动态库定义的所有符号都对外隐藏。这将使得项目的贡献者，能够清楚地划分库和外部代码之间的接口，因为他们必须显式地标记所有要在项目外部使用的符号。 ","date":"2024-02-01","objectID":"/posts/cmake_note_42/:1:0","tags":["CMake"],"title":"CMake 笔记 | [42] 导出头文件","uri":"/posts/cmake_note_42/"},{"categories":["C++"],"content":"二、项目结构 . ├── CMakeLists.txt ├── src │ ├── CMakeLists.txt │ ├── hello_world.cpp │ ├── message.cpp │ └── message.hpp └── test └── CMakeLists.txt 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter9/02 ","date":"2024-02-01","objectID":"/posts/cmake_note_42/:2:0","tags":["CMake"],"title":"CMake 笔记 | [42] 导出头文件","uri":"/posts/cmake_note_42/"},{"categories":["C++"],"content":"三、相关源码 CMakeLists.txt # CMake 3.6 needed for IMPORTED_TARGET option # to pkg_search_module cmake_minimum_required(VERSION 3.6 FATAL_ERROR) project( example LANGUAGES CXX VERSION 1.0.0 ) # \u003c\u003c\u003c General set up \u003e\u003e\u003e set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_EXTENSIONS OFF) set(CMAKE_CXX_STANDARD_REQUIRED ON) # 检查是否已经设置了安装前缀 if(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT) # 设置安装目录为项目源目录下的output文件夹 set(CMAKE_INSTALL_PREFIX \"${CMAKE_SOURCE_DIR}/output/\" CACHE PATH \"...\" FORCE) endif() message(STATUS \"Project will be installed to ${CMAKE_INSTALL_PREFIX}\") if(NOT CMAKE_BUILD_TYPE) set(CMAKE_BUILD_TYPE Release CACHE STRING \"Build type\" FORCE) endif() message(STATUS \"Build type set to ${CMAKE_BUILD_TYPE}\") include(GNUInstallDirs) set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${PROJECT_BINARY_DIR}/${CMAKE_INSTALL_LIBDIR}) set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${PROJECT_BINARY_DIR}/${CMAKE_INSTALL_LIBDIR}) set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${PROJECT_BINARY_DIR}/${CMAKE_INSTALL_BINDIR}) # Offer the user the choice of overriding the installation directories set(INSTALL_LIBDIR ${CMAKE_INSTALL_LIBDIR} CACHE PATH \"Installation directory for libraries\") set(INSTALL_BINDIR ${CMAKE_INSTALL_BINDIR} CACHE PATH \"Installation directory for executables\") set(INSTALL_INCLUDEDIR ${CMAKE_INSTALL_INCLUDEDIR} CACHE PATH \"Installation directory for header files\") if(WIN32 AND NOT CYGWIN) set(DEF_INSTALL_CMAKEDIR CMake) else() set(DEF_INSTALL_CMAKEDIR share/cmake/${PROJECT_NAME}) endif() set(INSTALL_CMAKEDIR ${DEF_INSTALL_CMAKEDIR} CACHE PATH \"Installation directory for CMake files\") # Report to user foreach(p LIB BIN INCLUDE CMAKE) file(TO_NATIVE_PATH ${CMAKE_INSTALL_PREFIX}/${INSTALL_${p}DIR} _path ) message(STATUS \"Installing ${p} components to ${_path}\") unset(_path) endforeach() add_subdirectory(src) enable_testing() add_subdirectory(test) src/CMakeLists.txt # Search for pkg-config and UUID find_package(PkgConfig QUIET) if(PKG_CONFIG_FOUND) pkg_search_module(UUID uuid IMPORTED_TARGET) if(TARGET PkgConfig::UUID) message(STATUS \"Found libuuid\") set(UUID_FOUND TRUE) endif() endif() # \u003c\u003c\u003c Build targets \u003e\u003e\u003e # SHARED library add_library(message-shared SHARED \"\") target_sources(message-shared PRIVATE ${CMAKE_CURRENT_LIST_DIR}/message.cpp ) target_compile_definitions(message-shared PUBLIC $\u003c$\u003cBOOL:${UUID_FOUND}\u003e:HAVE_UUID\u003e ) target_link_libraries(message-shared PUBLIC $\u003c$\u003cBOOL:${UUID_FOUND}\u003e:PkgConfig::UUID\u003e ) set_target_properties(message-shared PROPERTIES POSITION_INDEPENDENT_CODE 1 CXX_VISIBILITY_PRESET hidden VISIBILITY_INLINES_HIDDEN 1 SOVERSION ${PROJECT_VERSION_MAJOR} OUTPUT_NAME \"message\" DEBUG_POSTFIX \"_d\" PUBLIC_HEADER \"message.hpp;${CMAKE_BINARY_DIR}/${INSTALL_INCLUDEDIR}/message_export.h\" MACOSX_RPATH ON ) include(GenerateExportHeader) generate_export_header(message-shared BASE_NAME \"message\" EXPORT_MACRO_NAME \"MESSAGE_LIB_API\" EXPORT_FILE_NAME \"${CMAKE_BINARY_DIR}/${INSTALL_INCLUDEDIR}/message_export.h\" STATIC_DEFINE \"MESSAGE_STATIC_DEFINE\" DEFINE_NO_DEPRECATED ) target_include_directories(message-shared PUBLIC ${CMAKE_BINARY_DIR}/${INSTALL_INCLUDEDIR} ) # STATIC library add_library(message-static STATIC \"\") target_sources(message-static PRIVATE ${CMAKE_CURRENT_LIST_DIR}/message.cpp ) target_compile_definitions(message-static PUBLIC MESSAGE_STATIC_DEFINE $\u003c$\u003cBOOL:${UUID_FOUND}\u003e:HAVE_UUID\u003e ) target_include_directories(message-static PUBLIC ${CMAKE_BINARY_DIR}/${INSTALL_INCLUDEDIR} ) target_link_libraries(message-static PUBLIC $\u003c$\u003cBOOL:${UUID_FOUND}\u003e:PkgConfig::UUID\u003e ) set_target_properties(message-static PROPERTIES POSITION_INDEPENDENT_CODE 1 ARCHIVE_OUTPUT_NAME \"message\" DEBUG_POSTFIX \"_sd\" RELEASE_POSTFIX \"_s\" PUBLIC_HEADER \"message.hpp;${CMAKE_BINARY_DIR}/${INSTALL_INCLUDEDIR}/message_export.h\" ) # EXECUTABLES add_executable(hello-world_wDSO hello_world.cpp) target_link_libraries(hello-world_wDSO PUBLIC message-shared ) # Prepare RPATH file(RELATIVE_PATH _rel ${CMAKE_INSTALL_PREFIX}/${INSTALL_BINDIR} ${CMAKE_INSTALL_PREFIX}) if(APPLE) set(_rpath \"@loader_path/${","date":"2024-02-01","objectID":"/posts/cmake_note_42/:3:0","tags":["CMake"],"title":"CMake 笔记 | [42] 导出头文件","uri":"/posts/cmake_note_42/"},{"categories":["C++"],"content":"四、结果展示 \u0026 mkdir build \u0026 cd build \u0026 cmake .. \u0026 cmake --build . --target install Scanning dependencies of target message-static [ 12%] Building CXX object src/CMakeFiles/message-static.dir/message.cpp.o [ 25%] Linking CXX static library ../lib/libmessage_s.a [ 25%] Built target message-static Scanning dependencies of target hello-world_wAR [ 37%] Building CXX object src/CMakeFiles/hello-world_wAR.dir/hello_world.cpp.o [ 50%] Linking CXX executable ../bin/hello-world_wAR [ 50%] Built target hello-world_wAR Scanning dependencies of target message-shared [ 62%] Building CXX object src/CMakeFiles/message-shared.dir/message.cpp.o [ 75%] Linking CXX shared library ../lib/libmessage.so [ 75%] Built target message-shared Scanning dependencies of target hello-world_wDSO [ 87%] Building CXX object src/CMakeFiles/hello-world_wDSO.dir/hello_world.cpp.o [100%] Linking CXX executable ../bin/hello-world_wDSO [100%] Built target hello-world_wDSO Install the project... -- Install configuration: \"Release\" -- Installing: /home/jiangli/repo/tutorials/cmake-tutorial/chapter9/02/output/lib/libmessage.so.1 -- Up-to-date: /home/jiangli/repo/tutorials/cmake-tutorial/chapter9/02/output/lib/libmessage.so -- Up-to-date: /home/jiangli/repo/tutorials/cmake-tutorial/chapter9/02/output/include/message/message.hpp -- Installing: /home/jiangli/repo/tutorials/cmake-tutorial/chapter9/02/output/include/message/message_export.h -- Installing: /home/jiangli/repo/tutorials/cmake-tutorial/chapter9/02/output/lib/libmessage_s.a -- Up-to-date: /home/jiangli/repo/tutorials/cmake-tutorial/chapter9/02/output/include/message/message.hpp -- Up-to-date: /home/jiangli/repo/tutorials/cmake-tutorial/chapter9/02/output/include/message/message_export.h -- Installing: /home/jiangli/repo/tutorials/cmake-tutorial/chapter9/02/output/bin/hello-world_wDSO -- Set runtime path of \"/home/jiangli/repo/tutorials/cmake-tutorial/chapter9/02/output/bin/hello-world_wDSO\" to \"$ORIGIN/../lib\" -- Installing: /home/jiangli/repo/tutorials/cmake-tutorial/chapter9/02/output/bin/hello-world_wAR 输出： 导处头文件 ","date":"2024-02-01","objectID":"/posts/cmake_note_42/:4:0","tags":["CMake"],"title":"CMake 笔记 | [42] 导出头文件","uri":"/posts/cmake_note_42/"},{"categories":["C++"],"content":"一、导言 导言 这篇笔记，将通过一个小项目来介绍一些基本概念，这些概念也将在后面的笔记中使用。安装文件、库和可执行文件是一项非常基础的任务，但是也可能会带来一些问题。通过这篇笔记，展示如何使用CMake有效地避开这些问题。 ","date":"2024-02-01","objectID":"/posts/cmake_note_41/:1:0","tags":["CMake"],"title":"CMake 笔记 | [41] 安装项目","uri":"/posts/cmake_note_41/"},{"categories":["C++"],"content":"二、项目结构 . ├── CMakeLists.txt ├── src │ ├── CMakeLists.txt │ ├── hello_world.cpp │ ├── message.cpp │ └── message.hpp └── test └── CMakeLists.txt 项目地址 https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter9/01 ","date":"2024-02-01","objectID":"/posts/cmake_note_41/:2:0","tags":["CMake"],"title":"CMake 笔记 | [41] 安装项目","uri":"/posts/cmake_note_41/"},{"categories":["C++"],"content":"三、相关源码 src/CMakeLists.txt # Search for pkg-config and UUID find_package(PkgConfig QUIET) if(PKG_CONFIG_FOUND) pkg_search_module(UUID uuid IMPORTED_TARGET) if(TARGET PkgConfig::UUID) message(STATUS \"Found libuuid\") set(UUID_FOUND TRUE) endif() endif() # SHARED library add_library(message-shared SHARED \"\") target_sources(message-shared PRIVATE ${CMAKE_CURRENT_LIST_DIR}/message.cpp ) target_compile_definitions(message-shared PUBLIC $\u003c$\u003cBOOL:${UUID_FOUND}\u003e:HAVE_UUID\u003e ) target_link_libraries(message-shared PUBLIC $\u003c$\u003cBOOL:${UUID_FOUND}\u003e:PkgConfig::UUID\u003e ) set_target_properties(message-shared PROPERTIES POSITION_INDEPENDENT_CODE 1 SOVERSION ${PROJECT_VERSION_MAJOR} OUTPUT_NAME \"message\" DEBUG_POSTFIX \"_d\" PUBLIC_HEADER \"message.hpp\" MACOSX_RPATH ON WINDOWS_EXPORT_ALL_SYMBOLS ON ) add_executable(hello-world_wDSO hello_world.cpp) target_link_libraries(hello-world_wDSO PUBLIC message-shared ) # Prepare RPATH file(RELATIVE_PATH _rel ${CMAKE_INSTALL_PREFIX}/${INSTALL_BINDIR} ${CMAKE_INSTALL_PREFIX}) if(APPLE) set(_rpath \"@loader_path/${_rel}\") else() set(_rpath \"\\$ORIGIN/${_rel}\") endif() file(TO_NATIVE_PATH \"${_rpath}/${INSTALL_LIBDIR}\" message_RPATH) set_target_properties(hello-world_wDSO PROPERTIES MACOSX_RPATH ON SKIP_BUILD_RPATH OFF BUILD_WITH_INSTALL_RPATH OFF INSTALL_RPATH \"${message_RPATH}\" INSTALL_RPATH_USE_LINK_PATH ON ) # \u003c\u003c\u003c Install and export targets \u003e\u003e\u003e install( TARGETS message-shared hello-world_wDSO ARCHIVE DESTINATION ${INSTALL_LIBDIR} COMPONENT lib RUNTIME DESTINATION ${INSTALL_BINDIR} COMPONENT bin LIBRARY DESTINATION ${INSTALL_LIBDIR} COMPONENT lib PUBLIC_HEADER DESTINATION ${INSTALL_INCLUDEDIR}/message COMPONENT dev ) tips target_compile_definitions(message-shared PUBLIC $\u003c$\u003cBOOL:${UUID_FOUND}\u003e:HAVE_UUID\u003e ) 如果我们找到了三方库UUID的话，该命令会将 HAVE_UUID 编译定义添加到消息共享目标及其依赖库中。 引用 这段 CMake 脚本使用了 set_target_properties 命令来为 message-shared 这个目标（通常是一个库或可执行文件）设置一系列属性。下面我会用中文解释这些属性的含义： set_target_properties(message-shared PROPERTIES POSITION_INDEPENDENT_CODE 1 SOVERSION ${PROJECT_VERSION_MAJOR} OUTPUT_NAME \"message\" DEBUG_POSTFIX \"_d\" PUBLIC_HEADER \"message.hpp\" MACOSX_RPATH ON WINDOWS_EXPORT_ALL_SYMBOLS ON ) POSITION_INDEPENDENT_CODE 1: 设置代码为位置无关代码。这对于创建共享库是重要的，因为它允许代码在内存中的任何位置运行，这对于共享库来说是必需的。 SOVERSION ${PROJECT_VERSION_MAJOR}: 设置共享对象版本号，这里使用的是项目的主版本号。 OUTPUT_NAME \"message\": 指定输出的名称。尽管目标名称是 message-shared，在构建时生成的文件将被命名为 message（例如，message.dll 或 message.so）。 DEBUG_POSTFIX \"_d\": 为调试版本的输出添加后缀。在构建调试版本时，输出文件的名称会有一个额外的 _d 后缀，有助于区分调试和发布版本。 PUBLIC_HEADER \"message.hpp\": 指定公共头文件。 MACOSX_RPATH ON: 在 macOS 系统上启用 RPATH。这是一种动态库查找路径的设置方法，有助于应用程序在运行时找到其依赖的共享库。 WINDOWS_EXPORT_ALL_SYMBOLS ON: 在 Windows 上自动导出所有符号。这对于创建 DLL（动态链接库）特别有用，因为它简化了符号导出的过程。 引用 file(RELATIVE_PATH _rel ${CMAKE_INSTALL_PREFIX}/${INSTALL_BINDIR} ${CMAKE_INSTALL_PREFIX}) if(APPLE) set(_rpath \"@loader_path/${_rel}\") else() set(_rpath \"\\$ORIGIN/${_rel}\") endif() 在这个 CMake 脚本命令中，file(RELATIVE_PATH ...) 用于计算两个路径之间的相对路径。 这个命令的目的是为了找出 ${CMAKE_INSTALL_PREFIX} 相对于 ${CMAKE_INSTALL_PREFIX}/${INSTALL_BINDIR} 的相对路径。换句话说，它在寻找从安装的二进制目录（INSTALL_BINDIR）到安装的根目录（CMAKE_INSTALL_PREFIX）的路径。在大多数情况下，这将简单地解析为从二进制目录向上到达根目录的相对路径（比如 ../ 或者更多级的 ../../，取决于 INSTALL_BINDIR 的深度）。 这种类型的计算在处理安装和打包时非常有用，尤其是当需要处理可移植性和不同系统结构时。通过这样的相对路径设置，可以确保不管你的软件安装在哪里，文件和资源的相互引用都是正确的。 这段 CMake 脚本代码使用 file(RELATIVE_PATH ...) 命令计算了一个相对路径，并根据操作系统类型（Apple 系统或其他）设置了一个名为 _rpath 的变量，用于指定动态库的运行时搜索路径（RPATH）。下面是详细解释： if(APPLE) 和 else(): 这两行代码检查当前是否在 Apple 系统（比如 macOS）上进行构建。如果是，在 Apple 系统上使用一种 RPATH 设置方法；如果不是（比如在 Linux 或 Windows 上），使用另一种方法。 set(_rpath \"@loader_path/${_rel}\"): 在 Apple 系统上，_rpath 被设置为 \"@loader_path/${_rel}\"。这里的 @loader_path 是一个特殊的标记，它表示加载动态库的可执行文件的位置。这种方法允许动态库在与可执行文件相对的路径中被找到。 set(_rpath \"\\$ORIGIN/${_rel}\"): 在非 Apple 系统上，_rpath 被设置为 \"\\$ORIGIN/${_rel}\"。这里的 $ORIGIN 是一个特殊的标记，它也表示加载动态库的可执行文件的位置。与 Apple 系统的方法类似，它使得动态库可以在相对于可执行文件的路径中被找到。 引用 set_target_properties(hello-world_wDSO PROPERTIES MACOSX_RPATH ON SKIP_BUILD_RPATH OFF BUILD_WITH_INSTALL_RPATH OFF INSTALL_RPATH \"${message_RPATH}\" INSTALL_RPATH_USE_LINK_PATH ON ) 使用 set_target_propert","date":"2024-02-01","objectID":"/posts/cmake_note_41/:3:0","tags":["CMake"],"title":"CMake 笔记 | [41] 安装项目","uri":"/posts/cmake_note_41/"},{"categories":["C++"],"content":"四、结果展示 mkdir build \u0026 cd build cmake .. cmake --build . --target install GNU/Linux构建目录的内容如下: ├── build ├── bin │ └── hello-world_wDSO ├── CMakeCache.txt ├── cmake_install.cmake ├── CTestTestfile.cmake ├── install_manifest.txt ├── lib │ ├── libmessage.so -\u003e libmessage.so.1 │ └── libmessage.so.1 ├── Makefile ├── src ├── test └── Testing 在安装位置，可以找到如下的目录结构: . ├── bin │ └── hello-world_wDSO ├── include │ └── message │ └── message.hpp └── lib ├── libmessage.so -\u003e libmessage.so.1 └── libmessage.so.1 ","date":"2024-02-01","objectID":"/posts/cmake_note_41/:4:0","tags":["CMake"],"title":"CMake 笔记 | [41] 安装项目","uri":"/posts/cmake_note_41/"},{"categories":["C++"],"content":"五、补充内容 安装到标准位置 对于项目的安装来说，什么是好的布局呢？如果只有自己使用该项目，那就无所谓好或坏的布局。然而，一旦向外部发布产品，和他人共用该项目，就应该在安装项目时提供一个合理的布局。 我们可以遵循一些标准，CMake可以帮助我们做到这一点。实际上，GNUInstallDirs.cmake模块所做的就是定义这样一组变量，这些变量是安装不同类型文件的子目录的名称。 CMAKE_INSTALL_BINDIR：用于定义用户可执行文件所在的子目录，即所选安装目录下的bin目录。 CMAKE_INSTALL_LIBDIR：将扩展到目标代码库(即静态库和动态库)所在的子目录。在64位系统上，它是lib64，而在32位系统上，它只是lib。 CMAKE_INSTALL_INCLUDEDIR：使用这个变量为头文件获取正确的子目录，该变量为include。 用户可能希望覆盖这些选项。允许在主CMakeLists.txt文件中使用以下方式覆盖选项: # Offer the user the choice of overriding the installation directories set(INSTALL_LIBDIR ${CMAKE_INSTALL_LIBDIR} CACHE PATH \"Installation directory for libraries\") set(INSTALL_BINDIR ${CMAKE_INSTALL_BINDIR} CACHE PATH \"Installation directory for executables\") set(INSTALL_INCLUDEDIR ${CMAKE_INSTALL_INCLUDEDIR} CACHE PATH \"Installation directory for header files\") 重新定义了在项目中使用的INSTALL_BINDIR、INSTALL_LIBDIR和INSTALL_INCLUDEDIR变量。 当只要求安装库： $ cmake -D COMPONENT=lib -P cmake_install.cmake 正确设置RPATH可能相当麻烦，但这对于用户来说无法避免。默认情况下，CMake设置可执行程序的RPATH，假设它们将从构建树运行。但是，安装之后RPATH被清除，当用户想要运行hello-world_wDSO时，就会出现问题。使用Linux上的ldd工具，我们可以检查构建树中的hello-world_wDSO可执行文件，运行ldd hello-world_wDSO将得到以下结果: libmessage.so.1 =\u003e /home/jiangli/repo/tutorials/cmake-tutorial/chapter9/01/build/lib/libmessage.so.1 (0x00007f43a4df7000) 在安装目录中运行ldd hello-world_wDSO将得到以下结果: libmessage.so.1 =\u003e Not found 这显然是不行的。但是，总是硬编码RPATH来指向构建树或安装目录也是错误的：这两个位置中的任何一个都可能被删除，从而导致可执行文件的损坏。给出的解决方案为构建树和安装目录中的可执行文件设置了不同的RPATH，因此它总是指向“有意义”的位置；也就是说，尽可能接近可执行文件。在构建树中运行ldd显示相同的输出: libmessage.so.1 =\u003e /home/jiangli/repo/tutorials/cmake-tutorial/chapter9/01/output/bin/./../lib/libmessage.so.1 (0x00007f0ebfc4a000) libmessage.so.1 =\u003e /home/jiangli/repo/tutorials/cmake-tutorial/chapter9/01/build/lib/libmessage.so.1 (0x00007f43a4df7000) 使用了带有目标参数的CMake安装命令，该命令还有另外4个参数: FILES和PROGRAMS，分别用于安装文件或程序。安装后，并设置安装文件适当的权限。对于文件，对所有者具有读和写权限，对组以及其他用户和组具有读权限。对于程序，将授予执行权限。注意，PROGRAMS要与非构建目标的可执行程序一起使用。 DIRECTORY，用于安装目录。当只给出一个目录名时，它通常被理解为相对于当前源目录。可以对目录的安装粒度进行控制。 SCRIPT，可以使用它在CMake脚本中定义自定义安装规则。 EXPORT，该参数用于导出目标。 ","date":"2024-02-01","objectID":"/posts/cmake_note_41/:5:0","tags":["CMake"],"title":"CMake 笔记 | [41] 安装项目","uri":"/posts/cmake_note_41/"},{"categories":["C++"],"content":"一、导言 导言 每个项目都需要处理依赖关系，使用**CMake很容易查询这些依赖关系，是否存在于配置项目中。前面的笔记中，展示了如何找到安装在系统上的依赖项，到目前为止我们一直使用这种模式。但是，当不满足依赖关系，我们只能使配置失败，并向用户警告失败的原因。然而，使用CMake可以组织我们的项目，如果在系统上找不到依赖项，就可以自动获取和构建依赖项。后续的几篇笔记将介绍和分析ExternalProject.cmake和FetchContent.cmake标准模块，及在超级构建模式中的使用。前者允许在构建时检索项目的依赖项，后者允许我们在配置时检索依赖项(CMake的3.11版本后添加)。使用超级构建模式，我们可以利用CMake作为包管理器：相同的项目中，将以相同的方式处理依赖项，无论依赖项在系统上是已经可用，还是需要重新构建。** 首先通过一个简单示例，介绍超级构建模式。我们将展示如何使用**ExternalProject_Add命令来构建一个的hello_world程序。** ","date":"2024-01-31","objectID":"/posts/cmake_note_40/:1:0","tags":["CMake"],"title":"CMake 笔记 | [40] 超级构建模式","uri":"/posts/cmake_note_40/"},{"categories":["C++"],"content":"二、项目结构 . ├── CMakeLists.txt └── src ├── CMakeLists.txt └── hello-world.cpp 项目结构： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter8/01 ","date":"2024-01-31","objectID":"/posts/cmake_note_40/:2:0","tags":["CMake"],"title":"CMake 笔记 | [40] 超级构建模式","uri":"/posts/cmake_note_40/"},{"categories":["C++"],"content":"三、相关源码 src/CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(example_core LANGUAGES CXX) add_executable(hello-world hello_world.cpp) src/hello_world.cpp #include \u003ccstdlib\u003e #include \u003ciostream\u003e #include \u003cstring\u003e std::string say_hello() { return std::string(\"Hello, CMake superbuild world!\"); } int main() { std::cout \u003c\u003c say_hello() \u003c\u003c std::endl; return EXIT_SUCCESS; } CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(example LANGUAGES CXX) set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_EXTENSIONS OFF) set(CMAKE_CXX_STANDARD_REQUIRED ON) set_property(DIRECTORY PROPERTY EP_BASE ${CMAKE_BINARY_DIR}/subprojects) include(ExternalProject) ExternalProject_Add(${PROJECT_NAME}_core SOURCE_DIR ${CMAKE_CURRENT_LIST_DIR}/src CMAKE_ARGS -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER} -DCMAKE_CXX_STANDARD=${CMAKE_CXX_STANDARD} -DCMAKE_CXX_EXTENSIONS=${CMAKE_CXX_EXTENSIONS} -DCMAKE_CXX_STANDARD_REQUIRED=${CMAKE_CXX_STANDARD_REQUIRED} CMAKE_CACHE_ARGS -DCMAKE_CXX_FLAGS:STRING=${CMAKE_CXX_FLAGS} BUILD_ALWAYS 1 INSTALL_COMMAND \"\" ) 引用 set_property(DIRECTORY PROPERTY EP_BASE ${CMAKE_BINARY_DIR}/subprojects) 为当前目录和底层目录设置EP_BASE目录属性。 引用 include(ExternalProject) 包括ExternalProject.cmake标准模块。该模块提供了ExternalProject_Add函数。 引用 ExternalProject_Add(${PROJECT_NAME}_core SOURCE_DIR ${CMAKE_CURRENT_LIST_DIR}/src CMAKE_ARGS -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER} -DCMAKE_CXX_STANDARD=${CMAKE_CXX_STANDARD} -DCMAKE_CXX_EXTENSIONS=${CMAKE_CXX_EXTENSIONS} -DCMAKE_CXX_STANDARD_REQUIRED=${CMAKE_CXX_STANDARD_REQUIRED} CMAKE_CACHE_ARGS -DCMAKE_CXX_FLAGS:STRING=${CMAKE_CXX_FLAGS} BUILD_ALWAYS 1 INSTALL_COMMAND \"\" ) Hello, World源代码通过调用ExternalProject_Add函数作为外部项目添加的。外部项目的名称为example_core。 ExternalProject_Add命令可用于添加第三方源。本篇通过将自己的项目，分为不同CMake项目的集合管理。本例中，主CMakeLists.txt和子CMakeLists.txt都声明了一个CMake项目，它们都使用了project命令。 ExternalProject_Add有许多选项，可用于外部项目的配置和编译等所有方面。这些选择可以分为以下几类: Directory:用于调优源码的结构，并为外部项目构建目录。本篇，我们使用SOURCE_DIR选项让CMake知道源文件在${CMAKE_CURRENT_LIST_DIR}/src文件夹中。用于构建项目和存储临时文件的目录，也可以在此类选项或目录属性中指定。通过设置EP_BASE目录属性，CMake将按照以下布局为各个子项目设置所有目录: TMP_DIR = \u003cEP_BASE\u003e/tmp/\u003cname\u003e STAMP_DIR = \u003cEP_BASE\u003e/Stamp/\u003cname\u003e DOWNLOAD_DIR = \u003cEP_BASE\u003e/Download/\u003cname\u003e SOURCE_DIR = \u003cEP_BASE\u003e/Source/\u003cname\u003e BINARY_DIR = \u003cEP_BASE\u003e/Build/\u003cname\u003e INSTALL_DIR = \u003cEP_BASE\u003e/Install/\u003cname\u003e Download：外部项目的代码可能需要从在线存储库或资源处下载。 Update和Patch：可用于定义如何更新外部项目的源代码或如何应用补丁。 Configure：默认情况下，CMake会假定外部项目是使用CMake配置的。如下所示，我们并不局限于这种情况。如果外部项目是CMake项目，ExternalProject_Add将调用CMake可执行文件，并传递选项。对于本篇示例，我们通过CMAKE_ARGS和CMAKE_CACHE_ARGS选项传递配置参数。前者作为命令行参数直接传递，而后者通过CMake脚本文件传递。实际，脚本文件位于build/subprojects/tmp/example_core/example_core- cache-.cmake。然后，配置如以下所示: loading initial cache file /home/jiangli/repo/tutorials/cmake-tutorial/chapter8/01/build/subprojects/tmp/example_core/example_core-cache-.cmake -- The CXX compiler identification is GNU 9.4.0 -- Check for working CXX compiler: /usr/bin/c++ -- Check for working CXX compiler: /usr/bin/c++ -- works -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Detecting CXX compile features -- Detecting CXX compile features - done -- Configuring done -- Generating done -- Build files have been written to: /home/jiangli/repo/tutorials/cmake-tutorial/chapter8/01/build/subprojects/Build/example_core Build：可用于调整外部项目的实际编译。我们使用BUILD_ALWAYS选项确保外部项目总会重新构建。 Install：这些选项用于配置应该如何安装外部项目。我们将INSTALL_COMMAND保留为空。 Test：为基于源代码构建的软件运行测试。ExternalProject_Add的这类选项可以用于此目的。我们的没有使用这些选项，因为Hello, World示例没有任何测试。 ","date":"2024-01-31","objectID":"/posts/cmake_note_40/:3:0","tags":["CMake"],"title":"CMake 笔记 | [40] 超级构建模式","uri":"/posts/cmake_note_40/"},{"categories":["C++"],"content":"四、结果展示 $ mkdir -p build $ cmake .. $ cmake --build . 构建目录的结构稍微复杂一些，subprojects文件夹的内容如下: build/subprojects/ ├── Build │ └── example_core │ ├── CMakeCache.txt │ ├── CMakeFiles │ ├── cmake_install.cmake │ ├── hello-world │ └── Makefile ├── Download │ └── example_core ├── Install │ └── example_core ├── Stamp │ └── exampleq_core │ ├── example_core-configure │ ├── example_core-done │ ├── example_core-download │ ├── example_core-install │ ├── example_core-mkdir │ ├── example_core-patch │ └── example_core-update └── tmp └── example_core ├── example_core-cache-.cmake ├── example_core-cfgcmd.txt └── example_core-cfgcmd.txt.in 补充内容 ExternalProject.cmake定义了ExternalProject_Get_Property命令，该命令对于检索外部项目的属性非常有用。外部项目的属性是在首次调用ExternalProject_Add命令时设置的。例如，在配置example_core时，检索要传递给CMake的参数可以通过以下方法实现: ExternalProject_Get_Property(${PROJECT_NAME}_core CMAKE_ARGS) message(STATUS \"CMAKE_ARGS of ${PROJECT_NAME}_core ${CMAKE_ARGS}\") ExternalProject.cmake模块定义了以下附加命令: ExternalProject_Add_Step: 当添加了外部项目，此命令允许将附加的命令作为自定义步骤锁定在其上。 ExternalProject_Add_StepTargets:允许将外部项目中的步骤(例如：构建和测试步骤)定义为单独的目标。这意味着可以从完整的外部项目中单独触发这些步骤，并允许对项目中的复杂依赖项，进行细粒度控制。 ExternalProject_Add_StepDependencies:外部项目的步骤有时可能依赖于外部目标，而这个命令的设计目的就是处理这些情况。 ","date":"2024-01-31","objectID":"/posts/cmake_note_40/:4:0","tags":["CMake"],"title":"CMake 笔记 | [40] 超级构建模式","uri":"/posts/cmake_note_40/"},{"categories":["C++"],"content":"一、导言 导言 本篇，我们将讨论上一篇的另一种方法，并不使用add_subdirectory的情况下，使用module include组装不同的CMakeLists.txt文件。其允许我们使用target_link_libraries链接到当前目录之外定义的目标。 就项目架构而言，不推荐本篇的构建方式。 ","date":"2024-01-31","objectID":"/posts/cmake_note_39/:1:0","tags":["CMake"],"title":"CMake 笔记 | [39] 构建项目策略及限制变量范围2","uri":"/posts/cmake_note_39/"},{"categories":["C++"],"content":"二、项目结构 . ├── CMakeLists.txt ├── external │ ├── CMakeLists.txt │ ├── conversion.cpp │ └── conversion.hpp ├── src │ ├── CMakeLists.txt │ ├── evolution │ │ ├── CMakeLists.txt │ │ ├── evolution.cpp │ │ └── evolution.hpp │ ├── initial │ │ ├── CMakeLists.txt │ │ ├── initial.cpp │ │ └── initial.hpp │ ├── io │ │ ├── CMakeLists.txt │ │ ├── io.cpp │ │ └── io.hpp │ ├── main.cpp │ └── parser │ ├── CMakeLists.txt │ ├── parser.cpp │ └── parser.hpp └── tests ├── catch.hpp ├── CMakeLists.txt └── test.cpp 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter7/08 ","date":"2024-01-31","objectID":"/posts/cmake_note_39/:2:0","tags":["CMake"],"title":"CMake 笔记 | [39] 构建项目策略及限制变量范围2","uri":"/posts/cmake_note_39/"},{"categories":["C++"],"content":"三、相关源码 将使用与上一篇相同的源代码。唯一的更改将出现在CMakeLists.txt文件中，我们将在下面的部分中讨论这些更改。 CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(example LANGUAGES CXX) set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_EXTENSIONS OFF) set(CMAKE_CXX_STANDARD_REQUIRED ON) include(GNUInstallDirs) set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_LIBDIR}) set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_LIBDIR}) set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_BINDIR}) # defines targets and sources include(src/CMakeLists.txt) include(external/CMakeLists.txt) enable_testing() add_subdirectory(tests) src/CMakeLists.txt add_library(automaton \"\") add_library(evolution \"\") include(${CMAKE_CURRENT_LIST_DIR}/evolution/CMakeLists.txt) include(${CMAKE_CURRENT_LIST_DIR}/initial/CMakeLists.txt) include(${CMAKE_CURRENT_LIST_DIR}/io/CMakeLists.txt) include(${CMAKE_CURRENT_LIST_DIR}/parser/CMakeLists.txt) add_executable(automata \"\") target_sources(automata PRIVATE ${CMAKE_CURRENT_LIST_DIR}/main.cpp ) target_link_libraries(automata PRIVATE automaton conversion ) src/evolution/CMakeLists.txt target_sources(automaton PRIVATE ${CMAKE_CURRENT_LIST_DIR}/evolution.cpp PUBLIC ${CMAKE_CURRENT_LIST_DIR}/evolution.hpp ) target_include_directories(automaton PUBLIC ${CMAKE_CURRENT_LIST_DIR} ) target_sources(evolution PRIVATE ${CMAKE_CURRENT_LIST_DIR}/evolution.cpp PUBLIC ${CMAKE_CURRENT_LIST_DIR}/evolution.hpp ) target_include_directories(evolution PUBLIC ${CMAKE_CURRENT_LIST_DIR} ) 其余CMakeLists.txt文件和src/initial/CMakeLists.txt相同。 src/initial/CMakeLists.txt target_sources(automaton PRIVATE ${CMAKE_CURRENT_LIST_DIR}/initial.cpp PUBLIC ${CMAKE_CURRENT_LIST_DIR}/initial.hpp ) target_include_directories(automaton PUBLIC ${CMAKE_CURRENT_LIST_DIR} ) 定义了三个库: conversion(在external定义) automaton(包含除转换之外的所有源) evolution(在src/evolution中定义，并通过cpp_test链接) 我们通过使用include()引用CMakeLists.txt文件，在父范围内，仍然能保持所有目标可用。 include(src/CMakeLists.txt) include(external/CMakeLists.txt) 构建一个包含树，记住当进入子目录(src/CMakeLists.txt)时，我们需要使用相对于父范围的路径: include(${CMAKE_CURRENT_LIST_DIR}/evolution/CMakeLists.txt) include(${CMAKE_CURRENT_LIST_DIR}/initial/CMakeLists.txt) include(${CMAKE_CURRENT_LIST_DIR}/io/CMakeLists.txt) include(${CMAKE_CURRENT_LIST_DIR}/parser/CMakeLists.txt) 这样，我们就可以定义并链接到通过include()语句访问文件树中任何位置的目标。 ","date":"2024-01-31","objectID":"/posts/cmake_note_39/:3:0","tags":["CMake"],"title":"CMake 笔记 | [39] 构建项目策略及限制变量范围2","uri":"/posts/cmake_note_39/"},{"categories":["C++"],"content":"四、结果展示 $ cd build $ cmake .. $ cmake --build build $ ctest Running tests... Start 1: test_evolution 1/1 Test #1: test_evolution ................... Passed 0.00 sec 100% tests passed, 0 tests failed out of 1 补充内容 我们可以再次使用CMake和Graphviz生成这个项目的依赖关系图: $ cd build $ cmake --graphviz=example.dot .. $ dot -T png example.dot -o example.png 项目结构 ","date":"2024-01-31","objectID":"/posts/cmake_note_39/:4:0","tags":["CMake"],"title":"CMake 笔记 | [39] 构建项目策略及限制变量范围2","uri":"/posts/cmake_note_39/"},{"categories":["C++"],"content":"一、导言 导言 我们将讨论构建项目的策略，并限制变量的范围和副作用，目的是降低代码的复杂性和简化项目的维护。本篇，我们将把一个项目分割成几个范围有限的CMakeLists.txt文件，这些文件将使用add_subdirectory命令进行处理。 将源文件分割成更小、更易于管理的单元是有意义的。可以将所有源代码都编译成一个库或可执行文件。实际上，项目更喜欢将源代码编译分成更小的、定义良好的库。这样做既是为了本地化和简化依赖项，也是为了简化代码维护。这意味着如在这里所做的那样，由许多库构建一个项目是一种常见的情况。 ","date":"2024-01-31","objectID":"/posts/cmake_note_38/:1:0","tags":["CMake"],"title":"CMake 笔记 | [38] 构建项目的策略及限制变量的范围和副作用","uri":"/posts/cmake_note_38/"},{"categories":["C++"],"content":"二、项目结构 . ├── CMakeLists.txt ├── external │ ├── CMakeLists.txt │ ├── conversion.cpp │ └── conversion.hpp ├── src │ ├── CMakeLists.txt │ ├── evolution │ │ ├── CMakeLists.txt │ │ ├── evolution.cpp │ │ └── evolution.hpp │ ├── initial │ │ ├── CMakeLists.txt │ │ ├── initial.cpp │ │ └── initial.hpp │ ├── io │ │ ├── CMakeLists.txt │ │ ├── io.cpp │ │ └── io.hpp │ ├── main.cpp │ └── parser │ ├── CMakeLists.txt │ ├── parser.cpp │ └── parser.hpp └── tests ├── catch.hpp ├── CMakeLists.txt └── test.cpp 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter7/07 ","date":"2024-01-31","objectID":"/posts/cmake_note_38/:2:0","tags":["CMake"],"title":"CMake 笔记 | [38] 构建项目的策略及限制变量的范围和副作用","uri":"/posts/cmake_note_38/"},{"categories":["C++"],"content":"三、相关源码 本篇的代码以及项目结构比较简单，并未涉及到新的内容，所以以下代码都没有具体讲解，相关代码的知识点都在前面笔记中。 CMakeLists.txt cmake_minimum_required(VERSION 3.5 FATAL_ERROR) project(recipe-07 LANGUAGES CXX) set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_EXTENSIONS OFF) set(CMAKE_CXX_STANDARD_REQUIRED ON) include(GNUInstallDirs) set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_LIBDIR}) set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_LIBDIR}) set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_BINDIR}) # defines targets and sources add_subdirectory(src) # contains an \"external\" library we will link to add_subdirectory(external) # enable testing and define tests enable_testing() add_subdirectory(tests) external/conversion.hpp #pragma once #include \u003cstring\u003e std::string BinaryRepresentation(const int decimal); external/conversion.cpp #include \"conversion.hpp\" #include \u003cbitset\u003e std::string BinaryRepresentation(const int decimal) { return std::bitset\u003c8\u003e(decimal).to_string(); } external/CMakeLists.txt add_library(conversion \"\") target_sources(conversion PRIVATE ${CMAKE_CURRENT_LIST_DIR}/conversion.cpp PUBLIC ${CMAKE_CURRENT_LIST_DIR}/conversion.hpp ) target_include_directories(conversion PUBLIC ${CMAKE_CURRENT_LIST_DIR} ) src/CMakeLists.txt add_executable(automata main.cpp) add_subdirectory(evolution) add_subdirectory(initial) add_subdirectory(io) add_subdirectory(parser) target_link_libraries(automata PRIVATE conversion evolution initial io parser ) src/evolution/evolution.hpp #pragma once #include \u003cstring\u003e #include \u003cvector\u003e std::vector\u003cint\u003e Evolve(const std::vector\u003cint\u003e row, const std::string rule_binary); src/evolution/evolution.cpp #include \"evolution.hpp\" #include \u003cvector\u003e std::vector\u003cint\u003e Evolve(const std::vector\u003cint\u003e row, const std::string rule_binary) { std::vector\u003cint\u003e result; for (auto i = 0; i \u003c row.size(); ++i) { auto left = (i == 0 ? row.size() : i) - 1; auto center = i; auto right = (i + 1) % row.size(); auto ancestors = 4 * row[left] + 2 * row[center] + 1 * row[right]; ancestors = 7 - ancestors; auto new_state = std::stoi(rule_binary.substr(ancestors, 1)); result.push_back(new_state); } return result; } src/evolution/CMakeLists.txt add_library(evolution \"\") target_sources(evolution PRIVATE evolution.cpp PUBLIC ${CMAKE_CURRENT_LIST_DIR}/evolution.hpp ) target_include_directories(evolution PUBLIC ${CMAKE_CURRENT_LIST_DIR} ) src/initial/initial.hpp #pragma once #include \u003cvector\u003e std::vector\u003cint\u003e InitialDistribution(const int length); src/initial/initial.cpp #include \"initial.hpp\" #include \u003cvector\u003e std::vector\u003cint\u003e InitialDistribution(const int length) { // we start with a vector which is zeroed out std::vector\u003cint\u003e result(length, 0); // more or less in the middle we place a living cell result[length / 2] = 1; return result; } src/initial/CMakeLists.txt add_library(initial \"\") target_sources(initial PRIVATE initial.cpp PUBLIC ${CMAKE_CURRENT_LIST_DIR}/initial.hpp ) target_include_directories(initial PUBLIC ${CMAKE_CURRENT_LIST_DIR} ) src/io/io.hpp #pragma once #include \u003cvector\u003e void PrintRow(const std::vector\u003cint\u003e row); src/io/io.cpp #include \"io.hpp\" #include \u003calgorithm\u003e #include \u003ciostream\u003e #include \u003cvector\u003e void PrintRow(const std::vector\u003cint\u003e row) { std::for_each(row.begin(), row.end(), [](int const \u0026value) { std::cout \u003c\u003c (value == 1 ? '*' : ' '); }); std::cout \u003c\u003c std::endl; } src/io/CMakeLists.txt add_library(io \"\") target_sources(io PRIVATE io.cpp PUBLIC ${CMAKE_CURRENT_LIST_DIR}/io.hpp ) target_include_directories(io PUBLIC ${CMAKE_CURRENT_LIST_DIR} ) src/parser/parser.hpp #pragma once #include \u003ctuple\u003e std::tuple\u003cint, int, int\u003e ParseArguments(int argc, char *argv[]); src/parser/parser.cpp #include \"parser.hpp\" #include \u003ccassert\u003e #include \u003cstring\u003e #include \u003ctuple\u003e std::tuple\u003cint, int, int\u003e ParseArguments(int argc, char *argv[]) { assert(argc == 4 \u0026\u0026 \"program called with wrong number of arguments\"); auto length = std::stoi(argv[1]); auto num_steps = std::stoi(argv[2]); auto rule_decimal = std::stoi(argv[3]); ","date":"2024-01-31","objectID":"/posts/cmake_note_38/:3:0","tags":["CMake"],"title":"CMake 笔记 | [38] 构建项目的策略及限制变量的范围和副作用","uri":"/posts/cmake_note_38/"},{"categories":["C++"],"content":"四、结果展示 $ mkdir -p build $ cd build $ cmake .. $ cmake --build . Scanning dependencies of target conversion [ 7%] Building CXX object external/CMakeFiles/conversion.dir/conversion.cpp.o [ 14%] Linking CXX static library ../lib64/libconversion.a [ 14%] Built target conversion Scanning dependencies of target evolution [ 21%] Building CXX object src/evolution/CMakeFiles/evolution.dir/evolution.cpp.o [ 28%] Linking CXX static library ../../lib64/libevolution.a [ 28%] Built target evolution Scanning dependencies of target initial [ 35%] Building CXX object src/initial/CMakeFiles/initial.dir/initial.cpp.o [ 42%] Linking CXX static library ../../lib64/libinitial.a [ 42%] Built target initial Scanning dependencies of target io [ 50%] Building CXX object src/io/CMakeFiles/io.dir/io.cpp.o [ 57%] Linking CXX static library ../../lib64/libio.a [ 57%] Built target io Scanning dependencies of target parser [ 64%] Building CXX object src/parser/CMakeFiles/parser.dir/parser.cpp.o [ 71%] Linking CXX static library ../../lib64/libparser.a [ 71%] Built target parser Scanning dependencies of target automata [ 78%] Building CXX object src/CMakeFiles/automata.dir/main.cpp.o [ 85%] Linking CXX executable ../bin/automata [ 85%] Built target automata Scanning dependencies of target cpp_test [ 92%] Building CXX object tests/CMakeFiles/cpp_test.dir/test.cpp.o [100%] Linking CXX executable ../bin/cpp_test [100%] Built target cpp_test $ ctest Running tests... Start 1: test_evolution 1/1 Test #1: test_evolution ................... Passed 0.00 sec 100% tests passed, 0 tests failed out of 1 补充内容 CMake可以使用Graphviz图形可视化软件生成项目的依赖关系图: $ cd build $ cmake --graphviz=example.dot .. $ dot -T png example.dot -o example.png cmake 项目关系依赖图 ","date":"2024-01-31","objectID":"/posts/cmake_note_38/:4:0","tags":["CMake"],"title":"CMake 笔记 | [38] 构建项目的策略及限制变量的范围和副作用","uri":"/posts/cmake_note_38/"},{"categories":["C++"],"content":"一、导言 导言 废弃是在不断发展的项目开发过程中一种重要机制，它向开发人员发出信号，表明将来某个函数、宏或变量将被删除或替换。在一段时间内，函数、宏或变量将继续可访问，但会发出警告，最终可能会上升为错误。 ","date":"2024-01-31","objectID":"/posts/cmake_note_37/:1:0","tags":["CMake"],"title":"CMake 笔记 | [37] 使用废弃函数、宏和变量","uri":"/posts/cmake_note_37/"},{"categories":["C++"],"content":"二、项目结构 . ├── cmake │ └── custom_guard.cmake └── CMakeLists.txt 项目结构： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter7/06 ","date":"2024-01-31","objectID":"/posts/cmake_note_37/:2:0","tags":["CMake"],"title":"CMake 笔记 | [37] 使用废弃函数、宏和变量","uri":"/posts/cmake_note_37/"},{"categories":["C++"],"content":"三、相关源码 CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(example LANGUAGES NONE) macro(custom_include_guard) if(NOT DEFINED included_modules) set(included_modules) endif() if (\"${CMAKE_CURRENT_LIST_FILE}\" IN_LIST included_modules) message(WARNING \"module ${CMAKE_CURRENT_LIST_FILE} processed more than once\") endif() list(APPEND included_modules ${CMAKE_CURRENT_LIST_FILE}) endmacro() function(deprecate_variable _variable _access) if(_access STREQUAL \"READ_ACCESS\") message(DEPRECATION \"variable ${_variable} is deprecated\") endif() endfunction() if (CMAKE_VERSION VERSION_GREATER \"3.9\") # deprecate custom_include_guard macro(custom_include_guard) message(DEPRECATION \"custom_include_guard is deprecated - use built-in include_guard instead\") _custom_include_guard(${ARGV}) endmacro() # deprecate variable included_modules variable_watch(included_modules deprecate_variable) endif() include(cmake/custom_guard.cmake) message(STATUS \"list of all included modules: ${included_modules}\") 引用 macro(custom_include_guard) if(NOT DEFINED included_modules) set(included_modules) endif() if (\"${CMAKE_CURRENT_LIST_FILE}\" IN_LIST included_modules) message(WARNING \"module ${CMAKE_CURRENT_LIST_FILE} processed more than once\") endif() list(APPEND included_modules ${CMAKE_CURRENT_LIST_FILE}) endmacro() 定义了一个自定义的包含保护机制，包括一个自定义模块(与上一篇内容相同)，并打印所有包含模块的列表。对于CMake 3.10或更高版本有内置的include_guard。但是，不能简单地删除custom_include_guard和${included_modules}，而是使用一个废弃警告来弃用宏和变量。某个时候，可以将该警告转换为FATAL_ERROR，使代码停止配置，并迫使开发人员对代码进行修改，切换到内置命令。 引用 废弃函数、宏和变量的方法如下: 1.定义一个函数，使用它来弃用一个变量 function(deprecate_variable _variable _access) if(_access STREQUAL \"READ_ACCESS\") message(DEPRECATION \"variable ${_variable} is deprecated\") endif() endfunction() 2.如果CMake的版本大于3.9，我们重新定义custom_include_guard并将variable_watch附加到included_modules中: if (CMAKE_VERSION VERSION_GREATER \"3.9\") # deprecate custom_include_guard macro(custom_include_guard) message(DEPRECATION \"custom_include_guard is deprecated - use built-in include_guard instead\") _custom_include_guard(${ARGV}) endmacro() # deprecate variable included_modules variable_watch(included_modules deprecate_variable) endif() cmake/custom_guard.cmake custom_include_guard() message(STATUS \"custom.cmake is included and processed\") ","date":"2024-01-31","objectID":"/posts/cmake_note_37/:3:0","tags":["CMake"],"title":"CMake 笔记 | [37] 使用废弃函数、宏和变量","uri":"/posts/cmake_note_37/"},{"categories":["C++"],"content":"四、结果展示 $ mkdir -p build $ cd build $ cmake .. CMake3.10以下版本的项目会产生以下结果: -- custom_custom.cmake is included and processed -- list of all included modules: /home/jiangli/repo/tutorials/cmake-tutorial/chapter7/06/cmake/custom.cmake CMake3.10以下版本的项目会产生以下结果: CMake Deprecation Warning at CMakeLists.txt:26 (message): custom_include_guard is deprecated - use built-in include_guard instead Call Stack (most recent call first): cmake/custom_guard.cmake:1 (custom_include_guard) CMakeLists.txt:34 (include) -- custom_custom.cmake is included and processed CMake Deprecation Warning at CMakeLists.txt:19 (message): variable included_modules is deprecated Call Stack (most recent call first): CMakeLists.txt:9999 (deprecate_variable) CMakeLists.txt:36 (message) -- list of all included modules: /home/jiangli/repo/tutorials/cmake-tutorial/chapter7/06/cmake/custom_guard.cmake -- Configuring done -- Generating done -- Build files have been written to: /home/jiangli/repo/tutorials/cmake-tutorial/chapter7/06/build ","date":"2024-01-31","objectID":"/posts/cmake_note_37/:4:0","tags":["CMake"],"title":"CMake 笔记 | [37] 使用废弃函数、宏和变量","uri":"/posts/cmake_note_37/"},{"categories":["C++"],"content":"一、导言 导言 前面的笔记中，我们研究了函数和宏，并使用了位置参数。本篇，我们将定义一个带有命名参数的函数。我们将复用第1节中的代码，使用函数和宏重用代码。 ","date":"2024-01-31","objectID":"/posts/cmake_note_36/:1:0","tags":["CMake"],"title":"CMake 笔记 | [36] 用指定参数定义函数或宏","uri":"/posts/cmake_note_36/"},{"categories":["C++"],"content":"二、项目结构 . ├── cmake │ └── testing.cmake ├── CMakeLists.txt ├── src │ ├── CMakeLists.txt │ ├── main.cpp │ ├── sum_integers.cpp │ └── sum_integers.hpp └── tests ├── catch.hpp ├── CMakeLists.txt └── test.cpp https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter7/04 ","date":"2024-01-31","objectID":"/posts/cmake_note_36/:2:0","tags":["CMake"],"title":"CMake 笔记 | [36] 用指定参数定义函数或宏","uri":"/posts/cmake_note_36/"},{"categories":["C++"],"content":"三、相关源码 cmake/testing.cmake function(add_catch_test) set(options) set(oneValueArgs NAME COST) set(multiValueArgs LABELS DEPENDS REFERENCE_FILES) cmake_parse_arguments(add_catch_test \"${options}\" \"${oneValueArgs}\" \"${multiValueArgs}\" ${ARGN} ) message(STATUS \"defining a test ...\") message(STATUS \" NAME: ${add_catch_test_NAME}\") message(STATUS \" LABELS: ${add_catch_test_LABELS}\") message(STATUS \" COST: ${add_catch_test_COST}\") message(STATUS \" REFERENCE_FILES: ${add_catch_test_REFERENCE_FILES}\") add_test( NAME ${add_catch_test_NAME} COMMAND $\u003cTARGET_FILE:cpp_test\u003e [${add_catch_test_NAME}] --success --out ${PROJECT_BINARY_DIR}/tests/${add_catch_test_NAME}.log --durations yes WORKING_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR} ) set_tests_properties(${add_catch_test_NAME} PROPERTIES LABELS \"${add_catch_test_LABELS}\" ) if(add_catch_test_COST) set_tests_properties(${add_catch_test_NAME} PROPERTIES COST ${add_catch_test_COST} ) endif() if(add_catch_test_DEPENDS) set_tests_properties(${add_catch_test_NAME} PROPERTIES DEPENDS ${add_catch_test_DEPENDS} ) endif() if(add_catch_test_REFERENCE_FILES) file( COPY ${add_catch_test_REFERENCE_FILES} DESTINATION ${CMAKE_CURRENT_BINARY_DIR} ) endif() endfunction() 引用 function(add_catch_test) set(options) set(oneValueArgs NAME COST) set(multiValueArgs LABELS DEPENDS REFERENCE_FILES) cmake_parse_arguments(add_catch_test \"${options}\" \"${oneValueArgs}\" \"${multiValueArgs}\" ${ARGN} ) ... endfunction() CMake提供cmake_parse_arguments命令，我们使用函数名(add_catch_test)选项(我们的例子中是none)、单值参数(NAME和COST)和多值参数(LABELS、DEPENDS和REFERENCE_FILES)调用该命令。 options、oneValueArgs 和 multiValueArgs 定义了函数可以接受的不同参数类型。options是布尔标志，oneValueArgs 接受一个值，而 multiValueArgs 可以接受多个值。 cmake_parse_arguments命令解析选项和参数，并定义如下: add_catch_test_NAME add_catch_test_COST add_catch_test_LABELS add_catch_test_DEPENDS add_catch_test_REFERENCE_FILES 这种方法使我们有机会用更健壮的接口和更具有可读的函数/宏调用，来实现函数和宏。 引用 add_test( NAME ${add_catch_test_NAME} COMMAND $\u003cTARGET_FILE:cpp_test\u003e [${add_catch_test_NAME}] --success --out ${PROJECT_BINARY_DIR}/tests/${add_catch_test_NAME}.log --durations yes WORKING_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR} ) NAME 和 COMMAND 参数分别指定测试名称和运行测试的命令。 测试被配置为将结果输出到项目二进制目录下的日志文件中。 引用 set_tests_properties 用于为测试分配属性。这些属性包括: LABELS （标签），用于对测试进行分类。 COST(成本)，用于指定测试的相对资源使用量。 DEPENDS 指定必须在该测试之前运行的其他测试。 if(add_catch_test_DEPENDS) set_tests_properties(${add_catch_test_NAME} PROPERTIES DEPENDS ${add_catch_test_DEPENDS} ) endif() 如果指定了任何参考文件，则使用 file(COPY ... DESTINATION ...) 命令将这些文件复制到当前二进制目录。这对需要将其输出与已知良好输出进行比较的测试非常有用。 tests/CMakeLists.txt add_executable(cpp_test test.cpp) target_link_libraries(cpp_test sum_integers) include(testing) add_catch_test( NAME short LABELS short cpp_test COST 1.5 ) add_catch_test( NAME long LABELS long cpp_test COST 2.5 ) CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(example LANGUAGES CXX) set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_EXTENSIONS OFF) set(CMAKE_CXX_STANDARD_REQUIRED ON) list(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/cmake\") include(GNUInstallDirs) set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_LIBDIR}) set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_LIBDIR}) set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_BINDIR}) add_subdirectory(src) enable_testing() add_subdirectory(tests) ","date":"2024-01-31","objectID":"/posts/cmake_note_36/:3:0","tags":["CMake"],"title":"CMake 笔记 | [36] 用指定参数定义函数或宏","uri":"/posts/cmake_note_36/"},{"categories":["C++"],"content":"四、结果展示 $ mkdir -p build $ cd build $ cmake .. -- ... -- defining a test ... -- NAME: short -- LABELS: short;cpp_test -- COST: 1.5 -- REFERENCE_FILES: -- defining a test ... -- NAME: long -- LABELS: long;cpp_test -- COST: 2.5 -- REFERENCE_FILES: -- ... cmake --build . ctest 输出结果 ","date":"2024-01-31","objectID":"/posts/cmake_note_36/:4:0","tags":["CMake"],"title":"CMake 笔记 | [36] 用指定参数定义函数或宏","uri":"/posts/cmake_note_36/"},{"categories":["C++"],"content":"一、导言 引用 模块包含不应该用作函数调用，因为模块可能被包含多次。本篇，我们将编写我们自己的包含保护机制，如果多次包含一个模块，将触发警告。内置的include_guard命令从3.10版开始可以使用，对于C/C++头文件，它的行为就像#pragma一样。对于当前版本的CMake，我们将演示如何重新定义函数和宏，并且展示如何检查CMake版本，对于低于3.10的版本，我们将使用定制的包含保护机制。 ","date":"2024-01-31","objectID":"/posts/cmake_note_35/:1:0","tags":["CMake"],"title":"CMake 笔记 | [35] 重新定义函数和宏","uri":"/posts/cmake_note_35/"},{"categories":["C++"],"content":"二、项目结构 . ├── cmake │ ├── custom.cmake │ └── include_guard.cmake └── CMakeLists.txt 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter7/05 相关源码 cmake/include_guard.cmake macro(include_guard) if (CMAKE_VERSION VERSION_LESS \"3.10\") # for CMake below 3.10 we define our # own include_guard(GLOBAL) message(STATUS \"calling our custom include_guard\") # if this macro is called the first time # we start with an empty list if(NOT DEFINED included_modules) set(included_modules) endif() if (\"${CMAKE_CURRENT_LIST_FILE}\" IN_LIST included_modules) message(WARNING \"module ${CMAKE_CURRENT_LIST_FILE} processed more than once\") endif() list(APPEND included_modules ${CMAKE_CURRENT_LIST_FILE}) else() # for CMake 3.10 or higher we augment # the built-in include_guard message(STATUS \"calling the built-in include_guard\") _include_guard(${ARGV}) endif() endmacro() 引用 macro(include_guard) if (CMAKE_VERSION VERSION_LESS \"3.10\") # ... else() # ... endif() endmacro() include_guard宏包含两个分支，一个用于CMake低于3.10，另一个用于CMake高于3.10。 引用 message(STATUS \"calling our custom include_guard\") # if this macro is called the first time # we start with an empty list if(NOT DEFINED included_modules) set(included_modules) endif() if (\"${CMAKE_CURRENT_LIST_FILE}\" IN_LIST included_modules) message(WARNING \"module ${CMAKE_CURRENT_LIST_FILE} processed more than once\") endif() list(APPEND included_modules ${CMAKE_CURRENT_LIST_FILE}) 如果CMake版本低于3.10，进入第一个分支，并且内置的include_guard不可用，所以我们自定义了一个。 如果第一次调用宏，则included_modules变量没有定义，因此我们将其设置为空列表。然后检查${CMAKE_CURRENT_LIST_FILE}是否是included_modules列表中的元素。如果是，则会发出警告；如果没有，我们将${CMAKE_CURRENT_LIST_FILE}追加到这个列表。CMake输出中，我们可以验证自定义模块的第二个包含确实会导致警告。 引用 macro(include_guard) if (CMAKE_VERSION VERSION_LESS \"3.10\") # ... else() message(STATUS \"calling the built-in include_guard\") _include_guard(${ARGV}) endif() endmacro() CMake 3.10及更高版本的情况有所不同；在这种情况下，存在一个内置的include_guard，我们用自己的宏接收到参数并调用它。 这里，_include_guard(${ARGV})指向内置的include_guard。这里，我们使用自定义消息(调用内置的include_guard)进行了扩展。这种模式为我们提供了一种机制，来重新定义自己的或内置的函数和宏，这对于调试或记录日志来说非常有用。 cmake/custom.cmake include_guard(GLOBAL) message(STATUS \"custom.cmake is included and processed\") CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(example LANGUAGES NONE) # (re)defines include_guard include(cmake/include_guard.cmake) # this is some custom module include(cmake/custom.cmake) # we simulate that we accidentally include the module a second time include(cmake/custom.cmake) ","date":"2024-01-31","objectID":"/posts/cmake_note_35/:2:0","tags":["CMake"],"title":"CMake 笔记 | [35] 重新定义函数和宏","uri":"/posts/cmake_note_35/"},{"categories":["C++"],"content":"三、结果展示 $ mkdir -p build $ cd build $ cmake .. CMake 3.10及更高版本的结果如下: -- calling the built-in include_guard -- custom.cmake is included and processed -- calling the built-in include_guard CMake 3.10以下的结果如下: - calling our custom include_guard -- custom.cmake is included and processed -- calling our custom include_guard CMake Warning at cmake/include_guard.cmake:7 (message): module /home/user/example/cmake/custom.cmake processed more than once Call Stack (most recent call first): cmake/custom.cmake:1 (include_guard) CMakeLists.txt:12 (include) ","date":"2024-01-31","objectID":"/posts/cmake_note_35/:3:0","tags":["CMake"],"title":"CMake 笔记 | [35] 重新定义函数和宏","uri":"/posts/cmake_note_35/"},{"categories":["C++"],"content":"一、导言 导言 前两篇，我们使用了宏。本篇，将使用一个函数来抽象细节并避免代码重复。我们将实现一个接受编译器标志列表的函数。该函数将尝试用这些标志逐个编译测试代码，并返回编译器理解的第一个标志。这样，我们将了解几个新特性：****函数、列表操作、字符串操作，以及检查编译器是否支持相应的标志。 ","date":"2024-01-31","objectID":"/posts/cmake_note_34/:1:0","tags":["CMake"],"title":"CMake 笔记 | [34] 编写函数来测试和设置编译器标志","uri":"/posts/cmake_note_34/"},{"categories":["C++"],"content":"二、项目结构 . ├── cmake │ └── set_compiler_flag.cmake └── CMakeLists.txt https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter7/03 相关源码 cmake/set_compiler_flag.cmake include(CheckCCompilerFlag) include(CheckCXXCompilerFlag) include(CheckFortranCompilerFlag) function(set_compiler_flag _result _lang) set(_list_of_flags) set(_flag_is_required FALSE) foreach(_arg IN ITEMS ${ARGN}) string(TOUPPER \"${_arg}\" _arg_uppercase) if(_arg_uppercase STREQUAL \"REQUIRED\") set(_flag_is_required TRUE) else() list(APPEND _list_of_flags \"${_arg}\") endif() endforeach() set(_flag_found FALSE) foreach(flag IN ITEMS ${_list_of_flags}) unset(_flag_works CACHE) if(_lang STREQUAL \"C\") check_c_compiler_flag(\"${flag}\" _flag_works) elseif(_lang STREQUAL \"CXX\") check_cxx_compiler_flag(\"${flag}\" _flag_works) elseif(_lang STREQUAL \"Fortran\") check_Fortran_compiler_flag(\"${flag}\" _flag_works) else() message(FATAL_ERROR \"Unknown language in set_compiler_flag: ${_lang}\") endif() if(_flag_works) set(${_result} \"${flag}\" PARENT_SCOPE) set(_flag_found TRUE) break() endif() endforeach() if(_flag_is_required AND NOT _flag_found) message(FATAL_ERROR \"None of the required flags were supported\") endif() endfunction() tips include(CheckCCompilerFlag) include(CheckCXXCompilerFlag) include(CheckFortranCompilerFlag) 这都是标准的CMake模块，CMake将在${CMAKE_MODULE_PATH}中找到它们。这些模块分别提供check_c_compiler_flag、check_cxx_compiler_flag和check_fortran_compiler_flag宏。 tips function(set_compiler_flag _result _lang) ... endfunction() set_compiler_flag函数需要两个参数，_result(保存成功编译标志或为空字符串)和_lang(指定语言:C、C++或Fortran)。 我们也能这样调用函数: set_compiler_flag(working_compile_flag C REQUIRED \"-Wall\" \"-warn all\") 这里有五个调用参数，但是函数头只需要两个参数。这意味着REQUIRED、-Wall和-warn all将放在${ARGN}中。 tips # build a list of flags from the arguments set(_list_of_flags) # also figure out whether the function # is required to find a flag set(_flag_is_required FALSE) foreach(_arg IN ITEMS ${ARGN}) string(TOUPPER \"${_arg}\" _arg_uppercase) if(_arg_uppercase STREQUAL \"REQUIRED\") set(_flag_is_required TRUE) else() list(APPEND _list_of_flags \"${_arg}\") endif() endforeach() 使用foreach构建一个标志列表。同时，从标志列表中过滤出REQUIRED，并使用它来设置_flag_is_required，将标志列表中的其他参数放到_list_of_flags中。 tips set(_flag_found FALSE) # loop over all flags, try to find the first which works foreach(flag IN ITEMS ${_list_of_flags}) unset(_flag_works CACHE) if(_lang STREQUAL \"C\") check_c_compiler_flag(\"${flag}\" _flag_works) elseif(_lang STREQUAL \"CXX\") check_cxx_compiler_flag(\"${flag}\" _flag_works) elseif(_lang STREQUAL \"Fortran\") check_Fortran_compiler_flag(\"${flag}\" _flag_works) else() message(FATAL_ERROR \"Unknown language in set_compiler_flag: ${_lang}\") endif() # if the flag works, use it, and exit # otherwise try next flag if(_flag_works) set(${_result} \"${flag}\" PARENT_SCOPE) set(_flag_found TRUE) break() endif() endforeach() 现在，我们将循环${_list_of_flags}，尝试每个标志，如果_flag_works被设置为TRUE，我们将_flag_found设置为TRUE，并中止进一步的搜索。 unset(_flag_works CACHE)确保check_*_compiler_flag的结果，不会在使用_flag_works result变量时，使用的是缓存结果。 引用 if(_flag_works) set(${_result} \"${flag}\" PARENT_SCOPE) set(_flag_found TRUE) break() endif() 如果找到了标志，并且_flag_works设置为TRUE，我们就将_result映射到的变量。 这需要使用PARENT_SCOPE来完成，因为我们正在修改一个变量，希望打印并在函数体外部使用该变量。请注意，如何使用${_result}语法解引用，从父范围传递的变量_result的值。不管函数的名称是什么，这对于确保工作标志被设置非常有必要。 引用 # raise an error if no flag was found if(_flag_is_required AND NOT _flag_found) message(FATAL_ERROR \"None of the required flags were supported\") endif() 如果没有找到任何标志，并且该标志设置了REQUIRED，那我们将使用一条错误消息停止配置。 CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(example LANGUAGES C CXX) include(cmake/set_compiler_flag.cmake) set_compiler_flag( working_compile_flag C REQUIRED \"-foo\" # this should fail \"-wrong\" # this should fail \"-wrong\" # this should fail \"-Wall\" # this should work with GNU \"-warn all\" # this should work with Intel \"-Minform=inform\" # this should work with PGI \"-nope\" # this should fail ) message(STATUS \"working C compile flag: ${working_compile_flag}\") set_compiler_flag( working_compile_flag CXX ","date":"2024-01-31","objectID":"/posts/cmake_note_34/:2:0","tags":["CMake"],"title":"CMake 笔记 | [34] 编写函数来测试和设置编译器标志","uri":"/posts/cmake_note_34/"},{"categories":["C++"],"content":"三、结果展示 $ mkdir -p build $ cd build $ cmake .. -- ... -- Performing Test _flag_works -- Performing Test _flag_works - Failed -- Performing Test _flag_works -- Performing Test _flag_works - Failed -- Performing Test _flag_works -- Performing Test _flag_works - Failed -- Performing Test _flag_works -- Performing Test _flag_works - Success -- working C compile flag: -Wall -- Performing Test _flag_works -- Performing Test _flag_works - Failed -- Performing Test _flag_works -- Performing Test _flag_works - Success -- working CXX compile flag: -g -- ... ","date":"2024-01-31","objectID":"/posts/cmake_note_34/:3:0","tags":["CMake"],"title":"CMake 笔记 | [34] 编写函数来测试和设置编译器标志","uri":"/posts/cmake_note_34/"},{"categories":["C++"],"content":"一、导言 导言 项目通常从单个**CMakeLists.txt文件开始，随着时间的推移，这个文件会逐渐增长。本篇，我们将演示一种将CMakeLists.txt分割成更小单元的机制。将CMakeLists.txt拆分为模块的动机：** 主CMakeLists.txt更易于阅读； CMake模块可以在其他项目中重用 与函数相结合，模块可以帮助我们限制变量的作用范围。 本篇，我们将演示如何定义和包含一个宏，该宏允许我们获得**CMake的彩色输出(用于重要的状态消息或警告)。** ","date":"2024-01-31","objectID":"/posts/cmake_note_33/:1:0","tags":["CMake"],"title":"CMake 笔记 | [33] 将源码分成模块","uri":"/posts/cmake_note_33/"},{"categories":["C++"],"content":"二、项目结构 . ├── cmake │ └── colors.cmake └── CMakeLists.txt https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter7/02 相关源码 cmake/color.cmake # colorize CMake output macro(define_colors) if(WIN32) # has no effect on WIN32 set(ColourReset \"\") set(ColourBold \"\") set(Red \"\") set(Green \"\") set(Yellow \"\") set(Blue \"\") set(Magenta \"\") set(Cyan \"\") set(White \"\") set(BoldRed \"\") set(BoldGreen \"\") set(BoldYellow \"\") set(BoldBlue \"\") set(BoldMagenta \"\") set(BoldCyan \"\") set(BoldWhite \"\") else() string(ASCII 27 Esc) set(ColourReset \"${Esc}[m\") set(ColourBold \"${Esc}[1m\") set(Red \"${Esc}[31m\") set(Green \"${Esc}[32m\") set(Yellow \"${Esc}[33m\") set(Blue \"${Esc}[34m\") set(Magenta \"${Esc}[35m\") set(Cyan \"${Esc}[36m\") set(White \"${Esc}[37m\") set(BoldRed \"${Esc}[1;31m\") set(BoldGreen \"${Esc}[1;32m\") set(BoldYellow \"${Esc}[1;33m\") set(BoldBlue \"${Esc}[1;34m\") set(BoldMagenta \"${Esc}[1;35m\") set(BoldCyan \"${Esc}[1;36m\") set(BoldWhite \"${Esc}[1;37m\") endif() endmacro() CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(example LANGUAGES NONE) list(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/cmake\") include(colors) define_colors() message(STATUS \"This is a normal message\") message(STATUS \"${Red}This is a red${ColourReset}\") message(STATUS \"${BoldRed}This is a bold red${ColourReset}\") message(STATUS \"${Green}This is a green${ColourReset}\") message(STATUS \"${BoldMagenta}This is bold${ColourReset}\") 引用 list(APPEND CMAKE_MODULE_PATH \"${CMAKE_CURRENT_SOURCE_DIR}/cmake\") 将cmake子目录添加到CMake模块搜索的路径列表中。 tips include(colors) define_colors() 包括colors.cmake模块，调用其中定义的宏。 引用 message(STATUS \"This is a normal message\") message(STATUS \"${Red}This is a red${ColourReset}\") message(STATUS \"${BoldRed}This is a bold red${ColourReset}\") message(STATUS \"${Green}This is a green${ColourReset}\") message(STATUS \"${BoldMagenta}This is bold${ColourReset}\") 打印了不同颜色的信息。 ","date":"2024-01-31","objectID":"/posts/cmake_note_33/:2:0","tags":["CMake"],"title":"CMake 笔记 | [33] 将源码分成模块","uri":"/posts/cmake_note_33/"},{"categories":["C++"],"content":"三、结果展示 mkdir build cd build cmake .. 结果展示 ","date":"2024-01-31","objectID":"/posts/cmake_note_33/:3:0","tags":["CMake"],"title":"CMake 笔记 | [33] 将源码分成模块","uri":"/posts/cmake_note_33/"},{"categories":["C++"],"content":"一、导言 导言 任何编程语言中，函数允许我们抽象(隐藏)细节并避免代码重复，****CMake也不例外。我们将以宏和函数为例进行讨论，并介绍一个宏，以便方便地定义测试和设置测试的顺序。我们的目标是定义一个宏，能够替换add_test和set_tests_properties，用于定义每组和设置每个测试的预期开销。 ","date":"2024-01-31","objectID":"/posts/cmake_note_32/:1:0","tags":["CMake"],"title":"CMake 笔记 | [32] 使用函数和宏重用代码","uri":"/posts/cmake_note_32/"},{"categories":["C++"],"content":"二、项目结构 . ├── CMakeLists.txt ├── src │ ├── CMakeLists.txt │ ├── main.cpp │ ├── sum_integers.cpp │ └── sum_integers.hpp └── tests ├── catch.hpp ├── CMakeLists.txt └── test.cpp https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter7/01 相关源码 CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(example LANGUAGES CXX) set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_EXTENSIONS OFF) set(CMAKE_CXX_STANDARD_REQUIRED ON) include(GNUInstallDirs) set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_LIBDIR}) set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_LIBDIR}) set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_BINDIR}) add_subdirectory(src) enable_testing() add_subdirectory(tests) tips include(GNUInstallDirs) set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_LIBDIR}) set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_LIBDIR}) set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/${CMAKE_INSTALL_BINDIR}) 根据GNU标准定义binary和library路径。 tips add_subdirectory(src) enable_testing() add_subdirectory(tests) 使用add_subdirectory调用src/CMakeLists.txt和tests/CMakeLists.txt。 src/CMakeLists.txt set(CMAKE_INCLUDE_CURRENT_DIR_IN_INTERFACE ON) add_library(sum_integers sum_integers.cpp) add_executable(sum_up main.cpp) target_link_libraries(sum_up sum_integers) tips set(CMAKE_INCLUDE_CURRENT_DIR_IN_INTERFACE ON) 这个命令会将当前目录，添加到CMakeLists.txt中定义的所有目标的interface_include_directory属性中。换句话说，我们不需要使用target_include_directory来添加cpp_test所需头文件的位置。 src/sun_integers.hpp #ifndef SUM_INTEGERS_H #define SUM_INTEGERS_H #include \u003cvector\u003e int sum_integers(const std::vector\u003cint\u003e \u0026integers); #endif // ! SUM_INTEGERS_H src/sun_integers.cpp #include \"sum_integers.hpp\" int sum_integers(const std::vector\u003cint\u003e\u0026 integers) { auto sum = 0; for (auto i : integers) { sum += i; } return sum; } src/main.cpp #include \u003ciostream\u003e #include \u003cstring\u003e #include \"sum_integers.hpp\" int main(int argc, char *argv[]) { std::vector\u003cint\u003e integers; for (auto i = 1; i \u003c argc; i++) { integers.push_back(std::stoi(argv[i])); } auto sum = sum_integers(integers); std::cout \u003c\u003c sum \u003c\u003c std::endl; return 0; } tests/CMakeLists.txt add_executable(cpp_test test.cpp) target_link_libraries(cpp_test sum_integers) macro(add_catch_test _name _cost) math(EXPR num_macro_calls \"${num_macro_calls} + 1\") message(STATUS \"add_catch_test called with ${ARGC} arguments: ${ARGV}\") set(_argn \"${ARGN}\") if(_argn) message(STATUS \"oops - macro received argument(s) we did not expect: ${ARGN}\") endif() add_test( NAME ${_name} COMMAND $\u003cTARGET_FILE:cpp_test\u003e [${_name}] --success --out ${PROJECT_BINARY_DIR}/tests/${_name}.log --durations yes WORKING_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR} ) set_tests_properties( ${_name} PROPERTIES COST ${_cost} ) endmacro() set(num_macro_calls 0) add_catch_test(short 1.5) add_catch_test(long1 2.5) add_catch_test(long2 3.0 extra_argument) message(STATUS \"in total there were ${num_macro_calls} calls to add_catch_test\") tips macro(add_catch_test _name _cost) math(EXPR num_macro_calls \"${num_macro_calls} + 1\") message(STATUS \"add_catch_test called with ${ARGC} arguments: ${ARGV}\") set(_argn \"${ARGN}\") if(_argn) message(STATUS \"oops - macro received argument(s) we did not expect: ${ARGN}\") endif() add_test( NAME ${_name} COMMAND $\u003cTARGET_FILE:cpp_test\u003e [${_name}] --success --out ${PROJECT_BINARY_DIR}/tests/${_name}.log --durations yes WORKING_DIRECTORY ${CMAKE_CURRENT_BINARY_DIR} ) set_tests_properties( ${_name} PROPERTIES COST ${_cost} ) endmacro() 这个配置中新添加了add_catch_test宏。这个宏需要两个参数_name和_cost，可以在宏中使用这些参数来调用add_test和set_tests_properties。参数前面的下划线，是为了表明这些参数只能在宏中访问。另外，宏自动填充了${ARGC}(参数数量)和${ARGV}(参数列表)，我们可以在输出中验证了这一点: -- add_catch_test called with 2 arguments: short;1.5 -- add_catch_test called with 3 arguments: long;2.5;extra_argument 宏还定义了${ARGN}，用于保存最后一个参数之后的参数列表。此外，我们还可以使用${ARGV0}、${ARGV1}等来处理参数。我们演示一下，如何捕捉到调用中的额外参数(extra_argument): add_catch_test(long 2.5 extra_argument) 使用了以下方法: set(_ar","date":"2024-01-31","objectID":"/posts/cmake_note_32/:2:0","tags":["CMake"],"title":"CMake 笔记 | [32] 使用函数和宏重用代码","uri":"/posts/cmake_note_32/"},{"categories":["C++"],"content":"三、结果展示 $ mkdir -p build $ cd build $ cmake .. -- ... -- add_catch_test called with 2 arguments: short;1.5 -- add_catch_test called with 3 arguments: long;2.5;extra_argument -- oops - macro received argument(s) we did not expect: extra_argument -- in total there were 2 calls to add_catch_test -- ... 构建并运行测试 $ cmake --build . $ ctest 测试结果展示 ","date":"2024-01-31","objectID":"/posts/cmake_note_32/:3:0","tags":["CMake"],"title":"CMake 笔记 | [32] 使用函数和宏重用代码","uri":"/posts/cmake_note_32/"},{"categories":["C++"],"content":"四、补充内容 上述内容中的使用宏定义的方法替换add_test、add_tests_properties的方法可以使用一个函数来实现： function(add_catch_test _name _cost) ... endfunction() 宏和函数之间的区别在于它们的变量范围。宏在调用者的范围内执行，而函数有自己的变量范围。换句话说，如果我们使用宏，需要设置或修改对调用者可用的变量。如果不去设置或修改输出变量，最好使用函数。我们注意到，可以在函数中修改父作用域变量，但这必须使用PARENT_SCOPE显式表示: set(variable_visible_outside \"some value\" PARENT_SCOPE) 如果我们将宏更改为函数，测试仍然可以工作，但是num_macro_calls在父范围内的所有调用中始终为0。将CMake宏想象成类似函数是很有用的，这些函数被直接替换到它们被调用的地方(在C语言中内联)。将CMake函数想象成黑盒函数很有必要。黑盒中，除非显式地将其定义为PARENT_SCOPE，否则不会返回任何内容。CMake中的函数没有返回值。 ","date":"2024-01-31","objectID":"/posts/cmake_note_32/:4:0","tags":["CMake"],"title":"CMake 笔记 | [32] 使用函数和宏重用代码","uri":"/posts/cmake_note_32/"},{"categories":["C++"],"content":"一、导言 导言 上一篇，在配置时记录了代码存储库(Git Hash)的状态。然而，该方法方法有一个令人不满意的地方，如果在配置代码之后更改分支或提交更改，则源代码中包含的版本记录可能指向错误的Git Hash值。本篇，我们将演示如何在构建时记录·Git Hash·(或者，执行其他操作)，以确保每次构建代码时都运行这些操作，因为实际操作中可能只配置一次，但是会构建多次。 ","date":"2024-01-31","objectID":"/posts/cmake_note_31/:1:0","tags":["CMake"],"title":"CMake 笔记 | [31] 构建时记录Git Hash值","uri":"/posts/cmake_note_31/"},{"categories":["C++"],"content":"二、项目结构 . ├── cmake │ └── git-hash.cmake ├── CMakeLists.txt ├── example.cpp └── version.hpp.in https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter6/05 相关源码 version.hpp.in #pragma once #include \u003cstring\u003e const std::string GIT_HASH = \"@GIT_HASH@\"; example.cpp #include \"version.hpp\" #include \u003ciostream\u003e int main() { std::cout \u003c\u003c \"This code has been built from version \" \u003c\u003c GIT_HASH \u003c\u003c std::endl; } git-hash.cmake set(GIT_HASH \"unknown\") # find Git and if available set GIT_HASH variable find_package(Git QUIET) if(GIT_FOUND) execute_process( COMMAND ${GIT_EXECUTABLE} log -1 --pretty=format:%h OUTPUT_VARIABLE GIT_HASH OUTPUT_STRIP_TRAILING_WHITESPACE ERROR_QUIET ) endif() message(STATUS \"Git hash is ${GIT_HASH}\") configure_file( ${CMAKE_SOURCE_DIR}/version.hpp.in ${TARGET_DIR}/generated/version.hpp @ONLY ) CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(recipe-07 LANGUAGES CXX) set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_EXTENSIONS OFF) set(CMAKE_CXX_STANDARD_REQUIRED ON) add_executable(example example.cpp) target_include_directories(example PRIVATE ${CMAKE_CURRENT_BINARY_DIR}/generated ) add_custom_command( OUTPUT ${CMAKE_CURRENT_BINARY_DIR}/generated/version.hpp ALL COMMAND ${CMAKE_COMMAND} -D TARGET_DIR=${CMAKE_CURRENT_BINARY_DIR} -P ${CMAKE_CURRENT_SOURCE_DIR}/cmake/git-hash.cmake WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR} ) # rebuild version.hpp every time add_custom_target( get_git_hash ALL DEPENDS ${CMAKE_CURRENT_BINARY_DIR}/generated/version.hpp ) # version.hpp has to be generated before we start building example add_dependencies(example get_git_hash) tips add_custom_command( OUTPUT ${CMAKE_CURRENT_BINARY_DIR}/generated/version.hpp ALL COMMAND ${CMAKE_COMMAND} -D TARGET_DIR=${CMAKE_CURRENT_BINARY_DIR} -P ${CMAKE_CURRENT_SOURCE_DIR}/cmake/git-hash.cmake WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR} ) 自定义命令调用CMake来执行git-hash.cmake脚本。这里使用CLI的-P开关，通过传入脚本的位置实现的。请注意，可以像往常一样使用CLI开关-D传递选项。git-hash.cmake脚本生成${TARGET_DIR}/generated/version.hpp。自定义目标被添加到ALL目标中，并且依赖于自定义命令的输出。换句话说，当构建默认目标时，我们确保自定义命令已经运行。此外，自定义命令将ALL目标作为输出。这样，我们就能确保每次都会生成version.hpp了。 ","date":"2024-01-31","objectID":"/posts/cmake_note_31/:2:0","tags":["CMake"],"title":"CMake 笔记 | [31] 构建时记录Git Hash值","uri":"/posts/cmake_note_31/"},{"categories":["C++"],"content":"三、结果展示 $ mkdir -p build $ cd build $ cmake .. $ cmake --build . $ ./example This code has been configured from version c66f02 生成git hash版本文件 ","date":"2024-01-31","objectID":"/posts/cmake_note_31/:3:0","tags":["CMake"],"title":"CMake 笔记 | [31] 构建时记录Git Hash值","uri":"/posts/cmake_note_31/"},{"categories":["C++"],"content":"四、补充内容 可以改进配置，以便在记录的Git Hash外，包含其他的信息。检测构建环境是否污染(即是否包含未提交的更改和未跟踪的文件)，或者干净。可以使用git describe --abbrev=7 --long --always --dirty --tags检测这些信息。根据可重现性，甚至可以将Git的状态，完整输出记录到头文件中。 ","date":"2024-01-31","objectID":"/posts/cmake_note_31/:4:0","tags":["CMake"],"title":"CMake 笔记 | [31] 构建时记录Git Hash值","uri":"/posts/cmake_note_31/"},{"categories":["C++"],"content":"一、导言 导言 大多数现代源代码存储库都使用**Git作为版本控制系统进行跟踪，提交的Git Hash决定了源代码的状态。因此，为了标记可执行文件，尝试将Git Hash记录到可执行文件中，方法是将哈希字符串记录在一个头文件中，该头文件可以包含在代码中。** ","date":"2024-01-31","objectID":"/posts/cmake_note_30/:1:0","tags":["CMake"],"title":"CMake 笔记 | [30] 配置时记录Git Hash值","uri":"/posts/cmake_note_30/"},{"categories":["C++"],"content":"二、项目结构 . ├── CMakeLists.txt ├── example.cpp └── version.hpp.in https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter6/04 相关源码 version.hpp.in #pragma once #include \u003cstring\u003e const std::string GIT_HASH = \"@GIT_HASH@\"; example.cpp #include \"version.hpp\" #include \u003ciostream\u003e int main() { std::cout \u003c\u003c \"This code has been configured from version \" \u003c\u003c GIT_HASH \u003c\u003c std::endl; } CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(example LANGUAGES CXX) set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_EXTENSIONS OFF) set(CMAKE_CXX_STANDARD_REQUIRED ON) set(GIT_HASH \"unknown\") find_package(Git QUIET) if(GIT_FOUND) execute_process( COMMAND ${GIT_EXECUTABLE} log -1 --pretty=format:%h OUTPUT_VARIABLE GIT_HASH OUTPUT_STRIP_TRAILING_WHITESPACE ERROR_QUIET WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR} ) endif() message(STATUS \"Git hash is ${GIT_HASH}\") configure_file( version.hpp.in generated/version.hpp @ONLY ) add_executable(example example.cpp) target_include_directories(example PRIVATE ${CMAKE_CURRENT_BINARY_DIR}/generated ) 引用 set(GIT_HASH \"unknown\") 由于Git命令可能会失败(源代码已经分发到Git存储库之外)，或者Git在系统上不可用，我们希望为这个变量设置一个默认值。 tips find_package(Git QUIET) if(GIT_FOUND) execute_process( COMMAND ${GIT_EXECUTABLE} log -1 --pretty=format:%h OUTPUT_VARIABLE GIT_HASH OUTPUT_STRIP_TRAILING_WHITESPACE ERROR_QUIET WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR} ) endif() 使用find_package(Git QUIET)来检测系统上是否有可用的Git。如果有(GIT_FOUND为True)，运行一个Git命令:${GIT_EXECUTABLE} log -1 --pretty=format:%h。这个命令给出了当前提交Hash的简短版本。 当然，这里我们可以灵活地运行Git命令。 要求execute_process命令将结果放入名为GIT_HASH的变量中，然后删除任何尾随的空格。使用ERROR_QUIET，如果Git命令由于某种原因失败，不会停止配置。 ","date":"2024-01-31","objectID":"/posts/cmake_note_30/:2:0","tags":["CMake"],"title":"CMake 笔记 | [30] 配置时记录Git Hash值","uri":"/posts/cmake_note_30/"},{"categories":["C++"],"content":"三、结果展示 $ mkdir -p build $ cd build $ cmake .. $ cmake --build . $ ./example This code has been configured from version 74e4aa9 生成保存git hash的文件 version.hpp #pragma once #include \u003cstring\u003e const std::string GIT_HASH = \"74e4aa9\"; ","date":"2024-01-31","objectID":"/posts/cmake_note_30/:3:0","tags":["CMake"],"title":"CMake 笔记 | [30] 配置时记录Git Hash值","uri":"/posts/cmake_note_30/"},{"categories":["C++"],"content":"一、 导言 导言 本篇内容目的和上一篇相似，但是出发点不同。我们计划是从文件中读取版本信息，而不是将其设置在CMakeLists.txt中。将版本保存在单独文件中的目的，是允许其他构建框架或开发工具使用独立于**CMake的信息，而不需要将信息复制到多个文件中。** ","date":"2024-01-31","objectID":"/posts/cmake_note_29/:1:0","tags":["CMake"],"title":"CMake 笔记 | [29] 从文件中记录项目版本","uri":"/posts/cmake_note_29/"},{"categories":["C++"],"content":"二、项目结构 . ├── CMakeLists.txt ├── example.cpp ├── version.hpp.in └── VERSION.txt https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter6/03 ","date":"2024-01-31","objectID":"/posts/cmake_note_29/:2:0","tags":["CMake"],"title":"CMake 笔记 | [29] 从文件中记录项目版本","uri":"/posts/cmake_note_29/"},{"categories":["C++"],"content":"三、相关源码 VERSION.txt 2.0.1-rc-2 version.hpp.in #pragma once #include \u003cstring\u003e const std::string PROGRAM_VERSION = \"@PROGRAM_VERSION@\"; example.cpp #include \"version.hpp\" #include \u003ciostream\u003e int main() { std::cout \u003c\u003c \"This is output from code v\" \u003c\u003c PROGRAM_VERSION \u003c\u003c std::endl; std::cout \u003c\u003c \"Hello CMake world!\" \u003c\u003c std::endl; } CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(example LANGUAGES CXX) set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_EXTENSIONS OFF) set(CMAKE_CXX_STANDARD_REQUIRED ON) if(EXISTS \"${CMAKE_CURRENT_SOURCE_DIR}/VERSION.txt\") file(READ \"${CMAKE_CURRENT_SOURCE_DIR}/VERSION.txt\" PROGRAM_VERSION) string(STRIP \"${PROGRAM_VERSION}\" PROGRAM_VERSION) else() message(FATAL_ERROR \"File ${CMAKE_CURRENT_SOURCE_DIR}/VERSION.txt not found\") endif() configure_file( version.hpp.in generated/version.hpp @ONLY ) add_executable(example example.cpp) target_include_directories(example PRIVATE ${CMAKE_CURRENT_BINARY_DIR}/generated ) 引用 if(EXISTS \"${CMAKE_CURRENT_SOURCE_DIR}/VERSION.txt\") file(READ \"${CMAKE_CURRENT_SOURCE_DIR}/VERSION.txt\" PROGRAM_VERSION) string(STRIP \"${PROGRAM_VERSION}\" PROGRAM_VERSION) else() message(FATAL_ERROR \"File ${CMAKE_CURRENT_SOURCE_DIR}/VERSION.txt not found\") endif() 首先，检查文件VERSION.txt文件是否存在，如果不存在，则发出错误消息。如果存在，将内容读入PROGRAM_VERSION变量中，该变量会去掉尾部的空格。 当设置了变量PROGRAM_VERSION，就可以使用它来配置version.hpp.in，生成generated/version.hpp： configure_file( version.hpp.in generated/version.hpp @ONLY ) ","date":"2024-01-31","objectID":"/posts/cmake_note_29/:3:0","tags":["CMake"],"title":"CMake 笔记 | [29] 从文件中记录项目版本","uri":"/posts/cmake_note_29/"},{"categories":["C++"],"content":"四、结果展示 $ mkdir -p build $ cd build $ cmake .. $ cmake --build . $ ./example This is output from code v2.0.1-rc-2 Hello CMake world! 生成版本文件 version.hpp #pragma once #include \u003cstring\u003e const std::string PROGRAM_VERSION = \"2.0.1-rc-2\"; ","date":"2024-01-31","objectID":"/posts/cmake_note_29/:4:0","tags":["CMake"],"title":"CMake 笔记 | [29] 从文件中记录项目版本","uri":"/posts/cmake_note_29/"},{"categories":["C++"],"content":"一、导言 导言 代码版本很重要，不仅是为了可重复性，还为了记录API功能或简化支持请求和bug报告。源代码通常处于某种版本控制之下，例如可以使用Git标记附加额外版本号。然而，不仅需要对源代码进行版本控制，而且可执行文件还需要记录项目版本，以便将其打印到代码输出或用户界面上。 本篇，将在CMake源文件中定义版本号。我们的目标是在配置项目时将程序版本记录到头文件中。然后，生成的头文件可以包含在代码的正确位置和时间，以便将代码版本打印到输出文件或屏幕上。 ","date":"2024-01-31","objectID":"/posts/cmake_note_28/:1:0","tags":["CMake"],"title":"CMake 笔记 | [28] 记录项目版本信息以便报告","uri":"/posts/cmake_note_28/"},{"categories":["C++"],"content":"二、项目结构 . ├── CMakeLists.txt ├── version.h.in └── example.cpp 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter6/02 ","date":"2024-01-31","objectID":"/posts/cmake_note_28/:2:0","tags":["CMake"],"title":"CMake 笔记 | [28] 记录项目版本信息以便报告","uri":"/posts/cmake_note_28/"},{"categories":["C++"],"content":"三、相关源码 example.cpp #include \"version.h\" #include \u003ciostream\u003e int main() { std::cout \u003c\u003c \"This is output from code \" \u003c\u003c PROJECT_VERSION \u003c\u003c std::endl; std::cout \u003c\u003c \"Major version number: \" \u003c\u003c PROJECT_VERSION_MAJOR \u003c\u003c std::endl; std::cout \u003c\u003c \"Minor version number: \" \u003c\u003c PROJECT_VERSION_MINOR \u003c\u003c std::endl; std::cout \u003c\u003c \"Hello CMake world!\" \u003c\u003c std::endl; } 这里，假设PROJECT_VERSION_MAJOR、PROJECT_VERSION_MINOR和PROJECT_VERSION是在version.h中定义的。 目标是从以下模板中生成version.h.in: version.h.in #pragma once #define PROJECT_VERSION_MAJOR @PROJECT_VERSION_MAJOR@ #define PROJECT_VERSION_MINOR @PROJECT_VERSION_MINOR@ #define PROJECT_VERSION_PATCH @PROJECT_VERSION_PATCH@ #define PROJECT_VERSION \"v@PROJECT_VERSION@\" 这里使用预处理器定义，也可以使用字符串或整数常量来提高类型安全性。 CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(example VERSION 2.0.1 LANGUAGES CXX) configure_file( version.h.in generated/version.h @ONLY ) add_executable(${PROJECT_NAME} example.cpp) target_include_directories(${PROJECT_NAME} PRIVATE ${CMAKE_CURRENT_BINARY_DIR}/generated ) 当使用版本参数调用CMake的project时，CMake将为项目设置PROJECT_VERSION_MAJOR、PROJECT_VERSION_MINOR和PROJECT_VERSION_PATCH。 configure_file接受一个输入文件(本例中是version.h.in)，通过将@之间的占位符替换成对应的CMake变量，生成一个输出文件(本例中是generate/version.h)。它将@PROJECT_VERSION_MAJOR@替换为2，以此类推。使用关键字@ONLY，我们将configure_file限制为只替换@variables@，而不修改${variables}。 ","date":"2024-01-31","objectID":"/posts/cmake_note_28/:3:0","tags":["CMake"],"title":"CMake 笔记 | [28] 记录项目版本信息以便报告","uri":"/posts/cmake_note_28/"},{"categories":["C++"],"content":"四、结果 mkdir build \u0026 cd build cmake .. cmake --build . ./example This is output from code v2.0.1 Major version number: 2 Minor version number: 0 Hello CMake world! 生成版本信息 #pragma once #define PROJECT_VERSION_MAJOR 2 #define PROJECT_VERSION_MINOR 0 #define PROJECT_VERSION_PATCH 1 #define PROJECT_VERSION \"v2.0.1\" ","date":"2024-01-31","objectID":"/posts/cmake_note_28/:4:0","tags":["CMake"],"title":"CMake 笔记 | [28] 记录项目版本信息以便报告","uri":"/posts/cmake_note_28/"},{"categories":["C++"],"content":"五、补充内容 CMake以x.y.z格式给出的版本号，并将变量PROJECT_VERSION和\u003cproject-name\u003e_VERSION设置为给定的值。此外,PROJECT_VERSION_MAJOR(\u003cproject-name\u003e_VERSION_MAJOR),PROJECT_VERSION_MINOR(\u003cproject-name\u003e_VERSION_MINOR) PROJECT_VERSION_PATCH(\u003cproject-name\u003e_VERSION_PATCH)和PROJECT_VERSION_TWEAK(\u003cproject-name\u003e_VERSION_TWEAK),将分别设置为X, Y, Z和t。 为了确保只有当CMake变量被认为是一个真正的常量时，才定义预处理器变量，可以使用configure_file，在配置的头文件中使用#cmakedefin而不是#define。 根据是否定义了CMake变量并将其计算为一个真正的常量，#cmakedefine YOUR_VARIABLE将被替换为#define YOUR_VARIABLE …或者/* #undef YOUR_VARIABLE */。还有#cmakedefine01，将根据变量是否定义，将变量设置为0或1。 ","date":"2024-01-31","objectID":"/posts/cmake_note_28/:5:0","tags":["CMake"],"title":"CMake 笔记 | [28] 记录项目版本信息以便报告","uri":"/posts/cmake_note_28/"},{"categories":["C++"],"content":"一、导言 导言 代码生成在配置时发生，如 CMake可以检测操作系统和可用库；基于这些信息，可以定制构建的源代码。本篇我们将探索如何生成一个简单源文件，该文件定义了一个函数，用于报告构建系统配置。 ","date":"2024-01-31","objectID":"/posts/cmake_note_27/:1:0","tags":["CMake"],"title":"CMake 笔记 | [27] 配置时生成源码","uri":"/posts/cmake_note_27/"},{"categories":["C++"],"content":"二、项目结构 . ├── CMakeLists.txt └── print_info.c.in 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter6/01 相关源码 CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(config_generator LANGUAGES C) execute_process( COMMAND whoami TIMEOUT 1 OUTPUT_VARIABLE _user_name OUTPUT_STRIP_TRAILING_WHITESPACE ) # host name information cmake_host_system_information(RESULT _host_name QUERY HOSTNAME) cmake_host_system_information(RESULT _fqdn QUERY FQDN) # processor information cmake_host_system_information(RESULT _processor_name QUERY PROCESSOR_NAME) cmake_host_system_information(RESULT _processor_description QUERY PROCESSOR_DESCRIPTION) # os information cmake_host_system_information(RESULT _os_name QUERY OS_NAME) cmake_host_system_information(RESULT _os_release QUERY OS_RELEASE) cmake_host_system_information(RESULT _os_version QUERY OS_VERSION) cmake_host_system_information(RESULT _os_platform QUERY OS_PLATFORM) string(TIMESTAMP _configuration_time \"%Y-%m-%d %H:%M:%S [UTC]\" UTC) configure_file(print_info.c.in print_info.c @ONLY) tips execute_process( COMMAND whoami TIMEOUT 1 OUTPUT_VARIABLE _user_name OUTPUT_STRIP_TRAILING_WHITESPACE ) 使用 execute_process为项目获取当前使用者的信息。 tips # host name information cmake_host_system_information(RESULT _host_name QUERY HOSTNAME) cmake_host_system_information(RESULT _fqdn QUERY FQDN) # processor information cmake_host_system_information(RESULT _processor_name QUERY PROCESSOR_NAME) cmake_host_system_information(RESULT _processor_description QUERY PROCESSOR_DESCRIPTION) # os information cmake_host_system_information(RESULT _os_name QUERY OS_NAME) cmake_host_system_information(RESULT _os_release QUERY OS_RELEASE) cmake_host_system_information(RESULT _os_version QUERY OS_VERSION) cmake_host_system_information(RESULT _os_platform QUERY OS_PLATFORM) 使用cmake_host_system_information()函数查询系统信息。 tips string(TIMESTAMP _configuration_time \"%Y-%m-%d %H:%M:%S [UTC]\" UTC) 捕获配置时的时间戳，并通过使用字符串操作函数。 tips configure_file(print_info.c.in print_info.c @ONLY) 通过configure_file函数生成代码。注意，这里只要求以@开头和结尾的字符串被替换。 print_info.c.in #include \u003cstdio.h\u003e #include \u003cunistd.h\u003e void print_info(void) { printf(\"\\n\"); printf(\"Configuration and build information\\n\"); printf(\"-----------------------------------\\n\"); printf(\"\\n\"); printf(\"Who compiled | %s\\n\", \"@_user_name@\"); printf(\"Compilation hostname | %s\\n\", \"@_host_name@\"); printf(\"Fully qualified domain name | %s\\n\", \"@_fqdn@\"); printf(\"Operating system | %s\\n\", \"@_os_name@, @_os_release@, @_os_version@\"); printf(\"Platform | %s\\n\", \"@_os_platform@\"); printf(\"Processor info | %s\\n\", \"@_processor_name@, @_processor_description@\"); printf(\"CMake version | %s\\n\", \"@CMAKE_VERSION@\"); printf(\"CMake generator | %s\\n\", \"@CMAKE_GENERATOR@\"); printf(\"Configuration time | %s\\n\", \"@_configuration_time@\"); printf(\"Fortran compiler | %s\\n\", \"@CMAKE_Fortran_COMPILER@\"); printf(\"C compiler | %s\\n\", \"@CMAKE_C_COMPILER@\"); printf(\"\\n\"); fflush(stdout); } 结果展示: 生成print_info.c print_info.c #include \u003cstdio.h\u003e #include \u003cunistd.h\u003e void print_info(void) { printf(\"\\n\"); printf(\"Configuration and build information\\n\"); printf(\"-----------------------------------\\n\"); printf(\"\\n\"); printf(\"Who compiled | %s\\n\", \"jiangli\"); printf(\"Compilation hostname | %s\\n\", \"jiangli-virtual-machine\"); printf(\"Fully qualified domain name | %s\\n\", \"jiangli-virtual-machine.lan\"); printf(\"Operating system | %s\\n\", \"Linux, 5.15.0-89-generic, #99~20.04.1-Ubuntu SMP Thu Nov 2 15:16:47 UTC 2023\"); printf(\"Platform | %s\\n\", \"x86_64\"); printf(\"Processor info | %s\\n\", \"Unknown AMD family, 16 core AMD Ryzen 7 4800H with Radeon Graphics\"); printf(\"CMake version | %s\\n\", \"3.16.3\"); printf(\"CMake generator | %s\\n\", \"Unix Makefiles\"); printf(\"Configuration time | %s\\n\", \"2023-11-24 01:01:31 [UTC]\"); printf(\"Fortran compiler | %s\\n\", \"\"); printf(\"C compiler | %s\\n\", \"/usr/bin/gcc\"); printf(\"\\n\"); fflush(stdout); } 补充 用值替换占位符时，CMake中的变量名应该与将要配置的文件中使用的变量名完全相同，并放在@之间。可以在调用configure_file时定义的任何CMake变量。 ","date":"2024-01-31","objectID":"/posts/cmake_note_27/:2:0","tags":["CMake"],"title":"CMake 笔记 | [27] 配置时生成源码","uri":"/posts/cmake_note_27/"},{"categories":["C++"],"content":"一、导言 导言 本篇通过展示如何使用来自对应的CheckSourceCompiles.cmake标准模块的check__source_compiles函数，以评估给定编译器是否可以将预定义的代码编译成可执行文件。该命令可帮助确定: 编译器支持所需的特性。 链接器工作正常，并理解特定的标志。 可以使用find_package找到的包含目录和库。 我们将展示如何检测OpenMP 4.5标准的循环特性，以便在C++可执行文件中使用。使用一个C++源文件，来探测编译器是否支持这样的特性。CMake提供了一个附加命令try_compile来探究编译。 ","date":"2024-01-31","objectID":"/posts/cmake_note_26/:1:0","tags":["CMake"],"title":"CMake 笔记 | [26] 探究编译和编译命令","uri":"/posts/cmake_note_26/"},{"categories":["C++"],"content":"二、项目结构 ├── CMakeLists.txt └── task_loop.cpp 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter5/04 相关源码 CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(test LANGUAGES CXX) set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_EXTENSIONS OFF) set(CMAKE_CXX_STANDARD_REQUIRED ON) find_package(OpenMP) if(OpenMP_FOUND) # this will get wiped unless you run cmake with --debug-trycompile set(scratch_dir ${CMAKE_CURRENT_BINARY_DIR}/omp_try_compile) try_compile( omp_task_loop_test_1 ${scratch_dir} SOURCES ${CMAKE_CURRENT_SOURCE_DIR}/task_loop.cpp LINK_LIBRARIES OpenMP::OpenMP_CXX ) message(STATUS \"Result of try_compile: ${omp_task_loop_test_1}\") include(CheckCXXSourceCompiles) file(READ ${CMAKE_CURRENT_SOURCE_DIR}/task_loop.cpp snippet) set(CMAKE_REQUIRED_LIBRARIES OpenMP::OpenMP_CXX) check_cxx_source_compiles(\"${snippet}\" omp_task_loop_test_2) unset(CMAKE_REQUIRED_LIBRARIES) message(STATUS \"Result of check_cxx_source_compiles: ${omp_task_loop_test_2}\") else() message(STATUS \"OpenMP not found: no test for taskloop is run\") endif() 方式一： set(scratch_dir ${CMAKE_CURRENT_BINARY_DIR}/omp_try_compile) 如果找到OpenMP，再检查所需的特性是否可用。为此，设置了一个临时目录，try_compile将在这个目录下来生成中间文件。我们把它放在前面步骤中引入的if语句中。如果我们构建时使用如下命令，则会在omp_try_compile文件夹中产生中间文件。 cmake .. --debug-trycompile 生成可执行文件cmTC_e8239 try_compile( omp_task_loop_test_1 ${scratch_dir} SOURCES ${CMAKE_CURRENT_SOURCE_DIR}/task_loop.cpp LINK_LIBRARIES OpenMP::OpenMP_CXX ) message(STATUS \"Result of try_compile: ${omp_task_loop_test_1}\") 调用try_compile生成一个小项目，以尝试编译源文件task_loop.cpp。编译成功或失败的状态，将保存到omp_task_loop_test_1变量中。需要为这个示例编译设置适当的编译器标志、包括目录和链接库。因为使用导入的目标OpenMP::OpenMP_CXX，所以只需将LINK_LIBRARIES选项设置为OpenMP::OpenMP_CXX即可。如果编译成功，则任务循环特性可用，我们打印一条消息。 方式二： include(CheckCXXSourceCompiles) 要使用check_cxx_source_compiles函数，需要包含CheckCXXSourceCompiles.cmake模块文件。其他语言也有类似的模块文件，C(CheckCSourceCompiles.cmake)和Fortran(CheckFortranSourceCompiles.cmake)。 file(READ ${CMAKE_CURRENT_SOURCE_DIR}/task_loop.cpp snippet) 复制源文件的内容，通过file(READ ...)命令读取内容到一个变量中，试图编译和连接这个变量。 set(CMAKE_REQUIRED_LIBRARIES OpenMP::OpenMP_CXX) 设置了CMAKE_REQUIRED_LIBRARIES。对于下一步正确调用编译器是必需的。注意使用导入的OpenMP::OpenMP_CXX目标，它还将设置正确的编译器标志和包含目录。 check_cxx_source_compiles(\"${snippet}\" omp_task_loop_test_2) 使用代码片段作为参数，调用check_cxx_source_compiles函数。检查结果将保存到omp_task_loop_test_2变量中。 unset(CMAKE_REQUIRED_LIBRARIES) message(STATUS \"Result of check_cxx_source_compiles: ${omp_task_loop_test_2}\" 调用check_cxx_source_compiles并向用户打印消息之前，取消变量的设置。 task_loop.cpp #include \u003ccmath\u003e #include \u003ciostream\u003e void LongRunningTask() { double number = 5.0; double result = std::pow(number, 2); std::cout \u003c\u003c \"长时间运行的任务结果：\" \u003c\u003c result \u003c\u003c std::endl; } void LoopBody(int i, int j) { double calculation_result = std::sin(i) * std::cos(j); std::cout \u003c\u003c \"在循环体中计算结果：\" \u003c\u003c calculation_result \u003c\u003c std::endl; } void ParallelWork() { int i, j; #pragma omp taskgroup { #pragma omp task LongRunningTask(); #pragma omp taskloop private(j) grainsize(500) nogroup for (i = 0; i \u003c 10000; i++) { for (j = 0; j \u003c i; j++) { LoopBody(i, j); } } } } int main() { ParallelWork(); return 0; } 结果 $ mkdir -p build $ cd build $ cmake .. -- ... -- Found OpenMP_CXX: -fopenmp (found version \"4.5\") -- Found OpenMP: TRUE (found version \"4.5\") -- Result of try_compile: TRUE -- Performing Test omp_taskloop_test_2 -- Performing Test omp_taskloop_test_2 - Success -- Result of check_cxx_source_compiles: 1 ","date":"2024-01-31","objectID":"/posts/cmake_note_26/:2:0","tags":["CMake"],"title":"CMake 笔记 | [26] 探究编译和编译命令","uri":"/posts/cmake_note_26/"},{"categories":["C++"],"content":"一、导言 导言 add_custom_command 是 CMake 中用于添加自定义构建规则的命令，通常用于在编译项目时执行一些自定义操作，例如生成文件、运行脚本等。 ","date":"2024-01-30","objectID":"/posts/cmake_note_25/:1:0","tags":["CMake"],"title":"CMake 笔记 | [25] 构建时为特定目标运行自定义命令","uri":"/posts/cmake_note_25/"},{"categories":["C++"],"content":"二、项目结构 . ├── CMakeLists.txt ├── generate_config.cmake └── main.cpp 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter5/03 相关源码 CMakeLists.txt cmake_minimum_required(VERSION 3.10) project(test_command) # 设置需要生成的头文件的路径 set(CONFIG_HEADER ${CMAKE_BINARY_DIR}/config.h) # 添加一个自定义命令来生成头文件 add_custom_command( OUTPUT ${CONFIG_HEADER} COMMAND ${CMAKE_COMMAND} -DOUTPUT_FILE=${CONFIG_HEADER} -P ${CMAKE_CURRENT_SOURCE_DIR}/generate_config.cmake COMMENT \"Generating config.h\" ) # 将生成的头文件的路径添加到包含目录 include_directories(${CMAKE_BINARY_DIR}) # 添加可执行文件 add_executable(test_app main.cpp) # 将自定义命令的输出文件添加为依赖项 add_dependencies(test_app config_h_target) # 定义一个自定义目标以便其他目标可以依赖它 add_custom_target(config_h_target DEPENDS ${CONFIG_HEADER}) # 将自定义目标添加到 ALL 阶段，以确保在每次构建时都生成 config.h add_dependencies(test_app config_h_target) generate_config.cmake # 你可以在这里定义所需的宏 set(APP_NAME \"TJUApp\") set(APP_VERSION \"1.0.0\") set(DEBUG_MODE 1) # 生成 config.h 头文件 file(WRITE ${OUTPUT_FILE} \"#ifndef CONFIG_H\\n\") file(APPEND ${OUTPUT_FILE} \"#define CONFIG_H\\n\") file(APPEND ${OUTPUT_FILE} \"\\n\") # 添加宏定义 file(APPEND ${OUTPUT_FILE} \"#define APP_NAME \\\"${APP_NAME}\\\"\\n\") file(APPEND ${OUTPUT_FILE} \"#define APP_VERSION \\\"${APP_VERSION}\\\"\\n\") if (DEBUG_MODE) file(APPEND ${OUTPUT_FILE} \"#define DEBUG_MODE 1\\n\") else () file(APPEND ${OUTPUT_FILE} \"#define DEBUG_MODE 0\\n\") endif () # 结束文件 file(APPEND ${OUTPUT_FILE} \"\\n#endif\\n\") #include \u003ciostream\u003e #include \"config.h\" int main() { #ifdef DEBUG_MODE std::cout \u003c\u003c \"DEBUG_MODE: \" \u003c\u003c DEBUG_MODE \u003c\u003c std::endl; #endif return 0; } 结果 mkdir build \u0026 cd build cmake .. make 生成config.h文件 ``` DEBUG_MODE: 1 ``` ","date":"2024-01-30","objectID":"/posts/cmake_note_25/:2:0","tags":["CMake"],"title":"CMake 笔记 | [25] 构建时为特定目标运行自定义命令","uri":"/posts/cmake_note_25/"},{"categories":["C++"],"content":"一、导言 引用 项目的构建目标取决于命令的结果，这些命令只能在构建系统生成完成后的构建执行。CMake提供了三个选项来在构建时执行自定义命令: 使用add_custom_command编译目标，生成输出文件。 add_custom_target的执行没有输出。 构建目标前后，add_custom_command的执行可以没有输出。 这三个选项强制执行特定的语义，并且不可互换。接下来的我们将分别学习具体的用法。 ","date":"2024-01-30","objectID":"/posts/cmake_note_24/:1:0","tags":["CMake"],"title":"CMake 笔记 | [24] 构建时运行自定义命令add_custom_command","uri":"/posts/cmake_note_24/"},{"categories":["C++"],"content":"二、项目结构 本项目比较简单，我们通过对add_custom_command的简单使用，来探索它的功能。 . ├── CMakeLists.txt ├── config │ └── config.txt └── test.cpp 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter5/02 CMakeLists.txt cmake_minimum_required(VERSION 3.0) project(custom_command_example) # Set static library to lib file set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib) # Set dynamic library to lib file set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib) # Set dynamic runtime library or exetuable file to bin file set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin) add_executable(${PROJECT_NAME} test.cpp) if (MSVC) file(GLOB config_file \"${CMAKE_SOURCE_DIR}/config/*.txt\") add_custom_command(TARGET ${PROJECT_NAME} POST_BUILD COMMAND ${CMAKE_COMMAND} -E copy_if_different ${config_file} $\u003cTARGET_FILE_DIR:${PROJECT_NAME}\u003e) elseif(UNIX) file(GLOB config_file \"${CMAKE_SOURCE_DIR}/config/*.txt\") file(COPY ${config_file} DESTINATION ${CMAKE_RUNTIME_OUTPUT_DIRECTORY}) endif() 引用 add_custom_command 是 CMake 中的一个命令，用于向构建系统添加自定义的构建规则或自定义命令。这可以用于执行各种任务，如生成源文件、拷贝文件、执行脚本等。它允许在 CMake 构建过程中定义一些额外的操作。 以下是 add_custom_command 命令的一般语法和参数： add_custom_command( OUTPUT output1 [output2...] COMMAND command1 [ARGS] [command2 [ARGS] ...] [MAIN_DEPENDENCY depend] [DEPENDS depend [depend ...]] [WORKING_DIRECTORY dir] [COMMENT comment] [VERBATIM] [APPEND] [USES_TERMINAL] ) OUTPUT output1 [output2...]: 指定命令执行后生成的输出文件。这些文件通常是构建过程的目标，可以是可执行文件、库文件、数据文件等。 COMMAND command1 [ARGS] [command2 [ARGS] ...]: 定义要执行的命令。这可以是外部命令、脚本或自定义操作。 MAIN_DEPENDENCY depend: 指定主要的依赖项，通常是影响命令执行的文件。如果 depend 被修改，命令将重新运行。 DEPENDS depend [depend ...]: 指定其他依赖项。这些文件会触发命令重新运行，如果它们被修改。 WORKING_DIRECTORY dir: 指定命令执行的工作目录。 COMMENT comment: 可选，用于描述自定义命令的文本注释。 VERBATIM: 可选，告诉 CMake 保持命令的参数不变，不进行任何转义。 APPEND: 可选，将新的自定义命令追加到同一输出文件上。 USES_TERMINAL: 可选，指示命令是否使用终端。 通常，add_custom_command 用于在构建期间执行一些非标准的操作，例如生成代码、转换文件格式、运行测试或其他自定义任务。这可以帮助您在 CMake 构建系统中添加额外的步骤，以满足项目的特定需求。 本项目需要在Windows系统中构建，以探究add_custom_command 命令的功能。该命令在本项目中的主要功能是将根目录下config·文件夹下的所有txt本文文件拷贝到可执行文件所在的目录。 之所以在Windows中的命令和Linux中的命令不一样，根本原因是由于操作系统的文件系统的不同造成的。 相关源码 test.cpp #include \u003cfstream\u003e #include \u003ciostream\u003e #include \u003cstring\u003e int main() { // 文件路径 std::string file_name = \"config.txt\"; // 打开文件 std::ifstream file(file_name); // 检查文件是否成功打开 if (!file.is_open()) { std::cerr \u003c\u003c \"无法打开文件: \" \u003c\u003c file_name \u003c\u003c std::endl; return 1; } std::string line; // 逐行读取文件内容 while (std::getline(file, line)) { std::cout \u003c\u003c line \u003c\u003c std::endl; } // 关闭文件 file.close(); return 0; } 运行结果 version: 0.0.1 author: jiangli email: 1316762810@qq.com ","date":"2024-01-30","objectID":"/posts/cmake_note_24/:2:0","tags":["CMake"],"title":"CMake 笔记 | [24] 构建时运行自定义命令add_custom_command","uri":"/posts/cmake_note_24/"},{"categories":["C++"],"content":"一、导言 导言 已经好久好久没有更新这个系列了，但是无论如何这个系列一定会以较全面的形式更新完成，只是在时间上可能比较拖沓。没有更新的原因也是最近一个月在做一个项目，没日没夜的度过了一个多月的加班加点的生活。 我们言归正传，通过前面的学习，我们已经了解了CMake如何在配置时运行许多子任务，以便找到工作的编译器和必要的依赖项。本篇，我们将学习使用execute_process命令在配置时运行定制化命令。 ","date":"2024-01-30","objectID":"/posts/cmake_note_23/:1:0","tags":["CMake"],"title":"CMake 笔记 | [23] 配置时运行自定义命令","uri":"/posts/cmake_note_23/"},{"categories":["C++"],"content":"二、项目结构 本篇比较简单，只有一个简单的CMakeLists.txt。 相关源码： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter5/01 CMakeLists.txt cmake_minimum_required(VERSION 3.5 FATAL_ERROR) project(test_exe_proc LANGUAGES NONE) find_package(PythonInterp REQUIRED) # this is set as variable to prepare for abstraction using loops or functions set(module_name \"cffi\") execute_process( COMMAND ${PYTHON_EXECUTABLE} \"-c\" \"import ${module_name}; print(${module_name}.__version__)\" OUTPUT_VARIABLE stdout ERROR_VARIABLE stderr OUTPUT_STRIP_TRAILING_WHITESPACE ERROR_STRIP_TRAILING_WHITESPACE ) if(stderr MATCHES \"ModuleNotFoundError\") message(STATUS \"Module ${module_name} not found\") else() message(STATUS \"Found module ${module_name} v${stdout}\") endif() 代码详解 execute_process命令将从当前正在执行的CMake进程中派生一个或多个子进程，从而提供了在配置项目时运行任意命令的方法。可以在一次调用execute_process时执行多个命令。注意，每个命令的输出将通过管道传输到下一个命令中。该命令接受多个参数: WORKING_DIRECTORY，指定应该在哪个目录中执行命令。 RESULT_VARIABLE将包含进程运行的结果。这要么是一个整数，表示执行成功，要么是一个带有错误条件的字符串。 OUTPUT_VARIABLE和ERROR_VARIABLE将包含执行命令的标准输出和标准错误。由于命令的输出是通过管道传输的，因此只有最后一个命令的标准输出才会保存到OUTPUT_VARIABLE中。 INPUT_FILE指定标准输入重定向的文件名 OUTPUT_FILE指定标准输出重定向的文件名 ERROR_FILE指定标准错误输出重定向的文件名 设置OUTPUT_QUIET和ERROR_QUIET后，CMake将静默地忽略标准输出和标准错误。 设置OUTPUT_STRIP_TRAILING_WHITESPACE，可以删除运行命令的标准输出中的任何尾随空格 设置ERROR_STRIP_TRAILING_WHITESPACE，可以删除运行命令的错误输出中的任何尾随空格 execute_process( COMMAND ${PYTHON_EXECUTABLE} \"-c\" \"import ${module_name}; print(${module_name}.__version__)\" OUTPUT_VARIABLE stdout ERROR_VARIABLE stderr OUTPUT_STRIP_TRAILING_WHITESPACE ERROR_STRIP_TRAILING_WHITESPACE ) 该命令检查python -c \"import cffi; print(cffi.__version__)\"的输出。如果没有找到模块，stderr将包含ModuleNotFoundError，我们将在if语句中对其进行检查。本例中，我们将打印Module cffi not found。如果导入成功，Python代码将打印模块的版本，该模块通过管道输入stdout，这样就可以打印如下内容: message(STATUS \"Found module ${_module_name} v${stdout}\") 运行结果 mkdir build cd build cmake .. -- Found PythonInterp: /usr/bin/python3.8 (found version \"3.8.10\") -- Module cffi not found -- Configuring done -- Generating done -- Build files have been written to: /home/jiangli/repo/tutorials/cmake-tutorial/chapter5/01/build sudo pip3 install cffi mkdir build cd build cmake .. -- Found module cffi v1.16.0 -- Configuring done -- Generating done -- Build files have been written to: /home/jiangli/repo/tutorials/cmake-tutorial/chapter5/01/build 补充说明 本篇，只打印了结果，但实际项目中，可以警告、中止配置，或者设置可以查询的变量，来切换某些配置选项。 ","date":"2024-01-30","objectID":"/posts/cmake_note_23/:2:0","tags":["CMake"],"title":"CMake 笔记 | [23] 配置时运行自定义命令","uri":"/posts/cmake_note_23/"},{"categories":["C++"],"content":"一、导言 Original jjjstephen Hope Hut 2023-09-21 09:03 Posted on 天津 导言 通过前几篇的学习，我们基本掌握了关于单元测试的相关内容。当然，随着技术的不断发展，根据不同业务的需求测试框架层出不穷，我们没有办法一一列举。本篇我们将补充几个测试的相关技术，如预期失败、并行测试以及测试子集等。 ","date":"2024-01-30","objectID":"/posts/cmake_note_22/:1:0","tags":["CMake"],"title":"CMake 笔记 | [22] 测试的其他补充(重要)","uri":"/posts/cmake_note_22/"},{"categories":["C++"],"content":"二、预期测试失败 理想情况下，我们希望所有的测试能在每个平台上通过。然而，也可能想要测试预期的失败或异常是否会在受控的设置中进行。这种情况下，我们将把预期的失败定义为成功。我们认为，这通常应该交给测试框架(例如：Catch2或Google Test)的任务，它应该检查预期的失败并向CMake报告成功。但是，在某些情况下，可能希望将测试的非零返回代码定义为成功；换句话说，可能想要颠倒成功和失败的定义。 项目结构 . ├── CMakeLists.txt └── test.py 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter4/05 CMakeLists.txt cmake_minimum_required(VERSION 3.5 FATAL_ERROR) project(test_error LANGUAGES NONE) find_package(PythonInterp REQUIRED) enable_testing() add_test(example ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test.py) set_tests_properties(example PROPERTIES WILL_FAIL true) 引用 定义测试并告诉CMake，测试预期会失败: set_tests_properties(example PROPERTIES WILL_FAIL true) 相关源码 test.py import sys # simulate a failing test sys.exit(1) 输出结果 Test project /home/jiangli/repo/tutorials/cmake-tutorial/chapter4/05/build Start 1: example 1/1 Test #1: example .......................... Passed 0.01 sec 100% tests passed, 0 tests failed out of 1 Total Test time (real) = 0.02 sec ","date":"2024-01-30","objectID":"/posts/cmake_note_22/:2:0","tags":["CMake"],"title":"CMake 笔记 | [22] 测试的其他补充(重要)","uri":"/posts/cmake_note_22/"},{"categories":["C++"],"content":"三、使用超时测试运行时间过长的测试 理想情况下，测试集应该花很短的时间进行，以便开发人员经常运行测试，并使每个提交(变更集)进行测试成为可能(或更容易)。然而，有些测试可能会花费更长的时间或者被卡住(例如，由于高文件I/O负载)，可能需要设置超时来终止耗时过长的测试，它们延迟了整个测试，并阻塞了部署管道。本节，将通过一种设置超时的方法，可以针对每个测试设置不同的超时。 项目结构 . ├── CMakeLists.txt └── test.py 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter4/06 CMakeLists.txt cmake_minimum_required(VERSION 3.5 FATAL_ERROR) project(test_long_test LANGUAGES NONE) find_package(PythonInterp REQUIRED) enable_testing() add_test(example ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test.py) set_tests_properties(example PROPERTIES TIMEOUT 10) set_tests_properties(example PROPERTIES TIMEOUT 10) 为测试指定时限，设置为10秒 相关源码 test.py import sys import time # wait for 2 seconds time.sleep(2) # report success sys.exit(0) 输出结果 mkdir build \u0026 cd build cmake .. ctest Test project /home/jiangli/repo/tutorials/cmake-tutorial/chapter4/06/build Start 1: example 1/1 Test #1: example .......................... Passed 2.01 sec 100% tests passed, 0 tests failed out of 1 Total Test time (real) = 2.02 sec 为了验证超时是否有效，将test.py中的sleep命令增加到11秒，并重新运行测试: Test project /home/jiangli/repo/tutorials/cmake-tutorial/chapter4/06/build Start 1: example 1/1 Test #1: example ..........................***Timeout 10.02 sec 0% tests passed, 1 tests failed out of 1 Total Test time (real) = 10.02 sec The following tests FAILED: 1 - example (Timeout) Errors while running CTest ","date":"2024-01-30","objectID":"/posts/cmake_note_22/:3:0","tags":["CMake"],"title":"CMake 笔记 | [22] 测试的其他补充(重要)","uri":"/posts/cmake_note_22/"},{"categories":["C++"],"content":"四、并行测试 大多数现代计算机都有4个或更多个CPU核芯。CTest有个非常棒的特性，能够并行运行测试，如果有多个可用的核。这可以减少测试的总时间。 项目结构 . ├── CMakeLists.txt └── test ├── a.py ├── b.py ├── c.py ├── d.py ├── e.py ├── f.py ├── g.py ├── h.py ├── i.py └── j.py 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter4/07 CMakeLists.txts cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(recipe-08 LANGUAGES NONE) find_package(PythonInterp REQUIRED) enable_testing() add_test(a ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test/a.py) add_test(b ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test/b.py) add_test(c ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test/c.py) add_test(d ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test/d.py) add_test(e ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test/e.py) add_test(f ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test/f.py) add_test(g ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test/g.py) add_test(h ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test/h.py) add_test(i ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test/i.py) add_test(j ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test/j.py 相关源码 这里我们只给出了一个python文件，其他文件按照如下表格设置时间即可。 测试用例 该单元耗时 a,b,c,d 0.5 e,f,g 1.5 h 2.5 i 3.5 j 4.5 a.py import sys import time # wait for 0.5 seconds time.sleep(0.5) # finally report success sys.exit(0) 输出结果 mkdir build \u0026 cd build cmake .. ctest Test project /home/jiangli/repo/tutorials/cmake-tutorial/chapter4/07/build Start 1: a 1/10 Test #1: a ................................ Passed 0.51 sec Start 2: b 2/10 Test #2: b ................................ Passed 0.52 sec Start 3: c 3/10 Test #3: c ................................ Passed 0.52 sec Start 4: d 4/10 Test #4: d ................................ Passed 0.52 sec Start 5: e 5/10 Test #5: e ................................ Passed 1.52 sec Start 6: f 6/10 Test #6: f ................................ Passed 1.52 sec Start 7: g 7/10 Test #7: g ................................ Passed 1.52 sec Start 8: h 8/10 Test #8: h ................................ Passed 2.52 sec Start 9: i 9/10 Test #9: i ................................ Passed 3.52 sec Start 10: j 10/10 Test #10: j ................................ Passed 4.52 sec 100% tests passed, 0 tests failed out of 10 Total Test time (real) = 17.20 sec ctest --parallel 4 Test project /home/jiangli/repo/tutorials/cmake-tutorial/chapter4/07/build Start 10: j Start 9: i Start 8: h Start 7: g 1/10 Test #7: g ................................ Passed 1.51 sec Start 6: f 2/10 Test #8: h ................................ Passed 2.51 sec Start 5: e 3/10 Test #6: f ................................ Passed 1.51 sec Start 4: d 4/10 Test #9: i ................................ Passed 3.52 sec Start 3: c 5/10 Test #4: d ................................ Passed 0.51 sec Start 2: b 6/10 Test #5: e ................................ Passed 1.51 sec Start 1: a 7/10 Test #3: c ................................ Passed 0.51 sec 8/10 Test #2: b ................................ Passed 0.51 sec 9/10 Test #10: j ................................ Passed 4.51 sec 10/10 Test #1: a ................................ Passed 0.51 sec 100% tests passed, 0 tests failed out of 10 Total Test time (real) = 4.54 sec ctest --parallel 8 Test project /home/jiangli/repo/tutorials/cmake-tutorial/chapter4/07/build Start 10: j Start 9: i Start 8: h Start 7: g Start 6: f Start 5: e Start 4: d Start 2: b 1/10 Test #4: d ................................ Passed 0.52 sec Start 3: c 2/10 Test #2: b ................................ Passed 0.52 sec Start 1: a 3/10 Test #3: c ................................ Passed 0.51 sec 4/10 Test #1: a ................................ Passed 0.51 sec 5/10 Test #7: g ................................ Passed 1.52 sec 6/10 Test #6: f ................................ Passed 1.52 sec 7/10 Test #5: e ................................ Passed 1.52 sec 8/10 Test #8: h ................................ Passed 2.52 sec 9/10 Test #9: i .......................","date":"2024-01-30","objectID":"/posts/cmake_note_22/:4:0","tags":["CMake"],"title":"CMake 笔记 | [22] 测试的其他补充(重要)","uri":"/posts/cmake_note_22/"},{"categories":["C++"],"content":"五、运行测试子集 前几节，我们学习了如何在CMake的帮助下并行运行测试，并讨论了从最长的测试开始是最高效的。虽然，这种策略将总测试时间最小化，但是在特定特性的代码开发期间，或者在调试期间，我们可能不希望运行整个测试集。对于调试和代码开发，我们只需要能够运行选定的测试子集。t通过本节我们对这一策略进行进一步探究。 项目结构 . ├── CMakeLists.txt └── test ├── benchmark-a.py ├── benchmark-b.py ├── feature-a.py ├── feature-b.py ├── feature-c.py └── feature-d.py 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter4/08 CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(test_subset LANGUAGES NONE) find_package(PythonInterp REQUIRED) enable_testing() add_test( NAME feature-a COMMAND ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test/feature-a.py ) add_test( NAME feature-b COMMAND ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test/feature-b.py ) add_test( NAME feature-c COMMAND ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test/feature-c.py ) add_test( NAME feature-d COMMAND ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test/feature-d.py ) add_test( NAME benchmark-a COMMAND ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test/benchmark-a.py ) add_test( NAME benchmark-b COMMAND ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test/benchmark-b.py ) set_tests_properties( feature-a feature-b feature-c PROPERTIES LABELS \"quick\" ) set_tests_properties( feature-d benchmark-a benchmark-b PROPERTIES LABELS \"long\" ) 给较短的测试贴上quick的标签，给较长的测试贴上long的标签: set_tests_properties( feature-a feature-b feature-c PROPERTIES LABELS \"quick\" ) set_tests_properties( feature-d benchmark-a benchmark-b PROPERTIES LABELS \"long\" ) 相关源码 我们假设总共有六个测试：前三个测试比较短，名称分别为feature-a、feature-b和feature-c，还有三个长测试，名称分别是feature-d、benchmark-a和benchmark-b。我们只给出feature-a.py，其他只是睡眠时间的不同。 import sys import time # wait for 0.1 seconds time.sleep(1) # finally report success sys.exit(0) 输出结果 ctest -R feature Test project /home/jiangli/repo/tutorials/cmake-tutorial/chapter4/08/build Start 1: feature-a 1/4 Test #1: feature-a ........................ Passed 0.11 sec Start 2: feature-b 2/4 Test #2: feature-b ........................ Passed 0.11 sec Start 3: feature-c 3/4 Test #3: feature-c ........................ Passed 0.11 sec Start 4: feature-d 4/4 Test #4: feature-d ........................ Passed 1.01 sec 100% tests passed, 0 tests failed out of 4 Label Time Summary: long = 1.01 sec*proc (1 test) quick = 0.33 sec*proc (3 tests) Total Test time (real) = 1.36 sec ctest -L long Test project /home/jiangli/repo/tutorials/cmake-tutorial/chapter4/08/build Start 4: feature-d 1/3 Test #4: feature-d ........................ Passed 1.01 sec Start 5: benchmark-a 2/3 Test #5: benchmark-a ...................... Passed 1.01 sec Start 6: benchmark-b 3/3 Test #6: benchmark-b ...................... Passed 1.01 sec 100% tests passed, 0 tests failed out of 3 Label Time Summary: long = 3.04 sec*proc (3 tests) Total Test time (real) = 3.04 sec ctest -L quick Test project /home/jiangli/repo/tutorials/cmake-tutorial/chapter4/08/build Start 1: feature-a 1/3 Test #1: feature-a ........................ Passed 0.11 sec Start 2: feature-b 2/3 Test #2: feature-b ........................ Passed 0.11 sec Start 3: feature-c 3/3 Test #3: feature-c ........................ Passed 0.12 sec 100% tests passed, 0 tests failed out of 3 Label Time Summary: quick = 0.34 sec*proc (3 tests) Total Test time (real) = 0.34 sec ","date":"2024-01-30","objectID":"/posts/cmake_note_22/:5:0","tags":["CMake"],"title":"CMake 笔记 | [22] 测试的其他补充(重要)","uri":"/posts/cmake_note_22/"},{"categories":["C++"],"content":"六、使用测试固件 本节将学习如何使用测试固件。这对于更复杂的测试非常有用，这些测试需要在测试运行前进行设置，以及在测试完成后执行清理操作(例如：创建示例数据库、设置连接、断开连接、清理测试数据库等等)。我们需要运行一个设置或清理操作的测试，并能够以一种可预测和健壮的方式自动触发这些步骤，而不需要引入代码重复。这些设置和清理步骤可以委托给测试框架(例如Google Test或Catch2)。 项目结构 . ├── CMakeLists.txt └── test ├── cleanup.py ├── feature-a.py ├── feature-b.py └── setup.py 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter4/09 CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(test_firmware LANGUAGES NONE) find_package(PythonInterp REQUIRED) enable_testing() add_test( NAME setup COMMAND ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test/setup.py ) set_tests_properties( setup PROPERTIES FIXTURES_SETUP my-fixture ) add_test( NAME feature-a COMMAND ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test/feature-a.py ) add_test( NAME feature-b COMMAND ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test/feature-b.py ) set_tests_properties( feature-a feature-b PROPERTIES FIXTURES_REQUIRED my-fixture ) add_test( NAME cleanup COMMAND ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test/cleanup.py ) set_tests_properties( cleanup PROPERTIES FIXTURES_CLEANUP my-fixture ) add_test( NAME setup COMMAND ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test/setup.py ) set_tests_properties( setup PROPERTIES FIXTURES_SETUP my-fixture ) add_test( NAME feature-a COMMAND ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test/feature-a.py ) add_test( NAME feature-b COMMAND ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test/feature-b.py ) set_tests_properties( feature-a feature-b PROPERTIES FIXTURES_REQUIRED my-fixture ) add_test( NAME cleanup COMMAND ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test/cleanup.py ) set_tests_properties( cleanup PROPERTIES FIXTURES_CLEANUP my-fixture ) 定义了一个文本固件，并将其称为my-fixture。我们为安装测试提供了FIXTURES_SETUP属性，并为清理测试了FIXTURES_CLEANUP属性，并且使用FIXTURES_REQUIRED，我们确保测试feature-a和feature-b都需要安装和清理步骤才能运行。将它们绑定在一起，可以确保在定义良好的状态下，进入和离开相应的步骤。 相关源码 setup.py import sys print(\"tearing down\") # report success sys.exit(0) feature-a.py import sys print(\"running test a\") # report success sys.exit(0) feature-b.py import sys print(\"running test b\") # report success sys.exit(0) clearup.py import sys print(\"tearing down\") # report success sys.exit(0) 输出结果 ctest Test project /home/jiangli/repo/tutorials/cmake-tutorial/chapter4/09/build Start 1: setup 1/4 Test #1: setup ............................ Passed 0.01 sec Start 2: feature-a 2/4 Test #2: feature-a ........................ Passed 0.01 sec Start 3: feature-b 3/4 Test #3: feature-b ........................ Passed 0.01 sec Start 4: cleanup 4/4 Test #4: cleanup .......................... Passed 0.01 sec 100% tests passed, 0 tests failed out of 4 Total Test time (real) = 0.05 sec ctest -R feature-a Test project /home/jiangli/repo/tutorials/cmake-tutorial/chapter4/09/build Start 1: setup 1/3 Test #1: setup ............................ Passed 0.01 sec Start 2: feature-a 2/3 Test #2: feature-a ........................ Passed 0.01 sec Start 4: cleanup 3/3 Test #4: cleanup .......................... Passed 0.01 sec 100% tests passed, 0 tests failed out of 3 Total Test time (real) = 0.03 sec ","date":"2024-01-30","objectID":"/posts/cmake_note_22/:6:0","tags":["CMake"],"title":"CMake 笔记 | [22] 测试的其他补充(重要)","uri":"/posts/cmake_note_22/"},{"categories":["C++"],"content":"一、导言 导言 *目前，内存缺陷：写入或读取越界，或者内存泄漏（已分配但从未释放的内存），会生产难以跟踪的*bug*，最好尽早将它们检查出来。**Valgrind*是一个通用的工具，用来检测内存缺陷和内存泄漏。本篇将在使用*CMake/CTest*测试时使用*Valgrind*对内存问题进行警告。 ","date":"2024-01-30","objectID":"/posts/cmake_note_21/:1:0","tags":["CMake"],"title":"CMake 笔记 | [21] 利用Valgrind来检测内存缺陷","uri":"/posts/cmake_note_21/"},{"categories":["C++"],"content":"二、Valgrind安装 下载Valgrind wget https://sourceware.org/pub/valgrind/valgrind-3.21.0.tar.bz2 解压 tar -xjvf valgrind-3.15.0.tar.bz2 cd valgrind-3.21.0 配置 ./configure 编译 make 安装 sudo make install ","date":"2024-01-30","objectID":"/posts/cmake_note_21/:2:0","tags":["CMake"],"title":"CMake 笔记 | [21] 利用Valgrind来检测内存缺陷","uri":"/posts/cmake_note_21/"},{"categories":["C++"],"content":"三、项目结构 . ├── CMakeLists.txt ├── leaky_implementation.cpp ├── leaky_implementation.h └── test.cpp 项目结构： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter4/04 CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(test_leaky LANGUAGES CXX) set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_EXTENSIONS OFF) set(CMAKE_CXX_STANDARD_REQUIRED ON) add_library(example_library leaky_implementation.cpp) add_executable(cpp_test test.cpp) target_link_libraries(cpp_test example_library) find_program(MEMORYCHECK_COMMAND NAMES valgrind) set(MEMORYCHECK_COMMAND_OPTIONS \"--trace-children=yes --leak-check=full\") # add memcheck test action include(CTest) enable_testing() add_test( NAME cpp_test COMMAND $\u003cTARGET_FILE:cpp_test\u003e ) 引用 find_program(MEMORYCHECK_COMMAND NAMES valgrind) 查找valgrind，并将MEMORYCHECK_COMMAND设置为其绝对路径。 引用 set(MEMORYCHECK_COMMAND_OPTIONS \"--trace-children=yes --leak-check=full\") 将相关参数传递给Valgrind。内存检查会创建一个日志文件，该文件可用于详细记录内存缺陷信息。 相关源码 leaky_implementation.h #ifndef LEAKY_IMPLEMENTATION_H #define LEAKY_IMPLEMENTATION_H int DoSomeWork(); #endif // ！LEAKY_IMPLEMENTATION_H leaky_implementation.cpp #include \"leaky_implementation.h\" int DoSomeWork() { // we allocate an array double *default_array = new double[1000]; // do some work // ... // we forget to deallocate it // delete[] default_array; return 0; } test.cpp #include \"leaky_implementation.h\" int main() { int ret = DoSomeWork(); return ret; } 输出结果 Site: jiangli-virtual-machine Build name: Linux-g++ Memory check project /home/jiangli/repo/tutorials/cmake-tutorial/chapter4/04/build Start 1: cpp_test 1/1 MemCheck #1: cpp_test ......................... Passed 1.03 sec 100% tests passed, 0 tests failed out of 1 Total Test time (real) = 1.03 sec -- Processing memory checking output: 1/1 MemCheck: #1: cpp_test ......................... Defects: 1 MemCheck log files can be found here: ( * corresponds to test number) /home/jiangli/repo/tutorials/cmake-tutorial/chapter4/04/build/Testing/Temporary/MemoryChecker.*.log Memory checking results: Memory Leak - 1 ","date":"2024-01-30","objectID":"/posts/cmake_note_21/:3:0","tags":["CMake"],"title":"CMake 笔记 | [21] 利用Valgrind来检测内存缺陷","uri":"/posts/cmake_note_21/"},{"categories":["C++"],"content":"一、导言 导言 本篇，我们将学习如何在CMake的帮助下使用Google Test框架实现单元测试。与前一个配置（Catch2）相比，Google Test框架不仅仅是一个头文件，也是一个库，包含两个需要构建和链接的文件。可以将它们与我们的代码项目放在一起，但是为了使项目更加轻量级，我们将选择在配置时，下载一个定义良好的Google Test，然后构建框架并链接它。我们将使用较新的FetchContent模块（从CMake版本3.11开始可用）。关于相关使用将在后续的笔记中学习。 此外我们将在相关测试内同学习完成后挑选一个测试框架（目前Google Test更加流行）*写一个小的项目实践，尽可能多的将该框架下的功能加以熟悉。* ","date":"2024-01-28","objectID":"/posts/cmake_note_20/:1:0","tags":["CMake"],"title":"CMake 笔记 | [20] 利用Google Test库进行单元测试","uri":"/posts/cmake_note_20/"},{"categories":["C++"],"content":"二、项目结构 NOTE: main.cpp、sum_integers.cpp和sum_integers.hpp与上一篇内容相同，我们对test.cpp将做相关的修改。 . ├── CMakeLists.txt ├── main.cpp ├── sum_integers.cpp ├── sum_integers.h └── test.cpp 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter4/03 ","date":"2024-01-28","objectID":"/posts/cmake_note_20/:2:0","tags":["CMake"],"title":"CMake 笔记 | [20] 利用Google Test库进行单元测试","uri":"/posts/cmake_note_20/"},{"categories":["C++"],"content":"三、项目代码 CMakeLists.txt cmake_minimum_required(VERSION 3.11 FATAL_ERROR) project(test_gtest LANGUAGES CXX) set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_EXTENSIONS OFF) set(CMAKE_CXX_STANDARD_REQUIRED ON) set(CMAKE_WINDOWS_EXPORT_ALL_SYMBOLS ON) add_library(sum_integers sum_integers.cpp) add_executable(sum_up main.cpp) target_link_libraries(sum_up sum_integers) option(ENABLE_UNIT_TESTS \"Enable unit tests\" ON) message(STATUS \"Enable testing: ${ENABLE_UNIT_TESTS}\") if(ENABLE_UNIT_TESTS) include(FetchContent) FetchContent_Declare( googletest GIT_REPOSITORY https://gitcode.net/mirrors/google/googletest.git GIT_TAG release-1.8.0 ) FetchContent_GetProperties(googletest) if(NOT googletest_POPULATED) FetchContent_Populate(googletest) # Prevent GoogleTest from overriding our compiler/linker options # when building with Visual Studio set(gtest_force_shared_crt ON CACHE BOOL \"\" FORCE) # Prevent GoogleTest from using PThreads set(gtest_disable_pthreads ON CACHE BOOL \"\" FORCE) # adds the targers: gtest, gtest_main, gmock, gmock_main add_subdirectory( ${googletest_SOURCE_DIR} ${googletest_BINARY_DIR} ) # Silence std::tr1 warning on MSVC if(MSVC) foreach(_tgt gtest gtest_main gmock gmock_main) target_compile_definitions(${_tgt} PRIVATE \"_SILENCE_TR1_NAMESPACE_DEPRECATION_WARNING\" ) endforeach() endif() endif() add_executable(cpp_test \"\") target_sources(cpp_test PRIVATE test.cpp ) target_link_libraries(cpp_test PRIVATE sum_integers gtest_main ) enable_testing() add_test( NAME google_test COMMAND $\u003cTARGET_FILE:cpp_test\u003e ) endif() **注意:**CMake 3.11版本以后才可以使用FetchContent模块。 引用 set(CMAKE_WINDOWS_EXPORT_ALL_SYMBOLS ON) 告诉CMake在 Windows 平台上自动从共享库（DLL）中导出所有符号（函数、变量、类等）。 当将此选项设置为 ON 时，CMake会自动在库的代码中插入导出指令，确保它们可以被外部链接。这在 Windows 上特别重要，因为需要明确的导出声明才能让符号从 DLL 外部访问。 然而，启用此选项可能会导致生成较大的二进制文件，并可能意外地暴露符号。如果链接了多个库，还可能导致符号冲突。因此，虽然它简化了符号的导出，但需要仔细考虑其影响，以及是否适用于自己的项目。 引用 option(ENABLE_UNIT_TESTS \"Enable unit tests\" ON) message(STATUS \"Enable testing: ${ENABLE_UNIT_TESTS}\") if(ENABLE_UNIT_TESTS) # all the remaining CMake code will be placed here endif() 检查ENABLE_UNIT_TESTS。默认情况下，它为ON，但有时需要设置为OFF，以免在没有网络连接时，也能使用Google Test。 引用 include(FetchContent) FetchContent_Declare( googletest GIT_REPOSITORY https://gitcode.net/mirrors/google/googletest.git GIT_TAG release-1.8.0 ) 使用了FetchContent模块来下载和集成Google Test库（googletest）。 include(FetchContent)：用于包含FetchContent模块，该模块允许在项目中获取外部依赖项。 FetchContent_Declare(googletest ...)：使用FetchContent_Declare宏来声明要获取的外部依赖项。在这种情况下，它声明了一个名为googletest的外部依赖项。 GIT_REPOSITORY：这是指定用于获取库的Git存储库的URL。 GIT_TAG：这是Git存储库中的特定标签或分支，指定希望获取的库的版本。在这里，它指定了Google Test库的版本为release-1.8.0。 使用这段代码后，当构建项目时，CMake将尝试下载并集成Google Test库，以便可以在项目中进行单元测试。请注意，实际项目中可能还需要在测试目标中链接Google Test库，并设置测试用例等。 引用 if(NOT googletest_POPULATED) FetchContent_Populate(googletest) # Prevent GoogleTest from overriding our compiler/linker options # when building with Visual Studio set(gtest_force_shared_crt ON CACHE BOOL \"\" FORCE) # Prevent GoogleTest from using PThreads set(gtest_disable_pthreads ON CACHE BOOL \"\" FORCE) # adds the targers: gtest, gtest_main, gmock, gmock_main add_subdirectory( ${googletest_SOURCE_DIR} ${googletest_BINARY_DIR} ) # Silence std::tr1 warning on MSVC if(MSVC) foreach(_tgt gtest gtest_main gmock gmock_main) target_compile_definitions(${_tgt} PRIVATE \"_SILENCE_TR1_NAMESPACE_DEPRECATION_WARNING\" ) endforeach() endif() endif() if(NOT googletest_POPULATED)：检查是否已经获取并集成了Google Test库。如果googletest_POPULATED未定义，则会执行其中的代码块。 FetchContent_Populate(googletest)：将下载的Google Test库内容填充到指定的目录，以便后续构建和集成。 set(gtest_force_shared_crt ON CACHE BOOL \"\" FORCE)：在使用Visual Studio构建时，将强制Google Test使用共享运行时（C Runtime）库。可以避免构建时的链接错误。 set(gtest_disable_pthreads ON CACHE BOOL \"\" FORCE)：禁用Google Test对pthreads的使用。这可能在某些环境中是必需的，例如在没有pthreads支持的平台上。 add_subdirectory(...)：将Google Test库添加到项目中。它会在指定的源码目录和二进制目录中进行构建。 对于Microsoft Visual Studio（MSVC），在构建Google Test库时，通过target_compile_definitions为gtest、gtest_main、gmock和gmock_main目标添加了宏定义以消除MSVC下的警告。 相关源码 test.cpp #include \"sum_integers.h\" #include \"gtest/gtest.h\" #includ","date":"2024-01-28","objectID":"/posts/cmake_note_20/:3:0","tags":["CMake"],"title":"CMake 笔记 | [20] 利用Google Test库进行单元测试","uri":"/posts/cmake_note_20/"},{"categories":["C++"],"content":"一、导言 导言 *上一篇，我们通过返回码来表示**test.cpp*测试的成功或者失败。对于简单的功能没问题，但是通常情况下，我们想要使用一个测试框架，它提供了相关基础设施来运行更复杂的测试，包括固定方式进行测试，与数值公差进行比较，以及在测试失败时输出更好的错误报告。本篇，通过使用目前比较流行的测试库Catch2来进行探索相关内容。这个测试框架有个很好的特性，它可以通过单个头文件包含在项目中进行测试，这使得编译和更新框架特别容易。通过CMake和Catch2结合使用，来测试上一篇的求和代码。 ","date":"2024-01-28","objectID":"/posts/cmake_note_19/:1:0","tags":["CMake"],"title":"CMake 笔记 | [19] 利用Catch2库进行单元测试","uri":"/posts/cmake_note_19/"},{"categories":["C++"],"content":"二、项目结构 NOTE 本项目中Catch使用的版本是2.0.1，目前已经更新到3.4.0。关于最新版本的使用我们将在本系列最后开启一个具体的小型项目探索测试框架。 . ├── catch.hpp ├── CMakeLists.txt ├── main.cpp ├── sum_integers.cpp ├── sum_integers.h └── test.cpp 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter4/02 CMakeLists.txt # set minimum cmake version cmake_minimum_required(VERSION 3.10 FATAL_ERROR) # project name and language project(test_catch2 LANGUAGES CXX) # require C++11 set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_EXTENSIONS OFF) set(CMAKE_CXX_STANDARD_REQUIRED ON) # example library add_library(sum_integers sum_integers.cpp) # main code add_executable(sum_up main.cpp) target_link_libraries(sum_up sum_integers) # testing binary add_executable(cpp_test test.cpp) target_link_libraries(cpp_test sum_integers) enable_testing() add_test( NAME catch_test COMMAND $\u003cTARGET_FILE:cpp_test\u003e --success ) 引用 add_test( NAME catch_test COMMAND $\u003cTARGET_FILE:cpp_test\u003e --success ) --success选项可传递给单元测试的可执行文件。这是一个Catch2选项，测试成功时，也会有输出。 相关源码 main.cpp、sum_integers.cpp和sum_integers.h与之前的示例相同。 test.cpp #include \u003cvector\u003e #include \"sum_integers.h\" // this tells catch to provide a main() // only do this in one cpp file #define CATCH_CONFIG_MAIN #include \"catch.hpp\" TEST_CASE(\"Sum of integers for a short vector\", \"[shirt]\") { auto integers = {1, 2, 3, 4, 5}; REQUIRE(sum_integers(integers) == 15); } TEST_CASE(\"Sum of integers for a longer vector\", \"[long]\") { std::vector\u003cint\u003e integers; for (int i = 1; i \u003c 1001; ++i) { integers.push_back(i); } REQUIRE(sum_integers(integers) == 500500); } 输出结果: mkdir -p build cd build cmake .. cmake --build . ctest -V UpdateCTestConfiguration from :/home/jiangli/repo/tutorials/cmake-tutorial/chapter4/02/build/DartConfiguration.tcl UpdateCTestConfiguration from :/home/jiangli/repo/tutorials/cmake-tutorial/chapter4/02/build/DartConfiguration.tcl Test project /home/jiangli/repo/tutorials/cmake-tutorial/chapter4/02/build Constructing a list of tests Done constructing a list of tests Updating test list for fixtures Added 0 tests to meet fixture requirements Checking test dependency graph... Checking test dependency graph end test 1 Start 1: catch_test 1: Test command: /home/jiangli/repo/tutorials/cmake-tutorial/chapter4/02/build/cpp_test \"--success\" 1: Test timeout computed to be: 10000000 1: 1: ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 1: cpp_test is a Catch v2.0.1 host application. 1: Run with -? for options 1: 1: ------------------------------------------------------------------------------- 1: Sum of integers for a short vector 1: ------------------------------------------------------------------------------- 1: /home/jiangli/repo/tutorials/cmake-tutorial/chapter4/02/test.cpp:13 1: ............................................................................... 1: 1: /home/jiangli/repo/tutorials/cmake-tutorial/chapter4/02/test.cpp:15: 1: PASSED: 1: REQUIRE( sum_integers(integers) == 15 ) 1: with expansion: 1: 15 == 15 1: 1: ------------------------------------------------------------------------------- 1: Sum of integers for a longer vector 1: ------------------------------------------------------------------------------- 1: /home/jiangli/repo/tutorials/cmake-tutorial/chapter4/02/test.cpp:18 1: ............................................................................... 1: 1: /home/jiangli/repo/tutorials/cmake-tutorial/chapter4/02/test.cpp:23: 1: PASSED: 1: REQUIRE( sum_integers(integers) == 500500 ) 1: with expansion: 1: 500500 (0x7a314) == 500500 (0x7a314) 1: 1: =============================================================================== 1: All tests passed (2 assertions in 2 test cases) 1: 1/1 Test #1: catch_test ....................... Passed 0.00 sec 100% tests passed, 0 tests failed out of 1 Total Test time (real) = 0.00 sec 测试cpp_test的二进制文件，可以直接从Catch2中看到输出： ./cpp_test --success ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ cpp_test is a Catch v2.0.1 host application. Run with -? for op","date":"2024-01-28","objectID":"/posts/cmake_note_19/:2:0","tags":["CMake"],"title":"CMake 笔记 | [19] 利用Catch2库进行单元测试","uri":"/posts/cmake_note_19/"},{"categories":["C++"],"content":"三、附录 Catch2是一个单头文件测试框架，所以不需要定义和构建额外的目标。只需要确保CMake能找到catch.hpp，从而构建test.cpp即可。为了方便起见，将它放在与test.cpp相同的目录中，我们可以选择一个不同的位置，并使用target_include_directory指示该位置。另一种方法是将头部封装到接口库中： # Prepare \"Catch\" library for other executables set(CATCH_INCLUDE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/catch) add_library(Catch INTERFACE) target_include_directories(Catch INTERFACE ${CATCH_INCLUDE_DIR}) 然后，对库进行如下链接: target_link_libraries(cpp_test Catch) Catch2提供了更多功能。有关Catch2框架的完整文档，可访问： https://github.com/catchorg/Catch2 Catch2代码库包含有CMake函数，用于解析Catch测试并自动创建CMake测试，不需要显式地输入add_test()函数，可见： https://github.com/catchorg/Catch2/blob/master/contrib/ParseAndAddCatchTests.cmake ","date":"2024-01-28","objectID":"/posts/cmake_note_19/:3:0","tags":["CMake"],"title":"CMake 笔记 | [19] 利用Catch2库进行单元测试","uri":"/posts/cmake_note_19/"},{"categories":["C++"],"content":"一、导言 导言 CTest是CMake的测试工具，本篇通过编写和测试能够对整数求和的代码，以窥探CTest其中的功能一二。为了说明CMake没有对实际测试的语言进行任何限制，我们不仅使用C++可执行文件测试代码，还使用Python脚本和shell脚本作为测试代码。为了简单起见，我们将不使用任何测试库来实现，但是我们将在后面的笔记中熟悉C++测试框架。 ","date":"2024-01-28","objectID":"/posts/cmake_note_18/:1:0","tags":["CMake"],"title":"CMake 笔记 | [18] 利用CTest进行单元测试","uri":"/posts/cmake_note_18/"},{"categories":["C++"],"content":"二、项目结构 . ├── CMakeLists.txt ├── main.cpp ├── sum_integers.cpp ├── sum_integers.h ├── test.cpp ├── test.py └── test.sh 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter4/01 CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(test_ctest LANGUAGES CXX) set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_EXTENSIONS OFF) set(CMAKE_CXX_STANDARD_REQUIRED ON) find_package(PythonInterp REQUIRED) find_program(BASH_EXECUTABLE NAMES bash REQUIRED) # example library add_library(sum_integers sum_integers.cpp) # main code add_executable(sum_up main.cpp) target_link_libraries(sum_up sum_integers) # testing binary add_executable(cpp_test test.cpp) target_link_libraries(cpp_test sum_integers) enable_testing() add_test( NAME bash_test COMMAND ${BASH_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test.sh $\u003cTARGET_FILE:sum_up\u003e ) add_test( NAME cpp_test COMMAND $\u003cTARGET_FILE:cpp_test\u003e ) add_test( NAME python_test_long COMMAND ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test.py --executable $\u003cTARGET_FILE:sum_up\u003e ) add_test( NAME python_test_short COMMAND ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test.py --short --executable $\u003cTARGET_FILE:sum_up\u003e ) 引用 find_program(BASH_EXECUTABLE NAMES bash REQUIRED) 用于查找系统中的bash可执行文件，并将可执行文件的路径存储在变量BASH_EXECUTABLE中。这可以用于在CMake构建过程中执行bash脚本或命令。 引用 enable_testing() 测试这个目录和所有子文件夹(因为我们把它放在主CMakeLists.txt)。 Tips add_test( NAME cpp_test COMMAND $\u003cTARGET_FILE:cpp_test\u003e ) 定义了一个新的测试，并设置测试名称和运行命令。 上述代码中，使用了生成器表达式:$\u003cTARGET_FILE:cpp_test\u003e。生成器表达式，是在生成构建系统生成时的表达式。我们将在后续的学习内容中介绍和学习生成器表达式。然后，可以声明$\u003cTARGET_FILE:cpp_test\u003e变量，将使用cpp_test可执行目标的完整路径进行替换。 NOTE: 生成器表达式在测试时非常方便，因为不必显式地将可执行程序的位置和名称，可以硬编码到测试中。以一种可移植的方式实现这一点非常麻烦，因为可执行文件和可执行后缀(例如，Windows上是.exe后缀)的位置在不同的操作系统、构建类型和生成器之间可能有所不同。使用生成器表达式，我们不必显式地了解位置和名称。 也可以将参数传递给要运行的test命令： add_test( NAME python_test_short COMMAND ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test.py --short --executable $\u003cTARGET_FILE:sum_up\u003e ) NOTE CTest可以以任何编程语言运行测试集。CTest关心的是，通过命令的返回码测试用例是否通过。CTest遵循的标准约定是：返回零意味着成功，非零返回意味着失败。可以返回零或非零的脚本，都可以做测试用例。 相关源码 sum_integers.h #ifndef SUM_INTEGERS_H #define SUM_INTEGERS_H #include \u003cvector\u003e int sum_integers(const std::vector\u003cint\u003e \u0026integers); #endif // ! SUM_INTEGERS_H sum_integers.cpp #include \"sum_integers.h\" int sum_integers(const std::vector\u003cint\u003e\u0026 integers) { auto sum = 0; for (auto i : integers) { sum += i; } return sum; } main.cpp #include \u003ciostream\u003e #include \u003cstring\u003e #include \"sum_integers.h\" int main(int argc, char *argv[]) { std::vector\u003cint\u003e integers; for (auto i = 1; i \u003c argc; i++) { integers.push_back(std::stoi(argv[i])); } auto sum = sum_integers(integers); std::cout \u003c\u003c sum \u003c\u003c std::endl; return 0; } test.cpp #include \"sum_integers.h\" int main() { auto integers = {1, 2, 3, 4, 5}; if (sum_integers(integers) == 15) { return 0; } else { return 1; } } test.py import subprocess import argparse # test script expects the executable as argument parser = argparse.ArgumentParser() parser.add_argument('--executable', help='full path to executable') parser.add_argument('--short', default=False, action='store_true', help='run a shorter test') args = parser.parse_args() def execute_cpp_code(integers): result = subprocess.check_output([args.executable] + integers) return int(result) if args.short: # we collect [1, 2, ..., 100] as a list of strings result = execute_cpp_code([str(i) for i in range(1, 101)]) assert result == 5050, 'summing up to 100 failed' else: # we collect [1, 2, ..., 1000] as a list of strings result = execute_cpp_code([str(i) for i in range(1, 1001)]) assert result == 500500, 'summing up to 1000 failed' test.sh #!/usr/bin/env bash EXECUTABLE=$1 OUTPUT=$($EXECUTABLE 1 2 3 4) if [ \"$OUTPUT\" = \"10\" ] then exit 0 else exit 1 fi ","date":"2024-01-28","objectID":"/posts/cmake_note_18/:2:0","tags":["CMake"],"title":"CMake 笔记 | [18] 利用CTest进行单元测试","uri":"/posts/cmake_note_18/"},{"categories":["C++"],"content":"三、附录 1. 考虑以下定义: add_test( NAME python_test_long COMMAND ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/test.py --executable $\u003cTARGET_FILE:sum_up\u003e ) 前面的定义可以通过显式指定脚本运行的WORKING_DIRECTORY重新表达，如下: add_test( NAME python_test_long COMMAND ${PYTHON_EXECUTABLE} test.py --executable $\u003cTARGET_FILE:sum_up\u003e WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR} ) 测试名称可以包含/字符，按名称组织相关测试也很有用，例如： add_test( NAME python/long COMMAND ${PYTHON_EXECUTABLE} test.py --executable $\u003cTARGET_FILE:sum_up\u003e WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR} ) 有时候，我们需要为测试脚本设置环境变量。这可以通过set_tests_properties实现: set_tests_properties(python_test PROPERTIES ENVIRONMENT ACCOUNT_MODULE_PATH=${CMAKE_CURRENT_SOURCE_DIR} ACCOUNT_HEADER_FILE=${CMAKE_CURRENT_SOURCE_DIR}/account/account.h ACCOUNT_LIBRARY_FILE=$\u003cTARGET_FILE:account\u003e ) 这种方法在不同的平台上并不总可行，CMake提供了解决这个问题的方法。下面的代码片段与上面给出的代码片段相同，在执行实际的Python测试脚本之前，通过CMAKE_COMMAND调用CMake来预先设置环境变量： add_test( NAME python_test COMMAND ${CMAKE_COMMAND} -E env ACCOUNT_MODULE_PATH=${CMAKE_CURRENT_SOURCE_DIR} ACCOUNT_HEADER_FILE=${CMAKE_CURRENT_SOURCE_DIR}/account/account.h ACCOUNT_LIBRARY_FILE=$\u003cTARGET_FILE:account\u003e ${PYTHON_EXECUTABLE} ${CMAKE_CURRENT_SOURCE_DIR}/account/test.py ) 同样，要注意使用生成器表达式$\u003cTARGET_FILE:account\u003e来传递库文件的位置。 2. 不同平台测试命令 我们已经使用ctest命令执行测试，CMake还将为生成器创建目标(Unix Makefile生成器为make test，Ninja工具为ninja test，或者Visual Studio为RUN_TESTS)。这意味着，还有另一种(几乎)可移植的方法来运行测试： $ cmake --build . --target test 当使用Visual Studio生成器时，我们需要使用RUN_TESTS来代替: $ cmake --build . --target RUN_TESTS ","date":"2024-01-28","objectID":"/posts/cmake_note_18/:3:0","tags":["CMake"],"title":"CMake 笔记 | [18] 利用CTest进行单元测试","uri":"/posts/cmake_note_18/"},{"categories":["C++"],"content":"一、导言 导言 目前上一篇，我们了解了CMake其中一种自定义检测外部库的方式，本篇将展示通过编写一个find模块来定位系统上的ZeroMQ库，以能够在非操作系统上检测该库。 ","date":"2024-01-28","objectID":"/posts/cmake_note_17/:1:0","tags":["CMake"],"title":"CMake 笔记 | [17] 检测外部库 -- 自定义find模块","uri":"/posts/cmake_note_17/"},{"categories":["C++"],"content":"二、项目结构 . ├── CMakeLists.txt ├── FindZeroMQ.cmake ├── zmq_client.cpp └── zmq_server.cpp 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter3/06 注：相关cpp源码与上一篇相同。 CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(test_zmq LANGUAGES CXX) set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_EXTENSIONS OFF) set(CMAKE_CXX_STANDARD_REQUIRED ON) set(CMAKE_PREFIX_PATH /opt/zmq) list(APPEND CMAKE_MODULE_PATH ${CMAKE_CURRENT_SOURCE_DIR}) find_package(ZeroMQ REQUIRED) add_executable(hw_server zmq_server.cpp) target_include_directories(hw_server PRIVATE ${ZeroMQ_INCLUDE_DIRS} ) target_link_libraries(hw_server PRIVATE ${ZeroMQ_LIBRARIES} ) add_executable(hw_client zmq_client.cpp) target_include_directories(hw_client PRIVATE ${ZeroMQ_INCLUDE_DIRS} ) target_link_libraries(hw_client PRIVATE ${ZeroMQ_LIBRARIES} ) 引用 list(APPEND CMAKE_MODULE_PATH ${CMAKE_CURRENT_SOURCE_DIR}) 这行代码是用于在CMake中向CMAKE_MODULE_PATH变量中添加一个目录的路径。通常，CMAKE_MODULE_PATH用于存放自定义的CMake模块文件，这些模块文件可以在项目的CMakeLists.txt文件中通过include等命令来使用。 具体而言，这行代码的作用是将${CMAKE_CURRENT_SOURCE_DIR}添加到CMAKE_MODULE_PATH中。${CMAKE_CURRENT_SOURCE_DIR}表示当前CMakeLists.txt所在的目录，即源代码目录。这样做的目的是为了告诉CMake在这个目录中查找自定义的CMake模块。 这样CMake就可以找到，我们自定义的FindZeroMQ.cmake模块。 此示例的主CMakeLists.txt在使用FindZeroMQ.cmake时，与上一篇中使用的CMakeLists.txt不同。这个模块使用find_path和find_library CMake内置命令，搜索ZeroMQ头文件和库，并使用find_package_handle_standard_args设置相关变量。 FindZeroMQ.cmake if(NOT ZeroMQ_ROOT) set(ZeroMQ_ROOT \"$ENV{ZeroMQ_ROOT}\") endif() if(NOT ZeroMQ_ROOT) find_path(_ZeroMQ_ROOT NAMES include/zmq.h) else() set(_ZeroMQ_ROOT \"${ZeroMQ_ROOT}\") endif() find_path(ZeroMQ_INCLUDE_DIRS NAMES zmq.h HINTS ${_ZeroMQ_ROOT}/include) if(ZeroMQ_INCLUDE_DIRS) set(_ZeroMQ_H ${ZeroMQ_INCLUDE_DIRS}/zmq.h) function(_zmqver_EXTRACT _ZeroMQ_VER_COMPONENT _ZeroMQ_VER_OUTPUT) set(CMAKE_MATCH_1 \"0\") set(_ZeroMQ_expr \"^[ \\\\t]*#define[ \\\\t]+${_ZeroMQ_VER_COMPONENT}[ \\\\t]+([0-9]+)$\") file(STRINGS \"${_ZeroMQ_H}\" _ZeroMQ_ver REGEX \"${_ZeroMQ_expr}\") string(REGEX MATCH \"${_ZeroMQ_expr}\" ZeroMQ_ver \"${_ZeroMQ_ver}\") set(${_ZeroMQ_VER_OUTPUT} \"${CMAKE_MATCH_1}\" PARENT_SCOPE) endfunction() _zmqver_EXTRACT(\"ZMQ_VERSION_MAJOR\" ZeroMQ_VERSION_MAJOR) _zmqver_EXTRACT(\"ZMQ_VERSION_MINOR\" ZeroMQ_VERSION_MINOR) _zmqver_EXTRACT(\"ZMQ_VERSION_PATCH\" ZeroMQ_VERSION_PATCH) // We should provide version to find_package_handle_standard_args in the same format as it was requested, // otherwise it can't check whether version matches exactly. if(ZeroMQ_FIND_VERSION_COUNT GREATER 2) set(ZeroMQ_VERSION \"${ZeroMQ_VERSION_MAJOR}.${ZeroMQ_VERSION_MINOR}.${ZeroMQ_VERSION_PATCH}\") else() // User has requested ZeroMQ version without patch part =\u003e user is not interested in specific patch =\u003e // any patch should be an exact match. set(ZeroMQ_VERSION \"${ZeroMQ_VERSION_MAJOR}.${ZeroMQ_VERSION_MINOR}\") endif() if(NOT ${CMAKE_C_PLATFORM_ID} STREQUAL \"Windows\") find_library(ZeroMQ_LIBRARIES NAMES zmq HINTS ${_ZeroMQ_ROOT}/lib ${_ZeroMQ_ROOT}/lib/x86_64-linux-gnu ) else() find_library(ZeroMQ_LIBRARIES NAMES libzmq \"libzmq-mt-${ZeroMQ_VERSION_MAJOR}_${ZeroMQ_VERSION_MINOR}_${ZeroMQ_VERSION_PATCH}\" \"libzmq-${CMAKE_VS_PLATFORM_TOOLSET}-mt-${ZeroMQ_VERSION_MAJOR}_${ZeroMQ_VERSION_MINOR}_${ZeroMQ_VERSION_PATCH}\" libzmq_d \"libzmq-mt-gd-${ZeroMQ_VERSION_MAJOR}_${ZeroMQ_VERSION_MINOR}_${ZeroMQ_VERSION_PATCH}\" \"libzmq-${CMAKE_VS_PLATFORM_TOOLSET}-mt-gd-${ZeroMQ_VERSION_MAJOR}_${ZeroMQ_VERSION_MINOR}_${ZeroMQ_VERSION_PATCH}\" HINTS ${_ZeroMQ_ROOT}/lib ) endif() endif() include(FindPackageHandleStandardArgs) find_package_handle_standard_args(ZeroMQ FOUND_VAR ZeroMQ_FOUND REQUIRED_VARS ZeroMQ_INCLUDE_DIRS ZeroMQ_LIBRARIES VERSION_VAR ZeroMQ_VERSION ) 引用 if(NOT ZeroMQ_ROOT) set(ZeroMQ_ROOT \"$ENV{ZeroMQ_ROOT}\") endif() 如果ZeroMQ_ROOT变量没有被设置，就尝试从环境变量中获取该路径并设置到ZeroMQ_ROOT变量中。这样的设计可以让我们在不修改CMakeLists.txt文件的情况下，通过设置环境变量来指定ZeroMQ库的路径。 引用 if(NOT ZeroMQ_ROOT) find_path(_ZeroMQ_ROOT NAMES include/zmq.h) else() set(_ZeroMQ_ROOT \"${ZeroMQ_ROOT}\") endif() find_path(ZeroMQ_INCLUDE_DIRS NAMES zmq.h HINTS ${_Ze","date":"2024-01-28","objectID":"/posts/cmake_note_17/:2:0","tags":["CMake"],"title":"CMake 笔记 | [17] 检测外部库 -- 自定义find模块","uri":"/posts/cmake_note_17/"},{"categories":["C++"],"content":"三、附录 find-module通常遵循特定的模式: 检查用户是否为所需的包提供了自定义位置。 使用find_家族中的命令搜索所需包的必需组件，即头文件、库、可执行程序等等。我们使用find_path查找头文件的完整路径，并使用find_library查找库。CMake还提供find_file、find_program和find_package。这些命令的参数示意如下: find_path(\u003cVAR\u003e NAMES name PATHS paths) 如果搜索成功，\u003cVAR\u003e将保存搜索结果；如果搜索失败，则会设置为\u003cVAR\u003e-NOTFOUND。NAMES和PATHS分别是CMake应该查找的文件的名称和搜索应该指向的路径。 初步搜索的结果中，可以提取版本号。本例中，ZeroMQ头文件包含库版本，可以使用字符串操作和正则表达式提取库版本信息。 最后，调用find_package_handle_standard_args命令。处理find_package命令的REQUIRED、QUIET和版本参数，并设置ZeroMQ_FOUND变量。 总结：有四种方式可用于找到依赖包。 使用由包供应商提供CMake文件\u003cpackage\u003eConfig.cmake ，\u003cpackage\u003eConfigVersion.cmake和\u003cpackage\u003eTargets.cmake，通常会在包的标准安装位置查找。 无论是由CMake还是第三方提供的模块，为所需包使用find-module。 使用pkg-config，如本篇的示例所示。 如果这些都不可行，那么编写自己的find模块。 这四种可选方案按相关性进行了排序，每种方法也都有其挑战。 目前，并不是所有的包供应商都提供CMake的Find文件，不过正变得越来越普遍。因为导出CMake目标，使得第三方代码很容易使用它所依赖的库和/或程序附加的依赖。 从一开始，Find-module就一直是CMake中定位依赖的主流手段。但是，它们中的大多数仍然依赖于设置依赖项使用的变量，比如Boost_INCLUDE_DIRS、PYTHON_INTERPRETER等等。这种方式很难在第三方发布自己的包时，确保依赖关系被满足。 使用pkg-config的方法可以很好地进行适配，因为它已经成为Unix系统的标准。然而，也由于这个原因，它不是一个完全跨平台的方法。此外，如CMake文档所述，在某些情况下，用户可能会意外地覆盖检测包，并导致pkg-config提供不正确的信息。 最后的方法是编写自己的查找模块脚本，就像本示例中那样。这是可行的，并且依赖于FindPackageHandleStandardArgs.cmake。然而，编写一个全面的查找模块脚本绝非易事，需要考虑很多可能性。 最后祝大家变得更强！ ![Image](data:image/svg+xml,%3C%3Fxml version=‘1.0’ encoding=‘UTF-8’%3F%3E%3Csvg width=‘1px’ height=‘1px’ viewBox=‘0 0 1 1’ version=‘1.1’ xmlns=‘http://www.w3.org/2000/svg' xmlns:xlink=‘http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke=‘none’ stroke-width=‘1’ fill=‘none’ fill-rule=‘evenodd’ fill-opacity=‘0’%3E%3Cg transform=‘translate(-249.000000, -126.000000)’ fill=’%23FFFFFF’%3E%3Crect x=‘249’ y=‘126’ width=‘1’ height=‘1’%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E) ![Image](data:image/svg+xml,%3C%3Fxml version=‘1.0’ encoding=‘UTF-8’%3F%3E%3Csvg width=‘1px’ height=‘1px’ viewBox=‘0 0 1 1’ version=‘1.1’ xmlns=‘http://www.w3.org/2000/svg' xmlns:xlink=‘http://www.w3.org/1999/xlink'%3E%3Ctitle%3E%3C/title%3E%3Cg stroke=‘none’ stroke-width=‘1’ fill=‘none’ fill-rule=‘evenodd’ fill-opacity=‘0’%3E%3Cg transform=‘translate(-249.000000, -126.000000)’ fill=’%23FFFFFF’%3E%3Crect x=‘249’ y=‘126’ width=‘1’ height=‘1’%3E%3C/rect%3E%3C/g%3E%3C/g%3E%3C/svg%3E) cmake44 cmake · 目录 上一篇CMake:检测外部库—使用pkg-config下一篇CMake:利用CTest进行单元测试 People who liked this content also liked CMake:超级构建模式 Hope Hut 不喜欢 不看的原因 OK 内容质量低 不看此公众号 IDEA 2023.3 爆了！ 架构汪 不喜欢 不看的原因 OK 内容质量低 不看此公众号 CMake: 构建时记录Git Hash值 Hope Hut 不喜欢 不看的原因 OK 内容质量低 不看此公众号 Scan to Follow people underline ","date":"2024-01-28","objectID":"/posts/cmake_note_17/:3:0","tags":["CMake"],"title":"CMake 笔记 | [17] 检测外部库 -- 自定义find模块","uri":"/posts/cmake_note_17/"},{"categories":["C++"],"content":"一、检测外部库—使用pkg-config 导言 前面几篇内容的学习，我们基本上了解了如何链接一个三方库的方法。本篇以及下一篇将补充两个检测外部库的方法。 目前为止，我们已经学习了两种检测外部依赖关系的方法： 使用CMake自带的find-module，但并不是所有的包在CMake的find模块都找得到。 使用\u003cpackage\u003eConfig.cmake ,\u003cpackage\u003eConfigVersion.cmake和\u003cpackage\u003eTargets.cmake，这些文件由软件包供应商提供，并与软件包一起安装在标准位置的cmake文件夹下。 如果某个依赖项既不提供查找模块，也不提供供应商的CMake文件，在这种情况下： 依赖pkg-config程序，来找到系统上的包。这依赖于包供应商在.pc配置文件中，其中有关于发行包的元数据。 为依赖项编写自己的find-package模块。 接下来，我们通过ZMQ的使用，来演示第一种方法的使用。 ","date":"2024-01-28","objectID":"/posts/cmake_note_16/:0:0","tags":["CMake"],"title":"CMake 笔记 | [16] 检测外部库---使用pkg-config","uri":"/posts/cmake_note_16/"},{"categories":["C++"],"content":"二、ZMQ的安装 ZMQ下载： https://github.com/zeromq 下载好后解压, 并进入目录：： tar -xzvf libzmq-4.3.4.tar.gz . cd libzmq-4.3.4 开始安装 ./autogen.sh 使用prefix来指定安装目录 ./configure --prefix=/opt/zmq/ --without-libsodium make sudo make install ","date":"2024-01-28","objectID":"/posts/cmake_note_16/:1:0","tags":["CMake"],"title":"CMake 笔记 | [16] 检测外部库---使用pkg-config","uri":"/posts/cmake_note_16/"},{"categories":["C++"],"content":"三、项目结构 . ├── CMakeLists.txt ├── zmq_client.cpp └── zmq_server.cpp 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter3/05 CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(test_zmq LANGUAGES CXX) set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_EXTENSIONS OFF) set(CMAKE_CXX_STANDARD_REQUIRED ON) set(CMAKE_PREFIX_PATH /opt/zmq) find_package(PkgConfig REQUIRED QUIET) pkg_search_module( ZeroMQ REQUIRED libzeromq libzmq lib0mq IMPORTED_TARGET ) if(TARGET PkgConfig::ZeroMQ) message(STATUS \"Found ZeroMQ\") endif() add_executable(hw_server zmq_server.cpp) target_link_libraries(hw_server PkgConfig::ZeroMQ) add_executable(hw_client zmq_client.cpp) target_link_libraries(hw_client PkgConfig::ZeroMQ) 使用pkg_search_module通搜索任何附带包配置.pc文件的库或程序来查找和导入ZeroMQ库。这个命令会在CMake中通过PkgConfig工具查找和配置ZeroMQ库。 pkg_search_module( ZeroMQ REQUIRED libzeromq libzmq lib0mq IMPORTED_TARGET ) ZeroMQ的信息将会被存储在一个导入目标中，其名称是PkgConfig::ZeroMQ，可以将这个目标链接到可执行文件或库。 导入目标 相关源码 zmq_client.cpp #include \u003cstdio.h\u003e #include \u003cstring.h\u003e #include \u003cunistd.h\u003e #include \u003czmq.h\u003e int main() { void *context = zmq_ctx_new(); void *requester = zmq_socket(context, ZMQ_REQ); int rc = zmq_connect(requester, \"tcp://localhost:5555\"); if (rc != 0) { perror(\"Failed to connect to server\"); return 1; } while (true) { char buffer[] = \"Hello\"; zmq_send(requester, buffer, sizeof(buffer), 0); char reply[10]; zmq_recv(requester, reply, sizeof(reply), 0); printf(\"Received: %s\\n\", reply); sleep(10); } zmq_close(requester); zmq_ctx_destroy(context); return 0; } zmq_server.cpp include \u003cstdio.h\u003e #include \u003cstring.h\u003e #include \u003cunistd.h\u003e #include \u003czmq.h\u003e int main() { void *context = zmq_ctx_new(); void *responder = zmq_socket(context, ZMQ_REP); int rc = zmq_bind(responder, \"tcp://*:5555\"); if (rc != 0) { perror(\"Failed to bind socket\"); return 1; } while (1) { char buffer[10]; zmq_recv(responder, buffer, sizeof(buffer), 0); printf(\"Received: %s\\n\", buffer); zmq_send(responder, \"World\", 5, 0); } zmq_close(responder); zmq_ctx_destroy(context); return 0; } 构建项目，并执行 $ mkdir -p build $ cd build $ cmake .. $ cmake --build . 执行生成的两个进程结果： 输出结果 ","date":"2024-01-28","objectID":"/posts/cmake_note_16/:2:0","tags":["CMake"],"title":"CMake 笔记 | [16] 检测外部库---使用pkg-config","uri":"/posts/cmake_note_16/"},{"categories":["C++"],"content":"一、检测并使用OpenMP的并行环境 导言 目前，市面上的计算机几乎都是多核机器，对于性能敏感的程序，我们必须关注这些多核处理器，并在编程模型中使用并发。OpenMP是多核处理器上并行性的标准之一。为了从OpenMP并行化中获得性能收益，通常不需要修改或重写现有程序。一旦确定了代码中的性能关键部分，例如：使用分析工具，我们就可以借助OpenMP通过预处理器指令，指示编译器为这些区域生成可并行的代码。 ","date":"2024-01-27","objectID":"/posts/cmake_note_15/:1:0","tags":["CMake"],"title":"CMake 笔记 | [15] 检测并使用OpenMP的并行环境","uri":"/posts/cmake_note_15/"},{"categories":["C++"],"content":"二、OpenMP简介 OpenMP（Open Multi-Processing）是一个用于共享内存多处理器计算机体系结构的并行编程模型。它提供了一套用于并行化应用程序的指令集和编程接口，使得开发者能够更容易地在多核处理器上实现并行计算。以下是关于OpenMP的一些基本介绍： 1. 并行性模型： OpenMP旨在简化并行程序的编写过程，它基于共享内存架构，其中多个处理器核心共享同一内存。每个核心都可以访问所有内存位置，因此通过共享数据来实现并行计算。 2. 指令注释： OpenMP使用一种通过在现有代码中插入特殊的指令注释来实现并行性的方法。这些指令告诉编译器在代码中的哪些部分可以并行执行，以及如何在并行执行期间处理共享的数据。 3. 线程级并行： OpenMP将任务分解成多个线程，每个线程在不同的处理器核心上运行。每个线程都可以独立地执行指定的任务，这样可以充分利用多核处理器的计算能力。 4. 并行语法： OpenMP使用预处理器指令、函数注释以及库函数来实现并行性。可以通过在代码中插入特定的编译器指令来标识需要并行执行的代码块。 5. 数据共享与同步： 在多线程并行计算中，共享数据的访问需要特别注意。OpenMP提供了一些机制，如原子操作和临界段，以确保数据的正确共享和同步。 6. 跨平台： OpenMP支持许多不同的操作系统和编译器，使得开发者可以在各种平台上使用相同的并行代码。 7. 编译器支持： 大多数现代编译器都支持OpenMP，并可以通过在编译时启用OpenMP选项来生成并行代码。 8. 灵活性： OpenMP提供了不同级别的并行性，从单一的for循环并行到更复杂的任务并行。 9. 用途广泛： OpenMP适用于许多领域，包括科学计算、数据分析、图像处理等，使得在多核处理器上提高应用程序性能变得更加简单。 总之，OpenMP是一个用于共享内存并行编程的强大工具，它通过为开发者提供简单且高效的方式来实现多核处理器上的并行计算，帮助优化性能并加速应用程序的执行。 ","date":"2024-01-27","objectID":"/posts/cmake_note_15/:2:0","tags":["CMake"],"title":"CMake 笔记 | [15] 检测并使用OpenMP的并行环境","uri":"/posts/cmake_note_15/"},{"categories":["C++"],"content":"三、项目代码 项目结构 . ├── CMakeLists.txt ├── test_no_openmp.cpp └── test_openmp.cpp 为了窥探使用OpenMP与不使用OpenMP之间的差异性，项目中新建了两个进程以验证其性能，具体性能表现参考最后一部分的输出结果。 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter3/04 CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(test_openmp LANGUAGES CXX) set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_EXTENSIONS OFF) set(CMAKE_CXX_STANDARD_REQUIRED ON) find_package(OpenMP REQUIRED) add_executable(test_openmp test_openmp.cpp) target_link_libraries(test_openmp PUBLIC OpenMP::OpenMP_CXX ) add_executable(test_no_openmp test_no_openmp.cpp) target_link_libraries(test_no_openmp PUBLIC OpenMP::OpenMP_CXX ) 引用 find_package(OpenMP REQUIRED) 调用find_package来搜索OpenMP。 引用 add_executable(example example.cpp) target_link_libraries(example PUBLIC OpenMP::OpenMP_CXX ) 链接到FindOpenMP模块提供的导入目标。 相关源码 test_openmp.cpp #include \u003comp.h\u003e #include \u003ciostream\u003e #include \u003cstring\u003e int main(int argc, char *argv[]) { std::cout \u003c\u003c \"number of available processors: \" \u003c\u003c omp_get_num_procs() \u003c\u003c std::endl; std::cout \u003c\u003c \"number of threads: \" \u003c\u003c omp_get_max_threads() \u003c\u003c std::endl; auto n = 1000000000; std::cout \u003c\u003c \"we will form sum of numbers from 1 to \" \u003c\u003c n \u003c\u003c std::endl; // start timer auto t0 = omp_get_wtime(); auto s = 0LL; #pragma omp parallel for reduction(+ : s) for (auto i = 1; i \u003c= n; i++) { s += i; } // stop timer auto t1 = omp_get_wtime(); std::cout \u003c\u003c \"sum: \" \u003c\u003c s \u003c\u003c std::endl; std::cout \u003c\u003c \"elapsed wall clock time: \" \u003c\u003c t1 - t0 \u003c\u003c \" seconds\" \u003c\u003c std::endl; return 0; } test_no_openmp.cpp #include \u003comp.h\u003e #include \u003ciostream\u003e #include \u003cstring\u003e int main(int argc, char *argv[]) { auto n = 1000000000; std::cout \u003c\u003c \"we will form sum of numbers from 1 to \" \u003c\u003c n \u003c\u003c std::endl; // start timer auto t0 = omp_get_wtime(); auto s = 0LL; for (auto i = 1; i \u003c= n; i++) { s += i; } // stop timer auto t1 = omp_get_wtime(); std::cout \u003c\u003c \"sum: \" \u003c\u003c s \u003c\u003c std::endl; std::cout \u003c\u003c \"elapsed wall clock time: \" \u003c\u003c t1 - t0 \u003c\u003c \" seconds\" \u003c\u003c std::endl; return 0; } 输出结果: $ mkdir -p build $ cd build $ cmake .. $ cmake --build . $./test_openmp number of available processors: 16 number of threads: 16 we will form sum of numbers from 1 to 1000000000 sum: 500000000500000000 elapsed wall clock time: 0.15193 seconds $./test_no_openmp torials/cmake-tutorial/chapter3/04/build/test_openmp number of available processors: 16 number of threads: 16 we will form sum of numbers from 1 to 1000000000 sum: 500000000500000000 ","date":"2024-01-27","objectID":"/posts/cmake_note_15/:3:0","tags":["CMake"],"title":"CMake 笔记 | [15] 检测并使用OpenMP的并行环境","uri":"/posts/cmake_note_15/"},{"categories":["C++"],"content":"一、检测Python模块和包 引用 上一篇，我们基本了解了如何检测python的解释器和python库。通常，代码是依赖于特定的python模块的，无论是python工具、嵌入python的程序，还是扩展python的库。例如，numpy包。依赖于python模块或包的项目中，确定满足对这些python模块的依赖非常重要。 ","date":"2024-01-27","objectID":"/posts/cmake_note_14/:1:0","tags":["CMake"],"title":"CMake 笔记 | [14] 检测Python模块和包","uri":"/posts/cmake_note_14/"},{"categories":["C++"],"content":"二、项目结构 ├── CMakeLists.txt ├── py3_pure_embedding.cpp └── use_numpy.py 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter3/03 CMakeLists.txt cmake_minimum_required(VERSION 3.5 FATAL_ERROR) project(python_module LANGUAGES CXX) set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_EXTENSIONS OFF) set(CMAKE_CXX_STANDARD_REQUIRED ON) find_package(PythonInterp REQUIRED) find_package(PythonLibs ${PYTHON_VERSION_MAJOR}.${PYTHON_VERSION_MINOR} EXACT REQUIRED) execute_process( COMMAND ${PYTHON_EXECUTABLE} \"-c\" \"import re, numpy; print(re.compile('/__init__.py.*').sub('',numpy.__file__))\" RESULT_VARIABLE numpy_status OUTPUT_VARIABLE numpy_location ERROR_QUIET OUTPUT_STRIP_TRAILING_WHITESPACE ) if(NOT numpy_status) set(NumPy ${numpy_location} CACHE STRING \"Location of NumPy\") endif() execute_process( COMMAND ${PYTHON_EXECUTABLE} \"-c\" \"import numpy; print(numpy.__version__)\" OUTPUT_VARIABLE numpy_version ERROR_QUIET OUTPUT_STRIP_TRAILING_WHITESPACE ) include(FindPackageHandleStandardArgs) find_package_handle_standard_args(NumPy FOUND_VAR NumPy_FOUND REQUIRED_VARS NumPy VERSION_VAR numpy_version ) add_executable(pure-embedding py3_pure_embedding.cpp) target_include_directories(pure-embedding PRIVATE ${PYTHON_INCLUDE_DIRS} ) target_link_libraries(pure-embedding PRIVATE ${PYTHON_LIBRARIES} ) add_custom_command( OUTPUT ${CMAKE_CURRENT_BINARY_DIR}/use_numpy.py COMMAND ${CMAKE_COMMAND} -E copy_if_different ${CMAKE_CURRENT_SOURCE_DIR}/use_numpy.py ${CMAKE_CURRENT_BINARY_DIR}/use_numpy.py DEPENDS ${CMAKE_CURRENT_SOURCE_DIR}/use_numpy.py ) # make sure building pure-embedding triggers the above custom command target_sources(pure-embedding PRIVATE ${CMAKE_CURRENT_BINARY_DIR}/use_numpy.py ) Tip execute_process( COMMAND ${PYTHON_EXECUTABLE} \"-c\" \"import re, numpy; print(re.compile('/__init__.py.*').sub('',numpy.__file__))\" RESULT_VARIABLE numpy_status OUTPUT_VARIABLE numpy_location ERROR_QUIET OUTPUT_STRIP_TRAILING_WHITESPACE ) 使用了CMake的execute_process函数来运行一个python脚本。该脚本导入了re和numpy模块，然后使用re.compile函数来替换numpy模块路径中的一个模式。RESULT_VARIABLE用于捕获python脚本执行的状态，而OUTPUT_VARIABLE用于捕获修改后的numpy模块文件的位置。通过使用ERROR_QUIET来抑制进程生成的任何错误，并且使用OUTPUT_STRIP_TRAILING_WHITESPACE来移除输出中的尾随空格。 Tip if(NOT numpy_status) set(NumPy ${numpy_location} CACHE STRING \"Location of NumPy\") endif() 如果numpy_status不为空，那么设置了一个名为NumPy的CMake缓存变量，其值为numpy_location，这个变量用于存储NumPy库的位置信息。这个操作允许在CMake配置过程中指定NumPy的位置，以便后续的构建过程可以使用它。如果numpy_status为空，则不进行任何操作。 Tip execute_process( COMMAND ${PYTHON_EXECUTABLE} \"-c\" \"import numpy; print(numpy.__version__)\" OUTPUT_VARIABLE numpy_version ERROR_QUIET OUTPUT_STRIP_TRAILING_WHITESPACE ) 这段代码使用execute_process命令来执行一个python脚本。 ${PYTHON_EXECUTABLE} 是一个CMake变量，用于指定python可执行文件的路径。 -c 选项告诉python解释器后面紧跟着的字符串是要执行的python代码。 在这个python代码中，首先导入了numpy库，然后使用print函数输出了numpy库的版本号。 OUTPUT_VARIABLE 选项用于捕获python代码的输出，即numpy库的版本号。 ERROR_QUIET 选项用于忽略可能的错误信息。 OUTPUT_STRIP_TRAILING_WHITESPACE 选项用于移除输出字符串末尾的空格。 通过这个操作，可以在CMake配置过程中获取并保存numpy库的版本号，以便后续的构建过程可以使用。 Tip add_custom_command( OUTPUT ${CMAKE_CURRENT_BINARY_DIR}/use_numpy.py COMMAND ${CMAKE_COMMAND} -E copy_if_different ${CMAKE_CURRENT_SOURCE_DIR}/use_numpy.py ${CMAKE_CURRENT_BINARY_DIR}/use_numpy.py DEPENDS ${CMAKE_CURRENT_SOURCE_DIR}/use_numpy.py ) 使用 CMake 中的 add_custom_command 命令，用于定义自定义的构建步骤，以及生成相应的输出文件。 OUTPUT 指定了生成的输出文件，这里是 ${CMAKE_CURRENT_BINARY_DIR}/use_numpy.py。 COMMAND 指定了生成输出文件所需要执行的命令，这里是将 ${CMAKE_CURRENT_SOURCE_DIR}/use_numpy.py 复制到 ${CMAKE_CURRENT_BINARY_DIR}/use_numpy.py。 DEPENDS 列出了生成输出文件所依赖的文件，这里是 ${CMAKE_CURRENT_SOURCE_DIR}/use_numpy.py。 这段代码的作用是在构建过程中，如果 ${CMAKE_CURRENT_SOURCE_DIR}/use_numpy.py 发生变化，就执行指定的命令来将该文件复制到构建目录 ${CMAKE_CURRENT_BINARY_DIR} 下的相同路径。这可以确保在构建过程中，始终使用最新的 use_numpy.py 文件。 Tip target_sources(pure-embedding PRIVATE ${CMAKE_CURRENT_BINARY_DIR}/use_numpy.py ) 在 CMake 的构建过程中为名为 pure-embedding 的目标（通常是一个可执行文件或库）指定了源文件。在这里，并没有直接添加 C++ 源代码，而是添加了一个 python 脚本文件 ${CMAKE_CURRENT_BINARY_DIR}/use_numpy.py。 这意味着在构建 pure-embedding 目标时，CMake 会将 ${CMAKE_CURRENT_BINARY_DIR}/use_numpy.py 视为目标的源文件之一，并确","date":"2024-01-27","objectID":"/posts/cmake_note_14/:2:0","tags":["CMake"],"title":"CMake 笔记 | [14] 检测Python模块和包","uri":"/posts/cmake_note_14/"},{"categories":["C++"],"content":"一、检测python解释器和python库 导言 python是一种非常流行的语言。许多项目用python编写的工具，从而将主程序和库打包在一起，或者在配置或构建过程中使用python脚本。这种情况下，确保运行时python解释器的依赖也需要得到满足。本篇将展示如何检测和使用python解释器。 除此之外，还有其他方法可以将解释语言(如python)与编译语言(如C或C++)组合在一起使用。一种是扩展python，通过编译成共享库的C或C++模块在这些类型上提供新类型和新功能。另一种是将python解释器嵌入到C或C++程序中。两种方法都需要下列条件: python解释器的工作版本 python头文件python.h的可用性 python运行时库libpython ","date":"2024-01-27","objectID":"/posts/cmake_note_13/:1:0","tags":["CMake"],"title":"CMake 笔记 | [13] 检测python解释器和python库","uri":"/posts/cmake_note_13/"},{"categories":["C++"],"content":"二、检测python解释器 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter3/01 CMakeLists.txt文件 cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(python_interperter LANGUAGES NONE) find_package(PythonInterp REQUIRED) execute_process( COMMAND ${PYTHON_EXECUTABLE} \"-c\" \"print('Hello, python interpreter!')\" RESULT_VARIABLE RESULT_STATUS OUTPUT_VARIABLE RESULT_OUTPUT ERROR_QUIET OUTPUT_STRIP_TRAILING_WHITESPACE ) # message(STATUS \"RESULT_VARIABLE is: ${RESULT_STATUS}\") # message(STATUS \"OUTPUT_VARIABLE is: ${RESULT_OUTPUT}\") include(CMakePrintHelpers) cmake_print_variables(RESULT_STATUS RESULT_OUTPUT) 引用 find_package(PythonInterp REQUIRED) 使用find_package命令找到python解释器。 find_package是用于发现和设置包的CMake模块的命令。这些模块包含CMake命令，用于标识系统标准位置中的包。CMake模块文件称为Find\u003cname\u003e.cmake，当调用find_package(\u003cname\u003e)时，模块中的命令将会运行。 除了在系统上实际查找包模块之外，查找模块还会设置了一些有用的变量，反映实际找到了什么，也可以在自己的CMakeLists.txt中使用这些变量。对于python解释器，相关模块为FindPythonInterp.cmake附带的设置了一些CMake变量: PYTHONINTERP_FOUND：是否找到解释器 PYTHON_EXECUTABLE：python解释器到可执行文件的路径 PYTHON_VERSION_STRING：python解释器的完整版本信息 PYTHON_VERSION_MAJOR：python解释器的主要版本号 PYTHON_VERSION_MINOR ：python解释器的次要版本号 PYTHON_VERSION_PATCH：python解释器的补丁版本号 可以强制CMake，查找特定版本的包。例如，要求python解释器的版本大于或等于2.7：find_package(PythonInterp 2.7)。 CMake有很多查找软件包的模块。建议在CMake在线文档中查询Find\u003cpackage\u003e.cmake模块，并在使用它们之前详细阅读它们的文档。find_package命令的文档可以参考 : https://cmake.org/cmake/help/v3.5/command/find_ackage.html 引用 execute_process( COMMAND ${PYTHON_EXECUTABLE} \"-c\" \"print('Hello, world!')\" RESULT_VARIABLE _status OUTPUT_VARIABLE _hello_world ERROR_QUIET OUTPUT_STRIP_TRAILING_WHITESPACE ) 执行python命令并捕获它的输出和返回值。 输出 -- Found PythonInterp: /usr/bin/python3.8 (found version \"3.8.10\") -- RESULT_VARIABLE is: 0 -- OUTPUT_VARIABLE is: Hello, python interpreter! -- Configuring done -- Generating done -- Build files have been written to: /home/jiangli/repo/tutorials/cmake-tutorial/chapter3/01/build 附录 软件包没有安装在标准位置时，CMake无法正确定位它们。用户可以使用-D参数传递相应的选项，告诉CMake查看特定的位置。python解释器可以使用以下配置: $ cmake -D PYTHON_EXECUTABLE=/custom/location/python .. 这将指定非标准/custom/location/python安装目录中的python可执行文件。 注意:每个包都是不同的，Find\u003cpackage\u003e.cmake模块试图提供统一的检测接口。当CMake无法找到模块包时，可以阅读相应检测模块的文档，以了解如何正确地使用CMake模块。可以在终端中直接浏览文档，可使用cmake --help-module FindPythonInterp查看。 除了检测包之外，我们还想提到一个便于打印变量的helper模块: message(STATUS \"RESULT_VARIABLE is: ${_status}\") message(STATUS \"OUTPUT_VARIABLE is: ${_hello_world}\") 使用以下工具进行调试: include(CMakePrintHelpers) cmake_print_variables(_status _hello_world) 将产生以下输出: -- _status=\"0\" ; _hello_world=\"Hello, world!\" 三、检测python库 项目结构 . ├── CMakeLists.txt └── hello_embedded_python.c 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter3/02 CMakeLists.txt文件 cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(link_python LANGUAGES C) set(CMAKE_C_STANDARD 99) set(CMAKE_C_EXTENSIONS OFF) set(CMAKE_C_STANDARD_REQUIRED ON) find_package(PythonInterp REQUIRED) find_package(PythonLibs ${PYTHON_VERSION_MAJOR}.${PYTHON_VERSION_MINOR} EXACT REQUIRED) add_executable(hello_embedded_python hello_embedded_python.c) target_include_directories(hello_embedded_python PRIVATE ${PYTHON_INCLUDE_DIRS} ) target_link_libraries(hello_embedded_python PRIVATE ${PYTHON_LIBRARIES} ) 为了确保可执行文件、头文件和库都有一个匹配的版本。这对于不同版本，可能在运行时导致崩溃。通过FindPythonInterp.cmake中定义的PYTHON_VERSION_MAJOR和PYTHON_VERSION_MINOR来实现: find_package(PythonInterp REQUIRED) find_package(PythonLibs ${PYTHON_VERSION_MAJOR}.${PYTHON_VERSION_MINOR} EXACT REQUIRED) 可执行文件包含python.h头文件。因此，这个目标的include目录必须包含python的include目录，可以通过PYTHON_INCLUDE_DIRS变量进行指定: target_include_directories(hello_embedded_python PRIVATE ${PYTHON_INCLUDE_DIRS} ) 将可执行文件链接到python库，通过PYTHON_LIBRARIES变量访问: target_link_libraries(hello_embedded_python PRIVATE ${PYTHON_LIBRARIES} ) 相关源码 #include \u003cPython.h\u003e int main(int argc, char *argv[]) { /* optional but recommended */ Py_SetProgramName(argv[0]); Py_Initialize(); PyRun_SimpleString(\"print('Today is Tuesday!')\\n\"); Py_Finalize(); return 0; } 附录 当python不在标准安装目录中，如何确定python头文件和库的位置是正确的？ 对于python解释器，可以通过-D选项传递PYTHON_LIBRARY和PYTHON","date":"2024-01-27","objectID":"/posts/cmake_note_13/:2:0","tags":["CMake"],"title":"CMake 笔记 | [13] 检测python解释器和python库","uri":"/posts/cmake_note_13/"},{"categories":["C++"],"content":"一、CMake:为Eigen库使能向量化 导言 本篇开始将涉及检测外部库相关的内容，期间会穿插着一些其他的内容。为了能够使得系统在系统中运行Eigen库，我们首先需要在系统中配置好Eigen库。然后介绍与Eigen库相关的CMake配置。 ","date":"2024-01-26","objectID":"/posts/cmake_note_12/:1:0","tags":["CMake"],"title":"CMake 笔记 | [12] 检测环境","uri":"/posts/cmake_note_12/"},{"categories":["C++"],"content":"二、构建Eigen Windows 从官网下载安装包(下载ZIP格式)： https://eigen.tuxfamily.org/index.php?title=Main_Page Eigen 下载官网截图 解压到某一路径中,使用cmake编译。这里以vs15以及x64为例： Cmake 编译截图 Cmake 编译截图 选择输出路径并点击generate： CMake 编译截图 VS打开项目 打开项目 在vs2015中生成INSTALL。右键点击“生成”： 生成eigen库 将生成后的库添加到环境变量中： 添加环境变量 ubuntu 从官网下载安装包(下载tar.gz格式)： https://eigen.tuxfamily.org/index.php?title=Main_Page 下载Eigen Eigen包安装 下载完成后，对压缩包进行解压后（解压在home目录即可），运行如下命令进行安装： cd (eigen文件夹中) mkdir build cd build cmake .. sudo make install 将eigen文件复制到本地调用文件夹中（/usr/include） sudo cp -r /usr/local/include/eigen3 /usr/include ","date":"2024-01-26","objectID":"/posts/cmake_note_12/:2:0","tags":["CMake"],"title":"CMake 笔记 | [12] 检测环境","uri":"/posts/cmake_note_12/"},{"categories":["C++"],"content":"三、Linear_algebra项目举例 项目结构 . ├── CMakeLists.txt └── linear_algebra.cpp 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter2/05 CMakeLists.txt文件 cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(eigen_tensor LANGUAGES CXX) set(CMAKE_CXX_STANDARD 11) set(CMAKE_CXX_EXTENSIONS OFF) set(CMAKE_CXX_STANDARD_REQUIRED ON) find_package(Eigen3 3.4 REQUIRED CONFIG) include(CheckCXXCompilerFlag) check_cxx_compiler_flag(\"-march=native\" _march_native_works) check_cxx_compiler_flag(\"-xHost\" _xhost_works) set(_CXX_FLAGS) if(_march_native_works) message(STATUS \"Using processor's vector instructions (-march=native compiler flag set)\") set(_CXX_FLAGS \"-march=native\") elseif(_xhost_works) message(STATUS \"Using processor's vector instructions (-xHost compiler flag set)\") set(_CXX_FLAGS \"-xHost\") else() message(STATUS \"No suitable compiler flag found for vectorization\") endif() add_executable(linear-algebra-unoptimized linear_algebra.cpp) target_link_libraries(linear-algebra-unoptimized PRIVATE Eigen3::Eigen ) add_executable(linear-algebra linear_algebra.cpp) target_compile_options(linear-algebra PRIVATE ${_CXX_FLAGS} ) target_link_libraries(linear-algebra PRIVATE Eigen3::Eigen ) ```find_package(Eigen3 3.4 REQUIRED CONFIG)``` find_package 是CMake中的一个命令，用于查找和加载特定的第三方库（例如Eigen3）的CMake配置文件。 Eigen3 是一个用于线性代数计算的C++模板库，它提供了矩阵、向量、矢量计算等功能。通过在CMake中使用 find_package(Eigen3 3.4 REQUIRED CONFIG) 命令，告诉CMake去查找Eigen3库，并且要求它的版本至少是3.4。REQUIRED 参数表示如果找不到Eigen3库，CMake将会报错并停止构建。 CONFIG 参数指示CMake查找Eigen3的CMake配置文件（通常是 Eigen3Config.cmake 或类似名称），其中包含有关库的信息和设置。 一旦找到Eigen3库的CMake配置文件，CMake会加载该配置文件并设置相关的变量，例如 EIGEN3_INCLUDE_DIR，其中包含了Eigen3库的头文件路径。在接下来的CMake构建中，你可以使用这些设置的变量来链接和包含Eigen3库。 ```include(CheckCXXCompilerFlag)``` 在CMake中，include(CheckCXXCompilerFlag) 是一个用于检查C++编译器标志是否可用的CMake命令。 这个命令的作用是为了检查特定的C++编译器标志是否受支持。在某些情况下，需要根据编译器的不同来启用或禁用一些特性或优化选项。 使用这个命令的一般形式是： include(CheckCXXCompilerFlag \u003cflag\u003e) 其中\u003cflag\u003e是你要检查的C++编译器标志，例如 -std=c++11、-fPIC 等。 此命令将尝试将指定的编译器标志添加到C++源代码，并编译一个简单的测试程序来检查编译器是否支持该标志。如果支持，那么CMake将定义一个CMake变量，例如 CMAKE_REQUIRED_FLAGS 或 CMAKE_REQUIRED_LIBRARIES，来表示该标志是可用的。 通过这种方式，可以在CMake脚本中根据编译器支持情况进行条件编译或设置不同的选项。 例如，假设我们要检查编译器是否支持C++11标准： include(CheckCXXCompilerFlag) check_cxx_compiler_flag(\"-std=c++11\" COMPILER_SUPPORTS_CXX11) if (COMPILER_SUPPORTS_CXX11) # 设置C++11标准 set(CMAKE_CXX_STANDARD 11) message(STATUS \"C++11 supported by the compiler.\") else () message(FATAL_ERROR \"C++11 is not supported by the compiler.\") endif () check_cxx_compiler_flag(\"-march=native\" _march_native_works) check_cxx_compiler_flag(\"-xHost\" _xhost_works) set(_CXX_FLAGS) if(_march_native_works) message(STATUS \"Using processor's vector instructions (-march=native compiler flag set)\") set(_CXX_FLAGS \"-march=native\") elseif(_xhost_works) message(STATUS \"Using processor's vector instructions (-xHost compiler flag set)\") set(_CXX_FLAGS \"-xHost\") else() message(STATUS \"No suitable compiler flag found for vectorization\") endif() 这段CMake代码片段用于检查编译器是否支持特定的矢量指令优化标志，并根据结果设置 _CXX_FLAGS 变量以启用适当的矢量化优化。 -march=native 是一个编译器标志，用于告诉编译器根据当前主机的处理器架构来优化生成的机器码。这个标志会让编译器针对当前的 CPU 架构生成最优化的代码，以充分利用处理器的特性和指令集。 例如，在使用 -march=native 标志编译代码时，如果你的计算机的处理器支持 AVX2 指令集，编译器将会针对 AVX2 进行优化。如果运行这个优化过的代码在支持 AVX2 的处理器上，它将能够获得更高的性能。 请注意，使用 -march=native 标志编译代码可能会导致生成的可执行文件在其他不同架构的计算机上运行不正确或不稳定。因此，在分发或共享可执行文件时，最好使用更加通用的编译选项，除非确实需要充分利用特定处理器架构的优化。 -xHost 是 Intel 编译器的编译选项，用于指示编译器使用主机处理器支持的最高级别的指令集来优化生成的机器码。 类似于 -march=native，-xHost 也会让编译器根据当前主机的处理器架构来选择最优化的指令集。它会自动根据当前系统的处理器类型来决定使用最高级别的指令集，以充分利用处理器的性能和功能。 然而，与 -march=native 不同的是，-xHost 是特定于 Intel 编译器的选项，而不是在其他编译器中通用的标志。 请注意，与 -march=native 一样，使用 -xHost 也可能会导致生成的可执行文件在其他不同架构的计算机上运行不正确或不稳定，因此在分发或共享可执行文件时需谨慎使用。 相关源码 linear_algebra.cpp #include \u003ceigen3/Eigen/Dense\u003e #include \u003cchrono\u003e #include \u003ciostream\u003e EIGEN_DONT_INLINE double simple_function(Eigen::VectorXd \u0026va, Eigen::VectorXd \u0026vb) { // this simple function computes the dot product of two vectors // of course it could be expressed more compactly double d = va.dot(vb); return d; } int main() { int len = 1","date":"2024-01-26","objectID":"/posts/cmake_note_12/:3:0","tags":["CMake"],"title":"CMake 笔记 | [12] 检测环境","uri":"/posts/cmake_note_12/"},{"categories":["C++"],"content":"一、CMake:检测环境 导言 通过前面几篇的学习，我们掌握CMake以及与C++相关的基本知识。尽管CMake跨平台，但有时源代码并不是完全可移植。为了使得我们的源代码能够跨平台、操作系统和编译器，根据平台不同的方式配置和/或构建代码是在构建项目过程中必不可少的环节。 ","date":"2024-01-26","objectID":"/posts/cmake_note_11/:1:0","tags":["CMake"],"title":"CMake 笔记 | [11] 检测环境","uri":"/posts/cmake_note_11/"},{"categories":["C++"],"content":"二、检测操作系统 CMake是一组跨平台工具。在实际的开发过程中，我们需要操作系统相关的CMake代码，会根据操作系统启用条件编译，或者在可用或必要时使用特定于编译器的扩展。 这里举个特定示例说明： Windows与Unix系统的文件结构有明显的差异，如将深度学习模型集成于C++开发的软件系统中时，我们想要将深度学习模型(*.pth)拷贝到指定的文件中时： if (MSVC) file(GLOB MODEL \"${CMAKE_SOURCE_DIR}/resource/*.pt\") add_custom_command(TARGET ${PROJECT_NAME} POST_BUILD COMMAND ${CMAKE_COMMAND} -E copy_if_different ${MODEL} $\u003cTARGET_FILE_DIR:${PROJECT_NAME}\u003e) elseif(UNIX) file(GLOB MODEL \"${CMAKE_SOURCE_DIR}/resource/*.pt\") file(COPY ${MODEL} DESTINATION ${EXECUTE_FILE}) endif() 这段CMake代码用于在构建项目后，根据目标平台的不同（Windows或UNIX/Linux），将模型文件复制到输出目录中，以确保运行程序时所需的模型文件（具有.pt扩展名）与可执行文件位于同一目录下。 对于MSVC（Microsoft Visual C++编译器，通常用于Windows平台）： 使用file()命令并设置GLOB选项，在CMake源代码目录（${CMAKE_SOURCE_DIR}）下的resource目录中查找所有.pt模型文件。 然后使用add_custom_command()命令将自定义的后期构建命令添加到目标``（${PROJECT_NAME}）中。 自定义命令会将找到的所有.pt模型文件复制到输出目录（$\u003cTARGET_FILE_DIR:${PROJECT_NAME}\u003e）。使用copy_if_different参数确保仅在目标文件与源文件不同或目标目录中不存在时才复制文件。 对于UNIX平台（包括Linux）： 使用file()命令并设置GLOB选项，在CMake源代码目录（\\${CMAKE_SOURCE_DIR}）下的resource目录中查找所有.pt模型文件。 然后使用file()命令并设置COPY选项，将找到的所有.pt模型文件复制到指定的目标目录（${EXECUTE_FILE}）。 接下来，我们将通过一个不需要编译任何源代码的示例，演示如何使用CMake检测操作系统。 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter2/01 CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(os_test) if(CMAKE_SYSTEM_NAME STREQUAL \"Linux\") message(STATUS \"Configuring on/for Linux\") elseif(CMAKE_SYSTEM_NAME STREQUAL \"Darwin\") message(STATUS \"Configuring on/for macOs\") elseif(CMAKE_SYSTEM_NAME STREQUAL \"Windows\") message(STATUS \"Configuring on/for Windows\") elseif(CMAKE_SYSTEM_NAME STREQUAL \"AIX\") message(STATUS \"Configuring on/for IBM AIX\") else() message(STATUS \"Configuring on/for ${CMAKE_SYSTEM_NAME}\") endif() 输出结果 -- The C compiler identification is GNU 9.4.0 -- The CXX compiler identification is GNU 9.4.0 -- Check for working C compiler: /usr/bin/cc -- Check for working C compiler: /usr/bin/cc -- works -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Detecting C compile features -- Detecting C compile features - done -- Check for working CXX compiler: /usr/bin/c++ -- Check for working CXX compiler: /usr/bin/c++ -- works -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Detecting CXX compile features -- Detecting CXX compile features - done -- Configuring on/for Linux -- Configuring done -- Generating done -- Build files have been written to: /home/jiangli/repo/tutorials/cmake-tutorial/chapter2/01/build CMake为目标操作系统定义了CMAKE_SYSTEM_NAME，因此不需要使用定制命令、工具或脚本来查询此信息。然后，可以使用此变量的值实现特定于操作系统的条件和解决方案。 在macOS上CMAKE_SYSTEM_NAME为Darwin。 在Linux和Windows上，CMAKE_SYSTEM_NAME分别为Linux和Windows。我们了解了如何在特定的操作系统上执行特定的CMake代码。当然，应该尽量减少这种定制化行为，以便简化迁移到新平台的过程。 注意：为了最小化从一个平台转移到另一个平台时的成本，应该避免直接使用Shell命令，还应该避免显式的路径分隔符(Linux和macOS上的前斜杠和Windows上的后斜杠)。CMake代码中只使用前斜杠作为路径分隔符，CMake将自动将它们转换为所涉及的操作系统环境。 ","date":"2024-01-26","objectID":"/posts/cmake_note_11/:2:0","tags":["CMake"],"title":"CMake 笔记 | [11] 检测环境","uri":"/posts/cmake_note_11/"},{"categories":["C++"],"content":"三、处理与编译器相关的源代码 为了可移植性，我们尽量避免去编写新代码，但遇到有依赖的情况我们也要去解决，特别是当使用历史代码或处理编译器依赖工具。 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter2/02 CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(hello_os LANGUAGES CXX) add_executable(${PROJECT_NAME} hello_os.cpp) if(CMAKE_SYSTEM_NAME STREQUAL \"Linux\") target_compile_definitions(${PROJECT_NAME} PUBLIC \"IS_LINUX\") endif() if(CMAKE_SYSTEM_NAME STREQUAL \"Darwin\") target_compile_definitions(${PROJECT_NAME} PUBLIC \"IS_MACOS\") endif() if(CMAKE_SYSTEM_NAME STREQUAL \"Windows\") target_compile_definitions(${PROJECT_NAME} PUBLIC \"IS_WINDOWS\") endif() 通过target_compile_definitions()命令向目标（hello_os）添加预定义宏IS_LINUX、IS_MACOS或者IS_WINDOWS，该宏在编译过程中将生效。 target_compile_definitions会将将定义限制于一个特定的目标，以及通过PRIVATE|PUBLIC|INTERFACE限定符，限制这些定义可见性: PRIVATE，编译定义将只应用于给定的目标，而不应用于相关的其他目标。 INTERFACE，对给定目标的编译定义将只应用于使用它的目标。 PUBLIC，编译定义将应用于给定的目标和使用它的所有其他目标。 当然，在C++中，可以直接使用预定义的宏来识别不同的平台和操作系统。这些预定义的宏是由编译器或操作系统提供的，可以在源代码中使用它们来编写平台相关的代码。以下是一些常用的平台识别宏： __APPLE__：在苹果（Apple）平台（例如 macOS 和 iOS）上定义。 __linux__：在Linux平台上定义。 _WIN32：在32位Windows操作系统上定义。 _WIN64：在64位Windows操作系统上定义。 _MSC_VER：在使用Microsoft Visual C++编译器时定义，表示编译器的版本号。 __GNUC__：在使用GNU编译器（例如g++）时定义，表示编译器的版本号。 hello_os.cpp #include \u003cstring\u003e #include \u003ciostream\u003e std::string HelloOS(); int main() { std::cout \u003c\u003c HelloOS() \u003c\u003c std::endl; return EXIT_SUCCESS; } std::string HelloOS() { #ifdef IS_WINDOWS return std::string(\"Hello from Windows!\"); #elif IS_LINUX return std::string(\"Hello from Linux!\"); #elif IS_MACOS return std::string(\"Hello from macOS!\"); #else return std::string(\"Hello from an unknown system!\"); #endif } Windows系统上，将看到来自Windows的Hello。其他操作系统将产生不同的输出。 ","date":"2024-01-26","objectID":"/posts/cmake_note_11/:3:0","tags":["CMake"],"title":"CMake 笔记 | [11] 检测环境","uri":"/posts/cmake_note_11/"},{"categories":["C++"],"content":"四、检测与处理器体系结构 19世纪70年代，出现的64位整数运算和本世纪初出现的用于个人计算机的64位寻址，扩大了内存寻址范围，开发商投入了大量资源来移植为32位体系结构硬编码，以支持64位寻址。虽然，避免显式硬编码的方式非常明智，但需要在使用CMake配置的代码中适应硬编码限制。 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter2/03 CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(arch_dependent LANGUAGES CXX) add_executable( ${PROJECT_NAME} ${CMAKE_SOURCE_DIR}/arch_dependent.cpp ) # 检查空指针类型的大小 if(CMAKE_SIZEOF_VOID_P EQUAL 8) target_compile_definitions( ${PROJECT_NAME} PUBLIC \"IS_64_BIT_ARCH\" ) message(STATUS \"Target is 64 bits\") else() target_compile_definitions( ${PROJECT_NAME} PUBLIC \"IS_32_BIT_ARCH\" ) message(STATUS \"Target is 32 bits\") endif() # 通过定义目标编译定义，让预处理器了解主机处理器架构 if(CMAKE_HOST_SYSTEM_PROCESSOR MATCHES \"i386\") message(STATUS \"i386 architecture detected\") elseif(CMAKE_HOST_SYSTEM_PROCESSOR MATCHES \"i686\") message(STATUS \"i686 architecture detected\") elseif(CMAKE_HOST_SYSTEM_PROCESSOR MATCHES \"x86_64\") message(STATUS \"x86_64 architecture detected\") else() message(STATUS \"host processor architecture is unknown\") endif() target_compile_definitions( ${PROJECT_NAME} PUBLIC \"ARCHITECTURE=${CMAKE_HOST_SYSTEM_PROCESSOR}\" ) CMake定义了CMAKE_HOST_SYSTEM_PROCESSOR变量，以包含当前运行的处理器的名称。可以设置为i386、i686、x86_64、AMD64等等，当然，这取决于当前的CPU。 CMAKE_SIZEOF_VOID_P为void指针的大小。可以在CMake配置时进行查询，以便修改目标或目标编译定义。可以基于检测到的主机处理器体系结构，使用预处理器定义，确定需要编译的分支源代码。 当然，编写新代码时应该避免这种依赖，但在处理遗留代码或交叉编译时，这种依赖是有用的。 注意：使用CMAKE_SIZEOF_VOID_P是检查当前CPU是否具有32位或64位架构的唯一“真正”可移植的方法。 arch_dependent.cpp #include \u003ccstdlib\u003e #include \u003ciostream\u003e #include \u003cstring\u003e #define STRINGIFY(x) #x #define TOSTRING(x) STRINGIFY(x) std::string ArchInfo(); int main() { std::cout \u003c\u003c ArchInfo() \u003c\u003c std::endl; return EXIT_SUCCESS; } std::string ArchInfo() { std::string arch_info(TOSTRING(ARCHITECTURE)); arch_info += std::string(\" architecture. \"); #ifdef IS_32_BIT_ARCH return arch_info + std::string(\"Compiled on a 32 bit host processor.\"); #elif IS_64_BIT_ARCH return arch_info + std::string(\"Compiled on a 64 bit host processor.\"); #else return arch_info + std::string(\"Neither 32 not 64 bit, puzzling ...\"); #endif } 输出结果 mkdir build cd build cmake .. -- The CXX compiler identification is GNU 9.4.0 -- Check for working CXX compiler: /usr/bin/c++ -- Check for working CXX compiler: /usr/bin/c++ -- works -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Detecting CXX compile features -- Detecting CXX compile features - done -- Target is 64 bits -- x86_64 architecture detected -- Configuring done -- Generating done -- Build files have been written to: /home/jiangli/repo/tutorials/cmake-tutorial/chapter2/03/build make Scanning dependencies of target arch_dependent [ 50%] Building CXX object CMakeFiles/arch_dependent.dir/arch_dependent.cpp.o [100%] Linking CXX executable arch_dependent [100%] Built target arch_dependent ./arch_dependent x86_64 architecture. Compiled on a 64 bit host processor. ","date":"2024-01-26","objectID":"/posts/cmake_note_11/:4:0","tags":["CMake"],"title":"CMake 笔记 | [11] 检测环境","uri":"/posts/cmake_note_11/"},{"categories":["C++"],"content":"五、附录 除了CMAKE_HOST_SYSTEM_PROCESSOR, CMake还定义了CMAKE_SYSTEM_PROCESSOR变量。前者包含当前运行的CPU在CMake的名称，而后者将包含当前正在为其构建的CPU的名称。这是一个细微的差别，在交叉编译时起着非常重要的作用。 另一种让CMake检测主机处理器体系结构，是使用C或C++中定义的符号，结合CMake的try_run函数: #if defined(__i386) || defined(__i386__) || defined(_M_IX86) #error cmake_arch i386 #elif defined(__x86_64) || defined(__x86_64__) || defined(__amd64) || defined(_M_X64) #error cmake_arch x86_64 #endif 这种策略也是检测目标处理器体系结构的推荐策略，因为CMake似乎没有提供可移植的内在解决方案。 另一种选择，将只使用CMake，完全不使用预处理器，代价是为每种情况设置不同的源文件，然后使用target_source命令将其设置为可执行目标arch_dependent依赖的源文件: add_executable(arch-dependent \"\") if(CMAKE_HOST_SYSTEM_PROCESSOR MATCHES \"i386\") message(STATUS \"i386 architecture detected\") target_sources(arch_dependent PRIVATE arch_dependent_i386.cpp ) elseif(CMAKE_HOST_SYSTEM_PROCESSOR MATCHES \"i686\") message(STATUS \"i686 architecture detected\") target_sources(arch_dependent PRIVATE arch_dependent_i686.cpp ) elseif(CMAKE_HOST_SYSTEM_PROCESSOR MATCHES \"x86_64\") message(STATUS \"x86_64 architecture detected\") target_sources(arch_dependent PRIVATE arch_dependent_x86_64.cpp ) else() message(STATUS \"host processor architecture is unknown\") endif() 这种方法，显然需要对现有项目进行更多的工作，因为源文件需要分离。此外，不同源文件之间的代码复制肯定也会成为问题。 ","date":"2024-01-26","objectID":"/posts/cmake_note_11/:5:0","tags":["CMake"],"title":"CMake 笔记 | [11] 检测环境","uri":"/posts/cmake_note_11/"},{"categories":["C++"],"content":"六、检测处理器指令集 CMake可以检测主机处理器支持的指令集。这个功能是较新版本添加到CMake中的，需要CMake 3.10或更高版本。检测到的主机系统信息，可用于设置相应的编译器标志，或实现可选的源代码编译，或根据主机系统生成源代码。 将使用config.h.in生成config.h文件。config.h.in如下: #ifndef CONFIG_HEADER_IN_H #define CONFIG_HEADER_IN_H #define NUMBER_OF_LOGICAL_CORES @_NUMBER_OF_LOGICAL_CORES@ #define NUMBER_OF_PHYSICAL_CORES @_NUMBER_OF_PHYSICAL_CORES@ #define TOTAL_VIRTUAL_MEMORY @_TOTAL_VIRTUAL_MEMORY@ #define AVAILABLE_VIRTUAL_MEMORY @_AVAILABLE_VIRTUAL_MEMORY@ #define TOTAL_PHYSICAL_MEMORY @_TOTAL_PHYSICAL_MEMORY@ #define AVAILABLE_PHYSICAL_MEMORY @_AVAILABLE_PHYSICAL_MEMORY@ #define IS_64BIT @_IS_64BIT@ #define HAS_FPU @_HAS_FPU@ #define HAS_MMX @_HAS_MMX@ #define HAS_MMX_PLUS @_HAS_MMX_PLUS@ #define HAS_SSE @_HAS_SSE@ #define HAS_SSE2 @_HAS_SSE2@ #define HAS_SSE_FP @_HAS_SSE_FP@ #define HAS_SSE_MMX @_HAS_SSE_MMX@ #define HAS_AMD_3DNOW @_HAS_AMD_3DNOW@ #define HAS_AMD_3DNOW_PLUS @_HAS_AMD_3DNOW_PLUS@ #define HAS_IA64 @_HAS_IA64@ #define OS_NAME \"@_OS_NAME@\" #define OS_RELEASE \"@_OS_RELEASE@\" #define OS_VERSION \"@_OS_VERSION@\" #define OS_PLATFORM \"@_OS_PLATFORM@\" #endif // ! CONFIG_HEADER_IN_H CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(progressor_info LANGUAGES CXX) add_executable(${PROJECT_NAME} \"\") target_sources(${PROJECT_NAME} PRIVATE ${CMAKE_SOURCE_DIR}/processor_info.cpp ) target_include_directories(${PROJECT_NAME} PRIVATE ${PROJECT_BINARY_DIR} ) foreach(key IN ITEMS NUMBER_OF_LOGICAL_CORES NUMBER_OF_PHYSICAL_CORES TOTAL_VIRTUAL_MEMORY AVAILABLE_VIRTUAL_MEMORY TOTAL_PHYSICAL_MEMORY AVAILABLE_PHYSICAL_MEMORY IS_64BIT HAS_FPU HAS_MMX HAS_MMX_PLUS HAS_SSE HAS_SSE2 HAS_SSE_FP HAS_SSE_MMX HAS_AMD_3DNOW HAS_AMD_3DNOW_PLUS HAS_IA64 OS_NAME OS_RELEASE OS_VERSION OS_PLATFORM ) cmake_host_system_information(RESULT _${key} QUERY ${key}) endforeach() configure_file(config.h.in config.h @ONLY) foreach循环会查询多个键值，并定义相应的变量。cmake_host_system_information查询运行CMake的主机系统的系统信息。本例中，对每个键使用了一个函数调用。然后，使用这些变量来配置config.h.in中的占位符，输入并生成config.h。 此配置使用configure_file命令完成。最后，config.h包含在processor_info.cpp中。编译后，它将把值打印到屏幕上。 target_include_directories(${PROJECT_NAME} PRIVATE ${PROJECT_BINARY_DIR} ) 这将生成的可执行文件链接到可执行文件所在的文件夹中。 我们编译后，config.h将于build中生成，在本机中生成的内容如下： #ifndef CONFIG_HEADER_IN_H #define CONFIG_HEADER_IN_H #define NUMBER_OF_LOGICAL_CORES 16 #define NUMBER_OF_PHYSICAL_CORES 16 #define TOTAL_VIRTUAL_MEMORY 2047 #define AVAILABLE_VIRTUAL_MEMORY 2047 #define TOTAL_PHYSICAL_MEMORY 7903 #define AVAILABLE_PHYSICAL_MEMORY 6007 #define IS_64BIT 1 #define HAS_FPU 1 #define HAS_MMX 1 #define HAS_MMX_PLUS 0 #define HAS_SSE 1 #define HAS_SSE2 1 #define HAS_SSE_FP 0 #define HAS_SSE_MMX 0 #define HAS_AMD_3DNOW 0 #define HAS_AMD_3DNOW_PLUS 0 #define HAS_IA64 0 #define OS_NAME \"Linux\" #define OS_RELEASE \"5.15.0-78-generic\" #define OS_VERSION \"#85~20.04.1-Ubuntu SMP Mon Jul 17 09:42:39 UTC 2023\" #define OS_PLATFORM \"x86_64\" #endif // ! CONFIG_HEADER_IN_H processor_info.cpp #include \u003ccstdlib\u003e #include \u003ciostream\u003e #include \"config.h\" int main() { std::cout \u003c\u003c \"Number of logical cores: \" \u003c\u003c NUMBER_OF_LOGICAL_CORES \u003c\u003c std::endl; std::cout \u003c\u003c \"Number of physical cores: \" \u003c\u003c NUMBER_OF_PHYSICAL_CORES \u003c\u003c std::endl; std::cout \u003c\u003c \"Total virtual memory in megabytes: \" \u003c\u003c TOTAL_VIRTUAL_MEMORY \u003c\u003c std::endl; std::cout \u003c\u003c \"Available virtual memory in megabytes: \" \u003c\u003c AVAILABLE_VIRTUAL_MEMORY \u003c\u003c std::endl; std::cout \u003c\u003c \"Total physical memory in megabytes: \" \u003c\u003c TOTAL_PHYSICAL_MEMORY \u003c\u003c std::endl; std::cout \u003c\u003c \"Available physical memory in megabytes: \" \u003c\u003c AVAILABLE_PHYSICAL_MEMORY \u003c\u003c std::endl; std::cout \u003c\u003c \"Processor is 64Bit: \" \u003c\u003c IS_64BIT \u003c\u003c std::endl; std::cout \u003c\u003c \"Processor has floating point unit: \" \u003c\u003c HAS_FPU \u003c\u003c std::endl; std::cout \u003c\u003c \"Processor supports MMX instructions: \" \u003c\u003c HAS_MMX \u003c\u003c std::endl; std::cout \u003c\u003c \"Processor supports Ext. MMX instructions: \" \u003c\u003c HAS_MMX_PLUS \u003c\u003c std::endl; std::cout \u003c\u003c \"Processor supports SSE instructions: \" \u003c\u003c HAS_SSE \u003c\u003c std::endl; std::cout \u003c\u003c \"Processor supports SSE2 instructions: \" \u003c\u003c HAS_SSE2 \u003c\u003c std::endl; std::cout \u003c\u003c \"Processor ","date":"2024-01-26","objectID":"/posts/cmake_note_11/:6:0","tags":["CMake"],"title":"CMake 笔记 | [11] 检测环境","uri":"/posts/cmake_note_11/"},{"categories":["C++"],"content":"一、CMake:使用控制流 导言 在前面的示例中，我们已经使用过if-else-endif。CMake还提供了创建循环的语言工具：foreach-endforeach和while-endwhile。两者都可以与break结合使用，以便尽早从循环中跳出。而本篇也是为第一章的完结篇，算是正式的踏入了CMake学习的大门了。 ","date":"2024-01-25","objectID":"/posts/cmake_note_10/:1:0","tags":["CMake"],"title":"CMake 笔记 | [10] 使用控制流","uri":"/posts/cmake_note_10/"},{"categories":["C++"],"content":"二、项目结构 . ├── cal_add.h ├── cal_subtract.cpp ├── cal_subtract.h ├── CMakeLists.txt ├── main.cpp ├── message.cpp └── message.h 本项目结构回归到了简单的结构，目的主要是为了快速展示本篇的主旨，即如何使用控制流实现一些功能。 项目地址： https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter1/13 ","date":"2024-01-25","objectID":"/posts/cmake_note_10/:2:0","tags":["CMake"],"title":"CMake 笔记 | [10] 使用控制流","uri":"/posts/cmake_note_10/"},{"categories":["C++"],"content":"三、CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(control-flow LANGUAGES CXX) set(CXX_STANDARD 11) add_library(test_lib STATIC ${CMAKE_SOURCE_DIR}/message.h ${CMAKE_SOURCE_DIR}/message.cpp ${CMAKE_SOURCE_DIR}/cal_add.h ${CMAKE_SOURCE_DIR}/cal_subtract.h ${CMAKE_SOURCE_DIR}/cal_subtract.cpp ) # 使用-O3编译器优化级别编译库，对目标设置一个私有编译器选项 target_compile_options(test_lib PRIVATE -O3) # 生成一个源文件列表，以较低的优化选项进行编译 list(APPEND sources_with_lower_optimization cal_subtract.cpp ) # 循环这些源文件，将它们的优化级别调到-O2。使用它们的源文件属性完成 message(STATUS \"Setting source properties using IN LISTS syntax:\") foreach(_source IN LISTS sources_with_lower_optimization) set_source_files_properties(${_source} PROPERTIES COMPILE_FLAGS -O2) message(STATUS \"Appending -O2 flag for ${_source}\") endforeach() # 为了确保设置属性，再次循环并在打印每个源文件的COMPILE_FLAGS属性 message(STATUS \"Querying sources properties using plain syntax:\") foreach(_source ${sources_with_lower_optimization}) get_source_file_property(_flags ${_source} COMPILE_FLAGS) message(STATUS \"Source ${_source} has the following extra COMPILE_FLAGS: ${_flags}\") endforeach() add_executable(${PROJECT_NAME} main.cpp) target_link_libraries(${PROJECT_NAME} test_lib) set_source_files_properties(file PROPERTIES property value) 将属性设置为给定文件的传递值。与目标非常相似，文件在CMake中也有属性，允许对构建系统进行非常细粒度的控制。 Tip get_source_file_property(VAR file property) 检索给定文件所需属性的值，并将其存储在CMakeVAR变量中。 注意：CMake中，列表是用分号分隔的字符串组。列表可以由list或set命令创建。例如，set(var a b c d e)和list(APPEND a b c d e)都创建了列表a;b;c;d;e。 引用 foreach(loop_var range total) or foreach(loop_var range start stop [step]) 通过指定一个范围，可以对整数进行循环 ✦ ","date":"2024-01-25","objectID":"/posts/cmake_note_10/:3:0","tags":["CMake"],"title":"CMake 笔记 | [10] 使用控制流","uri":"/posts/cmake_note_10/"},{"categories":["C++"],"content":"四、相关源码 cal_add.h #ifndef CALCULATE_ADD_HEADER #define CALCULATE_ADD_HEADER template \u003ctypename T, typename U\u003e auto Add(T t, U u) -\u003e decltype(t + u){ return t + u; } #endif // ! CALCULATE_ADD_HEADER cal_substruct.h #ifndef CALCULATE_SUBSTRACT_HEADER #define CALCULATE_SUBSTRACT_HEADER float Substract(float a, float b); #endif // ! CALCULATE_SUBSTRACT_HEADER cal_substruct.cpp float Substract(float a, float b) { return a - b; } message.h #ifndef MESSAGE_HEADER_H_ #define MESSAGE_HEADER_H_ #include \u003cstring\u003e class Message { public: Message() {} void Print(const std::string\u0026 message); }; #endif // ! MESSAGE_HEADER_H_ message.cpp #include \"message.h\" #include \u003ciostream\u003e void Message::Print(const std::string\u0026 message) { std::cout \u003c\u003c message \u003c\u003c std::endl; } main.cpp #include \"message.h\" #include \"cal_add.h\" #include \"cal_subtract.h\" int main() { int a = 1; int b = 2; auto c = Add(a , b); Message message; message.Print(std::to_string(c)); return 0; } ","date":"2024-01-25","objectID":"/posts/cmake_note_10/:4:0","tags":["CMake"],"title":"CMake 笔记 | [10] 使用控制流","uri":"/posts/cmake_note_10/"},{"categories":["C++"],"content":"五、编译结果 -- The CXX compiler identification is GNU 9.4.0 -- Check for working CXX compiler: /usr/bin/c++ -- Check for working CXX compiler: /usr/bin/c++ -- works -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Detecting CXX compile features -- Detecting CXX compile features - done -- Setting source properties using IN LISTS syntax: -- Appending -O2 flag for cal_add.cpp -- Appending -O2 flag for cal_subtract.cpp -- Configuring done -- Generating done -- Build files have been written to: /home/jiangli/repo/tutorials/cmake-tutorial/chapter1/13/build ","date":"2024-01-25","objectID":"/posts/cmake_note_10/:5:0","tags":["CMake"],"title":"CMake 笔记 | [10] 使用控制流","uri":"/posts/cmake_note_10/"},{"categories":["C++"],"content":"五、附录 foreach()的四种使用方式: foreach(loop_var arg1 arg2 ...): 其中提供循环变量和显式项列表。当为sources_with_lower_optimization中的项打印编译器标志集时，使用此表单。注意，如果项目列表位于变量中，则必须显式展开它；也就是说，${sources_with_lower_optimization}必须作为参数传递。 通过指定一个范围，可以对整数进行循环，例如：foreach(loop_var range total)或foreach(loop_var range start stop [step])。 对列表值变量的循环，例如：foreach(loop_var IN LISTS [list1[...]]) 。参数解释为列表，其内容就会自动展开。 对变量的循环，例如：foreach(loop_var IN ITEMS [item1 [...]])。参数的内容没有展开。 ","date":"2024-01-25","objectID":"/posts/cmake_note_10/:6:0","tags":["CMake"],"title":"CMake 笔记 | [10] 使用控制流","uri":"/posts/cmake_note_10/"},{"categories":["C++"],"content":"cmake常用命令的一些整理 CMake 是什么我就不用再多说什么了，相信大家都有接触才会看一篇文章。对于不太熟悉的开发人员可以把这篇文章当个查找手册。 ","date":"2024-01-24","objectID":"/posts/commandcollection/:0:0","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.CMake语法 ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:0","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.1 指定cmake的最小版本 cmake_minimum_required(version 版本号) 例如： cmake_minimum_required(version 2.8) ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:1","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.2 定义工程名称 #定义工程名称 project(项目名称) 例如： project(MyTest) ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:2","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.3 显示定义变量 set(var [value]) 例如： # 第一种用法，生成代码文件列表 #先直接设置SRC_LIST的值 set(SRC_LIST add.h add.cpp) #然后再在SRC_LIST中追加main.cpp set(SRC_LIST ${SRC_LIST} main.cpp) # 第二种用法，设置库生成目录或者可执行文件生成目录 set(LIBRARY_OUTPUT_PATH ${PROJECT_SOURCE_DIR}/lib/linux) set(EXECUTABLE_OUTPUT_PATH ${PROJECT_SOURCE_DIR}/bin) ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:3","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.4 设置编译类型 # 编译静态库 add_library(库名称 STATIC 代码文件名称) # 编译动态库 add_library(库名称 SHARED 代码文件名称) # 编译可执行程序 add_executable(可执行程序名 代码文件名称) 例如： # 把`.cpp`、`.h`文件编译成静态库 add_library(add STATIC add.h add.cpp) add_library(add STATIC ${ADD_SRC} ${ADD_HDR}) # 把`.cpp`、`.h`文件编译成动态库 add_library(add SHARED add.h add.cpp) add_library(add SHARED ${ADD_SRC} ${ADD_HDR}) # 编译可执行程序 add_executable(main add.h add.cpp mai.cpp) add_executable(main ${MAIN_SRC} ${MAIN_HDR}) ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:4","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.5 指定静态库或者动态库编译输出目录 例如将当前编译的静态库或者动态库输出到当前项目文件夹lib子目录下 // cmake中`LIBRARY_OUTPUT_PATH`变量为库文件输出路径 set(LIBRARY_OUTPUT_PATH ${PROJECT_SOURCE_DIR}/lib) ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:5","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.6 指定可执行程序编译输出目录 例如将当前可执行程序输出到当前项目文件夹的bin子目录下 // 设定可执行二进制文件的目录 set(EXECUTABLE_OUTPUT_PATH ${PROJECT_SOURCE_DIR}/bin) ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:6","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.7 设置链接库搜索目录 例如将链接库搜索目录设置为当前项目文件夹下lib/linux文件夹 // ${PROJECT_SOURCE_DIR} 为当前项目文件夹 link_directories(${PROJECT_SOURCE_DIR}/lib/linux) ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:7","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.8 设置包含目录 例如将包含目录设置为当前项目文件夹下include文件夹 include_directories(${PROJECT_SOURCE_DIR}/include) ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:8","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.9 设置宏定义 #预定义宏 add_definitions(-D宏名称) 例如： add_definitions(-DWINDOWS) add_definitions(-DLINUX) ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:9","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.10 链接静态库 link_libraries( 静态库1 静态库2 静态库3 ... ) tips: link_libraries 和 target_link_libraries 链接库 注意: link_libraries中的静态库为全路径，常与1.7 link_directories 搭配使用，例如： lib1.a, lib2.a在目录${PROJECT_SOURCE_DIR}/lib/linux下，则先设置链接目录，再链接相应的库 #设置链接目录 link_directories(${PROJECT_SOURCE_DIR}/lib/linux) # 链接相应的库 link_libraries( lib1.a lib2.a ) ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:10","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.11 链接动态库 target_link_libraries(所需生成的文件名称 所需链接的动态库名称) 例如 target_link_libraries(main dl) ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:11","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.12 link_libraries 和 target_link_libraries 区别 在cmake语法中，link_libraries和target_link_libraries是很重要的两个链接库的方式，虽然写法上很相似，但是功能上有很大区别： 注意 (1) link_libraries用在add_executable之前，target_link_libraries用在add_executable之后 (2) link_libraries用来链接静态库，target_link_libraries用来链接导入库，即按照header file + .lib + .dll方式隐式调用动态库的.lib库 注意: windows系统下，静态库后缀为.lib, 导入库的后缀为.lib，动态库的后缀为.dll linux系统写，静态库后缀为.a, 动态库的后缀为.so ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:12","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.13 file语法 1.13.1 将文件夹所有的类型的文件添加到文件列表 例如将当前文件夹下所有.cpp文件的文件名加入到MAIN_SRC中，将当前文件夹下所有.h加入到MAIN_HDR中。 file(GLOB MAIN_SRC ${CMAKE_CURRENT_SOURCE_DIR}/*.cpp) file(GLOB MAIN_HDR ${CMAKE_CURRENT_SOURCE_DIR}/*.h) 例如将当前文件夹子目录src文件夹下所有.cpp文件的文件名加入到MAIN_SRC中，将当前文件夹子目录src文件夹下所有.h加入到MAIN_HDR中。 file(GLOB MAIN_SRC ${CMAKE_CURRENT_SOURCE_DIR}/src/*.cpp) file(GLOB MAIN_HDR ${CMAKE_CURRENT_SOURCE_DIR}/src/*.h) 1.13.2 递归搜索该文件夹，将文件夹下（包含子目录）符合类型的文件添加到文件列表 例如将当前文件夹下（包括子目录下）所有.cpp文件的文件名加入到MAIN_SRC中，所有.h加入到MAIN_HDR中 file(GLOB_RECURSE MAIN_SRC ${CMAKE_CURRENT_SOURCE_DIR}/*.cpp) file(GLOB_RECURSE MAIN_HDR ${CMAKE_CURRENT_SOURCE_DIR}/*.h) ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:13","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.14 List操作 常见的List操作包括： list(LENGTH \u003clist\u003e \u003coutput variable\u003e) list(GET \u003clist\u003e \u003celement index\u003e [\u003celement index\u003e ...] \u003coutput variable\u003e) list(APPEND \u003clist\u003e [\u003celement\u003e ...]) list(FIND \u003clist\u003e \u003cvalue\u003e \u003coutput variable\u003e) list(INSERT \u003clist\u003e \u003celement_index\u003e \u003celement\u003e [\u003celement\u003e ...]) list(REMOVE_ITEM \u003clist\u003e \u003cvalue\u003e [\u003cvalue\u003e ...]) list(REMOVE_AT \u003clist\u003e \u003cindex\u003e [\u003cindex\u003e ...]) list(REMOVE_DUPLICATES \u003clist\u003e) list(REVERSE \u003clist\u003e) list(SORT \u003clist\u003e) 1.14.1 List移除指定项 例如从MAIN_SRC移除指定项 list(REMOVE_ITEM MAIN_SRC ${CMAKE_CURRENT_SOURCE_DIR}/add.cpp) 1.14.2 将两个List链接起来 # 搜索当前目录 file(GLOB MAIN_SRC ${CMAKE_CURRENT_SOURCE_DIR}/*.cpp) file(GLOB MAIN_HDR ${CMAKE_CURRENT_SOURCE_DIR}/*.h) # 递归搜索当前目录下src子目录 file(GLOB_RECURSE MAIN_SRC_ELSE ${CMAKE_CURRENT_SOURCE_DIR}/src/*.cpp) file(GLOB_RECURSE MAIN_HDR_ELSE ${CMAKE_CURRENT_SOURCE_DIR}/src/*.h) # 将MAIN_SRC_ELSE中的值添加到MAIN_SRC # 将MAIN_HDR_ELSE中的值添加到MAIN_HDR list(APPEND MAIN_SRC ${MAIN_SRC_ELSE}) list(APPEND MAIN_HDR ${MAIN_HDR_ELSE}) ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:14","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.15 添加子文件夹 例如 add_subdirectory(src) 该语句会在执行完当前文件夹CMakeLists.txt之后执行src子目录下的CMakeLists.txt。 ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:15","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.16 message输出消息机制 输出正常： message(STATUS \"Enter cmake ${CMAKE_CURRENT_LIST_DIR}\") 输出警告 message(WARNING \"Enter cmake ${CMAKE_CURRENT_LIST_DIR}\") 输出错误： message(FATAL_ERROR \"Enter cmake ${CMAKE_CURRENT_LIST_DIR}\") ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:16","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.17 安装 install() install 指令用于定义安装规则，安装的内容包括二进制可执行文件、动态库、静态库以及文件、目录、脚本等。 1.17.1 目标文件安装 例如： install(TARGETS util RUNTIME DESTINATION bin LIBRARY DESTINATION lib ARCHIVE DESTINATION lib) ARCHIVE指静态库，LIBRARY指动态库，RUNTIME指可执行目标二进制，上述示例的意思是： 如果目标util是可执行二进制目标，则安装到${CMAKE_INSTALL_PREFIX}/bin目录 如果目标util是静态库，则安装到安装到${CMAKE_INSTALL_PREFIX}/lib目录 如果目标util是动态库，则安装到安装到${CMAKE_INSTALL_PREFIX}/lib目录 1.17.2 文件夹安装 install(DIRECTORY include/ DESTINATION include/util) 这个语句的意思是将include/目录安装到include/util目录 ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:17","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.18 设置编译选项 设置编译选项可以通过add_compile_options命令，也可以通过set命令修改CMAKE_CXX_FLAGS或CMAKE_C_FLAGS。 方式1 set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=c++11 -march=native -O3 -frtti -fpermissive -fexceptions -pthread\") 方式2 add_compile_options(-march=native -O3 -fexceptions -pthread -fPIC) 这两种方式的区别在于： add_compile_options命令添加的编译选项是针对所有编译器的(包括c和c++编译器)，而set命令设置CMAKE_C_FLAGS或CMAKE_CXX_FLAGS变量则是分别只针对c和c++编译器的。 ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:18","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.19 预定义变量 1.19.1 基本变量 PROJECT_SOURCE_DIR—————————————–我们使用cmake命令后紧跟的目录，一般是工程的根目录； PROJECT_BINARY_DIR ——————————————执行cmake命令的目录,通常是${PROJECT_SOURCE_DIR}/build； CMAKE_INCLUDE_PATH—————————————–系统环境变量,非cmake变量； CMAKE_LIBRARY_PATH——————————————系统环境变量,非cmake变量； CMAKE_CURRENT_SOURCE_DIR—————————当前处理的CMakeLists.txt所在的路径； CMAKE_CURRENT_BINARY_DIR—————————–target编译目录（使用ADD_SURDIRECTORY(src bin)可以更改此变量的值 ，SET(EXECUTABLE_OUTPUT_PATH \u003c新路径\u003e)并不会对此变量有影响,只是改变了最终目标文件的存储路径）； CMAKE_CURRENT_LIST_FILE——————————–输出调用这个变量的CMakeLists.txt的完整路径； CMAKE_CURRENT_LIST_LINE——————————–输出这个变量所在的行； CMAKE_MODULE_PATH—————————————–定义自己的cmake模块所在的路径（这个变量用于定义自己的cmake模块所在的路径，如果你的工程比较复杂，有可能自己编写一些cmake模块，比如SET(CMAKE_MODULE_PATH ${PROJECT_SOURCE_DIR}/cmake),然后可以用INCLUDE命令来调用自己的模块）； EXECUTABLE_OUTPUT_PATH——————————重新定义目标二进制可执行文件的存放位置； LIBRARY_OUTPUT_PATH————————————–重新定义目标链接库文件的存放位置； PROJECT_NAME————————————————-返回通过PROJECT指令定义的项目名称； CMAKE_ALLOW_LOOSE_LOOP_CONSTRUCTS—用来控制IF ELSE语句的书写方式； ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:19","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.19.2 操作系统变量 CMAKE_MAJOR_VERSION—————————–cmake主版本号,如3.4.1中的3； CMAKE_MINOR_VERSION—————————–cmake次版本号,如3.4.1中的4； CMAKE_PATCH_VERSION—————————–cmake补丁等级,如3.4.1中的1； CMAKE_SYSTEM—————————————-操作系统名称，包括版本名，如Linux-2.6.22； CAMKE_SYSTEM_NAME——————————-操作系统名称，不包括版本名，如Linux； CMAKE_SYSTEM_VERSION————————–操作系统版本号,如2.6.22； CMAKE_SYSTEM_PROCESSOR——————–电脑处理器名称，如i686； UNIX——————————————————–在所有的类UNIX平台为TRUE,包括OS X和cygwin，Linux/Unix操作系统； WIN32—————————————————–在所有的win32平台为TRUE,包括cygwin，Windows操作系统； APPLE—————————————————-苹果操作系统； 例如操作系统判断方式一： if(WIN32) message(STATUS “This operating system is Windows.”) elseif(UNIX) message(STATUS “This operating system is Linux.”) elseif(APPLE) message(STATUS “This operating system is APPLE.”) endif(WIN32) 操作系统判断方式二： if (CMAKE_SYSTEM_NAME MATCHES \"Linux** message(STATUS \"current platform: Linux \") elseif (CMAKE_SYSTEM_NAME MATCHES \"Windows\") message(STATUS \"current platform: Windows\") elseif (CMAKE_SYSTEM_NAME MATCHES \"FreeBSD\") message(STATUS \"current platform: FreeBSD\") else () message(STATUS \"other platform: ${CMAKE_SYSTEM_NAME}\") endif (CMAKE_SYSTEM_NAME MATCHES \"Linux\") ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:20","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.19.3 开关选项 BUILD_SHARED_LIBS———————————————控制默认的库编译方式。如果未进行设置,使用ADD_LIBRARY时又没有指定库类型,默认编译生成的库都是静态库； CMAKE_C_FLAGS————————————————-设置C编译选项，也可以通过指令ADD_DEFINITIONS()添加； CMAKE_CXX_FLAGS———————————————-设置C++编译选项，也可以通过指令ADD_DEFINITIONS()添加； CMAKE_C_COMPILER——————————————–指定C编译器； CMAKE_CXX_COMPILER—————————————-指定C++编译器； CMAKE_BUILD_TYPE:：build 类型(Debug, Release, …)-CMAKE_BUILD_TYPE=Debug ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:21","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.19.4 环境变量 设置环境变量： set(env{name} value) 调用环境变量： $env{name} 例如 message(STATUS \"$env{name}\") ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:22","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.19.5 CMAKE_INCLUDE_CURRENT_DIR 自动添加CMAKE_CURRENT_BINARY_DIR和CMAKE_CURRENT_SOURCE_DIR到当前处理的CMakeLists.txt。 相当于在每个CMakeLists.txt加入： include_directories(${CMAKE_CURRENT_BINARY_DIR} ${CMAKE_CURRENT_SOURCE_DIR}) ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:23","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.20 条件判断 ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:24","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.20.1 逻辑判断和比较 if (expression)：expression 不为空时为真，false的值包括（0,N,NO,OFF,FALSE,NOTFOUND）； if (not exp)：与上面相反； if (var1 AND var2)：如果两个变量都为真时为真； if (var1 OR var2)：如果两个变量有一个为真时为真； if (COMMAND cmd)：如果 cmd 确实是命令并可调用为真； if (EXISTS dir) if (EXISTS file)：如果目录或文件存在为真； if (file1 IS_NEWER_THAN file2)：当 file1 比 file2 新，或 file1/file2 中有一个不存在时为真，文件名需使用全路径； if (IS_DIRECTORY dir)：当 dir 是目录时为真； if (DEFINED var)：如果变量被定义为真； if (var MATCHES regex)：给定的变量或者字符串能够匹配正则表达式 regex 时为真，此处 var 可以用 var 名，也可以用 ${var}； if (string MATCHES regex)：给定的字符串能够匹配正则表达式regex时为真。 ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:25","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.20.2 数字比较 if (variable LESS number)：如果variable小于number时为真； if (string LESS number)：如果string小于number时为真； if (variable GREATER number)：如果variable大于number时为真； if (string GREATER number)：如果string大于number时为真； if (variable EQUAL number)：如果variable等于number时为真； if (string EQUAL number)：如果string等于number时为真。 ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:26","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.20.3 字母表顺序比较 if (variable STRLESS string) if (string STRLESS string) if (variable STRGREATER string) if (string STRGREATER string) if (variable STREQUAL string) if (string STREQUAL string) ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:27","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.21 循环 ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:28","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.21.1 foreach start 表示起始数，stop 表示终止数，step 表示步长 foreach(loop_var RANGE start stop [step]) ... endforeach(loop_var) ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:29","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.21.2 while while(condition) ... endwhile() ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:30","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.22 自动检测编译器是否支持C++11 include(CheckCXXCompilerFlag) CHECK_CXX_COMPILER_FLAG(\"-std=c++11\" COMPILER_SUPPORTS_CXX11) CHECK_CXX_COMPILER_FLAG(\"-std=c++0x\" COMPILER_SUPPORTS_CXX0X) if(COMPILER_SUPPORTS_CXX11) set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=c++11\") elseif(COMPILER_SUPPORTS_CXX0X) set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=c++0x\") else() message(STATUS \"The compiler ${CMAKE_CXX_COMPILER} has no C++11 support. Please use a different C++ compiler.\") endif() ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:31","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.23 CMake生成VS解决方案将项目放置在设定文件夹下 例如，我们在工程中引用了许多的第三方开源库，这些库的源码与自己所写的代码需要进行区分和隔离，通常情况下会单独开一个third筛选器存储这些第三方库的项目，怎么做？ ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:32","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"第一步： 在第三方库的CMakeLists.txt中cmake_minimum_required(VERSION 2.6)中加上set_property(GLOBAL PROPERTY USE_FOLDERS On) ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:33","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"第二步：在生成编译目标的语法之后，如： add_executable(demo demo.cpp) # 生成可执行文件 add_library(common STATIC util.cpp) # 生成静态库 add_library(common SHARED util.cpp) # 生成动态库或共享库 加入一句 set_target_properties(${第三方库项目名称} PROPERTIES FOLDER “目标文件夹名称”) ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:34","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.24 CMake常用变量 1）CMAKE_BINARY_DIR、PROJECT_BINARY_DIR、\u003cprojectname\u003e_BINARY_DIR三个变量指代的内容是一致的，如果是 in source 编译，指得就是工程顶层目录，如果是 out-of-source 编译，指的是工程编译发生的目录。PROJECT_BINARY_DIR 跟其他指令稍有区别，暂时可以理解为他们是一致的。 （2）CMAKE_SOURCE_DIR、PROJECT_SOURCE_DIR、\u003cprojectname\u003e_SOURCE_DIR这三个变量指代的内容是一致的，不论采用何种编译方式，都是工程顶层目录。也就是在in source 编译时，他跟 CMAKE_BINARY_DIR 等变量一致。PROJECT_SOURCE_DIR 跟其他指令稍有区别，暂时理解为他们是一致的。 （3）CMAKE_CURRENT_SOURCE_DIR指的是当前处理的CMakeLists.txt 所在的路径。 （4）CMAKE_CURRRENT_BINARY_DIR，如果是in-source 编译，它跟 CMAKE_CURRENT_SOURCE_DIR 一致，如果是out-of-source 编译，他指的是target 编译目录。使用ADD_SUBDIRECTORY(src bin)可以更改这个变量的值。使用SET(EXECUTABLE_OUTPUT_PATH \u003c新路径\u003e)并不会对这个变量造成影响，它仅仅修改了最终目标文件存放的路径。 （5）CMAKE_CURRENT_LIST_FILE输出调用这个变量的CMakeLists.txt 的完整路径。 （6）CMAKE_CURRENT_LIST_LINE输出这个变量所在的行。 （7）CMAKE_MODULE_PATH这个变量用来定义自己的cmake模块所在的路径。如果你的工程比较复杂，有可能会自己编写一些cmake模块，这些cmake 模块是随你的工程发布的，为了让cmake 在处理 CMakeLists.txt 时找到这些模块，你需要通过SET 指令，将自己的cmake 模块路径设置一下。 比如： SET(CMAKE_MODULE_PATH ${PROJECT_SOURCE_DIR}/cmake), 这时候你就可以通过INCLUDE 指令来调用自己的模块了。 （8）EXECUTABLE_OUTPUT_PATH 和 LIBRARY_OUTPUT_PATH分别用来重新定义最终结果的存放目录。 （9）PROJECT_NAME返回通过PROJECT指令定义的项目名称。 ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:35","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"1.25 target_sources() 来源: https://blog.csdn.net/guaaaaaaa/article/details/125601766 作用: 使用 target_sources() 将当前文件夹下的所有.c、.h文件作为源文件添加到项目中 ","date":"2024-01-24","objectID":"/posts/commandcollection/:1:36","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"2 错误解决方案 ","date":"2024-01-24","objectID":"/posts/commandcollection/:2:0","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"2.1 Cannot specify link libraries for target “/…/…/lib/linux/libMyDll.a” which 这个问题要将生成执行文件、静态库、动态库的声明 add_executable(demo demo.cpp) # 生成可执行文件 add_library(common STATIC util.cpp) # 生成静态库 add_library(common SHARED util.cpp) # 生成动态库或共享库 放在 target_link_libraries() 之前。 ","date":"2024-01-24","objectID":"/posts/commandcollection/:2:1","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"2.2 警告：检测到时钟错误。您的创建可能是不完整的。 在项目根目录下执行命令： touch * 更新所有文件时间。 ","date":"2024-01-24","objectID":"/posts/commandcollection/:2:2","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["C++"],"content":"3 参考 [1].cmake常用命令的一些整理 [2].简明教程 [3].CMake 命令行参数 [4].https://blog.csdn.net/geyichongchujianghu/article/details/124781090?spm=1001.2101.3001.6650.1\u0026utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-124781090-blog-85257728.235%5Ev40%5Epc_relevant_3m_sort_dl_base1\u0026depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-124781090-blog-85257728.235%5Ev40%5Epc_relevant_3m_sort_dl_base1\u0026utm_relevant_index=2 [5].https://blog.csdn.net/Zhanganliu/article/details/85257728 [6].https://blog.csdn.net/llffss/article/details/120121617 [7].https://blog.csdn.net/wzj_110/category_10357507.html [8].https://blog.csdn.net/fengbingchun/category_783053.html ","date":"2024-01-24","objectID":"/posts/commandcollection/:3:0","tags":["CMake"],"title":"CMake 常用命令查询","uri":"/posts/commandcollection/"},{"categories":["Linux"],"content":"1、 简介 ./configure make make install 以上三个命令是源码安装软件的通用步骤。其主要完成以下工作： ./configure: 配置，是用来检测你的安装平台的目标特征。比如它会检测你是不是有CC或GCC，并不是需要CC或GCC，它是个shell脚本。configure 脚本负责在使用的系统上准备好软件的构建环境。确保接下来的构建和安装过程所需要的依赖准备好，并且搞清楚使用这些依赖需要的东西。 make: 构建，用来编译，它从Makefile中读取指令，然后编译。下载的源码包一般没有一个最终的 Makefile 文件，一般是一个模版文件 http://Makefile.in 文件，然后 configure 根据系统的参数生成一个定制化的 Makefile 文件。这个过程会执行在 Makefile 文件中定义的一系列任务将软件源代码编译成可执行文件。 make install:安装，它也从Makefile中读取指令，安装到指定的位置。make install 命令就是将可执行文件、第三方依赖包和文档复制到正确的路径。 tips 这些脚本是怎么产生的? 安装过程简单说就是 configure 脚本根据系统信息将 Makefile.in 模版文件转换为 Makefile文件，但是 configure 和 Makefile.in 文件是怎么产生的呢？ 如果你曾经试着打开 configure 或者 Makefile.in 文件，你会发现超长而且复杂的 shell 脚本语言。有时候这些脚本代码比它们要安装的程序源代码还要长。 如果想手动创建一个这样的 configure 脚本文件是非常可怕的，好消息是这些脚本是通过代码生成的。 通过这种方式构建的软件通常是通过一个叫做 autotools 的工具集打包的。这个工具集包含 autoconf 、automake 等工具，所有的这些工具使得维护软件生命周期变得很容易。最终用户不需要了解这些工具，但却可以让软件在不同的 Unix 系统上的安装步骤变得简单。 ","date":"2024-01-20","objectID":"/posts/make_install/:1:0","tags":["make_install"],"title":"configure、make、make install 背后的原理","uri":"/posts/make_install/"},{"categories":["Linux"],"content":"2、 详细说明 ","date":"2024-01-20","objectID":"/posts/make_install/:2:0","tags":["make_install"],"title":"configure、make、make install 背后的原理","uri":"/posts/make_install/"},{"categories":["Linux"],"content":"2.1 configure命令 这一步一般用来生成 Makefile，为下一步的编译做准备，你可以通过在 configure 后加上参数来对安装进行控制，具体参数可以通过configure --help 察看，下面举几个例子: ./configure --prefix=/usr ... --prefix=/usr: 意思是将该软件安装在 /usr 下面，执行文件就会安装在 /usr/bin (而不是默认的 /usr/local/bin), 资源文件就会安装在 /usr/share(而不是默认的/usr/local/share)。选项的另一个好处是卸载软件或移植软件。当某个安装的软件不再需要时，只须简单的删除该安装目录，就可以把软件卸载得干干净净；移植软件只需拷贝整个目录到另外一个机器即可（相同的操作系统） --bindir=: 指定二进制文件的安装位置.这里的二进制文件定义为可以被用户直接执行的程序 --enable-static与--enable-shared: --enable-static: 生成静态链接库 --enable-shared: 生成动态链接库 --with-: 用于启用或禁用特定功能或模块。例如: --with-ssl表示启用SSL支持 --without-gui表示禁用图形界面。 --with-package=dir --with-apxs 是指定 apache 的配置程序路径，php编译程序会通过这个程序查找apache的相关路径 --with-libxml-dir: 指向的是 libxml 的库路径 --with-gd: 指静态编译gd库 --with-png-dir: 指定 libpng 的路径 --enable-: 用于启用或禁用特定功能或模块。与–with-选项类似，但更常用于启用或禁用编译选项。 --disable-: 用于禁用特定功能或模块。与–enable-选项相反，用于禁用编译选项。 –sys-config=: 指定软件的配置文件。有一些软件还可以加上 –with、–enable、–without、–disable 等等参数对编译加以控制 ","date":"2024-01-20","objectID":"/posts/make_install/:2:1","tags":["make_install"],"title":"configure、make、make install 背后的原理","uri":"/posts/make_install/"},{"categories":["Linux"],"content":"2.2 make 命令 这一步就是编译，大多数的源代码包都经过这一步进行编译（当然有些perl或python编写的软件需要调用perl或python来进行编译）。如果 在 make 过程中出现 error ，你就要记下错误代码（注意不仅仅是最后一行），然后你可以向开发者提交 bugreport（一般在 INSTALL 里有提交地址），或者你的系统少了一些依赖库等，这些需要自己仔细研究错误代码。 可能遇到的错误：make *** 没有指明目标并且找不到 makefile。 没有Makefile，先./configure 一下，再make。make uninstall 是卸载，不加参数就是默认的进行源代码编译。 make工具，它是一个自动化编译工具，你可以使用一条命令实现完全编译。但是你需要编写一个规则文件，make依据它来批处理编译，这个文件就是makefile。 ","date":"2024-01-20","objectID":"/posts/make_install/:2:2","tags":["make_install"],"title":"configure、make、make install 背后的原理","uri":"/posts/make_install/"},{"categories":["Linux"],"content":"2.3 make install 命令 这条命令来进行安装（当然有些软件需要先运行 make check 或 make test 来进行一些测试），这一步一般需要你有 root 权限（因为要向系统写入文件）。 make install 和make install prefix=/usr/local/ 等价。 make install prefix=/usr/local/ sysconfdir=/etc DESTDIR=/tmp/build支持DESTDIR的意义就是，保证所有要安装的文件，都会被安装在DESTDIR目录下，不会污染系统的package的目录。install也 是linux系统命令。 ","date":"2024-01-20","objectID":"/posts/make_install/:2:3","tags":["make_install"],"title":"configure、make、make install 背后的原理","uri":"/posts/make_install/"},{"categories":["Linux"],"content":"2.4 扩展说明 Linux的用户可能知道，在Linux下安装一个应用程序时，一般先运行脚本configure，然后用make来编译源程序，在运行make install，最后运行make clean删除一些临时文件。 configure是一个shell脚本，它可以自动设定源程序以符合各种不同平台上Unix系统的特性，并且根据系统叁数及环境产生合适的Makefile文件或是C的头文件(header file)，让源程序可以很方便地在这些不同的平台上被编译连接。 利用configure所产生的Makefile文件有几个预设的目标可供使用，其中几个重要的简述如下： make all: 产生我们设定的目标，即此范例中的可执行文件。只打make也可以，此时会开始编译原始码，然后连结，并且产生可执行文件。只打make 默认就是make all，只编译其中某个目标则在后面给目标名称：make ce-common。 make clean: 清除编译产生的可执行文件及目标文件(object file，*.o)。 make distclean: 除了清除可执行文件和目标文件外，把configure所产生的Makefile也清除掉。 make install: 将程序安装至系统中。如果原始码编译无误，且执行结果正确，便可以把程序安装至系统预设的可执行文件存放路径。 make dist: 将程序和相关的档案包装成一个压缩文件以供发布。执行完在目录下会产生一个以PACKAGE-VERSION.tar.gz为名称的文件。 PACKAGE和VERSION这两个变数是根据http://configure.in文件中AM_INIT_AUTOMAKE(PACKAGE，VERSION)的定义。在此范例中会产生test-1.0.tar.gz的档案。 make distcheck: 和make dist类似，但是加入检查包装后的压缩文件是否正常。这个目标除了把程序和相关文件包装成tar.gz文件外，还会自动把这个压缩文件解开，执行 configure，并且进行make all 的动作，确认编译无误后，会显示这个tar.gz文件可供发布了。这个检查非常有用，检查过关的包，基本上可以给任何一个具备GNU开发环境-的人去重新编译。 ","date":"2024-01-20","objectID":"/posts/make_install/:2:4","tags":["make_install"],"title":"configure、make、make install 背后的原理","uri":"/posts/make_install/"},{"categories":["Linux"],"content":"3. 总结 通过源码编译安装一个软件如下: ./configure --prefix=/usr/local/${program_name} make make install make clean 注意: --prefix可以在configure或者make install时指定安装路径。 ","date":"2024-01-20","objectID":"/posts/make_install/:3:0","tags":["make_install"],"title":"configure、make、make install 背后的原理","uri":"/posts/make_install/"},{"categories":["Linux"],"content":"4. 参考 Linux命令详解：./configure、make、make install 命令 configure、 make、 make install 背后的原理(翻译) ","date":"2024-01-20","objectID":"/posts/make_install/:4:0","tags":["make_install"],"title":"configure、make、make install 背后的原理","uri":"/posts/make_install/"},{"categories":["C++"],"content":"0. 简介 作为一个程序而言，benchmark是非常关键的一个衡量指标，无论是程序算法的指标还是程序运行性能的指标，这些我们都可以去完成衡量。对于性能衡量而言google benchmark无疑是一个比较好的选择。 性能测试工具对比 ","date":"2024-01-19","objectID":"/posts/google_benchmark_introduction/:1:0","tags":["Google Benchmark"],"title":"Google Benchmark 性能测试分析工具","uri":"/posts/google_benchmark_introduction/"},{"categories":["C++"],"content":"1. google benchmark安装 google benchmark 下载地址 编译安装: 登录 linux环境，执行以下命令，进行编译安装： git clone https://github.com/google/benchmark.git cd benchmark git clone https://github.com/google/googletest.git mkdir build cd build cmake .. -DCMAKE_BUILD_TYPE=RELEASE make -j4 # 如果想全局安装就接着运行下面的命令 sudo make install ","date":"2024-01-19","objectID":"/posts/google_benchmark_introduction/:2:0","tags":["Google Benchmark"],"title":"Google Benchmark 性能测试分析工具","uri":"/posts/google_benchmark_introduction/"},{"categories":["C++"],"content":"2. 代码编写 创建一个C++源文件，并编写包含基准测试函数的代码。例如，创建一个名为benchmark_example.cpp的文件，并编写如下内容： #include \u003cbenchmark/benchmark.h\u003e static void BM_MyFunction(benchmark::State\u0026 state) { // 在这里编写您要测试的代码 for (auto _ : state) { // 执行您的代码 } } BENCHMARK(BM_MyFunction); BENCHMARK_MAIN(); 在上述示例中，BM_MyFunction是您要测试的函数。 然后我们可以使用C++编译器编译您的代码，并链接Google Benchmark库。 g++ benchmark_example.cpp -o benchmark_example -lbenchmark -lpthread 如果是cmakelist，则可以使用 set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -pthread\") # benchmark依赖thread线程库 add_library(benchmark STATIC IMPORTED) set_property(TARGET benchmark PROPERTY IMPORTED_LOCATION /usr/local/lib/libbenchmark.a) add_executable(demo demo.cpp) target_link_libraries(demo benchmark ) install(TARGETS demo DESTINATION \"bin/\" ) ","date":"2024-01-19","objectID":"/posts/google_benchmark_introduction/:3:0","tags":["Google Benchmark"],"title":"Google Benchmark 性能测试分析工具","uri":"/posts/google_benchmark_introduction/"},{"categories":["C++"],"content":"2.1 基础代码调用测试 我们可以看到每一个benchmark测试用例都是一个类型为std::function的函数，其中benchmark::State\u0026负责测试的运行及额外参数的传递。 测试用例编写完成后，我们需要使用BENCHMARK()将我们的测试用例注册进benchmark，这样程序运行时才会执行我们的测试。 最后是用BENCHMARK_MAIN();替代直接编写的main函数，它会处理命令行参数并运行所有注册过的测试用例生成测试结果。 Example 1: #include \u003cbenchmark/benchmark.h\u003e #include \u003cvector\u003e #include \u003carray\u003e constexpr int len = 6; std::vector\u003cint\u003e vec{1, 2, 3, 4, 5, 6}; std::array\u003cint, len\u003e array{1, 2, 3, 4, 5, 6}; // benchmark::State \u0026state用于维护测试上下文信息，以及控制迭代次数 static void vector_test(benchmark::State \u0026state) { for (auto _ : state) { vec[0]; vec[1]; vec[2]; vec[3]; vec[4]; vec[5]; } } static void array_test(benchmark::State \u0026state) { for (auto _ : state) { array[0]; array[1]; array[2]; array[3]; array[4]; array[5]; } } // 注册测试用例 BENCHMARK(vector_test); BENCHMARK(array_test); // benchmark的主函数 BENCHMARK_MAIN(); 结果格式如下: Load Average: 0.43, 0.25, 0.10 ------------------------------------------------------ Benchmark Time CPU Iterations ------------------------------------------------------ vector_test 6.81 ns 6.81 ns 102373755 array_test 13.6 ns 13.6 ns 51227934 Example 2 #include \u003cbenchmark/benchmark.h\u003e #include \u003carray\u003e constexpr int len = 6; // constexpr function具有inline属性，你应该把它放在头文件中 constexpr auto my_pow(const int i) { return i * i; } // 使用operator[]读取元素，依次存入1-6的平方 static void bench_array_operator(benchmark::State\u0026 state) { std::array\u003cint, len\u003e arr; constexpr int i = 1; for (auto _: state) { arr[0] = my_pow(i); arr[1] = my_pow(i+1); arr[2] = my_pow(i+2); arr[3] = my_pow(i+3); arr[4] = my_pow(i+4); arr[5] = my_pow(i+5); } } BENCHMARK(bench_array_operator); // 使用at()读取元素，依次存入1-6的平方 static void bench_array_at(benchmark::State\u0026 state) { std::array\u003cint, len\u003e arr; constexpr int i = 1; for (auto _: state) { arr.at(0) = my_pow(i); arr.at(1) = my_pow(i+1); arr.at(2) = my_pow(i+2); arr.at(3) = my_pow(i+3); arr.at(4) = my_pow(i+4); arr.at(5) = my_pow(i+5); } } BENCHMARK(bench_array_at); // std::get\u003c\u003e(array)是一个constexpr function，它会返回容器内元素的引用，并在编译期检查数组的索引是否正确 static void bench_array_get(benchmark::State\u0026 state) { std::array\u003cint, len\u003e arr; constexpr int i = 1; for (auto _: state) { std::get\u003c0\u003e(arr) = my_pow(i); std::get\u003c1\u003e(arr) = my_pow(i+1); std::get\u003c2\u003e(arr) = my_pow(i+2); std::get\u003c3\u003e(arr) = my_pow(i+3); std::get\u003c4\u003e(arr) = my_pow(i+4); std::get\u003c5\u003e(arr) = my_pow(i+5); } } BENCHMARK(bench_array_get); BENCHMARK_MAIN(); 我们可以看到每一个benchmark测试用例都是一个类型为std::function\u003cvoid(benchmark::State\u0026)\u003e的函数，其中benchmark::State\u0026负责测试的运行及额外参数的传递。 随后我们使用for (auto _: state) {}来运行需要测试的内容，state会选择合适的次数来运行循环，时间的计算从循环内的语句开始，所以我们可以选择像例子中一样在for循环之外初始化测试环境，然后在循环体内编写需要测试的代码。 测试用例编写完成后我们需要使用BENCHMARK(\u003cfunction_name\u003e);将我们的测试用例注册进benchmark，这样程序运行时才会执行我们的测试。 最后是用BENCHMARK_MAIN();替代直接编写的main函数，它会处理命令行参数并运行所有注册过的测试用例生成测试结果。 示例中大量使用了constexpt，这是为了能在编译期计算出需要的数值避免对测试产生太多噪音。 然后我们编译测试程序： g++ -Wall -std=c++14 benchmark_example.cpp -pthread -lbenchmark benchmark需要链接libbenchmark.so，所以需要指定-lbenchmark，此外还需要thread的支持，因为libstdc++不提供thread的底层实现，我们需要pthread。另外不建议使用-lpthread，官方表示会出现兼容问题，在我这测试也会出现链接错误。注意文件名一定要在-lbenchmark前面，否则编译会失败，具体参见：https://github.com/google/benchmark/issues/619 如果你是在Windows平台使用google/benchmark，那么你需要额外链接shlwapi.lib才能使benchmark正常编译和运行。详细信息在这里。 编译好程序后就可以运行测试了： 2024-01-20T15:56:26+08:00 Running ./benchmark_example_two Run on (4 X 3700 MHz CPU s) CPU Caches: L1 Data 32 KiB (x4) L1 Instruction 32 KiB (x4) L2 Unified 256 KiB (x4) L3 Unified 8192 KiB (x1) Load Average: 0.36, 0.64, 0.82 ***WARNING*** CPU scaling is enabled, the benchmark real time measurements may be noisy and will incur extra overhead. --------------------------------------------------------------- Benchmark Time CPU Iterations --------------------------------------------------------------- bench_array_operator 30.9 ns 30.6 ns 22700640 bench_array_at 31.1 ns 30.9 ns 22376913 bench_array_get 29.4 ns 29.4 ns 23760270 显示的警告信息表示在当前系统环境有一些噪音(例如其他在运行的程序)可能导致结果不太准确，并不影响我们的测试。 在Windows上通常没有上述警告，如果你需要在Linux平台上去除相关警告的话，请参考此处。 测试结果与预期基本相符，std::get最快，at()最慢。 ","date":"2024-01-19","objectID":"/posts/google_benchmark_introduction/:3:1","tags":["Google Benchmark"],"title":"Google Benchmark 性能测试分析工具","uri":"/posts/google_benchmark_introduction/"},{"categories":["C++"],"content":"2.2 传参调用测试 上面的测试用例都只接受一个benchmark::State\u0026类型的参数，所以我们可以使用BENCHMARK宏生成的对象的Arg方法来完成参数的传递。 传递进来的参数会被放入state对象内部存储，通过range方法获取，调用时的参数0是传入参数的需要，对应第一个参数。 举个例子，假如我们需要实现一个队列，现在有ring buffer和linked list两种实现可选，现在我们要测试两种方案在不同情况下的性能表现： // 必要的数据结构 #include \u003cbenchmark/benchmark.h\u003e #include \"ring.h\" #include \"linked_ring.h\" // ring buffer的测试 static void bench_array_ring_insert_int_10(benchmark::State\u0026 state) { auto ring = ArrayRing\u003cint\u003e(10); for (auto _: state) { for (int i = 1; i \u003c= 10; ++i) { ring.insert(i); } state.PauseTiming(); // 暂停计时 ring.clear(); state.ResumeTiming(); // 恢复计时 } } BENCHMARK(bench_array_ring_insert_int_10); // linked list的测试 static void bench_linked_queue_insert_int_10(benchmark::State \u0026state) { auto ring = LinkedRing\u003cint\u003e{}; for (auto _:state) { for (int i = 0; i \u003c 10; ++i) { ring.insert(i); } state.PauseTiming(); ring.clear(); state.ResumeTiming(); } } BENCHMARK(bench_linked_queue_insert_int_10); // 还有针对删除的测试，以及针对string的测试，都是高度重复的代码，这里不再罗列 很显然，上面的测试除了被测试类型和插入的数据量之外没有任何区别，如果可以通过传入参数进行控制的话就可以少写大量重复的代码。 编写重复的代码是浪费时间，而且往往意味着你在做一件蠢事，google的工程师们当然早就注意到了这一点。虽然测试用例只能接受一个benchmark::State\u0026类型的参数，但我们可以将参数传递给state对象，然后在测试用例中获取： static void bench_array_ring_insert_int(benchmark::State\u0026 state) { auto length = state.range(0); auto ring = ArrayRing\u003cint\u003e(length); for (auto _: state) { for (int i = 1; i \u003c= length; ++i) { ring.insert(i); } state.PauseTiming(); ring.clear(); state.ResumeTiming(); } } BENCHMARK(bench_array_ring_insert_int)-\u003eArg(10); 上面的例子展示了如何传递和获取参数： 传递参数使用BENCHMARK宏生成的对象的Arg方法 传递进来的参数会被放入state对象内部存储，通过range方法获取，调用时的参数0是传入参数的需要，对应第一个参数 Arg方法一次只能传递一个参数，那如果一次想要传递多个参数呢？也很简单： static void bench_array_ring_insert_int(benchmark::State\u0026 state) { auto ring = ArrayRing\u003cint\u003e(state.range(0)); for (auto _: state) { for (int i = 1; i \u003c= state.range(1); ++i) { ring.insert(i); } state.PauseTiming(); ring.clear(); state.ResumeTiming(); } } BENCHMARK(bench_array_ring_insert_int)-\u003eArgs({10, 10}); 上面的例子没什么实际意义，只是为了展示如何传递多个参数，Args方法接受一个vector对象，所以我们可以使用c++11提供的大括号初始化器简化代码，获取参数依然通过state.range方法，1对应传递进来的第二个参数。 有一点值得注意，参数传递只能接受整数，如果你希望使用其他类型的附加参数，就需要另外想些办法了。 ","date":"2024-01-19","objectID":"/posts/google_benchmark_introduction/:3:2","tags":["Google Benchmark"],"title":"Google Benchmark 性能测试分析工具","uri":"/posts/google_benchmark_introduction/"},{"categories":["C++"],"content":"2.3 简化多个类似测试用例的生成功 向测试用例传递参数的最终目的是为了在不编写重复代码的情况下生成多个测试用例，在知道了如何传递参数后你可能会这么写： static void bench_array_ring_insert_int(benchmark::State\u0026 state) { auto length = state.range(0); auto ring = ArrayRing\u003cint\u003e(length); for (auto _: state) { for (int i = 1; i \u003c= length; ++i) { ring.insert(i); } state.PauseTiming(); ring.clear(); state.ResumeTiming(); } } // 下面我们生成测试插入10，100，1000次的测试用例 BENCHMARK(bench_array_ring_insert_int)-\u003eArg(10); BENCHMARK(bench_array_ring_insert_int)-\u003eArg(100); BENCHMARK(bench_array_ring_insert_int)-\u003eArg(1000); 2024-01-20T15:56:26+08:00 Running ./benchmark_example_two Run on (4 X 3700 MHz CPU s) CPU Caches: L1 Data 32 KiB (x4) L1 Instruction 32 KiB (x4) L2 Unified 256 KiB (x4) L3 Unified 8192 KiB (x1) Load Average: 0.36, 0.64, 0.82 ***WARNING*** CPU scaling is enabled, the benchmark real time measurements may be noisy and will incur extra overhead. -------------------------------------------------------------------------------- Benchmark Time CPU Iterations ---------------------------------------------------------------------------------- bench_array_ring_insert_int/10 584 ns 547 ns 1000000 bench_array_ring_insert_int/100 1357 ns 1367 ns 560000 bench_array_ring_insert_int/1000 9207 ns 9521 ns 64000 以上的代码虽然结果是正确的，但是仍然写了很多重复代码！ 幸好Arg和Args会将我们的测试用例使用的参数进行注册以便产生用例名/参数的新测试用例，并且返回一个指向BENCHMARK宏生成对象的指针，换句话说，如果我们想要生成仅仅是参数不同的多个测试的话，只需要链式调用Arg和Args即可： BENCHMARK(bench_array_ring_insert_int)-\u003eArg(10)-\u003eArg(100)-\u003eArg(1000); 结果和上面一样。 但这还不是最优解，我们仍然重复调用了Arg方法，如果我们需要更多用例时就不得不又要做重复劳动了。 对此google benchmark也有解决办法：我们可以使用Range方法来自动生成一定范围内的参数。 先看看Range的原型： BENCHMAEK(func)-\u003eRange(int64_t start, int64_t limit); start表示参数范围起始的值，limit表示范围结束的值，Range所作用于的是一个_闭区间_。 但是如果我们这样改写代码，是会得到一个错误的测试结果: BENCHMARK(bench_array_ring_insert_int)-\u003eRange(10, 1000); -------------------------------------------------------------------------------- Benchmark Time CPU Iterations ---------------------------------------------------------------------------------- bench_array_ring_insert_int/10 584 ns 625 ns 1000000 bench_array_ring_insert_int/64 1042 ns 1029 ns 896000 bench_array_ring_insert_int/512 4948 ns 5313 ns 100000 bench_array_ring_insert_int/1000 9221 ns 8545 ns 89600 为什么会这样呢？那是因为Range默认除了start和limit，中间的其余参数都会是某一个基底（base）的幂，基地默认为8，所以我们会看到64和512，它们分别是8的平方和立方。 想要改变这一行为也很简单，只要重新设置基底即可，通过使用RangeMultiplier方法： BENCHMARK(bench_array_ring_insert_int)-\u003eRangeMultiplier(10)-\u003eRange(10, 1000); 现在结果恢复如初了。 使用Ranges可以处理多个参数的情况： BENCHMARK(func)-\u003eRangeMultiplier(10)-\u003eRanges({{10, 1000}, {128， 256}}); 第一个范围指定了测试用例的第一个传入参数的范围，而第二个范围指定了第二个传入参数可能的值（注意这里不是范围了）。 与下面的代码等价： BENCHMARK(func)-\u003eArgs({10, 128}) -\u003eArgs({100, 128}) -\u003eArgs({1000, 128}) -\u003eArgs({10, 256}) -\u003eArgs({100, 256}) -\u003eArgs({1000, 256}) 实际上就是用生成的第一个参数的范围于后面指定内容的参数做了一个笛卡尔积。 ","date":"2024-01-19","objectID":"/posts/google_benchmark_introduction/:3:3","tags":["Google Benchmark"],"title":"Google Benchmark 性能测试分析工具","uri":"/posts/google_benchmark_introduction/"},{"categories":["C++"],"content":"2.4 使用参数生成器 如果我想定制没有规律的更复杂的参数呢？这时就需要实现自定义的参数生成器了。 一个参数生成器的签名如下： void CustomArguments(benchmark::internal::Benchmark* b); 我们在生成器中计算处参数，然后调用benchmark::internal::Benchmark对象的Arg或Args方法像上两节那样传入参数即可。 随后我们使用Apply方法把生成器应用到测试用例上： BENCHMARK(func)-\u003eApply(CustomArguments); 其实这一过程的原理并不复杂，我做个简单的解释： BENCHMARK宏产生的就是一个benchmark::internal::Benchmark对象然后返回了它的指针 向benchmark::internal::Benchmark对象传递参数需要使用Arg和Args等方法 Apply方法会将参数中的函数应用在自身 我们在生成器里使用benchmark::internal::Benchmark对象的指针b的Args等方法传递参数，这时的b其实指向我们的测试用例 到此为止生成器是如何工作的已经一目了然了，当然从上面得出的结论，我们还可以让Apply做更多的事情。 下面看下Apply的具体使用： // 这次我们生成100，200，...，1000的测试用例，用range是无法生成这些参数的 static void custom_args(benchmark::internal::Benchmark* b) { for (int i = 100; i \u003c= 1000; i += 100) { b-\u003eArg(i); } } BENCHMARK(bench_array_ring_insert_int)-\u003eRangeMultiplier(10)-\u003eApply(custom_args); ","date":"2024-01-19","objectID":"/posts/google_benchmark_introduction/:3:4","tags":["Google Benchmark"],"title":"Google Benchmark 性能测试分析工具","uri":"/posts/google_benchmark_introduction/"},{"categories":["C++"],"content":"2.5 模板类的调用测试 如果针对每一种情况写测试函数，显然违反了DRY原则，因为除了vector的类型参数不同，其他代码几乎是完全一样的。 #include \u003cbenchmark/benchmark.h\u003e #include \u003cvector\u003e #include \u003carray\u003e template \u003ctypename T, std::size_t length, bool is_reserve = true\u003e void bench_vector_reserve(benchmark::State\u0026 state) { for (auto _ : state) { std::vector\u003cT\u003e container; if constexpr (is_reserve) { container.reserve(length); } for (std::size_t i = 0; i \u003c length; ++i) { container.push_back(T{}); } } } // BENCHMARK_TEMPLATE(bench_vector_reserve, std::string, 100); // // benchmark的主函数 // BENCHMARK_MAIN(); 非常的简单，我们通过length控制插入的元素个数；is_reserve则负责控制是否预分配内存，通过if constexpr可以生成reserve和不进行任何操作的两种代码（如果不熟悉c++17的if constexpr，推荐花两分钟看看这里）。 然后我们像往常一样定义一个测试用例： BENCHMARK(bench_vector_reserve\u003cstd::string,100\u003e); 可是等我们编译的时候却报错了！ $ g++ test.cpp -lpthread -lbenchmark -lbenchmark_main test.cpp:19:48: 错误：宏“BENCHMARK”传递了 2 个参数，但只需要 1 个 19 | BENCHMARK(bench_vector_reserve\u003cstd::string,100\u003e); | ^ In file included from a.cpp:1: /usr/local/include/benchmark/benchmark.h:1146: 附注：macro \"BENCHMARK\" defined here 1146 | #define BENCHMARK(n) \\ | test.cpp:19:1: 错误：‘BENCHMARK’不是一个类型名 19 | BENCHMARK(bench_vector_reserve\u003cstd::string,100\u003e); 原因是这样的，在编译器处理宏的时候实际上不会考虑c++语法，所以分割模板参数的逗号被识别成了分割宏参数的逗号，因此在宏处理器的眼里我们像是传了两个参数。这也说明了BENCHMARK是处理不了模板的。 不过别担心，Google早就想到这种情况了，所以提供了BENCHMARK_TEMPLATE宏，我们只需要把模板名字和需要的类型参数依次传给宏即可： BENCHMARK_TEMPLATE(bench_vector_reserve, std::string, 100); BENCHMARK_TEMPLATE(bench_vector_reserve, std::string, 1000); BENCHMARK_TEMPLATE(bench_vector_reserve, std::string, 10000); BENCHMARK_TEMPLATE(bench_vector_reserve, std::string, 100000); BENCHMARK_TEMPLATE(bench_vector_reserve, std::string, 100, false); BENCHMARK_TEMPLATE(bench_vector_reserve, std::string, 1000, false); BENCHMARK_TEMPLATE(bench_vector_reserve, std::string, 10000, false); BENCHMARK_TEMPLATE(bench_vector_reserve, std::string, 100000, false); 输出: 2024-01-20T19:12:57+08:00 Running ./benchmark_template Run on (4 X 3700 MHz CPU s) CPU Caches: L1 Data 32 KiB (x4) L1 Instruction 32 KiB (x4) L2 Unified 256 KiB (x4) L3 Unified 8192 KiB (x1) Load Average: 1.67, 1.82, 1.39 ***WARNING*** CPU scaling is enabled, the benchmark real time measurements may be noisy and will incur extra overhead. ------------------------------------------------------------------------------------------- Benchmark Time CPU Iterations ------------------------------------------------------------------------------------------- bench_vector_reserve\u003cstd::string, 100\u003e 2912 ns 2910 ns 239967 bench_vector_reserve\u003cstd::string, 1000\u003e 27585 ns 27571 ns 25299 bench_vector_reserve\u003cstd::string, 10000\u003e 275549 ns 275527 ns 2534 bench_vector_reserve\u003cstd::string, 100000\u003e 3158585 ns 2818440 ns 253 bench_vector_reserve\u003cstd::string, 100, false\u003e 7743 ns 7635 ns 89883 bench_vector_reserve\u003cstd::string, 1000, false\u003e 54695 ns 54663 ns 12540 bench_vector_reserve\u003cstd::string, 10000, false\u003e 671379 ns 671340 ns 1050 bench_vector_reserve\u003cstd::string, 100000, false\u003e 8904492 ns 8903935 ns 79 ","date":"2024-01-19","objectID":"/posts/google_benchmark_introduction/:3:5","tags":["Google Benchmark"],"title":"Google Benchmark 性能测试分析工具","uri":"/posts/google_benchmark_introduction/"},{"categories":["C++"],"content":"2.6 定制测试参数 在上面的代码中，length参数其实是不必要的，所以代码可以这样改： template \u003ctypename T, bool is_reserve = true\u003e void bench_vector_reserve(benchmark::State\u0026 state) { for (auto _ : state) { std::vector\u003cT\u003e container; if constexpr (is_reserve) { // 通过range方法获取传入的参数 container.reserve(state.range(0)); } for (std::size_t i = 0; i \u003c state.range(0); ++i) { container.push_back(T{}); } } } BENCHMARK_TEMPLATE(bench_vector_reserve, std::string)-\u003eRangeMultiplier(10)-\u003eRange(10, 10000 * 10); BENCHMARK_TEMPLATE(bench_vector_reserve, std::string, false)-\u003eRangeMultiplier(10)-\u003eRange(10, 10000 * 10); 现在我们测试的元素数量是[10, 100, 1000, 10^4, 10^5]。 除此之外还有另一种叫“密集参数”的Ranges。google benchmark提供了DenseRange方法。 这个方法的原型如下： DenseRange(int64_t start, int64_t end, int64_t step); Ranges是累乘，而DenseRange是累加，因为累乘会导致几何级数的增长，在数轴上的分布越来越稀疏，累加则看上去像是均匀分布的，因此累加的参数生成器被叫做密集参数生成器。 如果我们把测试用例这么改： BENCHMARK_TEMPLATE(bench_vector_reserve, std::string)-\u003eDenseRange(1000, 100 * 100, 1000); 现在我们的length就是这样一个序列：[1000，2000，3000， ...，9000，10000]。 关于自定义参数最后一个知识点是ArgsProduct。看名字就知道这是一个参数工厂。 ArgsProduct(const std::vector\u003c std::vector\u003cint64_t\u003e \u003e\u0026 arglists); std::vector\u003cint64_t\u003e实际上就是一组参数，arglists就是多组参数的合集，他们之间会被求笛卡尔积，举个例子： BENCHMARK(BM_test)-\u003eArgsProduct({ {\"a\", \"b\", \"c\", \"d\"}, {1, 2, 3, 4} }); // 等价于下面的 BENCHMARK(BM_test)-\u003eArgs({\"a\", 1}) -\u003eArgs({\"a\", 2}) -\u003eArgs({\"a\", 3}) -\u003eArgs({\"a\", 4}) -\u003eArgs({\"b\", 1}) -\u003eArgs({\"b\", 2}) -\u003eArgs({\"b\", 3}) ... -\u003eArgs({\"d\", 3}) -\u003eArgs({\"d\", 4}) ``` 我们可以看到参数工厂其实得自己手写所有参数，那如果我想配合工厂使用Ranges呢？ 没问题，benchmark的开发者们早就想到了，所以提供了下面这些帮助函数： benchmark::CreateRange(8, 128, /*multi=*/2) // 生成：[8, 16, 32, 64, 128] benchmark::CreateDenseRange(1, 6, /*step=*/1) // 生成：[1, 2, 3, 4, 5, 6] 如果换成我们的例子，就可以这样写： BENCHMARK_TEMPLATE(bench_vector_reserve, std::string)-\u003eArgsProduct({ benchmark::CreateRange(10, 10000*10, 10) }); BENCHMARK_TEMPLATE(bench_vector_reserve, std::string, false)-\u003eArgsProduct({ benchmark::CreateRange(10, 10000*10, 10) }); 借助仅仅两行代码我们就能生成数量可观的测试用例： 2024-01-20T19:26:55+08:00 Running ./bm_template_2 Run on (4 X 3700 MHz CPU s) CPU Caches: L1 Data 32 KiB (x4) L1 Instruction 32 KiB (x4) L2 Unified 256 KiB (x4) L3 Unified 8192 KiB (x1) Load Average: 1.91, 2.05, 1.65 ***WARNING*** CPU scaling is enabled, the benchmark real time measurements may be noisy and will incur extra overhead. ------------------------------------------------------------------------------------------ Benchmark Time CPU Iterations ------------------------------------------------------------------------------------------ bench_vector_reserve\u003cstd::string\u003e/10 466 ns 466 ns 1505218 bench_vector_reserve\u003cstd::string\u003e/100 3549 ns 3548 ns 200461 bench_vector_reserve\u003cstd::string\u003e/1000 34067 ns 34049 ns 20858 bench_vector_reserve\u003cstd::string\u003e/10000 324499 ns 324370 ns 2125 bench_vector_reserve\u003cstd::string\u003e/100000 3229254 ns 3227361 ns 219 bench_vector_reserve\u003cstd::string, false\u003e/10 1604 ns 1603 ns 436414 bench_vector_reserve\u003cstd::string, false\u003e/100 7707 ns 7705 ns 89743 bench_vector_reserve\u003cstd::string, false\u003e/1000 57709 ns 57694 ns 12026 bench_vector_reserve\u003cstd::string, false\u003e/10000 688582 ns 688283 ns 1008 bench_vector_reserve\u003cstd::string, false\u003e/100000 9208480 ns 9205775 ns 75 当然，这只是一个类型参数，实际上我们还有另外两个类型需要测试。另外这是1.5.5新增的功能，如果你想尝鲜得先升级google benchmark。 通常做到上面那一步就足够了，然而在这里我们还有优化空间，因为如果我们把其他两个测试用的类型加上，代码是这样的，MyClass的定义后面会给出： BENCHMARK_TEMPLATE(bench_vector_reserve, std::string)-\u003eArgsProduct({ benchmark::CreateRange(10, 10000*10, 10) }); BENCHMARK_TEMPLATE(bench_vector_reserve, std::string, false)-\u003eArgsProduct({ benchmark::CreateRange(10, 10000*10, 10) }); BENCHMARK_TEMPLATE(bench_vector_reserve, std::size_t)-\u003eArgsProduct({ benchmark::CreateRange(10, 10000*10, 10) }); BENCHMARK_TEMPLATE(bench_vector_reserve, std::size_t, false)-\u003eArgsProduct({ benchmark::CreateRange(10, 10000*10, 10) }); BENCHMARK_TEMPLATE(bench_vector_reserve, MyClass)-\u003eArgsProduct({ benchmark::CreateRange(10, 10000*10, 10) }); BENCHMARK_TEMPLATE(bench_vector_reserve, MyClass, false)-\u003eArgsProduct({ benchmark::CreateRange(10, 10000*10, 10) }); 你看见了什么？没错，重复重复重复！我们又违背了DRY原则。 ","date":"2024-01-19","objectID":"/posts/google_benchmark_introduction/:3:6","tags":["Google Benchmark"],"title":"Google Benchmark 性能测试分析工具","uri":"/posts/google_benchmark_introduction/"},{"categories":["C++"],"content":"2.7. 使用Benchmark接口 这里将待测试的函数注册为一个基准测试用例，并指定测试用例的名称和参数。该代码中使用了三种不同的注册方式：函数指针、Lambda 函数和带参数的函数指针。最后，使用 benchmark::RunSpecifiedBenchmarks 函数运行所有注册的基准测试用例，并使用 benchmark::Shutdown 函数释放资源。 #include \u003cbenchmark/benchmark.h\u003e #include \u003cchrono\u003e #include \u003cthread\u003e void BM_DemoSleep(benchmark::State\u0026 state) { for (auto _ : state){ std::this_thread::sleep_for(std::chrono::nanoseconds(1000)); //待测试的代码 } } void BM_DemoSleep1(benchmark::State\u0026 state, int id) { std::cout \u003c\u003c \"id:\"\u003c\u003c id \u003c\u003c std::endl; for (auto _ : state){ std::this_thread::sleep_for(std::chrono::nanoseconds(1000)); } } int main(int argc, char** argv) { benchmark::Initialize(\u0026argc, argv); // 初始化Benchmark if (benchmark::ReportUnrecognizedArguments(argc, argv)) return 1; // 使用函数指针注册 benchmark::RegisterBenchmark(\"BM_DemoSleep\", \u0026BM_DemoSleep); // 使用Lamba函数注册 benchmark::RegisterBenchmark(\"BM_DemoSleep1\", [](benchmark::State\u0026 state){ for (auto _ : state){ std::this_thread::sleep_for(std::chrono::nanoseconds(1000)); } }); // 使用带参数的函数指针注册 int id = 10; benchmark::RegisterBenchmark(\"BM_DemoSleep2\", \u0026BM_DemoSleep1, id); benchmark::RunSpecifiedBenchmarks(); // 运行 benchmark::Shutdown(); } ","date":"2024-01-19","objectID":"/posts/google_benchmark_introduction/:3:7","tags":["Google Benchmark"],"title":"Google Benchmark 性能测试分析工具","uri":"/posts/google_benchmark_introduction/"},{"categories":["C++"],"content":"3. Ref: [1]. https://mp.weixin.qq.com/s/hrKwlKj6i2twd_qNqaHyYg [2]. Google Benchmark 用户手册 [3]. https://www.cnblogs.com/apocelipes/p/10348925.html ","date":"2024-01-19","objectID":"/posts/google_benchmark_introduction/:4:0","tags":["Google Benchmark"],"title":"Google Benchmark 性能测试分析工具","uri":"/posts/google_benchmark_introduction/"},{"categories":["C++"],"content":"四、C++ 20新增特性 ","date":"2024-01-17","objectID":"/posts/cmake_note_9/:1:0","tags":["CMake"],"title":"CMake 笔记 | [9] 设置语言标准 (三)","uri":"/posts/cmake_note_9/"},{"categories":["C++"],"content":"4.1 新增关键字 concept(见下文) requires std::require 是一个constexpr 函数模板，用于在编译时检查某个表达式的真假值。如果表达式为真，则该函数返回一个无意义的类型 void_t；否则编译会失败，出现相应的错误信息 consteval 用来修饰函数时常量值的表达式，而且是强制性的。如果函数本身不是常量值的表达式的话则会编译失败 co_await(协程相关) co_return(协程相关) co_yield(协程相关) char8_t ","date":"2024-01-17","objectID":"/posts/cmake_note_9/:1:1","tags":["CMake"],"title":"CMake 笔记 | [9] 设置语言标准 (三)","uri":"/posts/cmake_note_9/"},{"categories":["C++"],"content":"4.2 新增标识符 import module 模块 优点 没有头文件 声明实现仍然可分离, 但非必要 可以显式指定那些导出(类, 函数等) 不需要头文件重复引入宏 (include guards) 模块之间名称可以相同不会冲突 模块只处理一次, 编译更快 (头文件每次引入都需要处理) 预处理宏只在模块内有效 模块引入顺序无关紧要 创建模块 // cppcon.cpp export module cppcon; namespace CppCon { auto GetWelcomeHelper() { return \"Welcome to CppCon 2019!\"; } export auto GetWelcome() { return GetWelcomeHelper();} } 引用模块 // main.cpp import cppcon; int main(){ std::cout \u003c\u003c CppCon::GetWelcome(); } ","date":"2024-01-17","objectID":"/posts/cmake_note_9/:1:2","tags":["CMake"],"title":"CMake 笔记 | [9] 设置语言标准 (三)","uri":"/posts/cmake_note_9/"},{"categories":["C++"],"content":"4.3 import头文件 import 隐式地将 iostream 转换为模块 加速构建, 因为 iostream 只会处理一次 和预编译头 (PCH) 具有相似的效果 ","date":"2024-01-17","objectID":"/posts/cmake_note_9/:1:3","tags":["CMake"],"title":"CMake 笔记 | [9] 设置语言标准 (三)","uri":"/posts/cmake_note_9/"},{"categories":["C++"],"content":"4.4 Ranges Range 代表一串元素, 或者一串元素中的一段，类似于begin/end 对。 好处 简化语法和方便使用 防止 begin/end 不配对 使变换/过滤等串联操作成为可能 相关功能 视图: 延迟计算, 不持有, 不改写 Actions: 即时处理, 改写 Algorithms: 所有接受 begin/end 对的算法都可用 Views 和 actions 使用管道符|串联 ","date":"2024-01-17","objectID":"/posts/cmake_note_9/:1:4","tags":["CMake"],"title":"CMake 笔记 | [9] 设置语言标准 (三)","uri":"/posts/cmake_note_9/"},{"categories":["C++"],"content":"4.5 协程 协程定义是一个函数，具备如下关键字之一: co_wait: 挂起协程, 等待其它计算完成 co_return: 从协程返回 (协程 return 禁止使用) co_yield: 同 python yield, 弹出一个值, 挂起协程, 下一次调用继续协程的运行 for co_await 循环体 应用场景 简化generator 简化异步I/O 简化延迟计算 简化事件驱动的程序 ","date":"2024-01-17","objectID":"/posts/cmake_note_9/:1:5","tags":["CMake"],"title":"CMake 笔记 | [9] 设置语言标准 (三)","uri":"/posts/cmake_note_9/"},{"categories":["C++"],"content":"4.6 Concepts 对模板类和函数的模板形参的约束 编译期断言 可声明多个 定义 template\u003ctypename T\u003e concept Incrementable = requires(T x) {x++; ++x;}; 使用 template\u003cIncrementable T\u003e void Foo(T t); template\u003ctypename T\u003e requires Incrementable\u003cT\u003e void Foo(T t); template\u003ctypename T\u003e void Foo(T t) requires Incrementable\u003cT\u003e; void Foo(Incrementable auto t); ","date":"2024-01-17","objectID":"/posts/cmake_note_9/:1:6","tags":["CMake"],"title":"CMake 笔记 | [9] 设置语言标准 (三)","uri":"/posts/cmake_note_9/"},{"categories":["C++"],"content":"4.7 Lambda表达式更新 [=, this] 需要显式捕获this变量 C++20 之前 [=] 隐式捕获this C++20 开始 需要显式捕获this: [=, this] 模板形式的 Lambda 表达式 可以在lambda表达式中使用模板语法: []template\u003cT\u003e(T x) {/* ... */}; []template\u003cT\u003e(T* p) {/* ... */}; []template\u003cT, int N\u003e(T (\u0026a)[N]) {/* ... */}; 优点 C++20之前: 获取 vector 元素类型, 需要这么写 auto func = [](auto vec){ using T = typename decltype(vec)::value_type; } C++20 可以: auto func = []\u003ctypename T\u003e(vector\u003cT\u003e vec){ // ... } 方便获取通用lambda形参类型, 访问静态函数: C++20之前： auto func = [](auto const\u0026 x){ using T = std::decay_t\u003cdecltype(x)\u003e; T copy = x; T::static_function(); using Iterator = typename T::iterator; } C++20以后： auto func = []\u003ctypename T\u003e(const T\u0026 x){ T copy = x; T::static_function(); using Iterator = typename T::iterator; } 完美转发 C++20之前： auto func = [](auto\u0026\u0026 ...args) { return foo(std::forward\u003cdecltype(args)\u003e(args)...); } C++20以后： auto func = []\u003ctypename …T\u003e(T\u0026\u0026 …args){ return foo(std::forward(args)...); } Lambda 表达式捕获支持打包展开(Pack Expansion) C++20之前： template\u003cclass F, class... Args\u003e auto delay_invoke(F f, Args... args){ return [f, args...]{ return std::invoke(f, args...); } } C++20以后： template\u003cclass F, class... Args\u003e auto delay_invoke(F f, Args... args){ // Pack Expansion: args = std::move(args)... return [f = std::move(f), args = std::move(args)...](){ return std::invoke(f, args...); } } ","date":"2024-01-17","objectID":"/posts/cmake_note_9/:1:7","tags":["CMake"],"title":"CMake 笔记 | [9] 设置语言标准 (三)","uri":"/posts/cmake_note_9/"},{"categories":["C++"],"content":"4.8 常量表达式(constexpr)的更新 constexpr 虚函数 constexpr 的虚函数可以重写非 constexpr 的虚函数 非 constexpr 虚函数可以重写 constexpr 的虚函数 使用 dynamic_cast() 和 typeid 动态内存分配 更改union成员的值 包含 try/catch 不允许throw语句 在触发常量求值的时候 try/catch 不发生作用 需要开启 constexpr std::vector constexpr string \u0026vector std::string 和 std::vector 类型现在可以作为 constexpr 未来需要支持 constexpr 反射 ","date":"2024-01-17","objectID":"/posts/cmake_note_9/:1:8","tags":["CMake"],"title":"CMake 笔记 | [9] 设置语言标准 (三)","uri":"/posts/cmake_note_9/"},{"categories":["C++"],"content":"4.9 原子智能指针 智能指针(shared_ptr)线程安全问题： 安全: 引用计数控制单元线程安全, 保证对象只被释放一次 不安全：对于数据的读写没有线程安全 将智能指针变成线程安全： 使用 mutex 控制智能指针的访问 使用全局非成员原子操作函数访问, 诸如: std::atomic_load(), atomic_store(), … C++20: atomic\u003cshared_ptr\u003cT\u003e\u003e, atomic\u003cweak_ptr\u003cT\u003e\u003e： 内部原理可能使用了mutex 全局非成员原子操作函数标记为不推荐使用(deprecated) ","date":"2024-01-17","objectID":"/posts/cmake_note_9/:1:9","tags":["CMake"],"title":"CMake 笔记 | [9] 设置语言标准 (三)","uri":"/posts/cmake_note_9/"},{"categories":["C++"],"content":"4.10 自动合流(Joining),可中断的线程 自动合流 void DoWorkPreCpp20() { std::thread job([] { /* ... */ }); try { // ... Do something else ... } catch (...) { job.join(); throw; // rethrow } job.join(); } void DoWork() { std::jthread job([] { /* ... */ }); // ... Do something else ... } // jthread destructor automatically calls join() 中断 std::jthread job([](std::stop_token token) { while (!token.stop_requested()) { //... } }); //... job.request_stop(); // auto source = job.get_stop_source() // auto token = job.get_stop_token() ","date":"2024-01-17","objectID":"/posts/cmake_note_9/:1:10","tags":["CMake"],"title":"CMake 笔记 | [9] 设置语言标准 (三)","uri":"/posts/cmake_note_9/"},{"categories":["C++"],"content":"4.11 同步(Synchronization)库 在传统的多线程（进程）的编程中，处理数据共享是一个重中之重。目前流行的多核（多CPU）编程中，虽然采用了更多的分布式的算法，但最终细分到一个处理单元中，仍然是处理线程间数据的拆分。即，通过数据结构的设计和算法的分拆，实现最小的数据冲突结果。 解决多线程编程中的一个重要的问题就是 如何处理数据的同步问题，如有mutex,event,condition等等。也有的会提到c++11后的lock等。 在c++20中增加了以下几类同步 数据结构: 信号量(Semaphore) 轻量级的同步原语，可以实现 mutex, latches, barriers, …等同步数据结构。 两种表现类型: 多元信号量(counting semaphore): 建模非负值资源计数 二元信号量(binary semaphore): 只有两个状态的信号量 主要方法有： release：增加内部计数器并对获取者解除阻塞 acquire ：减少内部计数器或阻塞到直至能获取 try_acquire：尝试减少内部计数器而不阻塞 try_acquire_for ：尝试减少内部计数器，至多阻塞一段时长 try_acquire_until：尝试减少内部计数器，阻塞直至一个时间点 std::atomic 等待和通知接口 等待/阻塞在原子对象直到其值发生改变, 然后通知函数发送通知，它比单纯的自旋锁和轮询要效率高。 主要方法有： wait：阻塞线程直至被提醒且原子值更改 notify_one：提醒至少一个在原子对象上的等待中阻塞的线程 notify_all：提醒所有在原子对象上的等待中阻塞的线程 这个其实是实现CAS的，在以前就有，在c++20中又增加了相关的一些具体的实现罢了。 锁存器(Latches) latch 是 std::ptrdiff_t 类型的向下计数器，它能用于同步线程。在创建时初始化计数器的值。线程可能在 latch 上阻塞直至计数器减少到零。没有可能增加或重置计数器，这使得 latch 为单次使用的屏障。同时调用 latch 的成员函数，除了析构函数，不引入数据竞争。 注意：它区别于下面的Barriers的是它只有使用一次。 屏障(Barriers) std::barrier 提供允许至多为期待数量的线程阻塞直至期待数量的线程到达该屏障。不同于 std::latch ，屏障可重用：一旦到达的线程从屏障阶段的同步点除阻，则可重用同一屏障。 ","date":"2024-01-17","objectID":"/posts/cmake_note_9/:1:11","tags":["CMake"],"title":"CMake 笔记 | [9] 设置语言标准 (三)","uri":"/posts/cmake_note_9/"},{"categories":["C++"],"content":"4.12 std::atomic_ref std::atomic_ref类型对其引用的对象进行原子操作。 使用std::atomic_ref 进行多线程读写时不会造成数据争用。被引用对象的生命周期必须超过std::atomic_ref 。操作std::atomic_ref 的子对象是未定义行为。 ","date":"2024-01-17","objectID":"/posts/cmake_note_9/:1:12","tags":["CMake"],"title":"CMake 笔记 | [9] 设置语言标准 (三)","uri":"/posts/cmake_note_9/"},{"categories":["C++"],"content":"4.13 其他更新 指定初始化(Designated Initializers) struct Data { int anInt = 0; std::string aString; }; Data d{ .aString = \"Hello\" }; 三路比较运算符 \u003c=\u003e // 如果 a \u003c b 则为 true (a \u003c=\u003e b) \u003c 0 // 如果 a \u003e b 则为 true (a \u003c=\u003e b) \u003e 0 // 如果 a 与 b 相等或者等价 则为 true (a \u003c=\u003e b) == 0 标准库类型支持: vector, string, map, set, sub_match, … 范围 for 循环语句支持初始化语句 switch 语句初始化 (C++17): struct Foo { int value; int result; }; Foo GetData() { return Foo(); } int main() { switch (auto data = GetData(); data.value) { case 1: return data.result; } } if 语句初始化 (C++17): struct Foo { int value; int result; }; Foo* GetData() { return new Foo(); } int main() { if (auto data = GetData(); data) { // Use 'data’ } } 现在范围 for 循环同样支持初始化 (C++20): struct Foo { std::vector\u003cint\u003e values; }; Foo GetData() { return Foo(); } int main() { for (auto data = GetData(); auto\u0026 value : data.values) { // Use 'data’ } } 非类型模板形参支持字符串 template\u003cauto\u0026 s\u003e void DoSomething() { std::cout \u003c\u003c s \u003c\u003c std::endl; } int main() { DoSomething\u003c\"CppCon\"\u003e(); } [[likely]], [[unlikely]] 先验概率指导编译器优化 switch (value) { case 1: break; [[likely]] case 2: break; [[unlikely]] case 3: break; } 日历(Calendar)和时区(Timezone)功能 增加日历和时区的支持 只支持公历(Gregorian calendar) 其他日历也可通过扩展加入, 并能和 进行交互 具体操作和相关类型请参考其他示例。 std::span 定义：某段连续数据的”视图” 特性： 不持有数据, 不分配和销毁数据 拷贝非常快, 推荐复制的方式传参(类似 string_view) 不支持数据跨步(stride) 可通过运行期确定长度也可编译器确定长度 // fixed-size: 42 ints int data[42]; span\u003cint, 42\u003e a {data}; // dynamic-size: 42 ints span\u003cint\u003e b {data}; // compilation error span\u003cint, 50\u003e c {data}; // dynamic-size: len ints span\u003cint\u003e d{ ptr, len }; 特性测试宏 通过它可以判断编译器是否支持某个功能。 语言特性： __has_cpp_attribute(fallthrough) __cpp_binary_literals __cpp_char8_t __cpp_coroutines 标准库特性: __cpp_lib_concepts __cpp_lib_ranges __cpp_lib_scoped_lock 包含 C++ 标准库版本, 发布日期, 版权证书, 特性宏等。 consteval 函数 constexpr 函数可能编译期执行, 也可以在运行期执行 consteval 只能在编译器执行, 如果不满足要求编译不通过。 constinit: 强制指定以常量方式初始化 const char* GetStringDyn() { return \"dynamic init\"; } constexpr const char* GetString(bool constInit) { return constInit ? \"constant init\" : GetStringDyn(); } // ✔ constinit const char* a = GetString(true); // ❌ constinit const char* b = GetString(false); 用 using 引用 enum 类型 enum class CardTypeSuit { Clubs, Diamonds, Hearts, Spades }; std::string_view GetString(const CardTypeSuit cardTypeSuit) { switch (cardTypeSuit) { case CardTypeSuit::Clubs: return \"Clubs\"; case CardTypeSuit::Diamonds: return \"Diamonds\"; case CardTypeSuit::Hearts: return \"Hearts\"; case CardTypeSuit::Spades: return \"Spades\"; } } std::string_view GetString(const CardTypeSuit cardTypeSuit) { switch (cardTypeSuit) { using enum CardTypeSuit; case Clubs: return \"Clubs\"; case Diamonds: return \"Diamonds\"; case Hearts: return \"Hearts\"; case Spades: return \"Spades\"; } } 格式化库(std::format) std::string s = std::format(\"Hello CppCon {}!\", 2019); 增加数学常量 包含 e, log2e, log10e, pi, inv_pi, inv_sqrt ln2, ln10, sqrt2, sqrt3, inv_sqrt3, egamma std::source_location 用于获取代码位置, 对于日志和错误信息尤其有用 [[nodiscard(reason)]] 表明返回值不可抛弃, 加入理由的支持 [[nodiscard(\"Ignoring the return value will result in memory leaks.\")]] void* GetData() { /* ... */ } 位运算 加入循环移位, 计数0和1位等功能 一些小更新 字符串支持 starts_with, ends_with map 支持 contains 查询是否存在某个键 list 和 forward list 的 remove, remove_if 和 unique 操作返回 size_type 表明删除个数 增加 shift_left, shift_right midpoint 计算中位数, 可避免溢出 lerp 线性插值 lerp( float a, float b, float t ) 返回 新的向量化策略 unsequenced_policy(execution::unseq) std::string str = \"Hello world!\"; // starts_with, ends_with bool b = str.starts_with(\"Hello\"); std::map myMap{ std::pair{1, \"one\"s}, {2, \"two\"s}, {3, \"three\"s} }; // contains, 再也不用 .find() == .end() 了 bool result = myMap.contains(2); ","date":"2024-01-17","objectID":"/posts/cmake_note_9/:1:13","tags":["CMake"],"title":"CMake 笔记 | [9] 设置语言标准 (三)","uri":"/posts/cmake_note_9/"},{"categories":["C++"],"content":"三、C++ 14新特性 ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:1:0","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"3.1 函数返回值类型推导 c++14对函数返回值类型推导规则做了优化：用auto推导函数的返回值 #include \u003ciostream\u003e using namespace std; auto func(int i) { return i; } int main() { cout \u003c\u003c func(4) \u003c\u003c endl; return 0; } 上面的代码使用C++11是不能通过编译的，通过编译器输出的信息得知这个特性需要到C++14才被支持。 返回值类型推导也可以用在模板中 #include \u003ciostream\u003e using namespace std; template\u003ctypename T\u003e auto func(T t) { return t; } int main() { cout \u003c\u003c func(4) \u003c\u003c endl; cout \u003c\u003c func(3.4) \u003c\u003c endl; return 0; } 注意: 函数内如果有多个return语句，它们必须返回相同的类型，否则编译失败 如果return语句返回初始化列表，返回值类型推导也会失败 如果函数是虚函数，不能使用返回值类型推导 返回类型推导可以用在前向声明中，但是在使用它们之前，翻译单元中必须能够得到函数定义 返回类型推导可以用在递归函数中，但是递归调用必须以至少一个返回语句作为先导，以便编译器推导出返回类型 lambda参数auto: 在C++11中，lambda表达式参数需要使用具体的类型声明： auto f = [] (int a) { return a; } 在C++14中，对此进行优化，lambda表达式参数可以直接是auto： auto f = [] (auto a) { return a; }; cout \u003c\u003c f(1) \u003c\u003c endl; cout \u003c\u003c f(2.3f) \u003c\u003c endl; ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:1:1","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"3.2 变量模板 对变量的类型使用模板: template\u003cclass T\u003e constexpr T pi = T(3.1415926535897932385L); int main() { // 3 cout \u003c\u003c pi\u003cint\u003e \u003c\u003c endl; // 3.14159 cout \u003c\u003c pi\u003cdouble\u003e \u003c\u003c endl; return 0; } ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:1:2","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"3.3 别名模板 对别名使用模板，并且仍然保留模板特性: template\u003ctypename T, typename U\u003e struct A { T t; U u; }; template\u003ctypename T\u003e using B = A\u003cT, int\u003e; int main() { B\u003cdouble\u003e b; b.t = 10; b.u = 20; cout \u003c\u003c b.t \u003c\u003c endl; cout \u003c\u003c b.u \u003c\u003c endl; return 0; } ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:1:3","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"3.4 constexptr的限制 C++14相较于C++11对constexpr减少了一些限制: C++11中constexpr函数可以使用递归，在C++14中可以使用局部变量和循环 // C++14 和 C++11均可 constexpr int factorial(int n) { return n \u003c= 1 ? 1 : (n * factorial(n - 1)); } // C++11中不可，C++14中可以 constexpr int factorial(int n) { int ret = 0; for (int i = 0; i \u003c n; ++i) { ret += i; } return ret; } C++11中constexpr函数必须把所有东西都放在一个单独的return语句中，而constexpr则无此限制 // C++14 和 C++11均可 constexpr int func(bool flag) { return 0; } // C++11中不可，C++14中可以 constexpr int func(bool flag) { if (flag) return 1; else return 0; } ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:1:4","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"3.5 deprecated标记 C++14中增加了deprecated标记，修饰类、变、函数等，当程序中使用到了被其修饰的代码时，编译时被产生警告，用户提示开发者该标记修饰的内容将来可能会被丢弃，尽量不要使用。 ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:1:5","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"3.6 二进制字面量与整型字面量分隔符 C++14引入了二进制字面量，也引入了分隔符 int a = 0b0001'0011'1010; double b = 3.14'1234'1234'1234; ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:1:6","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"3.7 std::make_unique C++11中有std::make_shared，却没有std::make_unique，在C++14已经改善 struct A {}; std::unique_ptr\u003cA\u003e ptr = std::make_unique\u003cA\u003e(); ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:1:7","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"3.8 std::shared_time_mutex与std::shared_lock C++14通过std::shared_timed_mutex和std::shared_lock来实现读写锁，保证多个线程可以同时读，但是写线程必须独立运行，写操作不可以同时和读操作一起进行。 struct ThreadSafe { mutable std::shared_timed_mutex mutex_; int value_; ThreadSafe() { value_ = 0; } int get() const { std::shared_lock\u003cstd::shared_timed_mutex\u003e lock(mutex_); return value_; } void increase() { std::unique_lock\u003cstd::shared_timed_mutex\u003e lock(mutex_); value_ += 1; } }; ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:1:8","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"3.9 std::integer_sequence template\u003ctypename T, T... ints\u003e void print_sequence(std::integer_sequence\u003cT, ints...\u003e int_seq) { std::cout \u003c\u003c \"The sequence of size \" \u003c\u003c int_seq.size() \u003c\u003c \": \"; ((std::cout \u003c\u003c ints \u003c\u003c ' '), ...); std::cout \u003c\u003c '\\n'; } int main() { print_sequence(std::integer_sequence\u003cint, 9, 2, 5, 1, 9, 1, 6\u003e{}); return 0; } ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:1:9","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"3.10 std::exchange int main() { std::vector\u003cint\u003e v; std::exchange(v, {1,2,3,4}); cout \u003c\u003c v.size() \u003c\u003c endl; for (int a : v) { cout \u003c\u003c a \u003c\u003c \" \"; } return 0; } 看样子貌似和std::swap作用相同，但是实际上std::exchange将数组{1,2,3,4}赋值给了数组v,但是没有对数组v进行赋值。 ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:1:10","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"3.11 std::quoted C++14引入std::quoted用于给字符串添加双引号 int main() { string str = \"hello world\"; cout \u003c\u003c str \u003c\u003c endl; cout \u003c\u003c std::quoted(str) \u003c\u003c endl; return 0; } 输出: \"hello world\" ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:1:11","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"四、C++ 17新特性 ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:2:0","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"4.1 构造函数模板推导 在C++17前构造一个模板类对象需要指明类型: std::pair\u003cint, double\u003e p(1, 2.2); C++17就不需要特殊指定，直接可以推导出类型: // c++17 自动推导 std::pair p(1, 2.2); // c++17 std::vector v = {1, 2, 3}; ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:2:1","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"4.2 结构化绑定 通过结构化绑定，对于tuple、map等类型，获取相应值: std::tuple\u003cint, double\u003e func() { return std::tuple(1, 2.2); } int main() { // C++17 auto[i, d] = func(); cout \u003c\u003c i \u003c\u003c endl; cout \u003c\u003c d \u003c\u003c endl; } // -------------***-------------// void f() { map\u003cint, string\u003e m = { {0, \"a\"}, {1, \"b\"}, }; for (const auto \u0026[i, s] : m) { cout \u003c\u003c i \u003c\u003c \" \" \u003c\u003c s \u003c\u003c endl; } } int main() { std::pair a(1, 2.3f); auto[i, f] = a; cout \u003c\u003c i \u003c\u003c endl; // 1 cout \u003c\u003c f \u003c\u003c endl; // 2.3f return 0; } 结构化绑定还可以改变对象的值，使用引用即可: // 通过结构化绑定改变对象的值 int main() { std::pair a(1, 2.3f); auto\u0026 [i, f] = a; i = 2; // 2 cout \u003c\u003c a.first \u003c\u003c endl; } 注意: 结构化绑定不能应用于constexpr。 // compile error, C++20可以 constexpr auto[x, y] = std::pair(1, 2.3f); 结构化绑定不止可以绑定pair和tuple，还可以绑定数组和结构体等 int array[3] = {1, 2, 3}; auto [a, b, c] = array; cout \u003c\u003c a \u003c\u003c \" \" \u003c\u003c b \u003c\u003c \" \" \u003c\u003c c \u003c\u003c endl; // 注意这里的struct的成员一定要是public的 struct Point { int x; int y; }; Point func() { return {1, 2}; } const auto [x, y] = func(); ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:2:2","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"4.3 if-switch语句初始化 C++17之后可以这样: if (init; condition) if (int a = GetValue()); a \u003c 101) { cout \u003c\u003c a; } string str = \"Hi World\"; if (auto [pos, size] = pair(str.find(\"Hi\"), str.size()); pos != string::npos) { std::cout \u003c\u003c pos \u003c\u003c \" Hello, size is \" \u003c\u003c size; } ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:2:3","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"4.4 内敛变量 C++17前只有内联函数，现在有了内联变量，我们印象中C++类的静态成员变量在头文件中是不能初始化的，但是有了内联变量，就可以达到此目的: // header file struct A { static const int value; }; inline int const A::value = 10; struct A { inline static const int value = 10; } ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:2:4","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"4.5 折叠表达式 C++17引入了折叠表达式使可变参数模板编程更方便： template \u003ctypename ... Ts\u003e auto sum(Ts ... ts) { return (ts + ...); } int a {sum(1, 2, 3, 4, 5)}; // 15 std::string a{\"hello \"}; std::string b{\"world\"}; cout \u003c\u003c sum(a, b) \u003c\u003c endl; // hello world ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:2:5","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"4.6 constexptr lambda表达式 C++17前lambda表达式只能在运行时使用，C++17引入了constexpr lambda表达式，可以用于在编译期进行计算: int main() { // c++17可编译 constexpr auto lamb = [] (int n) { return n * n; }; static_assert(lamb(3) == 9, \"a\"); } constexpr函数有如下限制： 函数体不能包含汇编语句、goto语句、label、try块、静态变量、线程局部存储、没有初始化的普通变量，不能动态分配内存，不能有new delete等，不能有虚函数。 ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:2:6","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"4.7 namespace嵌套 namespace A { namespace B { namespace C { void func(); } } } // c++17，更方便 namespace A::B::C { void func();) } ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:2:7","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"4.8 __has_include预处理表达式 可以判断是否有某个头文件，代码可能会在不同编译器下工作，不同编译器的可用头文件有可能不同，所以可以使用此来判断： #if defined __has_include #if __has_include(\u003ccharconv\u003e) #define has_charconv 1 #include \u003ccharconv\u003e #endif #endif std::optional\u003cint\u003e ConvertToInt(const std::string\u0026 str) { int value{}; #ifdef has_charconv const auto last = str.data() + str.size(); const auto res = std::from_chars(str.data(), last, value); if (res.ec == std::errc{} \u0026\u0026 res.ptr == last) { return value; } #else // alternative implementation... // 其它方式实现 #endif return std::nullopt; } ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:2:8","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"4.9 在lambda表达式用*this捕获对象副本 正常情况下，lambda表达式中访问类的对象成员变量需要捕获this，但是这里捕获的是this指针，指向的是对象的引用，正常情况下可能没问题，但是如果多线程情况下，函数的作用域超过了对象的作用域，对象已经被析构了，还访问了成员变量，就会有问题。 struct A { int a; void func() { auto f = [this] { cout \u003c\u003c a \u003c\u003c endl; }; f(); } }; int main() { A a; a.func(); return 0; } C++17增加了新特性，捕获*this，不持有this指针，而是持有对象的拷贝，这样生命周期就与对象的生命周期不相关: struct A { int a; void func() { auto f = [*this] { cout \u003c\u003c a \u003c\u003c endl; }; f(); } }; int main() { A a; a.func(); return 0; } ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:2:9","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"4.10 新增Attribute 平时在项目中见过__declspec, attribute , #pragma指示符，使用它们来给编译器提供一些额外的信息，来产生一些优化或特定的代码，也可以给其它开发者一些提示信息。 struct A { short f[3]; } __attribute__((aligned(8))); void fatal() __attribute__((noreturn)); 在C++11和C++14中有更方便的方法： [[carries_dependency]] 让编译期跳过不必要的内存栅栏指令 [[noreturn]] 函数不会返回 [[deprecated]] 函数将弃用的警告 [[noreturn]] void terminate() noexcept; [[deprecated(\"use new func instead\")]] void func() {} C++17又新增了三个： [[fallthrough]]，用在switch中提示可以直接落下去，不需要break，让编译期忽略警告 switch (i) {} case 1: // warning xxx; case 2: xxx; // 警告消除 [[fallthrough]]; case 3: xxx; break; } [[nodiscard]]: 表示修饰的内容不能被忽略，可用于修饰函数，标明返回值一定要被处理 [[nodiscard]] int func(); void F() { // warning 没有处理函数返回值 func(); } [[maybe_unused]]: 提示编译器修饰的内容可能暂时没有使用，避免产生警告 void func1() {} // 警告消除 [[maybe_unused]] void func2() {} void func3() { int x = 1; // 警告消除 [[maybe_unused]] int y = 2; } ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:2:10","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"4.11 std::variant 新增from_chars函数和to_chars函数，直接看代码： #include \u003ccharconv\u003e int main() { const std::string str{\"123456098\"}; int value = 0; const auto res = std::from_chars(str.data(), str.data() + 4, value); if (res.ec == std::errc()) { cout \u003c\u003c value \u003c\u003c \", distance \" \u003c\u003c res.ptr - str.data() \u003c\u003c endl; } else if (res.ec == std::errc::invalid_argument) { cout \u003c\u003c \"invalid\" \u003c\u003c endl; } str = std::string(\"12.34); double val = 0; const auto format = std::chars_format::general; res = std::from_chars(str.data(), str.data() + str.size(), value, format); str = std::string(\"xxxxxxxx\"); const int v = 1234; res = std::to_chars(str.data(), str.data() + str.size(), v); cout \u003c\u003c str \u003c\u003c \", filled \" \u003c\u003c res.ptr - str.data() \u003c\u003c \" characters \\n\"; // 1234xxxx, filled 4 characters } ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:2:11","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"4.12 std::optional c++17增加std::variant实现类似union的功能，但却比union更高级，举个例子union里面不能有string这种类型，但std::variant却可以，还可以支持更多复杂类型，如map等 int main() { // c++17可编译 std::variant\u003cint, std::string\u003e var(\"hello\"); cout \u003c\u003c var.index() \u003c\u003c endl; var = 123; cout \u003c\u003c var.index() \u003c\u003c endl; try { var = \"world\"; // 通过类型获取值 std::string str = std::get\u003cstd::string\u003e(var); var = 3; // 通过index获取对应值 int i = std::get\u003c0\u003e(var); cout \u003c\u003c str \u003c\u003c endl; cout \u003c\u003c i \u003c\u003c endl; } catch(...) { // xxx; } return 0; } 注意: 一般情况下variant的第一个类型一般要有对应的构造函数，否则编译失败： struct A { A(int i){} }; int main() { // 编译失败 std::variant\u003cA, int\u003e var; } 避免这种情况呢，可以使用std::monostate来打个桩，模拟一个空状态。 // 可以编译成功 std::variant\u003cstd::monostate, A\u003e var; ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:2:12","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"4.13 std::optional 有时候可能会有需求，让函数返回一个对象 struct A {}; A func() { if (flag) return A(); else { // 异常情况下，怎么返回异常值呢，想返回个空呢 } } 有一种办法是返回对象指针，异常情况下就可以返回nullptr，但是这就涉及到了内存管理，也许你会使用智能指针，但这里其实有更方便的办法就是std::optional。 std::optional\u003cint\u003e StoI(const std::string \u0026s) { try { return std::stoi(s); } catch(...) { return std::nullopt; } } void func() { std::string s{\"123\"}; std::optional\u003cint\u003e o = StoI(s); if (o) { cout \u003c\u003c *o \u003c\u003c endl; } else { cout \u003c\u003c \"error\" \u003c\u003c endl; } } ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:2:13","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"4.14 std::any C++17引入了any可以存储任何类型的单个值 int main() { // c++17可编译 std::any a = 1; cout \u003c\u003c a.type().name() \u003c\u003c \" \" \u003c\u003c std::any_cast\u003cint\u003e(a) \u003c\u003c endl; a = 2.2f; cout \u003c\u003c a.type().name() \u003c\u003c \" \" \u003c\u003c std::any_cast\u003cfloat\u003e(a) \u003c\u003c endl; if (a.has_value()) { cout \u003c\u003c a.type().name(); } a.reset(); if (a.has_value()) { cout \u003c\u003c a.type().name(); } a = std::string(\"a\"); cout \u003c\u003c a.type().name() \u003c\u003c \" \" \u003c\u003c std::any_cast\u003cstd::string\u003e(a) \u003c\u003c endl; return 0; } ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:2:14","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"4.15 std::apply 使用std::apply可以将tuple展开作为函数的参数传入 int add(int first, int second) { return first + second; } auto add_lambda = [](auto first, auto second) { return first + second; }; int main() { std::cout \u003c\u003c std::apply(add, std::pair(1, 2)) \u003c\u003c '\\n'; std::cout \u003c\u003c add(std::pair(1, 2)) \u003c\u003c \"\\n\"; // error std::cout \u003c\u003c std::apply(add_lambda, std::tuple(2.0f, 3.0f)) \u003c\u003c '\\n'; } ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:2:15","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"4.16 std::make_from_tuple 使用make_from_tuple可以将tuple展开作为构造函数参数 struct Foo { Foo(int first, float second, int third) { std::cout \u003c\u003c first \u003c\u003c \", \" \u003c\u003c second \u003c\u003c \", \" \u003c\u003c third \u003c\u003c \"\\n\"; } }; int main() { auto tuple = std::make_tuple(42, 3.14f, 0); std::make_from_tuple\u003cFoo\u003e(std::move(tuple)); } ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:2:16","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"4.17 std::string_view 通常传递一个string时会触发对象的拷贝操作，大字符串的拷贝赋值操作会触发堆内存分配，很影响运行效率，有了string_view就可以避免拷贝操作，平时传递过程中传递string_view即可。 void func(std::string_view stv) { cout \u003c\u003c stv \u003c\u003c endl; } int main(void) { std::string str = \"Hello World\"; std::cout \u003c\u003c str \u003c\u003c std::endl; std::string_view stv(str.c_str(), str.size()); cout \u003c\u003c stv \u003c\u003c endl; func(stv); return 0; } ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:2:17","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"4.18 as_const C++17使用as_const可以将左值转成const类型 std::string str = \"str\"; const std::string\u0026 constStr = std::as_const(str); ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:2:18","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"4.19 file_system C++17正式将file_system纳入标准中，提供了关于文件的大多数功能，基本上应有尽有: namespace fs = std::filesystem; fs::create_directory(dir_path); fs::copy_file(src, dst, fs::copy_options::skip_existing); fs::exists(filename); fs::current_path(err_code); ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:2:19","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"4.20 std::shared_mutex C++17引入了shared_mutex，可以实现读写锁。 ","date":"2024-01-17","objectID":"/posts/cmake_note_8/:2:20","tags":["CMake"],"title":"CMake 笔记 | [8] 设置语言标准 (二)","uri":"/posts/cmake_note_8/"},{"categories":["C++"],"content":"一、C ++ 标准历史 1998 年，C++ 标准委员会发布了第一版 C++ 标准，并将其命名为 C++ 98 标准 2011 年，新的 C++ 11 标准诞生，用于取代 C++ 98 标准。此标准还有一个别名，为C++ 0x 2014 年，C++ 14 标准发布，该标准库对 C++ 11 标准库做了更优的修改和更新 2017 年底，C++ 17 标准正式颁布 ","date":"2024-01-17","objectID":"/posts/cmake_note_7/:1:0","tags":["CMake"],"title":"CMake 笔记 | [7] 设置语言标准（一）","uri":"/posts/cmake_note_7/"},{"categories":["C++"],"content":"二、C++ 11版本特性介绍 在 C++ 11 标准之前，C++ 标准委员会还在 2003 年对 C++ 98 标准做了一次修改（称为 C++ 03 标准），但由于仅仅修复了一些 C++ 98 标准中存在的漏洞，并未修改核心语法，因此人们习惯将这次修订和 C++ 98 合称为 C++98/03 标准。 以上 3 个标准中，C++ 11 标准无疑是颠覆性的，该标准在 C++ 98 的基础上修正了约 600 个 C++ 语言中存在的缺陷，同时添加了约 140 个新特性，这些更新使得 C++ 语言焕然一新。 ","date":"2024-01-17","objectID":"/posts/cmake_note_7/:2:0","tags":["CMake"],"title":"CMake 笔记 | [7] 设置语言标准（一）","uri":"/posts/cmake_note_7/"},{"categories":["C++"],"content":"2.1 类型推导之auto和decltype 在 C++11 之前的版本中，定义变量或者声明变量之前都必须指明它的类型，比如 int、char 等。C++11 使用 auto 关键字来支持自动类型推导。 在之前的 C++ 版本中，auto 用来指明变量的存储类型，它和 static 是相对的。auto 表示变量是自动存储的，这也是编译器的默认规则，所以写不写都一样，这使得 auto 的存在变得非常鸡肋。 C++ 11 赋予 auto 新的含义，用它来做自动类型推导。即，使用 auto 关键字后，编译器会在编译期间自动推导出变量的类型。 注意 auto 仅仅是一个占位符，在编译器期间它会被真正的类型所替代。C++ 中的变量必须是有明确类型的，只是这个类型是由编译器自己推导出来的。 使用 auto 类型推导的变量必须马上初始化，因为 auto 在 C++11 中只是占位符，并非如 int 一样的真正的类型声明。 auto与const的结合使用 int x = 0; // n 为const int,auto 被推导为int const auto n = x; // f为const int， auto 被推导为int（const属性被抛弃） auto f = n; // r1为const int \u0026类型，auto被推导为int const auto \u0026r1 = x; // r1为const int\u0026类型，auto 被推导为const int 类型 auto \u0026r2 = r1; auto 与 const 结合的用法： 当类型不为引用时，auto 的推导结果将不保留表达式的 const 属性； 当类型为引用时，auto 的推导结果将保留表达式的 const 属性。 auto的限制： 使用auto时必须对变量进行初始化 auto不能作为函数的形参 auto 不能作用于类的 非静态成员变量中 auto 关键字不能定义数组 auto 不能作用于模板参数 decltype 是 C++11 新增的一个关键字，它和 auto 的功能一样，都用来在编译时期进行自动类型推导。decltype 是declare type的缩写，译为声明类型。 auto 并不适用于所有的自动类型推导场景，在某些特殊情况下 auto 用起来非常不方便，甚至压根无法使用，所以 decltype 关键字也被引入到 C++11 中。 auto var_name = value; decltype(exp) var_name = value; 其中，var_name 表示变量名，value 表示赋给变量的值，exp 表示一个表达式。 auto 根据=右边的初始值 value 推导出变量的类型，而 decltype 根据 exp 表达式推导出变量的类型，跟=右边的 value 没有关系。 auto 要求变量必须初始化，而 decltype 不要求。 exp 就是一个普通的表达式，它可以是任意复杂的形式，但是必须要保证 exp 的结果是有类型的，不能是 void；例如，当 exp 调用一个返回值类型为 void 的函数时，exp 的结果也是 void 类型，此时就会导致编译错误。 int a = 0; // b 被推导成了 int decltype(a) b = 1; // x 被推导成了 double decltype(10.8) x = 5.5; // y 被推导成了 double decltype(x + 100) y; decltype 推导规则 如果 exp 是一个不被括号( )包围的表达式，或者是一个类成员访问表达式，或者是一个单独的变量，那么 decltype(exp) 的类型就和 exp 一致。 如果 exp 是函数调用，那么 decltype(exp) 的类型就和函数返回值的类型一致。 如果 exp 是一个左值，或者被括号( )包围，那么 decltype(exp)的类型就是 exp 的引用；假设 exp 的类型为 T，那么 decltype(exp) 的类型就是 T\u0026。 注意 左值是指那些在表达式执行结束后依然存在的数据，也就是持久性的数据； 右值是指那些在表达式执行结束后不再存在的数据，也就是临时性的数据。 有一种很简单的方法来区分左值和右值，对表达式取地址，如果编译器不报错就为左值，否则为右值。 auto与decltype对 cv 限定符的处理: cv 限定符是 const 和 volatile 关键字的统称: const 关键字用来表示数据是只读的，也就是不能被修改 volatile 和 const 是相反的，它用来表示数据是可变的、易变的，目的是不让 CPU 将数据缓存到寄存器，而是从原始的内存中读取 在推导变量类型时，auto 和 decltype 对 cv 限制符的处理是不一样的。decltype 会保留 cv 限定符，而 auto 有可能会去掉 cv 限定符。其原理见auto与const的结合使用。 auto与decltype对引用(\u0026)的处理: 当表达式的类型为引用时，auto 和 decltype 的推导规则也不一样；decltype 会保留引用类型，而 auto 会抛弃引用类型，直接推导出它的原始类型。 ","date":"2024-01-17","objectID":"/posts/cmake_note_7/:2:1","tags":["CMake"],"title":"CMake 笔记 | [7] 设置语言标准（一）","uri":"/posts/cmake_note_7/"},{"categories":["C++"],"content":"2.2 C++ 返回值类型后置 在泛型编程中，如果需要通过参数的运算来得到返回值的类型： template \u003ctypename R, typename T, typename U\u003e R Add(T t, U u) { return t+u; } int main() { int a = 1; float b = 2.0f; auto c = Add\u003cdecltype(a + b)\u003e(a + b); return 0; } 以上代码是因为我们并不关心a + b的类型是什么，因此只需要通过decltype(a + b)直接得到返回值类型即可。 上述使用过程十分不方便，因为外部其实并不知道参数之间应该如何运算，只有Add函数知道返回值应该如何推导。 在函数定义上直接通过decltype获取返回值： template \u003ctypename T, typename U\u003e decltype(T() + U()) add(T t, U u) { return t + u; } 考虑到 T、U 可能是没有无参构造函数的类，正确的写法如下： template \u003ctypename T, typename U\u003e decltype((*(T*)0) + (*(U*)0)) add(T t, U u) { return t + u; } 上述代码虽然成功地使用 decltype 完成了返回值的推导，但写法过于晦涩，会大大增加decltype在返回值类型推导上的使用难度并降低代码的可读性。 因此，在 C++11 中增加了返回类型后置语法，将 decltype 和 auto 结合起来完成返回值类型的推导。 template \u003ctypename T, typename U\u003e auto add(T t, U u) -\u003e decltype(t + u){ return t + u; } ","date":"2024-01-17","objectID":"/posts/cmake_note_7/:2:2","tags":["CMake"],"title":"CMake 笔记 | [7] 设置语言标准（一）","uri":"/posts/cmake_note_7/"},{"categories":["C++"],"content":"2.3 对模板实例化中连续尖括号»改进 在 C++98/03 的泛型编程中，模板实例化过程中，连续两个右尖括号（»）会被编译器解释成右移操作符，而不是模板参数表的结束。 template \u003ctypename T\u003e struct Foo{ typedef T type; }; template \u003ctypename T\u003e class A{ // ... }; int main(){ //编译出错 Foo\u003cA\u003cint\u003e\u003e::type xx; return 0; } 上述代码使用 gcc 编译时，会得到如下错误提示： error: ‘\u003e\u003e’ should be ‘\u003e\u003e’ within a nested template argument list Foo\u003cA\u003e::type xx; 意思就是，Foo\u003cA\u003e这种写法是不被支持的，要写成这样Foo\u003cA\u003cint\u003e \u003e(注意两个右尖括号之间的空格)。 这种限制是很没有必要的。因为在 C++ 的各种成对括号中，目前只有右尖括号连续写两个会出现这种二义性。static_cast、reinterpret_cast 等 C++ 标准转换运算符，都是使用\u003c\u003e来获得待转换类型（type-id）的。若这个 type-id 本身是一个模板，用起来会很不方便。 在 C++11 标准中，要求编译器对模板的右尖括号做单独处理，使编译器能够正确判断出»是一个右移操作符还是模板参数表的结束标记。 注意：上述这种自动化的处理在某些时候会与老标准不兼容： template \u003cint N\u003e struct Foo{ // ... }; int main() { // 解决方案： // Foo\u003c(100 \u003e\u003e 2)\u003e xx; Foo\u003c100 \u003e\u003e 2\u003e xx; return 0; } 在 C++98/03 的编译器中编译是没问题的，但 C++11 的编译器会显示: error: expected unqualif?ied-id before ‘\u003e’ token Foo\u003c100 \u003e\u003e 2\u003e xx; ","date":"2024-01-17","objectID":"/posts/cmake_note_7/:2:3","tags":["CMake"],"title":"CMake 笔记 | [7] 设置语言标准（一）","uri":"/posts/cmake_note_7/"},{"categories":["C++"],"content":"2.4 使用using定义别名（替代typedef） C++可以使用typedef重定义一个类型，被重定义的类型不一定是一个新的类型，也有可能仅仅是原有类型取了一个新的名字。使用typedef重定义类型是很方便的，但它也有一些限制，如无法重定义一个模板等。 template\u003ctypename T\u003e using str_map_t = std::map\u003cstd::string, T\u003e; // ... str_map_t\u003cint\u003e map_1; 实际上，using的别名语法覆盖了typedef的全部功能。 // 重定义unsigned int typedef unsigned int uint_t; using uint_t = unsigned int; // 重定义std::map typedef std::map\u003cstd::string, int\u003e map_int_t; using map_int_t = std::map\u003cstd::string, int\u003e; // 重定义模板 // C++98/03 template \u003ctypename T\u003e struct func_t{ typedef void (*type)(T, T); }; // 使用 func_t 模板 func_t\u003cint\u003e::type xx_1; // C++11 template \u003ctypename T\u003e using func_t = void (*)(T, T); // 使用 func_t 模板 func_t\u003cint\u003e xx_2; 从示例中可以看出，通过 using 定义模板别名的语法，只是在普通类型别名语法的基础上增加 template 的参数列表。使用 using 可以轻松地创建一个新的模板别名，而不需要像 C++98/03 那样使用烦琐的外敷模板。 ","date":"2024-01-17","objectID":"/posts/cmake_note_7/:2:4","tags":["CMake"],"title":"CMake 笔记 | [7] 设置语言标准（一）","uri":"/posts/cmake_note_7/"},{"categories":["C++"],"content":"2.5 支持函数模板的默认参数 在 C++98/03 标准中，类模板可以有默认的模板参数: template \u003ctypename T, typename U = int, U N = 0\u003e struct Foo{ // ... }; 但是不支持函数的默认模板参数： // error in C++98/03: default template arguments template \u003ctypename T = int\u003e void func(){ // ... } 现在这一限制在 C++11 中被解除了。上面的 func 函数在 C++11 中可以直接使用: int main(void){ //T = int func(); return 0; } 函数模板的默认模板参数在使用规则上和其他的默认参数也有一些不同，它没有必须写在参数表最后的限制。甚至于，根据实际场景中函数模板被调用的情形，编译器还可以自行推导出部分模板参数的类型。即当默认模板参数和编译器自行推导出模板参数类型的能力一起结合使用时，代码的书写将变得异常灵活。我们可以指定函数中的一部分模板参数采用默认参数，而另一部分使用自动推导： template \u003ctypename R = int, typename U\u003e R func(U val){ return val; } int main(){ // R=int, U=int func(97); // R=char, U=int func\u003cchar\u003e(97); // R=double, U=int func\u003cdouble, int\u003e(97); return 0; } 当默认模板参数和自行推导的模板参数同时使用时，若无法推导出函数模板参数的类型，编译器会选择使用默认模板参数；如果模板参数无法推导出来，又未设置其默认值，则编译器直接报错。 template \u003ctypename T, typename U = double\u003e void func(T val1 = 0, U val2 = 0) { //... } int main() { // T=char, U=double func('c'); // 编译报错 func(); return 0; } ","date":"2024-01-17","objectID":"/posts/cmake_note_7/:2:5","tags":["CMake"],"title":"CMake 笔记 | [7] 设置语言标准（一）","uri":"/posts/cmake_note_7/"},{"categories":["C++"],"content":"2.6 在函数模板和类模板中使用可变参数 可变参数，指的是参数的个数和类型都可以是任意的。 对于函数参数而言，C++ 一直都支持为函数设置可变参数，最典型的代表就是 printf() 函数，它的语法格式为: int printf ( const char * format, ... ); ...就表示的是可变参数，即 printf() 函数可以接收任意个参数，且各个参数的类型可以不同。 printf(\"%d\", 10); printf(\"%d %c\",10, 'A'); printf(\"%d %c %f\",10, 'A', 1.23); 通常将容纳多个参数的可变参数称为参数包。借助 format 字符串，printf() 函数可以轻松判断出参数包中的参数个数和类型。 #include \u003ciostream\u003e #include \u003ccstdarg\u003e //可变参数的函数 void vair_fun(int count, ...) { va_list args; va_start(args, count); for (int i = 0; i \u003c count; ++i) { int arg = va_arg(args, int); std::cout \u003c\u003c arg \u003c\u003c \" \"; } va_end(args); } int main() { //可变参数有 4 个，分别为 10、20、30、40 vair_fun(4, 10, 20, 30,40); return 0; } 想使用参数包中的参数，需要借助\u003ccstdarg\u003e头文件中的 va_start、va_arg 以及 va_end 这 3 个带参数的宏： va_start(args, count)：args 是 va_list 类型的变量，可以简单的将其视为 char * 类型。借助 count 参数，找到可变参数的起始位置并赋值给 args； va_arg(args, int)：调用 va_start找到可变参数起始位置的前提下，通过指明参数类型为 int，va_arg 就可以将可变参数中的第一个参数返回; va_end(args)：不再使用 args 变量后，应及时调用 va_end 宏清理 args 变量。 使用…可变参数的过程中，需注意以下几点： … 可变参数必须作为函数的最后一个参数，且一个函数最多只能拥有 1 个可变参数; 可变参数的前面至少要有 1 个有名参数; 当可变参数中包含 char 类型的参数时，va_arg 宏要以 int 类型的方式读取；当可变参数中包含 short 类型的参数时，va_arg 宏要以 double 类型的方式读取。 需要注意的是, …可变参数的方法仅适用于函数参数，并不适用于模板参数。 ","date":"2024-01-17","objectID":"/posts/cmake_note_7/:2:6","tags":["CMake"],"title":"CMake 笔记 | [7] 设置语言标准（一）","uri":"/posts/cmake_note_7/"},{"categories":["C++"],"content":"2.7 可变参数模板 C++ 11 标准发布之前，函数模板和类模板只能设定固定数量的模板参数。C++11 标准对模板的功能进行了扩展，允许模板中包含任意数量的模板参数，这样的模板又称可变参数模板。 可变参数函数模板 template\u003ctypename... T\u003e void vair_fun(T...args) { //函数体 } 模板参数中， typename（或者 class）后跟 … 就表明 T 是一个 可变模板参数 ，它可以接收多种数据类型，又称 模板参数包 。vair_fun() 函数中，args 参数的类型用 T… 表示，表示 args 参数可以接收任意个参数，又称 函数参数包 。即此函数模板最终实例化出的 vair_fun() 函数可以指定任意类型、任意数量的参数。 vair_fun(); vair_fun(1, \"abc\"); vair_fun(1, \"abc\", 1.23); 在模板函数内部“解”参数包方法： 方法一：递归方式解包 #include \u003ciostream\u003e using namespace std; //模板函数递归的出口 void vir_fun() { } template \u003ctypename T, typename... args\u003e void vir_fun(T argc, args... argv) { cout \u003c\u003c argc \u003c\u003c endl; //开始递归，将第一个参数外的 argv 参数包重新传递给 vir_fun vir_fun(argv...); } int main() { vir_fun(1, \"http://www.biancheng.net\", 2.34); return 0; } 结果： 1 http://www.biancheng.net 2.34 程序的执行流程 首先，main() 函数调用 vir_fun() 模板函数时，根据所传实参的值，可以很轻易地判断出模板参数 T 的类型为 inT，函数参数 argc 的值为 1，剩余的模板参数和函数参数都分别位于 args 和 argv 中； vir_fun() 函数中，首先输出了 argc 的值（为 1），然后重复调用自身，同时将函数参数包 argv 中的数据作为实参传递给形参 argc 和 argv； 再次执行 vir_fun() 函数，此时模板参数 T 的类型为 char*，输出 argc 的值为 http:www.biancheng.net。再次调用自身，继续将 argv 包中的数据作为实参； 再次执行 vir_fun() 函数，此时模板参数 T 的类型为 double，输出 argc 的值为 2.34。再次调用自身，将空的 argv 包作为实参； 由于 argv 包没有数据，此时会调用无任何形参、函数体为空的 vir_fun() 函数，最终执行结束。 **注意:**以递归方式解包，一定要设置递归结束的出口。例如本例中，无形参、函数体为空的 vir_fun() 函数就是递归结束的出口。 方法二：非递归方式解包（借助逗号表达式和初始化列表，也可以解开参数包） #include \u003ciostream\u003e using namespace std; template \u003ctypename T\u003e void dispaly(T t) { cout \u003c\u003c t \u003c\u003c endl; } template \u003ctypename... args\u003e void vir_fun(args... argv){ // 逗号表达式+初始化列表 int arr[] = { (dispaly(argv),0)... }; } int main() { vir_fun(1, \"http://www.biancheng.net\", 2.34); return 0; } 以{ }初始化列表的方式对数组 arr 进行了初始化， (display(argv),0)… 会依次展开为 (display(1),0)、(display(“http://www.biancheng.net”),0) 和 (display(2.34),0)。 所以，下面的语句是等价的： int arr[] = { (dispaly(argv),0)... }; int arr[] = { (dispaly(1),0), (dispaly(\"http://www.biancheng.net\"),0), (dispaly(2.34),0) }; 可以看到，每个元素都是一个逗号表达式，以 (display(1), 0) 为例，它会先计算 display(1)，然后将 0 作为整个表达式的值返回给数组，因此 arr 数组最终存储的都是 0。arr 数组纯粹是为了将参数包展开，没有发挥其它作用。 可变参数类模板 C++11 标准中，类模板中的模板参数也可以是一个可变参数。C++11 标准提供的 tuple 元组类就是一个典型的可变参数模板类。 template \u003ctypename... Types\u003e class tuple; 和固定模板参数的类不同，tuple 模板类实例化时，可以接收任意数量、任意类型的模板参数: std::tuple\u003c\u003e tp0; std::tuple\u003cint\u003e tp1 = std::make_tuple(1); std::tuple\u003cint, double\u003e tp2 = std::make_tuple(1, 2.34); std::tuple\u003cint, double, string\u003e tp3 = std::make_tuple(1, 2.34, \"http://www.biancheng.net\"); ","date":"2024-01-17","objectID":"/posts/cmake_note_7/:2:7","tags":["CMake"],"title":"CMake 笔记 | [7] 设置语言标准（一）","uri":"/posts/cmake_note_7/"},{"categories":["C++"],"content":"2.8 引入tuple和Lambda tuple 的应用场景: 当需要存储多个不同类型的元素时，可以使用 tuple； 当函数需要返回多个数据时，可以将这些数据存储在 tuple 中，函数只需返回一个 tuple 对象即可。 具体使用方式请参考《C++标准库》 Lambda语法格式 [外部变量访问方式说明符](参数) mutable noexcept/throw()-\u003e返回值类型 { 函数体; }; [外部变量访问方式说明符]：[]方括号用于向编译器表明当前是一个lambda表达式，其不能被省略。在方括号内部，可以注明当前 lambda 函数的函数体中可以使用哪些外部变量(外部变量，指的是和当前 lambda 表达式位于同一作用域内的所有局部变量)。 外部变量格式 功能 [] 空方括号表示当前lambda匿名函数不导入任何外部变量 [=] 只有一个=符合，表示以值传递的方式导入所有外部变量 [\u0026] 只有一个\u0026符号，表示以引用传递的方式导入所有外部变量 [val1, val2,…] 表示以值传递的方式导入val1、val2等外部变量，同时多个变量之间没有前后次序 [\u0026val1, \u0026val2,…] 表示以引用传递的方式导入val1、val2等指定的外部变量，多个变量之间没有前后次序 [val, \u0026val2,…] 以上两种方式还可以混合使用 [=, \u0026val1,…] 表示除val1以引用传递的方式导入以外，其他外部变量都以值传递的方式导入 [this] 表示以值传递的方式导入当前的this指针 (参数)：和普通函数的定义一样，lambda 匿名函数也可以接收外部传递的多个参数。和普通函数不同的是，如果不需要传递参数，可以连同()小括号一起省略。 mutable：此关键字可以省略，如果使用之前的 () 小括号将不能省略（参数个数可以为 0）。默认情况下，对于以值传递方式引入的外部变量，不允许在 lambda 表达式内部修改它们的值（可以理解为这部分变量都是 const 常量）。而如果想修改它们，就必须使用 mutable 关键字。（注意，对于以值传递方式引入的外部变量，lambda 表达式修改的是拷贝的那一份，并不会修改真正的外部变量）。 noexcept/throw()：可以省略，如果使用，在之前的 () 小括号将不能省略（参数个数可以为 0）。默认情况下，lambda 函数的函数体中可以抛出任何类型的异常。而标注 noexcept 关键字，则表示函数体内不会抛出任何异常；使用throw()可以指定 lambda 函数内部可以抛出的异常类型。（注意，如果 lambda 函数标有 noexcept 而函数体内抛出了异常，又或者使用 throw() 限定了异常类型而函数体内抛出了非指定类型的异常，这些异常无法使用 try-catch 捕获，会导致程序执行失败）。 -\u003e返回值类型：指明 lambda 匿名函数的返回值类型。值得一提的是，如果 lambda 函数体内只有一个 return 语句，或者该函数返回 void，则编译器可以自行推断出返回值类型，此情况下可以直接省略-\u003e 返回值类型。 函数体：和普通函数一样，lambda 匿名函数包含的内部代码都放置在函数体中。该函数体内除了可以使用指定传递进来的参数之外，还可以使用指定的外部变量以及全局范围内的所有全局变量。 注意:外部变量会受到以值传递还是以引用传递方式引入的影响，而全局变量则不会。换句话说，在 lambda 表达式内可以使用任意一个全局变量，必要时还可以直接修改它们的值。 ","date":"2024-01-17","objectID":"/posts/cmake_note_7/:2:8","tags":["CMake"],"title":"CMake 笔记 | [7] 设置语言标准（一）","uri":"/posts/cmake_note_7/"},{"categories":["C++"],"content":"2.9 列表初始化 具体使用方式请参考《C++ Primer Plus》《C++标准库》 ","date":"2024-01-17","objectID":"/posts/cmake_note_7/:2:9","tags":["CMake"],"title":"CMake 笔记 | [7] 设置语言标准（一）","uri":"/posts/cmake_note_7/"},{"categories":["C++"],"content":"2.10 非受限联合体 POD (Plain Old Data) 类型介绍: POD类型一般具有以下几种特征： 没有用户自定义的构造函数，析构函数、拷贝构造函数和移动构造函数 不能包含虚函数和虚基类 非静态成员必须声明为public 类中的第一个非静态成员的类型与基类不同 在类或者结构体继承时，满足以下两种情况之一： 派生类中有非静态成员，且只有一个包含静态成员的基类 基类有非静态成员，而派生类没有非静态成员 所有非静态数据成员均和其基类也符合上述规则（递归定义），也就是说POD类型不能包含非POD类型的数据。 所有建通C语言的数据类型都是POD类型(struct、union等不能违背上述规则) 非受限联合体 在 C/C++ 中，**联合体**是一种构造数据类型。在一个联合体内，可以定义多个不同类型的成员，这些成员将会共享同一块内存空间。老版本的 C++ 为了和C语言保持兼容，对联合体的数据成员的类型进行了很大程度的限制，这些限制在今天看来并没有必要，因此 C++11 取消了这些限制。 C++11 标准规定，任何非引用类型都可以成为联合体的数据成员，这种联合体也被称为**非受限联合体**。 class Student{ public: Student(bool g, int a): gender(g), age(a) {} private: bool gender; int age; }; union T{ Student s; // 含有非POD类型的成员，gcc-5.1.0 版本报错 char name[10]; }; 上述的代码中，因为 Student 类带有自定义的构造函数，所以是一个非 POD 类型的，这导致编译器报错。 C++ 11改进1: C++11允许非POD类型 C++11允许联合体又静态成员(静态成员变量智能在联合体内定义，却不能在联合体外使用) 非受限联合体的赋值注意事项： C++11规定，如果非受限联合体内有一个非 POD 的成员，而该成员拥有自定义的构造函数，那么这个非受限联合体的默认构造函数将被编译器删除；其他的特殊成员函数，例如默认拷贝构造函数、拷贝赋值操作符以及析构函数等，也将被删除。 #include \u003cstring\u003e using namespace std; union U { string s; int n; }; int main() { // 构造失败，因为 U 的构造函数被删除 U u; return 0; } 在上面的例子中，因为 string 类拥有自定义的构造函数，所以 U 的构造函数被删除；定义 U 的类型变量 u 需要调用默认构造函数，所以 u 也就无法定义成功。 解决上面问题的一般需要用到 placement new: placement new 是 new 关键字的一种进阶用法，既可以在栈（stack）上生成对象，也可以在堆（heap）上生成对象。相对应地，把常见的new的用法称为 operator new，它只能在 heap 上生成对象。 placement new 的语法格式: new(address) ClassConstruct(…) address 表示已有内存的地址，该内存可以在栈上，也可以在堆上; ClassConstruct(…) 表示调用类的构造函数，如果构造函数没有参数，也可以省略括号。 placement new 利用已经申请好的内存来生成对象，它不再为对象分配新的内存，而是将对象数据放在 address 指定的内存中。 #include \u003cstring\u003e using namespace std; union U { string s; int n; public: U() { new(\u0026s) string; } ~U() { s.~string(); } }; int main() { U u; return 0; } 构造时，采用 placement new 将 s 构造在其地址 \u0026s 上，这里 placement new 的唯一作用只是调用了一下 string 类的构造函数。注意，在析构时还需要调用 string 类的析构函数。 ","date":"2024-01-17","objectID":"/posts/cmake_note_7/:2:10","tags":["CMake"],"title":"CMake 笔记 | [7] 设置语言标准（一）","uri":"/posts/cmake_note_7/"},{"categories":["C++"],"content":"2.11 非受限联合体的匿名声明和“枚举式类” 匿名联合体是指不具名的联合体（也即没有名字的联合体），定义如下: union U{ // 此联合体为匿名联合体 union { int x; }; }; 联合体 U 内定义了一个不具名的联合体，该联合体包含一个 int 类型的成员变量，称这个联合体为匿名联合体。 非受限联合体也可以匿名，而当非受限的匿名联合体运用于类的声明时，这样的类被称为枚举式类。 #include \u003ccstring\u003e using namespace std; class Student{ public: Student(bool g, int a): gender(g), age(a){} bool gender; int age; }; class Singer { public: enum Type { STUDENT, NATIVE, FOREIGENR }; Singer(bool g, int a) : s(g, a) { t = STUDENT; } Singer(int i) : id(i) { t = NATIVE; } Singer(const char* n, int s) { int size = (s \u003e 9) ? 9 : s; memcpy(name , n, size); name[s] = '\\0'; t = FOREIGENR; } ~Singer(){} private: Type t; union { Student s; int id; char name[10]; }; }; int main() { Singer(true, 13); Singer(310217); Singer(\"J Michael\", 9); return 0; } ","date":"2024-01-17","objectID":"/posts/cmake_note_7/:2:11","tags":["CMake"],"title":"CMake 笔记 | [7] 设置语言标准（一）","uri":"/posts/cmake_note_7/"},{"categories":["C++"],"content":"2.12 for循环(基于范围的循环) C++ 11标准之前（C++ 98/03 标准），如果要用 for 循环语句遍历一个数组或者容器，只能套用如下结构: for(表达式 1; 表达式 2; 表达式 3){ //循环体 } 举例: #include \u003ciostream\u003e #include \u003cvector\u003e #include \u003cstring.h\u003e using namespace std; int main() { char arc[] = \"http://c.biancheng.net/cplus/11/\"; int i; // for循环遍历普通数组 for (i = 0; i \u003c strlen(arc); i++) { cout \u003c\u003c arc[i]; } cout \u003c\u003c endl; vector\u003cchar\u003emyvector(arc,arc+23); vector\u003cchar\u003e::iterator iter; // for循环遍历 vector 容器 for (iter = myvector.begin(); iter != myvector.end(); ++iter) { cout \u003c\u003c *iter; } return 0; } C++ 11 标准中，除了可以沿用前面介绍的用法外，还为 for 循环添加了一种全新的语法格式: for (declaration : expression){ //循环体 } declaration:表示此处要定义一个变量，该变量的类型为要遍历序列中存储元素的类型。需要注意的是，C++ 11 标准中，declaration参数处定义的变量类型可以用 auto 关键字表示，该关键字可以使编译器自行推导该变量的数据类型。 expression:表示要遍历的序列，常见的可以为事先定义好的普通数组或者容器，还可以是用 {} 大括号初始化的序列。 #include \u003ciostream\u003e #include \u003cvector\u003e using namespace std; int main() { char arc[] = \"http://c.biancheng.net/cplus/11/\"; // for循环遍历普通数组 for (char ch : arc) { cout \u003c\u003c ch; } cout \u003c\u003c '!' \u003c\u003c endl; vector\u003cchar\u003emyvector(arc, arc + 23); // for循环遍历 vector 容器 for (auto ch : myvector) { cout \u003c\u003c ch; } cout \u003c\u003c '!'; // 新语法格式的 for 循环还支持遍历用{ }大括号初始化的列表 for (int num : {1, 2, 3, 4, 5}) { cout \u003c\u003c num \u003c\u003c \" \"; } return 0; } 注意: 程序中在遍历 myvector 容器时，定义了 auto 类型的 ch 变量，当编译器编译程序时，会通过 myvector 容器中存储的元素类型自动推导出 ch 为 char 类型。注意，这里的 ch 不是迭代器类型，而表示的是 myvector 容器中存储的每个元素。 在输出结果，其中第一行输出的字符串和 ! 之间还输出有一个空格，因为新格式的 for 循环在遍历字符串序列时，不只是遍历到最后一个字符，还会遍历位于该字符串末尾的 \\0（字符串的结束标志）。 注意: 在使用新语法格式的 for 循环遍历某个序列时，如果需要遍历的同时修改序列中元素的值，实现方案是在 declaration 参数处定义引用形式的变量。 #include \u003ciostream\u003e #include \u003cvector\u003e using namespace std; int main() { char arc[] = \"abcde\"; vector\u003cchar\u003emyvector(arc, arc + 5); // for循环遍历并修改容器中各个字符的值 for (auto \u0026ch : myvector) { ch++; } // for循环遍历输出容器中各个字符 for (auto ch : myvector) { cout \u003c\u003c ch; } return 0; } ","date":"2024-01-17","objectID":"/posts/cmake_note_7/:2:12","tags":["CMake"],"title":"CMake 笔记 | [7] 设置语言标准（一）","uri":"/posts/cmake_note_7/"},{"categories":["C++"],"content":"2.13 constexpr：验证是否为常量表达式 constexpr 是 C++ 11 标准新引入的关键字。 常量表达式，指的就是由多个（≥1）常量组成的表达式。即如果表达式中的成员都是常量，那么该表达式就是一个常量表达式。这也意味着，常量表达式一旦确定，其值将无法修改。 以定义数组为例，数组的长度就必须是一个常量表达式： //正确 int url[10]; // 正确 int url[6 + 4]; // 错误，length是变量 int length = 6; // 改进： const int length = 6; int url[length] 程序的执行过程为预处理、编译、汇编和链接四个阶段，具体请参考计算机系统漫游(一)。大致又可以说由编译、链接、运行这3 个阶段。常量表达式和非常量表达式的计算时机不同，非常量表达式只能在程序运行阶段计算出结果；而常量表达式的计算往往发生在程序的编译阶段，这可以极大提高程序的执行效率，因为表达式只需要在编译阶段计算一次，节省了每次程序运行时都需要计算一次的时间。 在实际开发中，判定一个表达式是否为常量表达式方式: 人为判定； C++11 标准还提供有 constexpr 关键字。 constexpr修饰普通变量 C++11 标准中，定义变量时可以用 constexpr 修饰，从而使该变量获得在编译阶段即可计算出结果的能力。 使用 constexpr 修改普通变量时，变量必须经过初始化且初始值必须是一个常量表达式。 #include \u003ciostream\u003e using namespace std; int main() { constexpr int num = 1 + 2 + 3; int url[num] = {1,2,3,4,5,6}; couts\u003c\u003c url[1] \u003c\u003c endl; return 0; } 上述代码中，如果尝试将 constexpr 删除，此时编译器会提示url[num] 定义中 num 不可用作常量。使用 constexpr 修饰 num 变量，同时将 1+2+3 这个常量表达式赋值给 num。由此，编译器就可以在编译时期对 num 这个表达式进行计算，因为 num 可以作为定义数组时的长度。 注意:当常量表达式中包含浮点数时，考虑到程序编译和运行所在的系统环境可能不同，常量表达式在编译阶段和运行阶段计算出的结果精度很可能会受到影响，因此 C++11 标准规定，浮点常量表达式在编译阶段计算的精度要至少等于（或者高于）运行阶段计算出的精度。 constexpr修饰函数 这样的函数又称为常量表达式函数。 constexpr 并非可以修改任意函数的返回值。必须满足如下条件: 整个函数的函数体中，除了可以包含 using 指令、typedef 语句以及static_assert断言外，只能包含一条 return 返回语句。 constexpr int display(int x) { // 可以添加 using 执行、typedef 语句以及 static_assert 断言 return 1 + 2 + x; } 该函数必须有返回值，即函数的返回值类型不能是 void 函数在使用之前，必须有对应的定义语句。函数的使用分为“声明”和“定义”两部分，普通的函数调用只需要提前写好该函数的声明部分即可（函数的定义部分可以放在调用位置之后甚至其它文件中），但常量表达式函数在使用前，必须要有该函数的定义。 return 返回的表达式必须是常量表达式 注意:在常量表达式函数的 return 语句中，不能包含赋值的操作（例如 return x=1 在常量表达式函数中不允许的）。另外，用 constexpr 修改函数时，函数本身也是支持递归的。 constexpr修饰类的构造函数 对于 C++ 内置类型的数据，可以直接用 constexpr 修饰，但如果是自定义的数据类型（用 struct 或者 class 实现），直接用 constexpr 修饰是不行的。 自定义一个可产生常量的类型时，正确的做法是在该类型的内部添加一个常量构造函数: #include \u003ciostream\u003e using namespace std; // 自定义类型的定义 struct MyType { constexpr MyType(char *name,int age):name(name),age(age){}; const char* name; int age; //其它结构体成员 }; int main() { constexpr struct MyType mt { \"zhangsan\", 10 }; cout \u003c\u003c mt.name \u003c\u003c \" \" \u003c\u003c mt.age \u003c\u003c endl; return 0; } 注意: constexpr 修饰类的构造函数时，要求该构造函数的函数体必须为空，且采用初始化列表的方式为各个成员赋值时，必须使用常量表达式。 constexpr 可用于修饰函数，而类中的成员方法完全可以看做是位于类这个命名空间中的函数，所以 constexpr 也可以修饰类中的成员函数，只不过此函数必须满足前面提到条件。 注意: C++11 标准中，不支持用 constexpr 修饰带有 virtual 的成员方法。 constexpr修饰模板函数 C++11 语法中，constexpr 可以修饰模板函数，但由于模板中类型的不确定性，因此模板函数实例化后的函数是否符合常量表达式函数的要求也是不确定的。 针对这种情况下，C++11 标准规定，如果 constexpr 修饰的模板函数实例化结果不满足常量表达式函数的要求，则 constexpr 会被自动忽略，即该函数就等同于一个普通函数。 constexpr与const的区别 C++ 11标准中，为了解决 const 关键字的双重语义问题，保留了 const 表示“只读”的语义，而将“常量”的语义划分给了新添加的 constexpr 关键字。因此 C++11 标准中，建议将 const 和 constexpr 的功能区分开，即凡是表达只读语义的场景都使用 const，表达常量语义的场景都使用 constexpr。 只读和不允许被修改之间并没有必然的联系 #include \u003ciostream\u003e using namespace std; int main() { int a = 10; const int \u0026 con_b = a; cout \u003c\u003c con_b \u003c\u003c endl; a = 20; cout \u003c\u003c con_b \u003c\u003c endl; } 程序中用 const 修饰了 con_b 变量，表示该变量只读，即无法通过变量自身去修改自己的值。但这并不意味着 con_b 的值不能借助其它变量间接改变，通过改变 a 的值就可以使 con_b 的值发生变化。 在大部分实际场景中，const 和 constexpr 是可以混用的: const int a = 5 + 4; constexpr int a = 5 + 4; 在某些场景中，必须明确使用 constexpr #include \u003ciostream\u003e #include \u003carray\u003e using namespace std; constexpr int sqr1(int arg) { return arg * arg; } const int sqr2(int arg) { return arg * arg; } int main() { // 可以，因为sqr1时constexpr函数 array\u003cint,sqr1(10)\u003e mylist1; // 不可以，因为sqr2不是constexpr函数 array\u003cint,sqr2(10)\u003e mylist1; return 0; } ","date":"2024-01-17","objectID":"/posts/cmake_note_7/:2:13","tags":["CMake"],"title":"CMake 笔记 | [7] 设置语言标准（一）","uri":"/posts/cmake_note_7/"},{"categories":["C++"],"content":"2.14 long long超长整形 将 long long 整形写入 C++ 11 标准中，如同 long 类型整数需明确标注 L 或者 l 后缀一样，要使用 long long 类型的整数，也必须标注对应的后缀： 对于有符号 long long 整形，后缀用 LL 或者 ll 标识。如，10LL 就表示有符号超长整数 10。 对于无符号 long long 整形，后缀用 ULL、ull、Ull 或者 uLL 标识。如，10ULL 就表示无符号超长整数 10； 注意: 如果不添加任何标识，则所有的整数都会默认为 int 类型。 了解当前平台上 long long 整形的取值范围，可以使用头文件中与 long long 整形相关的 3 个宏，分别为 LLONG_MIN、LLONG_MAX 和 ULLONG_MIN： LLONG_MIN：代表当前平台上最小的 long long 类型整数； LLONG_MAX：代表当前平台上最大的 long long 类型整数； ULLONG_MIN：代表当前平台上最大的 unsigned long long 类型整数（无符号超长整型的最小值为 0）； #include \u003ciostream\u003e #include \u003ciomanip\u003e #include \u003cclimits\u003e using namespace std; int main() { cout \u003c\u003c\"long long最大值：\" \u003c\u003c LLONG_MIN \u003c\u003c\" \"\u003c\u003c hex \u003c\u003c LLONG_MIN \u003c\u003c\"\\n\"; cout \u003c\u003c dec \u003c\u003c\"long long最小值：\" \u003c\u003c LLONG_MAX \u003c\u003c \" \" \u003c\u003c hex \u003c\u003c LLONG_MAX \u003c\u003c \"\\n\"; cout \u003c\u003c dec \u003c\u003c \"unsigned long long最大值：\" \u003c\u003c ULLONG_MAX \u003c\u003c \" \" \u003c\u003c hex \u003c\u003c ULLONG_MAX; return 0; } ","date":"2024-01-17","objectID":"/posts/cmake_note_7/:2:14","tags":["CMake"],"title":"CMake 笔记 | [7] 设置语言标准（一）","uri":"/posts/cmake_note_7/"},{"categories":["C++"],"content":"2.15 右值引用 C++左值和右值 在 C++/C 语言中，一个表达式（可以是字面量、变量、对象、函数的返回值等）根据其使用场景不同，分为左值表达式和右值表达式。确切的说 C++ 中左值和右值的概念是从 C 语言继承过来的。 注意：左值的英文简写为lvalue，右值的英文简写为rvalue。很多人认为它们分别是left value、right value 的缩写。其实不然，lvalue 是loactor value的缩写，可意为存储在内存中、有明确存储地址（可寻址）的数据，而 rvalue 译为 read value，指的是那些可以提供数据值的数据（不一定可以寻址，例如存储于寄存器中的数据）。 通常情况下，判断某个表达式是左值还是右值，最常用的有以下 2 种方法: 可位于赋值号(=)左侧的表达式就是左值；反之，只能位于赋值号右侧的表达式就是右值。 int a = 5; // 错误，5 不能为左值 5 = a; // b 是一个左值 int b = 10; // a、b 都是左值，只不过将 b 可以当做右值使用 a = b; 有名称的、可以获取到存储地址的表达式即为左值；反之则是右值。 以上面定义的变量 a、b 为例，a 和 b 是变量名，且通过 \u0026a 和 \u0026b 可以获得他们的存储地址，因此 a 和 b 都是左值；反之，字面量 5、10，它们既没有名称，也无法获取其存储地址（字面量通常存储在寄存器中，或者和代码存储在一起），因此 5、10 都是右值。 右值引用 右值引用可以从字面意思上理解，指的是以引用传递（而非值传递）的方式使用 C++ 右值。 C++98/03 标准中有引用，使用 \u0026 表示。但此种引用方式有一个缺陷，即正常情况下只能操作 C++ 中的左值，无法对右值添加引用。 int num = 10; // 正确 int \u0026b = num; // 错误 int \u0026c = 10; 注意: 虽然 C++98/03 标准不支持为右值建立非常量左值引用，但允许使用常量左值引用操作右值。也就是说，常量左值引用既可以操作左值，也可以操作右值。 int num = 10; const int \u0026b = num; const int \u0026c = 10; 注意: C++11 标准中对右值做了更细致的划分，分别称为 纯右值（pure value，简称 pvalue）和 将亡值（expiring value，简称 xvalue ）。其中纯右值就是 C++98/03 标准中的右值，而将亡值则指的是和右值引用相关的表达式（比如某函数返回的 T \u0026\u0026 类型的表达式）。对于纯右值和将亡值，都属于右值。 ","date":"2024-01-17","objectID":"/posts/cmake_note_7/:2:15","tags":["CMake"],"title":"CMake 笔记 | [7] 设置语言标准（一）","uri":"/posts/cmake_note_7/"},{"categories":["C++"],"content":"2.16 移动构造函数的功能和用法 右值引用主要用于实现移动（move）语义和完美转发。 完美转发及其实现 C++11 标准为 C++ 引入右值引用语法的同时，还解决了一个 C++ 98/03 标准长期存在的短板，即使用简单的方式即可在函数模板中实现参数的完美转发。 完美转发 指的是函数模板可以将自己的参数\"完美\"地转发给内部调用的其它函数。所谓完美，即不仅能准确地转发参数的值，还能保证被转发参数的左、右值属性不变。如： template\u003ctypename T\u003e void function(T t) { otherdef(t); } 上述示例中，function() 函数模板中调用了 otherdef() 函数。在此基础上，完美转发指的是：如果 function() 函数接收到的参数 t 为左值，那么该函数传递给 otherdef() 的参数 t 也是左值；反之如果 function() 函数接收到的参数 t 为右值，那么传递给 otherdef() 函数的参数 t 也必须为右值。 function() 函数模板并没有实现完美转发。 参数 t 为非引用类型，这意味着在调用 function() 函数时，实参将值传递给形参的过程就需要额外进行一次拷贝操作； 无论调用 function() 函数模板时传递给参数 t 的是左值还是右值，对于函数内部的参数 t 来说，它有自己的名称，也可以获取它的存储地址，因此它永远都是左值，也就是说，传递给 otherdef() 函数的参数 t 永远都是左值。总之，无论从那个角度看，function() 函数的定义都不“完美”。 如果使用 C++ 98/03 标准下的 C++ 语言，可以采用函数模板重载的方式实现完美转发，例如： #include \u003ciostream\u003e using namespace std; // 重载被调用函数，查看完美转发的效果 void otherdef(int \u0026 t) { cout \u003c\u003c \"lvalue\\n\"; } void otherdef(const int \u0026 t) { cout \u003c\u003c \"rvalue\\n\"; } // 重载函数模板，分别接收左值和右值 // 接收右值参数 template \u003ctypename T\u003e void function(const T\u0026 t) { otherdef(t); } // 接收左值参数 template \u003ctypename T\u003e void function(T\u0026 t) { otherdef(t); } int main() { // 5 是右值 function(5); int x = 1; // x 是左值 function(x); return 0; } 对于右值5 来说，它实际调用的参数类型为 const T\u0026 的函数模板，由于 t 为 const 类型，所以 otherdef() 函数实际调用的也是参数用 const 修饰的函数，所以输出“rvalue”；对于左值 x 来说，2 个重载模板函数都适用，C++编译器会选择最适合的参数类型为 T\u0026 的函数模板，进而 therdef() 函数实际调用的是参数类型为非 const 的函数，输出“lvalue”。 使用重载的模板函数实现完美转发也是有弊端的，此方式仅适用于模板函数仅有少量参数的情况，否则就需要编写大量的重载函数模板，造成代码的冗余。为了更快速地实现完美转发，C++ 11 标准中允许在函数模板中使用右值引用来实现完美转发。 C++11 标准中规定，通常情况下右值引用形式的参数只能接收右值，不能接收左值。但对于函数模板中使用右值引用语法定义的参数来说，不再遵守这一规定，既可以接收右值，也可以接收左值（此时的右值引用又被称为“万能引用”）。 在 C++11 标准中实现完美转发，只需要编写如下一个模板函数即可： template \u003ctypename T\u003e void function(T\u0026\u0026 t) { otherdef(t); } 此模板函数的参数 t 既可以接收左值，也可以接收右值。但仅仅使用右值引用作为函数模板的参数是远远不够的，还有一个问题继续解决，如果调用 function() 函数时为其传递一个左值引用或者右值引用的实参，如下所示： int n = 10; int \u0026 num = n; // T 为 int\u0026 function(num); int \u0026\u0026 num2 = 11; // T 为 int \u0026\u0026 function(num2); 由 function(num) 实例化的函数底层就变成了 function(int \u0026\u0026 t)，同样由 function(num2) 实例化的函数底层则变成了 function(int \u0026\u0026 \u0026\u0026 t)。C++98/03 标准是不支持这种用法的，而 C++ 11标准为了更好地实现完美转发，特意为其指定了新的类型匹配规则，又称为引用折叠规则（假设用 A 表示实际传递参数的类型）： 当实参为左值或者左值引用（A\u0026）时，函数模板中 T\u0026\u0026 将转变为 A\u0026（A\u0026 \u0026\u0026 = A\u0026）； 当实参为右值或者右值引用（A\u0026\u0026）时，函数模板中 T\u0026\u0026 将转变为 A\u0026\u0026（A\u0026\u0026 \u0026\u0026 = A\u0026\u0026）。 注意：在实现完美转发时，只要函数模板的参数类型为 T\u0026\u0026，则 C++ 可以自行准确地判定出实际传入的实参是左值还是右值。 通过将函数模板的形参类型设置为 T\u0026\u0026，可以很好地解决接收左、右值的问题。但除此之外，还需要解决一个问题，即无论传入的形参是左值还是右值，对于函数模板内部来说，形参既有名称又能寻址，因此它都是左值。 将函数模板接收到的形参连同其左、右值属性，一起传递给被调用的函数方法：引入一个模板函数 forword(): #include \u003ciostream\u003e using namespace std; // 重载被调用函数，查看完美转发的效果 void otherdef(int \u0026 t) { cout \u003c\u003c \"lvalue\\n\"; } void otherdef(const int \u0026 t) { cout \u003c\u003c \"rvalue\\n\"; } // 实现完美转发的函数模板 template \u003ctypename T\u003e void function(T\u0026\u0026 t) { otherdef(forward\u003cT\u003e(t)); } int main() { function(5); int x = 1; function(x); return 0; } 移动语义 指的就是以移动而非深拷贝的方式初始化含有指针成员的类对象。简单的理解，移动语义指的就是将其他对象（通常是临时对象）拥有的内存资源“移为已用”。 #include \u003ciostream\u003e using namespace std; class demo{ public: demo():num(new int(0)){ cout\u003c\u003c\"construct!\"\u003c\u003cendl; } demo(const demo \u0026d):num(new int(*d.num)){ cout\u003c\u003c\"copy construct!\"\u003c\u003cendl; } // 移动构造函数 demo(demo \u0026\u0026d):num(d.num){ d.num = NULL; cout\u003c\u003c\"move construct!\"\u003c\u003cendl; } ~demo(){ cout\u003c\u003c\"class destruct!\"\u003c\u003cendl; } private: int *num; }; demo get_demo(){ return demo(); } int main(){ demo a = get_demo(); return 0; } demo类的其中一个构造函数(demo(demo \u0026\u0026d))使用右值引用形式的参数，又称为移动构造函数。并且在此构造函数中，num 指针变量采用的是浅拷贝的复制方式，同时在函数内部重置了 d.num，有效避免了“同一块对空间被释放多次”情况的发生。 非 const 右值引用只能操作右值，程序执行结果中产生的临时对象（例如函数返回值、lambda 表达式等）既无名称也无法获取其存储地址，所以属于右值。当类中同时包含拷贝构造函数和移动构造函数时，如果使用临时对象初始化当前类的对象，编译器会优先调用移动构造函数来完成此操作。只有当类中没有合适的移动构造函数时，编译器才会退而求其次，调用拷贝构造函数。 注意:在实际开发中，通常在类中自定义移动构造函数的同时，会再为其自定义一个适当的拷贝构造函数，由此当用户利用右值初始化类对象时，会调用移动构造函数；使用左值（非右值）初始化类对象时，会调用拷贝构造函数。 默认情况下，左值初始化同类对象只能通过拷贝构造函数完成，如果想调用移动构造函数，则必须使用右值进行初始化。C++11 标准中为了满足用户使用左值初始化同类对象时也通过移动构造函数完成的需求，新引入了 std::move() 函数，它可以将左值强制转换成对应的右值，由此便可以使用移动构造函数。 ","date":"2024-01-17","objectID":"/posts/cmake_note_7/:2:16","tags":["CMake"],"title":"CMake 笔记 | [7] 设置语言标准（一）","uri":"/posts/cmake_note_7/"},{"categories":["C++"],"content":"2.17 move()函数:将左值转换为右值 C++11 标准中借助右值引用可以为指定类添加移动构造函数，这样当使用该类的右值对象（可以理解为临时对象）初始化同类对象时，编译器会优先选择移动构造函数。 移动构造函数的调用时机是：用同类的右值对象初始化新对象。用当前类的左值对象（有名称，能获取其存储地址的实例对象）初始化同类对象时，调用移动构造函数方法：调用 move() 函数。 move 的功能很简单，就是将某个左值强制转化为右值。 引用限定符的用法 首先，我们定义左值的类对象称为左值对象，右值的类对象称为右值对象。 默认情况下，对于类中用 public 修饰的成员函数，既可以被左值对象调用，也可以被右值对象调用: #include \u003ciostream\u003e using namespace std; class demo { public: demo(int num):num(num){} int get_num(){ return this-\u003enum; } private: int num; }; int main() { demo a(10); cout \u003c\u003c a.get_num() \u003c\u003c endl; cout \u003c\u003c move(a).get_num() \u003c\u003c endl; return 0; } 可以看到，demo 类中的 get_num() 成员函数既可以被 a 左值对象调用，也可以被 move(a) 生成的右值 demo 对象调用，运行程序会输出两个 10。 某些场景中，可能需要限制调用成员函数的对象的类型（左值还是右值），为此 C++11 新添加了引用限定符。所谓引用限定符，就是在成员函数的后面添加 \u0026 或者 \u0026\u0026，从而限制调用者的类型（左值还是右值）。 #include \u003ciostream\u003e using namespace std; class demo { public: demo(int num):num(num){} int get_num()\u0026{ return this-\u003enum; } private: int num; }; int main() { demo a(10); // 正确 cout \u003c\u003c a.get_num() \u003c\u003c endl; // 错误 cout \u003c\u003c move(a).get_num() \u003c\u003c endl; return 0; } #include \u003ciostream\u003e using namespace std; class demo { public: demo(int num):num(num){} int get_num()\u0026\u0026{ return this-\u003enum; } private: int num; }; int main() { demo a(10); // 错误 cout \u003c\u003c a.get_num() \u003c\u003c endl; // 正确 cout \u003c\u003c move(a).get_num() \u003c\u003c endl; return 0; } 注意:引用限定符不适用于静态成员函数和友元函数。 const和引用限定 const 也可以用于修饰类的成员函数，习惯称为常成员函数。 class demo{ public: int get_num() const; } const 和引用限定符修饰类的成员函数时，都位于函数的末尾。 注意: C++11 标准规定，当引用限定符和 const 修饰同一个类的成员函数时，const 必须位于引用限定符前面。 当 const \u0026\u0026 修饰类的成员函数时，调用它的对象只能是右值对象；当 const \u0026 修饰类的成员函数时，调用它的对象既可以是左值对象，也可以是右值对象。无论是 const \u0026\u0026 还是 const \u0026 限定的成员函数，内部都不允许对当前对象做修改操作。 #include \u003ciostream\u003e using namespace std; class demo { public: demo(int num,int num2) :num(num),num2(num2) {} //左值和右值对象都可以调用 int get_num() const \u0026{ return this-\u003enum; } //仅供右值对象调用 int get_num2() const \u0026\u0026 { return this-\u003enum2; } private: int num; int num2; }; int main() { demo a(10,20); // 正确 cout \u003c\u003c a.get_num() \u003c\u003c endl; // 正确 cout \u003c\u003c move(a).get_num() \u003c\u003c endl; // 错误 cout \u003c\u003c a.get_num2() \u003c\u003c endl; // 正确 cout \u003c\u003c move(a).get_num2() \u003c\u003c endl; return 0; } ","date":"2024-01-17","objectID":"/posts/cmake_note_7/:2:17","tags":["CMake"],"title":"CMake 笔记 | [7] 设置语言标准（一）","uri":"/posts/cmake_note_7/"},{"categories":["C++"],"content":"2.17 nullptr：初始化空指针 实际开发中，避免产生野指针最有效的方法，就是在定义指针的同时完成初始化操作，即便该指针的指向尚未明确，也要将其初始化为空指针。 野指针，又称悬挂指针，指的是没有明确指向的指针。野指针往往指向的是那些不可用的内存区域，这就意味着像操作普通指针那样使用野指针（例如 \u0026p），极可能导致程序发生异常。 C++98/03 标准中，将一个指针初始化为空指针的方式： int *p = 0; // 推荐使用 int *p = NULL; 可以看到，可以将指针明确指向 0（0x0000 0000）这个内存空间。一方面，明确指针的指向可以避免其成为野指针；另一方面，大多数操作系统都不允许用户对地址为 0 的内存空间执行写操作，若用户在程序中尝试修改其内容，则程序运行会直接报错。 相比第一种方式，推荐将指针初始化为 NULL。NULL 并不是 C++ 的关键字，它是 C++ 事先定义好的一个宏，并且它的值往往就是字面量 0（#define NULL 0）。 C++ 中将 NULL 定义为字面常量 0，虽然能满足大部分场景的需要，但个别情况下，它会导致程序的运行和预期不符。 #include \u003ciostream\u003e using namespace std; void isnull(void *c){ cout \u003c\u003c \"void*c\" \u003c\u003c endl; } void isnull(int n){ cout \u003c\u003c \"int n\" \u003c\u003c endl; } int main() { isnull(0); isnull(NULL); return 0; } 以上代码都将输出int n。对于 isnull(0) 来说，显然它真正调用的是参数为整形的 isnull() 函数；而对于 isnull(NULL)，我们期望它实际调用的是参数为 void*c 的 isnull() 函数，但程序的执行结果并不符合预期。 C++ 98/03 标准中，如果想令 isnull(NULL) 实际调用的是 isnull(void* c)，就需要对 NULL（或者 0）进行强制类型转换： isnull( (void*)NULL ); isnull( (void*)0 ); 由于 C++ 98 标准使用期间，NULL 已经得到了广泛的应用，出于兼容性的考虑，C++11 标准并没有对 NULL 的宏定义做任何修改。为了修正 C++ 存在的这一 BUG，在 C++11 标准中引入一个新关键字，即 nullptr。 nullptr 是 nullptr_t 类型的右值常量，专用于初始化空类型指针。nullptr_t 是 C++11 新增加的数据类型，可称为指针空值类型。也就是说，nullpter 仅是该类型的一个实例对象（已经定义好，可以直接使用），如果需要完全定义出多个同 nullptr 完全一样的实例对象。nullptr 可以被隐式转换成任意的指针类型。 通过将指针初始化为 nullptr，可以很好地解决 NULL 遗留的问题: #include \u003ciostream\u003e using namespace std; void isnull(void *c){ cout \u003c\u003c \"void*c\" \u003c\u003c endl; } void isnull(int n){ cout \u003c\u003c \"int n\" \u003c\u003c endl; } int main() { isnull(NULL); isnull(nullptr); return 0; } ","date":"2024-01-17","objectID":"/posts/cmake_note_7/:2:18","tags":["CMake"],"title":"CMake 笔记 | [7] 设置语言标准（一）","uri":"/posts/cmake_note_7/"},{"categories":["C++"],"content":"2.18 智能指针 智能指针，可以从字面上理解为“智能”的指针。具体来讲，智能指针和普通指针的用法是相似的，不同之处在于，智能指针可以在适当时机自动释放分配的内存。也就是说，使用智能指针可以很好地避免“忘记释放内存而导致内存泄漏”问题出现。 C++ 智能指针底层是采用引用计数的方式实现的。简单的理解，智能指针在申请堆内存空间的同时，会为其配备一个整形值（初始值为 1），每当有新对象使用此堆内存时，该整形值 +1；反之，每当使用此堆内存的对象被释放时，该整形值减 1。当堆空间对应的整形值为 0 时，即表明不再有对象使用它，该堆空间就会被释放掉。 关于智能指针的具体使用方法，请参考《C++标准库》 shared_ptr 实际上，每种智能指针都是以类模板的方式实现的，shared_ptr 也不例外。shared_ptr（其中 T 表示指针指向的具体数据类型）的定义位于头文件，并位于 std 命名空间中。 和 unique_ptr、weak_ptr 不同之处在于，多个 shared_ptr 智能指针可以共同使用同一块堆内存。并且，由于该类型智能指针在实现上采用的是引用计数机制，即便有一个 shared_ptr 指针放弃了堆内存的使用权（引用计数减 1），也不会影响其他指向同一堆内存的 shared_ptr 指针（只有引用计数为 0 时，堆内存才会被自动释放）。 unique_ptr unique_ptr 指针自然也具备“在适当时机自动释放堆内存空间”的能力。和 shared_ptr 指针最大的不同之处在于，unique_ptr 指针指向的堆内存无法同其它 unique_ptr 共享，也就是说，每个 unique_ptr 指针都独自拥有对其所指堆内存空间的所有权。 注意：每个 unique_ptr 指针指向的堆内存空间的引用计数，都只能为 1，一旦该 unique_ptr 指针放弃对所指堆内存空间的所有权，则该空间会被立即释放回收。 unique_ptr 智能指针是以模板类的形式提供的，unique_ptr（T 为指针所指数据的类型）定义在头文件，并位于 std 命名空间中。 weak_ptr 和 shared_ptr、unique_ptr 类型指针一样，weak_ptr 智能指针也是以模板类的方式实现的。weak_ptr（ T 为指针所指数据的类型）定义在头文件，并位于 std 命名空间中。 C++11标准虽然将 weak_ptr 定位为智能指针的一种，但该类型指针通常不单独使用（没有实际用处），只能和 shared_ptr 类型指针搭配使用。甚至于，我们可以将 weak_ptr 类型指针视为 shared_ptr 指针的一种辅助工具，借助 weak_ptr 类型指针， 我们可以获取 shared_ptr 指针的一些状态信息，比如有多少指向相同的 shared_ptr 指针、shared_ptr 指针指向的堆内存是否已经被释放等等。 当 weak_ptr 类型指针的指向和某一 shared_ptr 指针相同时，weak_ptr 指针并不会使所指堆内存的引用计数加 1；同样，当 weak_ptr 指针被释放时，之前所指堆内存的引用计数也不会因此而减 1。也就是说，weak_ptr 类型指针并不会影响所指堆内存空间的引用计数。 ","date":"2024-01-17","objectID":"/posts/cmake_note_7/:2:19","tags":["CMake"],"title":"CMake 笔记 | [7] 设置语言标准（一）","uri":"/posts/cmake_note_7/"},{"categories":["C++"],"content":"一、编译器选项相关概念 编译器选项是指在编译程序时，可以通过设置不同的选项来控制编译器的行为和生成的代码的特性。常见的编译器选项包括优化选项、调试选项、警告选项、链接选项等。 优化选项可以控制编译器对代码进行优化的程度，以提高程序的性能。 调试选项可以生成调试信息，以便在程序出现问题时进行调试。 警告选项可以控制编译器是否生成警告信息，以帮助开发者发现潜在的问题。 链接选项可以控制编译器如何将多个目标文件链接在一起，以生成最终的可执行文件。 不同的编译器可能支持不同的选项，具体的选项和使用方法可以参考编译器的文档或者官方网站。 本篇内容涉及到的编译器选项有: 优化选项: -fPIC、-fno-rtti、-fno exception -fPIC:表示生成位置无关代码。具体来说，位置无关代码可以在不同的进程空间中加载和执行，而不需要进行重定位操作。fPIC选项通常用于生成动态库，因为动态库需要在不同的进程空间中加载和执行。使用-fPIC选项可以确保动态库中的代码可以在不同的进程空间中正确地执行。需要注意的是，使用-fPIC选项会增加代码的大小和运行时开销，因此需要根据具体情况来决定是否使用该选项。 -fno-rtti: 选项可以控制编译器是否生成与C++运行时类型信息（RTTI）相关的代码，以减小程序的大小和运行时开销。需要注意的是，禁用RTTI可能会影响程序的可靠性和可维护性，因为RTTI可以帮助开发者在运行时获取对象的类型信息。因此，需要根据具体情况来决定是否使用该选项。 -fno exception: 表示禁用C++异常处理机制。具体来说，使用该选项可以使编译器不生成与异常处理相关的代码，从而减小程序的大小和运行时开销。需要注意的是，禁用异常处理机制可能会影响程序的可靠性和可维护性，因为异常处理机制可以帮助开发者处理程序中的异常情况。因此，需要根据具体情况来决定是否使用该选项。 警告选项:-Wall、-Wextra和-Wpedantic -Wall: 表示开启所有警告信息。具体来说，编译器会生成所有可能的警告信息，包括一些可能会被忽略的警告信息。开启-Wall选项可以帮助开发者发现潜在的问题，提高代码的质量和可靠性。但是，由于-Wall会生成大量的警告信息，有时候会影响开发效率，因此需要根据具体情况来决定是否开启该选项。 -Wextra: 表示开启额外的警告信息。具体来说，编译器会生成一些不属于-Wall选项的警告信息，例如一些不符合标准的代码风格、一些未使用的变量等。同理，开启-Wextra选项可以帮助开发者发现更多的潜在问题，提高代码的质量和可靠性。但是，由于-Wextra会生成更多的警告信息，有时候会影响开发效率，因此需要根据具体情况来决定是否开启该选项。 -Wpedantic: 表示开启严格的警告信息。具体来说，编译器会生成一些不符合C或C++标准的代码警告信息，例如使用了不推荐的语法、未定义的行为等。开启-Wpedantic选项可以帮助开发者编写符合标准的代码，提高代码的可移植性和可靠性。同理，由于-Wpedantic会生成更多的警告信息，有时候会影响开发效率，因此需要根据具体情况来决定是否开启该选项 ","date":"2024-01-16","objectID":"/posts/cmake_note_6/:1:0","tags":["CMake"],"title":"CMake 笔记 | [6] 设置编译选项","uri":"/posts/cmake_note_6/"},{"categories":["C++"],"content":"二、编译器选项设置 为目标准备了标志列表，其中一些将无法在Windows上使用： list(APPEND compile_flags \"-fPIC\" \"-Wall\" \"-fPIC\") if(NOT WIN32) list(APPEND compile_flags \"-Wextra\" \"-Wpedantic\") endif() 为库设置编译选项： target_compile_options(test_message PRIVATE ${compile_flags} ) 编译选项可以添加三个级别的可见性：INTERFACE、PUBLIC和PRIVATE。 PRIVATE:编译选项会应用于给定的目标，不会传递给与目标相关的目标。 INTERFACE:给定的编译选项将只应用于指定目标，并传递给与目标相关的目标。 PUBLIC:编译选项将应用于指定目标和使用它的目标。 如何确定项目在CMake构建时，实际使用了哪些编译标志？ 一种方法是，使用CMake将额外的参数传递给本地构建工具。本例中会设置环境变量VERBOSE=1： mkdir -p build $ cd build $ cmake .. $ cmake --build . -- VERBOSE=1 ... lots of output ... Scanning dependencies of target test_message make[2]: 离开目录“/home/jiangli/repo/tutorials/cmake-tutorial/chapter1/13/build” /usr/bin/make -f message-module/CMakeFiles/test_message.dir/build.make message-module/CMakeFiles/test_message.dir/build make[2]: 进入目录“/home/jiangli/repo/tutorials/cmake-tutorial/chapter1/13/build” [ 25%] Building CXX object message-module/CMakeFiles/test_message.dir/src/message.cpp.o cd /home/jiangli/repo/tutorials/cmake-tutorial/chapter1/13/build/message-module \u0026\u0026 /usr/bin/c++ -I/home/jiangli/repo/tutorials/cmake-tutorial/chapter1/13/message-module/include -O3 -DNDEBUG -fPIC -Wall -Wextra -Wpedantic -std=gnu++11 -o CMakeFiles/test_message.dir/src/message.cpp.o -c /home/jiangli/repo/tutorials/cmake-tutorial/chapter1/13/message-module/src/message.cpp [ 50%] Linking CXX static library ../lib/libtest_message_release.a ... lots of output ... 第二种，使用CMake参数进行配置： $ cmake -D CMAKE_CXX_FLAGS=\"-fno-exceptions -fno-rtti\" .. 这个命令将编译项目，禁用异常和运行时类型标识(RTTI)。 ","date":"2024-01-16","objectID":"/posts/cmake_note_6/:2:0","tags":["CMake"],"title":"CMake 笔记 | [6] 设置编译选项","uri":"/posts/cmake_note_6/"},{"categories":["C++"],"content":"三、补充 大多数时候，编译器有特性标示。当前的例子只适用于GCC和Clang；其他编译器不确定是否会理解这些标志。如果项目是真正跨平台，那么这个问题就必须得到解决，以下为两种解决方案： 第一种，所需编译器标志列表附加到每个配置类型CMake变量CMAKE_\u003cLANG\u003e_FLAGS_\u003cCONFIG\u003e。标志确定设置为给定编译器有效的标志，因此将包含在if-endif子句中，用于检查CMAKE_\u003cLANG\u003e_COMPILER_ID变量： if(CMAKE_CXX_COMPILER_ID MATCHES GNU) list(APPEND CMAKE_CXX_FLAGS \"-fno-rtti\" \"-fno-exceptions\") list(APPEND CMAKE_CXX_FLAGS_DEBUG \"-Wsuggest-final-types\" \"-Wsuggest-final-methods\" \"-Wsuggest-override\") list(APPEND CMAKE_CXX_FLAGS_RELEASE \"-O3\" \"-Wno-unused\") endif() if(CMAKE_CXX_COMPILER_ID MATCHES Clang) list(APPEND CMAKE_CXX_FLAGS \"-fno-rtti\" \"-fno-exceptions\" \"-Qunused-arguments\" \"-fcolor-diagnostics\") list(APPEND CMAKE_CXX_FLAGS_DEBUG \"-Wdocumentation\") list(APPEND CMAKE_CXX_FLAGS_RELEASE \"-O3\" \"-Wno-unused\") endif() 第二种，定义特定的标志列表： set(COMPILER_FLAGS) set(COMPILER_FLAGS_DEBUG) set(COMPILER_FLAGS_RELEASE) if(CMAKE_CXX_COMPILER_ID MATCHES GNU) list(APPEND CXX_FLAGS \"-fno-rtti\" \"-fno-exceptions\") list(APPEND CXX_FLAGS_DEBUG \"-Wsuggest-final-types\" \"-Wsuggest-final-methods\" \"-Wsuggest-override\") list(APPEND CXX_FLAGS_RELEASE \"-O3\" \"-Wno-unused\") endif() if(CMAKE_CXX_COMPILER_ID MATCHES Clang) list(APPEND CXX_FLAGS \"-fno-rtti\" \"-fno-exceptions\" \"-Qunused-arguments\" \"-fcolor-diagnostics\") list(APPEND CXX_FLAGS_DEBUG \"-Wdocumentation\") list(APPEND CXX_FLAGS_RELEASE \"-O3\" \"-Wno-unused\") endif() 稍后，使用生成器表达式来设置编译器标志的基础上，为每个配置和每个目标生成构建系统: target_compile_option(test_message PRIVATE ${CXX_FLAGS} \"$\u003c$\u003cCONFIG:Debug\u003e:${CXX_FLAGS_DEBUG}\u003e\" \"$\u003c$\u003cCONFIG:Release\u003e:${CXX_FLAGS_RELEASE}\u003e\" ) 这里我们推荐使用第二种方法。 两种方法都有效，并在许多项目中得到广泛应用。不过，每种方式都有缺点。CMAKE_\u003cLANG\u003e_COMPILER_ID不能保证为所有编译器都定义。此外，一些标志可能会被弃用，或者在编译器的较晚版本中引入。 与CMAKE_\u003cLANG\u003e_COMPILER_ID类似，CMAKE_\u003cLANG\u003e_COMPILER_VERSION变量不能保证为所有语言和供应商都提供定义。尽管检查这些变量的方式非常流行，但我们认为更健壮的替代方法是检查所需的标志集是否与给定的编译器一起工作，这样项目中实际上只使用有效的标志。 ","date":"2024-01-16","objectID":"/posts/cmake_note_6/:3:0","tags":["CMake"],"title":"CMake 笔记 | [6] 设置编译选项","uri":"/posts/cmake_note_6/"},{"categories":["C++"],"content":"一、基本概念构建类型 CMake可以识别的构建类型是： Debug：用于在没有优化的情况下，使用带有调试符号构建库或者可执行文件 Release: 用于构建的优化的库或者可执行文件，不包含调试符号 RelWithDebInfo：用于构建较少的优化库或者可执行文件，包含调试符号 MinSizeRel：用于不增加目标代码大小的优化方式，来构建库或者可执行文件 控制生成构建系统使用的配置变量是CMAKE_BUILD_TYPE，该变量默认为空。 这里我们仍然选择CMake第三篇—动态库和静态库的补充中的代码，但是这里我们对CMakeLists.txt稍作修改。 ","date":"2024-01-15","objectID":"/posts/cmake_note_5/:1:0","tags":["CMake"],"title":"CMake 笔记 | [5] 构建类型(Debug、Release以及其他)","uri":"/posts/cmake_note_5/"},{"categories":["C++"],"content":"二、项目结构 . ├── cmake │ └── message_config.cmake.in ├── message-module │ ├── CMakeLists.txt │ ├── include │ │ ├── message_export_lib.h │ │ └── message.h │ └── src │ └── message.cpp ├── CMakeLists.txt └── hello_world.cpp 4 directories, 9 files 项目源码: https://github.com/jianye0428/CMake_Learning_Notes/tree/main/Note_5/message_module_lib_standard ","date":"2024-01-15","objectID":"/posts/cmake_note_5/:2:0","tags":["CMake"],"title":"CMake 笔记 | [5] 构建类型(Debug、Release以及其他)","uri":"/posts/cmake_note_5/"},{"categories":["C++"],"content":"2.1 message-module模块下的CMakeLists.txt file(GLOB SOURCE_FILE ${CMAKE_CURRENT_SOURCE_DIR}/src/*.cpp) if (BUILD_SHARED_LIBS) add_library(test_message SHARED ${SOURCE_FILE}) target_compile_definitions(test_message PUBLIC -DMESSAGE_LIB_SHARED_BUILD) target_compile_definitions(test_message PRIVATE -DMESSAGE_LIB_EXPORTS) else() add_library(test_message STATIC ${SOURCE_FILE}) endif() # 添加别名，以便库可以在构建树中使用，例如在测试时 add_library(test_message::test_message ALIAS test_message) target_include_directories(test_message PUBLIC $\u003cBUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}\u003e/include $\u003cINSTALL_INTERFACE:include\u003e ) set_target_properties(test_message PROPERTIES CXX_STANDARD 11 CMAKE_CXX_STANDARD_REQUIRED True ) set_target_properties(test_message PROPERTIES DEBUG_POSTFIX \"_debug\" RELEASE_POSTFIX \"_release\" ) install(TARGETS test_message EXPORT message_export_target RUNTIME DESTINATION \"bin\" LIBRARY DESTINATION \"lib\" ARCHIVE DESTINATION \"lib\" ) install(DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/include/ DESTINATION \"include\" FILES_MATCHING PATTERN \"*.h\" ) install(DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/include/ DESTINATION \"include\" FILES_MATCHING PATTERN \"*.hpp\" ) install(EXPORT message_export_target FILE message_lib.cmake DESTINATION lib/cmake/test_message ) include(CMakePackageConfigHelpers) # generate the config file that is includes the exports configure_package_config_file( ${CMAKE_SOURCE_DIR}/cmake/message_config.cmake.in \"${CMAKE_SOURCE_DIR}/cmake/message_config.cmake\" INSTALL_DESTINATION \"lib/cmake/test_message\" ) # generate the version file for the config file write_basic_package_version_file( \"${CMAKE_SOURCE_DIR}/cmake/message_config_version.cmake\" VERSION \"${PROJECT_VERSION_MAJOR}.${PROJECT_VERSION_MINOR}\" COMPATIBILITY AnyNewerVersion ) install(FILES ${CMAKE_SOURCE_DIR}/cmake/message_config.cmake ${CMAKE_SOURCE_DIR}/cmake/message_config_version.cmake DESTINATION lib/cmake/test_message ) export(EXPORT message_export_target FILE ${CMAKE_SOURCE_DIR}/cmake/message_config_version.cmake) 代码释义: 这里，我们基本上没有做修改，只添加了以下内容： 引用 set_target_properties(test_message PROPERTIES DEBUG_POSTFIX \"_debug\" RELEASE_POSTFIX \"_release\" ) 这将在 debug 构建模式下将库名后缀设置为 _debug，在 release 构建模式下将库名后缀设置为 _release。 然后，可以使用 test_message_debug 或 test_message_release 来引用库。当然，我们其实可以使用find_package，然后直接使用库的别名test_message即可。 ","date":"2024-01-15","objectID":"/posts/cmake_note_5/:2:1","tags":["CMake"],"title":"CMake 笔记 | [5] 构建类型(Debug、Release以及其他)","uri":"/posts/cmake_note_5/"},{"categories":["C++"],"content":"2.2 根目录下的CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(hello-world LANGUAGES CXX) set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib) set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib) set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin) option(BUILD_SHARED_LIBS \"Specifies the type of libraries (SHARED or STATIC) to build\" OFF) # Set install direcotory if(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT) set(CMAKE_INSTALL_PREFIX ${CMAKE_SOURCE_DIR}/output/) endif() if(NOT CMAKE_BUILD_TYPE) set(CMAKE_BUILD_TYPE Release CACHE STRING \"Build type\" FORCE) endif() message(STATUS \"Build type: ${CMAKE_BUILD_TYPE}\") message(STATUS \"C flags, Debug configuration: ${CMAKE_C_FLAGS_DEBUG}\") message(STATUS \"C flags, Release configuration: ${CMAKE_C_FLAGS_RELEASE}\") message(STATUS \"C flags, Release configuration with Debug info: ${CMAKE_C_FLAGS_RELWITHDEBINFO}\") message(STATUS \"C flags, minimal Release configuration: ${CMAKE_C_FLAGS_MINSIZEREL}\") message(STATUS \"C++ flags, Debug configuration: ${CMAKE_CXX_FLAGS_DEBUG}\") message(STATUS \"C++ flags, Release configuration: ${CMAKE_CXX_FLAGS_RELEASE}\") message(STATUS \"C++ flags, Release configuration with Debug info: ${CMAKE_CXX_FLAGS_RELWITHDEBINFO}\") message(STATUS \"C++ flags, minimal Release configuration: ${CMAKE_CXX_FLAGS_MINSIZEREL}\") add_subdirectory(${CMAKE_SOURCE_DIR}/message-module) include_directories( ${CMAKE_SOURCE_DIR}/message-module/include ) add_executable( ${PROJECT_NAME} ${CMAKE_SOURCE_DIR}/hello_world.cpp ) target_link_libraries( ${PROJECT_NAME} test_message ) 这里，我们添加了以下内容： 引用 if(NOT CMAKE_BUILD_TYPE) set(CMAKE_BUILD_TYPE Release CACHE STRING \"Build type\" FORCE) endif() message(STATUS \"Build type: ${CMAKE_BUILD_TYPE}\") message(STATUS \"C flags, Debug configuration: ${CMAKE_C_FLAGS_DEBUG}\") message(STATUS \"C flags, Release configuration: ${CMAKE_C_FLAGS_RELEASE}\") message(STATUS \"C flags, Release configuration with Debug info: ${CMAKE_C_FLAGS_RELWITHDEBINFO}\") message(STATUS \"C flags, minimal Release configuration: ${CMAKE_C_FLAGS_MINSIZEREL}\") message(STATUS \"C++ flags, Debug configuration: ${CMAKE_CXX_FLAGS_DEBUG}\") message(STATUS \"C++ flags, Release configuration: ${CMAKE_CXX_FLAGS_RELEASE}\") message(STATUS \"C++ flags, Release configuration with Debug info: ${CMAKE_CXX_FLAGS_RELWITHDEBINFO}\") message(STATUS \"C++ flags, minimal Release configuration: ${CMAKE_CXX_FLAGS_MINSIZEREL}\") 首先，检查是否设置了构建类型。如果没有，则将构建类型设置为 Release。然后，它使用 message 命令输出各种编译标志，包括 C 和 C++ 的 Debug 和 Release 配置，以及最小 Release 配置和带有调试信息的 Release配置。这些信息对于调试和优化构建非常有用。 ","date":"2024-01-15","objectID":"/posts/cmake_note_5/:2:2","tags":["CMake"],"title":"CMake 笔记 | [5] 构建类型(Debug、Release以及其他)","uri":"/posts/cmake_note_5/"},{"categories":["C++"],"content":"2.3 验证输出 我们执行以下命令，这里没有指定构建类型，即默认构建类型为Release。 mkdir build cd build cmake .. 输出: -- The CXX compiler identification is GNU 7.5.0 -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Check for working CXX compiler: /usr/bin/c++ - skipped -- Detecting CXX compile features -- Detecting CXX compile features - done -- Build type: Release -- C flags, Debug configuration: -- C flags, Release configuration: -- C flags, Release configuration with Debug info: -- C flags, minimal Release configuration: -- C++ flags, Debug configuration: -g -- C++ flags, Release configuration: -O3 -DNDEBUG -- C++ flags, Release configuration with Debug info: -O2 -g -DNDEBUG -- C++ flags, minimal Release configuration: -Os -DNDEBUG -- Configuring done -- Generating done -- Build files have been written to: /home/yejian/yejian_personal/c++_playground/CMake_Learning_Notes/Note_5/message_module_lib_standard/build 执行make: make [ 25%] Building CXX object message_module/CMakeFiles/test_message.dir/src/message.cpp.o [ 50%] Linking CXX static library ../lib/libtest_message_release.a [ 50%] Built target test_message [ 75%] Building CXX object CMakeFiles/hello-world.dir/hello_world.cpp.o [100%] Linking CXX executable bin/hello-world [100%] Built target hello-world 可以看到，我们执行make命令后，生成的库命名为libtest_message_release.a,并将其存入lib目录中。 执行: make install 输出结果如下: [ 50%] Built target test_message [100%] Built target hello-world Install the project... -- Install configuration: \"Release\" -- Installing: /home/jiangli/repo/tutorials/cmake-tutorial/chapter1/12/output/lib/libtest_message_release.a -- Installing: /home/jiangli/repo/tutorials/cmake-tutorial/chapter1/12/output/include -- Installing: /home/jiangli/repo/tutorials/cmake-tutorial/chapter1/12/output/include/message_export_lib.h -- Installing: /home/jiangli/repo/tutorials/cmake-tutorial/chapter1/12/output/include/message.h -- Up-to-date: /home/jiangli/repo/tutorials/cmake-tutorial/chapter1/12/output/include -- Installing: /home/jiangli/repo/tutorials/cmake-tutorial/chapter1/12/output/lib/cmake/test_message/message_lib.cmake -- Installing: /home/jiangli/repo/tutorials/cmake-tutorial/chapter1/12/output/lib/cmake/test_message/message_lib-release.cmake -- Installing: /home/jiangli/repo/tutorials/cmake-tutorial/chapter1/12/output/lib/cmake/test_message/message_config.cmake -- Installing: /home/jiangli/repo/tutorials/cmake-tutorial/chapter1/12/output/lib/cmake/test_message/message_config_version.cmake 设置构建类型为debug: mkdir build cd build cmake .. -DCMAKE_BUILD_TYPE=Debug 则输出: -- The CXX compiler identification is GNU 7.5.0 -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Check for working CXX compiler: /usr/bin/c++ - skipped -- Detecting CXX compile features -- Detecting CXX compile features - done -- Build type: Debug -- C flags, Debug configuration: -- C flags, Release configuration: -- C flags, Release configuration with Debug info: -- C flags, minimal Release configuration: -- C++ flags, Debug configuration: -g -- C++ flags, Release configuration: -O3 -DNDEBUG -- C++ flags, Release configuration with Debug info: -O2 -g -DNDEBUG -- C++ flags, minimal Release configuration: -Os -DNDEBUG -- Configuring done -- Generating done -- Build files have been written to: /home/yejian/yejian_personal/c++_playground/CMake_Learning_Notes/Note_5/message_module_lib_standard/build 执行make: make 输出如下: [ 25%] Building CXX object message_module/CMakeFiles/test_message.dir/src/message.cpp.o [ 50%] Linking CXX static library ../lib/libtest_message_debug.a [ 50%] Built target test_message [ 75%] Building CXX object CMakeFiles/hello-world.dir/hello_world.cpp.o [100%] Linking CXX executable bin/hello-world [100%] Built target hello-world 可以看到，我们执行make命令后，生成的库命名为libtest_message_debug.a,并将其存入lib目录中。 make install Consolidate compiler generated dependencies of target test_message [ 50%] Built target test_message Consolidate compiler generated dependencies of target hello-world [100%] Built target hello-wor","date":"2024-01-15","objectID":"/posts/cmake_note_5/:2:3","tags":["CMake"],"title":"CMake 笔记 | [5] 构建类型(Debug、Release以及其他)","uri":"/posts/cmake_note_5/"},{"categories":["C++"],"content":"三、补充 Release和Debug在构建项目通常很有用，如评估编译器优化级别的效果。对于单配置生成器，如Unix Makefile、MSYS Makefile或者Ninja，因为要对项目重新配置，这里需要运行CMake两次。 不过，CMake也支持符合配置生成器。这些通常是集成开发环境提供的项目文件，最显著的是Visual Studio和XCode，它们可以同时处理多个配置。可以使用CMAKE_CONFIGURATION_TYPES变量对这些生成器的可用配置进行调整。 mkdir -p build cd build cmake .. -G\"Visual Studio 14 2019 Win64\" -D CMAKE_CONFIGURATION_TYPES=\"Release;Debug\" 将为Release和Debug配置生成一个构建树。然后，您可以使–config标志来决定构建这两个中的哪一个: cmake --build . --config Release ","date":"2024-01-15","objectID":"/posts/cmake_note_5/:3:0","tags":["CMake"],"title":"CMake 笔记 | [5] 构建类型(Debug、Release以及其他)","uri":"/posts/cmake_note_5/"},{"categories":["C++"],"content":"一、条件语句 首先，我们还是拿我们上一篇根目录下的CMakeLists.txt文件进行讲解。 源码地址为：https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter1/11 cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(hello-world LANGUAGES CXX) set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib) set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib) set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin) option(BUILD_SHARED_LIBS \"Specifies the type of libraries (SHARED or STATIC) to build\" OFF) # Set install direcotory if(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT) set(CMAKE_INSTALL_PREFIX ${CMAKE_SOURCE_DIR}/output/) endif() add_subdirectory(${CMAKE_SOURCE_DIR}/message-module) include_directories( ${CMAKE_SOURCE_DIR}/message-module/include ) add_executable( ${PROJECT_NAME} ${CMAKE_SOURCE_DIR}/hello_world.cpp ) target_link_libraries( ${PROJECT_NAME} test_message ) 这里，我们使用了一个条件语句if()...endif()和一个选项命令option。这一节我们先对条件语句if()...endif()进行讲解，关于选项option命令，将在下一节进行讲解。 Tip if(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT) set(CMAKE_INSTALL_PREFIX ${CMAKE_SOURCE_DIR}/output/) endif() 判断CMake自带的宏CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT有没有处于开启状态，如果是默认状态的话，则CMAKE_INSTALL_PREFIX将被设置为${CMAKE_SOURCE_DIR}/output/。 这里，我们只写一个CMakeLists.txt对条件语句if()...else()和宏CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT、CMAKE_INSTALL_PREFIX进行探索。 cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(condition) if(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT) set(CMAKE_INSTALL_PREFIX ${CMAKE_SOURCE_DIR}/output/) endif() message(\"CMAKE_INSTALL_PREFIX is \" ${CMAKE_INSTALL_PREFIX}) 如果我们对CMAKE_INSTALL_PREFIX提前进行了定义 cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(condition) set(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT off) if(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT) set(CMAKE_INSTALL_PREFIX ${CMAKE_SOURCE_DIR}/output/) else() set(CMAKE_INSTALL_PREFIX ${CMAKE_SOURCE_DIR}/output/test) endif() message(\"CMAKE_INSTALL_PREFIX is \" ${CMAKE_INSTALL_PREFIX}) ","date":"2024-01-15","objectID":"/posts/cmake_note_4/:1:0","tags":["CMake"],"title":"CMake 笔记 | [4] 条件语句、选项命令以及指定编译器","uri":"/posts/cmake_note_4/"},{"categories":["C++"],"content":"二、命令选项 当然，上述内容我们也可以在编译时，使用如下命令，而不用显式地在CMakeLists.txt中对CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT进行设置，但我们需要在CMakeLists.txt中添加option命令。 cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(condition) option(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT \"Set default install path\" off) if(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT) set(CMAKE_INSTALL_PREFIX ${CMAKE_SOURCE_DIR}/output/) else() set(CMAKE_INSTALL_PREFIX ${CMAKE_SOURCE_DIR}/output/test) endif() message(\"CMAKE_INSTALL_PREFIX is \" ${CMAKE_INSTALL_PREFIX}) cmake .. -DCMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT=OFF 其中，-D开关用于为CMake设置任何类型的变量：逻辑变量、路径等等。 源码地址: https://gitee.com/jiangli01/tutorials/tree/master/cmake-tutorial/chapter1/11 ","date":"2024-01-15","objectID":"/posts/cmake_note_4/:2:0","tags":["CMake"],"title":"CMake 笔记 | [4] 条件语句、选项命令以及指定编译器","uri":"/posts/cmake_note_4/"},{"categories":["C++"],"content":"三、指定编译器 到目前为止，我们还没有考虑过使用CMake如何选择编译器。CMake可以根据平台和生成器选择编译器，还能将编译器标志设置为默认值。 在实际工作中，指定编译器十分重要，比如我们要交叉编译嵌入式的项目，亦或是我们可以将Qt、OpenCV等三方库交叉编译到我们的嵌入式项目中。具体关于如何编译其他三方库生成指定的形式，我们将在之后讲到交叉编译时会详细讲解。 ","date":"2024-01-15","objectID":"/posts/cmake_note_4/:3:0","tags":["CMake"],"title":"CMake 笔记 | [4] 条件语句、选项命令以及指定编译器","uri":"/posts/cmake_note_4/"},{"categories":["C++"],"content":"3.1 通过命令行的形式指定 cmake -D CMAKE_CXX_COMPILER=clang++ .. 指定c++的编译器为clang++ CMAKE_CXX_COMPILER 指定C++编译器 CMAKE_C_COMPILER 指定C编译器 CMAKE_Fortran_COMPILER 指定Fortran编译器 ","date":"2024-01-15","objectID":"/posts/cmake_note_4/:3:1","tags":["CMake"],"title":"CMake 笔记 | [4] 条件语句、选项命令以及指定编译器","uri":"/posts/cmake_note_4/"},{"categories":["C++"],"content":"3.2 通过导出环境变量指定 env CXX=clang++ cmake .. 导出环境变量，指定C++的编译器为Clang++ CXX(C++编译器)、CC(C编译器)和FC(Fortran编译器) 引用 注意: CMake了解运行环境，可以通过-D开关或者环境变量设置许多选项。第一种方法覆盖第二种方法，但是建议使用-D的显式设置选项。显式由于隐式，因为环境变量可能被设置为不合适的值（当前项目）。 注意: 这里，我们假设，其他的编译器，如clang++在标准的路径中可以用，CMake可以在标准路径中执行查找编译器。如果在标准路径中不可以用使用，则用户需要将完整的编译器可执行文件或者包装器路径传递给CMake。如： cmake -D CMAKE_CXX_COMPILER=/mnt/usr/bin/clang++ .. 注意: 这里，建议使用-DCMAKE_\u003cLANG\u003e_COMPILER选项设置编译器，而不是导出CXX、CC和FC。这是确保跨平台并与非POSIX兼容的唯一方法。为了避免变量污染环境，这些变量会影响与项目一起构建的外部库环境。 ","date":"2024-01-15","objectID":"/posts/cmake_note_4/:3:2","tags":["CMake"],"title":"CMake 笔记 | [4] 条件语句、选项命令以及指定编译器","uri":"/posts/cmake_note_4/"},{"categories":["C++"],"content":"3.3 在CMake中指定 set(CMAKE_CXX_COMPILER /mnt/usr/bin/clang++) 在使用CMake进行构建时，CMake会进行一系列的平台测试，以确定哪些编译器可以使用以及它们是否适合当前的项目。 一个合适的编译器不仅取决于我们使用的平台，还取决于我们想要的生成器。CMake执行的第一个测试基于项目语言的编译器名称。如，CC是一个工作i的C编译器，那么它将用作C项目的默认编译器。 GNU/Linux上，使用Unix Makefile或Ninja时，GCC家族中的编译器很可能是C++、C和Fortran的默认选择。Windows上，将选择Visual Studio中C++和C编译器。如果选择MinGW或MSYS Makefile作为生成器，则默认使用MinGW编译器。 ","date":"2024-01-15","objectID":"/posts/cmake_note_4/:3:3","tags":["CMake"],"title":"CMake 笔记 | [4] 条件语句、选项命令以及指定编译器","uri":"/posts/cmake_note_4/"},{"categories":["C++"],"content":"3.4 编译器的补充 我们平台上的CMake可以找到可用的编译器和编译器标志的方法是：CMake提供--system-information标志，他将把关于系统的所有信息转储到屏幕或者文件中。 cmake --system-information information.txt 文件中可以看到CMAKE_CXX_COMPILER、CMAKE_C_COMPILER和CMAKE_Fortran_COMPILER的默认值，以及默认标志。 CMake提供了额外的变量来与编译器交互： CMAKE_\u003cLANG\u003e_COMPILER_LOADED:如果为项目启用了语言，则将设置为TRUE。 CMAKE_\u003cLANG\u003e_COMPILER_ID:编译器标识字符串，编译器供应商所特有。例如，GCC用于GNU编译器集合，AppleClang用于macOS上的Clang, MSVC用于Microsoft Visual Studio编译器。注意，不能保证为所有编译器或语言定义此变量。 CMAKE_COMPILER_IS_GNU\u003cLANG\u003e:如果语言是GNU编译器集合的一部分，则将此逻辑变量设置为TRUE。注意变量名的部分遵循GNU约定：C语言为CC, C++语言为CXX, Fortran语言为G77。 CMAKE_\u003cLANG\u003e_COMPILER_VERSION:此变量包含一个字符串，该字符串给定语言的编译器版本。版本信息在major[.minor[.patch[.tweak]]]中给出。但是，对于CMAKE__COMPILER_ID，不能保证所有编译器或语言都定义了此变量。 我们可以使用不同的编译器，构建下面的CMakeLists.txt。 cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(recipe-06 LANGUAGES C CXX) message(STATUS \"Is the C++ compiler loaded? ${CMAKE_CXX_COMPILER_LOADED}\") if(CMAKE_CXX_COMPILER_LOADED) message(STATUS \"The C++ compiler ID is: ${CMAKE_CXX_COMPILER_ID}\") message(STATUS \"Is the C++ from GNU? ${CMAKE_COMPILER_IS_GNUCXX}\") message(STATUS \"The C++ compiler version is: ${CMAKE_CXX_COMPILER_VERSION}\") endif() message(STATUS \"Is the C compiler loaded? ${CMAKE_C_COMPILER_LOADED}\") if(CMAKE_C_COMPILER_LOADED) message(STATUS \"The C compiler ID is: ${CMAKE_C_COMPILER_ID}\") message(STATUS \"Is the C from GNU? ${CMAKE_COMPILER_IS_GNUCC}\") message(STATUS \"The C compiler version is: ${CMAKE_C_COMPILER_VERSION}\") endif() ","date":"2024-01-15","objectID":"/posts/cmake_note_4/:3:4","tags":["CMake"],"title":"CMake 笔记 | [4] 条件语句、选项命令以及指定编译器","uri":"/posts/cmake_note_4/"},{"categories":["C++"],"content":"一、导言 对CMake在不同平台上构建动态库和静态库做进一步的探索，即如何利用一个比较统一的模板在不同的平台构建静态库和动态库，以及对add_library命令的其他参数做进一步的探索。 ","date":"2024-01-14","objectID":"/posts/cmake_note_3/:1:0","tags":["CMake"],"title":"CMake 笔记 | [3] 静态库和动态的补充","uri":"/posts/cmake_note_3/"},{"categories":["C++"],"content":"二、库模板 ","date":"2024-01-14","objectID":"/posts/cmake_note_3/:2:0","tags":["CMake"],"title":"CMake 笔记 | [3] 静态库和动态的补充","uri":"/posts/cmake_note_3/"},{"categories":["C++"],"content":"2.1 项目结构 . ├── cmake │ └── message_config.cmake.in ├── message-module │ ├── include │ │ ├── message_export_lib.h │ │ └── message.h │ ├── src │ │ └── message.cpp │ └── CMakeLists.txt ├── hello_world.cpp └── CMakeLists.txt 本项目的结构相对比较复杂，为了能够生成一套比较标准的库（静态库/动态库），所以项目中会包含很多配置项，接下来我们会对项目中的所有内容进行一一讲解。 ","date":"2024-01-14","objectID":"/posts/cmake_note_3/:2:1","tags":["CMake"],"title":"CMake 笔记 | [3] 静态库和动态的补充","uri":"/posts/cmake_note_3/"},{"categories":["C++"],"content":"2.2 根目录下的CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(hello-world LANGUAGES CXX) set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib) set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/lib) set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${CMAKE_BINARY_DIR}/bin) option(BUILD_SHARED_LIBS \"Specifies the type of libraries (SHARED or STATIC) to build\" OFF) # Set install direcotory if(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT) set(CMAKE_INSTALL_PREFIX ${CMAKE_SOURCE_DIR}/output/) endif() add_subdirectory(${CMAKE_SOURCE_DIR}/message-module) include_directories( ${CMAKE_SOURCE_DIR}/message-module/include ) add_executable( ${PROJECT_NAME} ${CMAKE_SOURCE_DIR}/hello_world.cpp ) target_link_libraries( ${PROJECT_NAME} test_message ) Tip option(BUILD_SHARED_LIBS \"Specifies the type of libraries (SHARED or STATIC) to build\" OFF) 首先，我们提供了在执行cmake命令时的参数选项，默认默认情况下BUILD_SHARED_LIBS的状态是关闭的(OFF)，即默认情况下我们默认构建的是静态库。 当我们要构建动态库时，我们需执行以下命令（假设你已经在项目中构建了build文件夹,并且你现在在build目录中） cmake .. -DBUILD_SHARED_LIBS=ON Tip if(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT) set(CMAKE_INSTALL_PREFIX ${CMAKE_SOURCE_DIR}/output/) endif() 如果我们没有指定在make install后的输出路径，则CMAKE_INSTALL_PREFIX 将设置为${CMAKE_SOURCE_DIR}/output/，即当前项目下的output目录。 ","date":"2024-01-14","objectID":"/posts/cmake_note_3/:2:2","tags":["CMake"],"title":"CMake 笔记 | [3] 静态库和动态的补充","uri":"/posts/cmake_note_3/"},{"categories":["C++"],"content":"2.3 cmake目录下的message_config.cmake.in @PACKAGE_INIT@ include ( \"${CMAKE_CURRENT_LIST_DIR}/message_config.cmake\" ) 为了能够生成一个标准的库，我们写了一个message_config.cmake.in文件，该文件执行make install时将被调用，调用时我们再进行讲解。 ","date":"2024-01-14","objectID":"/posts/cmake_note_3/:2:3","tags":["CMake"],"title":"CMake 笔记 | [3] 静态库和动态的补充","uri":"/posts/cmake_note_3/"},{"categories":["C++"],"content":"2.4 message-module下message_export_lib.h #ifndef MESSAGE_EXPORT_LIB_H_ #define MESSAGE_EXPORT_LIB_H_ #ifdef MESSAGE_LIB_SHARED_BUILD #ifdef _WIN32 #ifdef MESSAGE_LIB_EXPORTS #define MESSAGE_LIB_API __declspec(dllexport) #else #define MESSAGE_LIB_API __declspec(dllimport) #endif // MESSAGE_LIB_EXPORTS #else #define MESSAGE_LIB_API #endif // _WIN32 #else #define MESSAGE_LIB_API #endif // MESSAGE_LIB_SHARED_BUILD #endif // ! MESSAGE_EXPORT_LIB_H_ 首先，如果我们定义了宏定义MESSAGE_LIB_SHARED_BUILD(即我们要构建动态库时)，我们将执行以下命令：如果是Windows平台，并且是在生成动态库时，即定义了(MESSAGE_LIB_EXPORTS)，将__declspec(dllexport)定义为MESSAGE_LIB_API；如果是使用动态库时，即未定义(MESSAGE_LIB_EXPORTS)，则将__declspec(dllimport)定义为MESSAGE_LIB_API。如果是非Windows平台，则对宏MESSAGE_LIB_API不做任何操作(因为在非Windows平台上可以动态库的生成和使用与静态库是一样的)。 然后，如果我们未定义宏定义MESSAGE_LIB_SHARED_BUILD(即我们要构建静态库时)，我们对宏MESSAGE_LIB_API不做任何操作。 注意：关于宏定义MESSAGE_LIB_SHARED_BUILD和MESSAGE_LIB_EXPORTS是否要添加利用message-module下的CMakeLists.txt进行配置。 ","date":"2024-01-14","objectID":"/posts/cmake_note_3/:2:4","tags":["CMake"],"title":"CMake 笔记 | [3] 静态库和动态的补充","uri":"/posts/cmake_note_3/"},{"categories":["C++"],"content":"2.5 message-module下message.h #ifndef MESSAGE_HEADER_H_ #define MESSAGE_HEADER_H_ #include \u003ciostream\u003e #include \u003cstring\u003e #include \"message_export_lib.h\" class MESSAGE_LIB_API Message { public: Message() {} void Print(const std::string \u0026message); }; #endif 我们将头文件message_export_lib.h包含进来，来控制在不同平台生成不同的库时的选项。 ","date":"2024-01-14","objectID":"/posts/cmake_note_3/:2:5","tags":["CMake"],"title":"CMake 笔记 | [3] 静态库和动态的补充","uri":"/posts/cmake_note_3/"},{"categories":["C++"],"content":"2.6 message-module下的CMakeLists.txt file(GLOB SOURCE_FILE ${CMAKE_CURRENT_SOURCE_DIR}/src/*.cpp) if (BUILD_SHARED_LIBS) add_library(test_message SHARED ${SOURCE_FILE}) target_compile_definitions(test_message PUBLIC -DMESSAGE_LIB_SHARED_BUILD) target_compile_definitions(test_message PRIVATE -DMESSAGE_LIB_EXPORTS) else() add_library(test_message STATIC ${SOURCE_FILE}) endif() # 添加别名，以便库可以在构建树中使用，例如在测试时 add_library(test_message::test_message ALIAS test_message) target_include_directories(test_message PUBLIC $\u003cBUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}\u003e/include $\u003cINSTALL_INTERFACE:include\u003e ) set_target_properties(test_message PROPERTIES CXX_STANDARD 11 CMAKE_CXX_STANDARD_REQUIRED True ) install(TARGETS test_message EXPORT message_export_target RUNTIME DESTINATION \"bin\" LIBRARY DESTINATION \"lib\" ARCHIVE DESTINATION \"lib\" ) install(DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/include/ DESTINATION \"include\" FILES_MATCHING PATTERN \"*.h\" ) install(DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR}/include/ DESTINATION \"include\" FILES_MATCHING PATTERN \"*.hpp\" ) install(EXPORT message_export_target FILE message_lib.cmake DESTINATION lib/cmake/test_message ) include(CMakePackageConfigHelpers) # generate the config file that is includes the exports configure_package_config_file( ${CMAKE_SOURCE_DIR}/cmake/message_config.cmake.in \"${CMAKE_SOURCE_DIR}/cmake/message_config.cmake\" INSTALL_DESTINATION \"lib/cmake/test_message\" ) # generate the version file for the config file write_basic_package_version_file( \"${CMAKE_SOURCE_DIR}/cmake/message_config_version.cmake\" VERSION \"${PROJECT_VERSION_MAJOR}.${PROJECT_VERSION_MINOR}\" COMPATIBILITY AnyNewerVersion ) install(FILES ${CMAKE_SOURCE_DIR}/cmake/message_config.cmake ${CMAKE_SOURCE_DIR}/cmake/message_config_version.cmake DESTINATION lib/cmake/test_message ) export(EXPORT message_export_target FILE ${CMAKE_SOURCE_DIR}/cmake/message_config_version.cmake) 如果我们让宏BUILD_SHARED_LIBS为开启状态(即我们要构建动态库)，我们要将宏定义MESSAGE_LIB_SHARED_BUILD和MESSAGE_LIB_EXPORTS添加到编译器中，这样我们的头文件message_export_lib.h中便知道我们要构建动态库。 否则(即我们没有让BUILD_SHARED_LIBS开启)，我们将构建静态库。 利用CMakePackageConfigHelpers模块生成关于test_message库的cmake的配置文件，且可以使用命令find_package命令找到库test_message库。关于以上命令的具体参数使用，我们将在具体的命令学习章节进行具体的讲解和学习。 ","date":"2024-01-14","objectID":"/posts/cmake_note_3/:2:6","tags":["CMake"],"title":"CMake 笔记 | [3] 静态库和动态的补充","uri":"/posts/cmake_note_3/"},{"categories":["C++"],"content":"三、add_library其他参数的一些探索 ","date":"2024-01-14","objectID":"/posts/cmake_note_3/:3:0","tags":["CMake"],"title":"CMake 笔记 | [3] 静态库和动态的补充","uri":"/posts/cmake_note_3/"},{"categories":["C++"],"content":"3.1 生成对象库 cmake_minimum_required(VERSION 3.5 FATAL_ERROR) project(recipe-03 LANGUAGES CXX) add_library(message-objs OBJECT Message.hpp Message.cpp ) # this is only needed for older compilers # but doesn't hurt either to have it set_target_properties(message-objs PROPERTIES POSITION_INDEPENDENT_CODE 1 ) add_library(message-shared SHARED $\u003cTARGET_OBJECTS:message-objs\u003e ) add_library(message-static STATIC $\u003cTARGET_OBJECTS:message-objs\u003e ) add_executable(hello-world hello-world.cpp) target_link_libraries(hello-world message-static) 为了保证编译的目标文件与生成位置无关，可以通过使用set_target_properties命令，设置message-objs目标的相应属性来实现。 **注意:**可能在某些平台和/或使用较老的编译器上，需要显式地为目标设置POSITION_INDEPENDENT_CODE属性。 现在，可以使用这个对象库来获取静态库(message-static)和动态库(message-shared)。要注意引用对象库的生成器表达式语法:$\u003cTARGET_OBJECTS:message-objs\u003e。生成器表达式是CMake在生成时(即配置之后)构造，用于生成特定于配置的构建输出。 ","date":"2024-01-14","objectID":"/posts/cmake_note_3/:3:1","tags":["CMake"],"title":"CMake 笔记 | [3] 静态库和动态的补充","uri":"/posts/cmake_note_3/"},{"categories":["C++"],"content":"3.2 将静态库和动态库同时命名为同名的两个库 add_library(message-shared SHARED $\u003cTARGET_OBJECTS:message-objs\u003e ) set_target_properties(message-shared PROPERTIES OUTPUT_NAME \"message\" ) add_library(message-static STATIC $\u003cTARGET_OBJECTS:message-objs\u003e ) set_target_properties(message-static PROPERTIES OUTPUT_NAME \"message\" ) ","date":"2024-01-14","objectID":"/posts/cmake_note_3/:3:2","tags":["CMake"],"title":"CMake 笔记 | [3] 静态库和动态的补充","uri":"/posts/cmake_note_3/"},{"categories":["C++"],"content":"一、项目结构 . ├── include │ └── message.h ├── src │ └── message.cpp ├── hello_world.cpp └── CMakeLists.txt 项目结构是为了让我们开发人员对项目更加清晰，使代码结构更加清晰（模块化）。一般我们的项目比较简单时，可以构建为如上的项目结构。但是在构建大型项目时，项目结构会更加复杂，具体请参考下节内容。 这里我们构建了include目录和src目录，include目录主要存放的是CPP文件的头文件，即函数的声明，为使用它的文件提供API。src目录主要是存放的函数的具体实现。 源码地址: ","date":"2024-01-12","objectID":"/posts/cmake_note_2/:0:1","tags":["CMake"],"title":"CMake 笔记 | [2] 多目录多文件的CMake构建方式","uri":"/posts/cmake_note_2/"},{"categories":["C++"],"content":"二、message.h #ifndef MESSAGE_HEADER_H_ #define MESSAGE_HEADER_H_ #include \u003ciostream\u003e #include \u003cstring\u003e class Message { public: Message() {} void Print(const std::string \u0026message); }; #endif // ! MESSAGE_HEADER_H_ ","date":"2024-01-12","objectID":"/posts/cmake_note_2/:0:2","tags":["CMake"],"title":"CMake 笔记 | [2] 多目录多文件的CMake构建方式","uri":"/posts/cmake_note_2/"},{"categories":["C++"],"content":"三、message.cpp #include \"message.h\" void Message::Print(const std::string \u0026message) { std::cout \u003c\u003c message \u003c\u003c std::endl; } ","date":"2024-01-12","objectID":"/posts/cmake_note_2/:0:3","tags":["CMake"],"title":"CMake 笔记 | [2] 多目录多文件的CMake构建方式","uri":"/posts/cmake_note_2/"},{"categories":["C++"],"content":"四、hello_world.cpp #include \"message.h\" int main() { Message message; message.Print(\"Hello, CMake World!\"); message.Print(\"Goodbye, CMake World!\"); return EXIT_SUCCESS; } ","date":"2024-01-12","objectID":"/posts/cmake_note_2/:0:4","tags":["CMake"],"title":"CMake 笔记 | [2] 多目录多文件的CMake构建方式","uri":"/posts/cmake_note_2/"},{"categories":["C++"],"content":"五、CMake文件 cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(hello-world LANGUAGES CXX) include_directories( ${CMAKE_SOURCE_DIR}/include ) file(GLOB HEADER ${CMAKE_SOURCE_DIR}/include/*.h) file(GLOB SOURCE ${CMAKE_SOURCE_DIR}/src/*.cpp) add_executable( ${PROJECT_NAME} ${HEADER} ${SOURCE} ${CMAKE_SOURCE_DIR}/hello_world.cpp ) 代码释义: Tip include_directories( ${CMAKE_SOURCE_DIR}/include ) 将include目录下的所有文件包含进来，这样include目录下的message.h将会被包含到整个项目中。如果我们在细分目录中使用包含某一模块的头文件，我们可以在具体模块的CMakeLists.txt中使用该命令，且要包含的头文件的可见性只有该模块，其他模块不可见，具体使用方法，请参考下节内容。 Tip file(GLOB HEADER ${CMAKE_SOURCE_DIR}/include/*.h) file(GLOB SOURCE ${CMAKE_SOURCE_DIR}/src/*.cpp) 如果include目录和src目录中有多个头文件和源文件，使用如上命令可以将所有头文件集合到HEADER和SOURCE自定义宏定义中，使用时的命令为${HEADER}和${SOURCE}。 Tip add_executable( ${PROJECT_NAME} ${HEADER} ${SOURCE} ${CMAKE_SOURCE_DIR}/hello_world.cpp ) 这将结合include目录下的文件和src目录下的文件以及hello_world.cpp生成名为hello-world的可执行文件。 ","date":"2024-01-12","objectID":"/posts/cmake_note_2/:0:5","tags":["CMake"],"title":"CMake 笔记 | [2] 多目录多文件的CMake构建方式","uri":"/posts/cmake_note_2/"},{"categories":["C++"],"content":"六、构建及编译 mkdir build cd build cmake .. 构建过程: -- The CXX compiler identification is GNU 9.4.0 -- Check for working CXX compiler: /usr/bin/c++ -- Check for working CXX compiler: /usr/bin/c++ -- works -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Detecting CXX compile features -- Detecting CXX compile features - done -- Configuring done -- Generating done -- Build files have been written to: /home/jiangli/repo/tutorials/cmake-tutorial/chapter1/02/build 构建可执行文件并输出: make Scanning dependencies of target hello-world [ 33%] Building CXX object CMakeFiles/hello-world.dir/src/message.cpp.o [ 66%] Building CXX object CMakeFiles/hello-world.dir/hello_world.cpp.o [100%] Linking CXX executable hello-world [100%] Built target hello-world 上一篇我们没有讲将执行cmake命令后生成的MakeFile文件，其如何构建出可执行文件的具体操作，只是简单的说MakeFile需要make命令执行。 在我们执行完cmake ..后，将生成MakeFile文件，然后执行make后便可以生成可执行文件。 这里我们进行补充说明：如果我们在GNU/Linux上，执行CMake ..后会生成MakeFile文件，然后执行make命令即可生成可执行文件；在Windows上，执行cmake ..后会生成sln文件，需要使用VS进行打开，然后对其进行生成操作。Windows生成sln文件后的具体操作过程请参考最后一些补充内容。除此之外，我们可以执行以下命令，不分平台直接构建出可执行文件: cmake --build . ","date":"2024-01-12","objectID":"/posts/cmake_note_2/:0:6","tags":["CMake"],"title":"CMake 笔记 | [2] 多目录多文件的CMake构建方式","uri":"/posts/cmake_note_2/"},{"categories":["C++"],"content":"七、静态库和动态库简介 首先，如果对程序的生命周期的不清楚，请先移步这里进行学习。 7.1 静态库 在链接阶段，会将汇编生成的目标文件.o与引用到的库一起链接打包到可执行文件中。这个链接方式为静态链接，所需要的.o（unix系统）称为静态库。 静态库对函数库的链接是放在编译时期完成的。 程序在运行时与函数库再无瓜葛，移植方便。 浪费空间和资源，因为所有相关的目标文件与牵涉到的函数库被链接成一个可执行文件。 静态库对程序的更新、部署和发布会带来麻烦。如果静态库libxxx.o更新了，所有使用它的应用程序都需要重新编译、发布给用户。 7.2 动态库 动态库在程序编译时并不会链接到目标代码中，而是在程序运行时才被载入。不同的应用程序如果调用相同的库，那么在内存只需要有一份该共享库的实例，规避了空间浪费。 动态库在程序运行时才被载入，也解决了静态库对程序的更新、部署和发布带来的问题，用户只需要更新动态库即可，增量更新。 Windows与Linux执行文件格式不同，在创建动态库的时候有一些差异： 在Windows系统下的执行文件格式是PE格式，动态库需要一个DllMain函数做初始化的入口，通常在导出函数的声明时需要有_declspec(dllexport)关键字。 Linux下gcc编译的执行文件默认是ELF格式，不需要初始化入口，亦不需要函数做特别的声明，编写比较方便 ","date":"2024-01-12","objectID":"/posts/cmake_note_2/:0:7","tags":["CMake"],"title":"CMake 笔记 | [2] 多目录多文件的CMake构建方式","uri":"/posts/cmake_note_2/"},{"categories":["C++"],"content":"八、构建和链接静态库 8.1 项目结构 . ├── message-module │ ├── include │ │ └── message.h │ ├── src │ │ └── message.cpp │ └── CMakeLists.txt ├── hello_world.cpp └── CMakeLists.txt 在实际的项目开发过程中，我们的项目结构往往会由很多个模块组成，每个模块通过一个单独的CMakeLists.txt去控制，最后在根目录下的CMakeLists.txt中将各个模块组合使用。 本项目中为了简化学习，只构建了一个message-module模块，构建多个模块的方式同理。其中项目中的所有CPP源文件与第一节内容相同，这里就不展开描述了。 源码地址:https://github.com/jianye0428/CMake_Learning_Notes/tree/main/Note_2/message_static_lib 8.2 message-module目录下的CMakeLists include_directories( ${CMAKE_CURRENT_SOURCE_DIR}/include ) file(GLOB HEADER ${CMAKE_CURRENT_SOURCE_DIR}/include/*.h) file(GLOB SOURCE ${CMAKE_CURRENT_SOURCE_DIR}/src/*.cpp) add_library( test_message STATIC ${HEADER} ${SOURCE} ) 代码释义: Tip add_library( test_message STATIC ${HEADER} ${SOURCE} ) add_library生成必要的构建指令，将指定的源码编译到库中。第一个参数是目标名。整个项目中，可使用相同的名称来引用库。生成的库的实际名称将由CMake通过在前面添加前缀lib和适当的扩展名作为后缀来形成。生成库是根据第二个参数(STATIC或SHARED)和操作系统确定的，本项目是将目标文件生成静态库。 8.3 根目录下的CMakeLists cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(hello-world LANGUAGES CXX) # 设置可执行文件到bin文件夹下 set(EXECUTE_FILE ${CMAKE_BINARY_DIR}/bin) set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${EXECUTE_FILE}) # 设置静态库到lib文件夹下 set(LIB_FILE ${CMAKE_BINARY_DIR}/lib) set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${LIB_FILE}) include_directories( ${CMAKE_SOURCE_DIR}/message-module/include ) add_subdirectory( ${CMAKE_SOURCE_DIR}/message-module ) add_executable( ${PROJECT_NAME} ${CMAKE_SOURCE_DIR}/hello_world.cpp ) target_link_libraries( ${PROJECT_NAME} test_message ) 代码释义: Tip # 设置可执行文件到bin文件夹下 set(EXECUTE_FILE ${CMAKE_BINARY_DIR}/bin) set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${EXECUTE_FILE}) # 设置静态库到lib文件夹下 set(LIB_FILE ${CMAKE_BINARY_DIR}/lib) set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY ${LIB_FILE}) 在构建项目时，我们为了使得项目结构更加清晰，使得生成的可执行文件、静态库以及动态库等文件能够存放在合适的位置。这样的构建方式有助于我们在项目重构、项目优化、debug的时候逻辑更加清晰。 Tip include_directories( ${CMAKE_SOURCE_DIR}/message-module/include ) 这个命令同第一节内容，因为hello_world.cpp要使用message-module模块的API，且与该CMakeLists.txt在相同层级的目录，所以需要将message-module模块的API包含进去。 如果hello_world.cpp中使用到了多个模块，则此处可以包含多个模块的API： include_directories( ${CMAKE_SOURCE_DIR}/message-module/include ${CMAKE_SOURCE_DIR}/xxx-module/include ) Tip add_subdirectory( ${CMAKE_SOURCE_DIR}/message-module ) 将我们的message-module添加进来进行编译，这个函数命令将寻找message-module目录下的CMakeLists.txt，如果该目录下没有CMakeLists.txt将报错。 由于在本项目中，hello_world.cpp要使用message-module模块中编译生成的静态库，所以add_subdirectory命令将message-module添加到项目中, add_subdirectory的顺序必须要先于add_executable命令。 Tip add_executable( ${PROJECT_NAME} ${CMAKE_SOURCE_DIR}/hello_world.cpp ) target_link_libraries( ${PROJECT_NAME} test_message ) add_executable命令将hello_world.cpp编译成可执行文件，其名字为项目名称hello-world，该可执行文件使用target_link_libraries命令将message-module模块下编译生成的静态库test_message链接到可执行文件中。 注意：在子模块message-module中编译生成的test_message是全局可见的，即任何模块或者根目录下的CMakeLists.txt都可以直接使用test_message进行调用。 8.4 构建以及编译 mkdir build cd build cmake .. 构建及编译过程: -- The CXX compiler identification is GNU 9.4.0 -- Check for working CXX compiler: /usr/bin/c++ -- Check for working CXX compiler: /usr/bin/c++ -- works -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Detecting CXX compile features -- Detecting CXX compile features - done -- Configuring done -- Generating done -- Build files have been written to: /home/jiangli/repo/tutorials/cmake-tutorial/chapter1/03/build # cmake --build . make Scanning dependencies of target test_message [ 25%] Building CXX object message-module/CMakeFiles/test_message.dir/src/message.cpp.o [ 50%] Linking CXX static library ../lib/libtest_message.a [ 50%] Built target test_message Scanning dependencies of target hello-world [ 75%] Building CXX object CMakeFiles/hello-world.dir/hello_world.cpp.o [100%] Linking CXX executable bin/hello-world [100%] Built target hello-world 可以通过编译日志看到，首先编译了message-module模块，并将编译生成的libtest_message.a存档到了../lib/，即build文件夹中的lib目录中。然后链接hello-world所需要的依赖项，此时便将test-message链接到了hello-world中，最终生成可执行文件hello-world，并将其存放到bin目录中，即build文件夹下的bin目录。 ","date":"2024-01-12","objectID":"/posts/cmake_note_2/:0:8","tags":["CMake"],"title":"CMake 笔记 | [2] 多目录多文件的CMake构建方式","uri":"/posts/cmake_note_2/"},{"categories":["C++"],"content":"九、只链接链接三方库（静态） 我们在构建实际项目过程中，一个项目往往需要链接许多的三方库，抑或是我们将自己的算法以静态库的形式发布，通常需要为我们的项目链接三方库。本节讲其中的一种，后续涉及到三方库的链接将讲述所有链接的方式。关于third-party模块下include文件夹下的message.h头文件与前面相同，lib文件夹下的libtest_message.a是第三节编译生成的静态库。 9.1 项目结构 . ├── third-party │ ├── include │ │ └── message.h │ └── lib │ └── libtest_message.a ├── hello_world.cpp └── CMakeLists.txt 一般，我们将三方库放到项目中一个third-party的文件夹下，当然你也可以随意命名。三方库third-party中包含include和lib分别存放三方库的API和静态库。 源码地址:https://github.com/jianye0428/CMake_Learning_Notes/tree/main/Note_2/message_static_lib_third_party 9.2 CMakeLists.txt cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(hello-world LANGUAGES CXX) # 设置可执行文件到bin文件夹下 set(EXECUTE_FILE ${CMAKE_BINARY_DIR}/bin) set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${EXECUTE_FILE}) set(TEST_MESSAGE ${CMAKE_SOURCE_DIR}/third-party/lib/libtest_message.a) include_directories( ${CMAKE_SOURCE_DIR}/third-party/include ) add_executable( ${PROJECT_NAME} ${CMAKE_SOURCE_DIR}/hello_world.cpp ) target_link_libraries( ${PROJECT_NAME} ${TEST_MESSAGE} ) 代码释义: Tip set(TEST_MESSAGE ${CMAKE_SOURCE_DIR}/third-party/lib/libtest_message.a) 将三方库中的静态库定义为TEST_MESSAGE，方便后续使用${TEST_MESSAGE}进行调用。当然你也可以直接在target_link_libraries命令中使用${CMAKE_SOURCE_DIR}/third-party/lib/libtest_message.a进行链接，但是这么做是不推荐的。如果多个模块都使用到了该库，那么定义为宏的方式更加方便和清晰。 今后，我们都将定义出来的宏统一采用了大写，意和CMake自身变量命名对其。 9.3 构建及编译 mkdir build cd build cmake .. 构建及编译过程: -- The CXX compiler identification is GNU 9.4.0 -- Check for working CXX compiler: /usr/bin/c++ -- Check for working CXX compiler: /usr/bin/c++ -- works -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Detecting CXX compile features -- Detecting CXX compile features - done -- Configuring done -- Generating done -- Build files have been written to: /home/jiangli/repo/tutorials/cmake-tutorial/chapter1/04/build cmake --build . Scanning dependencies of target hello-world [ 50%] Building CXX object CMakeFiles/hello-world.dir/hello_world.cpp.o [100%] Linking CXX executable bin/hello-world [100%] Built target hello-world ","date":"2024-01-12","objectID":"/posts/cmake_note_2/:0:9","tags":["CMake"],"title":"CMake 笔记 | [2] 多目录多文件的CMake构建方式","uri":"/posts/cmake_note_2/"},{"categories":["C++"],"content":"十、编译和连接动态库 动态库的编写需要区分平台，在GNU/Linux平台上，动态库的编写和调用与静态库没有差别，但是在Windows平台上动态库的编写和调用需要做一定的修改。 10.1 GNU/Linux平台上动态库的编译和链接 在GNU/Linux上生成动态库的方法和静态库生成的方法类似，其目录结构等都与静态库相同，只有在使用add_library命令时，参数STATIC改为SHARE即可,相关项目结构和CMakeLists.txt如下。 . ├── message-module │ ├── include │ │ └── message.h │ ├── src │ │ └── message.cpp │ └── CMakeLists.txt ├── hello_world.cpp └── CMakeLists.txt 源码地址: https://github.com/jianye0428/CMake_Learning_Notes/tree/main/Note_2/message_dynamic_lib 配置动态库的CMakeLists.txt: cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(hello-world LANGUAGES CXX) # 设置可执行文件到bin文件夹下 set(EXECUTE_FILE ${CMAKE_BINARY_DIR}/bin) set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${EXECUTE_FILE}) # 设置动态库到lib文件夹下 set(LIB_FILE ${CMAKE_BINARY_DIR}/lib) set(CMAKE_LIBRARY_OUTPUT_DIRECTORY ${LIB_FILE}) include_directories( ${CMAKE_SOURCE_DIR}/message-module/include ) add_subdirectory( ${CMAKE_SOURCE_DIR}/message-module ) add_executable( ${PROJECT_NAME} ${CMAKE_SOURCE_DIR}/hello_world.cpp ) target_link_libraries( ${PROJECT_NAME} test_message ) 这里我们设置动态库存放的路径的宏为CMAKE_LIBRARY_OUTPUT_DIRECTORY。 源码地址： 10.2 GNU/Linux只链接三方库（动态库） 在GNU/Linux上链接动态库的方法和静态库生成的方法类似，其目录结构等都与静态库相同，只有在使用add_library命令时，参数STATIC改为SHARE即可,相关项目结构和CMakeLists.txt如下。 目录结构: . ├── third-party │ ├── include │ │ └── message.h │ └── lib │ └── libtest_message.so ├── hello_world.cpp └── CMakeLists.txt 源码地址: https://github.com/jianye0428/CMake_Learning_Notes/tree/main/Note_2/message_dynamic_lib_third_party CMakeLists.txt文件: cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(hello-world LANGUAGES CXX) # 设置可执行文件到bin文件夹下 set(EXECUTE_FILE ${CMAKE_BINARY_DIR}/bin) set(CMAKE_RUNTIME_OUTPUT_DIRECTORY ${EXECUTE_FILE}) set(TEST_MESSAGE ${CMAKE_SOURCE_DIR}/third-party/lib/libtest_message.so) include_directories( ${CMAKE_SOURCE_DIR}/third-party/include ) add_executable( ${PROJECT_NAME} ${CMAKE_SOURCE_DIR}/hello_world.cpp ) target_link_libraries( ${PROJECT_NAME} ${TEST_MESSAGE} ) 10.3 Windows平台上动态库的编译和链接 注意：通过实践发现，Windows中CMAKE_LIBRARY_OUTPUT_DIRECTORY没有作用。在Windows中生成的动态库将会自动生成到可执行文件所在的目录。 前面我们说Windows平台中生成动态库的源码和静态库是不同的，在Windows平台中，在导出动态库时除了会生成.dll动态库之外，还会生成一个.lib文件。注意，这个.lib文件和静态库的.lib文件是不同的，它里面并不保存代码生成的二进制文件，而是所有需要导出符号的符号表。因此这个.lib文件和编译生成的静态库.lib相比较而言会小的多。 符号表是需要我们在编写源码时进行指定的，如果我们将一个符号导出（符号可以指类、函数等各种类型）,需要在其前面加上__declspec(dllexport)标志，这样这个符号的相关信息就会在导出的.lib中的符号表中了。 如果在源码中没有任何的__declspec(dllexport),依然可以成功的编译出动态库，但是并不会生成保存符号表的.lib文件。 class __declspec(dllexport) Message { public: Message() {} void Print(const std::string \u0026message); }; 除了导出符号标识符__declspec(dllexport)以外，作为用户使用动态库的时候，对应的头文件的符号还需要__declspec(dllimport)标识符来表示这个符号是从动态库导入的。 class __declspec(dllimport) Message { public: Message() {} void Print(const std::string \u0026message); }; 一般，一个库文件我们并不想对导入和导出分别写两个几乎同样的头文件，因此可以使用宏定义来代替直接使用__declspec(dllexport)和__declspec(dllimport)关键字。 #ifndef MESSAGE_HEADER_H_ #define MESSAGE_HEADER_H_ #ifdef SHARED_LIB_EXPORT #define SHARED_LIB_EXPORT __declspec(dllexport) #else #define SHARED_LIB_EXPORT __declspec(dllimport) #endif class SHARED_LIB_EXPORT Message { public: Message() {} void Print(const std::string \u0026message); }; #endif // ! MESSAGE_HEADER_H_ 这样我们只需要在编译（导出）这个库的时候，给编译器添加SHARED_LIB_EXPORT宏。而在使用该库的时候什么都不定义即可。 我们通常编写一个头文件来专门管理SHARED_LIB_EXPORT宏定义。为了使得我们的代码在Linux中平台以及静态库的情况，我们的头文件编写如下： #ifndef EXPORT_LIB_HEADER_H_ #define EXPORT_LIB_HEADER_H_ #ifdef SHARED_LIB_BUILD #ifdef _WIN32 #ifdef SHARED_LIB_EXPORT #define SHARED_LIB_API __declspec(dllexport) #else #define SHARED_LIB_API __declspec(dllimport) #endif // SHARED_LIB_EXPORT #else #define SHARED_LIB_API #endif // _WIN32 #else #define SHARED_LIB_API #endif // SHARED_LIB_BUILD #endif // ! EXPORT_LIB_HEADER_H_ 我们除了使用SHARED_LIB_API宏定义来判断是否导出为动态库以外，还使用了编译器自带的_WIN32宏来判断是实在windows平台上以及使用。SHARED_LIB_BUILD来判断是否正在编译动态库。 有了这个头文件之后，我们只需要在导出符号表的头文件中包含该头文件，就可以使用SHARED_LIB_API宏定义了。 除此之外，上述的头文件可以通过CMake提供的GenerateExportHeader命令自动生成。关于该命令的使用在后续介绍中会详细的进行探索。 项目结构: . ├── message-module │ ├── include │ │ └── message.h │ ├── src │ │ └── message.cpp │ └── CMakeLists.txt ├── hello_world.cpp └── CMak","date":"2024-01-12","objectID":"/posts/cmake_note_2/:0:10","tags":["CMake"],"title":"CMake 笔记 | [2] 多目录多文件的CMake构建方式","uri":"/posts/cmake_note_2/"},{"categories":["C++"],"content":"十一、补充 在window上使用vs生成可执行文件和执行install命令。 首先，我们首先新建一个build目录，并进入该目录。 mkdir build cd build 然后使用cmake进行构建项目。 cmake .. 然后在build目录下可以看到sln文件，使用vs打开。 构建所有: 在vs中的解决方案资源管理器中右键ALL_BUILD，然后点击生成 编译生成hello-world进程，右键hello-world,然后点击生成。如果我们使用CMake在一个项目中生成了多个进程，我们在测试某一个进程时，在对应的进程上右键设为启动项目即可。 执行install安装命令: 在INSTALL上右键，然后点击生成即可。注意：只有当我们的CMake中有install命令时，VS中才会出现INTALL选项。 ","date":"2024-01-12","objectID":"/posts/cmake_note_2/:0:11","tags":["CMake"],"title":"CMake 笔记 | [2] 多目录多文件的CMake构建方式","uri":"/posts/cmake_note_2/"},{"categories":["C++"],"content":"一、项目结构 .. ├── CMakeLists.txt └── hello_world.cpp 0 directories, 2 files 本项目只包含了一个源文件hello_world.cpp和一个CMake文件。 源码地址: https://github.com/jianye0428/CMake_Learning_Notes/tree/main/Note_1/hello-world 注意 注意: CMake文件的名字只能是CMakeLists.txt，当然如果使用include命令（后续会讲到），可以以任何名字进行命名，只要以.cmake结尾即可。 ","date":"2024-01-12","objectID":"/posts/cmake_note_1/:0:1","tags":["CMake"],"title":"CMake 笔记 | [1] 单个源文件编译为可执行文件","uri":"/posts/cmake_note_1/"},{"categories":["C++"],"content":"二、CPP源文件 #include \u003ccstdlib\u003e #include \u003ciostream\u003e #include \u003cstring\u003e std::string SayHello(); int main() { std::cout \u003c\u003c SayHello() \u003c\u003c std::endl; return 0; } std::string SayHello() { return std::string(\"Hello, CMake World!\"); } ","date":"2024-01-12","objectID":"/posts/cmake_note_1/:0:2","tags":["CMake"],"title":"CMake 笔记 | [1] 单个源文件编译为可执行文件","uri":"/posts/cmake_note_1/"},{"categories":["C++"],"content":"三、CMake文件 cmake_minimum_required(VERSION 3.10 FATAL_ERROR) project(hello-world LANGUAGES CXX) add_executable( ${PROJECT_NAME} hello_world.cpp } cmake_minimum_required(VERSION 3.10 FATAL_ERROR) 设置CMake所需的最低版本的最低版本，如果使用的CMake版本低于该版本，则会发出致命错误。 今后，笔记中CMake的版本要求都为3.10。vscode中CMake Tool插件使用debug功能要求CMake版本不低于3.10。如果使用的系统ubuntu 16.04的话，需要升级CMake版本，windows请自行安装高于3.10版本的CMake。 project(hello-world LANGUAGES CXX) 声明了项目的名称和支持的编程语言，且该命令必须生命在cmake_minimum_required之后。一旦声明了项目的名称后，可以使用宏定义${PROJECT_NAME}进行调用。 在CMake中，C++是默认的编程语言。不过在实际编写代码过程中，仍建议使用LANGUAGES选项在project命令中显示地声明项目的语言。 add_executable(${PROJECT_NAME} hello_world.cpp} CMake创建一个新可执行文件，其名字为${PROJECT_NAME}（也可以使用其他任意的名字）。这个可执行文件是通过编译和链接源文件hello_world.cpp生成的。 CMake将为编译器使用默认设置，并自动生成工具。 ","date":"2024-01-12","objectID":"/posts/cmake_note_1/:0:3","tags":["CMake"],"title":"CMake 笔记 | [1] 单个源文件编译为可执行文件","uri":"/posts/cmake_note_1/"},{"categories":["C++"],"content":"四、操作 在工程文件夹下，执行如下操作: mkdir build cd build cmake .. 输出结果: -- The CXX compiler identification is GNU 9.4.0 -- Check for working CXX compiler: /usr/bin/c++ -- Check for working CXX compiler: /usr/bin/c++ -- works -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Detecting CXX compile features -- Detecting CXX compile features - done -- Configuring done -- Generating done -- Build files have been written to: /home/jiangli/repo/tutorials/cmake-tutorial/chapter1/01/build CMake的构建方式有两种: 源内构建和源外构建。源内构建即在CMakeLists.txt同级目录中进行构建，构建出来的CMake文件将在该目录中，这通常是不推荐的，因为这会混合源代码和项目的目录树。源外构建的构建方式，就是笔记的构建方式，往后我们都采用源外构建的方式。 CMake是一个构建系统生成器。将描述构建系统，如Unix Makefile、Ninja、sln等应当如何操作才能编译代码。然后，CMake为所选的构建系统生成相应的指令。默认情况下，在GNU/Linux和macOS系统上，CMake使用Unix Makefile生成器。Windows上，sln是默认的生成器。 GNU/Linux上，CMake默认生成 Makefile来构建项目: Makefile: make将运行指令来构建项目。 CMakefile: 包含临时文件的目录，CMake用于检测操作系统、编译器等。此外，根据所选的生成器，它还包含特定的文件。 cmake_install.cmake: 处理安装规则的CMake脚本，在项目安装时使用（命令为执行为make后执行make install）。 CMakeCache.txt: 如文件名所示，CMake缓存。CMake在重新运行配置时使用这个文件。 ","date":"2024-01-12","objectID":"/posts/cmake_note_1/:0:4","tags":["CMake"],"title":"CMake 笔记 | [1] 单个源文件编译为可执行文件","uri":"/posts/cmake_note_1/"},{"categories":null,"content":"Here Is Articles Pilot C++ C++基础 💡 C++基础(一) 💡 C++基础(二) C++新特性[11\\14\\17] Cmake CMake简介 CMake常用命令 cmake_cookbook professional cmake C++ Concurrency In Action Effective Modern C++ Effective C++ part one part two Effective STL 软件安装 各种程序安装教程 Vim安装教程 Zsh安装教程 Math 曲线拟合 GIT Git常用命令查询 Git核心知识点总结 数据结构与算法 排序算法 二叉树 背包问题 ","date":"2024-01-06","objectID":"/pilot/:0:0","tags":null,"title":"文章导航","uri":"/pilot/"},{"categories":["AutonomousDriving"],"content":"一、简介 Argoverse数据集是由Argo AI、卡内基梅隆大学、佐治亚理工学院发布的用于支持自动驾驶汽车3D Tracking和Motion Forecasting研究的数据集。 数据集包括: 带标注的传感器数据集: 含1000个多模态数据序列，包括来自七个环视摄像机和两个双目摄像机的高分辨率图像，以及激光雷达点云和6自由度地图配准位姿。序列包含26个目标类别的三维长方体标注，所有这些标注都是充分采样的，以支持训练和三维感知模型的评估。 激光雷达数据集: 包含20,000个未标记的激光雷达点云序列和地图配准位姿。该数据集是有史以来最大的激光雷达传感器数据集合，支持自监督学习和新兴的点云预测任务。 运动预测数据集: 包含250,000个场景，挖掘每个场景中自车与其他参与者之间有趣和具有挑战性的交互。模型的任务是预测每个场景中scored actors的未来运动，并提供跟踪历史，捕捉目标的位置、航向、速度和类别。 在所有三个数据集中，每个场景都包含自己的高精地图，带有3D车道和人行横道几何形状–来自六个不同城市的数据。所有数据集都是在CC BY-NC-SA 4.0许可下发布的。 ","date":"2024-01-05","objectID":"/posts/argoverse2/:1:0","tags":["dataset","prediction"],"title":"Argoverse 2 数据集","uri":"/posts/argoverse2/"},{"categories":["AutonomousDriving"],"content":"二、Argoverse 2 Datasets ","date":"2024-01-05","objectID":"/posts/argoverse2/:2:0","tags":["dataset","prediction"],"title":"Argoverse 2 数据集","uri":"/posts/argoverse2/"},{"categories":["AutonomousDriving"],"content":"2.1 Sensor Dataset 传感器数据集 Argoverse 2传感器数据集是Argoverse 1 3D跟踪数据集的后续。AV2更大，有1000个场景，高于Argoverse 1中的113个，但每个AV2场景也更丰富–AV2中有23倍的非车辆、非行人长方体。作者手工选择Argoverse 2传感器数据集中的30s组成场景，以包含拥挤的场景，其中包含未被表示的对象、值得注意的天气和有趣的行为，如插队和乱穿马路。每个场景的持续时间为15秒。表1将AV2传感器数据集与自动驾驶数据集进行了比较。图1、2和3显示了AV2的场景在标注范围、目标多样性、目标密度和场景动态性方面如何优于其他数据集。 与本文最相似的传感器数据集是非常有影响力的nuScenes[4]–这两个数据集都有1000个场景和高清地图，尽管Argoverse在拥有地面高度地图方面是独一无二的。nuScenes包含毫米波雷达数据，而AV2包含双目图像。nuScenes有一个很大的分类学–23个目标类别，其中10个有适合训练和评估（evaluation）的数据。本文的数据集包含30个目标类别，其中26个被很好地采样，足以用于训练和评估。nuScenes横跨两个城市，而本文的提出的数据集横跨六个城市。 传感器套件。 激光雷达扫描收集在10赫兹，以及20 fps图像从7个摄像头定位，以提供一个完整的全景视野。此外，还提供了全局坐标系下的摄像机内参、外参和6自由度 ego-vehicle 姿态。激光雷达回波由两个32波束激光雷达捕获，激光雷达在同一方向以10赫兹旋转，但在方向上相隔180°。摄像机触发与两个激光雷达同步，导致20赫兹的帧率。七个全局快门摄像机与激光雷达同步，使它们的曝光集中在激光雷达上，扫描它们的视野。在附录中，本文提供了一个示意图，说明了汽车传感器套件及其坐标框架。 激光雷达同步精度。 在AV2中，本文改进了摄像机和激光雷达的同步比Argoverse 1明显。本文的同步精度在[-1.39,1.39]ms，与Waymo开放数据集[-6,7]ms[45]相比较。 标注。 AV2传感器数据集包含本文30个类分类法中的对象的10 Hz 3D长方体标注（图1）。长方体的轨道标识符随着时间的推移对于相同的目标实例是一致的。如果对象在“感兴趣区域”(ROI)内–在映射的“可驾驶”区域的五米内，则对其进行标注。 隐私。 为了保护隐私，所有的脸和车牌，无论是在车辆内还是在可驾驶区域外，都被广泛模糊。 传感器数据集分割。 本文随机地将数据集划分为700、150和150个场景的训练、验证和测试拆分。 ","date":"2024-01-05","objectID":"/posts/argoverse2/:2:1","tags":["dataset","prediction"],"title":"Argoverse 2 数据集","uri":"/posts/argoverse2/"},{"categories":["AutonomousDriving"],"content":"2.2 Lidar Dataset 激光雷达数据集 Argoverse 2 激光雷达数据集旨在支持激光雷达域中的自监督学习研究以及点云预测[48,49]。由于激光雷达数据比完整的传感器套件更紧凑，本文可以包括两倍长度的场景（30秒而不是15秒），和更多 （20,000 而不是 1,000），相当于大约40倍的驾驶小时，空间预算是5倍。AV2激光雷达数据集的挖掘标准与预测数据集（第3.3.2节）相同，以确保每个场景都是有趣的。虽然激光雷达数据集没有3D目标标注，但每个场景都带有一张高清地图，其中包含关于场景的丰富的3D信息。 本文的数据集是迄今为止最大的此类集合，有20,000个30秒序列。唯一一个类似的数据集，是同时发布的ONCE[36]，包含1M激光雷达帧，而本文的是6M激光雷达帧。本文的数据集以10 Hz采样，而不是像ONCE[36]中那样以2 Hz采样，使本文的数据集更适合于点云预测或自监督任务，这些任务点云随时间的演变是重要的。 激光雷达数据集分割。 本文用分别为16,000个、2000个和2000个场景的train、validation和test拆分 随机划分数据集。 ","date":"2024-01-05","objectID":"/posts/argoverse2/:2:2","tags":["dataset","prediction"],"title":"Argoverse 2 数据集","uri":"/posts/argoverse2/"},{"categories":["AutonomousDriving"],"content":"2.3 Motion Forecasting Dataset 运动预测数据集 运动预测解决了预测局部环境中动态行为者的未来状态（或占用图）的问题。自动驾驶相关行为者的一些例子包括：车辆（停车和移动）、行人、骑自行车的人、滑板车和宠物。由预测系统生成的预测未来被用作运动规划的主要输入，运动规划根据这种预测条件进行轨迹选择。生成这些预测提出了一个复杂的、多模态的问题，涉及许多不同的、部分观察的和社会交互的主体。然而，通过利用观察到的ground truth futures 来“自我标记”数据的能力，运动预测成为机器学习应用的理想领域（ideal domain）。 在Argoverse 1成功的基础上，Argoverse 2运动预测数据集提供了从自动驾驶车队收集的一组更新的预测场景。下面列举的设计决策总结了本文从内部研究/开发中吸取的集体经验教训，以及来自3个竞赛中近260个独特团队提交的2700多份submissions的反馈意见[43]: 运动预测是长尾域中的一个安全关键系统。 因此，本文的数据集偏向于包含不同类型focal agent的不同和有趣的场景（见第3.3.2节）。本文的目标是鼓励开发确保尾部事件（tail events）期间安全的方法，而不是优化“轻松里程”上的预期性能。 There is a “Goldilocks zone” of task difficulty. Argoverse1测试集的性能已经开始稳定下来，如附录的图10所示。Argoverse 2的设计是为了增加预测的难度，在未来几年刺激富有成效的重点研究。这些变化旨在激励在扩展预测范围(3s→6s)上表现良好的方法，处理多种类型的动态对象(1→5)，并确保长尾场景的安全性。未来的Argoverse releases可能会通过减少观测窗口和增加预测层位来继续增加问题的难度。 可用性很重要。 Argoverse 1受益于一个庞大而活跃的研究社区–在很大程度上是由于设置和使用的简单性。因此，本文注意确保现有的Argoverse模型可以很容易地移植到Argoverse 2上运行。特别是，本文优先考虑对地图元素的直观访问，鼓励使用车道图作为强优先级的方法。为了提高训练和泛化，所有姿态也被插值和重新采样在精确的10赫兹（Argoverse 1是近似的）。新的数据集包括更少，但更长和更复杂的场景；这确保总的数据集大小保持足够大，可以训练复杂的模型，但足够小，可以方便地访问。 ","date":"2024-01-05","objectID":"/posts/argoverse2/:2:3","tags":["dataset","prediction"],"title":"Argoverse 2 数据集","uri":"/posts/argoverse2/"},{"categories":["AutonomousDriving"],"content":"2.4 HD Maps 高精地图 上述三个数据集中的每个场景共享相同的HD地图表示。每个场景都带有自己的本地地图区域，类似于Waymo Open Motion[12]数据集。这与最初的Argoverse数据集不同，在最初的数据集中，所有场景都被本地化到两张城市地图上–一张是匹兹堡的，一张是迈阿密的。在附录中，本文提供了例子。每个场景映射的优点包括更高效的查询和处理映射更改的能力。在本文的数据集中，一个特定的十字路口可能会被观察多次，在此期间车道、人行横道甚至地面高度都可能发生变化。 车道图。 HD地图的核心特征是车道图，由图组成，其中是单个车道段。在附录中，本文列举并定义了本文为每个车道段提供的属性。与Argoverse 1不同，本文提供了实际的3D车道边界，而不仅仅是中心线。但是，本文的API提供了代码，可以在任何期望的采样分辨率下快速推断中心线。折线被量化到1cm分辨率。本文的表示比nuScenes更丰富，它只在2D中提供车道几何，而不是3D。 可驾驶区域。 而不是像在Argoverse 1中所做的那样，以光栅化格式提供可驾驶区域分割，本文以矢量格式释放它，即作为3D多边形。这提供了多种优势，主要是在压缩方面，允许本文为成千上万的场景存储单独的地图，然而光栅格式仍然很容易衍生。将多边形顶点量化到1cm分辨率。 **地表高度。**只有传感器数据集包括密集的地表高度图（尽管其他数据集仍然有关于折线的稀疏的三维高度信息）。地地面高度为可行驶区域边界5m等值线内的区域提供，本文将其定义为感兴趣区域(ROI)[6]。本文这样做是因为对于建筑物内部和建筑密集的城市街区内部，地面车辆由于遮挡而无法观察的区域，地表高度的概念定义不清(ill-defined)。光栅栅格被量化到30cm分辨率，比Argoverse 1中的1m分辨率更高。 **本地地图的面积。**每个场景的局部地图都包括在ego-vehicle轨迹的l2范数中100米膨胀范围内找到的所有实体。 ","date":"2024-01-05","objectID":"/posts/argoverse2/:2:4","tags":["dataset","prediction"],"title":"Argoverse 2 数据集","uri":"/posts/argoverse2/"},{"categories":["AutonomousDriving"],"content":"三、Argoverse 2 API 简介 轨迹预测常用的有场景数据ArgoverseScenario和地图ArgoverseStaticMap 轨迹序列读取的API为scenario_serialization 可视化的API为visualize_scenario argoverse2和argoverse1不一样的地方是，每一段轨迹序列（Scenario）内有自己的json地图文件（虽然说都是同一幅HD map，但是对应HD map中的不同的位置），而argoverse1是所有轨迹序列共享一个地图文件 # 存放轨迹序列的类 from av2.datasets.motion_forecasting.data_schema import ArgoverseScenario # 用于读取轨迹序列的API from av2.datasets.motion_forecasting import scenario_serialization # 用于可视化的API from av2.datasets.motion_forecasting.viz.scenario_visualization import visualize_scenario # 用于读取地图的API from av2.map.map_api import ArgoverseStaticMap ArgoverseScenario 每个scenario有11s长的序列，包含actor的历史轨迹集合，就是这里面的tracks，对于每一个scenario，提供了以下的顶层属性: scenario_id: 该scenario的特有ID timestamps_ns: 该scenario的所有时间戳 tracks: 该scenario的所有轨迹序列 focal_track_id: 该scenario的焦点agent(focal agent)的track ID city_name: 该scenario对应的城市名 每个track包含以下属性: track_id: 该track的特有ID object_states: 该轨迹序列对应的object在这11s内的有效观测的状态，以timestep表示时间步，一般来说最多有110步，因为采样频率为10Hz，一步对应0.1s object_type: 该轨迹序列对应的object的类型，如vehicle等 category: 给轨迹序列分配种类，用于给轨迹预测的数据质量提供参考，一般来说，有四种：SCORED_TRACK，UNSCORED_TRACK，FOCAL_TRACK，TRACK_FRAGMENT。其中FOCAL_TRACK和SCORED_TRACK数据质量较好，UNSCORED_TRACK用于当作上下文输入，数据质量一般，而TRACK_FRAGMENT的时间长度不定，数据质量较差 TRACK_FRAGMENT: Lower quality track that may only contain a few timestamps of observations. 在数据中以整数0表示 UNSCORED_TRACK: Unscored track used for contextual input. 在数据中以整数1表示 SCORED_TRACK: High-quality tracks relevant to the AV - scored in the multi-agent prediction challenge. 在数据中以整数2表示 FOCAL_TRACK: The primary track of interest in a given scenario - scored in the single-agent prediction challenge. 在数据中以整数3表示 每个object_states包含以下属性，对应某一actor在某一时间点的所有信息： observed: Boolean 指示这个object state是否在该scenario的观测区间内(observed segment) timestep: 时间步，范围是[0, num_scenario_timesteps) Time step corresponding to this object state [0, num_scenario_timesteps). position: (x, y) Coordinates of center of object bounding box. object bounding box的xy坐标 heading: Heading associated with object bounding box (in radians, defined w.r.t the map coordinate frame). object bounding box的航向角，单位是弧度，是在地图坐标系下的 velocity: (x, y) Instantaneous velocity associated with the object (in m/s). object的xy方向的速度 每个track有以下10种label: Dynamic VEHICLE PEDESTRIAN MOTORCYCLIST CYCLIST BUS Static STATIC BACKGROUND CONSTRUCTION RIDERLESS_BICYCLE UNKNOWN ArgoverseStaticMap Vector Map: Lane Graph and Lane Segments The core feature of the HD map is the lane graph, consisting of a graph G = (V, E), where V are individual lane segments. Argoverse2 提供了3D的道路边界线，而不是仅仅有centerlines，也提供了快速获取特定采样分辨率的centerlines的API，在release中多边形的分辨率被设置为1cm 地图以json文件的形式提供, 可以通过以下方式读取： from av2.map.map_api import ArgoverseStaticMap log_map_dirpath = Path(\"av2\") / \"00a6ffc1-6ce9-3bc3-a060-6006e9893a1a\" / \"map\" avm = ArgoverseStaticMap.from_map_dir(log_map_dirpath=log_map_dirpath, build_raster=False) LaneSegment LaneSegment中包含以下属性： id: unique identifier for this lane segment (guaranteed to be unique only within this local map). 该lane segment的特有ID（仅在局部地图中保证是特有的ID） is_intersection: boolean value representing whether or not this lane segment lies within an intersection. boolean value，用来表示该lane segment是否位于一个路口内 lane_type: designation of which vehicle types may legally utilize this lane for travel. 表示车道线类型 right_lane_boundary: 3d polyline representing the right lane boundary. 3D线条，表示右车道边界线 left_lane_boundary: 3d polyline representing the left lane boundary. 3D线条，表示左车道边界线 right_mark_type: type of painted marking found along the right lane boundary . 右车道边界线的线型 left_mark_type: type of painted marking found along the left lane boundary. 左车道边界线的线型 predecessors: unique identifiers of lane segments that are predecessors of this object. 该lane segment的前继lane segment的unique ID successors: unique identifiers of lane segments that represent successor of this object. Note: this list will be empty if no successors exist. 该lane segment的后继lane segment的unique ID right_neighbor_id: unique identifier of the lane segment representing this object’s right neighbor. 该","date":"2024-01-05","objectID":"/posts/argoverse2/:3:0","tags":["dataset","prediction"],"title":"Argoverse 2 数据集","uri":"/posts/argoverse2/"},{"categories":["AutonomousDriving"],"content":"四、Argoverse 2 数据提取 raw_dir 文件夹内包含.parquet和.json文件，其中文件组织形式为log_map_archive_{$scenario_name}.parquet和scenario_{$scenario_name}.json，分别代表障碍物时序信息和地图信息。 设置原始数据路径: raw_dir = \"/home/yejian/yejian_personal/QCNet/train/\" raw_file_name = \"ffffe3df-8d26-42c3-9e7a-59de044736a0\" 读取障碍物信息和地图信息 parquet_file = os.path.join(raw_dir, raw_file_name, f'scenario_{raw_file_name}.parquet') print(f\"parquet_file: {parquet_file}\") # 障碍物信息 map_file = os.path.join(raw_dir, raw_file_name, f'log_map_archive_{raw_file_name}.json') print(f\"map_file: {map_file}\")# 地图信息 df = pd.read_from_parquet(parquet_file) map_file = read_json_file(map_file) 查看障碍物信息文件内容 df.columns.values.tolist() ['observed', 'track_id', 'object_type', 'object_category', 'timestep', 'position_x', 'position_y', 'heading', 'velocity_x', 'velocity_y', 'scenario_id', 'start_timestamp', 'end_timestamp', 'num_timestamps', 'focal_track_id', 'city'] ","date":"2024-01-05","objectID":"/posts/argoverse2/:4:0","tags":["dataset","prediction"],"title":"Argoverse 2 数据集","uri":"/posts/argoverse2/"},{"categories":["AutonomousDriving"],"content":"Reference [1]. https://blog.csdn.net/Yong_Qi2015/article/details/128731798 [2]. https://blog.csdn.net/m0_56423263/article/details/134593815 ","date":"2024-01-05","objectID":"/posts/argoverse2/:5:0","tags":["dataset","prediction"],"title":"Argoverse 2 数据集","uri":"/posts/argoverse2/"},{"categories":["DL"],"content":"一、传统的BP网络和CNN网络 BP网络和CNN网络没有时间维，和传统的机器学习算法理解起来相差无几，CNN在处理彩色图像的3通道时，也可以理解为叠加多层，图形的三维矩阵当做空间的切片即可理解，写代码的时候照着图形一层层叠加即可。如下图是一个普通的BP网络和CNN网络。 BP Network CNN Network 图中的隐含层、卷积层、池化层、全连接层等，都是实际存在的，一层层前后叠加，在空间上很好理解，因此在写代码的时候，基本就是看图写代码，比如用keras就是: # 示例代码，没有实际意义 model = Sequential() model.add(Conv2D(32, (3, 3), activation='relu')) # 添加卷积层 model.add(MaxPooling2D(pool_size=(2, 2))) # 添加池化层 model.add(Dropout(0.25)) # 添加dropout层 model.add(Conv2D(32, (3, 3), activation='relu')) # 添加卷积层 model.add(MaxPooling2D(pool_size=(2, 2))) # 添加池化层 model.add(Dropout(0.25)) # 添加dropout层 .... # 添加其他卷积操作 model.add(Flatten()) # 拉平三维数组为2维数组 model.add(Dense(256, activation='relu')) 添加普通的全连接层 model.add(Dropout(0.5)) model.add(Dense(10, activation='softmax')) .... # 训练网络 ","date":"2023-12-28","objectID":"/posts/lstm/:1:0","tags":["temporal sequences process"],"title":"长短期记忆网络 -- LSTM","uri":"/posts/lstm/"},{"categories":["DL"],"content":"二、LSTM网络 RNN网络的机构图如下图所示: 2.1 RNN Architecture Overview RNN 面临的问题:短时记忆和梯度消失/梯度爆炸 短时记忆 问题描述：RNN在处理长序列时，由于信息的传递是通过隐藏状态进行的，随着时间的推移，较早时间步的信息可能会在传递到后面的时间步时逐渐消失或被覆盖。 影响：这导致RNN难以捕捉和利用序列中的长期依赖关系，从而限制了其在处理复杂任务时的性能。 梯度消失/梯度爆炸 问题描述：在RNN的反向传播过程中，梯度会随着时间步的推移而逐渐消失（变得非常小）或爆炸（变得非常大）。 影响：梯度消失使得RNN在训练时难以学习到长期依赖关系，因为较早时间步的梯度信息在反向传播到初始层时几乎为零。梯度爆炸则可能导致训练过程不稳定，权重更新过大，甚至导致数值溢出。 LSTM解决问题: 大脑和LSTM在处理信息时都选择性地保留重要信息，忽略不相关细节，并据此进行后续处理。这种机制使它们能够高效地处理和输出关键信息，解决了RNN（递归神经网络）在处理长序列时面临的问题。 大脑记忆机制 大脑记忆机制：当浏览评论时，大脑倾向于记住重要的关键词。无关紧要的词汇和内容容易被忽略。回忆时，大脑提取并表达主要观点，忽略细节。 LSTM门控机制：LSTM通过输入门、遗忘门和输出门选择性地保留或忘记信息，使用保留的相关信息来进行预测，类似于大脑提取并表达主要观点。 图2.1是RNN循环神经网络经典的结构图，LSTM只是对隐含层节点A做了改进，整体结构不变，因此本文讨论的也是这个结构的可视化问题。 中间的A节点隐含层，左边是表示只有一层隐含层的LSTM网络，所谓LSTM循环神经网络就是在时间轴上的循环利用，在时间轴上展开后得到右图。 上图右边，我们看Xt表示序列，下标t是时间轴，所以，A的数量表示的是时间轴的长度，是同一个神经元在不同时刻的状态(Ht)，不是隐含层神经元个数。 我们知道，LSTM网络在训练时会使用上一时刻的信息，加上本次时刻的输入信息来共同训练。 举个简单的例子: 在第一天我生病了(初始状态H0)，然后吃药(利用输入信息X1训练网络)，第二天好转但是没有完全好(H1)，再吃药(X2),病情得到好转(H2),如此循环往复知道病情好转。因此，输入Xt是吃药，时间轴T是吃多天的药，隐含层状态是病情状况。因此我还是我，只是不同状态的我。 实际上，LSTM的网络是这样的: LSTM Network 上面的图表示包含2个隐含层的LSTM网络，在T=1时刻看，它是一个普通的BP网络，在T=2时刻看也是一个普通的BP网络，只是沿时间轴展开后，T=1训练的隐含层信息H,C会被传递到下一个时刻T=2，如下图所示。上图中向右的五个常常的箭头，所指的也是隐含层状态在时间轴上的传递。 LSTM Architecture Overview 注意，图中H表示隐藏层状态，C是遗忘门，后面会讲解它们的维度。 ","date":"2023-12-28","objectID":"/posts/lstm/:2:0","tags":["temporal sequences process"],"title":"长短期记忆网络 -- LSTM","uri":"/posts/lstm/"},{"categories":["DL"],"content":"2.1 LSTM的原理 RNN工作原理:第一个词被转换成了机器可读的向量，然后 RNN 逐个处理向量序列。 RNN 工作原理 隐藏状态的传递 过程描述：在处理序列数据时，RNN将前一时间步的隐藏状态传递给下一个时间步。 作用：隐藏状态充当了神经网络的“记忆”，它包含了网络之前所见过的数据的相关信息。 重要性：这种传递机制使得RNN能够捕捉序列中的时序依赖关系。 将隐藏状态传递给下一个时间步 隐藏状态的计算 细胞结构：RNN的一个细胞接收当前时间步的输入和前一时间步的隐藏状态。 组合方式：当前输入和先前隐藏状态被组合成一个向量，这个向量融合了当前和先前的信息。 激活函数：组合后的向量经过一个tanh激活函数的处理，输出新的隐藏状态。这个新的隐藏状态既包含了当前输入的信息，也包含了之前所有输入的历史信息。 BP Network **输出:**新的隐藏状态被输出，并被传递给下一个时间步，继续参与序列的处理过程。 RNN的细胞结构和运算 LSTM工作原理： LSTM的细胞结构和运算 输入门: 作用：决定哪些新信息应该被添加到记忆单元中。 组成：输入门由一个sigmoid激活函数和一个tanh激活函数组成。sigmoid函数决定哪些信息是重要的，而tanh函数则生成新的候选信息。 运算：输入门的输出与候选信息相乘，得到的结果将在记忆单元更新时被考虑。 输入门（sigmoid激活函数 + tanh激活函数） 遗忘门: 作用：决定哪些旧信息应该从记忆单元中遗忘或移除。 组成：遗忘门仅由一个sigmoid激活函数组成。 sigmoid激活函数（区间0～1） 运算：sigmoid函数的输出直接与记忆单元的当前状态相乘，用于决定哪些信息应该被保留，哪些应该被遗忘。输出值越接近1的信息将被保留，而输出值越接近0的信息将被遗忘。 遗忘门（sigmoid激活函数） 输出门: 作用：决定记忆单元中的哪些信息应该被输出到当前时间步的隐藏状态中。 组成：输出门同样由一个sigmoid激活函数和一个tanh激活函数组成。sigmoid函数决定哪些信息应该被输出，而tanh函数则处理记忆单元的状态以准备输出。 运算：sigmoid函数的输出与经过tanh函数处理的记忆单元状态相乘，得到的结果即为当前时间步的隐藏状态。 输出门(sigmoid激活函数 + tanh激活函数) ","date":"2023-12-28","objectID":"/posts/lstm/:2:1","tags":["temporal sequences process"],"title":"长短期记忆网络 -- LSTM","uri":"/posts/lstm/"},{"categories":["DL"],"content":"三、LSTM的输入结构 为了更好理解LSTM结构，还必须理解LSTM的数据输入情况。仿照3通道图像的样子，再加上时间轴后的多样本的多特征的不同时刻的数据立方体如下图所示: Input Structure of LSTM Network 右边的图是我们常见模型的输入，比如XGBOOST，lightGBM，决策树等模型，输入的数据格式都是这种(NF)的矩阵，而左边是加上时间轴后的数据立方体，也就是时间轴上的切片，它的维度是(NT*F),第一维度是样本数，第二维度是时间，第三维度是特征数，如下图所示: 天气数据立方体 这样的数据立方体很多，比如天气预报数据，把样本理解成城市，时间轴是日期，特征是天气相关的降雨风速PM2.5等，这个数据立方体就很好理解了。在NLP里面，一句话会被embedding成一个矩阵，词与词的顺序是时间轴T，索引多个句子的embedding三维矩阵如下图所示: NLP Embedding Matrix ","date":"2023-12-28","objectID":"/posts/lstm/:3:0","tags":["temporal sequences process"],"title":"长短期记忆网络 -- LSTM","uri":"/posts/lstm/"},{"categories":["DL"],"content":"四、Pytorch中的LSTM ","date":"2023-12-28","objectID":"/posts/lstm/:4:0","tags":["temporal sequences process"],"title":"长短期记忆网络 -- LSTM","uri":"/posts/lstm/"},{"categories":["DL"],"content":"4.1 Pytorch中定义的LSTM模型 pytorch中定义的LSTM模型的参数如下 class torch.nn.LSTM(*args, **kwargs) 参数有: - input_size: x的特征维度 - hidden_size: 隐藏层的特征维度 - num_layers: lstm隐层的层数，默认为1 - bias: False则bihbih=0和bhhbhh=0. 默认为True - batch_first: True则输入输出的数据格式为 (batch, seq, feature) - dropout: 除最后一层，每一层的输出都进行dropout，默认为: 0 - bidirectional: True则为双向lstm默认为False 结合前面的图形，我们一个个看。 (1)input_size: x的特征维度，就是数据立方体中的F，在NLP中就是一个词被embedding后的向量长度，如下图所示: LSTM Feature Matrix (2)hidden_size: 隐藏层的特征维度(隐藏层神经元个数)，如下图所示，我们有两个隐含层，每个隐藏层的特征维度都是5。注意，非双向LSTM的输出维度等于隐藏层的特征维度。 隐藏层特征维度 (3)num_layers: lstm隐层的层数，上面的图我们定义了2个隐藏层。 (4)batch_first: 用于定义输入输出维度，后面再讲。 (5)bidirectional: 是否是双向循环神经网络，如下图是一个双向循环神经网络，因此在使用双向LSTM的时候我需要特别注意，正向传播的时候有(Ht, Ct),反向传播也有(Ht’, Ct’),前面我们说了非双向LSTM的输出维度等于隐藏层的特征维度，而双向LSTM的输出维度是隐含层特征数2，而且H,C的维度是时间轴长度2。 Bidirectional RNN ","date":"2023-12-28","objectID":"/posts/lstm/:4:1","tags":["temporal sequences process"],"title":"长短期记忆网络 -- LSTM","uri":"/posts/lstm/"},{"categories":["DL"],"content":"4.2 喂给LSTM的数据格式 pytorch中LSTM的输入数据格式默认如下: input(seq_len, batch, input_size) 参数有: - seq_len: 序列长度，在NLP中就是句子长度，一般都会用pad_sequence补齐长度 - batch: 每次喂给网络的数据条数，在NLP中就是一次喂给网络多少个句子 - input_size: 特征维度，和前面定义网络结构的input_size一致。 前面也说到，如果LSTM的参数 batch_first=True，则要求输入的格式是: input(batch, seq_len, input_size) 刚好调换前面两个参数的位置。其实这是比较好理解的数据形式，下面以NLP中的embedding向量说明如何构造LSTM的输入。 之前我们的embedding矩阵如下图: Embedding Matrix 如果把batch放在第一位，则三维矩阵的形式如下: Batch First 其转换过程如下图所示: 将三维矩阵转换成二维形式 看懂了吗，这就是输入数据的格式，是不是很简单。 LSTM的另外两个输入是 h0 和 c0，可以理解成网络的初始化参数，用随机数生成即可。 h0(num_layers * num_directions, batch, hidden_size) c0(num_layers * num_directions, batch, hidden_size) 参数: - num_layers: 隐藏层数 - num_directions: 如果是单向循环网络，则num_directions=1，双向则num_directions=2 - batch: 输入数据的batch - hidden_size: 隐藏层神经元个数 注意，如果我们定义的input格式是: input(batch, seq_len, input_size) 则H和C的格式也是要变的: h0(batc，num_layers * num_directions, h, hidden_size) c0(batc，num_layers * num_directions, h, hidden_size) ","date":"2023-12-28","objectID":"/posts/lstm/:4:2","tags":["temporal sequences process"],"title":"长短期记忆网络 -- LSTM","uri":"/posts/lstm/"},{"categories":["DL"],"content":"4.3 LSTM的output格式 LSTM的输出是一个tuple，如下: output,(ht, ct) = net(input) - output: 最后一个状态的隐藏层的神经元输出 - ht: 最后一个状态的隐含层的状态值 - ct: 最后一个状态的隐含层的遗忘门值 output的默认维度是: output(seq_len, batch, hidden_size * num_directions) ht(num_layers * num_directions, batch, hidden_size) ct(num_layers * num_directions, batch, hidden_size) 和input的情况类似，如果我们前面定义的input格式是: input(batch, seq_len, input_size) 则ht和ct的格式也是要变的: ht(batc，num_layers * num_directions, h, hidden_size) ct(batc，num_layers * num_directions, h, hidden_size) 说了这么多，我们回过头来看看ht和ct在哪里，请看下图: LSTM Network output在哪里？请看下图: 输出层 ","date":"2023-12-28","objectID":"/posts/lstm/:4:3","tags":["temporal sequences process"],"title":"长短期记忆网络 -- LSTM","uri":"/posts/lstm/"},{"categories":["DL"],"content":"五、LSTM和其他网络组合 还记得吗，output的维度等于隐藏层神经元的个数，即hidden_size，在一些时间序列的预测中，会在output后，接上一个全连接层，全连接层的输入维度等于LSTM的hidden_size，之后的网络处理就和BP网络相同了，如下图: 在LSTM网络后接上全连接层 用pytorch实现上面的结构: import torch from torch import nn class RegLSTM(nn.Module): def __init__(self): super(RegLSTM, self).__init__() # 定义LSTM self.rnn = nn.LSTM(input_size, hidden_size, hidden_num_layers) # 定义回归层网络，输入的特征维度等于LSTM的输出，输出维度为1 self.reg = nn.Sequential( nn.Linear(hidden_size, 1) ) def forward(self, x): x, (ht,ct) = self.rnn(x) seq_len, batch_size, hidden_size= x.shape x = y.view(-1, hidden_size) x = self.reg(x) x = x.view(seq_len, batch_size, -1) return x 当然，有些模型则是将输出当做另一个LSTM的输入，或者使用隐藏层ht,ct的信息进行建模，不一而足。 好了，以上就是我对LSTM的一些学习心得，看完记得关注点赞。 REF: [[1]. 漂亮，LSTM模型结构的可视化](https: //mp.weixin.qq.com/s?__biz=MzU1OTYzNjg5OQ==\u0026mid=2247545117\u0026idx=1\u0026sn=670ba155d94b229d39c5bf0bf20239d5\u0026chksm=fc1639d1cb61b0c72434a00454b2af8f9022e7ac3030a4186cda22ef5594ef5994620dc5fd52\u0026mpshare=1\u0026scene=1\u0026srcid=0617kfSozC3sKY1lRjYg1f0u\u0026sharer_shareinfo=6833fdea9df7fee2c423a9474c0928be\u0026sharer_shareinfo_first=6833fdea9df7fee2c423a9474c0928be#rd) [2].https: //zhuanlan.zhihu.com/p/94757947 [3].https: //zhuanlan.zhihu.com/p/59862381 [4].https: //zhuanlan.zhihu.com/p/36455374 [5].https: //www.zhihu.com/question/41949741/answer/318771336 [6].https: //blog.csdn.net/android_ruben/article/details/80206792 to be added: [7].https: //www.analyticsvidhya.com/blog/2021/01/understanding-architecture-of-lstm/ [8]. 神经网络算法 - 一文搞懂LSTM(长短期记忆网络) ","date":"2023-12-28","objectID":"/posts/lstm/:5:0","tags":["temporal sequences process"],"title":"长短期记忆网络 -- LSTM","uri":"/posts/lstm/"},{"categories":["C++"],"content":"线程间的工作划分 为了提高线程利用率并最小化开销，必须决定要使用的线程数量，并为每个线程合理分配任务 ","date":"2023-11-28","objectID":"/posts/ch08_designing_concurrent_code/:1:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [8] | CH08 Designing Concurrent Code","uri":"/posts/ch08_designing_concurrent_code/"},{"categories":["C++"],"content":"开始处理之前的线程间数据划分 简单算法最容易并行化，比如要并行化 std::for_each，把元素划分到不同的线程上执行即可。如何划分才能获取最优性能，取决于数据结构的细节，这里用一个最简单的划分为例，每 N 个元素分配给一个线程，每个线程不需要与其他线程通信，直到独立完成各自的处理任务 如果使用过 MPI 或 OpenMP，会很熟悉这个结构，即把一个任务划分成一系列并行任务，工作线程独立完成任务，最后 reduce 合并结果。不过对 for_each 来说，最后的 reduce 实际不需要执行操作，但对其他需要合并结果的并行算法来说，最后一步很重要 尽管这个技术很强大，但不是万能的，有时数据不能灵活划分，只有在处理数据时划分才明显，最能明显体现这点的就是递归算法，比如快速排序 ","date":"2023-11-28","objectID":"/posts/ch08_designing_concurrent_code/:1:1","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [8] | CH08 Designing Concurrent Code","uri":"/posts/ch08_designing_concurrent_code/"},{"categories":["C++"],"content":"递归划分数据 要并行化快速排序，无法直接划分数据，因为只有处理之后才知道某一项应该置于基数的哪一边。因此，很容易想到的是使用递归，其中的递归调用完全独立，各自处理不同的元素集，十分适合并发执行 如果数据集很大，为每个递归生成新线程就会生成大量线程，如果线程过多就会影响性能。因此需要严格控制线程数，不过这个问题可以直接抛给 std::async #include \u003calgorithm\u003e #include \u003cfuture\u003e #include \u003clist\u003e template \u003ctypename T\u003e std::list\u003cT\u003e parallel_quick_sort(std::list\u003cT\u003e v) { if (v.empty()) { return {}; } std::list\u003cT\u003e res; res.splice(res.begin(), v, v.begin()); auto it = std::partition(v.begin(), v.end(), [\u0026](const T\u0026 x) { return x \u003c res.front(); }); std::list\u003cT\u003e low; low.splice(low.end(), v, v.begin(), it); std::future\u003cstd::list\u003cT\u003e\u003e l( std::async(\u0026parallel_quick_sort\u003cT\u003e, std::move(low))); auto r(parallel_quick_sort(std::move(v))); res.splice(res.end(), r); res.splice(res.begin(), l.get()); return res; } 也可以通过 hardware_concurrency 得知硬件可支持的线程数，再自己管理线程数。下面是一个使用 stack 存储已排序数据的并行快速排序 #include \u003calgorithm\u003e #include \u003catomic\u003e #include \u003cfuture\u003e #include \u003clist\u003e #include \u003cmemory\u003e #include \u003cthread\u003e #include \u003cvector\u003e #include \"concurrent_stack.hpp\" template \u003ctypename T\u003e class Sorter { public: Sorter() : max_thread_count(std::thread::hardware_concurrency() - 1) {} ~Sorter() { end_of_data = true; for (auto\u0026 x : threads) { if (x.joinable()) { x.join(); } } } std::list\u003cT\u003e do_sort(std::list\u003cT\u003e\u0026 v) { if (v.empty()) { return {}; } std::list\u003cT\u003e res; res.splice(res.begin(), v, v.begin()); auto it = std::partition(v.begin(), v.end(), [\u0026](const T\u0026 x) { return x \u003c res.front(); }); ChunkToSort low; low.data.splice(low.data.end(), v, v.begin(), it); std::future\u003cstd::list\u003cT\u003e\u003e l = low.promise.get_future(); chunks.push(std::move(low)); if (threads.size() \u003c max_thread_count) { threads.emplace_back(\u0026Sorter\u003cT\u003e::sort_thread, this); } auto r{do_sort(v)}; res.splice(res.end(), r); while (l.wait_for(std::chrono::seconds(0)) != std::future_status::ready) { try_sort_chunk(); } res.splice(res.begin(), l.get()); return res; } private: struct ChunkToSort { std::list\u003cT\u003e data; std::promise\u003cstd::list\u003cT\u003e\u003e promise; }; private: void sort_chunk(const std::shared_ptr\u003cChunkToSort\u003e\u0026 chunk) { chunk-\u003epromise.set_value(do_sort(chunk-\u003edata)); } void try_sort_chunk() { std::shared_ptr\u003cChunkToSort\u003e chunk = chunks.pop(); if (chunk) { sort_chunk(chunk); } } void sort_thread() { while (!end_of_data) { try_sort_chunk(); std::this_thread::yield(); } } private: ConcurrentStack\u003cChunkToSort\u003e chunks; std::vector\u003cstd::thread\u003e threads; const std::size_t max_thread_count; std::atomic\u003cbool\u003e end_of_data = false; }; template \u003ctypename T\u003e std::list\u003cT\u003e parallel_quick_sort(std::list\u003cT\u003e v) { if (v.empty()) { return {}; } return Sorter\u003cT\u003e{}.do_sort(v); } ","date":"2023-11-28","objectID":"/posts/ch08_designing_concurrent_code/:1:2","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [8] | CH08 Designing Concurrent Code","uri":"/posts/ch08_designing_concurrent_code/"},{"categories":["C++"],"content":"基于任务划分 如果数据动态生成或来自外部输入，上述划分方式都不适用，此时应该基于任务而非基于数据来划分。一种基于任务的划分方式是让线程针对性处理任务，对同一数据进行不同的操作，而不是都做相同的工作。这样线程是独立的，每个线程只需要负责完成总任务的某一部分。这就是 SoC（separation of concerns，关注点分离）设计原则 单线程中，如果有多个任务需要执行，只能依次执行任务，任务需要保存完成状态，并周期性地返回控制流给主循环。如果循环中添加了很多任务，就会导致程序变慢，对于一个用户发起的事件可能很久才会响应 这就是使用线程的原因，如果每个任务分离在线程上，保存状态和返回控制流给主循环这些事都抛给了操作系统，此时只需要关注任务本身，并且任务还可以并发运行，这样用户也能及时得到响应 但现实不一定这么顺利。如果任务都是独立的，线程之间不需要通信，那就很简单了。然而，这些后台运行的任务经常需要处理用户请求，因此就需要在完成时更新用户接口，以通知用户。此外，用户还可能想取消任务，这样就需要用户接口发送一条通知后台任务终止的消息。这些情况都要求周全的考虑和设计，以及合适的同步 虽然如此，但关注点仍然是分离的。用户接口线程线程仍处理用户接口，只是可能在被其他线程请求时要更新接口。同理，后台任务线程仍然关注自己的任务，只是允许被其他线程请求终止 多线程不是一定要 SoC，比如线程间有很多共享数据，或者需要互相等待。对于这样存在过多通信的线程，应该先找出通信的原因，如果所有的通信都关联同一个问题，合并成一个单线程来处理可能更好一些 基于任务划分不要求完全隔离，如果多个输入数据集合适用相同顺序的操作，可以把这个操作序列划分为多个子阶段来分配给每个线程，当一个线程完成操作后就把数据放进队列，供下一线程使用，这就是 pipeline。这也是另一种划分数据的方式，适用于操作开始前输入数据不是完全已知的情况，比如来自网络的数据或者扫描文件系统以识别要处理的文件 对于序列中耗时的操作，pipeline 就能提高响应速度。比如，如果操作包含 4 步，每步 5 秒，处理完一个数据就要 20秒，如果有 4 个包含整个操作的线程，虽然每 20 秒能处理 4 个数据，但每个数据仍要 20 秒处理。使用 pipeline，每个线程只处理一步，对于第一个数据需要 20 秒处理，之后处理每个数据都只需要 5 秒 // 非 pipeline：每 20 秒 4 个数据（每个数据仍要 20 秒） 线程A：-1- -1- -1- -1- -5- -5- -5- -5- 线程B：-2- -2- -2- -2- -6- -6- -6- -6- 线程C：-3- -3- -3- -3- -7- -7- -7- -7- 线程D：-4- -4- -4- -4- -8- -8- -8- -8- // pipeline：第一个数据 20 秒，之后每个 5 秒 线程A：-1- -2- -3- -4- -5- -6- -7- -8- 线程B：--- -1- -2- -3- -4- -5- -6- -7- 线程C：--- --- -1- -2- -3- -4- -5- -6- 线程D：--- --- --- -1- -2- -3- -4- -5- 以视频解码为例，每 4 秒 120 帧，第一秒达到 120 帧，卡顿 3 秒后播放下一个 120 帧，这样远不如稳定的每秒 30 帧 ","date":"2023-11-28","objectID":"/posts/ch08_designing_concurrent_code/:1:3","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [8] | CH08 Designing Concurrent Code","uri":"/posts/ch08_designing_concurrent_code/"},{"categories":["C++"],"content":"影响并发代码性能的因素 ","date":"2023-11-28","objectID":"/posts/ch08_designing_concurrent_code/:2:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [8] | CH08 Designing Concurrent Code","uri":"/posts/ch08_designing_concurrent_code/"},{"categories":["C++"],"content":"处理器数量 处理器数量是影响多线程程序性能的首要因素，一个并发程序在不同环境下的表现迥异，而开发者的环境和用户很可能不同，比如开发环境是双核或四核系统，但用户是任意多核或单核，因此必须谨慎考虑可能的影响并对其测试 单个 16 核、4 个四核、16 个单核是近似的，都能并发运行 16 个线程，要利用好这点，开发的程序必须至少用上 16 个线程。如果少于 16 个，就会浪费处理器性能（不考虑系统运行其他程序的情况），另一方面，如果多于 16 个，就会让处理器浪费时间在切换线程上，这种情况就是 oversubscription 使用 hardware_concurrency 可以获取硬件支持的线程数，但要注意它不会考虑已运行在系统上的其他线程，如果多个线程都用它给出的线程数，就会导致巨大的 oversubscription。这个问题可以抛给 std::async，它会适度处理并安排所有调用。这个问题也能用线程池解决 随着处理器数量增加，另一个影响性能的问题也随之而来，即多处理器尝试访问同一数据 ","date":"2023-11-28","objectID":"/posts/ch08_designing_concurrent_code/:2:1","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [8] | CH08 Designing Concurrent Code","uri":"/posts/ch08_designing_concurrent_code/"},{"categories":["C++"],"content":"乒乓缓存（cache ping-pong） 如果两个线程在不同处理器上并发执行，读取同一数据一般不会带来问题，数据将拷贝到它们的 cache，处理器可以同时处理。但如果一个线程修改数据，这个修改传给其他核的 cache 就需要花费时间，从而可能导致第二个处理器停止以等待改变传到内存硬件（取决于两个线程上的操作和这个操作使用的内存序）。从 CPU 指令的角度来看，这个操作慢到惊人，等价于数百个独立指令（具体取决于硬件的物理结构） std::atomic\u003cstd::size_t\u003e n(0); void f() { // 任何线程都能调用 // 每次n自增，处理器都要确保 cache 中的拷贝是最新的 // 修改值后再告知其他处理器 // fetch_add 是读改写操作，每次都要检索最新值 // 如果另一线程在另一处理器运行此代码 // n 的数据就要在两个处理器之间来回传递 // 这样 n 增加时两个处理器的 cache 才能有最新值 while (n.fetch_add(1, std::memory_order_relaxed) \u003c 100000000) { task(); // 如果很快完成或者有很多处理器运行此代码，处理器就要互相等待 // 一个处理器在更新值，另一个更新值的处理器就要等待 // 直到第一个更新完成并把改变传过来 // 这种情况就是 high contention // 反之处理器很少要互相等待的情况就是 low contention // 在类似这样的循环中，n 的数据在 cache 之间来回传递 // 这就是 cache ping-pong } } 如果处理器由于等待 cache 转移而挂起，就只能干等着而不能做任何工作。上例的情况可能不常见，但有一些和上例没有本质区别的常见情况，比如在循环中获取 mutex std::mutex m; void f() { while (true) { std::lock_guard\u003cstd::mutex\u003e l(m); // 现在需要来回传递的是 m if (done_processing(data)) { break; } } } 要避免乒乓缓存，就要尽量减少多个线程对同一内存位置的竞争。但即使一个特定内存位置只能被一个线程访问，仍然可能存在乒乓缓存，原因就是伪共享 ","date":"2023-11-28","objectID":"/posts/ch08_designing_concurrent_code/:2:2","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [8] | CH08 Designing Concurrent Code","uri":"/posts/ch08_designing_concurrent_code/"},{"categories":["C++"],"content":"伪共享（false sharing） 处理器 cache 不是独立的，而是以 cache line 作为最小单位，一般为 32 或 64 字节，因此小数据可能位于同一 cache line。有时这是好事，如果一个线程访问的数据都位于同一 cache line，性能会比分散在多个 cache line 好。但如果 cache line 中的数据项不相关，需要被多个线程访问，就会导致性能问题 假如有一个 int 数组，一组线程频繁访问和更新其中的数据。通常 int 大小不超过一个 cache line，因此一个 cache line 可以存储多个数据项，此时即使每个线程只访问自己需要的数据，cache 硬件也会造成乒乓缓存。比如访问 0 号数据的线程要更新数据，cache line 的所有权就要被转移到运行这个线程的处理器 数据可能不共享，但 cache line 是共享的，这就是伪共享。这个问题的解决方案是，构造数据，让能被同一线程访问的数据项位于内存中的临近位置，让能被不同线程访问的数据在内存中相距很远。C++17 提供了 std::hardware_destructive_interference_size 来指定当前编译目标伪共享的最大连续字节数，只要数据间隔大于此字节数就可以避免伪共享 ","date":"2023-11-28","objectID":"/posts/ch08_designing_concurrent_code/:2:3","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [8] | CH08 Designing Concurrent Code","uri":"/posts/ch08_designing_concurrent_code/"},{"categories":["C++"],"content":"data proximity 造成伪共享的原因是两个线程访问的数据过于接近，相应的，直接影响单线程的性能则是数据布局。如果单线程访问的数据分散在内存中，就类似位于不同的 cache line，如果在内存中十分靠近，就类似位于同一 cache line。如果数据是分散的，就需要从内存加载更多的 cache line 到处理器 cache，这就会增加内存访问延迟并降低性能 如果数据是分散的，一个包含当前线程数据的 cache line很可能会包含非当前线程的数据，极端情况下，cache 中将包含很多不需要的数据，这就会浪费宝贵的 cache 空间并增加处理器 cache miss 的概率，导致必须从主存获取数据。而这个数据可能曾在 cache 中保留过，但为了给其他数据让出空间必须从 cache 中移除 这看上去只对单线程很重要，但其实对多线程也很重要，原因在于任务切换（task switching）。如果线程数超过核数，就一定会有核要运行多线程，这就增加了 cache 的压力，因为为了避免伪共享必须确保不同的线程访问不同的 cache line，当处理器切换线程时，如果数据分散，很可能会重新载入 cache line。C++17 提供了std::hardware_constructive_interference_size 来指定保证同一 cache line 的最大连续字节数，如果数据尺寸小于此字节数就能降低 cache miss 的几率 如果线程数超过处理器核数，操作系统可能会调度线程，在某个时间片上给一个核，在下一个时间片上给另一个核，这就要求把第一个核的 cache 传给第二个，从而增加了时间开销。虽然操作系统一般会尽量避免这点，但如果发生了就会对性能造成影响 当大量线程准备运行而非等待时，就会经常出现任务切换问题，这种处理器在任务切换上花费大量时间的情况就是 oversubscription ","date":"2023-11-28","objectID":"/posts/ch08_designing_concurrent_code/:2:4","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [8] | CH08 Designing Concurrent Code","uri":"/posts/ch08_designing_concurrent_code/"},{"categories":["C++"],"content":"oversubscription 超额申请 线程经常花费时间来等待额外的 I/O、mutex 阻塞、条件变量，因此使用超过处理器核数的线程以确保没有闲置的处理器是合理的。但如果有过多的额外线程，操作系统确保为每个线程公平分配时间片，就会有沉重的任务切换负担。当一个任务重复而无限制地生成新线程，就会导致 oversubscription 如果生成的线程数过多的原因是数据划分，可以限制工作线程的数量。如果 oversubscription 是因为自然的工作划分，除了选择其他的划分方式，没有什么直接改善的办法。但选择合适的划分需要对目标平台有更多的了解，只有性能不可接受，而改变划分方式可以明显提高性能时才值得这样做 影响多线程代码性能的因素非常多，以上只是一些有明显可见影响的主要因素，比如乒乓缓存的开销在两个单核处理器和一个双核处理器上区别很大，即使两者有相同的CPU类型和时钟速度 ","date":"2023-11-28","objectID":"/posts/ch08_designing_concurrent_code/:2:5","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [8] | CH08 Designing Concurrent Code","uri":"/posts/ch08_designing_concurrent_code/"},{"categories":["C++"],"content":"适用多线程性能的数据结构 如果有两个上千行列的矩阵相乘，现在要用多线程来优化计算。一般非稀疏矩阵可以用一个大的一维数组表示，矩阵的每行在数组中连续排列。这个计算需要三个数组，其中一个存储计算结果。为了优化性能，就要仔细考虑数据访问模式，尤其是向结果数组的写入 划分方式有很多，如果行列数超过处理器数，每个线程可以计算结果的某些行或列，或者一个子矩阵 访问相邻元素可以减少对 cache 的使用，以及降低伪共享的概率。如果让线程计算结果的某列，就需要依次访问左矩阵的行（最终读取整个左矩阵），并读取右矩阵某列。矩阵保存于一维数组，行是相邻的，但列不是，因此写入结果时，其他线程可能访问同一行的其他元素。为了避免伪共享，需要让每行元素所占的空间正好是 cache line 的数量 如果让线程计算结果的某行，就需要读取左矩阵的某行，并依次读取右矩阵的列（最终读取整个右矩阵）。此时线程按行写入结果，由于一维数组里矩阵行是连续存储的，这个连续内存块不用被其他线程访问，比起上面按列写入结果是一个改进，伪共享只可能发生于一个结果块的最后几个元素与下一个块的前几个元素 如果划分为子矩阵，可以看成先按列划分再按行划分，因此它和按列划分一样存在伪共享的可能。如果可以避免这个可能，这个划分就有一个明显的好处，即不需要读取整个源矩阵，因此计算子矩阵比计算行好一些。当然，如果性能非常重要，必须针对目标架构 profile 各种选项并检索相关领域的文献 对于其他数据结构的数据访问模式进行优化时，需要考虑的本质上与优化对数组的访问类似 调整线程间的数据分布，让同一线程访问的数据尽量紧密 尽量减少线程所需的数据量 依据 std::hardware_destructive_interference_size，确保不同线程访问的数据距离足够远，以避免伪共享 这些用在其他数据结构上并不容易，比如二叉树很难在子树以外的任何单元中再分割，并且二叉树的节点一般是动态分配的，从而会分布在堆的不同位置上。数据位于堆的不同位置不是什么特别的问题，但确实意味着处理器需要在 cache 中保存更多东西。不过这是有益的，如果多个线程要遍历树，就都需要访问树节点，如果树节点只包含保存数据的指针，处理器只要在需要时从内存加载数据，如果数据被需要它的线程修改了，这能避免节点数据本身和提供树结构的数据之间的伪共享带来的性能问题 用 mutex 保护数据也有类似问题。假如有一个类，它包含一个 mutex 和一些被保护的数据，如果 mutex 和数据在内存中很接近，这对获取 mutex 的线程是很理想的，为了修改 mutex，需要的数据可能已经跟着加载在处理器 cache 中了。但这也有一个缺点，如果其他线程尝试获取 mutex，就会需要访问那块内存 互斥锁的典型实现为，一个操作在 mutex 内存位置上以尝试获取 mutex 的读改写原子操作，如果 mutex 已锁定，就接着调用操作系统内核。这个读改写操作可能会导致，持有该 mutex 的线程的 cache 中保存的数据无效。这对于 mutex 不是问题，在 mutex 解锁之前线程不会接触 mutex，但如果 mutex 与数据共享同一 cache line，另一个线程尝试获取 mutex 时，持有 mutex 的线程就会受到性能影响 一个测试这种伪共享是否会带来影响的方法是，在能被并发访问的数据之间添加巨大的填充块。比如用如下方式测试 mutex 竞争问题 struct ProtectedData { std::mutex m; // 使用超过一个 cache line 字节数的填充即可 char padding[std::hardware_destructive_interference_size]; // 不支持 C++17 则可以 padding[65536]; Data data_to_protect; }; 用如下方式测试数组数据伪共享，如果性能提高了就说明伪共享影响了性能，并且可以保留填充或者用其他方式重排数据访问来消除伪共享 struct Data { data_item1 d1; data_item2 d2; char padding[std::hardware_destructive_interference_size]; }; Data some_array[256]; ","date":"2023-11-28","objectID":"/posts/ch08_designing_concurrent_code/:3:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [8] | CH08 Designing Concurrent Code","uri":"/posts/ch08_designing_concurrent_code/"},{"categories":["C++"],"content":"并发设计的其他注意事项 除了上述问题，设计并发代码时还需要考虑异常安全和可扩展性。如果代码不是异常安全的，就可能导致破坏不变量或 race condition，或由于一个操作抛出异常导致程序意外终止。可扩展性指的是，性能会随着处理器核数的提升而提升，如果处理器核数是之前的 100 倍，则最理想的情况下性能也应该之前的 100 倍 ","date":"2023-11-28","objectID":"/posts/ch08_designing_concurrent_code/:4:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [8] | CH08 Designing Concurrent Code","uri":"/posts/ch08_designing_concurrent_code/"},{"categories":["C++"],"content":"并发算法的异常安全 并行算法比串行算法更注重异常问题。在串行算法中，如果一个操作抛出异常，只需要保证吞下此异常以避免资源泄漏或破坏不变量，它可以愉快地允许异常传播给调用者处理。但在并行算法中，许多操作运行在不同的线程上，异常就不允许传播，因为它在错误的调用栈上。如果新线程上的函数存在异常，程序就会终止 回顾以前提到的并行版本的 std::accumulate，它就是非异常安全的，代码可能抛出异常的位置如下 #include \u003calgorithm\u003e #include \u003cfunctional\u003e #include \u003cnumeric\u003e #include \u003cthread\u003e #include \u003cvector\u003e template \u003ctypename Iterator, typename T\u003e struct accumulate_block { void operator()(Iterator first, Iterator last, T\u0026 res) { res = std::accumulate(first, last, res); // 可能抛异常 } }; template \u003ctypename Iterator, typename T\u003e T parallel_accumulate(Iterator first, Iterator last, T init) { std::size_t len = std::distance(first, last); // 此时没做任何事，抛异常无影响 if (!len) { return init; } std::size_t min_per_thread = 25; std::size_t max_threads = (len + min_per_thread - 1) / min_per_thread; std::size_t hardware_threads = std::thread::hardware_concurrency(); std::size_t num_threads = std::min(hardware_threads != 0 ? hardware_threads : 2, max_threads); std::size_t block_size = len / num_threads; std::vector\u003cT\u003e res(num_threads); // 仍未做任何事，抛异常无影响 std::vector\u003cstd::thread\u003e threads(num_threads - 1); // 同上 Iterator block_start = first; // 同上 for (std::size_t i = 0; i \u003c num_threads - 1; ++i) { Iterator block_end = block_start; // 同上 std::advance(block_end, block_size); // 下面创建 std::thread，抛异常就导致析构对象，并调用 std::terminate // 终止程序 threads[i] = std::thread(accumulate_block\u003cIterator, T\u003e{}, block_start, block_end, std::ref(res[i])); block_start = block_end; } // accumulate_block::operator() 调用的 std::accumulate // 可能抛异常，此时抛异常造成问题同上 accumulate_block\u003cIterator, T\u003e()(block_start, last, res[num_threads - 1]); std::for_each(threads.begin(), threads.end(), std::mem_fn(\u0026std::thread::join)); // 最后调用 std::accumulate 可能抛异常，但不引发大问题，因为所有线程已 join return std::accumulate(res.begin(), res.end(), init); } 上面已经分析了所有可能抛出异常的位置，下面来处理这些问题。新线程想做的是返回计算结果，但可能抛出异常导致 std::thread 析构，而析构没被 join 的 std::thread 将导致程序终止。解决这个问题很简单，结合使用 std::packaged_task 和 std::future，再把工作线程的异常抛出到主线程，让主线程处理即可 #include \u003calgorithm\u003e #include \u003cfunctional\u003e #include \u003cfuture\u003e #include \u003cnumeric\u003e #include \u003cthread\u003e #include \u003cvector\u003e template \u003ctypename Iterator, typename T\u003e struct accumulate_block { T operator()(Iterator first, Iterator last) { return std::accumulate(first, last, T{}); } }; template \u003ctypename Iterator, typename T\u003e T parallel_accumulate(Iterator first, Iterator last, T init) { std::size_t len = std::distance(first, last); if (!len) { return init; } std::size_t min_per_thread = 25; std::size_t max_threads = (len + min_per_thread - 1) / min_per_thread; std::size_t hardware_threads = std::thread::hardware_concurrency(); std::size_t num_threads = std::min(hardware_threads != 0 ? hardware_threads : 2, max_threads); std::size_t block_size = len / num_threads; std::vector\u003cstd::future\u003cT\u003e\u003e fts(num_threads - 1); // 改用 std::future 获取值 std::vector\u003cstd::thread\u003e threads(num_threads - 1); Iterator block_start = first; for (std::size_t i = 0; i \u003c num_threads - 1; ++i) { Iterator block_end = block_start; std::advance(block_end, block_size); // 用 std::packaged_task 替代直接创建 std::thread std::packaged_task\u003cT(Iterator, Iterator)\u003e pt( accumulate_block\u003cIterator, T\u003e{}); fts[i] = pt.get_future(); threads[i] = std::thread(std::move(pt), block_start, block_end); block_start = block_end; } T last_res = accumulate_block\u003cIterator, T\u003e{}(block_start, last); std::for_each(threads.begin(), threads.end(), std::mem_fn(\u0026std::thread::join)); T res = init; try { for (std::size_t i = 0; i \u003c num_threads - 1; ++i) { res += fts[i].get(); } res += last_res; } catch (...) { for (auto\u0026 x : threads) { if (x.joinable()) { x.join(); } } throw; } return res; } 不过 try-catch 很难看，并且导致了重复代码（正常控制流和 catch 块都对线程执行 join），因此可以用 RAII 来处理 #include \u003calgorithm\u003e #include \u003cfunctional\u003e #include \u003cfuture\u003e #include \u003cnumeric\u003e #include \u003cthread\u003e #include \u003cvector\u003e class threads_guard { public: explicit threads_guard(std::vector\u003cstd::thread\u003e\u0026 threads) : threads_(threads) {} ~threads_guard() { for (auto\u0026 x : threads_) { if (x.joinable()) { x.join(); } } } private: std::vector\u003cstd::threa","date":"2023-11-28","objectID":"/posts/ch08_designing_concurrent_code/:4:1","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [8] | CH08 Designing Concurrent Code","uri":"/posts/ch08_designing_concurrent_code/"},{"categories":["C++"],"content":"可扩展性与阿姆达尔定律（Amdahl’s law） 可扩展性代表了程序对处理器的利用率。单线程程序就是不可扩展的，因为处理器增加完全不能提高单线程程序的性能。对于多线程程序，线程经常需要花费时间等待（等待其他线程、获取 mutex、修改条件变量、完成 I/O 操作……），一种简化看待多线程程序的方式是将其分为串行和并行部分，由此可以得到如下公式，即阿姆达尔定律 S = 1 / (a + ( 1 - a ) / N) // a 为串行部分占比，N 为处理器倍数，S 为性能倍数 // 正常情况下 S \u003c 1 / a，最理想的情况是 a 为 0，S = N ","date":"2023-11-28","objectID":"/posts/ch08_designing_concurrent_code/:4:2","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [8] | CH08 Designing Concurrent Code","uri":"/posts/ch08_designing_concurrent_code/"},{"categories":["C++"],"content":"用多线程隐藏延迟（lantency） 如果在线程等待期间让系统做一些有用的事，就相当于隐藏了等待。如果只有和处理器单元一样多的线程，阻塞就意味着浪费 CPU 时间，因此可以利用这个时间去运行额外的线程。比如一个用 pipeline 划分工作的病毒扫描程序，一个线程检索文件系统并将文件放入队列，这是一个费时的 I/O 操作，因此同时可以让另一线程从队列获取文件名，加载并扫描文件 利用空闲的 CPU 时间也可能不需要运行额外的线程。比如，如果一个线程因为等待 I/O 操作而阻塞，使用异步 I/O 就是合理的，当 I/O 操作异步运行在后台时，线程就能做有用的工作。又比如，一个线程等待另一线程执行一个操作时，与其阻塞，不如自己执行操作（如lock-free queue）。更极端的例子是，如果线程等待一个未被任何线程启动的任务完成，这个线程可能自己执行此任务，或执行另一个未完成的任务 ","date":"2023-11-28","objectID":"/posts/ch08_designing_concurrent_code/:4:3","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [8] | CH08 Designing Concurrent Code","uri":"/posts/ch08_designing_concurrent_code/"},{"categories":["C++"],"content":"用并发提高响应度（responsiveness） 添加线程不一定是为了确保使用所有可用的处理器，有时是为了确保及时处理外部事件，以提高系统响应度。现代 GUI 框架大多是事件驱动的，为了确保处理所有事件和消息，GUI 程序一般包含一个如下循环 while (true) { event_data event = get_event(); if (event.type == quit) { break; } process(event); } 如果是单线程程序，就很难编写长期运行的任务。为了确保即使响应用户输入，就要以合理频率调用 get_event 和 process，这意味着任务要被周期性悬挂（suspend）并把控制流返回给事件循环，或者在代码中的一个适当点调用 get_event 和 process，二者任一都会复杂化任务实现 通过 SoC（separation of concerns）可以把很长的任务放在一个全新的线程上，而让 GUI 线程来处理事件，线程可以通过简单的机制进行通信，而不需要混入处理事件的代码，这样即使任务耗费很长时间，用户线程也总能及时响应事件 std::thread task_thread; std::atomic\u003cbool\u003e task_cancelled(false); void gui_thread() { while (true) { event_data event = get_event(); if (event.type == quit) { break; } process(event); } } void task() { while (!task_complete() \u0026\u0026 !task_cancelled) do_next_operation(); if (task_cancelled) { perform_cleanup(); } else { post_gui_event(task_complete); } } void process(const event_data\u0026 event) { switch (event.type) { case start_task: task_cancelled = false; task_thread = std::thread(task); break; case stop_task: task_cancelled = true; task_thread.join(); break; case task_complete: task_thread.join(); display_results(); break; default: ... } } ","date":"2023-11-28","objectID":"/posts/ch08_designing_concurrent_code/:4:4","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [8] | CH08 Designing Concurrent Code","uri":"/posts/ch08_designing_concurrent_code/"},{"categories":["C++"],"content":"实践 下面为标准库的三个算法实现并行版本，这些实现仅是为了阐述技术的运用，而不是最先进高效的实现。更先进的实现可以在学术文献或专业的多线程库（如 Intel 的 Threading Building Blocks） 中找到 ","date":"2023-11-28","objectID":"/posts/ch08_designing_concurrent_code/:5:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [8] | CH08 Designing Concurrent Code","uri":"/posts/ch08_designing_concurrent_code/"},{"categories":["C++"],"content":"并行版 std::for_each std::for_each 会按顺序依次作用于每个元素，而并行版不保证顺序，元素最好被并发处理，为此需要把元素划分给每个线程。实际上，并行版 std::for_each 与并行版 std::accumulate的实现思路基本一样：使用 hardware_concurrency 决定线程数，使用连续数据块避免伪共享，使用 std::packaged_task 和 std::future 在线程间传递异常 #include \u003calgorithm\u003e #include \u003cfuture\u003e #include \u003cthread\u003e #include \u003cvector\u003e template \u003ctypename Iterator, typename Func\u003e void parallel_for_each(Iterator first, Iterator last, Func f) { std::size_t len = std::distance(first, last); if (!len) { return; } std::size_t min_per_thread = 25; std::size_t max_threads = (len + min_per_thread - 1) / min_per_thread; std::size_t hardware_threads = std::thread::hardware_concurrency(); std::size_t num_threads = std::min(hardware_threads != 0 ? hardware_threads : 2, max_threads); std::size_t block_size = len / num_threads; std::vector\u003cstd::future\u003cvoid\u003e\u003e fts(num_threads - 1); std::vector\u003cstd::jthread\u003e threads(num_threads - 1); Iterator block_start = first; for (std::size_t i = 0; i \u003c num_threads - 1; ++i) { Iterator block_end = block_start; std::advance(block_end, block_size); std::packaged_task\u003cvoid(void)\u003e pt( [=] { std::for_each(block_start, block_end, f); }); fts[i] = pt.get_future(); threads[i] = std::jthread(std::move(pt)); block_start = block_end; } std::for_each(block_start, last, f); for (std::size_t i = 0; i \u003c num_threads - 1; ++i) { fts[i].get(); // 只是为了传递异常 } } 也可以使用 std::async 来简化实现 #include \u003calgorithm\u003e #include \u003cfuture\u003e template \u003ctypename Iterator, typename Func\u003e void parallel_for_each(Iterator first, Iterator last, Func f) { std::size_t len = std::distance(first, last); if (!len) { return; } std::size_t min_per_thread = 25; if (len \u003c 2 * min_per_thread) { std::for_each(first, last, f); return; } const Iterator mid_point = first + len / 2; std::future\u003cvoid\u003e l = std::async(\u0026parallel_for_each\u003cIterator, Func\u003e, first, mid_point, f); parallel_for_each(mid_point, last, f); l.get(); } ","date":"2023-11-28","objectID":"/posts/ch08_designing_concurrent_code/:5:1","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [8] | CH08 Designing Concurrent Code","uri":"/posts/ch08_designing_concurrent_code/"},{"categories":["C++"],"content":"并行版 std::find std::find 的不同之处在于，只要找到目标值就应该停止继续查找。在并行版本中，一个线程找到了值，不仅自身要停止继续查找，还应该通知其他线程停止，这点可以使用一个原子变量作为标记来实现 有两种可选方式来返回值和传播异常，一是使用 std::future 数组和 std::packaged_task 将返回值和异常交给主线程处理，二是使用 std::promise 直接设置最终结果。如果想在首个异常上终止（即使没有处理完所有元素）则使用 std::promise，如果想让其他线程继续搜索则使用 std::packaged_task 保存所有异常，并在没有找到目标值时重新抛出其中一个异常。这里选择使用行为更接近 std::find 的 std::promise #include \u003calgorithm\u003e #include \u003catomic\u003e #include \u003cfunctional\u003e #include \u003cfuture\u003e #include \u003cnumeric\u003e #include \u003cthread\u003e #include \u003cvector\u003e template \u003ctypename Iterator, typename T\u003e Iterator parallel_find(Iterator first, Iterator last, T match) { struct find_element { void operator()(Iterator begin, Iterator end, T match, std::promise\u003cIterator\u003e* res, std::atomic\u003cbool\u003e* done_flag) { try { for (; begin != end \u0026\u0026 !done_flag-\u003eload(); ++begin) { if (*begin == match) { res-\u003eset_value(begin); done_flag-\u003estore(true); return; } } } catch (...) { try { res-\u003eset_exception(std::current_exception()); done_flag-\u003estore(true); } catch (...) { } } } }; std::size_t len = std::distance(first, last); if (!len) { return last; } std::size_t min_per_thread = 25; std::size_t max_threads = (len + min_per_thread - 1) / min_per_thread; std::size_t hardware_threads = std::thread::hardware_concurrency(); std::size_t num_threads = std::min(hardware_threads != 0 ? hardware_threads : 2, max_threads); std::size_t block_size = len / num_threads; std::promise\u003cIterator\u003e res; std::atomic\u003cbool\u003e done_flag(false); { std::vector\u003cstd::jthread\u003e threads(num_threads - 1); Iterator block_start = first; for (auto\u0026 x : threads) { Iterator block_end = block_start; std::advance(block_end, block_size); x = std::jthread(find_element{}, block_start, block_end, match, \u0026res, \u0026done_flag); block_start = block_end; } find_element{}(block_start, last, match, \u0026res, \u0026done_flag); } if (!done_flag.load()) { return last; } return res.get_future().get(); } 也可以使用 std::async 实现 #include \u003catomic\u003e #include \u003cfuture\u003e template \u003ctypename Iterator, typename T\u003e Iterator parallel_find_impl(Iterator first, Iterator last, T match, std::atomic\u003cbool\u003e\u0026 done_flag) { try { std::size_t len = std::distance(first, last); std::size_t min_per_thread = 25; if (len \u003c (2 * min_per_thread)) { for (; first != last \u0026\u0026 !done_flag.load(); ++first) { if (*first == match) { done_flag = true; return first; } } return last; } const Iterator mid_point = first + len / 2; std::future\u003cIterator\u003e async_res = std::async(\u0026parallel_find_impl\u003cIterator, T\u003e, mid_point, last, match, std::ref(done_flag)); const Iterator direct_res = parallel_find_impl(first, mid_point, match, done_flag); return direct_res == mid_point ? async_res.get() : direct_res; } catch (...) { done_flag = true; throw; } } template \u003ctypename Iterator, typename T\u003e Iterator parallel_find(Iterator first, Iterator last, T match) { std::atomic\u003cbool\u003e done_flag(false); return parallel_find_impl(first, last, match, done_flag); } ","date":"2023-11-28","objectID":"/posts/ch08_designing_concurrent_code/:5:2","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [8] | CH08 Designing Concurrent Code","uri":"/posts/ch08_designing_concurrent_code/"},{"categories":["C++"],"content":"并行版 std::partial_sum std::partial_sum 会依次累加元素的和（默认是加，也可以是其他二元操作） #include \u003cnumeric\u003e #include \u003cvector\u003e int main() { std::vector\u003cint\u003e v{1, 2, 3, 4}; std::partial_sum( v.begin(), v.end(), std::ostream_iterator\u003cint\u003e(std::cout \u003c\u003c \"hi\"), // 输出到的迭代器起始位置 std::plus\u003cint\u003e{}); // 使用的二元运算符，不指定则默认累加 } // 输出 hi13610 其实现为 template \u003cclass InputIt, class OutputIt, class BinaryOperation\u003e OutputIt partial_sum(InputIt first, InputIt last, OutputIt d_first, BinaryOperation op) { if (first == last) { return d_first; } typename std::iterator_traits\u003cInputIt\u003e::value_type sum = *first; *d_first = sum; while (++first != last) { sum = op(std::move(sum), *first); *++d_first = sum; } return ++d_first; } 实现并行版本时，第一种划分方式就是传统的按块划分 1 1 1 1 1 1 1 1 1 // 输入 9 个 1 // 划分为三部分 1 1 1 1 1 1 1 1 1 // 得到三个部分的结果 1 2 3 1 2 3 1 2 3 // 将第一部分的尾元素（即 3）加到第二部分 1 2 3 4 5 6 1 2 3 // 再将第二部分的尾元素（即 6）加到第三部分 1 2 3 4 5 6 7 8 9 由于需要线程间同步，这个实现不容易简单地用 std::async 重写 #include \u003calgorithm\u003e #include \u003cfuture\u003e #include \u003cnumeric\u003e template \u003ctypename Iterator\u003e void parallel_partial_sum(Iterator first, Iterator last) { using value_type = typename Iterator::value_type; struct process_chunk { void operator()(Iterator begin, Iterator last, std::future\u003cvalue_type\u003e* previous_end_value, std::promise\u003cvalue_type\u003e* end_value) { try { Iterator end = last; ++end; std::partial_sum(begin, end, begin); if (previous_end_value) { // 不是第一个块 value_type addend = previous_end_value-\u003eget(); *last += addend; if (end_value) { end_value-\u003eset_value(*last); } std::for_each(begin, last, [addend](value_type\u0026 item) { item += addend; }); } else if (end_value) { end_value-\u003eset_value(*last); // 是第一个块则可以为下个块更新尾元素 } } catch (...) { // 如果抛出异常则存储到 // std::promise，异常会传播给下一个块（获取这个块的尾元素时） if (end_value) { end_value-\u003eset_exception(std::current_exception()); } else { throw; // 异常最终传给最后一个块，此时再抛出异常 } } } }; std::size_t len = std::distance(first, last); if (!len) { return; } std::size_t min_per_thread = 25; std::size_t max_threads = (len + min_per_thread - 1) / min_per_thread; std::size_t hardware_threads = std::thread::hardware_concurrency(); std::size_t num_threads = std::min(hardware_threads != 0 ? hardware_threads : 2, max_threads); std::size_t block_size = len / num_threads; // end_values 存储块内尾元素值 std::vector\u003cstd::promise\u003cvalue_type\u003e\u003e end_values(num_threads - 1); // prev_end_values 检索前一个块的尾元素 std::vector\u003cstd::future\u003cvalue_type\u003e\u003e prev_end_values; prev_end_values.reserve(num_threads - 1); Iterator block_start = first; std::vector\u003cstd::jthread\u003e threads(num_threads - 1); for (std::size_t i = 0; i \u003c num_threads - 1; ++i) { Iterator block_last = block_start; std::advance(block_last, block_size - 1); // 指向尾元素 threads[i] = std::jthread(process_chunk{}, block_start, block_last, i != 0 ? \u0026prev_end_values[i - 1] : nullptr, \u0026end_values[i]); block_start = block_last; ++block_start; prev_end_values.emplace_back(end_values[i].get_future()); } Iterator final_element = block_start; std::advance(final_element, std::distance(block_start, last) - 1); process_chunk{}(block_start, final_element, num_threads \u003e 1 ? \u0026prev_end_values.back() : nullptr, nullptr); } 如果处理器核数非常多，就没必要使用上面的方式了，因为还有并发度更高的方式，即隔一定距离计算，每轮计算完成，下一轮计算使用的距离变为之前的两倍。这种方式不再需要进一步同步，因为所有中间的结果都直接传给了下一个需要这些结果的处理器，但实际上很少有处理器可以在多条数据上同时执行同一条指令（即 SIMD），因此必须为通用情况设计代码，在每步操作上显式同步线程，比如使用 barrier 的同步机制，直到所有线程到达 barrier 时才能继续执行下一步 1 1 1 1 1 1 1 1 1 // 输入 9 个 1 // 先让距离为 1 的元素相加 1 2 2 2 2 2 2 2 2 // 再让距离为 2 的元素相加 1 2 3 4 4 4 4 4 4 // 再让距离为 4 的元素相加 1 2 3 4 5 6 7 8 8 // 再让距离为 8 的元素相加 1 2 3 4 5 6 7 8 9 ","date":"2023-11-28","objectID":"/posts/ch08_designing_concurrent_code/:5:3","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [8] | CH08 Designing Concurrent Code","uri":"/posts/ch08_designing_concurrent_code/"},{"categories":["C++"],"content":"并发相关的 bug 类型 与并发直接相关的 bug 一般可以分为两大类，一是非预期阻塞，二是 race condition 非预期阻塞包含以下几种情况 死锁（deadlock）：两个线程互相等待，导致均无法完成工作。最明显的情况是，如果负责用户界面的线程死锁，界面将失去响应。也有一些情况是，界面可以保持响应，但一些任务无法完成，比如搜索不返回结果，或者文档不被打印 活锁（livelock）：类似于死锁，不同的是线程不是阻塞等待，而是在忙碌于一个检查循环中，比如自旋锁。严重时，其表现的症状就和死锁一样，比如程序不进行，此外由于线程仍在运行，CPU 会处于高使用率状态。在不太严重的情况下，活锁最终会被操作系统的随机调度解决，但仍然会造成任务的长时间延迟，并且延迟期间 CPU 使用率很高 I/O 阻塞或其他外部输入：如果线程阻塞等待外部输入，就无法继续处理工作。因此如果一个线程执行的任务会被其他线程等待，就不要让这个线程等待外部输入 许多死锁和活锁都是由于 race condition 造成的，不过很大一部分 race condition 是良性的，比如要处理任务队列的下一个任务，决定用哪个工作线程去处理是无关紧要的。造成问题的 race condtion 包含以下几种情况 数据竞争（data race）：数据竞争是一种特定类型的 race condtion，由于对共享内存位置的不同步的并发访问，它将导致未定义行为。数据竞争通常发生于不正确地使用原子操作来同步线程，或者不加锁访问共享数据 被破坏的不变量（broken invariant）：它可以表现为空悬指针（其他线程可以删除被访问的数据）、随机内存损坏（由于局部更新导致线程读取的值不一致）、双重释放（比如两个线程弹出队列的同一个数据）等。不变量的破坏是暂时的，因为它是基于值的。如果不同线程上的操作要求以一个特定顺序执行，不正确的同步就会导致 race condition，有时就会违反这个执行顺序 生命周期问题（lifetime issue）：这个问题可以归入 broken invariant，但这里单独提出来。这个问题表现为，线程比其访问的数据活得更长。一般这个问题发生于线程引用了超出范围的局部变量，但也不仅限于此，比如调用 join，要考虑异常抛出时，调用不被跳过 通常可以通过调试器来确认死锁和活锁的线程以及它们争用的同步对象。对于数据竞争、不变量的破坏、生命周期问题，可见症状（如随机崩溃或不正确的输出）可以显示在代码的任何位置，代码可能重写系统其他部分使用的内存，并且很久以后才被触及，这个错误可能在程序执行的后期出现在与 bug 代码完全无关的位置。这就是共享内存的真正祸端，无论如何限制线程对数据的访问和确保正确的同步，任何线程都可以重写其他线程中的数据 ","date":"2023-11-28","objectID":"/posts/ch11_testing_and_debugging_multithreaded_application/:1:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [11] | CH11 Testing and Debugging Multithreaded Applications","uri":"/posts/ch11_testing_and_debugging_multithreaded_application/"},{"categories":["C++"],"content":"定位 bug 的方法 ","date":"2023-11-28","objectID":"/posts/ch11_testing_and_debugging_multithreaded_application/:2:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [11] | CH11 Testing and Debugging Multithreaded Applications","uri":"/posts/ch11_testing_and_debugging_multithreaded_application/"},{"categories":["C++"],"content":"code review 让其他人或自己过段时间来 code review，因为对代码不熟悉，需要思考代码的工作方式，看待的角度也不一样，更有可能发现潜在的问题。多线程代码一般有以下问题 哪些数据需要被保护，以避免并发访问 如何确保数据得到保护 其他线程此时可能运行到代码的哪个位置 这个线程持有哪些锁 其他线程持有哪些锁 在这个线程中完成的操作和另一个线程中完成的操作之间是否有任何排序要求，如何执行这些要求 这个线程读的数据是否仍然有效，是否可能被其他线程修改过 假设另一个线程在修改数据，这意味着什么，如何确保这种情况永远不会发生 ","date":"2023-11-28","objectID":"/posts/ch11_testing_and_debugging_multithreaded_application/:2:1","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [11] | CH11 Testing and Debugging Multithreaded Applications","uri":"/posts/ch11_testing_and_debugging_multithreaded_application/"},{"categories":["C++"],"content":"测试 测试多线程程序的困难在于，具体的线程调度顺序是不确定的，对于相同的输入，得到的结果却不一定相同，结果可能有时是正确的，有时是错误的。因此存在潜在的 race condition 也不意味着总会得到失败的结果，有时可能也会成功 由于重现并发相关的 bug 很困难，所以值得仔细设计测试。最好让每个测试运行最小数量的代码，这样在测试失败时可以最好地隔离出错误代码。比如测试一个并发队列，分别测试并发的 push 和 pop 的工作，就直接比测试整个队列的功能要好 为了验证问题是否与并发相关，应该从测试中消除并发性。多线程中的 bug 并不意味着一定是并发相关的，如果一个问题在单线程中也总是出现，这就是一个普通的 bug，而不是并发相关的 bug。如果一个问题在单核系统中消失，而在多核或多处理器系统中总会出现，一般这就可能是一个 race condition，或同步、内存序相关的问题 测试用例 单线程调用 push() 或 pop()，以验证 queue 的基本功能 空 queue，一个线程 push()，另一个线程 pop() 空 queue，多线程 push() 满 queue，多线程 push() 空 queue，多线程 pop() 满 queue，多线程 pop() 有部分数据但不够所有线程用的 queue，多线程 pop() 空 queue，一个线程 pop()，多线程 push() 满 queue，一个线程 pop()，多线程 push() 空 queue，多线程 pop()，多线程 push() 满 queue，多线程 pop()，多线程 push() 测试环境 多线程在每种 case 中具体指多少线程 (3, 4, 1,024?) 是否有足够的处理器，让每个线程运行在自己的核上 在哪些处理器架构上进行测试 如何合理对测试中的 while 部分 suitable scheduling 一般满足以下条件的代码就是易于测试的，这些条件单线程和多线程中同样适用 每个函数和类的责任是清晰的 函数简明扼要（short and to the point） 测试可以完全控制被测代码所在环境 执行特定操作的被测代码在系统中是紧密而非分散的 代码在写下之前已被考虑过如何测试 为了测试设计并发代码的一个最好方法是消除并发，如果可以把代码分解成负责线程间通信路径的部分，以及在单线程中操作通信数据的部分，就可以极大地简化问题。对于操作通信数据的部分就可以用常规的单线程技术测试，对于负责线程间通信的部分，代码小了很多，测试也更容易 ","date":"2023-11-28","objectID":"/posts/ch11_testing_and_debugging_multithreaded_application/:2:2","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [11] | CH11 Testing and Debugging Multithreaded Applications","uri":"/posts/ch11_testing_and_debugging_multithreaded_application/"},{"categories":["C++"],"content":"多线程测试技术 第一种测试技术是压力测试，随着代码运行次数的增加，bug 出现的几率也更高，如果代码运行十亿次都通过，代码就很可能是没有问题的。如果测试是细粒度的（fine-grained），比如前面对并发队列的测试，压力测试就更可靠。如果粒度非常大，可能的组合也非常多，即使十亿次的测试的结果也不算可靠 压力测试的缺点是，如果测试本来就保证了问题不会发生，那么无论测试多少次都不会出现失败的情况，这就会造成误导。比如在单核系统上测试多线程程序，race condition 和乒乓缓存的问题根本不会出现，但这不表示这个程序在多核系统上是没问题的。又比如，不同处理器架构提供了不同的同步和内存序工具，在 x86 和 x86-64 架构上，无论使用 memory_order_relaxed 还是 memory_order_seq_cst 内存序，原子 load 操作总是一样的，这意味着在 x86 架构上使用 relaxed 语义总是可行的，但如果换成细粒度内存序指令的系统（比如 SPARC）就会失败 第二种测试技术是组合仿真测试（combination simulation testing），即使用一个特殊的软件来仿真真实的运行时环境。仿真软件将记录数据访问、锁定、原子操作的序列，然后使用 C++ 内存模型的规则来重复运行所有可能的操作组合，以确定 race condition 和死锁 虽然这种详尽的组合测试可以保证找到设计所要检测的所有问题，但会花费大量时间，因为组合的数量随线程 数和每个线程执行的操作数呈指数增长，它最好用于单个代码片段的细粒度测试，而非用于整个程序。这种技术的另一个明显缺点是，它要求访真软件能处理代码中的操作 第三种测试技术是使用专门的库。比如共享数据通常会用 mutex 保护，如果在访问数据时能检查哪些 mutex 被锁定了，就能验证线程在访问数据时是否锁定了相应的 mutex，如果没有锁定就报告失败。库实现也能记录上锁的顺序，如果另一个线程对同一个 mutex 以不同顺序上锁，这就会被记录为潜在的死锁 另一种类型的库是，同步原语的实现允许测试编写者在多线程等待时，可以控制哪个线程来获得锁，或者哪个线程被 notify_one 通知。这就允许设置特定方案，来验证代码是否在这些方案中按预期运行 一些测试工具已经作为标准库实现的一部分提供了，其他的则可以基于标准库的部分手动实现 ","date":"2023-11-28","objectID":"/posts/ch11_testing_and_debugging_multithreaded_application/:2:3","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [11] | CH11 Testing and Debugging Multithreaded Applications","uri":"/posts/ch11_testing_and_debugging_multithreaded_application/"},{"categories":["C++"],"content":"构建多线程测试代码 多线程测试代码可以分为以下几部分 必须先执行的总体设置 必须运行在每个线程上的线程特定的设置 要并发运行在每个线程上的代码 并发执行结束后的状态断言 如下是对一个队列的测试代码 void test_concurrent_push_and_pop_on_empty_queue() { ConcurrentQueue\u003cint\u003e q; // 总体设置：先创建一个队列 std::promise\u003cvoid\u003e go, push_ready, pop_ready; std::shared_future\u003cvoid\u003e ready(go.get_future()); std::future\u003cvoid\u003e push_done; std::future\u003cint\u003e pop_done; try { push_done = std::async( std::launch::async, // 指定异步策略保证每个任务运行在自己的线程上 [\u0026q, ready, \u0026push_ready]() { push_ready.set_value(); ready.wait(); q.push(42); // 线程特定的设置：存入一个 int }); pop_done = std::async(std::launch::async, [\u0026q, ready, \u0026pop_ready]() { pop_ready.set_value(); ready.wait(); return q.try_pop(); }); push_ready.get_future().wait(); // 等待开始测试的通知 pop_ready.get_future().wait(); // 同上 go.set_value(); // 通知开始真正的测试 push_done.get(); // 获取结果 assert(pop_done.get() == 42); // 获取结果 assert(q.empty()); } catch (...) { go.set_value(); // 避免空悬指针 throw; // 再抛出异常 } } ","date":"2023-11-28","objectID":"/posts/ch11_testing_and_debugging_multithreaded_application/:2:4","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [11] | CH11 Testing and Debugging Multithreaded Applications","uri":"/posts/ch11_testing_and_debugging_multithreaded_application/"},{"categories":["C++"],"content":"测试多线程代码的性能 使用并发的一个主要目的就是利用多核处理器来提高程序性能，因此测试代码来确保性能确实提升了是很重要的。性能相关的一个主要方面就是可扩展性，性能应该随着核数一起提升。在测试多线程代码性能时，最好在尽可能多的不同配置上进行测试 ","date":"2023-11-28","objectID":"/posts/ch11_testing_and_debugging_multithreaded_application/:2:5","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [11] | CH11 Testing and Debugging Multithreaded Applications","uri":"/posts/ch11_testing_and_debugging_multithreaded_application/"},{"categories":["C++"],"content":"执行策略（execution policy） C++17 对标准库算法重载了并行版本，区别是多了一个指定执行策略的参数 std::vector\u003cint\u003e v; std::sort(std::execution::par, v.begin(), v.end()); std::execution::par 表示允许多线程并行执行此算法，注意这是一个权限（permission）而非强制要求（requirement），此算法依然可以被单线程执行 另外，如果指定了执行策略，算法复杂度的要求也更宽松，因为并行算法为了利用好系统的并行性通常要做更多工作。比如把工作划分给 100 个处理器，即使总工作是原来的两倍，也仍然能获得原来的五十倍的性能 \u003cexecution\u003e 中指定了如下执行策略类 std::execution::sequenced_policy std::execution::parallel_policy std::execution::parallel_unsequenced_policy std::execution::unsequenced_policy // C++20 并指定了对应的全局对象 std::execution::seq std::execution::par std::execution::par_unseq std::execution::unseq // C++20 如果使用执行策略，算法的行为就会受执行策略影响，影响方面包括：算法复杂度、抛异常时的行为、算法步骤的执行位置（where）、方式（how）、时刻（when） 除了管理并行执行的调度开销，许多并行算法会执行更多的核心操作（交换、比较、使用函数对象等），这样可以减少总的实际消耗时间，从而全面提升性能。这就是算法复杂度受影响的原因，其具体改变因算法不同而异 在不指定执行策略时，如下对算法的调用，抛出的异常会被传播 std::for_each(v.begin(), v.end(), [](auto x) { throw my_exception(); }); 而指定执行策略时，如果算法执行期间抛出异常，则行为结果由执行策略决定。如果有任何未捕获的异常，执行策略将调用 std::terminate 终止程序，唯一可能抛出异常的情况是，内部操作不能获取足够的内存资源时抛出 std::bad_alloc。如下操作将调用 std::terminate 终止程序 std::for_each(std::execution::seq, v.begin(), v.end(), [](auto x) { throw my_exception(); }); 不同的执行策略的执行方式也不相同。执行策略会指定执行算法步骤的代理，可以是常规线程、矢量流、GPU 线程或其他任何东西。执行策略也会指定算法步骤运行的顺序限制，比如是否要以特定顺序运行、不同算法步骤的一部分是否可以互相交错或并行运行等。下面对不同的执行策略进行详细解释 ","date":"2023-11-28","objectID":"/posts/ch10_parallel_algorithm/:1:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [10] | CH10 Parallel Algorithm","uri":"/posts/ch10_parallel_algorithm/"},{"categories":["C++"],"content":"std::execution::sequenced_policy std::execution::sequenced_policy 策略要求可以不（may not）并行执行，所有操作将执行在一个线程上。但它也是执行策略，因此与其他执行策略一样会影响算法复杂度和异常行为 所有执行在一个线程上的操作必须以某个确定顺序执行，因此这些操作是不能互相交错的。但不规定具体顺序，因此对于不同的函数调用可能产生不同的顺序 std::vector\u003cint\u003e v(1000); int n = 0; // 把 1-1000 存入容器，存入顺序可能是顺序也可能是乱序 std::for_each(std::execution::seq, v.begin(), v.end(), [\u0026](int\u0026 x) { x = ++n; }); 因此 std::execution::sequenced_policy 策略很少要求算法使用迭代器、值、可调用对象，它们可以自由地使用同步机制，可以依赖于同一线程上调用的操作，尽管不能依赖于这些操作的顺序 ","date":"2023-11-28","objectID":"/posts/ch10_parallel_algorithm/:1:1","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [10] | CH10 Parallel Algorithm","uri":"/posts/ch10_parallel_algorithm/"},{"categories":["C++"],"content":"std::execution::parallel_policy std::execution::parallel_policy 策略提供了基本的跨多个线程的并行执行，操作可以执行在调用算法的线程上，或执行在由库创建的线程上，在一个给定线程上的操作必须以确定顺序执行，并且不能相互交错。同样这个顺序是未指定的，对于不同的调用可能会有不同的顺序。一个给定的操作将在一个固定的线程上运行完整个周期 因此 std::execution::parallel_policy 策略对于迭代器、值、可调用对象的使用就有一定要求，它们在并行调用时不能造成数据竞争，并且不能依赖于统一线程上的其他操作，或者说只能依赖于不运行在同一线程上的其他操作 大多数情况都可以使用 std::execution::parallel_policy 策略 std::for_each(std::execution::par, v.begin(), v.end(), [](auto\u0026 x) { ++x; }); 只有在元素之间有特定顺序或对共享数据的访问不同步时，它才有问题 std::vector\u003cint\u003e v(1000); int n = 0; std::for_each(std::execution::par, v.begin(), v.end(), [\u0026](int\u0026 x) { x = ++n; }); // 如果多个线程执行 lambda 就会对 n 产生数据竞争 因此使用 std::execution::parallel_policy 策略时，应该事先考虑可能出现的未定义行为。可以用 mutex 或原子变量来解决竞争问题，但这就影响了并发性。不过这个例子只是为了阐述此情况，一般使用 std::execution::parallel_policy 策略时都是允许同步访问共享数据的 ","date":"2023-11-28","objectID":"/posts/ch10_parallel_algorithm/:1:2","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [10] | CH10 Parallel Algorithm","uri":"/posts/ch10_parallel_algorithm/"},{"categories":["C++"],"content":"std::execution::parallel_unsequenced_policy std::execution::parallel_unsequenced_policy 策略提供了最大可能的并行化，代价是对算法使用的迭代器、值和可调用对象有最严格的的要求 使用 std::execution::parallel_unsequenced_policy 策略的算法允许以无序的方式在任意未指定的线程中执行，并且在每个线程中彼此不排序。也就是说，操作可以在单个线程上互相交错，同一线程上的第二个操作可以开始于第一个操作结束前，并且可以在线程间迁移，一个给定的操作可以开始于一个线程，运行于另一线程，而完成于第三个线程 使用 std::execution::parallel_unsequenced_policy 策略时，提供给算法的迭代器、值、可调用对象上的操作不能使用任何形式的同步，也不能调用与其他代码同步的任何函数。这意味着操作只能作用于相关元素，或任何基于这些元素的可访问数据，并且不能修改任何线程间或元素间的共享数据 ","date":"2023-11-28","objectID":"/posts/ch10_parallel_algorithm/:1:3","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [10] | CH10 Parallel Algorithm","uri":"/posts/ch10_parallel_algorithm/"},{"categories":["C++"],"content":"标准库并行算法 \u003calgorithm\u003e 和 \u003cnumberic\u003e 中的大部分算法都重载了并行版本。std::accumlate 没有并行版本，但 C++17 提供了 std::reduce std::accumulate(v.begin(), v.end(), 0); std::reduce(std::execution::par, v.begin(), v.end()); 如果常规算法有并行版的重载，则并行版对常规算法原有的所有重载都有一个对应重载版本 template \u003cclass RandomIt\u003e void sort(RandomIt first, RandomIt last); template \u003cclass RandomIt, class Compare\u003e void sort(RandomIt first, RandomIt last, Compare comp); // 并行版对应有两个重载 template \u003cclass ExecutionPolicy, class RandomIt\u003e void sort(ExecutionPolicy\u0026\u0026 policy, RandomIt first, RandomIt last); template \u003cclass ExecutionPolicy, class RandomIt, class Compare\u003e void sort(ExecutionPolicy\u0026\u0026 policy, RandomIt first, RandomIt last, Compare comp); 但并行版的重载对部分算法有一些区别，如果常规版本使用的是输入迭代器（input iterator）或输出迭代器（output iterator），则并行版的重载将使用前向迭代器（forward iterator） template \u003cclass InputIt, class OutputIt\u003e OutputIt copy(InputIt first, InputIt last, OutputIt d_first); template \u003cclass ExecutionPolicy, class ForwardIt1, class ForwardIt2\u003e ForwardIt2 copy(ExecutionPolicy\u0026\u0026 policy, ForwardIt1 first, ForwardIt1 last, ForwardIt2 d_first); 输入迭代器只能用来读取指向的值，迭代器自增后就再也无法访问之前指向的值，它一般用于从控制台或网络输入，或生成序列，比如 std::istream_iterator。同理，输出迭代器一般用来输出到文件，或添加值到容器，也是单向的，比如 std::ostream_iterator 前向迭代器返回元素的引用，因此可以用于读写，它同样只能单向传递，std::forward_list 的迭代器就是前向迭代器，虽然它不可以回到之前指向的值，但可以存储一个指向之前元素的拷贝（比如 std::forward_list::begin）来重复利用。对于并行性来说，可以重复利用迭代器很重要。此外，前向迭代器的自增不会使其他的迭代器拷贝失效，这样就不用担心其他线程中的迭代器受影响。如果使用输入迭代器，所有线程只能共用一个迭代器，显然无法并行 std::execution::par 是最常用的策略，除非实现提供了更符合需求的非标准策略。一些情况下也可以使用 std::execution::par_unseq，虽然这不保证更好的并发性，但它给了库通过重排和交错任务来提升性能的可能性，不过代价就是不能使用同步机制，要确保线程安全只能让算法本身不会让多个线程访问同一元素，并在调用该算法的外部使用同步机制来避免其他线程对数据的访问 内部带同步机制只能使用 std::execution::par，如果使用 std::execution::par_unseq 会出现未定义行为 #include \u003calgorithm\u003e #include \u003cmutex\u003e #include \u003cvector\u003e class A { public: int get() const { std::lock_guard\u003cstd::mutex\u003e l(m_); return n_; } void inc() { std::lock_guard\u003cstd::mutex\u003e l(m_); ++n_; } private: mutable std::mutex m_; int n_ = 0; }; void f(std::vector\u003cA\u003e\u0026 v) { std::for_each(std::execution::par, v.begin(), v.end(), [](A\u0026 x) { x.inc(); }); } 如果使用 std::execution::par_unseq 则应该在外部使用同步机制 #include \u003calgorithm\u003e #include \u003cmutex\u003e #include \u003cvector\u003e class A { public: int get() const { return n_; } void inc() { ++n_; } private: int n_ = 0; }; class B { public: void lock() { m_.lock(); } void unlock() { m_.unlock(); } std::vector\u003cA\u003e\u0026 get() { return v_; } private: std::mutex m_; std::vector\u003cA\u003e v_; }; void f(B\u0026 x) { std::lock_guard\u003cstd::mutex\u003e l(x); auto\u0026 v = x.get(); std::for_each(std::execution::par_unseq, v.begin(), v.end(), [](A\u0026 x) { x.inc(); }); } 下面是一个更实际的例子。假如有一个网站，访问日志有上百万条，为了方便查看数据需要对日志进行处理。对日志每行的处理是独立的工作，很适合使用并行算法 struct Log { std::string page; time_t visit_time; // any other fields }; extern Log parse(const std::string\u0026 line); using Map = std::unordered_map\u003cstd::string, unsigned long long\u003e; Map f(const std::vector\u003cstd::string\u003e\u0026 v) { struct Combine { // log、Map 两个参数有四种组合，所以需要四个重载 Map operator()(Map lhs, Map rhs) const { if (lhs.size() \u003c rhs.size()) { std::swap(lhs, rhs); } for (const auto\u0026 x : rhs) { lhs[x.first] += x.second; } return lhs; } Map operator()(Log l, Map m) const { ++m[l.page]; return m; } Map operator()(Map m, Log l) const { ++m[l.page]; return m; } Map operator()(Log lhs, Log rhs) const { Map m; ++m[lhs.page]; ++m[rhs.page]; return m; } }; return std::transform_reduce(std::execution::par, v.begin(), v.end(), Map{}, // 初始值，一个空的 map Combine{}, // 结合两个元素的二元操作 parse); // 对每个元素执行的一元操作 } ","date":"2023-11-28","objectID":"/posts/ch10_parallel_algorithm/:2:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [10] | CH10 Parallel Algorithm","uri":"/posts/ch10_parallel_algorithm/"},{"categories":["C++"],"content":"线程池 线程池一般会用一个表示线程数的参数来初始化，内部需要一个队列来存储任务。下面是一个最简单的线程池实现 #include \u003ccondition_variable\u003e #include \u003cfunctional\u003e #include \u003cmutex\u003e #include \u003cqueue\u003e #include \u003cthread\u003e #include \u003cutility\u003e class ThreadPool { public: explicit ThreadPool(std::size_t n) { for (std::size_t i = 0; i \u003c n; ++i) { std::thread{[this] { std::unique_lock\u003cstd::mutex\u003e l(m_); while (true) { if (!q_.empty()) { auto task = std::move(q_.front()); q_.pop(); l.unlock(); task(); l.lock(); } else if (done_) { break; } else { cv_.wait(l); } } }}.detach(); } } ~ThreadPool() { { std::lock_guard\u003cstd::mutex\u003e l(m_); done_ = true; // cv_.wait 使用了 done_ 判断所以要加锁 } cv_.notify_all(); } template \u003ctypename F\u003e void submit(F\u0026\u0026 f) { { std::lock_guard\u003cstd::mutex\u003e l(m_); q_.emplace(std::forward\u003cF\u003e(f)); } cv_.notify_one(); } private: std::mutex m_; std::condition_variable cv_; bool done_ = false; std::queue\u003cstd::function\u003cvoid()\u003e\u003e q_; }; 如果想让提交的任务带参数会麻烦很多 template \u003cclass F, class... Args\u003e auto ThreadPool::submit(F\u0026\u0026 f, Args\u0026\u0026... args) { using RT = std::invoke_result_t\u003cF, Args...\u003e; // std::packaged_task 不允许拷贝构造，不能直接传入 lambda， // 因此要借助 std::shared_ptr auto task = std::make_shared\u003cstd::packaged_task\u003cRT()\u003e\u003e( std::bind(std::forward\u003cF\u003e(f), std::forward\u003cArgs\u003e(args)...)); // 但 std::bind 会按值拷贝实参，因此这个实现不允许任务的实参是 move-only 类型 { std::lock_guard\u003cstd::mutex\u003e l(m_); q_.emplace([task]() { (*task)(); }); // 捕获指针以传入 std::packaged_task } cv_.notify_one(); return task-\u003eget_future(); } 书上实现的线程池都在死循环中使用了 std::this_thread::yield 来转让时间片 #include \u003catomic\u003e #include \u003cfunctional\u003e #include \u003cthread\u003e #include \u003cvector\u003e #include \"concurrent_queue.hpp\" class ThreadPool { public: ThreadPool() { std::size_t n = std::thread::hardware_concurrency(); try { for (std::size_t i = 0; i \u003c n; ++i) { threads_.emplace_back(\u0026ThreadPool::worker_thread, this); } } catch (...) { done_ = true; for (auto\u0026 x : threads_) { if (x.joinable()) { x.join(); } } throw; } } ~ThreadPool() { done_ = true; for (auto\u0026 x : threads_) { if (x.joinable()) { x.join(); } } } template \u003ctypename F\u003e void submit(F f) { q_.push(std::function\u003cvoid()\u003e(f)); } private: void worker_thread() { while (!done_) { std::function\u003cvoid()\u003e task; if (q_.try_pop(task)) { task(); } else { std::this_thread::yield(); } } } private: std::atomic\u003cbool\u003e done_ = false; ConcurrentQueue\u003cstd::function\u003cvoid()\u003e\u003e q_; std::vector\u003cstd::thread\u003e threads_; // 要在 done_ 和 q_ 之后声明 }; 这样做的问题是，如果线程池处于空闲状态，就会无限转让时间片，导致 CPU 使用率达 100%，下面是对书中的线程池的 CPU 使用率测试结果 对相同任务用之前实现的线程池的测试结果 这里还是把书上的内容列出来，下文均为书中内容 这个线程池只能执行无参数无返回值的函数，并且可能出现死锁，下面希望能执行无参数但有返回值的函数。为了得到返回值，就应该把函数传递给 std::packaged_task 再加入队列，并返回 std::packaged_task 中的 std::future。由于 std::packaged_task 是 move-only 类型，而 std::function 要求存储的函数实例可以拷贝构造，因此这里需要实现一个支持 move-only 类型的函数包裹类，即一个带 call 操作的类型擦除（type-erasure）类 #include \u003cmemory\u003e #include \u003cutility\u003e class FunctionWrapper { public: FunctionWrapper() = default; FunctionWrapper(const FunctionWrapper\u0026) = delete; FunctionWrapper\u0026 operator=(const FunctionWrapper\u0026) = delete; FunctionWrapper(FunctionWrapper\u0026\u0026 rhs) noexcept : impl_(std::move(rhs.impl_)) {} FunctionWrapper\u0026 operator=(FunctionWrapper\u0026\u0026 rhs) noexcept { impl_ = std::move(rhs.impl_); return *this; } template \u003ctypename F\u003e FunctionWrapper(F\u0026\u0026 f) : impl_(new ImplType\u003cF\u003e(std::move(f))) {} void operator()() const { impl_-\u003ecall(); } private: struct ImplBase { virtual void call() = 0; virtual ~ImplBase() = default; }; template \u003ctypename F\u003e struct ImplType : ImplBase { ImplType(F\u0026\u0026 f) noexcept : f_(std::move(f)) {} void call() override { f_(); } F f_; }; private: std::unique_ptr\u003cImplBase\u003e impl_; }; 用这个包裹类替代 std::function\u003cvoid()\u003e #include \u003catomic\u003e #include \u003cfuture\u003e #include \u003cthread\u003e #include \u003ctype_traits\u003e #include \u003cvector\u003e #include \"concurrent_queue.hpp\" #include \"function_wrapper.hpp\" class ThreadPool { public: ThreadPool() { std::size_t n = std::thread::hardware_concurrency(); try { for (std::size_t i = 0; i \u003c n; ++i) { threads_.emplace_back(\u0026ThreadPool::worker_thread, this); } } catch (...) { done_ = true; for (auto\u0026 x : threads_) { if (x.joinable()) { x.join(); } } thr","date":"2023-11-28","objectID":"/posts/ch09_advanced_thread_management/:1:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [9] | CH09 Advanced Thread Management","uri":"/posts/ch09_advanced_thread_management/"},{"categories":["C++"],"content":"中断 可中断线程的简单实现 class InterruptFlag { public: void set(); bool is_set() const; }; thread_local InterruptFlag this_thread_interrupt_flag; class InterruptibleThread { public: template \u003ctypename F\u003e InterruptibleThread(F f) { std::promise\u003cInterruptFlag*\u003e p; t = std::thread([f, \u0026p] { p.set_value(\u0026this_thread_interrupt_flag); f(); }); flag = p.get_future().get(); } void interrupt() { if (flag) { flag-\u003eset(); } } private: std::thread t; InterruptFlag* flag; }; void interruption_point() { if (this_thread_interrupt_flag.is_set()) { throw thread_interrupted(); } } 在函数中使用 void f() { while (!done) { interruption_point(); process_next_item(); } } 更好的方式是用 std::condition_variable 来唤醒，而非在循环中持续运行 class InterruptFlag { public: void set() { b_.store(true, std::memory_order_relaxed); std::lock_guard\u003cstd::mutex\u003e l(m_); if (cv_) { cv_-\u003enotify_all(); } } bool is_set() const { return b_.load(std::memory_order_relaxed); } void set_condition_variable(std::condition_variable\u0026 cv) { std::lock_guard\u003cstd::mutex\u003e l(m_); cv_ = \u0026cv; } void clear_condition_variable() { std::lock_guard\u003cstd::mutex\u003e l(m_); cv_ = nullptr; } struct ClearConditionVariableOnDestruct { ~ClearConditionVariableOnDestruct() { this_thread_interrupt_flag.clear_condition_variable(); } }; private: std::atomic\u003cbool\u003e b_; std::condition_variable* cv_ = nullptr; std::mutex m_; }; void interruptible_wait(std::condition_variable\u0026 cv, std::unique_lock\u003cstd::mutex\u003e\u0026 l) { interruption_point(); this_thread_interrupt_flag.set_condition_variable(cv); // 之后的 wait_for 可能抛异常，所以需要 RAII 清除标志 InterruptFlag::ClearConditionVariableOnDestruct guard; interruption_point(); // 设置线程看到中断前的等待时间上限 cv.wait_for(l, std::chrono::milliseconds(1)); interruption_point(); } template \u003ctypename Predicate\u003e void interruptible_wait(std::condition_variable\u0026 cv, std::unique_lock\u003cstd::mutex\u003e\u0026 l, Predicate pred) { interruption_point(); this_thread_interrupt_flag.set_condition_variable(cv); InterruptFlag::ClearConditionVariableOnDestruct guard; while (!this_thread_interrupt_flag.is_set() \u0026\u0026 !pred()) { cv.wait_for(l, std::chrono::milliseconds(1)); } interruption_point(); } 和 std::condition_variable 不同的是，std::condition_variable_any 可以使用不限于 std::unique_lock 的任何类型的锁，这意味着可以使用自定义的锁类型 #include \u003catomic\u003e #include \u003ccondition_variable\u003e #include \u003cmutex\u003e class InterruptFlag { public: void set() { b_.store(true, std::memory_order_relaxed); std::lock_guard\u003cstd::mutex\u003e l(m_); if (cv_) { cv_-\u003enotify_all(); } else if (cv_any_) { cv_any_-\u003enotify_all(); } } template \u003ctypename Lockable\u003e void wait(std::condition_variable_any\u0026 cv, Lockable\u0026 l) { class Mutex { public: Mutex(InterruptFlag* self, std::condition_variable_any\u0026 cv, Lockable\u0026 l) : self_(self), lock_(l) { self_-\u003em_.lock(); self_-\u003ecv_any_ = \u0026cv; } ~Mutex() { self_-\u003ecv_any_ = nullptr; self_-\u003em_.unlock(); } void lock() { std::lock(self_-\u003em_, lock_); } void unlock() { lock_.unlock(); self_-\u003em_.unlock(); } private: InterruptFlag* self_; Lockable\u0026 lock_; }; Mutex m(this, cv, l); interruption_point(); cv.wait(m); interruption_point(); } // rest as before private: std::atomic\u003cbool\u003e b_; std::condition_variable* cv_ = nullptr; std::condition_variable_any* cv_any_ = nullptr; std::mutex m_; }; template \u003ctypename Lockable\u003e void interruptible_wait(std::condition_variable_any\u0026 cv, Lockable\u0026 l) { this_thread_interrupt_flag.wait(cv, l); } 对于其他阻塞调用（比如 mutex、future）的中断，一般也可以像对 std::condition_variable 一样设置超时时间，因为不访问内部 mutex 或 future 无法在未满足等待的条件时中断等待 template \u003ctypename T\u003e void interruptible_wait(std::future\u003cT\u003e\u0026 ft) { while (!this_thread_interrupt_flag.is_set()) { if (ft.wait_for(std::chrono::milliseconds(1)) == std::future_status::ready) { break; } } interruption_point(); } 从被中断的线程角度来看，中断就是一个 thread_interrupted 异常。因此检查出中断后，可以像异常一样对其进行处理 internal_thread = std::thread{[f, \u0026p] { p.set_value(\u0026this_thread_interrupt_flag); try { f(); } catch (const thread_interrupted\u0026) { // 异常传入 std::thread 的析构函数时将调用 std::terminate // 为了防止程序终止就要捕获异常 } }}; 假如有一个桌面搜索程序，除了与用户交互，程序还需要监控文件系统的状态，以识别任何更改并更新其索引。为了避免影响 GUI 的响应性，这个处理通常会交给一个后台线程，后台线程需要运行于程序","date":"2023-11-28","objectID":"/posts/ch09_advanced_thread_management/:2:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [9] | CH09 Advanced Thread Management","uri":"/posts/ch09_advanced_thread_management/"},{"categories":["C++"],"content":"非阻塞数据结构 阻塞的算法和数据结构使用 mutex、条件变量、期值来同步数据，但非阻塞不等价于 lock-free，比如自旋锁没有使用任何阻塞函数的调用，是非阻塞的，但并非 lock-free 非阻塞数据结构由松到严可分为三个等级：obstruction-free、lock-free、wait-free obstruction-free（无障碍）：如果其他线程都暂停了，任何一个给定的线程都会在有限步数内完成操作。上例就是这种情况，但这种情况很少见，所以满足这个条件只能算一个失败的 lock-free 实现 lock-free（无锁）：如果多线程在同一个数据结构上操作，其中一个将在有限步数内完成操作。满足 lock-free 必定满足 obstruction-free wait-free（无等待）：如果多线程在同一个数据结构上操作，每个线程都会在有限步数内完成操作。满足 wait-free 必定满足 lock-free，但 wait-free 很难实现，因为要保证有限步数内完成操作，就要保证操作一次通过，并且执行到某一步不能导致其他线程操作失败 lock-free 数据结构必须允许多线程并发访问，但它们不能做相同操作，比如一个 lock-free 的 queue 允许一个线程 push、另一个线程 pop，但不允许两个线程同时 push。此外，如果一个访问 lock-free 数据结构的线程被中途挂起，其他线程必须能完成操作而不需要等待挂起的线程 使用 lock-free 数据结构主要是为了最大化并发访问，不需要阻塞。第二个原因是鲁棒性，如果线程在持有锁时死掉就会导致数据结构被永久破坏，而对 lock-free 数据结构来说，除了死掉的线程里的数据，其他的数据都不会丢失。lock-free 没有任何锁，所以一定不会出现死锁 但 lock-free 可能造成更大开销，用于 lock-free 的原子操作比非原子操作慢得多，且 lock-free 数据结构中的原子操作一般比 lock-based 中的多，此外，硬件必须访问同一个原子变量以在线程间同步数据。无论 lock-free 还是 lock-based，性能方面的检查（最坏情况等待时间、平均等待时间、总体执行时间或其他方面）都是非常重要的 ","date":"2023-11-28","objectID":"/posts/ch07_designing_lock_free_concurrent_data_structure/:1:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [7] | CH07 Designing Lock free Concurrent Data Structure","uri":"/posts/ch07_designing_lock_free_concurrent_data_structure/"},{"categories":["C++"],"content":"lock-free thread-safe stack 最简单的 stack 实现方式是包含头节点指针的链表。push 的过程很简单，创建一个新节点，然后让新节点的 next 指针指向当前 head，最后 head 设为新节点 这里的 race condition 在于，如果两个线程同时 push，让各自的新节点的 next 指针指向当前 head，这样必然导致 head 最终设为二者之一的新节点，而另一个被丢弃 解决方法是，在最后设置 head 时先进行判断，只有当前 head 与新节点的 next 相等，才将 head 设为新节点，如果不等则让 next 指向当前 head 并重新判断。而这个操作必须是原子的，因此就需要使用 compare_exchange_weak，不需要使用 compare_exchange_strong，因为 compare_exchange_weak 在相等时可能替换失败，但替换失败也会返回 false，放在循环里带来的效果是一样的，而 compare_exchange_weak 在一些机器架构上可以产生比 compare_exchange_strong 更优化的代码 #include \u003catomic\u003e template \u003ctypename T\u003e class LockFreeStack { public: void push(const T\u0026 x) { Node* t = new Node(x); t-\u003enext = head_.load(); while (!head_.compare_exchange_weak(t-\u003enext, t)) { } } private: struct Node { T v; Node* next = nullptr; Node(const T\u0026 x) : v(x) {} }; private: std::atomic\u003cNode*\u003e head_; }; pop 的过程很简单，先存储当前头节点指针，再将头节点设为下一节点，最后返回存储的头节点并删除指针。这里的 race condition 在于，如果两个线程同时 pop，如果一个已经删除了头节点，另一个线程读取头节点的下一节点就访问了空悬指针 先绕开删除指针这一步，考虑前几步的实现 template \u003ctypename T\u003e void LockFreeStack\u003cT\u003e::pop(T\u0026 res) { Node* t = head_.load(); // 未考虑头节点为空指针的情况 while (!head_.compare_exchange_weak(t, t-\u003enext)) { } res = t-\u003ev; } 传引用来保存结果的原因是，如果直接返回值，返回前一定会先移除元素，如果拷贝返回值时抛出异常，移除的元素就丢失了。但传引用的问题是，如果其他线程移除了节点，被移除的节点不能被解引用，当前线程就无法安全地拷贝数据。因此，如果想安全地返回值，应该返回智能指针 #include \u003catomic\u003e #include \u003cmemory\u003e template \u003ctypename T\u003e class LockFreeStack { public: void push(const T\u0026 x) { Node* t = new Node(x); t-\u003enext = head_.load(); while (!head_.compare_exchange_weak(t-\u003enext, t)) { } } std::shared_ptr\u003cT\u003e pop() { // 还未考虑释放原来的头节点指针 Node* t = head_.load(); while (t \u0026\u0026 !head_.compare_exchange_weak(t, t-\u003enext)) { } return t ? t-\u003ev : nullptr; } private: struct Node { std::shared_ptr\u003cT\u003e v; Node* next = nullptr; Node(const T\u0026 x) : v(std::make_shared\u003cT\u003e(x)) {} }; private: std::atomic\u003cNode*\u003e head_; }; 释放被移除的节点的难点在于，一个线程在释放内存时，无法得知其他线程是否持有要释放的指针 只要没有其他线程调用 pop，就能安全释放，因此可以用一个计数器来记录调用 pop 的线程数，计数不为 1 时，先把节点添加到待删除节点列表中，计数为 1 则安全释放 #include \u003catomic\u003e #include \u003cmemory\u003e template \u003ctypename T\u003e class LockFreeStack { public: void push(const T\u0026 x) { Node* t = new Node(x); t-\u003enext = head_.load(); while (!head_.compare_exchange_weak(t-\u003enext, t)) { } } std::shared_ptr\u003cT\u003e pop() { ++pop_cnt_; Node* t = head_.load(); while (t \u0026\u0026 !head_.compare_exchange_weak(t, t-\u003enext)) { } std::shared_ptr\u003cT\u003e res; if (t) { res.swap(t-\u003ev); } try_delete(t); return res; } private: struct Node { std::shared_ptr\u003cT\u003e v; Node* next = nullptr; Node(const T\u0026 x) : v(std::make_shared\u003cT\u003e(x)) {} }; private: static void delete_list(Node* head) { while (head) { Node* t = head-\u003enext; delete head; head = t; } } void append_to_delete_list(Node* first, Node* last) { last-\u003enext = to_delete_list_; // 确保 last-\u003enext 为 to_delete_list_，再设置 first 为新的头节点 while (!to_delete_list_.compare_exchange_weak(last-\u003enext, first)) { } } void append_to_delete_list(Node* head) { Node* last = head; while (Node* t = last-\u003enext) { last = t; } append_to_delete_list(head, last); } void try_delete(Node* head) { if (pop_cnt_ == 0) { return; } if (pop_cnt_ \u003e 1) { append_to_delete_list(head, head); --pop_cnt_; return; } Node* t = to_delete_list_.exchange(nullptr); if (--pop_cnt_ == 0) { delete_list(t); } else if (t) { append_to_delete_list(t); } delete head; } private: std::atomic\u003cNode*\u003e head_; std::atomic\u003cstd::size_t\u003e pop_cnt_; std::atomic\u003cNode*\u003e to_delete_list_; }; 如果要释放所有节点，必须有一个时刻计数器为 0。在高负载的情况下，往往不会存在这样的时刻，从而导致待删除节点的列表无限增长 ","date":"2023-11-28","objectID":"/posts/ch07_designing_lock_free_concurrent_data_structure/:2:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [7] | CH07 Designing Lock free Concurrent Data Structure","uri":"/posts/ch07_designing_lock_free_concurrent_data_structure/"},{"categories":["C++"],"content":"Hazard Pointer（风险指针） 另一个释放的思路是，在线程访问节点时，设置一个保存了线程 ID 和该节点的风险指针。用一个全局数组保存所有线程的风险指针，释放节点时，如果数组中不存在包含该节点的风险指针，则可以直接释放，否则将节点添加到待删除列表中。风险指针实现如下 #include \u003catomic\u003e #include \u003cstdexcept\u003e #include \u003cthread\u003e static constexpr std::size_t MaxSize = 100; struct HazardPointer { std::atomic\u003cstd::thread::id\u003e id; std::atomic\u003cvoid*\u003e p; }; static HazardPointer HazardPointers[MaxSize]; class HazardPointerHelper { public: HazardPointerHelper() { for (auto\u0026 x : HazardPointers) { std::thread::id default_id; if (x.id.compare_exchange_strong(default_id, std::this_thread::get_id())) { hazard_pointer = \u0026x; // 取一个未设置过的风险指针 break; } } if (!hazard_pointer) { throw std::runtime_error(\"No hazard pointers available\"); } } ~HazardPointerHelper() { hazard_pointer-\u003ep.store(nullptr); hazard_pointer-\u003eid.store(std::thread::id{}); } HazardPointerHelper(const HazardPointerHelper\u0026) = delete; HazardPointerHelper operator=(const HazardPointerHelper\u0026) = delete; std::atomic\u003cvoid*\u003e\u0026 get() { return hazard_pointer-\u003ep; } private: HazardPointer* hazard_pointer = nullptr; }; std::atomic\u003cvoid*\u003e\u0026 hazard_pointer_for_this_thread() { static thread_local HazardPointerHelper t; return t.get(); } bool is_existing(void* p) { for (auto\u0026 x : HazardPointers) { if (x.p.load() == p) { return true; } } return false; } 使用风险指针 #include \u003catomic\u003e #include \u003cfunctional\u003e #include \u003cmemory\u003e #include \"hazard_pointer.hpp\" template \u003ctypename T\u003e class LockFreeStack { public: void push(const T\u0026 x) { Node* t = new Node(x); t-\u003enext = head_.load(); while (!head_.compare_exchange_weak(t-\u003enext, t)) { } } std::shared_ptr\u003cT\u003e pop() { std::atomic\u003cvoid*\u003e\u0026 hazard_pointer = hazard_pointer_for_this_thread(); Node* t = head_.load(); do { // 外循环确保 t 为最新的头节点，循环结束后将头节点设为下一节点 Node* t2; do { // 循环至风险指针保存当前最新的头节点 t2 = t; hazard_pointer.store(t); t = head_.load(); } while (t != t2); } while (t \u0026\u0026 !head_.compare_exchange_strong(t, t-\u003enext)); hazard_pointer.store(nullptr); std::shared_ptr\u003cT\u003e res; if (t) { res.swap(t-\u003ev); if (is_existing(t)) { append_to_delete_list(new DataToDelete{t}); } else { delete t; } try_delete(); } return res; } private: struct Node { std::shared_ptr\u003cT\u003e v; Node* next = nullptr; Node(const T\u0026 x) : v(std::make_shared\u003cT\u003e(x)) {} }; struct DataToDelete { template \u003ctypename T\u003e DataToDelete(T* p) : data(p), deleter([](void* p) { delete static_cast\u003cT*\u003e(p); }) {} ~DataToDelete() { deleter(data); } void* data = nullptr; std::function\u003cvoid(void*)\u003e deleter; DataToDelete* next = nullptr; }; private: void append_to_delete_list(DataToDelete* t) { t-\u003enext = to_delete_list_.load(); while (!to_delete_list_.compare_exchange_weak(t-\u003enext, t)) { } } void try_delete() { DataToDelete* cur = to_delete_list_.exchange(nullptr); while (cur) { DataToDelete* t = cur-\u003enext; if (!is_existing(cur-\u003edata)) { delete cur; } else { append_to_delete_list(new DataToDelete{cur}); } cur = t; } } private: std::atomic\u003cNode*\u003e head_; std::atomic\u003cstd::size_t\u003e pop_cnt_; std::atomic\u003cDataToDelete*\u003e to_delete_list_; }; 风险指针实现简单并达到了安全释放的目的，但每次删除节点前后都要遍历数组并原子访问内部指针来检查，增加了很多开销 无锁内存回收技术领域十分活跃，大公司都会申请自己的专利，风险指针包含在 IBM 提交的专利申请中，在 GPL 协议下允许免费使用 ","date":"2023-11-28","objectID":"/posts/ch07_designing_lock_free_concurrent_data_structure/:2:1","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [7] | CH07 Designing Lock free Concurrent Data Structure","uri":"/posts/ch07_designing_lock_free_concurrent_data_structure/"},{"categories":["C++"],"content":"引用计数 另一个方案是使用引用计数记录访问每个节点的线程数量，std::shared_ptr 的操作是原子的，但要检查是否 lock-free std::shared_ptr\u003cint\u003e p(new int(42)); assert(std::atomic_is_lock_free(\u0026p)); 如果是，则可以用于实现 lock-free stack #include \u003catomic\u003e #include \u003cmemory\u003e template \u003ctypename T\u003e class LockFreeStack { public: ~LockFreeStack() { while (pop()) { } } void push(const T\u0026 x) { auto t = std::make_shared\u003cNode\u003e(x); t-\u003enext = std::atomic_load(\u0026head_); while (!std::atomic_compare_exchange_weak(\u0026head_, \u0026t-\u003enext, t)) { } } std::shared_ptr\u003cT\u003e pop() { std::shared_ptr\u003cNode\u003e t = std::atomic_load(\u0026head_); while (t \u0026\u0026 !std::atomic_compare_exchange_weak(\u0026head_, \u0026t, t-\u003enext)) { } if (t) { std::atomic_store(\u0026t-\u003enext, nullptr); return t-\u003ev; } return nullptr; } private: struct Node { std::shared_ptr\u003cT\u003e v; std::shared_ptr\u003cNode\u003e next; Node(const T\u0026 x) : v(std::make_shared\u003cT\u003e(x)) {} }; private: std::shared_ptr\u003cNode\u003e head_; }; C++20 支持 std::atomic\u003cstd::shared_ptr\u003e #include \u003catomic\u003e #include \u003cmemory\u003e template \u003ctypename T\u003e class LockFreeStack { public: ~LockFreeStack() { while (pop()) { } } void push(const T\u0026 x) { auto t = std::make_shared\u003cNode\u003e(x); t-\u003enext = head_.load(); while (!head_.compare_exchange_weak(t-\u003enext, t)) { } } std::shared_ptr\u003cT\u003e pop() { std::shared_ptr\u003cNode\u003e t = head_.load(); while (t \u0026\u0026 !head_.compare_exchange_weak(t, t-\u003enext.load())) { } if (t) { t-\u003enext = std::shared_ptr\u003cNode\u003e(); return t-\u003ev; } return nullptr; } private: struct Node { std::shared_ptr\u003cT\u003e v; std::atomic\u003cstd::shared_ptr\u003cNode\u003e\u003e next; Node(const T\u0026 x) : v(std::make_shared\u003cT\u003e(x)) {} }; private: std::atomic\u003cstd::shared_ptr\u003cNode\u003e\u003e head_; }; 但 VS2022 上测试发现 std::atomic\u003cstd::shared_ptr\u003e 并非 lock-free assert(!std::atomic\u003cstd::shared_ptr\u003cint\u003e\u003e{}.is_lock_free()); 更通用的方法是手动管理引用计数，为每个节点设置内外部两个引用计数，两者之和就是节点的引用计数，外部计数默认为 1，访问对象时递增外部计数并递减内部计数，访问结束后则不再需要外部计数，将外部计数减 2 并加到内部计数上 #include \u003catomic\u003e #include \u003cmemory\u003e template \u003ctypename T\u003e class LockFreeStack { public: ~LockFreeStack() { while (pop()) { } } void push(const T\u0026 x) { ReferenceCount t; t.p = new Node(x); t.external_cnt = 1; t.p-\u003enext = head_.load(); while (!head_.compare_exchange_weak(t.p-\u003enext, t)) { } } std::shared_ptr\u003cT\u003e pop() { ReferenceCount t = head_.load(); while (true) { increase_count(t); // 外部计数递增表示该节点正被使用 Node* p = t.p; // 因此可以安全地访问 if (!p) { return nullptr; } if (head_.compare_exchange_strong(t, p-\u003enext)) { std::shared_ptr\u003cT\u003e res; res.swap(p-\u003ev); // 将外部计数减 2 后加到内部计数，减 2 是因为， // 节点被删除减 1，该线程无法再次访问此节点再减 1 const int cnt = t.external_cnt - 2; if (p-\u003einner_cnt.fetch_add(cnt) == -cnt) { delete p; // 内外部计数和为 0 } return res; } if (p-\u003einner_cnt.fetch_sub(1) == 1) { delete p; // 内部计数为 0 } } } private: struct Node; struct ReferenceCount { int external_cnt; Node* p; }; struct Node { std::shared_ptr\u003cT\u003e v; std::atomic\u003cint\u003e inner_cnt = 0; ReferenceCount next; Node(const T\u0026 x) : v(std::make_shared\u003cT\u003e(x)) {} }; void increase_count(ReferenceCount\u0026 old_cnt) { ReferenceCount new_cnt; do { new_cnt = old_cnt; ++new_cnt.external_cnt; // 访问 head_ 时递增外部计数，表示该节点正被使用 } while (!head_.compare_exchange_strong(old_cnt, new_cnt)); old_cnt.external_cnt = new_cnt.external_cnt; } private: std::atomic\u003cReferenceCount\u003e head_; }; 不指定内存序则默认使用开销最大的 std::memory_order_seq_cst，下面根据操作间的依赖关系优化为最小内存序 #include \u003catomic\u003e #include \u003cmemory\u003e template \u003ctypename T\u003e class LockFreeStack { public: ~LockFreeStack() { while (pop()) { } } void push(const T\u0026 x) { ReferenceCount t; t.p = new Node(x); t.external_cnt = 1; // 下面比较中 release 保证之前的语句都先执行，因此 load 可以使用 relaxed t.p-\u003enext = head_.load(std::memory_order_relaxed); while (!head_.compare_exchange_weak(t.p-\u003enext, t, std::memory_order_release, std::memory_order_relaxed)) { } } std::shared_ptr\u003cT\u003e pop() { ReferenceCount t = head_.load(std::memory_order_relaxed); while (true) { increase_count(t); // acquire Node* p = t.p; if (!p) { return nullptr; } if (head_.compare_exchange_strong(t, p-\u003enext, std::memory_order_relaxed)) { std::shared_ptr\u003cT\u003e res; res.swap(p-\u003ev); // 将外部计数减 2 后加到内部计数，减 2 是因为， // 节点被删除减 1，该线程无法再次访问此节点再减 1 const int cnt = t.external_cnt - 2; // swap 要先于 delete，因此使用 rele","date":"2023-11-28","objectID":"/posts/ch07_designing_lock_free_concurrent_data_structure/:2:2","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [7] | CH07 Designing Lock free Concurrent Data Structure","uri":"/posts/ch07_designing_lock_free_concurrent_data_structure/"},{"categories":["C++"],"content":" 设计并发数据结构要考虑两点，一是确保访问 thread-safe，二是提高并发度 thread-safe 基本要求如下 数据结构的不变量（invariant）被一个线程破坏时，确保不被线程看到此状态 提供操作完整的函数来避免数据结构接口中固有的 race condition 注意数据结构出现异常时的行为，以确保不变量不被破坏 限制锁的范围，避免可能的嵌套锁，最小化死锁的概率 作为数据结构的设计者，要提高数据结构的并发度，可以从以下角度考虑 部分操作能否在锁的范围外执行 数据结构的不同部分是否被不同的 mutex 保护 是否所有操作需要同级别的保护 在不影响操作语义的前提下，能否对数据结构做简单的修改提高并发度 总结为一点，即最小化线程对共享数据的轮流访问，最大化真实的并发量 ","date":"2023-11-28","objectID":"/posts/ch06_designing_lock_based_concurrent_data_structure/:0:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [6] | CH06 Designing Lock-based Concurrent Data Structure","uri":"/posts/ch06_designing_lock_based_concurrent_data_structure/"},{"categories":["C++"],"content":"thread-safe queue 之前实现过的 thread-safe stack 和 queue 都是用一把锁定保护整个数据结构，这限制了并发性，多线程在成员函数中阻塞时，同一时间只有一个线程能工作。这种限制主要是因为内部实现使用的是 std::queue，为了支持更高的并发，需要更换内部的实现方式，使用细粒度的（fine-grained）锁。最简单的实现方式是包含头尾指针的单链表，不考虑并发的单链表实现如下 #include \u003cmemory\u003e #include \u003cutility\u003e template \u003ctypename T\u003e class Queue { public: Queue() = default; Queue(const Queue\u0026) = delete; Queue\u0026 operator=(const Queue\u0026) = delete; void push(T x) { auto new_node = std::make_unique\u003cNode\u003e(std::move(x)); Node* new_tail_node = new_node.get(); if (tail_) { tail_-\u003enext = std::move(new_node); } else { head_ = std::move(new_node); } tail_ = new_tail_node; } std::shared_ptr\u003cT\u003e try_pop() { if (!head_) { return nullptr; } auto res = std::make_shared\u003cT\u003e(std::move(head_-\u003ev)); std::unique_ptr\u003cNode\u003e head_node = std::move(head_); head_ = std::move(head_node-\u003enext); return res; } private: struct Node { explicit Node(T x) : v(std::move(x)) {} T v; std::unique_ptr\u003cNode\u003e next; }; std::unique_ptr\u003cNode\u003e head_; Node* tail_ = nullptr; }; 即使用两个 mutex 分别保护头尾指针，这个实现在多线程下也有明显问题。push 可以同时修改头尾指针，会对两个 mutex 上锁，另外仅有一个元素时头尾指针相等，push 写和 try_pop 读的 next 节点是同一对象，产生了竞争，锁的也是同一个 mutex 该问题很容易解决，在头节点前初始化一个 dummy 节点即可，这样 push 只访问尾节点，不会再与 try_pop 竞争头节点 #include \u003cmemory\u003e #include \u003cutility\u003e template \u003ctypename T\u003e class Queue { public: Queue() : head_(new Node), tail_(head_.get()) {} Queue(const Queue\u0026) = delete; Queue\u0026 operator=(const Queue\u0026) = delete; void push(T x) { auto new_val = std::make_shared\u003cT\u003e(std::move(x)); auto new_node = std::make_unique\u003cNode\u003e(); Node* new_tail_node = new_node.get(); tail_-\u003ev = new_val; tail_-\u003enext = std::move(new_node); tail_ = new_tail_node; } std::shared_ptr\u003cT\u003e try_pop() { if (head_.get() == tail_) { return nullptr; } std::shared_ptr\u003cT\u003e res = head-\u003ev; std::unique_ptr\u003cNode\u003e head_node = std::move(head_); head_ = std::move(head_node-\u003enext); return res; } private: struct Node { std::shared_ptr\u003cT\u003e v; std::unique_ptr\u003cNode\u003e next; }; std::unique_ptr\u003cNode\u003e head_; Node* tail_ = nullptr; }; 接着加上锁，锁的范围应该尽可能小 #include \u003cmemory\u003e #include \u003cmutex\u003e #include \u003cutility\u003e template \u003ctypename T\u003e class ConcurrentQueue { public: ConcurrentQueue() : head_(new Node), tail_(head_.get()) {} ConcurrentQueue(const ConcurrentQueue\u0026) = delete; ConcurrentQueue\u0026 operator=(const ConcurrentQueue\u0026) = delete; void push(T x) { auto new_val = std::make_shared\u003cT\u003e(std::move(x)); auto new_node = std::make_unique\u003cNode\u003e(); Node* new_tail_node = new_node.get(); std::lock_guard\u003cstd::mutex\u003e l(tail_mutex_); tail_-\u003ev = new_val; tail_-\u003enext = std::move(new_node); tail_ = new_tail_node; } std::shared_ptr\u003cT\u003e try_pop() { std::unique_ptr\u003cNode\u003e head_node = pop_head(); return head_node ? head_node-\u003ev : nullptr; } private: struct Node { std::shared_ptr\u003cT\u003e v; std::unique_ptr\u003cNode\u003e next; }; private: std::unique_ptr\u003cNode\u003e pop_head() { std::lock_guard\u003cstd::mutex\u003e l(head_mutex_); if (head_.get() == get_tail()) { return nullptr; } std::unique_ptr\u003cNode\u003e head_node = std::move(head_); head_ = std::move(head_node-\u003enext); return head_node; } Node* get_tail() { std::lock_guard\u003cstd::mutex\u003e l(tail_mutex_); return tail_; } private: std::unique_ptr\u003cNode\u003e head_; Node* tail_ = nullptr; std::mutex head_mutex_; std::mutex tail_mutex_; }; push 中创建新值和新节点都没上锁，多线程可用并发创建新值和新节点。虽然同时只有一个线程能添加新节点，但这只需要一个指针赋值操作，锁住尾节点的时间很短，try_pop 中对尾节点只是用来做一次比较，持有尾节点的时间同样很短，因此 try_pop 和 push 几乎可以同时调用。try_pop 中锁住头节点所做的也只是指针赋值操作，开销较大的析构在锁外进行，这意味着虽然同时只有一个线程能 pop_head，但允许多线程删除节点并返回数据，提升了 try_pop 的并发调用数量 最后再结合 std::condition_variable 实现 wait_and_pop，即得到与之前接口相同但并发度更高的 thread-safe queue #include \u003ccondition_variable\u003e #include \u003cmemory\u003e #include \u003cmutex\u003e #include \u003cutility\u003e template \u003ctypename T\u003e class ConcurrentQueue { public: ConcurrentQueue() : head_(new Node), tail_(head_.get()) {} ConcurrentQueue(const ConcurrentQueue\u0026) = delete; ConcurrentQueue\u0026 operator=(const ConcurrentQueue\u0026) = delete; void push(T x) { auto new_val = std::make_shared\u003cT\u003e(std::move(x)); auto new_node = std::make_unique\u003cNode\u003e(); Node* new_tail_node = new_node.get(); { std::lock_guard\u003cstd::mutex\u003e l(tail_mutex_); tail_-\u003ev = new_val; tail_-\u003en","date":"2023-11-28","objectID":"/posts/ch06_designing_lock_based_concurrent_data_structure/:1:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [6] | CH06 Designing Lock-based Concurrent Data Structure","uri":"/posts/ch06_designing_lock_based_concurrent_data_structure/"},{"categories":["C++"],"content":"thread-safe map 并发访问 std::map 和 std::unordered_map 的接口的问题在于迭代器，其他线程删除元素时会导致迭代器失效，因此 thread-safe map 的接口设计就要跳过迭代器 为了使用细粒度锁，就不应该使用标准库容器。可选的关联容器数据结构有三种，一是二叉树（如红黑树），但每次查找修改都要从访问根节点开始，也就表示根节点需要上锁，尽管沿着树向下访问节点时会解锁，但这个比起覆盖整个数据结构的单个锁好不了多少 第二种方式是有序数组，这比二叉树还差，因为无法提前得知一个给定的值应该放在哪，于是同样需要一个覆盖整个数组的锁 第三种方式是哈希表。假如有一个固定数量的桶，一个 key 属于哪个桶取决于 key 的属性和哈希函数，这意味着可以安全地分开锁住每个桶。如果使用读写锁，就能将并发度提高相当于桶数量的倍数 #include \u003calgorithm\u003e #include \u003cfunctional\u003e #include \u003clist\u003e #include \u003cmap\u003e #include \u003cmemory\u003e #include \u003cmutex\u003e #include \u003cshared_mutex\u003e #include \u003cutility\u003e #include \u003cvector\u003e template \u003ctypename K, typename V, typename Hash = std::hash\u003cK\u003e\u003e class ConcurrentMap { public: // 桶数默认为 19（一般用 x % 桶数作为 x 的桶索引，桶数为质数可使桶分布均匀） ConcurrentMap(std::size_t n = 19, const Hash\u0026 h = Hash{}) : buckets_(n), hasher_(h) { for (auto\u0026 x : buckets_) { x.reset(new Bucket); } } ConcurrentMap(const ConcurrentMap\u0026) = delete; ConcurrentMap\u0026 operator=(const ConcurrentMap\u0026) = delete; V get(const K\u0026 k, const V\u0026 default_value = V{}) const { return get_bucket(k).get(k, default_value); } void set(const K\u0026 k, const V\u0026 v) { get_bucket(k).set(k, v); } void erase(const K\u0026 k) { get_bucket(k).erase(k); } // 为了方便使用，提供一个到 std::map 的映射 std::map\u003cK, V\u003e to_map() const { std::vector\u003cstd::unique_lock\u003cstd::shared_mutex\u003e\u003e locks; for (auto\u0026 x : buckets_) { locks.emplace_back(std::unique_lock\u003cstd::shared_mutex\u003e(x-\u003em)); } std::map\u003cK, V\u003e res; for (auto\u0026 x : buckets_) { for (auto\u0026 y : x-\u003edata) { res.emplace(y); } } return res; } private: struct Bucket { std::list\u003cstd::pair\u003cK, V\u003e\u003e data; mutable std::shared_mutex m; // 每个桶都用这个锁保护 V get(const K\u0026 k, const V\u0026 default_value) const { // 没有修改任何值，异常安全 std::shared_lock\u003cstd::shared_mutex\u003e l(m); // 只读锁，可共享 auto it = std::find_if(data.begin(), data.end(), [\u0026](auto\u0026 x) { return x.first == k; }); return it == data.end() ? default_value : it-\u003esecond; } void set(const K\u0026 k, const V\u0026 v) { std::unique_lock\u003cstd::shared_mutex\u003e l(m); // 写，单独占用 auto it = std::find_if(data.begin(), data.end(), [\u0026](auto\u0026 x) { return x.first == k; }); if (it == data.end()) { data.emplace_back(k, v); // emplace_back 异常安全 } else { it-\u003esecond = v; // 赋值可能抛异常，但值是用户提供的，可放心让用户处理 } } void erase(const K\u0026 k) { std::unique_lock\u003cstd::shared_mutex\u003e l(m); // 写，单独占用 auto it = std::find_if(data.begin(), data.end(), [\u0026](auto\u0026 x) { return x.first == k; }); if (it != data.end()) { data.erase(it); } } }; Bucket\u0026 get_bucket(const K\u0026 k) const { // 桶数固定因此可以无锁调用 return *buckets_[hasher_(k) % buckets_.size()]; } private: std::vector\u003cstd::unique_ptr\u003cBucket\u003e\u003e buckets_; Hash hasher_; }; ","date":"2023-11-28","objectID":"/posts/ch06_designing_lock_based_concurrent_data_structure/:2:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [6] | CH06 Designing Lock-based Concurrent Data Structure","uri":"/posts/ch06_designing_lock_based_concurrent_data_structure/"},{"categories":["C++"],"content":"thread-safe list #include \u003cmemory\u003e #include \u003cmutex\u003e #include \u003cutility\u003e template \u003ctypename T\u003e class ConcurrentList { public: ConcurrentList() = default; ~ConcurrentList() { remove_if([](const Node\u0026) { return true; }); } ConcurrentList(const ConcurrentList\u0026) = delete; ConcurrentList\u0026 operator=(const ConcurrentList\u0026) = delete; void push_front(const T\u0026 x) { std::unique_ptr\u003cNode\u003e t(new Node(x)); std::lock_guard\u003cstd::mutex\u003e head_lock(head_.m); t-\u003enext = std::move(head_.next); head_.next = std::move(t); } template \u003ctypename F\u003e void for_each(F f) { Node* cur = \u0026head_; std::unique_lock\u003cstd::mutex\u003e head_lock(head_.m); while (Node* const next = cur-\u003enext.get()) { std::unique_lock\u003cstd::mutex\u003e next_lock(next-\u003em); head_lock.unlock(); // 锁住了下一节点，因此可以释放上一节点的锁 f(*next-\u003edata); cur = next; // 当前节点指向下一节点 head_lock = std::move(next_lock); // 转交下一节点锁的所有权，循环上述过程 } } template \u003ctypename F\u003e std::shared_ptr\u003cT\u003e find_first_if(F f) { Node* cur = \u0026head_; std::unique_lock\u003cstd::mutex\u003e head_lock(head_.m); while (Node* const next = cur-\u003enext.get()) { std::unique_lock\u003cstd::mutex\u003e next_lock(next-\u003em); head_lock.unlock(); if (f(*next-\u003edata)) { return next-\u003edata; // 返回目标值，无需继续查找 } cur = next; head_lock = std::move(next_lock); } return nullptr; } template \u003ctypename F\u003e void remove_if(F f) { Node* cur = \u0026head_; std::unique_lock\u003cstd::mutex\u003e head_lock(head_.m); while (Node* const next = cur-\u003enext.get()) { std::unique_lock\u003cstd::mutex\u003e next_lock(next-\u003em); if (f(*next-\u003edata)) { // 为 true 则移除下一节点 std::unique_ptr\u003cNode\u003e old_next = std::move(cur-\u003enext); cur-\u003enext = std::move(next-\u003enext); // 下一节点设为下下节点 next_lock.unlock(); } else { // 否则继续转至下一节点 head_lock.unlock(); cur = next; head_lock = std::move(next_lock); } } } private: struct Node { std::mutex m; std::shared_ptr\u003cT\u003e data; std::unique_ptr\u003cNode\u003e next; Node() = default; Node(const T\u0026 x) : data(std::make_shared\u003cT\u003e(x)) {} }; Node head_; }; ","date":"2023-11-28","objectID":"/posts/ch06_designing_lock_based_concurrent_data_structure/:3:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [6] | CH06 Designing Lock-based Concurrent Data Structure","uri":"/posts/ch06_designing_lock_based_concurrent_data_structure/"},{"categories":["C++"],"content":"进程 在进程模型中，计算机上所有可运行的软件，通常也包括操作系统，被组织成若干顺序进程(sequential process)，简称进程(process)，一个进程就是就是一个正在执行程序的实例，包括程序计数器、寄存器和变量的当前值 概念上来说，每个进程有自己的虚拟 CPU，但实际上真正的 CPU(假设只有一个 CPU)在各进程之间来回切换，同一时刻实际只有一个进程在运行 实际只有一个物理程序计数器。每个进程运行时，它的逻辑程序计数器被装入实际的程序计数器。当进程结束时，物理程序计数器保存到内存中该进程的逻辑程序计数器中 进程创建主要有四种形式 系统初始化：启动系统时会创建若干进程，包括和用户交互的前台进程和停在后台的守护进程，守护进程可以通过 UNIX 的 ps 指令或 Window 的任务管理器查看 运行中的程序执行创建进程的系统调用：比如启动一个程序，该程序要启动更多进程来分配任务 用户请求创建一个新进程：比如用户双击图标启动程序 大型机批处理作业的初始化 创建进程的系统调用在 UNIX 中是 fork，在 Windows 中是 CreateProcess，进程创建后，父子进程有不同的地址空间 进程终止通常也有四种形式 正常退出(自愿的)：比如点击浏览器的关闭图标。进程退出的系统调用在 UNIX 中是 exit，在 Windows 中是 ExitProcess 出错退出(自愿的)：比如执行 cc foo.c 编译 foo.c 而该文件不存在 严重错误(非自愿)：比如执行非法指令、引用不存在的内存、除数是零，UNIX中会希望自行处理这些错误以通知操作系统，进程会收到信号被中断而非终止 被其他进程杀死(非自愿)：UNIX 中是 kill，Windows 中是 TerminateProcess UNIX中，进程和其所有子进程(包括其后裔)组成一个进程组，当用户发出一个键盘信号，该信号会发送给进程组所有成员 Windows中没有进程层次的概念，所有进程地位相同 进程阻塞有两种情况，一是正常情况，比如操作系统调度另一个进程占用 CPU，二是异常情况，比如没有足够的 CPU 可调用 进程有三种状态：运行、就绪、阻塞 运行 \u003c-\u003e 就绪 ↘ ↗ 阻塞 运行：该时刻实际占用 CPU 就绪：操作系统调度了其他进程运行而暂时停止 阻塞：逻辑上不能继续运行，比如等待用户输入 操作系统通过维护一张进程表(一个结构数组)来实现进程模型，每个进程占一个表项(即进程控制块，Processing Control Block)。PCB 包含了进程状态的主要信息，如程序计数器、堆栈指针、内存分配状态、所打开的文件状态、账号和调度信息、进程状态切换时必须保存的信息 所有中断都从保存寄存器开始，通常会保存到当前进程的 PCB 中。一个进程在执行过程中可能中断几千次，但恢复时，被中断的进程都将返回到与中断发生前完全相同的状态 发生中断后，操作系统最底层的工作过程 中断硬件将程序计数器、程序状态字、寄存器压入堆栈 硬件从中断向量装入新的程序计数器 通过汇编保存寄存器值(因为这类操作无法用高级语言完成) 通过汇编设置新的堆栈 运行C语言(假设操作系统用C编写)中断服务例程 调用调度程序，决定接下来要运行的进程 C返回到汇编 通过汇编运行新进程 假设一个进程等待 I/O 操作与其在内存中停留的时间比为 p，则 n 个进程都在等待(此时 CPU 空转)的概率为 p ^ n，CPU 利用率为 1 - p ^ n，因此一般(该模型只是粗略情况)I/O 时间越短、运行进程越多，CPU 利用率越高 假如内存为 8G，操作系统和相关表格占 2G，用户程序也占 2G，内存最多容纳 3 个用户程序 假设 80% 时间用于等待 I/O 操作 CPU 利用率 = 1 - 0.8 ^ 3 = 49% 如果增加 8G 内存，则最多容纳 7 个用户程序 CPU 利用率 = 1 - 0.8 ^ 7 = 79%，吞吐量提高为 79% - 49% = 30% 如果再增加 8G 内存，则最多容纳 11 个用户程序 CPU 利用率 = 1 - 0.8 ^ 11 = 91%，吞吐量只提高了 12%，可见第一次增加内存比较划算 ","date":"2023-11-19","objectID":"/posts/processesandthreads/:1:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Processes and Threads","uri":"/posts/processesandthreads/"},{"categories":["C++"],"content":"线程 正如进程提供的抽象使得避免了对中断、定时器、上下文切换的考虑，多线程提供了一种新抽象，即并行实例共享同一地址空间和所有可用数据，这正是多进程模型(地址空间不同)无法表达的 第二个需要多线程的理由是，线程更轻量，创建和撤销都更快(通常创建一个线程比创建一个进程快 10 - 100 倍) 第三个理由是多核 CPU 系统中，多线程为真正的并行提供了可能 线程包含一个程序计数器(记录接下来要执行哪一条指令)、寄存器(保存线程当前的工作变量)、堆栈指针(记录执行历史，每个线程的堆栈有一帧，每一帧保存一个已调用但还未返回的过程，如局部变量、返回地址) 各线程可以访问进程地址空间的每一个内存地址，因此一个线程可以读写甚至清除另一个线程的堆栈。线程之间没有保护，因为不可能，也没必要 除了共享地址空间，线程还共享同一个打开文件集、子进程、定时器及相关信号量 线程可以处在运行、就绪、阻塞、终止等状态中的任何一个 thread_yield 允许线程自动放弃 CPU 转让给另一个线程运行，提供这个调用是因为，不同于进程，线程库不能利用时钟中断强制线程让出 CPU 实现线程包主要有两种方式，一是用户级线程(User-Level Thread)，二是内核级线程(Kernel-Level Thread)，另外也有混合实现 用户级线程把整个线程包放在用户空间中，内核对其一无所知，不需要内核支持，可以在不支持线程的操作系统上实现。在用户空间管理线程时，每个进程需要有其专用的线程表(thread table)，这些表和内核中的进程表类似，只不过记录的是各个线程的属性，如程序计数器、寄存器、堆栈指针和状态等。该线程表由运行时系统管理，当线程转换到就绪或阻塞状态时，在线程表中存放重启该线程所需的信息，与内核在进程表中存放进程的信息完全一样 用户级线程允许进程有自己定制的调度算法，具有更好的可扩展性(因为内核级线程需要一些固定表格空间和堆栈空间)，性能更好。用户级线程的切换需要少量机器指令，而内核级线程需要完整的上下文切换，修改内存映像，使高速缓存失效，这导致了若干数量级的延迟 用户级线程的问题是如何实现阻塞系统调用，比如线程读取键盘，在没有按下任何按键之前不能让该线程实际进行该系统调用，因为这会停止所有线程。另一个问题是，如果一个线程开始运行，则其所在进程的其他线程就不能运行，除非运行线程自动放弃 CPU。而使用内核级线程时，线程阻塞在 I/O 上时，不需要将整个进程挂起 内核级线程的线程表(和用户级线程的线程表一样，记录寄存器、状态和其他信息)存在于内核中，当一个线程希望创建一个新线程或撤销一个已有线程时，将进行一个系统调用，这个系统调用通过对线程表的更新完成创建或撤销工作 当内核级线程阻塞时，内核可以运行同一进程中的另一线程，或者运行另一个进程的线程。而对于用户级线程，运行时系统始终运行其所在进程的线程，直到内核剥夺 CPU(或没有可运行的线程存在)为止 在内核中创建或撤销线程的代价较大，因此内核级线程被撤销时，系统会将其标记为不可运行的，但其内核数据结构未受影响，之后必须创建新线程时就重新启动一个旧线程。用户级线程也可以这样回收，但因为管理代价很小，所以没必要 ","date":"2023-11-19","objectID":"/posts/processesandthreads/:2:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Processes and Threads","uri":"/posts/processesandthreads/"},{"categories":["C++"],"content":"进程间通信(Inter Process Communication) 对共享内存进行访问的程序片段称为临界区(critical region、critical section)，如果同一时刻临界区只有一个进程，就能避免 race condition 单处理器系统中实现这点的简单做法是，在每个进程刚进入临界区后立即屏蔽所有中断，在即将离开时再打开中断。屏蔽中断后，时钟中断也被屏蔽。CPU 只有发生时钟中断或其他中断才会进行进程切换，这样 CPU 就不会切换到其他进程 但这个方案并不好，因为把屏蔽中断的权力交给用户进程是不明智的，如果一个进程屏蔽中断后不打开，就可能导致整个系统终止。此外如果系统是多处理器，则屏蔽中断只对执行了 disable 指令的 CPU 有效，其他 CPU 仍将运行 对于内核来说，更新变量或列表的几条指令期间屏蔽中断很方便，因此屏蔽中断对操作系统本身是一项很有用的技术，但对用户进程则不是一种合适的互斥机制 第二种方式是一种软件方案，假设有一个共享锁变量，其初始值为 0，当进程要进入临界区时，首先测试锁，如果值为 0 则将锁设为1并进入临界区，如果锁的值已经为 1，则进程等待其值为 0 这种方式的问题在于，如果在一个进程检查到锁为 0，并要将锁设为 1 之前，恰好另一个线程被调度运行将锁设为 1，而第一个进程恢复运行时也将把锁设为 1 并进入临界区，此时临界区就有了两个进程 第三种方式是忙等待(busy waiting)，用一个循环不断测试变量值，直到变量值改变才进入临界区，用于忙等待的锁称为自旋锁(spin lock)。这种方式的问题是，在循环中浪费了大量 CPU 时间，应该避免，除非等待时间非常短才有使用的理由 // 进程 A while (true) { while (x) { } critical_region(); x = true; // 允许进程 B 进入临界区 noncritical_region(); } // 进程 B while (true) { while (!x) { } critical_region(); x = false; // 允许进程 A 进入临界区 noncritical_region(); } 第四种方式是 1981 年由 G. L. Peterson 提出的 Peterson 算法 constexpr int N = 2; // 进程数量为2 int turn = 0; // 轮到的进程 vector\u003cbool\u003e interested(N); void enter_region(int process) { int other = 1 - process; // 另一进程(进程号为 0 或 1) interested[process] = true; turn = process; // turn 只有一个，即使两个进程调用也只有后一个赋值会保留 while (turn == process \u0026\u0026 interested[other]) { } } void leave_region(int process) { // 调用上述函数完成后调用此函数 interested[process] = false; } // 若进程 A 调用 enter_region 则很快返回， // 此时进程 B 调用将在 while 循环挂起， // 直到进程 A 调用 leave_region // 若进程 AB 同时调用 enter_region， // turn 为后赋值者， // 则先赋值者退出循环并调用 leave_region，后赋值者再退出循环 第五种方式是一种硬件方式，需要借助 TSL 指令，即测试并加锁(test and set lock)，该指令是一个原子操作，执行 TSL 指令的 CPU 将锁住内存总线以禁止其他 CPU 在指令结束前访问该内存 TSL RX, LOCK // 将内存字 LOCK 读到寄存器 RX 中，然后在该内存地址写一个非零值，读写是原子操作 为了使用 TSL 指令实现互斥，用一个共享变量 LOCK 来协调对内存的访问，其值为 0 时任何进程都能用 TSL 指令将值设为 1 并读写共享内存，操作结束时再用 move 指令将值重置为 0 enter_region: TSL REGISTER, LOCK ;复制锁到寄存器并设置值为 1 CMP REGISTER, #0 ;值是否为 0 JNE enter_region ;不是 0 则循环 RET ;返回，进入临界区 leave_region: MOVE LOCK, #0 RET 可以用 XCHG 指令替代 TSL 指令，它原子交换两个位置的内容 enter_region: MOVE REGISTER, #1 ;在寄存器放一个 1 XCHG REGISTER, LOCK ;原子交换寄存器和锁变量的内容 CMP REGISTER, #0 ;值是否为 0 JNE enter_region ;不是 0 则循环 RET ;返回，进入临界区 leave_region: MOVE LOCK, #0 RET Peterson 算法和 TSL 或 XCHG 解法同样都有忙等待的问题，它们的本质都是在进程进入临界区时检查是否允许进入，不允许则原地等待直到允许为止 ","date":"2023-11-19","objectID":"/posts/processesandthreads/:3:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Processes and Threads","uri":"/posts/processesandthreads/"},{"categories":["C++"],"content":"生产者-消费者问题 两个进程共享一个固定大小的缓冲区，生产者进程将消息放入缓冲区，消费者进程从缓冲区取出消息 constexpr int N = 100; // 缓冲区的槽数 int cnt = 0; // 缓冲区数据数 void producer() { while (true) { int item = produce_item(); // 生成新数据 if (cnt == N) { sleep(); } insert_item(item); // 将消息放入缓冲区 ++cnt; // 1 if (cnt == 1) { wakeup(consumer); // 2 } } } void consumer() { while (true) { if (!cnt) { sleep(); // 3 } int item = remove_item(); // 从缓冲区取一个数据 --cnt; if (cnt == N - 1) { wakeup(producer); } consume_item(item); // 打印数据 } } // 问题在于 cnt 的访问存在 race condition， // 如果消费者执行到 3 处，cnt 为 0，在即将 sleep 之前， // 生产者在此之后才执行到 1 处，此时 cnt 为 1，执行到 2 处，调用 wakeup， // 但此时消费者还未 sleep，因此 wakeup 的信号丢失，没有实际作用， // 接着消费者 sleep，生产者开始下一轮循环， // 生产者下一轮循环到 1 处，cnt 为 2，到 2 处，不再调用 wakeup，消费者保持 sleep， // 生产者继续之后的循环，并且每一轮都不会唤醒消费者， // 最终生产者执行到 cnt 为 N 时 sleep，两个进程都将永久 sleep ","date":"2023-11-19","objectID":"/posts/processesandthreads/:4:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Processes and Threads","uri":"/posts/processesandthreads/"},{"categories":["C++"],"content":"信号量(semaphore) 信号量是由 E. W. Dijkstra 于 1965 年提出的一种方法，它使用一个整型变量作为信号量，值为 0 表示没有保存下来的唤醒操作，值为正数表示唤醒操作的次数 信号量有 down 和 up 两种操作，Dijkstra 在论文中称其为 P 和 V 操作(荷兰语中的 Proberen 意为尝试，Verhogen 意为增加或升高) down 操作检查值是否大于 0，若大于 0 则减 1 并继续，若为 0 则进程睡眠，并且此时 down 操作未结束 up 操作对值加 1。如果有进程在信号量上睡眠，无法完成一个先前的 down 操作，则由系统选择其中一个以允许完成其 down 操作。于是，对一个有睡眠进程的信号量执行一次 up 操作，信号量值仍为 0，但睡眠进程少了一个 down 操作和 up 操作中的所有操作都是原子的，一般作为系统调用实现。操作系统只要在执行测试信号量、更新信号量、使进程睡眠等操作时暂时屏蔽全部中断，这些动作只需要几条指令，所以屏蔽中断不会带来什么副作用。如果使用多个 CPU，则每个信号量应由一个一个锁保护，使用 TSL 或 XCHG 指令来确保同一时刻只有一个 CPU 对信号量进行操作 注意，这里使用 TSL 或 XCHG 指令来防止多 CPU 同时访问一个信号量，与生产者或消费者用忙等待来等待对方腾出或填充缓冲区是完全不同的。信号量操作只需要几毫秒，而生产者或消费者则可能需要任意长时间 使用三个信号量解决生产者-消费者问题：full 记录已充满的缓冲槽数，初值为 0；empty 记录空的缓冲槽数，初值为缓冲区中槽的数目；mutex 确保生产者和消费者不会同时访问缓冲区，初值为 1 供多个进程使用的信号量初值为 1，保证同时只有一个进程可以进入临界区，这种信号量称为二元信号量(binary semaphore)。如果每个进程进入临界区前执行一个 down 操作，并在刚退出时执行一个 up 操作，就能实现互斥 constexpr int N = 100; // 缓冲区的槽数 using semaphore = int; semaphore mutex = 1; semaphore empty = N; // 缓冲区空槽数 semaphore full = 0; // 缓冲区满槽数 void producer() { while (true) { int item = produce_item(); down(\u0026empty); down(\u0026mutex); insert_item(item); up(\u0026mutex); up(\u0026full); } } void consumer() { while (true) { down(\u0026full); down(\u0026mutex); int item = remove_item(); up(\u0026mutex); up(\u0026empty); consume_item(item); } } 信号量的另一个作用是实现同步(synchronization)，这里 full 和 empty 保证缓冲区满时生产者停止运行，缓冲区空时消费者停止运行 ","date":"2023-11-19","objectID":"/posts/processesandthreads/:5:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Processes and Threads","uri":"/posts/processesandthreads/"},{"categories":["C++"],"content":"互斥量(mutex) 如果不需要信号量的计数功能，可以使用其称为互斥量的简化版本。互斥量仅适用于管理共享资源或一小段代码。互斥量实现简单且有效，在实现用户空间线程包时十分有用 互斥量只有加锁和解锁两种状态，只需要一个二进制位表示，不过实际上一般用整型量，0 表示解锁，其他值表示加锁 线程需要访问临界区时调用 mutex_lock，如果互斥量是解锁的则临界区可用，调用成功，线程可以进入临界区，否则线程被阻塞，直到临界区中的线程完成并调用 mutex_unlock。如果多个线程阻塞在该互斥量上，则随机选择一个线程并允许它获得锁 用 TSL 或 XCHG 指令就可以很容易地在用户空间实现互斥量 mutex_lock: TSL REGISTER, MUTEX ;将互斥量复制到寄存器，并将互斥量置为 1 CMP REGISTER, #0 JZE ok ;如果互斥量为 0，它被解锁，所以返回 CALL thread_yield ;互斥量忙，调度另一个线程 JMP mutex_lock ;稍后再试 ok: RET mutex_unlock: MOVE MUTEX, #0 ;将互斥量置0 RET thread_yield 只是调用用户空间线程调度程序，运行十分快捷，这样 mutex_lock 和 mutex_unlock 都不需要任何内核调用。用户级线程通过互斥量的这个过程即可实现同步，而同步过程仅需要少量指令 ","date":"2023-11-19","objectID":"/posts/processesandthreads/:6:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Processes and Threads","uri":"/posts/processesandthreads/"},{"categories":["C++"],"content":"管程(monitor) 如果把生产者代码中的两个 down 操作交换顺序，使得 mutex 在 empty 之前减 1，就会导致死锁，因此使用信号量要十分小心。为了更易于编写正确的程序，Brinch Hansen 和 Hoare 提出了一种称为管程的高级同步原语 一个管程是由过程、变量、数据结构等组成的一个集合，它们组成一个特殊的模块或软件包，进程可以在任何需要的时候调用管程中的过程，但不能在管程之外声明的过程中直接访问管程内的数据结构 任一时刻管程中只能有一个活跃进程，这一特性使得管程能有效地完成互斥。管程是编程语言的组成部分，编译器知道其特殊性，进入管程时的互斥由编译器负责，通常做法是使用互斥量或二元信号量。这样就不需要程序员安排互斥，出错的可能性就小很多 管程提供了互斥的简便途径，但此外还需要一种方法使得进程在无法继续运行时被阻塞，这个方法就是引入条件变量(condition variable) 当一个管程过程发现它无法继续运行时(如生产者发现缓冲区满)，则会在某个条件变量(如 full)上执行 wait 操作，该操作将阻塞当前进程，并将另一个在管程外的进程调入管程。另一个进程可以通过对同一条件变量执行 signal 操作唤醒阻塞进程 为了避免管程中有两个活跃进程，执行 signal 操作之后有两种规则。Hoare 建议让新唤醒的进程运行，挂起另一个进程。Brinch Hansen 建议执行 signal 的进程必须立即退出管程，即 signal 语句只能作为一个管程过程的最后一条语句。后者在概念上更简单，并且更容易实现。第三种方法是，让发信号者继续运行，直到其退出管程，才允许等待的进程开始运行 如果一个条件变量上有若干进程正在等待，则对其执行 signal 操作之后，系统调度程序只能选择其中一个恢复运行 如果一个条件变量没有等待进程，则对其执行 signal 会丢失信号，因此 wait 操作必须在 signal 之前。这与之前提到的 sleep 和 wakeup 的关键区别是，管程的自动互斥保证了在 wait 完成之前不会先 signal ","date":"2023-11-19","objectID":"/posts/processesandthreads/:7:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Processes and Threads","uri":"/posts/processesandthreads/"},{"categories":["C++"],"content":"消息传递(message passing) 管程和信号量通过共享内存解决 CPU 互斥问题，但没有提供不同机器间(比如局域网中的机器)的信息交换方法 消息传递使用 send 和 receive 原语来实现进程间通信，它们像信号量而不像管程，是系统调用而非语言成分 send(destination, \u0026message); receive(source, \u0026message); send 向一个给定目标发送一条消息，receive 从一个给定源(或者任意源)接收一条消息，如果没有消息可用则接收者可能被阻塞直至有一条消息到达，或者带着一个错误码立即返回 消息传递系统面临许多设计难点：比如消息可能被网络丢失，需要三次握手来确认信息到达情况；比如发送方未收到确认，因此重发消息导致接收方收到两条相同消息，接收方需要区分新老消息；比如身份认证(authentication)问题，客户端如何确认通信的是一个文件服务器还是冒充者 消息传递方式可以有许多变体，一种对消息进行编址的方式是，为每个进程分配一个唯一地址，让消息按进程的地址编址。另一种方式是引入一种称为信箱(mailbox)的数据结构，用来对一定数量的消息进行缓冲。使用信箱时，send 和 receive 调用的地址参数就是信箱而非进程的地址 constexpr int N = 100; void producer() { message m; // 消息缓冲区 while (true) { int item = produce_item(); receive(consumer, \u0026m); // 等待消费者发送空缓冲区 build_message(\u0026m, item); // 建立一个待发送的消息 send(consumer, \u0026m); // 发送数据项给消费者 } } void consumer() { message m; for (int i = 0; i \u003c N; ++i) { send(producer, \u0026m); // 发送 N 个空缓冲区 } while (true) { receive(producer, \u0026m); // 接收包含数据项的消息 int item = extract_item(\u0026m); // 将数据项从消息中提取出来 send(producer, \u0026m); // 将空缓冲区发送回生产者 consume_item(item); } } 使用信箱的另一种极端方法是彻底取消缓冲。采取这种方法时，如果 send 在 receive 之前执行则发送进程被阻塞，直到 receive 发生，反之亦然。执行 receive 时，消息可以直接从发送者复制到接收者，不用任何中间缓冲。这种方案常被称为会和(rendezvous)，实现起来更容易，但降低了灵活性，因为发送者和接收者一定要以步步紧接的方式运行 通常在并行程序设计系统中使用消息传递，一个著名的消息传递系统是消息传递接口(Message-Passing Interface，MPI)，它广泛应用于科学计算 ","date":"2023-11-19","objectID":"/posts/processesandthreads/:8:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Processes and Threads","uri":"/posts/processesandthreads/"},{"categories":["C++"],"content":"屏障(barrier) 屏障是一种用于进程组的同步机制，只有所有进程就绪时才能进入下一阶段。每个阶段的结尾设置一个屏障，当一个进程到达屏障时将被阻拦，直到所有进程到达屏障为止 ","date":"2023-11-19","objectID":"/posts/processesandthreads/:9:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Processes and Threads","uri":"/posts/processesandthreads/"},{"categories":["C++"],"content":"调度 几乎所有进程的 I/O 请求和计算都是交替突发的，如果进程花费大量时间在计算上，则称为计算密集型(compute-bound)，如果大量时间花费在等待 I/O 上，则称为 I/O 密集型(I/O-bound) 随着 CPU 变得越来越快，更多的进程倾向为 I/O 密集型。这种现象的原因是 CPU 的改进比磁盘的改进快得多，所以未来对 I/O 密集型进程的调度处理更为重要 调度的基本思想是，如果需要运行 I/O 密集型进程，就应该让它尽快得到机会，以便发出磁盘请求并保持磁盘始终忙碌 根据如何处理时钟中断，可以把调度算法分为非抢占式和抢占式两类 非抢占式调度算法挑选一个进程，然后让该进程运行直至阻塞，或直到该进程自动释放 CPU。即使该进程运行了几个小时也不会被强迫挂起，这样导致时钟中断发生时不会进行调度。在处理完时钟中断后，如果没有更高优先级的进程，则被中断的进程将继续运行 抢占式调度算法挑选一个进程，让该进程运行某个固定时段的最大值，时段结束时将挂起该进程，并挑选另一个进程运行。抢占式调度需要在时间间隔的末端发生时钟中断，以便把 CPU 控制返回给调度程序，如果没有可用的时钟，就只能选择非抢占式调度 不同的应用领域有不同的目标，也就需要不同的调度算法。环境可以划分为三种 批处理：广泛用于商业领域，比如处理薪水清单、账目收入、账目支出、利息计算，批处理系统不会有用户在旁边急切等待响应，因此通常使用非抢占式算法，或对每个进程都有长时间周期的抢占式算法，这样减少了进程切换从而改进了性能 交互式：必须使用抢占式算法，以避免 CPU 被一个进程霸占而拒绝为其他进程服务。服务器也归于此类，因为通常要服务多个突发的远程用户 实时：有时不需要抢占，因为进程了解它们可能会长时间得不到运行，所以通常很快地完成各自工作并阻塞 ","date":"2023-11-19","objectID":"/posts/processesandthreads/:10:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Processes and Threads","uri":"/posts/processesandthreads/"},{"categories":["C++"],"content":"调度算法的评价指标 对于批处理系统，调度算法的评价指标主要有三个 吞吐量(throughout)：系统单位时间内完成的作业数量，比如 10 道作业花费 100 秒，则吞吐量为 0.1 道/秒 周转时间(turnaround time)：一个批处理作业从提交开始到完成的统计平均时间 CPU 利用率：CPU 忙碌时间相对总时间的占比 对于交互式系统，评价指标最重要的是最小响应时间，即从发出命令到得到响应之间的时间 实时系统的特点是或多或少必须满足截止时间，多数实时系统中，可预测性十分重要，比如如果多媒体实时系统的音频进程运行错误太多，音质就会明显下降，为此实时系统的调度算法必须是高度可预测和有规律的 ","date":"2023-11-19","objectID":"/posts/processesandthreads/:11:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Processes and Threads","uri":"/posts/processesandthreads/"},{"categories":["C++"],"content":"批处理系统中的调度 ","date":"2023-11-19","objectID":"/posts/processesandthreads/:12:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Processes and Threads","uri":"/posts/processesandthreads/"},{"categories":["C++"],"content":"先来先服务(First-Come First-Served，FCFS) 非抢占式。进程按照请求 CPU 的先后顺序调度，优点是公平，算法实现简单，不会导致进程饥饿(Starvation，等待时间对进程响应带来明显影响) 进程 到达时间 运行时间 P1 0 7 P2 2 4 P3 4 1 P4 5 4 先到先服务，因此调度顺序为 P1 -\u003e P2 -\u003e P3 -\u003e P4 P1 P2 P3 P4 ------- ---- - ---- 周转时间 = 完成时间 - 到达时间 P1 = 7 - 0 = 7 P2 = 11 - 2 = 9 P3 = 12 - 4 = 8 // 只运行 1，却需要等待 8，可见 FCFS 算法对短作业不利 P4 = 16 - 5 = 11 平均周转时间 = 8.75 带权周转时间 = 周转时间 / 运行时间 P1 = 7 / 7 = 1 P2 = 9 / 4 = 2.25 P3 = 8 / 1 = 8 P4 = 11 / 4 = 2.75 平均带权周转时间 = 3.5 等待时间 = 周转时间 - 运行时间(不考虑等待 I/O 操作的时间) P1 = 7 - 7 = 0 P2 = 9 - 4 = 5 P3 = 8 - 1 = 7 P4 = 11 - 4 = 7 平均等待时间 = 4.75 ","date":"2023-11-19","objectID":"/posts/processesandthreads/:12:1","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Processes and Threads","uri":"/posts/processesandthreads/"},{"categories":["C++"],"content":"最短作业优先(Shortest Job First，SJF) 非抢占式。选择已到达的且运行时间最短的进程，运行时间相同则先到达的先运行。目标是追求最短的平均周转时间、平均带权周转时间、平均等待时间，缺点是不公平，对短作业有利，对长作业不利，如果一直有短作业到达可能导致长作业饥饿 进程 到达时间 运行时间 P1 0 7 P2 2 4 P3 4 1 P4 5 4 P1 先到达，P1 运行结束时 P2、P3、P4 均到达，P3 运行时间最短先运行 P2、P4 运行时间相同，P2 先到达，因此 P2 先于 P4 运行 最终调度顺序为 P1 -\u003e P3 -\u003e P2 -\u003e P4 P1 P3 P2 P4 ------- - ---- ---- 周转时间 = 完成时间 - 到达时间 P1 = 7 - 0 = 7 P2 = 12 - 2 = 10 P3 = 8 - 4 = 4 P4 = 16 - 5 = 11 平均周转时间 = 8 带权周转时间 = 周转时间 / 运行时间 P1 = 7 / 7 = 1 P2 = 10 / 4 = 2.5 P3 = 4 / 1 = 4 P4 = 11 / 4 = 2.75 平均带权周转时间 = 2.56 等待时间 = 周转时间 - 运行时间(不考虑等待 I/O 操作的时间) P1 = 7 - 7 = 0 P2 = 10 - 4 = 6 P3 = 4 - 1 = 3 P4 = 11 - 4 = 7 平均等待时间 = 4 ","date":"2023-11-19","objectID":"/posts/processesandthreads/:12:2","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Processes and Threads","uri":"/posts/processesandthreads/"},{"categories":["C++"],"content":"最短剩余时间优先(Shortest Remaining Time Next，SRTN) SRTN 是 SJF 的抢占式版本，每当新进程加入时，调度程序总是选择剩余运行时间最短的进程运行，如果当前进程剩余运行时间比新进程长，则挂起当前进程而运行新进程 进程 到达时间 运行时间 P1 0 7 P2 2 4 P3 4 1 P4 5 4 P2 到达时，P1 剩余 5，P2 为 4，运行 P2 P3 到达时，P1 剩余 5，P2 剩余 2，P3 为 1，运行 P3 P4 到达时，P3 运行结束，P1 剩余 5，P2 剩余 2，P4 为 4，运行 P2 最后依次运行 P4 和 P1 最终调度顺序为 P1 -\u003e P2 -\u003e P3 -\u003e P2 -\u003e P4 -\u003e P1 P1 P2 P3 P2 P4 P1 -- -- - -- ---- ----- 周转时间 = 完成时间 - 到达时间 P1 = 16 - 0 = 16 P2 = 7 - 2 = 5 P3 = 5 - 4 = 1 P4 = 11 - 5 = 6 平均周转时间 = 7 带权周转时间 = 周转时间 / 运行时间 P1 = 16 / 7 = 2.29 P2 = 5 / 4 = 1.25 P3 = 1 / 1 = 1 P4 = 6 / 4 = 1.5 平均带权周转时间 = 1.51 等待时间 = 周转时间 - 运行时间(不考虑等待 I/O 操作的时间) P1 = 16 - 7 = 9 P2 = 5 - 4 = 1 P3 = 1 - 1 = 0 P4 = 6 - 4 = 2 平均等待时间 = 3 ","date":"2023-11-19","objectID":"/posts/processesandthreads/:12:3","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Processes and Threads","uri":"/posts/processesandthreads/"},{"categories":["C++"],"content":"高响应比优先(Highest Response Ratio Next，HRRN) 非抢占式。在所有已到达进程中选择响应比(等待时间 / 运行时间 + 1)最高的运行，综合 FCFS 和 SJF 的优点，等待时间长、运行时间短的优先，避免长作业饥饿的问题 进程 到达时间 运行时间 P1 0 7 P2 2 4 P3 4 1 P4 5 4 响应比 = (等待时间 + 运行时间) / 运行时间 P1 运行至结束，P2、P3、P4 均到达，响应比分别为 P2 = (5 + 4) / 4 = 2.25 P3 = (3 + 1) / 1 = 4 P4 = (2 + 4) / 4 = 1.5 运行 P3，P3 结束时，响应比分别为 P2 = (6 + 4) / 4 = 2.5 P4 = (3 + 4) / 4 = 1.75 运行 P2，最后运行 P4 最终调度顺序为 P1 -\u003e P3 -\u003e P2 -\u003e P4 P1 P3 P2 P4 ------- - ---- ---- ","date":"2023-11-19","objectID":"/posts/processesandthreads/:12:4","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Processes and Threads","uri":"/posts/processesandthreads/"},{"categories":["C++"],"content":"交互式系统中的调度 ","date":"2023-11-19","objectID":"/posts/processesandthreads/:13:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Processes and Threads","uri":"/posts/processesandthreads/"},{"categories":["C++"],"content":"时间片轮转调度(Round-Robin Scheduling，RR) RR 是一种简单公平的抢占式调度算法，并且可以避免饥饿。每个进程被分配一个时间片(quantum)。时间片结束时，如果进程还在运行，则剥夺 CPU 并分配给另一个进程。如果进程在时间片结束前阻塞或结束，则 CPU 立即切换。RR 算法实现很容易，只需要维护一张进程队列表 A -\u003e B -\u003e C -\u003e D 若 A 用完时间片，但仍在运行，则插入到队列尾 B -\u003e C -\u003e D -\u003e A 若 B 用完时间片，但仍在运行，并到达一个新进程 E，则先插入新进程 C -\u003e D -\u003e A -\u003e E -\u003e B 若 C 用完时间片之前就结束了，则直接切换到下一个进程 D -\u003e A -\u003e E -\u003e B 需要考虑的是时间片的长度，假设时间片为 4 ms，上下文切换为 1 ms，则 CPU 完成 4 ms 工作后将浪费 1 ms 进行上下文切换(context switch)，即浪费了 20% 的时间。但如果时间片太大，就会退化为 FCFS，导致增大响应时间。通常为了提高 CPU 效率，设置时间片时，切换开销占比应不超过 1% ","date":"2023-11-19","objectID":"/posts/processesandthreads/:13:1","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Processes and Threads","uri":"/posts/processesandthreads/"},{"categories":["C++"],"content":"优先级调度 为每个进程设置优先级，在已到达进程中，选择优先级最高的运行，可以为抢占式或非抢占式 比如对于操作系统来说，I/O 密集型进程的优先级应该更高。I/O 密集型继承多数时间用于等待 I/O 结束，因此需要 CPU 时应立即分配给它以便启动下一个 I/O 请求，这样就可以在另一个进程计算的同时执行 I/O 操作 一种简单做法是将优先级设置为 1 / f，f 为该进程在上一时间片中的运行时间占比。比如在 50 ms 时间片中，使用 1 ms 的进程优先级为 50，使用 25 ms 的进程优先级为 2。将进程按优先级分组，再使用 RR 算法调度高优先级组中的进程 ","date":"2023-11-19","objectID":"/posts/processesandthreads/:13:2","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Processes and Threads","uri":"/posts/processesandthreads/"},{"categories":["C++"],"content":"多级反馈队列调度 CTSS(Compatible Time Sharing System)是最早使用优先级调度的系统之一，但存在进程切换速度太慢的问题，其设计者意识到设置较长的时间片可以减少切换次数，但长时间片又会影响到响应时间。最终的解决方法是多级反馈队列调度，它是对 FCFS、SJF、RR、优先级调度的折中权衡 设置多个优先级队列，每个级别对应不同长度的时间片，比如第一级(最高级)时间片为 1，第二级为 2，第三级为 4，以此类推 如果一个进程用完当前级别时间片后仍未运行完，则加入下一级队列队尾，如果已经位于最后一级则放回该级队尾 高优先级队列为空时，才会调度低优先级队列，因此可能导致低优先级进程饥饿 比如一个进程需要 100 个时间片，第一次分配 1 个时间片，第二次分配 2 个，接下来是 4、8、16、32、64，最后一次使用 64 中的 37 个即可结束工作，一共进行 7 次切换。如果使用 RR 算法，则需要 100 次切换 ","date":"2023-11-19","objectID":"/posts/processesandthreads/:13:3","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Processes and Threads","uri":"/posts/processesandthreads/"},{"categories":["C++"],"content":"最短进程优先 关键在于如何从可运行进程中找出最短的一个 一种方法是根据过去的行为进行预测。假设某终端每条命令的估计运行时间为 T0，测量到下一次运行时间为 T1，则估计时间可以修正为 a * T0 + (1 - a) * T1，比如设 a 为 1 / 2 可以得到序列如下 T0 T0/2 + T1/2 T0/4 + T1/4 + T2/2 T0/8 + T1/8 + T2/4 + T3/2 // T0 在此时估计时间中的占比下降到 1/8 ","date":"2023-11-19","objectID":"/posts/processesandthreads/:13:4","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Processes and Threads","uri":"/posts/processesandthreads/"},{"categories":["C++"],"content":"保证调度 向用户作出明确的性能保证，然后实现它。比如有 n 个进程运行的单用户系统中，如果所有进程等价，则每个进程获得 1 / n 的CPU时间，为了实现所作的保证，系统跟踪每个进程已使用的 CPU 时间，并计算应获得的时间，然后转向已用时间最少的进程，直到超过最接近的竞争者 ","date":"2023-11-19","objectID":"/posts/processesandthreads/:13:5","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Processes and Threads","uri":"/posts/processesandthreads/"},{"categories":["C++"],"content":"彩票调度(Lottery Scheduling) 保证调度的想法不错，但很难实现。彩票调度既可以给出类似预测结果，并且实现非常简单。其基本思想是为进程提供各种系统资源(如 CPU 时间)的彩票，一旦需要做出调度决策时，就随机抽出一张彩票，拥有该彩票的进程获取该资源 比如系统掌握每秒 50 次的一种彩票，作为奖励每个获奖者可以获得 20 ms 的 CPU 时间 可以给更重要的进程额外的彩票，以增加其获胜的机会，比如出售 100 张彩票，一个进程持有其中 20 张，则每次抽奖该进程就有 20% 的取胜机会，在较长运行时间中该进程就会得到 20% 的 CPU 彩票调度可以解决其他方法很难解决的问题，比如一个视频服务器上有若干提供视频流的进程，每个流的帧率不同，假设帧率分别为 10、20、25，那么给这些进程分别分配 10、20、25 张彩票，它们就会自动按照接近 10:20:25 的比例划分 CPU 的使用 ","date":"2023-11-19","objectID":"/posts/processesandthreads/:13:6","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Processes and Threads","uri":"/posts/processesandthreads/"},{"categories":["C++"],"content":"公平分享调度 之前的调度关注的都是进程本身，而没有关注进程所有者。假设两个用户分别启动 9 个进程和 1 个进程，使用 RR 算法，则两者分别得到 90% 和 10% 的 CPU 时间。为了避免这种情况，在调度处理之前应该考虑进程拥有者 ","date":"2023-11-19","objectID":"/posts/processesandthreads/:13:7","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Processes and Threads","uri":"/posts/processesandthreads/"},{"categories":["C++"],"content":"无存储器抽象 早期计算机没有存储器抽象，每个程序都直接访问物理内存 MOV REGISTER1, 1000 ;将位置1000的物理内存中的内容移到 REGISTER1 中 因此那时呈现给程序员的存储器模型就是简单的物理内存：从 0 到某个上限的地址集合，每个地址对应一个可容纳一定数目（通常是 8 个）二进制位的存储单元 这种情况下，在内存中同时运行两个程序是不可能的，如果一个程序在 2000 的位置写入一个新值，就会擦掉另一个程序在相同位置上的内容，因此无法同时运行两个程序，这两个程序会立刻崩溃 为了运行多个程序，一个解决方法是，操作系统把当前内存中所有内容保存到磁盘，然后把下一个程序读入到内存中再运行即可。同一时刻，只要内存中只有一个程序，就不会发生冲突 但这种方法有一个重要的缺陷，即重定位（即逻辑地址到物理地址的转换）问题。假设有两个程序，第一个程序在 0 处的指令是 JMP 24，第二个程序在 0 处的指令是 JMP 28，当第一个程序运行一段时间后再运行第二个程序，第二个程序会跳到第一个程序 28 处的指令。由于对内存地址的不正确访问，程序立刻崩溃 一个补救方法是静态重定位，即装入时将逻辑地址转换为物理地址。当一个程序被装载到地址 16384 时，常数 16384 被加到每一个程序地址上。虽然这个机制在不出错误的情况下可行，但不是一种通用的解决方法，同时会减慢装载速度，并且它要求所有的可执行程序提供额外的信息，以区分哪些内存字中存有可重定位的地址，哪些没有 虽然直接引用物理地址对大型计算机、小型计算机、台式计算机、笔记本都已经成为了历史，但在嵌入式系统、智能卡系统中，缺少存储器抽象的情况仍然很常见。像收音机、洗衣机、微波炉都是采用访问绝对内存地址的寻址方式，其中的程序都是事先确定的，用户不能在其上运行自己的软件，因此它们可以正常工作 总之，把物理地址暴露给进程带来的严重问题有： 如果用户程序可以寻址内存的每个字节，就可以轻易破坏操作系统 想要运行多个程序很困难 ","date":"2023-11-19","objectID":"/posts/memorymanagement/:1:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Memory Management","uri":"/posts/memorymanagement/"},{"categories":["C++"],"content":"一种存储器抽象：地址空间 要使多个程序同时存在于内存中并且互不影响，需要解决保护（进程只能访问自己的内存）和重定位两个问题。对前者的一个原始的解决方法是，给内存标记上一个保护键，并且比较执行进程的键和其访问的每个内存字的保护键，比如进程能访问的空间是 0-100，CPU 标记此范围，然后在访问内存时检查是否为该进程可访问空间。不过这种方法并没有解决重定位问题 更好的方法是创造一个新的存储器抽象：地址空间。地址空间是一个进程可用于寻址内存的一套地址集合，每个进程都有一个自己的地址空间，并且这个地址空间独立于其他进程的地址空间（除了一些情况下进程需要共享地址空间） 地址空间的概念非常通用，比如 7 位数字的电话号码的地址空间是 0 000 000 到 9 999 999，x86 的 I/O 端口的地址空间是 0 到 16383，IPv4 的地址空间是 0 到 2 ^ 32 - 1。地址空间也可以是非数字的，比如以 .com 结尾的网络域名的集合 比较难的是给每个程序一个独有的地址空间，使得两个程序的相同地址（如地址 28）对应不同的物理地址 一个简单的方法是使用动态重定位，即运行时将逻辑地址转换为物理地址。把每个进程的地址空间映射到物理内存的不同部分，当一个进程运行时，程序的起始物理地址装载到基址寄存器（又称重定位寄存器），程序的长度装载到界限寄存器（又称限长寄存器）。进程访问内存，CPU 在把地址发送到内存总线前会自动把基址加到进程发出的地址值上，同时检查程序提供的地址是否超出了界限寄存器中的值，如果超出了就会产生错误并终止访问。对于之前的例子，比如第二个程序的 JMP 28，CPU 会将其解释为 JMP 16412 使用基址寄存器和界限寄存器重定位的缺点是，每次访问内存都需要进行加法和比较运算，比较运算可以很快，但加法运算由于进位传递时间的问题，在没有使用特殊电路的情况下会显得很慢 但物理内存是有限的，把所有进程一直保存在内存中需要巨大的内存，内存不足就无法支持这点。处理内存超载有两种通用方法，最简单的是交换（swapping）技术，即把进程完整调入内存运行一段时间，然后把它存回磁盘，这样空闲进程主要存储在磁盘上，不运行就不会占用内存。另一种方法是虚拟内存（virtual memory），它能使程序只有一部分调入内存的情况下运行 交换可能在内存中产生多个空闲区（hole）。把进程尽可能靠近，将这些小的间隙合并成一大块，这种技术称为内存紧缩（memory compaction）。通常不进行这个操作，因为它需要耗费大量 CPU 时间 如果进程的数据段可以增长（比如从堆中动态分配内存），进程与空闲区相邻，则可以把空闲区分配给进程使其增大。如果进程之间紧紧相邻，就需要把要增长的进程移到内存中一个足够大的区域，或者把一个或多个进程交换出去以生成足够大的空闲区。如果进程在内存中不能增长，并且磁盘上的交换区已满，则这个进程只能挂起直到有空间空闲，或者结束 如果大部分进程在运行时需要增长，为了减少因内存区不够而引起的进程交换和移动开销，一种方法是在换入或移动进程时额外分配一些预留内存 动态分配内存时，操作系统必须对其进行管理，一般跟踪内存使用情况有两种方法：位图和空闲区链表 使用位图法时，把内存划分成分配单元（每个单元小到几个字节或大到几千字节），用位图中的一位来记录每个分配单元的使用情况，比如 0 表示空闲 1 表示占用（或者相反）。分配单元越小，位图越大，不过即使 4 个字节大小的分配单元，32 位的内存只需要 1 位位图，位图只占用了 1 / 32 的内存 位图法的主要问题是，在决定把一个占 k 个分配单元的进程调入内存时，存储管理器必须搜索位图，在位图中找出有 k 个连续 0 的串，这个查找操作很耗时，因为在位图中该串可能跨越字的边界 另一个记录内存使用情况的方法是，维护一个记录已分配内存段和空闲内存段的链表，链表中的一个节点包含一个进程或者两个进程间的一块空闲区 使用链表法时，为进程分配内存的最简单的算法是首次适配（first fit）算法，存储管理器沿链表搜索，直到找到一个足够大的空闲区，然后将空闲区分为两部分，一部分为要分配的大小，供进程使用，另一部分形成新的空闲区 对首次适配算法进行小修改可以得到下次适配（next fit）算法，区别是在每次找到合适的空闲区时记录位置，这样下次就可以从上次结束的地方开始搜索。Bays 的仿真程序证明下次适配算法性能略低于首次适配算法 另一个著名并广泛使用的算法是最佳适配（best fit）算法，搜索整个链表，找到能容纳进程的最小空闲区。因为每次都要搜索整个链表，所以它比首次适配算法慢。有些令人意外的是，它比前两种算法浪费更多的内存，因为它会产生大量无用的小空闲区。为了避免分裂出很多非常小的空闲区，可以考虑最差适配（worst fit）算法，即总是分配最大的可用空闲区，但仿真程序表明这也不是一个好方法 一个提高算法速度的方式是，为进程和空闲区分别维护链表，代价是增加复杂度和内存释放速度变慢，因为必须将回收的段从进程链表删除并插入到空闲区链表 如果分别维护进程和空闲区的链表，就可以对空闲区链表按大小排序，以提高最佳适配算法的速度，比如按从小到大排序，第一个合适的空间就是最小的空闲区，就是最佳适配。排序后，首次适配算法与最佳适配算法一样快，下次适配算法无意义 单独维护空闲区链表时可以做一个小优化，利用空闲区存储信息，每个空闲区的第一个字就是空闲区大小，第二个字指向下一空闲区 另一种分配算法是快速分配（quick fit）算法，它为常用大小的空闲区维护单独的链表，比如链表第一项是 4 KB 大小空闲区的链表头指针，第二项是 8 KB 大小空闲区的链表头指针，以此类推。像 21 KB 的空闲区，既可以放在 20 KB 的链表中，也可以放在一个专门存放特殊大小的链表中。这种算法查找指定大小的空闲区很快，但同样存在的缺点是，进程终止或换出时，寻找它的相邻块并查找是否可以合并的过程非常费时，如果不合并，内存将很快分裂出大量无法利用的小空闲区 ","date":"2023-11-19","objectID":"/posts/memorymanagement/:2:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Memory Management","uri":"/posts/memorymanagement/"},{"categories":["C++"],"content":"虚拟内存 当程序大到内存无法容纳时，交换技术就有所缺陷，一个典型 SATA 磁盘的峰值传输率高达每秒几百兆，交换一个 1 GB 的程序就需要好几秒 程序大于内存的问题在一些应用领域早就存在了，比如模拟宇宙的创建就要花费大量内存。20 世纪 60 年代的解决方案是，将程序分割为多个覆盖区（overlay）。程序开始运行时，将覆盖管理模块装入内存，该模块立刻装入并运行第一个覆盖区，执行完成后，第一个覆盖区通知管理模块装入下一个覆盖区 程序员必须把程序分割成多个片段，这个工作非常费时枯燥，并且易出错。不久后有了虚拟内存（virtual memory）的方法，这些工作都可以交给计算机去做 虚拟内存的基本思想是，程序的地址空间被分割成多个页（page），每一页有连续的地址范围。这些页被映射到物理内存，但并不是所有页必须在内存中才能运行程序。当程序引用到一部分物理内存中的地址空间时，由硬件执行必要的映射。当程序引用到一部分不在物理内存中的地址空间时，由操作系统负责将缺失的部分装入物理内存并重新执行失败的指令 ","date":"2023-11-19","objectID":"/posts/memorymanagement/:3:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Memory Management","uri":"/posts/memorymanagement/"},{"categories":["C++"],"content":"分页（paging） 大部分虚拟内存系统都使用了分页技术 由程序产生的地址称为虚拟地址（virtual address） MOV REG, 1000 ;将地址为 1000 的内存单元的内容复制到 REG，1000 是虚拟地址 虚拟地址构成了虚拟地址空间（virtual address space）。在没有虚拟内存的计算机上，系统直接将虚拟地址送到内存总线上，读写操作使用相同地址的物理内存字。在使用虚拟内存时，虚拟地址被送到内存管理单元（Memory Management Unit，MMU），MMU 把虚拟地址映射为物理内存地址 页表给出虚拟地址与物理内存地址之间的映射关系 虚拟地址空间按固定大小划分为页面（page），物理内存中对应的单元称为页框（page frame），页面和页框的大小通常相同，页表说明了每个页面对应的页框。RAM 和磁盘之间的交换总是以整个页面为单元进行的 对应 64 KB 的虚拟地址空间和 32 KB 的物理内存，可以得到 16 个页面和 8 个页框 比如执行指令访问地址 0 时 MOV REG, 0 虚拟地址 0 被送到 MMU，MMU 发现其位于页面 0（0 - 4095），根据映射结果，页面 0 对应页框 2（8192 - 12287），于是 MMU 将地址转换为 8192，并把地址 8192 送到总线上。内存并不需要知道 MMU 做的事，只看到一个访问地址 8192 的请求并执行 当虚拟地址空间比物理内存大时，就会存在未被映射的页面。当程序执行指令访问未映射的页面 MOV REG, 32780 ;位于页面 8（从 32768 开始） MMU 发现该页面未被映射，于是使 CPU 陷入（traps）到操作系统，这称为缺页中断（page fault）。操作系统找到一个很少使用的页框并把其内容写入磁盘，比如找到页面 1 对应的页框 1。将页面 1 标记为未映射，再把页面 8 映射到这个页框 1，然后重新启动访问指令，此时虚拟地址 32780 就可以映射到物理地址 4108（4096 + 32780 - 32768） 页面大小一般是 2 的整数次幂。比如页面大小为 4 KB，即 2 ^ 12，对于一个 16 位的虚拟地址，即可用前 4 位表示页面的页号，后 12 位表示偏移量。比如虚拟地址 8192，二进制为 0010 0000 0000 0100，0010 即为页号，0000 0000 0100 即为偏移，因此 8192 位于页号 2 偏移 4 的位置 页表中，查找页号 2 对应的页框号为 6，把页框号 110 复制到输出寄存器的高 3 位，后 12 位保持不变，110 0000 0000 0100 即为物理地址 除了页框号，页表还会有一些其他的位 有效位，如果该位为 1 则说明存在映射，如果为 0，则访问该页面将引起缺页中断 保护（protection）位，指出一个页允许的访问方式，比如用一个位表示，0 表示读写，1 表示只读 修改（modified）位，记录页面使用情况，写入页面后由硬件自动设置修改位，该位也称为脏位（dirty bit），在重新分配页框时很有用，比如一个页是脏的（已被修改过），则必须把它写回磁盘，是干净的则可以直接丢弃 访问（referenced）位，在页面被访问时设置，主要用来帮助操作系统在发生缺页中断时选择要淘汰的页面 禁止高速缓存位，该位对于映射到设备寄存器而非常规内存的页面十分重要，比如操作系统持续等待 I/O 设备的响应，必须保证硬件读取的数据来自设备而非高速缓存 ","date":"2023-11-19","objectID":"/posts/memorymanagement/:4:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Memory Management","uri":"/posts/memorymanagement/"},{"categories":["C++"],"content":"加速分页过程 在任何分页系统中都需要考虑两个问题 虚拟地址到物理地址的映射必须非常快：每次访问内存都要进行映射，所有的指令最终都来自内存，并且很多指令也会访问内存中的操作数，因此每条指令进行一两次或更多页表访问是必要的。如果指令一条指令要 1 ns，页表查询必须在 0.2 ns 内完成，以避免映射成为主要瓶颈 如果虚拟地址空间很大，页表也会很大：现代计算机至少使用 32 位虚拟地址，假设页面大小为 4 KB，32 位的地址空间将有 100 万页，页表也必然有 100 万条表项。每个进程都有自己的虚拟地址空间，都需要自己的页表，于是需要为进程分配非常多的连续页框 大多数程序总是对少量页面多次访问，没有必要让将整个页表保存在内存中，由此得出的一种解决方案是，设置一个转换检测缓冲区（Translation Lookaside Buffer，TLB），也称相联存储器（associate memory）或快表，将虚拟内存直接映射到物理地址，而不必再访问页表 TLB 通常在 MMU 中，包含少量表项，实际中很少会超过 256 个。将一个虚拟地址放入 MMU 中进行转换时，硬件先将页号与 TLB 中所有表项进行匹配，如果匹配成功且操作不违反保护位，则直接从 TLB 中取出页框号，而不再访问页表。如果匹配失败，则进行正常的页表查询，并从 TLB 淘汰一个表项，然后用新找到的页表项代替它 处理巨大的虚拟地址空间有两种解决方法：多级页表和倒排页表 比如 32 位地址空间中，页面大小为 4 KB，偏移量占 12 位，则页号占 20 位。将页号分组，页表项大小为 4 B，4 KB 的页面就能放 1024 个表项，于是每 1024 个页号分为一组。这样分组得到的页表为二级页表，再用一个顶级页表映射页号到二级页表的物理地址即可 使用多级页表时，32 位的地址划分为 10 位的 PT1 域、10 位的 PT2 域、12 位的 Offset 域。比如对于虚拟地址 0000 0000 0100 0000 0011 0000 0000 0100，PT1 为 1，PT2 为 3，Offset 为 4，MMU 先访问顶级页表 1 处，得到二级页表的物理地址，由此访问二级页表 3 处，得到页框号，最后加上 Offset 即为最终的物理地址 二级页表可以扩充为更多级。每级页表大小不能超过一个页面，比如 4 KB 页面，偏移为 12 位，页表项大小为 4 B，每 1024 分为一组，则每级最多 10 位，如果是 40 位，则除去 12 位，剩余可以划分为一级 8 位、二级 10 位、三级 10 位的三级页表 单级页表只要进行两次访存（第一次访问页表得到物理地址，第二次访问物理地址），而每多一级页表就要多一次访存（不考虑 TLB） 另一种方式是倒排页表（inverted page table），让每个页框（而非页面）对应一个表项。比如对于 64 位虚拟地址，4 KB 的页，4 GB 的 RAM，一个倒排页表仅需要 2 ^ 20 个表项，表项记录了一个页框对应的页面（进程） 虽然倒排页表节省了大量空间，但从虚拟地址到物理地址的转换变得很困难，必须搜索整个倒排页表来找到页面，每一次搜索都要执行访问操作。这个问题可以通过 TLB 解决 倒排页表在 64 位机器中很常见，因为 64 位机器中，即使使用大页面页表项数量也很庞大，比如对于 4 MB 页面和 64 位虚拟地址，需要的页表项目数为 2 ^ 42 ","date":"2023-11-19","objectID":"/posts/memorymanagement/:5:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Memory Management","uri":"/posts/memorymanagement/"},{"categories":["C++"],"content":"页面置换算法 发生缺页中断时，操作系统必须换出内存中的一个页面，以腾出空间。如果换出的页面在内存驻留期间被修改过，就必须把它写回磁盘以更新其在磁盘上的副本，如果未被修改过则不需要写回 如果一个经常用到的页面被换出内存，短时间内它可能又被调入内存，这会带来不必要的开销。因此发生缺页中断时，如何选择要换出的页面是一个值得考虑的问题 ","date":"2023-11-19","objectID":"/posts/memorymanagement/:6:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Memory Management","uri":"/posts/memorymanagement/"},{"categories":["C++"],"content":"最优页面置换算法（OPTimal replacement，OPT） OPT 算法的思路很简单，从所有页面中选出下次访问时间距现在最久的淘汰 432143543215 // 页面队列 444444444222 // 页 1 33333333311 // 页 2 2111555555 // 页 3 TTTT T TT // 是否发生缺页中断（共发生 7 次缺页中断，4 次页面置换） | 把 2 替换掉，因为 432 中，2 下一次被访问的时间最靠后 这个算法的唯一问题在于，它是无法实现的，因为发生缺页中断时，操作系统无法得知各个页面下一次在什么时候被访问 作为理论最优算法，可以用它衡量其他算法的性能。如果操作系统的页面置换性能只比最优算法差 1%，那么花费大量精力来优化算法就不是特别必要的 ","date":"2023-11-19","objectID":"/posts/memorymanagement/:6:1","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Memory Management","uri":"/posts/memorymanagement/"},{"categories":["C++"],"content":"最近未使用页面置换算法（Not Recently Used，NRU） 操作系统为每个页面设置了两个状态位，当页面被访问时设置 R 位，被修改时设置 M 位。启动进程时，所有页面的 RM 均设为 0，并且 R 被定期（比如每次时钟中断时）清零 发生缺页中断时，根据 RM 位的值，可以将页面分为 4 类 第 0 类：未访问未修改（R 位为 0，M 位为 0） 第 1 类：未访问已修改（R 位为 0，M 位为 1，看起来似乎不可能，实际可以由第 3 类转换而来） 第 2 类：已访问未修改（R 位为 1，M 位为 0） 第 3 类：已访问已修改（R 位为 1，M 位为 1，R 在清零后即变为第 1 类） NRU 算法随机从第0类中选择一个页面淘汰，如果第 0 类中没有页面则选择第 1 类，以此类推，优先选择编号最小的类 这个算法的隐含思想是，淘汰一个未访问已修改页面（第 1 类），比淘汰一个频繁使用的干净页面（第 2 类）好 NRU 的主要优点是易理解且能有效实现，虽然性能不是最好的，但已经够用了 ","date":"2023-11-19","objectID":"/posts/memorymanagement/:6:2","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Memory Management","uri":"/posts/memorymanagement/"},{"categories":["C++"],"content":"先进先出页面置换算法（First-In First-Out，FIFO） 顾名思义，淘汰最早进入的页面 操作系统维护一个内存中所有当前页面的链表，最新进入的页面放在表尾，淘汰页面就是表头页面 FIFO 可能淘汰常用页面，甚至可能出现分配页面数增多但缺页率反而提高的异常现象（Belady 异常），因此很少使用纯粹的 FIFO 算法 ","date":"2023-11-19","objectID":"/posts/memorymanagement/:6:3","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Memory Management","uri":"/posts/memorymanagement/"},{"categories":["C++"],"content":"第二次机会页面置换算法（Second-Chance） 对 FIFO 做一个简单的修改：检查最老页面的 R 位（访问位），如果 R 位是 0 则淘汰，如果是 1 则把 R 位清零，并把该页面放到表尾，然后继续搜索 如果所有页面都被访问过，则该算法就简化为纯粹的 FIFO 算法 ","date":"2023-11-19","objectID":"/posts/memorymanagement/:6:4","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Memory Management","uri":"/posts/memorymanagement/"},{"categories":["C++"],"content":"时钟页面置换算法（clock） 第二次机会算法经常要在链表中移动页面，降低了效率且不是很有必要 一个更好的办法是将所有页面保存在在一个类似钟面的环形链表中，一个表针指向最老的页面。发生缺页中断时，检查表针指向的页面，如果 R 位是 0 则淘汰该页面，并在该位置插入新页面，然后表针后移一步。如果 R 位是 1 则把 R 位清零，然后表针后移一步。如果该页已存在，不发生缺页中断，R 位是 0 则改为 1，表针不需要移动 ","date":"2023-11-19","objectID":"/posts/memorymanagement/:6:5","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Memory Management","uri":"/posts/memorymanagement/"},{"categories":["C++"],"content":"最近最少使用页面置换算法（Least Recently Used，LRU） LRU 是 OPT 的一个近似思路，在前几条指令中频繁使用的页面很可能在后几条指令中被使用，反过来说，很久没使用的页面很可能在之后的长时间内仍然不使用 LRU 是可实现的，但代价很高。实现 LRU 需要维护一个所有页面的链表，最常使用的位于表头，每次访问时必须更新整个链表，在链表中找到页面删除后再添加到表头 有一些使用特殊硬件实现 LRU 的方法，比如要求硬件有一个 64 位计数器，它在每条指令执行完后加 1，每个页表项中有一个足够容纳这个计数器值的域。发生缺页中断时，检查所有页表项的计数值，值最小的就是最近最少使用的 只有非常少的计算机有这种硬件，LRU 很优秀但很难实现 ","date":"2023-11-19","objectID":"/posts/memorymanagement/:6:6","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Memory Management","uri":"/posts/memorymanagement/"},{"categories":["C++"],"content":"最不常用页面置换算法（Not Frequently Used，NFU） NFU 是 LRU 的一个软件实现方案 NFU 将每个页面与一个软件计数器关联，计数器初值为 0，每次时钟中断时，操作系统扫描内存中所有页面，将每个页面的 R 位值加到计数器上，这个计数器大致跟踪了各个页面被访问的频繁程度。发生缺页中断时，则置换计数器值最小的页面 NFU 的问题在于，第一遍扫描中频繁使用的页面，第二遍扫描时，计数器值仍然很高。这就会导致后续扫描中，即使该页面使用次数最少，也会由于计数器值较高而不被置换 ","date":"2023-11-19","objectID":"/posts/memorymanagement/:6:7","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Memory Management","uri":"/posts/memorymanagement/"},{"categories":["C++"],"content":"老化（aging）算法 老化算法对 NFU 做了一些改进，在R位加进之前先将计数器右移一位，然后把 R 位加到计数器最左端的位 页面 0 10000000 11000000 11100000 11110000 01111000 1 00000000 10000000 11000000 01100000 10110000 2 10000000 01000000 00100000 00100000 10001000 3 00000000 00000000 10000000 01000000 00100000 4 10000000 11000000 01100000 10110000 01011000 5 10000000 01000000 10100000 01010000 00101000 | | | | | 访问页面 024 访问 014 访问 013 访问 04 访问 12 发生缺页中断时，置换计数器值最小的页面，因为前面的 0 越多，说明其最近越不常被访问 老化算法非常近似 LRU，但有两个区别 比如最后一次访问时，如果发生缺页中断，需要置换一个页面。页面 3 和页面 5 开头都是 001，即前两次未被访问，前第三次被访问，如果前第三次是页面 5 先被访问，则 LRU 会替换页面 5，但这里无法区分两者谁先被访问，而只能替换值较小的页面 3 老化算法计数器位数有限，比如这里是 8 位，只能记录过去 8 次的访问，超过该次数的记录无法得知。不过实践中，如果时钟滴答是 20 ms，8 位一般是够用的，如果一个页面 160 ms 未被访问，则很可能不重要 ","date":"2023-11-19","objectID":"/posts/memorymanagement/:6:8","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Memory Management","uri":"/posts/memorymanagement/"},{"categories":["C++"],"content":"工作集页面置换算法 在单纯的分页系统中，刚开始启动进程时，内存中没有页面，CPU 尝试取第一条指令时就会产生一次缺页中断，使操作系统装入含第一条指令的页面。一段时间后，进程需要的大部分页面都在内存了，进程开始在较少缺页中断的情况下运行。这个策略称为请求调页（demand paging），因为页面在需要时被调入，而不是预先装入 一个进程当前正在使用的页面集合称为它的工作集（Denning），如果整个工作集都被装入内存中，那么进程在运行到下一阶段之前不会产生很多缺页中断。如果内存太小无法容纳整个工作集，进程的运行过程中将产生大量缺页中断，导致运行速度变慢，因为通常执行一条指令只要几纳秒，而从磁盘读入一个页面需要十几毫秒。如果每执行几条指令就发生一次缺页中断，就称这个程序发生了颠簸（Denning） 请求调页策略中，每次装入一个进程都要产生大量缺页中断，速度太慢，并且 CPU 花了很多时间处理缺页中断，浪费了许多 CPU 时间，因此不少分页系统会设法跟踪工作集，以确保在进程运行前，工作集已经在内存中了，这个方法称为工作集模型（Denning），也叫预先调页（prepaging），其目的在于大大减少缺页中断率 工作集是随着时间变化的，它是最近k次访存所访问过的页面集合。为了实现该算法，需要一种精确的方法来确定哪些页面在工作集中，为此必须预先选定 k 值。但有了工作集的定义并不意味着就能计算出工作集 假设有一个长度为 k 的移位寄存器，每次访存都把寄存器左移一位，然后在最右端插入刚才访问过的页面号，寄存器中 k 个页面号的集合就是工作集。理论上，发生缺页中断时，只要读出寄存器中的内容并排序，然后删除重复的页面，结果就是工作集。但维护该寄存器并在缺页中断时处理它需要很大的开销，因此该技术从未被使用过 有几种近似的方法作为替代，一种常见近似方法是，不向后查找最近 k 次的内存访问，而是查找过去一定时间内，比如过去 10 ms 访存所用到的页面集合 基于工作集的页面置换算法是，找出一个不在工作集中的页面并淘汰，为此表项中至少需要包含两条信息，一是上次使用该页面的近似时间，二是 R 位（访问位） 处理表项时，如果 R 位是 1，则把上次使用时间改为当前实际时间。如果 R 位是 0，则可以作为置换候选者，计算生存时间（当前实际时间与上次使用时间的差），如果生存时间大于定义工作集范围的时间，则该页面在工作集外，将其置换。如果 R 为 0 且生存时间不超过定义工作集范围的时间，则该页面仍在工作集中，记录该页面。如果扫描完整个页表都没有可淘汰的，则从记录页面中选一个生存时间最长的淘汰，如果记录页面为空，即所有页面 R 位均为 1，则随机选择一个淘汰 ","date":"2023-11-19","objectID":"/posts/memorymanagement/:6:9","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Memory Management","uri":"/posts/memorymanagement/"},{"categories":["C++"],"content":"工作集时钟（WSClock）页面置换算法 工作集算法需要扫描整个页表，比较费时，结合时钟算法的思路稍作改进，即可得到 WSClock 算法。它实现简单，性能较好，在实际工作中得到了广泛使用 ","date":"2023-11-19","objectID":"/posts/memorymanagement/:6:10","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Memory Management","uri":"/posts/memorymanagement/"},{"categories":["C++"],"content":"分段（Segmentation） 一个编译器在编译过程中会建立许多表，其中可能包括 被保存起来供打印清单用的源程序正文（用于批处理系统） 包含变量名字和属性的符号表 包含用到的所有整型量和浮点常量的表 包含程序语法分析结果的语法分析树 编译器内部过程调用使用的堆栈 在一维地址空间中，当有多个动态增加的表时，就可能发生碰撞。一种能令程序员不用管理表扩张和收缩的方法是，在机器上提供多个互相独立的段（segment）的地址空间，段的长度可以不同，在运行时可以改变，比如堆栈段的长度在数据压入时会增长，在数据弹出时会减小 每个段都构成一个独立的地址空间，在内存中占据连续空间，可以独立地增长或减小，而不会影响其他段 段是按逻辑功能的划分的实体，程序员使用起来更方便，并且程序的可读性更高。此外，分段有助于共享和保护。分段系统中，可以把共享库放到一个单独的段中由各个进程共享，而不需要在每个进程的地址空间中保存一份。当组成一个程序的所有过程都被编译和链接好以后，如果一个段的过程被修改并重新编译，也不会影响到其他段，因为这个段的起始地址（基址）没有被修改 要在分段的存储器中表示一个地址，必须提供一个段号（段名）和一个段内地址（段内偏移量） 31 ... 16 15 ... 0 // 可用 31 - 16 表示段号，15 - 0 表示段内地址 每个进程需要一张段表，每个段表项记录一个段的起始位置和段的长度。段表项长度是固定的，因此段号可以是隐含的，不占存储空间。查找时，如果段号越界，则产生越界中断。如果段内地址超出段长，则产生越界中断 K 号段的段表存放地址 = 段表起始位置 + K * 段表项长度 段号 基址 段长 0 20K 3K 1 60K 2K 2 40K 5K 如果一个逻辑地址段号为 1，段内地址为 1024 段号 1 的段长为 2K，大于 1024，不产生越界中断 存放地址 = 60K + 1024 = 61K 分段管理的缺点是，如果段长过大，则不便于分配连续空间，此外会产生外部碎片。分页管理的内存利用率高，不会产生外部碎片，只会有少量页内碎片。因此，两者结合可以互相弥补，实现段页式管理 段页式系统的地址由段号、页号、页内地址（页内偏移量）组成。分段对用户可见，而分页不可见 31 ... 16 15 ... 12 11 ... 0 // 可用 31 - 16 表示段号，15 - 12 表示页号，11 - 0 表示页内地址 每个段表项记录页表长度、页表起始地址，通过页表起始地址找到页号，通过页号对应的页表项目找到物理地址，一共需要三次访存（如果引入以段号和页号为关键字的 TLB 且命中，则只需要一次访存）。段表项长度是固定的，段号可以是隐含的。同样，每个页表项长度固定，页号是隐含的 ","date":"2023-11-19","objectID":"/posts/memorymanagement/:7:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Memory Management","uri":"/posts/memorymanagement/"},{"categories":["C++"],"content":"I/O 硬件原理 I/O 设备就是可以将数据输入到计算机(如鼠标、键盘)，或者可以接收计算机输出数据的外部设备(如显示器) I/O 设备按信息交换单位可分为两类 块设备(block device)：把信息存储在固定大小的块中，每个块都有自己的地址。块设备的基本特征是，传输速率快，可寻址，每个块都能独立于其他块而读写。磁盘就是最常见的块可寻址设备，无论磁盘臂当前处于什么位置，总是能寻址其他柱面并且等待所需要的磁盘块旋转到磁头下面 字符设备(character device)：以字符为单位发送或接收一个字符流，而不考虑任何块结构，因此传输速率较慢，不可寻址，也没有任何寻道操作，在输入/输出时常采用中断驱动方式。打印机、鼠标就是常见的字符设备 I/O 设备一般由机械部件和电子部件两部分组成 机械部件主要用于执行具体 I/O 操作，如鼠标的按钮、键盘的按键、显示器的屏幕、硬盘的磁盘臂 电子部件也称作设备控制器(device controller)或适配器(adapter)，通常是主板上的芯片，或一块插入主板扩充槽的印刷电路板 CPU 无法直接控制机械部件，因此需要通过设备控制器作为中介来控制机械部件。设备控制器的主要功能有 接收和识别 CPU 发出的命令：每个控制器有几个寄存器用于与 CPU 通信，通过写入这些寄存器，操作系统可以命令设备发送数据、接收数据、开启或关闭，或者执行其他某些操作 向 CPU 报告设备的状态：通过读取这些寄存器，操作系统可以了解设备的状态，是否准备好接收一个新的命令等 数据交换：除了控制寄存器外，许多设备还有一个操作系统可以读写的数据缓冲区，比如在屏幕上显示像素的常规方法是使用一个视频 RAM，这一 RAM 基本上只是一个数据缓冲区，可供程序或操作系统写入数据 地址识别：为了区分设备控制器中的寄存器，需要给每个寄存器设置一个地址，控制器通过 CPU 提供的地址来判断 CPU 要访问的寄存器 设备控制器中有多个寄存器，为这些寄存器编址有两种方式 内存映射 I/O(memory-mapped I/O)：所有设备控制器的寄存器映射到内存空间中，每个控制寄存器被分配一个唯一的内存地址，并且不会有内存被分配到这一地址 寄存器独立编址：每个寄存器被分配一个 I/O 端口(port)号，所有端口号形成 I/O 端口空间(I/O port space)，并且受到保护使得普通用户程序不能对其进行访问，只有操作系统可以访问。这一方案中，内存地址空间和 I/O 地址空间是不同且不相关的 ","date":"2023-11-19","objectID":"/posts/io/:1:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | IO","uri":"/posts/io/"},{"categories":["C++"],"content":"I/O 软件原理 I/O 软件的设计有以下目标 设备独立性(device independence)：允许编写出的程序可以访问任意 I/O 设备而无需事先指定设备，比如读取一个文件作为输入的程序，应该能在硬盘、DVD 或 USB 盘上读取文件，无需为每一种不同的设备修改程序 统一命名(uniform naming)：一个文件或一个设备的名字应该是一个简单的字符串或一个整数，不应依赖于设备 错误处理(error handling)：一般来说，错误应该尽可能在接近硬件的层面得到处理。当控制器发现一个读错误时，如果它能够处理，就应该自己设法纠正错误。如果控制器处理不了，设备驱动程序就应当予以处理，可能只需要重读一次这块数据就正确了 同步(synchronous，即阻塞)和异步(asynchronous，即中断驱动)传输：大多数物理 I/O 是异步的，比如 CPU 启动传输后便转去做其他工作，直到中断发生。如果 I/O 操作是阻塞的，用户程序就更容易编写，比如 read 系统调用之后程序将自动被挂起，直到缓冲区中的数据准备好，而正是操作系统将实际异步的操作变为了在用户程序看来是阻塞式的操作 缓冲(buffering)：数据离开一个设备之后通常不能直接存放到最终目的地，比如从网络上进来一个数据包时，直到将该数据包存放到某个地方，并对其进行检查，操作系统才知道要将其置于何处。缓冲涉及大量复制工作，经常对 I/O 性能有重大影响 共享设备和独占设备：共享设备能同时让多个用户使用(如磁盘)，独占设备则只能由单个用户独占使用(如磁带机)。独占设备的引入带来了各种问题(如死锁)，操作系统必须能处理共享设备和独占设备以避免问题发生 I/O 有三种实现方式 程序控制 I/O(programmed I/O)：这是 I/O 的最简单形式。CPU 轮询设备状态，当设备准备好时，CPU 向控制器发出读指令，从 I/O 设备中读取字，再把这些字写入到存储器。这种方式的优点是实现简单，缺点是在完成全部 I/O 之前，CPU 的所有时间都被其占用，如果 CPU 有其他事情要做，轮询就导致了 CPU 利用率低 中断驱动 I/O ：用中断阻塞等待 I/O 的进程，CPU 在等待 I/O 设备就绪时，通过调度程序先执行其他进程。当 I/O 完成后(比如打印机打印完一个字符，准备接收下一个字符)，设备控制器将向 CPU 发送一个中断信号，CPU 检测到中断信号后保存当前进程的运行环境信息，然后执行中断驱动程序来处理中断。CPU 从设备控制器读一个字的数据传送到 CPU 寄存器，再写入主存，接着 CPU 恢复其他进程的运行环境并继续执行(打印下一个字符)。中断的优点是提高了 CPU 利用率，缺点是每次只能读一个字，每次都要发生一个中断，频繁的中断处理将浪费一定的 CPU 时间 使用 DMA(Direct Memory Access)的 I/O ：让 DMA 控制器来完成 CPU 要做的工作，使得 CPU 可以在 I/O 期间做其他操作。有了 DMA 控制器，就不用每个字中断一次，而是减少到每个缓冲区一次。DMA 控制器通常比 CPU 慢很多，如果 CPU 在等待 DMA 中断时没有其他事情要做，采用中断驱动 I/O 甚至程序控制 I/O 也许更好 ","date":"2023-11-19","objectID":"/posts/io/:2:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | IO","uri":"/posts/io/"},{"categories":["C++"],"content":"I/O 软件层次 I/O 软件通常组织成四个层次，从上层到底层依次为 用户级 I/O 软件：实现了与用户交互的接口，为用户提供 I/O 操作相关的库函数接口，如 printf 与设备无关的操作系统软件：向用户层提供系统调用，如为 printf 提供 write，另外还要提供设备保护(设置访问权限)、缓冲、错误报告、分配与释放专用设备、建立逻辑设备名到物理设备名的映射关系等功能 设备驱动程序(device driver)：每个连接到计算机上的 I/O 设备都需要某些设备特定的代码来对其进行控制，这样的代码称为设备驱动程序 中断处理程序：进行中断处理 ","date":"2023-11-19","objectID":"/posts/io/:3:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | IO","uri":"/posts/io/"},{"categories":["C++"],"content":"盘 盘有多种多样的类型，最常用的是磁盘，它具有读写速度同样快的特点，适合作为辅助存储器(用于分页、文件系统等) 磁盘被组织成柱面，每一个柱面包含若干磁道，磁道数与垂直堆叠的磁头个数相同，磁道又被分为若干扇区，通过 (柱面号, 盘面号, 扇区号) 即可定位一个磁盘块 磁盘臂调度算法有 先来先服务算法(First-Come First-Served，FCFS)：按照请求接收顺序完成请求，优点是公平简单易实现，缺点是平均寻道时间较长 最短寻道时间优先算法(Shortest Seek Time First，SSTF)：下一次处理，磁头向所有请求中距离最近的位置移动。缺点是可能出现饥饿现象 扫描算法(SCAN)：也叫电梯算法(elevator algorithm)，磁头持续向一个方向移动，直到到达最内侧或最外侧时才改变方向。优点是平均寻道时间较短，不会产生饥饿现象 LOOK 调度算法：对扫描算法稍作优化，如果磁头移动方向上已没有需要处理的请求，则直接改变方向 循环扫描算法(C-SCAN)：SCAN 算法对于各个位置磁道的响应频率不平均，靠近磁盘两侧的可能更快被下一次访问。为了解决这个问题，C-SCAN 算法的原理是，只在一个移动方向上处理请求，磁头返回时不处理任何请求 C-LOOK：只在一个移动方向上处理请求，如果该方向之后没有要处理的请求，则磁头返回，并且只需要返回到第一个有请求的位置 ","date":"2023-11-19","objectID":"/posts/io/:4:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | IO","uri":"/posts/io/"},{"categories":["C++"],"content":" 进程运行时，可以在自己的地址空间存储信息，但这样保存信息的问题是 对于一些程序，如银行系统，这样的存储空间太小 进程终止时，保存的信息就丢失了 经常需要多个进程访问同一信息，这要求信息独立于任何一个进程 因此，长期存储信息有三个基本要求 能够存储大量信息 使用信息的进程终止时，信息仍存在 允许多个进程并发访问信息 理论上，磁盘(magnetic disk)就能解决长期存储的问题，但实际上，有许多操作不便于实现 如何找到信息? 如何防止一个用户读取另一个用户的数据? 如何知道哪些块是空闲的? 为了解决这个问题，引入文件的概念，它是一个建模于磁盘的抽象概念 文件由操作系统管理，文件的构造、命名、访问、使用、保护、实现、管理方法是操作系统设计的主要内容，操作系统中处理文件的部分称为文件系统(file system) ","date":"2023-11-19","objectID":"/posts/filesystems/:0:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | File Systems","uri":"/posts/filesystems/"},{"categories":["C++"],"content":"文件 ","date":"2023-11-19","objectID":"/posts/filesystems/:1:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | File Systems","uri":"/posts/filesystems/"},{"categories":["C++"],"content":"文件命名 各个系统中的文件命名规则不同，现代操作系统都允许用 1 到 8 个字母组成的字符串作为合法的文件名，通常也允许有数字和一些特殊字符 一般操作系统支持文件名用圆点分隔为两部分，如 main.cpp，圆点后的部分称为文件扩展名(file extension)。UNIX 中，文件扩展名只是一种约定，Windows 中的扩展名则有特别意义，用户或进程可以在操作系统中注册扩展名，并规定哪个程序拥有该扩展名(即双击该文件则启动此程序并运行该文件) ","date":"2023-11-19","objectID":"/posts/filesystems/:1:1","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | File Systems","uri":"/posts/filesystems/"},{"categories":["C++"],"content":"文件结构 文件可以有多种构造方式 常见的一种构造方式是无结构的单字节序列，操作系统见到的就是字节，文件内容的任何含义只在用户程序中解释，UNIX 和 Windows 都采用这种方法。这为操作系统提供了最大的灵活性，用户可以向文件中加入任何内容，以任何形式命名，操作系统不提供帮助也不进行阻碍 第二种构造方式是固定长度记录的序列，这种方式的中心思想是，读操作返回一个记录，写操作重写或追加一个记录。几十年前，80 列的穿孔卡片是主流时，很多大型机的操作系统使用的就是这种方式，文件由 80 个字符的记录组成，文件系统建立在这种文件基础上 第三种构造方式是用一棵记录树构成文件，记录的固定位置有一个键，树按键排序，从而可以对键进行快速查找，这种方式被广泛用于处理商业数据的大型计算机 ","date":"2023-11-19","objectID":"/posts/filesystems/:1:2","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | File Systems","uri":"/posts/filesystems/"},{"categories":["C++"],"content":"文件类型 操作系统一般支持多种文件类型，UNIX 和 Windows 都有普通文件(regular file)和目录(directory)，此外 UNIX 还有字符特殊文件(character special file)和块特殊文件(block special file) 普通文件一般分为 ASCII 文件和二进制文件 ASCII 文件由多行正文组成，每行用回车符或换行符或两者(如 MS-DOS)结束，其最大优势是可以显示、打印、编辑，如果很多程序都用 ASCII 文件作为输入和输出，就很容易把一个程序的输出作为另一个程序的输入 二进制文件打印出来是充满乱码的表，通常二进制文件有一定的内部结构，使用该文件的程序才了解这种结构。比如 UNIX 存档文件，每个文件以模块头开始，其中记录了名称、创建日期、所有者、保护码、文件大小，该模块头与可执行文件一样都是二进制数字，打印输出它们毫无意义 ","date":"2023-11-19","objectID":"/posts/filesystems/:1:3","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | File Systems","uri":"/posts/filesystems/"},{"categories":["C++"],"content":"文件访问 早期操作系统只有顺序访问(sequential access)一种文件访问方式，进程可以从头按顺序读取文件的字节，不能跳过某一些内容。在存储介质是磁带而不是磁盘时，顺序访问文件是很方便的 用磁盘存储文件时，就能以任何次序读取文件的字节，能被这种方式访问的文件称为随机访问文件(random access file)。对许多程序来说，随机访问文件必不可少，比如数据库系统，查找一条记录时，不需要先读出之前的成千上万条记录 ","date":"2023-11-19","objectID":"/posts/filesystems/:1:4","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | File Systems","uri":"/posts/filesystems/"},{"categories":["C++"],"content":"文件属性 除了文件名和数据，操作系统还会保存文件相关的信息，如创建日期、文件大小等，这些附加信息称为文件属性(attribute)或元数据(metadata)。不同系统中的文件属性差别很大 ","date":"2023-11-19","objectID":"/posts/filesystems/:1:5","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | File Systems","uri":"/posts/filesystems/"},{"categories":["C++"],"content":"文件操作 使用文件是为了存储信息并方便以后检索，不同的操作系统提供了不同的方式，常见的文件相关的系统调用有 create、delete、open、close、read、write、append、seek、get attributes、set attributes、rename ","date":"2023-11-19","objectID":"/posts/filesystems/:1:6","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | File Systems","uri":"/posts/filesystems/"},{"categories":["C++"],"content":"目录 目录系统的最简单形式是单层目录系统，即一个目录中包含所有文件，这个目录通常称为根目录，其优势是简单，且能快速定位文件，常用于简单的嵌入式装置，如电话、数码相机 现在的用户通常有成千上万的文件，用单层目录寻找文件就很困难了，这就需要层次结构(即一个目录树)，几乎所有现代文件系统使用的都是层次目录系统。用目录树组织文件系统时，常用绝对路径名(absolute path name)或相对路径名(relative path name)来指明文件名 UNIX 中常见的目录操作的系统调用有 create、delete(只能删除空目录)、opendir、closedir、readdir、rename、link、unlink ","date":"2023-11-19","objectID":"/posts/filesystems/:2:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | File Systems","uri":"/posts/filesystems/"},{"categories":["C++"],"content":"文件系统的实现 ","date":"2023-11-19","objectID":"/posts/filesystems/:3:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | File Systems","uri":"/posts/filesystems/"},{"categories":["C++"],"content":"文件系统布局 文件系统存放在磁盘上。多数磁盘划分为一个或多个分区，每个分区中有一个独立的文件系统 磁盘的 0 号扇区称为主引导记录(Master Boot Record，MBR)，用来引导计算机 MBR 的结尾是分区表，该表给出了每个分区的起始地址和结束地址。表中的一个分区被标记为活动分区，计算机被引导时，BIOS 读入并执行 MBR，MBR 做的第一件事就是确定活动分区，读入第一个块，即引导块(boot block)，并执行 除了引导块，磁盘分区的布局通常随文件系统的不同而变化，一个可能的文件系统布局如下 |-----------------整个磁盘-----------------| 分区表 磁盘分区 ↓ ↙ ↙ ↘ ↘ __________________________________________ |MBR||||________|________|________|________| / \\ / \\ |引导块|超级块|空闲空间管理|i节点|根目录|文件和目录| ","date":"2023-11-19","objectID":"/posts/filesystems/:3:1","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | File Systems","uri":"/posts/filesystems/"},{"categories":["C++"],"content":"文件的实现 文件存储实现的关键是记录文件用到了哪些磁盘块，不同的操作系统的实现方式不同 最简单的方式是连续分配，每个文件作为一连串连续数据块存储在磁盘上，比如块大小为 1 KB 的磁盘上，50 KB 的文件要分配 50 个连续的块。每个文件都要从一个新的块开始，上一个文件末尾块可能会存在部分被浪费的空间 连续分配的优势是实现简单，只需要为每个文件记录第一块的磁盘地址和使用的块数，另外读操作性能较好，单个操作就可以读出整个文件 缺点是删除文件会在磁盘中留下断断续续的空闲块。压缩磁盘代价太高，不可行。维护一个空闲块链表，但创建新文件时，为了选择选择合适的空闲区，必须先给出文件的最终大小，如果用户要创建一个文档然后录入，用户是无法给出最终大小的。但这在 CD-ROM 中是可行的，因为所有文件的大小都事先定好了，并且后续使用也不会被改变 第二种方式是链式分配，这样不会因为磁盘碎片而浪费存储空间，但随机访问很慢，每次要访问一个块时，都必须从第一个块开始。此外，指向下一个块的指针占用了一些字节，每个磁盘块存储数据的字节数不再是 2 的整数次幂，虽然这个问题不是非常严重，但也会降低系统的运行效率，因为程序一般以长度为 2 的整数次幂来读写磁盘块 第三种方式是把链式分配的指针放到内存的一个表中，这个表称为文件分配表(File Allocation Table，FAT)，这样就解决了大小不正常带来的问题，但如果表项过多，比如 1 TB 的磁盘和 1 KB 的块，FAT 有 10 亿项，每项至少占 3 字节，这就占了 3 GB 内存，因此 FAT 在大型磁盘中不实用 最后一种方式是为每个文件赋予一个 i 节点(index-node)的数据结构，其中列出了文件属性和文件块的磁盘地址。给定 i 节点就能找到文件的所有块，这种方式相对于 FAT 的优势是，只有在文件打开时，其 i 节点才在内存中，最终需要的内存与同时打开的最大文件数成正比 ","date":"2023-11-19","objectID":"/posts/filesystems/:3:2","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | File Systems","uri":"/posts/filesystems/"},{"categories":["C++"],"content":"目录的实现 读文件时必须先打开文件，打开文件时，操作系统利用路径名找到目录项，目录项中提供了查找文件磁盘块所需要的信息。这些信息与系统有关，信息可能是整个文件的磁盘地址(对于连续分配的系统)、第一块的编号(链式分配)、i 节点号。文件属性存放的位置可以是目录项或者 i 节点 现代操作系统一般都支持长度可变的长文件名。最简单的实现方式是，给文件名一个长度限制，如 255 个字符，并为每个文件名保留该长度的空间，这种方式简单但浪费了大量目录空间 第二种方式是，每个目录项中开头有一个记录目录项长度的固定部分，接着是文件属性、任意长度的文件名。缺点和连续分配的磁盘碎片问题一样，移除一个个文件后会留下断断续续的空隙。由于整个目录在内存中，只有对目录进行紧凑操作才能节省空间。另一个问题是一个目录项可能会分布在多个页面上，读取文件名时可能发生缺页中断 第三种方式是，使目录项有固定长度，将文件名放在目录后面的堆上，并管理这个堆，这样移除一个目录项后，下一个进来的目录项总可以填满这个空隙 线性查找文件名要从头到尾搜索目录，对于非常长的目录，一个优化方式是在每个目录中使用散列表来映射文件名和对应的目录项 ","date":"2023-11-19","objectID":"/posts/filesystems/:3:3","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | File Systems","uri":"/posts/filesystems/"},{"categories":["C++"],"content":"共享文件 几个用户在同一个项目中工作时常需要共享文件。对于如下文件系统，B 与 C 有一个共享文件，B 的目录与该文件的联系称为一个链接(link)。这样，文件系统本身是一个有向无环图(Derected Acyclic Graph，DAG)而不是一棵树，代价是维护变得复杂 共享文件的问题是，如果目录中包含磁盘地址，链接文件时必须将 C 目录中的磁盘地址复制到 B 目录中，如果 B(或 C)往文件中添加内容，新数据块只会列入 B(或 C)的用户目录中，C(或 B)对此改变是不知道的，这就违背了共享的目的 解决这个问题的第一个方法是，磁盘块不列入目录，而是列入一个与文件关联的小型数据结构，目录将指向这个小型数据结构。这是 UNIX 的做法，小型数据结构就是 i 节点 这种方法的缺点是，B 链接该共享文件时，i 节点记录的文件所有者仍是 C，只是将 i 节点的链接计数加 1，以让系统知道该文件有多少个指向它的目录项。如果 C 之后删除了这个文件，B 就有一个指向无效的i节点的目录项。如果这个 i 节点之后分配给另一个文件，B 的链接将指向一个错误的文件。系统可以通过i节点的计数知道文件被引用，但无法找到所有目录项并删除，也不可能把目录项指针存储在 i 节点中，因为可能有无数个这样的目录 第二个方法是符号链接(symbolic linking)，让系统建立一个 LINK 类型的文件，把该文件放在 B 目录下，使得 B 与 C 的一个文件存在链接。LINK 文件中包含了要链接的文件的路径名，B 读该链接文件时，操作系统发现是 LINK 类型，则找到其链接文件的路径并读取 符号链接在文件被删除后，通过路径名查找文件将失败，因此不会有第一种方法的问题。符号链接的问题在于需要额外开销，必须读取包含路径的文件，然后逐步扫描路径直到找到 i 节点，这些操作可能需要很多次额外的磁盘访问 此外，所有方式的链接都存在的一个问题是，文件有多个路径，如果查找文件，将多次定位到被链接的文件，如果一个程序的功能是查找某个文件并复制，就可能导致多次复制同一文件 ","date":"2023-11-19","objectID":"/posts/filesystems/:3:4","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | File Systems","uri":"/posts/filesystems/"},{"categories":["C++"],"content":"日志结构文件系统(Log-structured File System，LFS) 设计 LFS 的主要原因是，CPU 运行速度越来越快，RAM 内存变得更大，磁盘高速缓存迅速增加，不需要磁盘访问操作，就可能满足直接来自高速缓存的大部分读请求，由此可以推断，未来的磁盘访问多数是写操作，且写操作往往是零碎的，提前读机制并不能获得更好的性能 因此 LFS 的设计者决定重新实现一种 UNIX 文件系统，即使面对一个由大部分为零碎的随机写操作组成的任务，也能够充分利用磁盘带宽 基本思路是，将整个磁盘结构化为一个日志，最初所有写操作都缓冲在内存中，每隔一段时间或有特殊需要时，被缓冲在内存中未执行的写操作被放到一个单独的段中，作为日志末尾的一个邻接段被写入磁盘 但磁盘空间不是无限大的，这种做法最终将导致日志占满整个磁盘，此时就无法再写入新的段。为了解决这个问题，LFS 有一个清理线程，该线程周期性扫描日志进行磁盘压缩。整个磁盘成为一个大的环形缓冲区，写线程将新的段写到前面，清理线程将旧的段从后面移走 LFS 在处理大量零碎写操作时的性能比 UNIX 好一个数量级，在处理读和大块写操作时的性能也不比 UNIX 差，甚至更好 ","date":"2023-11-19","objectID":"/posts/filesystems/:3:5","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | File Systems","uri":"/posts/filesystems/"},{"categories":["C++"],"content":"日志文件系统 由于 LFS 和现有的文件系统不相匹配，所以还未被广泛使用，但其内在的一个思想，即面对出错的鲁棒性，可以被其他文件系统借鉴。这个基本想法是，保存一个用于记录系统下一步要做什么的日志。当系统在完成任务前崩溃时，重新启动后，就能通过查看日志获取崩溃前计划完成的任务。这样的文件系统被称为日志文件系统，并已被实际使用，比如微软的 NTFS、Linux ext3、RerserFS，OS X将日志文件系统作为可选项提供 ","date":"2023-11-19","objectID":"/posts/filesystems/:3:6","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | File Systems","uri":"/posts/filesystems/"},{"categories":["C++"],"content":"虚拟文件系统(Virtual File System，VFS) 同一台计算机或同一个操作系统中，可以有多个不同的文件系统 Windows 有一个主要的 NTFS 文件系统，但也有一个包含 FAT-32 或 FAT-16 的驱动器或分区，此外还可能有 CD-ROM 或者 DVD(每一个包含特定文件系统)，Windows 通过指定盘符来处理不同的文件系统，进程打开文件时，盘符是显式或隐式存在的，Windows 由此可知向哪个文件系统传递请求，不需要将不同的文件系统整合为统一模式 所有现代的 UNIX 尝试将多种文件系统整合到一个统一的结构中。一个 Linux 系统可以用 ext2 作为根文件系统，ext3 分区装载在 /usr 下，采用 RerserFS 的文件系统的硬盘装载在 /home 下，ISO 9660 的 CD-ROM 临时装载在 /mnt 下。用户视角中，只有一个文件系统层级，但实际上是对用户和进程不可见的多种不相容的文件系统 但是多种文件系统的存在在实际应用中是明确可见的，以前大多 UNIX 操作系统都使用 VFS 概念尝试将多种文件系统统一成一个有序结构，其核心思想是抽象出所有文件系统共有的部分为单独一层，这一层通过调用底层的实际文件系统来具体管理数据 UNIX 中，所有文件相关的系统调用最初都指向 VFS，这些来自用户进程的调用都是标准的 POSIX 系统调用，VFS 对用户进程提供的上层接口就是 POSIX 接口。VFS 也有一个对于实际文件系统的下层接口，即 VFS 接口，当创造一个新的文件系统和 VFS 一起工作时，新系统的设计者必须确定它提供 VFS 所需要的功能调用 -------------------------------- 用户进程 -------------------------------- | | POSIX 接口 ↓ -------------------------------- VFS -------------------------------- | | | | | | VFS 接口 ↓ ↓ ↓ -------------------------------- FS1 FS2 FS3 实际文件系统 -------------------------------- ↑ ↑ ↑ | | | ↓ ↓ ↓ -------------------------------- 高速缓冲区 -------------------------------- ","date":"2023-11-19","objectID":"/posts/filesystems/:3:7","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | File Systems","uri":"/posts/filesystems/"},{"categories":["C++"],"content":"文件系统管理和优化 ","date":"2023-11-19","objectID":"/posts/filesystems/:4:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | File Systems","uri":"/posts/filesystems/"},{"categories":["C++"],"content":"磁盘空间管理 几乎所有文件系统都将文件分割成固定大小的块存储，各块之间不一定相邻。块的大小是一个需要考虑的问题，块太小则文件块数越多，需要更多次的寻道与旋转延迟才能读出它们，从而降低了性能。块太大，则文件的最后一个块存在空间浪费。从历史观点上来说，一般设将块大小为 1 到 4 KB，但随着现在磁盘超过了 1 TB，磁盘空间已经不再短缺了，将块的大小提升到 64 KB并接受一些浪费比较好 选定块大小后，下一个问题是如何记录空闲块。有两种方法被广泛使用，一是链表，二是位图 为了防止占用太多磁盘空间，多用户操作系统通常提供了强制性磁盘配额机制，系统管理员为每个用户分配拥有文件和块的最大数量，操作系统确保每个用户不超过得到的配额 ","date":"2023-11-19","objectID":"/posts/filesystems/:4:1","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | File Systems","uri":"/posts/filesystems/"},{"categories":["C++"],"content":"文件系统备份 磁盘转储到磁带上有两种方案 物理转储：从磁盘的第 0 块开始，将全部的磁盘块按序输出到磁带上，直到最后一块复制完毕 逻辑转储：从一个或几个指定的目录开始，递归地转储其自给定日期后有所更改的全部文件和目录 ","date":"2023-11-19","objectID":"/posts/filesystems/:4:2","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | File Systems","uri":"/posts/filesystems/"},{"categories":["C++"],"content":"文件系统的一致性 很多文件系统读取磁盘块，修改后再写回磁盘。如果在写回完成前系统崩溃，文件系统可能处于不一致状态。为此，很多计算机都有一个检查文件系统一致性的实用程序，比如 UNIX 的 fsck、Windows 的 scandisk，系统启动时，特别是崩溃后的重启，可以运行该程序 一致性检查分两种 块的一致性检查：程序构造两张表，每张表为每个块设立一个计数器，第一张表记录块在文件中的出现次数，第二张记录块在空闲区的出现次数。如果文件系统一致，最终每一个块在其中一张表中的计数器为 1，如果一个块在两张表中的计数器都为 0，则称为块丢失 文件的一致性检查：原理同上，区别是一个文件(而非一个块)对应一个计数器。注意，由于存在硬链接，一个文件可能出现在多个目录中。而遇到符号链接是不计数的，不会对目标文件的计数器加 1 ","date":"2023-11-19","objectID":"/posts/filesystems/:4:3","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | File Systems","uri":"/posts/filesystems/"},{"categories":["C++"],"content":"文件系统性能 访问磁盘比访问内存慢很多，如果只需要一个字，内存访问可以比磁盘访问快百万数量级，因此许多文件系统采用了各种优化措施来改善性能 最常用的减少磁盘访问次数的技术是块高速缓存(block cache)或缓冲区高速缓存(buffer cache)，它们逻辑上属于磁盘，但实际上保存在内存中 第二个明显提高性能的技术是块提前读，在需要用到块之前先将块提前写入高速缓存，从而提高命中率。块提前读只适用于顺序读取的文件，如果请求文件系统在某个文件中生成一个块，文件系统将潜在地检查高速缓存，如果下一个块不在缓存中，则为下一个块安排一个预读 另一个重要技术是把可能顺序访问的块放在一起，最好是在同一个柱面上，从而减少磁盘臂的移动次数。这个技术仅当磁盘中装有磁盘臂时才有意义，现在固态硬盘(SSD)越来越流行，而它们不带移动部件。固态硬盘采用了和闪存同样的制造技术，使得随机访问与顺序访问在传输速度上已经较为接近，传统硬盘的诸多问题就消失了，但也有一些新问题，比如每一块只可写入有限次数，使用时要十分小心以达到均匀分散磨损的目的 ","date":"2023-11-19","objectID":"/posts/filesystems/:4:4","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | File Systems","uri":"/posts/filesystems/"},{"categories":["C++"],"content":"磁盘碎片整理 随着不断创建与删除文件，磁盘会逐渐产生许多碎片，创建一个新文件时，其使用的块会散布在整个磁盘上，造成性能降低 一个恢复方式是，移动文件使其相邻，把空闲区放到一个或多个大的连续区域内。Windows 有一个 defrag 程序，就是用于完成这项工作的，Windows 用户应该定期使用它。Linux 文件系统由于其选择磁盘块的方式，在磁盘碎片整理上一般不会遇到 Windows 那样的困难，因此很少需要手动整理磁盘碎片 固态硬盘不受磁盘碎片的影响，对其做磁盘碎片整理不仅没有提高性能，反而磨损了硬盘，缩短了使用寿命 ","date":"2023-11-19","objectID":"/posts/filesystems/:4:5","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | File Systems","uri":"/posts/filesystems/"},{"categories":["C++"],"content":"资源死锁(resource deadlock) 资源分为两类 可抢占资源(preemptable resource): 可以从拥有它的进程中抢占，而不会产生任何副作用，如存储器 不可抢占资源(nonpreemptable resource): 在不引起相关的计算失败的情况下，无法把它从占有它的进程处抢占过来，如光盘刻录机 死锁主要关心不可抢占资源 如果一个进程集合中，每个进程都在等待集合中的其他进程才能引发的事件，则该进程集合就是死锁的。通常这个事件是其他进程释放自身占有的资源，这种死锁称为资源死锁，这是最常见的死锁类型，但不是唯一的类型 发生资源死锁的四个必要条件是: 互斥条件: 每个资源要么分配给一个进程，要么是可用的 占有和等待条件: 已得到某个资源的进程可以再请求新的资源，并且不会释放已有资源 不可抢占条件: 已分配给一个进程的资源不能被强制抢占，只能被占有它的进程显式释放 环路等待条件: 死锁发生时，系统中必然有多个进程组成一条环路，环路中的每个进程都在等待下一个进程所占有的资源 ","date":"2023-11-19","objectID":"/posts/deadlocks/:1:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Dead Locks","uri":"/posts/deadlocks/"},{"categories":["C++"],"content":"鸵鸟算法 最简单的解决方法是，把头埋到沙子里，假装根本没有问题发生。不同人对该方法的看法也不同，数学家认为这种方法完全不可接受，无论代价多大都应该彻底防止死锁发生，工程师认为要根据死锁发生的频率、严重程度、系统崩溃次数来决定，如果死锁每五年发生一次，而系统每个月都会因故障崩溃一次，就没有必要用损失性能和可用性的代价去防止死锁 ","date":"2023-11-19","objectID":"/posts/deadlocks/:2:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Dead Locks","uri":"/posts/deadlocks/"},{"categories":["C++"],"content":"死锁检测和死锁恢复 第二种技术是死锁检测和恢复，使用这种技术时，系统不阻止死锁的产生，而是允许死锁发生，在检测到死锁发生后再恢复 用 E 表示现有资源向量(exisiting resource vector)，A 表示可用资源向量(available resource vector)，用 C 表示当前分配矩阵(current allocation matrix)，用 R 表示请求矩阵(request matrix)，死锁检测的算法是 在 R 中查找是否存在某一行(即一个进程)小于等于 A 如果找到这样一行，就将 C 中相同行数的行(即该进程的已分配资源)加到 A 中，然后标记该进程，再转到上一步 如果不存在这样一行，则算法终止。算法结束时，所有没标记过的进程都是死锁进程 死锁恢复方法有: 抢占、回滚、终止进程 ","date":"2023-11-19","objectID":"/posts/deadlocks/:3:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Dead Locks","uri":"/posts/deadlocks/"},{"categories":["C++"],"content":"死锁避免 如果当前状态下没有死锁发生，并且存在某种调度次序能使每个进程都运行完毕，则称该状态是安全的 对于目前有 3 个空闲资源的如下状态，先分配 2 个资源给 B，B 运行完释放 4 个资源，此时有 5 个空闲资源，接着 5 个资源全分配给 C，C 运行结束后将有 9 个空闲资源，最后将 9 个资源全分配给 A 即可。按 BCA 的分配顺序可以使得所有进程都能完成，因此这个状态是安全的 进程 已分配资源 最大需求 A 3 9 B 2 4 C 2 7 空闲资源数为 2 时的如下状态就是不安全状态。首先只能先运行 B，B 运行结束后共有 4 个空闲资源，无法再运行 A 或 C 进程 已分配资源 最大需求 A 4 9 B 2 4 C 2 7 安全状态和不安全状态的区别是: 从安全状态出发，系统可以保证所有进程都能完成，而从不安全状态出发就没有这样的保证 Dijkstra 提出了一种避免死锁的调度算法，称为银行家算法(banker’s algorithm)，方法是对每一个请求进行检查，如果满足这一请求会到达安全状态，则满足该请求，否则推迟对该请求的满足 之前安全状态的例子考虑的就是单个资源的银行家算法，下面考虑多个资源的银行家算法 已分配资源 进程 资源1 资源2 资源3 资源4 A 3 0 1 1 B 0 1 0 0 C 1 1 1 0 D 1 1 0 1 E 0 0 0 0 仍需要的资源 进程 资源1 资源2 资源3 资源4 A 1 1 0 0 B 0 1 1 2 C 3 1 0 0 D 0 0 1 0 E 2 1 1 0 对应的当前分配矩阵 C 和请求矩阵 R 为 C R 3011 1100 0100 0112 1110 3100 1101 0010 0000 2110 用三个向量表示现有资源 E、已分配资源 P、可用资源 A，计算分配矩阵 C 的每列和得到 P = (5322)，以 E = (6342) 为例，A = E - P = (1020) 检测一个状态是否安全的算法是 查找一个使用可用资源即可运行的进程，如果找不到则系统就会死锁 如果找到，则假设该进程获取所需资源并运行结束，将该进程标记为终止，再将其资源加到 A 上 重复上述两步，如果最后所有进程都被标记为终止，则初始状态是安全的 对于这个例子 进程 D 仍需要的资源为 (0010)，均小于 (1020)，因此运行 D，D 最初的已分配资源为 (1101)，因此结束后 A = (1020) + (1101) = (2121) 进程 A 仍需要的资源为 (1100)，均小于运行 (2121)，运行 A(此时 E 也满足条件，也可以运行 E)，A 最初的已分配资源为 (3011)，结束后 A = (2121) + (3011) = (5132) 运行 B，结束后 A = (5132) + (0100) = (5232) 运行 C，结束后 A = (5232) + (1110) = (6342) 运行 E，结束后 A = (6342) + (0000) = (6342) 所有进程都运行结束，因此这个例子的状态是安全的 ","date":"2023-11-19","objectID":"/posts/deadlocks/:4:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Dead Locks","uri":"/posts/deadlocks/"},{"categories":["C++"],"content":"死锁预防 死锁避免本质上来说是不可能的，因为它需要获取未来的请求，而这些请求是不可知的 死锁发生时，四个条件必须同时成立，因此破坏其中条件即可预防发生死锁 破坏互斥条件: 如果资源不被一个进程独占，就一定不会发生死锁。实际情况中，如果允许两个进程同时使用打印机就会造成混乱，解决这个问题的方法是假脱机打印机技术(spooling printer) 破坏占有并等待条件: 禁止已持有资源的进程再等待其他资源即可。一种实现方法是，规定所有进程在开始执行前请求所需的全部资源。这种方法的问题是，很多进程在运行时才知道需要多少资源，实际上如果进程知道需要多少资源就可以使用银行家算法。另一种方法是，当进程请求资源时，先暂时释放其占有的资源，再尝试一次获取所需的全部资源 破坏不可抢占条件: 这种方法是可能的 破坏环路等待条件: 对资源编号，请求必须按编号升序提出，但问题在于，几乎找不出一种使每个人都满意的编号次序 ","date":"2023-11-19","objectID":"/posts/deadlocks/:5:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Dead Locks","uri":"/posts/deadlocks/"},{"categories":["C++"],"content":"通信死锁(communication deadlock) 除了最常见的资源死锁，还有通信死锁。通信死锁发生在通信系统(如网络)中，比如进程 A 向进程 B 发送请求信息并阻塞至 B 回复，如果 A 发送的信息丢失，就会导致 A 和 B 均阻塞，从而导致死锁 通信死锁可以通过超时来解决，发送者在发送信息时启动计时器，如果计时器在回复到达前停止，则发送者可以认为信息已丢失，并重新发送 ","date":"2023-11-19","objectID":"/posts/deadlocks/:6:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Dead Locks","uri":"/posts/deadlocks/"},{"categories":["C++"],"content":"活锁(livelock) 活锁不会导致进程阻塞，甚至可以说进程正在活动，因此不是死锁，但实际上进程不会继续往下执行，因此可以称为活锁 void process_A() { acquire_lock(\u0026resource_1); while (!try_lock(\u0026resource_2)) { // 进程 A 尝试获取资源 2 失败 release_lock(\u0026resource_1); // 先释放资源 1，一段时间后再尝试获取资源 2 wait_fixed_time(); // 若 B 此时也在等待，则两者都让出了资源但对方都未获取 acquire_lock(\u0026resource_1); // 两者各自拿回资源，则下次获取对方资源仍会失败 } // 若此过程一直重复就是活锁 use_both_resources(); release_lock(\u0026resource_2); release_lock(\u0026resource_1); } void process_B() { acquire_lock(\u0026resource_2); while (!try_lock(\u0026resource_1)) { release_lock(\u0026resource_2); wait_fixed_time(); acquire_lock(\u0026resource_2); } use_both_resources(); release_lock(\u0026resource_1); release_lock(\u0026resource_2); } ","date":"2023-11-19","objectID":"/posts/deadlocks/:7:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action | Dead Locks","uri":"/posts/deadlocks/"},{"categories":["C++"],"content":"内存模型基础 为了避免 race condition，线程就要规定执行顺序。一种方式是使用 mutex，后一线程必须等待前一线程解锁。第二种方式是使用原子操作来避免竞争访问同一内存位置 原子操作是不可分割的操作，要么做了要么没做，不存在做一半的状态。如果读取对象值的加载操作是原子的，那么对象上的所有修改操作也是原子的，读取的要么是初始值，要么是某个修改完成后的存储值。因此，原子操作不存在修改过程中值被其他线程看到的情况，也就避免了竞争风险 每个对象从初始化开始都有一个修改顺序，这个顺序由来自所有线程对该对象的写操作组成。通常这个顺序在运行时会变动，但在任何给定的程序执行中，系统中所有线程都必须遵循此顺序 如果对象不是原子类型，就要通过同步来保证线程遵循每个变量的修改顺序。如果一个变量对于不同线程表现出不同的值序列，就会导致数据竞争和未定义行为。使用原子操作就可以把同步的责任抛给编译器 ","date":"2023-11-18","objectID":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/:1:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [5] | CH05 C++ Memory Model and Operations on Atomic Types","uri":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/"},{"categories":["C++"],"content":"原子操作和原子类型 ","date":"2023-11-18","objectID":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/:2:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [5] | CH05 C++ Memory Model and Operations on Atomic Types","uri":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/"},{"categories":["C++"],"content":"标准原子类型 标准原子类型定义在 \u003catomic\u003e 中。也可以用 mutex 模拟原子操作，实际上标准原子类型可能就是这样实现的，它们都有一个 is_lock_free 函数，返回 true 说明该原子类型操作是无锁的，用的是原子指令，返回 false 则是用锁 struct A { int a[100]; }; struct B { int x, y; }; assert(!std::atomic\u003cA\u003e{}.is_lock_free()); assert(std::atomic\u003cB\u003e{}.is_lock_free()); 原子操作的主要用处是替代 mutex 实现同步。如果原子操作内部是用 mutex 实现的，就不会有期望的性能提升，还不如直接用 mutex 来同步。C++17 中每个原子类型都有一个 is_always_lock_free 成员变量，为 true 时表示该原子类型在此平台上 lock-free assert(std::atomic\u003cint\u003e{}.is_always_lock_free); C++17 之前可以用标准库为各个原子类型定义的 ATOMIC_xxx_LOCK_FREE 宏来判断该类型是否无锁，值为 0 表示原子类型是有锁的，为 2 表示无锁，为 1 表示运行时才能确定 // LOCK-FREE PROPERTY #define ATOMIC_BOOL_LOCK_FREE 2 #define ATOMIC_CHAR_LOCK_FREE 2 #ifdef __cpp_lib_char8_t #define ATOMIC_CHAR8_T_LOCK_FREE 2 #endif // __cpp_lib_char8_t #define ATOMIC_CHAR16_T_LOCK_FREE 2 #define ATOMIC_CHAR32_T_LOCK_FREE 2 #define ATOMIC_WCHAR_T_LOCK_FREE 2 #define ATOMIC_SHORT_LOCK_FREE 2 #define ATOMIC_INT_LOCK_FREE 2 #define ATOMIC_LONG_LOCK_FREE 2 #define ATOMIC_LLONG_LOCK_FREE 2 #define ATOMIC_POINTER_LOCK_FREE 2 只有 std::atomic_flag 未提供 is_lock_free，该类型是一个简单的布尔标志，所有操作都保证 lock-free。基于 std::atomic_flag 就能实现一个简单的锁，并实现其他基础原子类型。其余原子类型可以通过特化 std::atomic 来实现，且可以有更完整的功能，但不保证 lock-free 标准库中为 std::atomic 对内置类型的特化定义了类型别名 namespace std { using atomic_bool = atomic\u003cbool\u003e; using atomic_char = std::atomic\u003cchar\u003e; } // namespace std 通常类型 std::atomic\u003cT\u003e 的别名就是 atomic_T，只有以下几种例外：signed 缩写为 s，unsigned 缩写为 u，long long 缩写为 llong namespace std { using atomic_schar = std::atomic\u003csigned char\u003e; using atomic_uchar = std::atomic\u003cunsigned char\u003e; using atomic_uint = std::atomic\u003cunsigned\u003e; using atomic_ushort = std::atomic\u003cunsigned short\u003e; using atomic_ulong = std::atomic\u003cunsigned long\u003e; using atomic_llong = std::atomic\u003clong long\u003e; using atomic_ullong = std::atomic\u003cunsigned long long\u003e; } // namespace std 原子类型不允许由另一个原子类型拷贝赋值，因为拷贝赋值调用了两个对象，破坏了操作的原子性。但可以用对应的内置类型赋值 T operator=(T desired) noexcept; T operator=(T desired) volatile noexcept; atomic\u0026 operator=(const atomic\u0026) = delete; atomic\u0026 operator=(const atomic\u0026) volatile = delete; 此外 std::atomic 为支持赋值提供了成员函数 std::atomic\u003cT\u003e::store // 替换当前值 std::atomic\u003cT\u003e::load // 返回当前值 std::atomic\u003cT\u003e::exchange // 替换值，并返回被替换前的值 // 与期望值比较，不等则将期望值设为原子值并返回 false // 相等则将原子值设为目标值并返回 true // 在缺少 CAS（compare-and-exchange）指令的机器上，weak 版本在相等时可能替换失败并返回 false // 因此 weak 版本通常要求循环，而 strong 版本返回 false 就能确保不相等 std::atomic\u003cT\u003e::compare_exchange_weak std::atomic\u003cT\u003e::compare_exchange_strong std::atomic\u003cT\u003e::fetch_add // 原子加法，返回相加前的值 std::atomic\u003cT\u003e::fetch_sub // 原子减法，返回相减前的值 std::atomic\u003cT\u003e::fetch_and std::atomic\u003cT\u003e::fetch_or std::atomic\u003cT\u003e::fetch_xor std::atomic\u003cT\u003e::operator++ // 前自增等价于 fetch_add(1) + 1 std::atomic\u003cT\u003e::operator++(int) // 后自增等价于 fetch_add(1) std::atomic\u003cT\u003e::operator-- // 前自减等价于 fetch_sub(1) - 1 std::atomic\u003cT\u003e::operator--(int) // 后自减等价于 fetch_sub(1) std::atomic\u003cT\u003e::operator+= // fetch_add(x) + x std::atomic\u003cT\u003e::operator-= // fetch_sub(x) - x std::atomic\u003cT\u003e::operator\u0026= // fetch_and(x) \u0026 x std::atomic\u003cT\u003e::operator|= // fetch_or(x) | x std::atomic\u003cT\u003e::operator^= // fetch_xor(x) ^ x 这些成员函数有一个用来指定内存序的参数 std::memory_order，后续会解释内存序的含义 typedef enum memory_order { memory_order_relaxed, memory_order_consume, memory_order_acquire, memory_order_release, memory_order_acq_rel, memory_order_seq_cst } memory_order; void store(T desired, std::memory_order order = std::memory_order_seq_cst); // store 的内存序只能是 // memory_order_relaxed、memory_order_release、memory_order_seq_cst T load(std::memory_order order = std::memory_order_seq_cst); // load 的内存序只能是 // memory_order_relaxed、memory_order_consume、memory_order_acquire、memory_order_seq_cst ","date":"2023-11-18","objectID":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/:2:1","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [5] | CH05 C++ Memory Model and Operations on Atomic Types","uri":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/"},{"categories":["C++"],"content":"std::atomic_flag std::atomic_flag 是一个原子的布尔类型，也是唯一保证 lock-free 的原子类型，只能用 ATOMIC_FLAG_INIT 初始化为 false std::atomic_flag x = ATOMIC_FLAG_INIT; x.clear(std::memory_order_release); // 将状态设为 false // 不能为读操作语义：memory_order_consume、memory_order_acquire、memory_order_acq_rel bool y = x.test_and_set(); // 将状态设为 true 且返回之前的值 用 std::atomic_flag 实现自旋锁 #include \u003catomic\u003e #include \u003ciostream\u003e #include \u003cthread\u003e #include \u003cvector\u003e class Spinlock { public: void lock() { while (flag_.test_and_set(std::memory_order_acquire)) { } } void unlock() { flag_.clear(std::memory_order_release); } private: std::atomic_flag flag_ = ATOMIC_FLAG_INIT; }; Spinlock m; void f(int n) { for (int i = 0; i \u003c 100; ++i) { m.lock(); std::cout \u003c\u003c \"Output from thread \" \u003c\u003c n \u003c\u003c '\\n'; m.unlock(); } } int main() { std::vector\u003cstd::thread\u003e v; for (int i = 0; i \u003c 10; ++i) { v.emplace_back(f, i); } for (auto\u0026 x : v) { x.join(); } } ","date":"2023-11-18","objectID":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/:2:2","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [5] | CH05 C++ Memory Model and Operations on Atomic Types","uri":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/"},{"categories":["C++"],"content":"其他原子类型 std::atomic_flag 功能过于局限，甚至无法像布尔类型一样使用，相比之下，std::atomic\u003cbool\u003e 更易用，它不保证 lock-free，可以用 is_lock_free 检验在当前平台上是否 lock-free std::atomic\u003cbool\u003e x(true); x = false; bool y = x.load(std::memory_order_acquire); // 读取 x 值返回给 y x.store(true); // x 写为 true y = x.exchange(false, std::memory_order_acq_rel); // x 用 false 替换，并返回旧值给 y bool expected = false; // 期望值 // 不等则将期望值设为 x 并返回 false，相等则将 x 设为目标值 true 并返回 true // weak 版本在相等时也可能替换失败而返回 false，因此一般用于循环 while (!x.compare_exchange_weak(expected, true) \u0026\u0026 !expected) { } // 对于只有两种值的 std::atomic\u003cbool\u003e 来说显得有些繁琐 // 但对其他原子类型来说，这个影响就大了 指针原子类型 std::atomic\u003cT*\u003e 也支持 is_lock_free、load、store、exchange、compare_exchange_weak、compare_exchange_strong，与 std::atomic\u003cbool\u003e 语义相同，只不过读取和返回的类型是 T* 而非 bool。此外指针原子类型还支持运算操作：fetch_add、fetch_sub、++、–、+=、-= class A {}; A a[5]; std::atomic\u003cA*\u003e p(a); // p 为 \u0026a[0] A* x = p.fetch_add(2); // p 为 \u0026a[2]，并返回原始值 a[0] assert(x == a); assert(p.load() == \u0026a[2]); x = (p -= 1); // p 为 \u0026a[1]，并返回给 x，相当于 x = p.fetch_sub(1) - 1 assert(x == \u0026a[1]); assert(p.load() == \u0026a[1]); 整型原子类型（如 std::atomic\u003cint\u003e）在上述操作之外还支持 fetch_or、fetch_and、fetch_xor、|=、\u0026=、^= std::atomic\u003cint\u003e i(5); int j = i.fetch_and(3); // 101 \u0026 011 = 001 assert(i == 1); assert(j == 5); 用整型原子类型实现 Spinlock #include \u003catomic\u003e class Spinlock { public: void lock() { int expected = 0; while (!flag_.compare_exchange_weak(expected, 1, std::memory_order_release, std::memory_order_relaxed)) { expected = 0; } } void unlock() { flag_.store(0, std::memory_order_release); } private: std::atomic\u003cint\u003e flag_ = 0; }; 用整型原子类型实现 SharedSpinlock #include \u003catomic\u003e class SharedSpinlock { public: void lock() { int expected = 0; while (!flag_.compare_exchange_weak(expected, 1, std::memory_order_release, std::memory_order_relaxed)) { expected = 0; } } void unlock() { flag_.store(0, std::memory_order_release); } void lock_shared() { int expected = 0; while (!flag_.compare_exchange_weak(expected, 2, std::memory_order_release, std::memory_order_acquire) \u0026\u0026 expected == 2) { expected = 0; } count_.fetch_add(1, std::memory_order_release); } void unlock_shared() { if (count_.fetch_sub(1, std::memory_order_release) == 1) { flag_.store(0, std::memory_order_release); } } private: std::atomic\u003cint\u003e flag_ = 0; std::atomic\u003cint\u003e count_ = 0; }; 用整型原子类型实现 Barrier #include \u003catomic\u003e #include \u003cthread\u003e class Barrier { public: explicit Barrier(unsigned n) : count_(n), spaces_(n), generation_(0) {} void wait() { unsigned gen = generation_.load(); if (--spaces_ == 0) { spaces_ = count_.load(); ++generation_; return; } while (generation_.load() == gen) { std::this_thread::yield(); } } void arrive() { --count_; if (--spaces_ == 0) { spaces_ = count_.load(); ++generation_; } } private: std::atomic\u003cunsigned\u003e count_; // 需要同步的线程数 std::atomic\u003cunsigned\u003e spaces_; // 剩余未到达 Barrier 的线程数 std::atomic\u003cunsigned\u003e generation_; // 所有线程到达 Barrier 的总次数 }; 如果原子类型是自定义类型，该自定义类型必须可平凡复制（trivially copyable），也就意味着该类型不能有虚函数或虚基类。这可以用 is_trivially_copyable 检验 class A { public: virtual void f() {} }; assert(!std::is_trivially_copyable_v\u003cA\u003e); std::atomic\u003cA\u003e a; // 错误：A 不满足 trivially copyable std::atomic\u003cstd::vector\u003cint\u003e\u003e v; // 错误 std::atomic\u003cstd::string\u003e s; // 错误 自定义类型的原子类型不允许运算操作，只允许 is_lock_free、load、store、exchange、compare_exchange_weak、compare_exchange_strong，以及赋值操作和向自定义类型转换的操作 除了每个类型各自的成员函数，原子操作库还提供了通用的自由函数，只不过函数名多了一个 atomic_ 前缀，参数变为指针类型 std::atomic\u003cint\u003e i(42); int j = std::atomic_load(\u0026i); // 等价于 i.load() 除 std::atomic_is_lock_free 外，每个自由函数有一个 _explicit 后缀版本，_explicit 自由函数额外接受一个内存序参数 std::atomic\u003cint\u003e i(42); std::atomic_load_explicit(\u0026i, std::memory_order_acquire); // i.load(std::memory_order_acquire) 自由函数的设计主要考虑的是 C 语言没有引用而只能使用指针，compare_exchange_weak、compare_exchange_strong 的第一个参数是引用，因此 std::atomic_compare_exchange_weak、std::atomic_compare_exchange_strong 的参数用的是指针 bool compare_exchange_weak(T\u0026 expected, T desired, std::memory_order success, std::memory_order failure); template \u003cclass T\u003e bool atomic_compare_exchange_weak(std::atomic\u003cT\u003e* obj, typename std::atomic\u003cT\u003e::value_type* expected, typename std::atomi","date":"2023-11-18","objectID":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/:2:3","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [5] | CH05 C++ Memory Model and Operations on Atomic Types","uri":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/"},{"categories":["C++"],"content":"同步操作和强制排序（enforced ordering） 两个线程分别读写数据，为了避免竞争，设置一个标记 std::vector\u003cint\u003e data; std::atomic\u003cbool\u003e data_ready(false); void read_thread() { while (!data_ready.load()) { // 1 happens-before 2 std::this_thread::sleep_for(std::chrono::milliseconds(1)); } std::cout \u003c\u003c data[0]; // 2 } void write_thread() { data.emplace_back(42); // 3 happens-before 4 data_ready = true; // 4 inter-thread happens-before 1 } std::atomic\u003cbool\u003e 上的操作要求强制排序，该顺序由内存模型关系 happens-before 和 synchronizes-with 提供 happens-before 保证了 1 在 2 之前发生，3 在 4 之前发生，而 1 要求 4，所以 4 在 1 之前发生，最终顺序确定为 3412 如果没有强制排序，CPU 可能会调整指令顺序，如果顺序是 4123，读操作就会因为越界而出错 ","date":"2023-11-18","objectID":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/:3:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [5] | CH05 C++ Memory Model and Operations on Atomic Types","uri":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/"},{"categories":["C++"],"content":"synchronizes-with synchronizes-with 关系只存在于原子类型操作上，如果一个数据结构包含原子类型，这个数据结构上的操作（比如加锁）也可能提供 synchronizes-with 关系 变量 x 上，标记了内存序的原子写操作 W，和标记了内存序的原子读操作，如果两者存在 synchronizes-with 关系，表示读操作读取的是：W 写入的值，或 W 之后同一线程上原子写操作写入 x 的值，或任意线程上对 x 的一系列原子读改写操作（比如 fetch_add、compare_exchange_weak）的值 简单来说，如果线程 A 写入一个值，线程 B 读取该值，则 A synchronizes-with B ","date":"2023-11-18","objectID":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/:3:1","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [5] | CH05 C++ Memory Model and Operations on Atomic Types","uri":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/"},{"categories":["C++"],"content":"happens-before happens-before 和 strongly-happens-before 关系是程序操作顺序的基本构建块，它指定某个操作可以看到其他操作的结果。对单线程来说很简单，如果一个操作在另一个之前，就可以说前一个操作 happens-before（且 strongly-happens-before） 后一个操作 如果操作发生在同一语句中，一般不存在 happens-before 关系，因为它们是无序的 #include \u003ciostream\u003e void f(int x, int y) { std::cout \u003c\u003c x \u003c\u003c y; } int g() { static int i = 0; return ++i; } int main() { f(g(), g()); // 无序调用 g，可能是 21 也可能是 12 // 一般 C++ 默认使用 __cdecl 调用模式，参数从右往左入栈，就是21 } 前一条语句中的所有操作都 happens-before 下一条语句中的所有操作 ","date":"2023-11-18","objectID":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/:3:2","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [5] | CH05 C++ Memory Model and Operations on Atomic Types","uri":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/"},{"categories":["C++"],"content":"inter-thread happens-before 如果一个线程中的操作 A happens-before 另一个线程中的操作 B，则 A inter-thread happens-before B A inter-thread happens-before B 包括以下情况 A synchronizes-with B A dependency-ordered-before B A inter-thread happens-before X，X inter-thread happens-before B A sequenced-before X，X inter-thread happens-before B A synchronizes-with X，X sequenced-before B ","date":"2023-11-18","objectID":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/:3:3","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [5] | CH05 C++ Memory Model and Operations on Atomic Types","uri":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/"},{"categories":["C++"],"content":"strongly-happens-before strongly-happens-before 关系大多数情况下和 happens-before 一样，A strongly-happens-before B 包括以下情况 A synchronizes-with B A sequenced-before X，X inter-thread happens-before B A strongly-happens-before X，X strongly-happens-before B 略微不同的是，inter-thread happens-before 关系可以用 memory_order_consume 标记，而 strongly-happens-before 不行。但大多数代码不应该使用 memory_order_consume，所以这点实际上影响不大 ","date":"2023-11-18","objectID":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/:3:4","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [5] | CH05 C++ Memory Model and Operations on Atomic Types","uri":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/"},{"categories":["C++"],"content":"std::memory_order typedef enum memory_order { memory_order_relaxed, // 无同步或顺序限制，只保证当前操作原子性 memory_order_consume, // 标记读操作，依赖于该值的读写不能重排到此操作前 memory_order_acquire, // 标记读操作，之后的读写不能重排到此操作前 memory_order_release, // 标记写操作，之前的读写不能重排到此操作后 memory_order_acq_rel, // 仅标记读改写操作，读操作相当于 acquire，写操作相当于 release memory_order_seq_cst // sequential consistency：顺序一致性，不允许重排，所有原子操作的默认选项 } memory_order; ","date":"2023-11-18","objectID":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/:3:5","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [5] | CH05 C++ Memory Model and Operations on Atomic Types","uri":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/"},{"categories":["C++"],"content":"Relaxed ordering 标记为 memory_order_relaxed 的原子操作不是同步操作，不强制要求并发内存的访问顺序，只保证原子性和修改顺序一致性 #include \u003catomic\u003e #include \u003cthread\u003e std::atomic\u003cint\u003e x = 0; std::atomic\u003cint\u003e y = 0; void f() { int i = y.load(std::memory_order_relaxed); // 1 x.store(i, std::memory_order_relaxed); // 2 } void g() { int j = x.load(std::memory_order_relaxed); // 3 y.store(42, std::memory_order_relaxed); // 4 } int main() { std::thread t1(f); std::thread t2(g); t1.join(); t2.join(); // 可能执行顺序为 4123，结果 i == 42, j == 42 } Relaxed ordering 不允许循环依赖 #include \u003catomic\u003e #include \u003cthread\u003e std::atomic\u003cint\u003e x = 0; std::atomic\u003cint\u003e y = 0; void f() { i = y.load(std::memory_order_relaxed); // 1 if (i == 42) { x.store(i, std::memory_order_relaxed); // 2 } } void g() { j = x.load(std::memory_order_relaxed); // 3 if (j == 42) { y.store(42, std::memory_order_relaxed); // 4 } } int main() { std::thread t1(f); std::thread t2(g); t1.join(); t2.join(); // 结果不允许为i == 42, j == 42 // 因为要产生这个结果，1 依赖 4，4 依赖 3，3 依赖 2，2 依赖 1 } 典型使用场景是自增计数器，比如 std::shared_ptr 的引用计数器，它只要求原子性，不要求顺序和同步 #include \u003catomic\u003e #include \u003ciostream\u003e #include \u003cthread\u003e #include \u003cvector\u003e std::atomic\u003cint\u003e x = 0; void f() { for (int i = 0; i \u003c 1000; ++i) { x.fetch_add(1, std::memory_order_relaxed); } } int main() { std::vector\u003cstd::thread\u003e v; for (int i = 0; i \u003c 10; ++i) { v.emplace_back(f); } for (auto\u0026 x : v) { x.join(); } std::cout \u003c\u003c x; // 10000 } ","date":"2023-11-18","objectID":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/:3:6","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [5] | CH05 C++ Memory Model and Operations on Atomic Types","uri":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/"},{"categories":["C++"],"content":"Release-Consume ordering 对于标记为 memory_order_consume 原子变量 x 的读操作 R，当前线程中依赖于 x 的读写不允许重排到 R 之前，其他线程中对依赖于 x 的变量写操作对当前线程可见 如果线程 A 对一个原子变量x的写操作为 memory_order_release，线程 B 对同一原子变量的读操作为 memory_order_consume，带来的副作用是，线程 A 中所有 dependency-ordered-before 该写操作的其他写操作（non-atomic和relaxed atomic），在线程 B 的其他依赖于该变量的读操作中可见 典型使用场景是访问很少进行写操作的数据结构（比如路由表），以及以指针为中介的 publisher-subscriber 场景，即生产者发布一个指针给消费者访问信息，但生产者写入内存的其他内容不需要对消费者可见，这个场景的一个例子是 RCU（Read-Copy Update）。该顺序的规范正在修订中，并且暂时不鼓励使用 memory_order_consume #include \u003catomic\u003e #include \u003ccassert\u003e #include \u003cthread\u003e std::atomic\u003cint*\u003e x; int i; void producer() { int* p = new int(42); i = 42; x.store(p, std::memory_order_release); } void consumer() { int* q; while (!(q = x.load(std::memory_order_consume))) { } assert(*q == 42); // 一定不出错：*q 带有 x 的依赖 assert(i == 42); // 可能出错也可能不出错：i 不依赖于 x } int main() { std::thread t1(producer); std::thread t2(consumer); t1.join(); t2.join(); } ","date":"2023-11-18","objectID":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/:3:7","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [5] | CH05 C++ Memory Model and Operations on Atomic Types","uri":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/"},{"categories":["C++"],"content":"Release-Acquire ordering 对于标记为 memory_order_acquire 的读操作 R，当前线程的其他读写操作不允许重排到 R 之前，其他线程中在同一原子变量上所有的写操作在当前线程可见 如果线程 A 对一个原子变量的写操作 W 为 memory_order_release，线程 B 对同一原子变量的读操作为 memory_order_acquire，带来的副作用是，线程 A 中所有 happens-before W 的写操作（non-atomic 和 relaxed atomic）都在线程 B 中可见 典型使用场景是互斥锁，线程 A 的释放后被线程 B 获取，则 A 中释放锁之前发生在 critical section 的所有内容都在 B 中可见 #include \u003catomic\u003e #include \u003ccassert\u003e #include \u003cthread\u003e std::atomic\u003cint*\u003e x; int i; void producer() { int* p = new int(42); i = 42; x.store(p, std::memory_order_release); } void consumer() { int* q; while (!(q = x.load(std::memory_order_acquire))) { } assert(*q == 42); // 一定不出错 assert(i == 42); // 一定不出错 } int main() { std::thread t1(producer); std::thread t2(consumer); t1.join(); t2.join(); } 对于标记为 memory_order_release 的写操作 W，当前线程中的其他读写操作不允许重排到W之后，若其他线程 acquire 该原子变量，则当前线程所有 happens-before 的写操作在其他线程中可见，若其他线程 consume 该原子变量，则当前线程所有 dependency-ordered-before W 的其他写操作在其他线程中可见 对于标记为 memory_order_acq_rel 的读改写（read-modify-write）操作，相当于写操作是 memory_order_release，读操作是 memory_order_acquire，当前线程的读写不允许重排到这个写操作之前或之后，其他线程中 release 该原子变量的写操作在修改前可见，并且此修改对其他 acquire 该原子变量的线程可见 Release-Acquire ordering 并不表示 total ordering #include \u003catomic\u003e #include \u003cthread\u003e std::atomic\u003cbool\u003e x = false; std::atomic\u003cbool\u003e y = false; std::atomic\u003cint\u003e z = 0; void write_x() { x.store(true, std::memory_order_release); // 1 happens-before 3（由于 3 的循环） } void write_y() { y.store(true, std::memory_order_release); // 2 happens-before 5（由于 5 的循环） } void read_x_then_y() { while (!x.load(std::memory_order_acquire)) { // 3 happens-before 4 } if (y.load(std::memory_order_acquire)) { // 4 ++z; } } void read_y_then_x() { while (!y.load(std::memory_order_acquire)) { // 5 happens-before 6 } if (x.load(std::memory_order_acquire)) { // 6 ++z; } } int main() { std::thread t1(write_x); std::thread t2(write_y); std::thread t3(read_x_then_y); std::thread t4(read_y_then_x); t1.join(); t2.join(); t3.join(); t4.join(); // z 可能为 0，134 y 为 false，256 x 为 false，但 12 之间没有关系 } 为了使两个写操作有序，将其放到一个线程里 #include \u003catomic\u003e #include \u003ccassert\u003e #include \u003cthread\u003e std::atomic\u003cbool\u003e x = false; std::atomic\u003cbool\u003e y = false; std::atomic\u003cint\u003e z = 0; void write_x_then_y() { x.store(true, std::memory_order_relaxed); // 1 happens-before 2 y.store(true, std::memory_order_release); // 2 happens-before 3（由于 3 的循环） } void read_y_then_x() { while (!y.load(std::memory_order_acquire)) { // 3 happens-before 4 } if (x.load(std::memory_order_relaxed)) { // 4 ++z; } } int main() { std::thread t1(write_x_then_y); std::thread t2(read_y_then_x); t1.join(); t2.join(); assert(z.load() != 0); // 顺序一定为 1234，z 一定不为 0 } 利用 Release-Acquire ordering 可以传递同步 #include \u003catomic\u003e #include \u003ccassert\u003e std::atomic\u003cbool\u003e x = false; std::atomic\u003cbool\u003e y = false; std::atomic\u003cint\u003e v[2]; void f() { // v[0]、v[1] 的设置没有先后顺序，但都 happens-before 1 v[0].store(1, std::memory_order_relaxed); v[1].store(2, std::memory_order_relaxed); x.store(true, std::memory_order_release); // 1 happens-before 2（由于 2 的循环） } void g() { while (!x.load(std::memory_order_acquire)) { // 2：happens-before 3 } y.store(true, std::memory_order_release); // 3 happens-before 4（由于 4 的循环） } void h() { while (!y.load( std::memory_order_acquire)) { // 4 happens-before v[0]、v[1] 的读取 } assert(v[0].load(std::memory_order_relaxed) == 1); assert(v[1].load(std::memory_order_relaxed) == 2); } 使用读改写操作可以将上面的两个标记合并为一个 #include \u003catomic\u003e #include \u003ccassert\u003e std::atomic\u003cint\u003e x = 0; std::atomic\u003cint\u003e v[2]; void f() { v[0].store(1, std::memory_order_relaxed); v[1].store(2, std::memory_order_relaxed); x.store(1, std::memory_order_release); // 1 happens-before 2（由于 2 的循环） } void g() { int i = 1; while (!x.compare_exchange_strong( i, 2, std::memory_order_acq_rel)) { // 2 happens-before 3（由于 3 的循环） // x 为 1 时，将 x 替换为 2，返回 true // x 为 0 时，将 i 替换为 x，返回 false i = 1; // 返回 false 时，x 未被替换，i 被替换为 0，因此将 i 重新设为 1 } } void h() { while (x.load(std::memory_order_acquire) \u003c 2) { // 3 } assert(v[0].load(std::memory_order_relaxed) == 1); assert(v[1].load(std::memory_order_relaxed) == 2); } ","date":"2023-11-18","objectID":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/:3:8","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [5] | CH05 C++ Memory Model and Operations on Atomic Types","uri":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/"},{"categories":["C++"],"content":"Sequentially-consistent ordering memory_order_seq_cst 是所有原子操作的默认选项，可以省略不写。对于标记为 memory_order_seq_cst 的操作，读操作相当于 memory_order_acquire，写操作相当于 memory_order_release，读改写操作相当于 memory_order_acq_rel，此外还附加一个单独的 total ordering，即所有线程对同一操作看到的顺序也是相同的。这是最简单直观的顺序，但由于要求全局的线程同步，因此也是开销最大的 #include \u003catomic\u003e #include \u003ccassert\u003e #include \u003cthread\u003e std::atomic\u003cbool\u003e x = false; std::atomic\u003cbool\u003e y = false; std::atomic\u003cint\u003e z = 0; // 要么 1 happens-before 2，要么 2 happens-before 1 void write_x() { x.store(true); // 1 happens-before 3（由于 3 的循环） } void write_y() { y.store(true); // 2 happens-before 5（由于 5 的循环） } void read_x_then_y() { while (!x.load()) { // 3 happens-before 4 } if (y.load()) { // 4 为 false 则 1 happens-before 2 ++z; } } void read_y_then_x() { while (!y.load()) { // 5 happens-before 6 } if (x.load()) { // 6 如果返回 false 则一定是 2 happens-before 1 ++z; } } int main() { std::thread t1(write_x); std::thread t2(write_y); std::thread t3(read_x_then_y); std::thread t4(read_y_then_x); t1.join(); t2.join(); t3.join(); t4.join(); assert(z.load() != 0); // z 一定不为 0 // z 可能为 1 或 2，12 之间必定存在 happens-before 关系 } ","date":"2023-11-18","objectID":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/:3:9","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [5] | CH05 C++ Memory Model and Operations on Atomic Types","uri":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/"},{"categories":["C++"],"content":"std::atomic_thread_fence #include \u003catomic\u003e #include \u003ccassert\u003e #include \u003cthread\u003e std::atomic\u003cbool\u003e x, y; std::atomic\u003cint\u003e z; void f() { x.store(true, std::memory_order_relaxed); // 1 happens-before 2 std::atomic_thread_fence(std::memory_order_release); // 2 synchronizes-with 3 y.store(true, std::memory_order_relaxed); } void g() { while (!y.load(std::memory_order_relaxed)) { } std::atomic_thread_fence(std::memory_order_acquire); // 3 happens-before 4 if (x.load(std::memory_order_relaxed)) { // 4 ++z; } } int main() { x = false; y = false; z = 0; std::thread t1(f); std::thread t2(g); t1.join(); t2.join(); assert(z.load() != 0); // 1 happens-before 4 } 将 x 替换为非原子 bool 类型，行为也一样 #include \u003catomic\u003e #include \u003ccassert\u003e #include \u003cthread\u003e bool x = false; std::atomic\u003cbool\u003e y; std::atomic\u003cint\u003e z; void f() { x = true; // 1 happens-before 2 std::atomic_thread_fence(std::memory_order_release); // 2 synchronizes-with 3 y.store(true, std::memory_order_relaxed); } void g() { while (!y.load(std::memory_order_relaxed)) { } std::atomic_thread_fence(std::memory_order_acquire); // 3 happens-before 4 if (x) { // 4 ++z; } } int main() { x = false; y = false; z = 0; std::thread t1(f); std::thread t2(g); t1.join(); t2.join(); assert(z.load() != 0); // 1 happens-before 4 } ","date":"2023-11-18","objectID":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/:3:10","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [5] | CH05 C++ Memory Model and Operations on Atomic Types","uri":"/posts/ch05_cpp_memory_model_and_operations_on_atomic_types/"},{"categories":["C++"],"content":"条件变量（condition variable） 在并发编程中，一种常见的需求是，一个线程等待另一个线程完成某个事件后，再继续执行任务。对于这种情况，标准库提供了 std::condition_variable #include \u003ccondition_variable\u003e #include \u003ciostream\u003e #include \u003cmutex\u003e #include \u003cthread\u003e class A { public: void step1() { { std::lock_guard\u003cstd::mutex\u003e l(m_); step1_done_ = true; } std::cout \u003c\u003c 1; cv_.notify_one(); } void step2() { std::unique_lock\u003cstd::mutex\u003e l(m_); cv_.wait(l, [this] { return step1_done_; }); step2_done_ = true; std::cout \u003c\u003c 2; cv_.notify_one(); } void step3() { std::unique_lock\u003cstd::mutex\u003e l(m_); cv_.wait(l, [this] { return step2_done_; }); std::cout \u003c\u003c 3; } private: std::mutex m_; std::condition_variable cv_; bool step1_done_ = false; bool step2_done_ = false; }; int main() { A a; std::thread t1(\u0026A::step1, \u0026a); std::thread t2(\u0026A::step2, \u0026a); std::thread t3(\u0026A::step3, \u0026a); t1.join(); t2.join(); t3.join(); } // 123 有多个能唤醒的任务时，notify_one() 会随机唤醒一个 #include \u003ccondition_variable\u003e #include \u003ciostream\u003e #include \u003cmutex\u003e #include \u003cthread\u003e class A { public: void wait1() { std::unique_lock\u003cstd::mutex\u003e l(m_); cv_.wait(l, [this] { return done_; }); std::cout \u003c\u003c 1; } void wait2() { std::unique_lock\u003cstd::mutex\u003e l(m_); cv_.wait(l, [this] { return done_; }); std::cout \u003c\u003c 2; } void signal() { { std::lock_guard\u003cstd::mutex\u003e l(m_); done_ = true; } cv_.notify_all(); } private: std::mutex m_; std::condition_variable cv_; bool done_ = false; }; int main() { A a; std::thread t1(\u0026A::wait1, \u0026a); std::thread t2(\u0026A::wait2, \u0026a); std::thread t3(\u0026A::signal, \u0026a); t1.join(); t2.join(); t3.join(); } // 12 or 21 std::condition_variable 只能与 std::unique_lock 协作，为此标准库提供了更通用的 std::condition_variable_any #include \u003ccondition_variable\u003e #include \u003ciostream\u003e #include \u003cmutex\u003e #include \u003cthread\u003e class Mutex { public: void lock() {} void unlock() {} }; class A { public: void signal() { std::cout \u003c\u003c 1; cv_.notify_one(); } void wait() { Mutex m; cv_.wait(m); std::cout \u003c\u003c 2; } private: std::condition_variable_any cv_; }; int main() { A a; std::thread t1(\u0026A::signal, \u0026a); std::thread t2(\u0026A::wait, \u0026a); t1.join(); t2.join(); } // 12 与 std::stack 一样，std::queue 的 front 和 pop 存在 race condition，为此将 front 和 pop 合并成 try_pop 函数，此外利用 std::condition_variable 实现 wait_and_pop 的接口，当没有元素可弹出时会阻塞，直至有元素可弹出 #include \u003ccondition_variable\u003e #include \u003cmemory\u003e #include \u003cmutex\u003e #include \u003cqueue\u003e template \u003ctypename T\u003e class ConcurrentQueue { public: ConcurrentQueue() = default; ConcurrentQueue(const ConcurrentQueue\u0026 rhs) { std::lock_guard\u003cstd::mutex\u003e l(rhs.m_); q_ = rhs.q_; } void push(T x) { std::lock_guard\u003cstd::mutex\u003e l(m_); q_.push(std::move(x)); cv_.notify_one(); } void wait_and_pop(T\u0026 res) { std::unique_lock\u003cstd::mutex\u003e l(m_); cv_.wait(l, [this] { return !q_.empty(); }); res = std::move(q_.front()); q_.pop(); } std::shared_ptr\u003cT\u003e wait_and_pop() { std::unique_lock\u003cstd::mutex\u003e l(m_); cv_.wait(l, [this] { return !q_.empty(); }); auto res = std::make_shared\u003cT\u003e(std::move(q_.front())); q_.pop(); return res; } bool try_pop(T\u0026 res) { std::lock_guard\u003cstd::mutex\u003e l(m_); if (q_.empty()) { return false; } res = std::move(q_.front()); q_.pop(); return true; } std::shared_ptr\u003cT\u003e try_pop() { std::lock_guard\u003cstd::mutex\u003e l(m_); if (q_.empty()) { return nullptr; } auto res = std::make_shared\u003cT\u003e(std::move(q_.front())); q_.pop(); return res; } bool empty() const { std::lock_guard\u003cstd::mutex\u003e l(m_); // 其他线程可能有此对象（拷贝构造）所以要上锁 return q_.empty(); } private: mutable std::mutex m_; std::condition_variable cv_; std::queue\u003cT\u003e q_; }; 这个实现有一个异常安全问题，notify_one() 只会唤醒一个线程，如果多线程等待时，被唤醒线程 wait_and_pop 中抛出异常（如构造 std::shared_ptr 对象时可能抛异常），其余线程将永远不被唤醒。用 notify_all() 可解决此问题，但会有不必要的唤醒，抛出异常时再调用 notify_one() 更好一些。对于此场景，最好的做法是将内部的 std::queue\u003cT\u003e 改为 std::queue\u003cstd::shared_ptr\u003cT\u003e\u003e，std::shared_ptr 对象只在 push 中构造，这样 wait_and_pop 就不会抛异常 #include \u003ccondition_variable\u003e #include \u003cmemory\u003e #include \u003cmutex\u003e #include \u003cqueue\u003e #include \u003cutility\u003e template \u003ctypename T\u003e class ConcurrentQueue { public: ConcurrentQueue() = default; ConcurrentQueue(const ConcurrentQueue\u0026 rhs) { std::lock_guard\u003cstd::mutex\u003e l(rhs.m_); q_ = rhs.q_; } void push(T x) { a","date":"2023-11-05","objectID":"/posts/ch04_synchronizing_concurrent_operation/:1:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [4] | CH04 Synchronizing concurrent operations","uri":"/posts/ch04_synchronizing_concurrent_operation/"},{"categories":["C++"],"content":"信号量（semaphore） 信号量用于实现多线程之间指定数量的事件通知，P 操作对信号量减 1，V 操作对信号量加 1，若 P 操作将导致信号量小于 0 则阻塞，直至可减少信号量为止。C++20 提供了 std::counting_semaphore ，构造时通过模板参数设置信号量的最大值，通过函数参数设置信号量的初始值，acquire() 即 P 操作，会在信号量值不小于 0 时将信号量减 1，否则阻塞至可以减 1 为止，release() 即 V 操作，会将信号量加上指定值（不指定则加 1），并唤醒指定数量的被 acquire() 阻塞的信号量 #include \u003ciostream\u003e #include \u003csemaphore\u003e #include \u003cthread\u003e class A { public: void wait1() { sem_.acquire(); std::cout \u003c\u003c 1; } void wait2() { sem_.acquire(); std::cout \u003c\u003c 2; } void signal() { sem_.release(2); } private: std::counting_semaphore\u003c2\u003e sem_{0}; // 初始值 0，最大值 2 }; int main() { A a; std::thread t1(\u0026A::wait1, \u0026a); std::thread t2(\u0026A::wait2, \u0026a); std::thread t3(\u0026A::signal, \u0026a); t1.join(); t2.join(); t3.join(); } // 12 or 21 std::binary_semaphore 是最大值为 1 的信号量，它是模板参数为 1 的 std::counting_semaphore 的别名 #include \u003ciostream\u003e #include \u003csemaphore\u003e #include \u003cthread\u003e class A { public: void wait() { sem_.acquire(); std::cout \u003c\u003c 2; } void signal() { std::cout \u003c\u003c 1; sem_.release(); } private: std::binary_semaphore sem_{0}; }; int main() { A a; std::thread t1(\u0026A::wait, \u0026a); std::thread t2(\u0026A::signal, \u0026a); t1.join(); t2.join(); } // 12 ","date":"2023-11-05","objectID":"/posts/ch04_synchronizing_concurrent_operation/:2:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [4] | CH04 Synchronizing concurrent operations","uri":"/posts/ch04_synchronizing_concurrent_operation/"},{"categories":["C++"],"content":"屏障（barrier） C++20 提供了 std::barrier，它用一个值作为要等待的线程的数量来构造，调用 std::barrier::arrive_and_wait 会阻塞至所有线程完成任务（因此称为屏障），当最后一个线程完成任务时，所有线程被释放，barrier 被重置。构造 std::barrier 时可以额外设置一个 noexcept 函数，当所有线程到达阻塞点时，由其中一个线程运行该函数。如果想从线程集中移除线程，则在该线程中对 barrier 调用 std::barrier::arrive_and_drop #include \u003cbarrier\u003e #include \u003ccassert\u003e #include \u003ciostream\u003e #include \u003cthread\u003e class A { public: void f() { std::barrier sync_point{3, [\u0026]() noexcept { ++i_; }}; for (auto\u0026 x : tasks_) { x = std::thread([\u0026] { std::cout \u003c\u003c 1; sync_point.arrive_and_wait(); assert(i_ == 1); std::cout \u003c\u003c 2; sync_point.arrive_and_wait(); assert(i_ == 2); std::cout \u003c\u003c 3; }); } for (auto\u0026 x : tasks_) { x.join(); // 析构 barrier 前 join 所有使用了 barrier 的线程 } // 析构 barrier 时，线程再调用 barrier 的成员函数是 undefined behavior } private: std::thread tasks_[3] = {}; int i_ = 0; }; int main() { A a; a.f(); } C++20 提供了 std::latch 作为一次性屏障，它用一个值作为计数器的初始值来构造，std::latch::count_down 将计数器减 1，std::latch::wait 将阻塞至计数器为 0，如果想让计数器减一并阻塞至为 0 则可以调用 std::latch::arrive_and_wait #include \u003ciostream\u003e #include \u003clatch\u003e #include \u003cstring\u003e #include \u003cthread\u003e class A { public: void f() { for (auto\u0026 x : data_) { x.t = std::jthread([\u0026] { x.s += x.s; done_.count_down(); }); } done_.wait(); for (auto\u0026 x : data_) { std::cout \u003c\u003c x.s \u003c\u003c std::endl; } } private: struct { std::string s; std::jthread t; } data_[3] = { {\"hello\"}, {\"down\"}, {\"demo\"}, }; std::latch done_{3}; }; int main() { A a; a.f(); } ","date":"2023-11-05","objectID":"/posts/ch04_synchronizing_concurrent_operation/:3:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [4] | CH04 Synchronizing concurrent operations","uri":"/posts/ch04_synchronizing_concurrent_operation/"},{"categories":["C++"],"content":"期值（future） std::thread 只能运行函数，无法获取函数的返回值，为此标准库提供了 std::future 来关联线程运行的函数和函数的返回结果，这种获取结果的方式是异步的。通过 std::async() 创建异步任务的 std::future，std::async 的创建任务的传参方式和 std::thread 一样 #include \u003cfuture\u003e #include \u003ciostream\u003e class A { public: int f(int i) { return i; } }; int main() { A a; std::future\u003cint\u003e res = std::async(\u0026A::f, \u0026a, 1); std::cout \u003c\u003c res.get(); // 1，阻塞至线程返回结果 } std::future 只能 get() 一次 #include \u003cfuture\u003e #include \u003ciostream\u003e int main() { std::future\u003cvoid\u003e res = std::async([] {}); res.get(); try { res.get(); } catch (const std::future_error\u0026 e) { std::cout \u003c\u003c e.what() \u003c\u003c std::endl; // no state } } std::async 的第一个参数可以指定为枚举 std::launch 的值，用于设置任务的运行策略 namespace std { enum class launch { // names for launch options passed to async async = 0x1, // 运行新线程来执行任务 deferred = 0x2 // 惰性求值，请求结果时才执行任务 }; } // std::async 创建任务默认使用两者 std::async([] {}); // 等价于 std::async(std::launch::async | std::launch::deferred, [] {}) 还可以用 std::packaged_task 封装异步任务，它可以用于在两个线程之间传递任务，比如一个线程将异步任务加入队列，另一个线程不断从队列中取任务执行 #include \u003cfuture\u003e #include \u003ciostream\u003e int main() { std::packaged_task\u003cint(int)\u003e task([](int i) { return i; }); task(1); // 请求计算结果，内部的 future 将设置结果值 std::future\u003cint\u003e res = task.get_future(); std::cout \u003c\u003c res.get(); // 1 } 一种更简单的情况是，只需要一个固定的返回值，为此使用 std::promise 即可 #include \u003cfuture\u003e #include \u003ciostream\u003e int main() { std::promise\u003cint\u003e ps; ps.set_value(1); // 内部的 future 将设置结果值 std::future\u003cint\u003e res = ps.get_future(); std::cout \u003c\u003c res.get(); // 1 } std::promise 可以实现事件通知的效果 #include \u003cchrono\u003e #include \u003cfuture\u003e #include \u003ciostream\u003e class A { public: void signal() { std::cout \u003c\u003c 1; ps_.set_value(); } void wait() { std::future\u003cvoid\u003e res = ps_.get_future(); res.wait(); std::cout \u003c\u003c 2; } private: std::promise\u003cvoid\u003e ps_; }; int main() { A a; std::thread t1{\u0026A::signal, \u0026a}; std::thread t2{\u0026A::wait, \u0026a}; t1.join(); t2.join(); } 不同于 std::condition_variable 的是，std::promise 只能通知一次，因此通常用来创建暂停状态的线程 #include \u003cchrono\u003e #include \u003cfuture\u003e #include \u003ciostream\u003e class A { public: void task() { std::cout \u003c\u003c 1; } void wait_for_task() { ps_.get_future().wait(); task(); } void signal() { ps_.set_value(); } private: std::promise\u003cvoid\u003e ps_; }; void task() { std::cout \u003c\u003c 1; } int main() { A a; std::thread t(\u0026A::wait_for_task, \u0026a); a.signal(); t.join(); } std::promise 只能关联一个 std::future #include \u003cfuture\u003e #include \u003ciostream\u003e int main() { std::promise\u003cvoid\u003e ps; auto a = ps.get_future(); try { auto b = ps.get_future(); } catch (const std::future_error\u0026 e) { std::cout \u003c\u003c e.what() \u003c\u003c std::endl; // future already retrieved } } std::future 可以存储任务中的异常 #include \u003cfuture\u003e #include \u003ciostream\u003e #include \u003cstdexcept\u003e int main() { std::future\u003cvoid\u003e res = std::async([] { throw std::logic_error(\"error\"); }); try { res.get(); } catch (const std::exception\u0026 e) { std::cout \u003c\u003c e.what() \u003c\u003c std::endl; } } std::promise 需要手动存储异常 #include \u003cfuture\u003e #include \u003ciostream\u003e #include \u003cstdexcept\u003e int main() { std::promise\u003cvoid\u003e ps; try { throw std::logic_error(\"error\"); } catch (...) { ps.set_exception(std::current_exception()); } auto res = ps.get_future(); try { res.get(); } catch (const std::exception\u0026 e) { std::cout \u003c\u003c e.what() \u003c\u003c std::endl; } } 注意 set_value() 时的异常不会被设置到 future 中 #include \u003cfuture\u003e #include \u003ciostream\u003e #include \u003cstdexcept\u003e int main() { std::promise\u003cint\u003e ps; try { ps.set_value([] { throw std::logic_error(\"error\"); return 0; }()); } catch (const std::exception\u0026 e) { std::cout \u003c\u003c e.what() \u003c\u003c std::endl; } ps.set_value(1); auto res = ps.get_future(); std::cout \u003c\u003c res.get(); // 1 } 如果 std::packaged_task 和 std::promise 直到析构都未设置值，std::future::get() 会抛异常 #include \u003cfuture\u003e #include \u003ciostream\u003e int main() { std::future\u003cvoid\u003e ft1; std::future\u003cvoid\u003e ft2; { std::packaged_task\u003cvoid()\u003e task([] {}); std::promise\u003cvoid\u003e ps; ft1 = task.get_future(); ft2 = ps.get_future(); } try { ft1.get(); } catch (const std::future_error\u0026 e) { std::cout \u003c\u003c e.what() \u003c\u003c std::endl; // broken promise } try { ft2.get(); } catch (const std::future_error\u0026 e) { std::cout \u003c\u003c e.what() \u003c\u003c std::endl; // broken promise } } std::shared_future 可以多次获取结果，它可以通过 st","date":"2023-11-05","objectID":"/posts/ch04_synchronizing_concurrent_operation/:4:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [4] | CH04 Synchronizing concurrent operations","uri":"/posts/ch04_synchronizing_concurrent_operation/"},{"categories":["C++"],"content":"时钟 对于标准库来说，时钟是提供了四种信息的类 当前时间，如 std::chrono::system_clock::now() 表示时间值的类型，如 std::chrono::time_point 时钟节拍（一个 tick 的周期），一般一秒有 25 个 tick，一个周期则为 std::ratio\u003c1, 25\u003e 通过时钟节拍确定时钟是否稳定（steady，匀速），如 std::chrono::steady_clock::is_steady()（稳定时钟，代表系统时钟的真实时间）、std::chrono::system_clock::is_steady()（一般因为时钟可调节而不稳定，即使这是为了考虑本地时钟偏差的自动调节）、high_resolution_clock::is_steady()（最小节拍最高精度的时钟） 获取当前 UNIX 时间戳，单位为纳秒 #ifdef _WIN32 #include \u003cchrono\u003e #elif defined __GNUC__ #include \u003ctime.h\u003e #endif long long now_in_ns() { #ifdef _WIN32 return std::chrono::duration_cast\u003cstd::chrono::nanoseconds\u003e( std::chrono::system_clock::now().time_since_epoch()) .count(); #elif defined __GNUC__ struct timespec t; clockid_t clk_id = CLOCK_REALTIME; clock_gettime(clk_id, \u0026t); return t.tv_sec * 1e9 + t.tv_nsec; #endif } 用 std::put_time 格式化打印时间 #include \u003cchrono\u003e #include \u003ciomanip\u003e #include \u003ciostream\u003e int main() { std::chrono::system_clock::time_point t = std::chrono::system_clock::now(); std::time_t c = std::chrono::system_clock::to_time_t(t); // UNIX 时间戳，秒 // %F 即 %Y-%m-%d，%T 即 %H:%M:%S，如 2011-11-11 11:11:11 std::cout \u003c\u003c std::put_time(std::localtime(\u0026c), \"%F %T\"); } std::chrono::duration 表示时间间隔 namespace std { namespace chrono { using nanoseconds = duration\u003clong long, nano\u003e; using microseconds = duration\u003clong long, micro\u003e; using milliseconds = duration\u003clong long, milli\u003e; using seconds = duration\u003clong long\u003e; using minutes = duration\u003cint, ratio\u003c60\u003e\u003e; using hours = duration\u003cint, ratio\u003c3600\u003e\u003e; // C++20 using days = duration\u003cint, ratio_multiply\u003cratio\u003c24\u003e, hours::period\u003e\u003e; using weeks = duration\u003cint, ratio_multiply\u003cratio\u003c7\u003e, days::period\u003e\u003e; using years = duration\u003cint, ratio_multiply\u003cratio\u003c146097, 400\u003e, days::period\u003e\u003e; using months = duration\u003cint, ratio_divide\u003cyears::period, ratio\u003c12\u003e\u003e\u003e; } // namespace chrono } // namespace std C++14 在 std::literals::chrono_literals 中提供了表示时间的后缀 #include \u003ccassert\u003e #include \u003cchrono\u003e using namespace std::literals::chrono_literals; int main() { auto a = 45min; assert(a.count() == 45); auto b = std::chrono::duration_cast\u003cstd::chrono::seconds\u003e(a); assert(b.count() == 2700); auto c = std::chrono::duration_cast\u003cstd::chrono::hours\u003e(a); assert(c.count() == 0); // 转换会截断 } duration 支持四则运算 #include \u003ccassert\u003e #include \u003cchrono\u003e using namespace std::literals::chrono_literals; int main() { assert((1h - 2 * 15min).count() == 30); assert((0.5h + 2 * 15min + 60s).count() == 3660); } 使用 duration 设置等待时间 #include \u003cchrono\u003e #include \u003cfuture\u003e #include \u003ciostream\u003e #include \u003cthread\u003e int f() { std::this_thread::sleep_for(std::chrono::seconds(1)); return 1; } int main() { auto res = std::async(f); if (res.wait_for(std::chrono::seconds(5)) == std::future_status::ready) { std::cout \u003c\u003c res.get(); } } std::chrono::time_point 是表示时间的类型，值为从某个时间点开始计时的时间长度 // 第一个模板参数为开始时间点的时钟类型，第二个为时间单位 std::chrono::time_point\u003cstd::chrono::system_clock, std::chrono::seconds\u003e std::chrono::time_point 可以与 duration 加减，也可以与自身相减 #include \u003ccassert\u003e #include \u003cchrono\u003e int main() { std::chrono::system_clock::time_point a = std::chrono::system_clock::now(); std::chrono::system_clock::time_point b = a + std::chrono::hours(1); long long diff = std::chrono::duration_cast\u003cstd::chrono::seconds\u003e(b - a).count(); assert(diff == 3600); } 如下函数支持设置超时时间，函数最多阻塞至时间到期 std::this_thread::sleep_for std::this_thread::sleep_until std::condition_variable::wait_for std::condition_variable::wait_until std::condition_variable_any::wait_for std::condition_variable_any::wait_until std::timed_mutex::try_lock_for std::timed_mutex::try_lock_until std::recursive_timed_mutex::try_lock_for std::recursive_timed_mutex::try_lock_until std::unique_lock::try_lock_for std::unique_lock::try_lock_until std::future::wait_for std::future::wait_until std::shared_future::wait_for std::shared_future::wait_until std::counting_semaphore::try_acquire_for std::counting_semaphore::try_acquire_until 由于不同机器的 CPU 频率不同，为了进行更精确的性能测试，通常不直接使用时间而是用 rdtsc 指令获取 CPU 周期，rdtsc 把 tsc 的低 32 位存放在 EAX，高 32 位存放在 EDX，不同 CPU 上获取的 tsc 可能不同步，如果开启了 constant_tsc 的 flag（通过 cat /proc/cpuinfo | gre","date":"2023-11-05","objectID":"/posts/ch04_synchronizing_concurrent_operation/:5:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [4] | CH04 Synchronizing concurrent operations","uri":"/posts/ch04_synchronizing_concurrent_operation/"},{"categories":["C++"],"content":"函数式编程（functional programming） 函数式编程是一种编程范式，使用的函数为纯函数，即如果函数的调用参数相同，则永远返回相同的结果，纯函数不会改变外部状态，因此对于只使用纯函数的函数式编程，天生就不存在 race condition 的问题。Haskell 是一种常见的函数式编程语言，以快速排序为例，Haskell 中的实现如下 quickSort :: Ord a =\u003e [a] -\u003e [a] quickSort [] = [] quickSort (x : xs) = l ++ [x] ++ r where l = quickSort (filter (\u003c= x) xs) r = quickSort (filter (\u003e x) xs) main :: IO () main = print (quickSort \"downdemo\") -- \"ddemnoow\" 相同思路的 C++ 实现 #include \u003calgorithm\u003e #include \u003ciostream\u003e #include \u003clist\u003e #include \u003cutility\u003e template \u003ctypename T\u003e std::list\u003cT\u003e quick_sort(std::list\u003cT\u003e v) { if (v.empty()) { return v; } std::list\u003cT\u003e res; res.splice(res.begin(), v, v.begin()); // 将 v 的首元素移到 res 中 // 将 v 按条件划分为两部分，并返回第一个不满足条件元素的迭代器 auto it = std::partition(v.begin(), v.end(), [\u0026](const T\u0026 x) { return x \u003c res.front(); }); std::list\u003cT\u003e low; low.splice(low.end(), v, v.begin(), it); // 转移左半部分到 low auto l(quick_sort(std::move(low))); // 递归对左半部分快速排序 auto r(quick_sort(std::move(v))); // 递归对右半部分快速排序 res.splice(res.end(), r); // 右半部分移到结果后 res.splice(res.begin(), l); // 左半部分移到结果前 return res; } int main() { for (auto\u0026 x : quick_sort(std::list\u003cint\u003e{1, 3, 2, 4, 5})) { std::cout \u003c\u003c x; // 12345 } } 使用 std::future 实现并行版本 #include \u003calgorithm\u003e #include \u003cfuture\u003e #include \u003ciostream\u003e #include \u003clist\u003e #include \u003cutility\u003e template \u003ctypename T\u003e std::list\u003cT\u003e quick_sort(std::list\u003cT\u003e v) { if (v.empty()) { return v; } std::list\u003cT\u003e res; res.splice(res.begin(), v, v.begin()); auto it = std::partition(v.begin(), v.end(), [\u0026](const T\u0026 x) { return x \u003c res.front(); }); std::list\u003cT\u003e low; low.splice(low.end(), v, v.begin(), it); // 用另一个线程对左半部分排序 std::future\u003cstd::list\u003cT\u003e\u003e l(std::async(\u0026quick_sort\u003cT\u003e, std::move(low))); auto r(quick_sort(std::move(v))); res.splice(res.end(), r); res.splice(res.begin(), l.get()); return res; } int main() { for (auto\u0026 x : quick_sort(std::list\u003cint\u003e{1, 3, 2, 4, 5})) { std::cout \u003c\u003c x; // 12345 } } ","date":"2023-11-05","objectID":"/posts/ch04_synchronizing_concurrent_operation/:6:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [4] | CH04 Synchronizing concurrent operations","uri":"/posts/ch04_synchronizing_concurrent_operation/"},{"categories":["C++"],"content":"链式调用 链式调用是函数式编程中经常使用的形式，常见于 ReactiveX，比如 RxJS，当上游产生数据时交给下游处理，将复杂的异步逻辑拆散成了多个小的操作，只需要关注每一步操作并逐步转换到目标结果即可。C++20 的 ranges 使用的 range-v3 就脱胎自 RxCpp import { interval } from 'rxjs'; import { withLatestFrom } from 'rxjs/operators'; const source1$ = interval(500); const source2$ = interval(1000); source1$.pipe(withLatestFrom(source2$, (x, y) =\u003e `${x}${y}`)); // 10 20 31 41 52 62--- 并发TS 提供了 std::experimental::promise 和 std::experimental::packaged_task，与标准库唯一不同的是，它们返回 std::experimental::future，std::experimental::future::then() 可链式调用 int f(std::experimental::future\u003cint\u003e); std::experimental::future\u003cint\u003e eft; auto ft1 = eft(); // std::experimental::future 由本身的构造函数生成 // 与 std::async 不同，不能传入 f 的参数 // 因为参数已经在运行库中定义为了一个就绪的期值 // 这里 f 的返回 int，因此参数就是 std::experimental::future\u003cint\u003e auto ft2 = ft1.then(f); // then 后原期值就无效了 assert(!ft1.valid()); assert(ft2.valid()); std::async 只能返回 std::future，如果想返回 std::experimental::future 则需要手动实现一个新的async template \u003ctypename F\u003e std::experimental::future\u003cdecltype(std::declval\u003cF\u003e()())\u003e new_async(F\u0026\u0026 func) { std::experimental::promise\u003cdecltype(std::declval\u003cF\u003e()())\u003e p; auto ft = p.get_future(); std::thread t([p = std::move(p), f = std::decay_t\u003cF\u003e(func)]() mutable { try { p.set_value_at_thread_exit(f()); } catch (...) { p.set_exception_at_thread_exit(std::current_exception()); } }); t.detach(); return ft; } 假如要实现一个登录逻辑，将用户名和密码发送给后台验证，取得用户信息后更新到显示界面，串行实现如下 void process_login(const std::string\u0026 username, const std::string\u0026 password) { try { const user_id id = backend.authenticate_user(username, password); const user_data info_to_display = backend.request_current_info(id); update_display(info_to_display); } catch (std::exception\u0026 e) { display_error(e); } } 为了不阻塞 UI 线程，就需要异步实现 std::future\u003cvoid\u003e process_login(const std::string\u0026 username, const std::string\u0026 password) { return std::async(std::launch::async, [=]() { try { const user_id id = backend.authenticate_user(username, password); const user_data info_to_display = backend.request_current_info(id); update_display(info_to_display); } catch (std::exception\u0026 e) { display_error(e); } }); } 但这个实现仍然会阻塞 UI 线程，为此就需要链式调用的机制，每个任务完成后连接到前一个任务上 std::experimental::future\u003cvoid\u003e process_login(const std::string\u0026 username, const std::string\u0026 password) { return new_async( [=]() { return backend.authenticate_user(username, password); }) .then([](std::experimental::future\u003cuser_id\u003e id) { return backend.request_current_info(id.get()); }) .then([](std::experimental::future\u003cuser_data\u003e info_to_display) { try { update_display(info_to_display.get()); } catch (std::exception\u0026 e) { display_error(e); } }); } 如果调用后台函数内部阻塞，可能是因为需要等待消息通过网络或者完成一个数据库操作，而这些还没有完成。即使把任务划分为多个独立部分，也仍会阻塞调用，得到阻塞的线程。这时后台调用真正需要的是，在数据准备好时返回就绪的期值，而不阻塞任何线程，所以这里用返回 std::experimental::future\u003cuser_id\u003e 的 backend.async_authenticate_user 替代返回 user_id 的 backend.authenticate_user std::experimental::future\u003cvoid\u003e process_login(const std::string\u0026 username, const std::string\u0026 password) { return backend.async_authenticate_user(username, password) .then([](std::experimental::future\u003cuser_id\u003e id) { return backend.async_request_current_info(id.get()); }) .then([](std::experimental::future\u003cuser_data\u003e info_to_display) { try { update_display(info_to_display.get()); } catch (std::exception\u0026 e) { display_error(e); } }); } 这样在异步函数链上就不存在阻塞了。最后这里还可以用泛型 lambda 来简化代码 std::experimental::future\u003cvoid\u003e process_login(const std::string\u0026 username, const std::string\u0026 password) { return backend.async_authenticate_user(username, password) .then( [](auto id) { return backend.async_request_current_info(id.get()); }) .then([](auto info_to_display) { try { update_display(info_to_display.get()); } catch (std::exception\u0026 e) { display_error(e); } }); } 除了 std::experimental::future，支持链式调用的还有 std::experimental::shared_future auto ft1 = new_async(some_function).share(); auto ft2 = ft1.then( [](std::experimental::shared_future\u003csome_data\u003e data) { do_stuff(data); }); auto ft3 = ft1.then([](std::experimental::shared_future\u003csome_data\u003e data) { return do_other_stuff(data); }); 使用 std::asy","date":"2023-11-05","objectID":"/posts/ch04_synchronizing_concurrent_operation/:7:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [4] | CH04 Synchronizing concurrent operations","uri":"/posts/ch04_synchronizing_concurrent_operation/"},{"categories":["C++"],"content":"CSP（Communicating Sequential Processes） CSP 是一种描述并发系统交互的编程模型，线程理论上是分开的，没有共享数据，每个线程可以完全独立地思考，消息通过 communication channel 在不同线程间传递，线程行为取决于收到的消息，因此每个线程实际上是一个状态机，收到一条消息时就以某种方式更新状态，并且还可能发送消息给其他线程。Erlang 采用了这种编程模型，并用于 MPI 做 C 和 C++ 的高性能计算。真正的 CSP 没有共享数据，所有通信通过消息队列传递，但由于 C++ 线程共享地址空间，无法强制实现这个要求，所以需要应用或者库的作者来确保线程间不会共享数据 考虑实现一个 ATM 应用，它需要处理取钱时和银行的交互，并控制物理机器对银行卡的反应。一个处理方法是分三个线程，分别处理物理机器、ATM 逻辑、与银行的交互，线程间通过消息通讯而非共享数据，比如插卡时机器线程发送消息给逻辑线程，逻辑线程返回一条消息通知机器线程可以给多少钱 一个简单的 ATM 逻辑的状态机建模如下 这个 ATM 逻辑的状态机与系统的其他部分各自运行在独立的线程上，不需要考虑同步和并发的问题，只要考虑在某个点接受和发送的消息，这种设计方式称为 actor model，系统中有多个独立的 actor，actor 之间可以互相发送消息但不会共享状态，这种方式可以极大简化并发系统的设计。完整的代码实现见此 ref: https://github.com/downdemo/Cpp-Concurrency-in-Action-2ed ","date":"2023-11-05","objectID":"/posts/ch04_synchronizing_concurrent_operation/:8:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [4] | CH04 Synchronizing concurrent operations","uri":"/posts/ch04_synchronizing_concurrent_operation/"},{"categories":["C++"],"content":"线程间共享数据存在的问题 不变量（invariant）：关于一个特定数据结构总为 true 的语句，比如 双向链表的两个相邻节点 A 和 B，A 的后指针一定指向 B，B 的前指针一定指向 A。有时程序为了方便会暂时破坏不变量，这通常发生于更新复杂数据结构的过程中，比如删除双向链表中的一个节点 N，要先让 N 的前一个节点指向 N 的后一个节点（不变量被破坏），再让 N 的后节点指向前节点，最后删除 N（此时不变量重新恢复） 线程修改共享数据时，就会发生破坏不变量的情况，此时如果有其他线程访问，就可能导致不变量被永久性破坏，这就是 race condition 如果线程执行顺序的先后对结果无影响，则为不需要关心的良性竞争。需要关心的是不变量被破坏时产生的 race condition C++ 标准中定义了 data race 的概念，指代一种特定的 race condition，即并发修改单个对象。data race 会造成未定义行为 race condition 要求一个线程进行时，另一线程访问同一数据块，出现问题时很难复现，因此编程时需要使用大量复杂操作来避免 race condition ","date":"2023-11-04","objectID":"/posts/ch03_sharing_data_between_threads/:1:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [3] | CH03 Sharing Data Between Threads","uri":"/posts/ch03_sharing_data_between_threads/"},{"categories":["C++"],"content":"互斥锁（mutex） 使用 mutex 在访问共享数据前加锁，访问结束后解锁。一个线程用特定的 mutex 锁定后，其他线程必须等待该线程的 mutex 解锁才能访问共享数据 C++11 提供了 std::mutex 来创建一个 mutex，可通过 lock 加锁，通过 unlock 解锁。一般不手动使用这两个成员函数，而是使用 std::lock_guard 来自动处理加锁与解锁，它在构造时接受一个 mutex，并会调用 mutex.lock()，析构时会调用 mutex.unlock() #include \u003ciostream\u003e #include \u003cmutex\u003e class A { public: void lock() { std::cout \u003c\u003c \"lock\" \u003c\u003c std::endl; } void unlock() { std::cout \u003c\u003c \"unlock\" \u003c\u003c std::endl; } }; int main() { A a; { std::lock_guard\u003cA\u003e l(a); // lock } // unlock } C++17 提供了的 std::scoped_lock，它可以接受任意数量的 mutex，并将这些 mutex 传给 std::lock 来同时上锁，它会对其中一个 mutex 调用 lock()，对其他调用 try_lock()，若 try_lock() 返回 false 则对已经上锁的 mutex 调用 unlock()，然后重新进行下一轮上锁，标准未规定下一轮的上锁顺序，可能不一致，重复此过程直到所有 mutex 上锁，从而达到同时上锁的效果。C++17 支持类模板实参推断，可以省略模板参数 #include \u003ciostream\u003e #include \u003cmutex\u003e class A { public: void lock() { std::cout \u003c\u003c 1; } void unlock() { std::cout \u003c\u003c 2; } bool try_lock() { std::cout \u003c\u003c 3; return true; } }; class B { public: void lock() { std::cout \u003c\u003c 4; } void unlock() { std::cout \u003c\u003c 5; } bool try_lock() { std::cout \u003c\u003c 6; return true; } }; int main() { A a; B b; { std::scoped_lock l(a, b); // 16 std::cout \u003c\u003c std::endl; } // 25 } 一般 mutex 和要保护的数据一起放在类中，定义为 private 数据成员，而非全局变量，这样能让代码更清晰。但如果某个成员函数返回指向数据成员的指针或引用，则通过这个指针的访问行为不会被 mutex 限制，因此需要谨慎设置接口，确保 mutex 能锁住数据 #include \u003cmutex\u003e class A { public: void f() {} }; class B { public: A* get_data() { std::lock_guard\u003cstd::mutex\u003e l(m_); return \u0026data_; } private: std::mutex m_; A data_; }; int main() { B b; A* p = b.get_data(); p-\u003ef(); // 未锁定 mutex 的情况下访问数据 } 即便在很简单的接口中，也可能遇到 race condition std::stack\u003cint\u003e s； if (!s.empty()) { int n = s.top(); // 此时其他线程 pop 就会获取错误的 top s.pop(); } 上述代码先检查非空再获取栈顶元素，在单线程中是安全的，但在多线程中，检查非空之后，如果其他线程先 pop，就会导致当前线程 top 出错。另一个潜在的竞争是，如果两个线程都未 pop，而是分别获取了 top，虽然不会产生未定义行为，但这种对同一值处理了两次的行为更为严重，因为看起来没有任何错误，很难定位 bug 既然如此，为什么不直接让 pop 返回栈顶元素？原因在于，构造返回值的过程可能抛异常，弹出后未返回会导致数据丢失。比如有一个元素为 vector 的 stack，拷贝 vector 需要在堆上分配内存，如果系统负载严重或资源有限（比如 vector 有大量元素），vector 的拷贝构造函数就会抛出 std::bad_alloc 异常。如果 pop 可以返回栈顶元素值，返回一定是最后执行的语句，stack 在返回前已经弹出了元素，但如果拷贝返回值时抛出异常，就会导致弹出的数据丢失（从栈上移除但拷贝失败）。因此 std::stack 的设计者将这个操作分解为 top 和 pop 两部分 下面思考几种把 top 和 pop 合为一步的方法。第一种容易想到的方法是传入一个引用来获取结果值，这种方式的明显缺点是，需要构造一个栈元素类型的实例，这是不现实的，为了获取结果而临时构造一个对象并不划算，元素类型可能不支持赋值（比如用户自定义某个类型），构造函数可能还需要一些参数 std::vector\u003cint\u003e res; s.pop(res); 因为 pop 返回值时只担心该过程抛异常，第二种方案是为元素类型设置不抛异常的拷贝或移动构造函数，使用 std::is_nothrow_copy_constructible 和 std::is_nothrow_move_constructible。但这种方式过于局限，只支持拷贝或移动不抛异常的类型 第三种方案是返回指向弹出元素的指针，指针可以自由拷贝且不会抛异常，std::shared_ptr 是个不错的选择，但这个方案的开销太大，尤其是对于内置类型来说，比如 int 为 4 字节， shared_ptr\u003cint\u003e 为 16 字节，开销是原来的 4 倍 第四种方案是结合方案一二或者一三，比如结合方案一三实现一个线程安全的 stack #include \u003cexception\u003e #include \u003cmemory\u003e #include \u003cmutex\u003e #include \u003cstack\u003e #include \u003cutility\u003e struct EmptyStack : std::exception { const char* what() const noexcept { return \"empty stack!\"; } }; template \u003ctypename T\u003e class ConcurrentStack { public: ConcurrentStack() = default; ConcurrentStack(const ConcurrentStack\u0026 rhs) { std::lock_guard\u003cstd::mutex\u003e l(rhs.m_); s_ = rhs.s_; } ConcurrentStack\u0026 operator=(const ConcurrentStack\u0026) = delete; void push(T x) { std::lock_guard\u003cstd::mutex\u003e l(m_); s_.push(std::move(x)); } bool empty() const { std::lock_guard\u003cstd::mutex\u003e l(m_); return s_.empty(); } std::shared_ptr\u003cT\u003e pop() { std::lock_guard\u003cstd::mutex\u003e l(m_); if (s_.empty()) { throw EmptyStack(); } auto res = std::make_shared\u003cT\u003e(std::move(s_.top())); s_.pop(); return res; } void pop(T\u0026 res) { std::lock_guard\u003cstd::mutex\u003e l(m_); if (s_.empty()) { throw EmptyStack(); } res = std::move(s_.top()); s_.pop(); } private: mutable std::mutex m_; std::stack\u003cT\u003e s_; }; 之前锁的粒度（锁保护的数据量大小）太小，保护操作覆盖不周全，这里的粒度就较大，覆盖了大量操作。但并非粒度越大越好，如果锁粒度太大，过多线程请求竞争占用资源时，并发的性能就会较差 如果给定操作需要对多个 mutex 上锁时，就会引入一个新的潜在问题，即死锁 ","date":"2023-11-04","objectID":"/posts/ch03_sharing_data_between_threads/:2:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [3] | CH03 Sharing Data Between Threads","uri":"/posts/ch03_sharing_data_between_threads/"},{"categories":["C++"],"content":"死锁 死锁的四个必要条件：互斥、占有且等待、不可抢占、循环等待 避免死锁通常建议让两个 mutex 以相同顺序上锁，总是先锁 A 再锁 B，但这并不适用所有情况。std::lock 可以同时对多个 mutex 上锁，并且没有死锁风险，它可能抛异常，此时就不会上锁，因此要么都锁住，要么都不锁 #include \u003cmutex\u003e #include \u003cthread\u003e struct A { explicit A(int n) : n_(n) {} std::mutex m_; int n_; }; void f(A \u0026a, A \u0026b, int n) { if (\u0026a == \u0026b) { return; // 防止对同一对象重复加锁 } std::lock(a.m_, b.m_); // 同时上锁防止死锁 // 下面按固定顺序加锁，看似不会有死锁的问题 // 但如果没有 std::lock 同时上锁，另一线程中执行 f(b, a, n) // 两个锁的顺序就反了过来，从而可能导致死锁 std::lock_guard\u003cstd::mutex\u003e lock1(a.m_, std::adopt_lock); std::lock_guard\u003cstd::mutex\u003e lock2(b.m_, std::adopt_lock); // 等价实现，先不上锁，后同时上锁 // std::unique_lock\u003cstd::mutex\u003e lock1(a.m_, std::defer_lock); // std::unique_lock\u003cstd::mutex\u003e lock2(b.m_, std::defer_lock); // std::lock(lock1, lock2); a.n_ -= n; b.n_ += n; } int main() { A x{70}; A y{30}; std::thread t1(f, std::ref(x), std::ref(y), 20); std::thread t2(f, std::ref(y), std::ref(x), 10); t1.join(); t2.join(); } std::unique_lock 在构造时接受一个 mutex，并会调用 mutex.lock()，析构时会调用 mutex.unlock() #include \u003ciostream\u003e #include \u003cmutex\u003e class A { public: void lock() { std::cout \u003c\u003c \"lock\" \u003c\u003c std::endl; } void unlock() { std::cout \u003c\u003c \"unlock\" \u003c\u003c std::endl; } }; int main() { A a; { std::unique_lock l(a); // lock } // unlock } std::lock_guard 未提供任何接口且不支持拷贝和移动，而 std::unique_lock 多提供了一些接口，使用更灵活，占用的空间也多一点。一种要求灵活性的情况是转移锁的所有权到另一个作用域 std::unique_lock\u003cstd::mutex\u003e get_lock() { extern std::mutex m; std::unique_lock\u003cstd::mutex\u003e l(m); prepare_data(); return l; // 不需要 std::move，编译器负责调用移动构造函数 } void f() { std::unique_lock\u003cstd::mutex\u003e l(get_lock()); do_something(); } 对一些费时的操作上锁可能造成很多操作被阻塞，可以在面对这些操作时先解锁 void process_file_data() { std::unique_lock\u003cstd::mutex\u003e l(m); auto data = get_data(); l.unlock(); // 费时操作没有必要持有锁，先解锁 auto res = process(data); l.lock(); // 写入数据前上锁 write_result(data, res); } C++17 最优的同时上锁方法是使用 std::scoped_lock 解决死锁并不简单，std::lock 和 std::scoped_lock 无法获取其中的锁，此时解决死锁更依赖于开发者的能力。避免死锁有四个建议 第一个避免死锁的建议是，一个线程已经获取一个锁时就不要获取第二个。如果每个线程只有一个锁，锁上就不会产生死锁（但除了互斥锁，其他方面也可能造成死锁，比如即使无锁，线程间相互等待也可能造成死锁） 第二个建议是，持有锁时避免调用用户提供的代码。用户提供的代码可能做任何时，包括获取锁，如果持有锁时调用用户代码获取锁，就会违反第一个建议，并造成死锁。但有时调用用户代码是无法避免的 第三个建议是，按固定顺序获取锁。如果必须获取多个锁且不能用 std::lock 同时获取，最好在每个线程上用固定顺序获取。上面的例子虽然是按固定顺序获取锁，但如果不同时加锁就会出现死锁，对于这种情况的建议是规定固定的调用顺序 第四个建议是使用层级锁，如果一个锁被低层持有，就不允许在高层再上锁 层级锁实现如下 #include \u003ciostream\u003e #include \u003cmutex\u003e #include \u003cstdexcept\u003e class HierarchicalMutex { public: explicit HierarchicalMutex(int hierarchy_value) : cur_hierarchy_(hierarchy_value), prev_hierarchy_(0) {} void lock() { validate_hierarchy(); // 层级错误则抛异常 m_.lock(); update_hierarchy(); } bool try_lock() { validate_hierarchy(); if (!m_.try_lock()) { return false; } update_hierarchy(); return true; } void unlock() { if (thread_hierarchy_ != cur_hierarchy_) { throw std::logic_error(\"mutex hierarchy violated\"); } thread_hierarchy_ = prev_hierarchy_; // 恢复前一线程的层级值 m_.unlock(); } private: void validate_hierarchy() { if (thread_hierarchy_ \u003c= cur_hierarchy_) { throw std::logic_error(\"mutex hierarchy violated\"); } } void update_hierarchy() { // 先存储当前线程的层级值（用于解锁时恢复） prev_hierarchy_ = thread_hierarchy_; // 再把其设为锁的层级值 thread_hierarchy_ = cur_hierarchy_; } private: std::mutex m_; const int cur_hierarchy_; int prev_hierarchy_; static thread_local int thread_hierarchy_; // 所在线程的层级值 }; // static thread_local 表示存活于一个线程周期 thread_local int HierarchicalMutex::thread_hierarchy_(INT_MAX); HierarchicalMutex high(10000); HierarchicalMutex mid(6000); HierarchicalMutex low(5000); void lf() { // 最低层函数 std::lock_guard\u003cHierarchicalMutex\u003e l(low); // 调用 low.lock()，thread_hierarchy_ 为 INT_MAX， // cur_hierarchy_ 为 5000，thread_hierarchy_ \u003e cur_hierarchy_， // 通过检查，上锁，prev_hierarchy_ 更新为 INT_MAX， // thread_hierarchy_ 更新为 5000 } // 调用 low.unlock()，thread_hierarchy_ == cur_hierarchy_， // 通过检查，thread_hierarchy_ 恢复为 prev_hierarchy_ 保存的 INT_MAX，解锁 void hf() { std::lock_guard\u003cHierarchicalMutex\u003e l(high); // high.cur_hierarchy_ 为 10000 // thread_hierarchy_ 为 10000，可以调用低层函数 lf(); // thread_hierarchy_ 从 10000 更新为 5000 // thread_hierarchy_ 恢复为 10000 } // thread_hierarchy_ 恢复为 INT_MAX void mf() { std::lock_gua","date":"2023-11-04","objectID":"/posts/ch03_sharing_data_between_threads/:3:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [3] | CH03 Sharing Data Between Threads","uri":"/posts/ch03_sharing_data_between_threads/"},{"categories":["C++"],"content":"读写锁（reader-writer mutex） 有时会希望对一个数据上锁时，根据情况，对某些操作相当于不上锁，可以并发访问，对某些操作保持上锁，同时最多只允许一个线程访问。比如对于需要经常访问但很少更新的缓存数据，用 std::mutex 加锁会导致同时最多只有一个线程可以读数据，这就需要用上读写锁，读写锁允许多个线程并发读但仅一个线程写 C++14 提供了 std::shared_timed_mutex，C++17 提供了接口更少性能更高的 std::shared_mutex，如果多个线程调用 shared_mutex.lock_shared()，多个线程可以同时读，如果此时有一个写线程调用 shared_mutex.lock()，则读线程均会等待该写线程调用 shared_mutex.unlock()。C++11 没有提供读写锁，可使用 boost::shared_mutex C++14 提供了 std::shared_lock，它在构造时接受一个 mutex，并会调用 mutex.lock_shared()，析构时会调用 mutex.unlock_shared() #include \u003ciostream\u003e #include \u003cshared_mutex\u003e class A { public: void lock_shared() { std::cout \u003c\u003c \"lock_shared\" \u003c\u003c std::endl; } void unlock_shared() { std::cout \u003c\u003c \"unlock_shared\" \u003c\u003c std::endl; } }; int main() { A a; { std::shared_lock l(a); // lock_shared } // unlock_shared } 对于 std::shared_mutex，通常在读线程中用 std::shared_lock 管理，在写线程中用 std::unique_lock 管理 class A { public: int read() const { std::shared_lock\u003cstd::shared_mutex\u003e l(m_); return n_; } int write() { std::unique_lock\u003cstd::shared_mutex\u003e l(m_); return ++n_; } private: mutable std::shared_mutex m_; int n_ = 0; }; ","date":"2023-11-04","objectID":"/posts/ch03_sharing_data_between_threads/:3:1","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [3] | CH03 Sharing Data Between Threads","uri":"/posts/ch03_sharing_data_between_threads/"},{"categories":["C++"],"content":"递归锁 std::mutex 是不可重入的，未释放前再次上锁是未定义行为 #include \u003cmutex\u003e class A { public: void f() { m_.lock(); m_.unlock(); } void g() { m_.lock(); f(); m_.unlock(); } private: std::mutex m_; }; int main() { A{}.g(); // Undefined Behavior } 为此 C++ 提供了 std::recursive_mutex，它可以在一个线程上多次获取锁，但在其他线程获取锁之前必须释放所有的锁 #include \u003cmutex\u003e class A { public: void f() { m_.lock(); m_.unlock(); } void g() { m_.lock(); f(); m_.unlock(); } private: std::recursive_mutex m_; }; int main() { A{}.g(); // OK } 多数情况下，如果需要递归锁，说明代码设计存在问题。比如一个类的每个成员函数都会上锁，一个成员函数调用另一个成员函数，就可能多次上锁，这种情况用递归锁就可以避免产生未定义行为。但显然这个设计本身是有问题的，更好的办法是提取其中一个函数作为 private 成员并且不上锁，其他成员先上锁再调用该函数 ","date":"2023-11-04","objectID":"/posts/ch03_sharing_data_between_threads/:3:2","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [3] | CH03 Sharing Data Between Threads","uri":"/posts/ch03_sharing_data_between_threads/"},{"categories":["C++"],"content":"对并发初始化的保护 除了对并发访问共享数据的保护，另一种常见的情况是对并发初始化的保护 #include \u003cmemory\u003e #include \u003cmutex\u003e #include \u003cthread\u003e class A { public: void f() {} }; std::shared_ptr\u003cA\u003e p; std::mutex m; void init() { m.lock(); if (!p) { p.reset(new A); } m.unlock(); p-\u003ef(); } int main() { std::thread t1{init}; std::thread t2{init}; t1.join(); t2.join(); } 上锁只是为了保护初始化过程，会不必要地影响性能，一种容易想到的优化方式是双重检查锁模式，但这存在潜在的 race condition #include \u003cmemory\u003e #include \u003cmutex\u003e #include \u003cthread\u003e class A { public: void f() {} }; std::shared_ptr\u003cA\u003e p; std::mutex m; void init() { if (!p) { // 未上锁，其他线程可能在执行 #1，则此时 p 不为空 std::lock_guard\u003cstd::mutex\u003e l(m); if (!p) { p.reset(new A); // 1 // 先分配内存，再在内存上构造 A 的实例并返回内存的指针，最后让 p 指向它 // 也可能先让 p 指向它，再在内存上构造 A 的实例 } } p-\u003ef(); // p 可能指向一块还未构造实例的内存，从而崩溃 } int main() { std::thread t1{init}; std::thread t2{init}; t1.join(); t2.join(); } 为此，C++11 提供了 std::once_flag 和 std::call_once 来保证对某个操作只执行一次 #include \u003cmemory\u003e #include \u003cmutex\u003e #include \u003cthread\u003e class A { public: void f() {} }; std::shared_ptr\u003cA\u003e p; std::once_flag flag; void init() { std::call_once(flag, [\u0026] { p.reset(new A); }); p-\u003ef(); } int main() { std::thread t1{init}; std::thread t2{init}; t1.join(); t2.join(); } std::call_once 也可以用在类中 #include \u003ciostream\u003e #include \u003cmutex\u003e #include \u003cthread\u003e class A { public: void f() { std::call_once(flag_, \u0026A::print, this); std::cout \u003c\u003c 2; } private: void print() { std::cout \u003c\u003c 1; } private: std::once_flag flag_; }; int main() { A a; std::thread t1{\u0026A::f, \u0026a}; std::thread t2{\u0026A::f, \u0026a}; t1.join(); t2.join(); } // 122 static 局部变量在声明后就完成了初始化，这存在潜在的 race condition，如果多线程的控制流同时到达 static 局部变量的声明处，即使变量已在一个线程中初始化，其他线程并不知晓，仍会对其尝试初始化。为此，C++11 规定，如果 static 局部变量正在初始化，线程到达此处时，将等待其完成，从而避免了 race condition。只有一个全局实例时，可以直接用 static 而不需要 std::call_once template \u003ctypename T\u003e class Singleton { public: static T\u0026 Instance(); Singleton(const Singleton\u0026) = delete; Singleton\u0026 operator=(const Singleton\u0026) = delete; private: Singleton() = default; ~Singleton() = default; }; template \u003ctypename T\u003e T\u0026 Singleton\u003cT\u003e::Instance() { static T instance; return instance; } ","date":"2023-11-04","objectID":"/posts/ch03_sharing_data_between_threads/:4:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [3] | CH03 Sharing Data Between Threads","uri":"/posts/ch03_sharing_data_between_threads/"},{"categories":["C++"],"content":"std::thread 每个程序有一个执行 main() 函数的主线程，将函数添加为 std::thread 的参数即可启动另一个线程，两个线程会同时运行 #include \u003ciostream\u003e #include \u003cthread\u003e void f() { std::cout \u003c\u003c \"hello world\"; } int main() { std::thread t{f}; t.join(); // 等待新起的线程退出 } std::thread 的参数也可以是函数对象或者 lambda #include \u003ciostream\u003e #include \u003cthread\u003e struct A { void operator()() const { std::cout \u003c\u003c 1; } }; int main() { A a; std::thread t1(a); // 会调用 A 的拷贝构造函数 std::thread t2(A()); // most vexing parse，声明名为 t2 参数类型为 A 的函数 std::thread t3{A()}; std::thread t4((A())); std::thread t5{[] { std::cout \u003c\u003c 1; }}; t1.join(); t3.join(); t4.join(); t5.join(); } 在线程销毁前要对其调用 join 等待线程退出或 detach 将线程分离，否则 std::thread 的析构函数会调用 std::terminate 终止程序，注意分离线程可能出现空悬引用的隐患 #include \u003ciostream\u003e #include \u003cthread\u003e class A { public: A(int\u0026 x) : x_(x) {} void operator()() const { for (int i = 0; i \u003c 1000000; ++i) { call(x_); // 存在对象析构后引用空悬的隐患 } } private: void call(int\u0026 x) {} private: int\u0026 x_; }; void f() { int x = 0; A a{x}; std::thread t{a}; t.detach(); // 不等待 t 结束 } // 函数结束后 t 可能还在运行，而 x 已经销毁，a.x_ 为空悬引用 int main() { std::thread t{f}; // 导致空悬引用 t.join(); } join 会在线程结束后清理 std::thread，使其与完成的线程不再关联，因此对一个线程只能进行一次 join #include \u003cthread\u003e int main() { std::thread t([] {}); t.join(); t.join(); // 错误 } 如果线程运行过程中发生异常，之后的 join 会被忽略，为此需要捕获异常，并在抛出异常前 join #include \u003cthread\u003e int main() { std::thread t([] {}); try { throw 0; } catch (int x) { t.join(); // 处理异常前先 join() throw x; // 再将异常抛出 } t.join(); // 之前抛异常，不会执行到此处 } C++20 提供了 std::jthread，它会在析构函数中对线程 join #include \u003cthread\u003e int main() { std::jthread t([] {}); } detach 分离线程会让线程在后台运行，一般将这种在后台运行的线程称为守护线程，守护线程与主线程无法直接交互，也不能被 join std::thread t([] {}); t.detach(); assert(!t.joinable()); 创建守护线程一般是为了长时间运行，比如有一个文档处理应用，为了同时编辑多个文档，每次新开一个文档，就可以开一个对应的守护线程 void edit_document(const std::string\u0026 filename) { open_document_and_display_gui(filename); while (!done_editing()) { user_command cmd = get_user_input(); if (cmd.type == open_new_document) { const std::string new_name = get_filename_from_user(); std::thread t(edit_document, new_name); t.detach(); } else { process_user_input(cmd); } } } ","date":"2023-11-01","objectID":"/posts/ch02_managing_threads/:1:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [2] | CH02 Managing Threads","uri":"/posts/ch02_managing_threads/"},{"categories":["C++"],"content":"为带参数的函数创建线程 有参数的函数也能传给 std::thread，参数的默认实参会被忽略 #include \u003cthread\u003e void f(int i = 1) {} int main() { std::thread t{f, 42}; // std::thread t{f} 则会出错，因为默认实参会被忽略 t.join(); } 参数的引用类型也会被忽略，为此要使用 std::ref #include \u003ccassert\u003e #include \u003cthread\u003e void f(int\u0026 i) { ++i; } int main() { int i = 1; std::thread t{f, std::ref(i)}; t.join(); assert(i == 2); } 如果对一个实例的 non-static 成员函数创建线程，第一个参数类型为成员函数指针，第二个参数类型为实例指针，后续参数为函数参数 #include \u003ciostream\u003e #include \u003cthread\u003e class A { public: void f(int i) { std::cout \u003c\u003c i; } }; int main() { A a; std::thread t1{\u0026A::f, \u0026a, 42}; // 调用 a-\u003ef(42) std::thread t2{\u0026A::f, a, 42}; // 拷贝构造 tmp_a，再调用 tmp_a.f(42) t1.join(); t2.join(); } 如果要为参数是 move-only 类型的函数创建线程，则需要使用 std::move 传入参数 #include \u003ciostream\u003e #include \u003cthread\u003e #include \u003cutility\u003e void f(std::unique_ptr\u003cint\u003e p) { std::cout \u003c\u003c *p; } int main() { std::unique_ptr\u003cint\u003e p(new int(42)); std::thread t{f, std::move(p)}; t.join(); } ","date":"2023-11-01","objectID":"/posts/ch02_managing_threads/:2:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [2] | CH02 Managing Threads","uri":"/posts/ch02_managing_threads/"},{"categories":["C++"],"content":"转移线程所有权 std::thread 是 move-only 类型，不能拷贝，只能通过移动转移所有权，但不能转移所有权到 joinable 的线程 #include \u003cthread\u003e #include \u003cutility\u003e void f() {} void g() {} int main() { std::thread a{f}; std::thread b = std::move(a); assert(!a.joinable()); assert(b.joinable()); a = std::thread{g}; assert(a.joinable()); assert(b.joinable()); // a = std::move(b); // 错误，不能转移所有权到 joinable 的线程 a.join(); a = std::move(b); assert(a.joinable()); assert(!b.joinable()); a.join(); } 移动操作同样适用于支持移动的容器 #include \u003calgorithm\u003e #include \u003cthread\u003e #include \u003cvector\u003e int main() { std::vector\u003cstd::thread\u003e v; for (int i = 0; i \u003c 10; ++i) { v.emplace_back([] {}); } std::for_each(std::begin(v), std::end(v), std::mem_fn(\u0026std::thread::join)); } std::thread 可以作为函数返回值 #include \u003cthread\u003e std::thread f() { return std::thread{[] {}}; } int main() { std::thread t{f()}; t.join(); } std::thread 也可以作为函数参数 #include \u003cthread\u003e #include \u003cutility\u003e void f(std::thread t) { t.join(); } int main() { f(std::thread([] {})); std::thread t([] {}); f(std::move(t)); } 实现一个可以直接用 std::thread 构造的自动清理线程的类 #include \u003cstdexcept\u003e #include \u003cthread\u003e #include \u003cutility\u003e class scoped_thread { public: explicit scoped_thread(std::thread x) : t_(std::move(x)) { if (!t_.joinable()) { throw std::logic_error(\"no thread\"); } } ~scoped_thread() { t_.join(); } scoped_thread(const scoped_thread\u0026) = delete; scoped_thread\u0026 operator=(const scoped_thread\u0026) = delete; private: std::thread t_; }; int main() { scoped_thread t{std::thread{[] {}}}; } 类似 std::jthread 的类 #include \u003cthread\u003e class Jthread { public: Jthread() noexcept = default; template \u003ctypename T, typename... Ts\u003e explicit Jthread(T\u0026\u0026 f, Ts\u0026\u0026... args) : t_(std::forward\u003cT\u003e(f), std::forward\u003cTs\u003e(args)...) {} explicit Jthread(std::thread x) noexcept : t_(std::move(x)) {} Jthread(Jthread\u0026\u0026 rhs) noexcept : t_(std::move(rhs.t_)) {} Jthread\u0026 operator=(Jthread\u0026\u0026 rhs) noexcept { if (joinable()) { join(); } t_ = std::move(rhs.t_); return *this; } Jthread\u0026 operator=(std::thread t) noexcept { if (joinable()) { join(); } t_ = std::move(t); return *this; } ~Jthread() noexcept { if (joinable()) { join(); } } void swap(Jthread\u0026\u0026 rhs) noexcept { t_.swap(rhs.t_); } std::thread::id get_id() const noexcept { return t_.get_id(); } bool joinable() const noexcept { return t_.joinable(); } void join() { t_.join(); } void detach() { t_.detach(); } std::thread\u0026 as_thread() noexcept { return t_; } const std::thread\u0026 as_thread() const noexcept { return t_; } private: std::thread t_; }; int main() { Jthread t{[] {}}; } ","date":"2023-11-01","objectID":"/posts/ch02_managing_threads/:3:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [2] | CH02 Managing Threads","uri":"/posts/ch02_managing_threads/"},{"categories":["C++"],"content":"查看硬件支持的线程数量 hardware_concurrency 会返回硬件支持的并发线程数 #include \u003ciostream\u003e #include \u003cthread\u003e int main() { unsigned int n = std::thread::hardware_concurrency(); std::cout \u003c\u003c n \u003c\u003c \" concurrent threads are supported.\\n\"; } 并行版本的 std::accumulate #include \u003calgorithm\u003e #include \u003ccassert\u003e #include \u003cfunctional\u003e #include \u003citerator\u003e #include \u003cnumeric\u003e #include \u003cthread\u003e #include \u003cvector\u003e template \u003ctypename Iterator, typename T\u003e struct accumulate_block { void operator()(Iterator first, Iterator last, T\u0026 res) { res = std::accumulate(first, last, res); } }; template \u003ctypename Iterator, typename T\u003e T parallel_accumulate(Iterator first, Iterator last, T init) { long len = std::distance(first, last); if (!len) { return init; } long min_per_thread = 25; long max_threads = (len + min_per_thread - 1) / min_per_thread; long hardware_threads = std::thread::hardware_concurrency(); long num_threads = // 线程数量 std::min(hardware_threads == 0 ? 2 : hardware_threads, max_threads); long block_size = len / num_threads; // 每个线程中的数据量 std::vector\u003cT\u003e res(num_threads); std::vector\u003cstd::thread\u003e threads(num_threads - 1); // 已有主线程故少一个线程 Iterator block_start = first; for (long i = 0; i \u003c num_threads - 1; ++i) { Iterator block_end = block_start; std::advance(block_end, block_size); // block_end 指向当前块尾部 threads[i] = std::thread{accumulate_block\u003cIterator, T\u003e{}, block_start, block_end, std::ref(res[i])}; block_start = block_end; } accumulate_block\u003cIterator, T\u003e()(block_start, last, res[num_threads - 1]); std::for_each(threads.begin(), threads.end(), std::mem_fn(\u0026std::thread::join)); return std::accumulate(res.begin(), res.end(), init); } int main() { std::vector\u003clong\u003e v(1000000); std::iota(std::begin(v), std::end(v), 0); long res = std::accumulate(std::begin(v), std::end(v), 0); assert(parallel_accumulate(std::begin(v), std::end(v), 0) == res); } ","date":"2023-11-01","objectID":"/posts/ch02_managing_threads/:4:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [2] | CH02 Managing Threads","uri":"/posts/ch02_managing_threads/"},{"categories":["C++"],"content":"线程号 可以通过对线程实例调用成员函数 get_id 或在当前线程中调用 std::this_thread::get_id 获取 线程号，其本质是一个无符号整型的封装，允许拷贝和比较，因此可以将其作为容器的键值，如果两个线程的线程号相等，则两者是同一线程或都是空线程（一般空线程的线程号为 0） #include \u003ciostream\u003e #include \u003cthread\u003e #ifdef _WIN32 #include \u003cWindows.h\u003e #elif defined __GNUC__ #include \u003csyscall.h\u003e #include \u003cunistd.h\u003e #endif void print_current_thread_id() { #ifdef _WIN32 std::cout \u003c\u003c std::this_thread::get_id() \u003c\u003c std::endl; // 19840 std::cout \u003c\u003c GetCurrentThreadId() \u003c\u003c std::endl; // 19840 std::cout \u003c\u003c GetThreadId(GetCurrentThread()) \u003c\u003c std::endl; // 19840 #elif defined __GNUC__ std::cout \u003c\u003c std::this_thread::get_id() \u003c\u003c std::endl; // 1 std::cout \u003c\u003c pthread_self() \u003c\u003c std::endl; // 140250646003520 std::cout \u003c\u003c getpid() \u003c\u003c std::endl; // 1502109，ps aux 显示此 pid std::cout \u003c\u003c syscall(SYS_gettid) \u003c\u003c std::endl; // 1502109 #endif } std::thread::id master_thread_id = std::this_thread::get_id(); void f() { if (std::this_thread::get_id() == master_thread_id) { // do_master_thread_work(); } // do_common_work(); } int main() { print_current_thread_id(); f(); std::thread t{f}; t.join(); } ","date":"2023-11-01","objectID":"/posts/ch02_managing_threads/:5:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [2] | CH02 Managing Threads","uri":"/posts/ch02_managing_threads/"},{"categories":["C++"],"content":"CPU 亲和性（affinity） 将线程绑定到一个指定的 CPU core 上运行，避免多核 CPU 上下文切换和 cache miss 的开销 #ifdef _WIN32 #include \u003cWindows.h\u003e #elif defined __GNUC__ #include \u003cpthread.h\u003e #include \u003csched.h\u003e #include \u003cstring.h\u003e #endif #include \u003ciostream\u003e #include \u003cthread\u003e void affinity_cpu(std::thread::native_handle_type t, int cpu_id) { #ifdef _WIN32 if (!SetThreadAffinityMask(t, 1ll \u003c\u003c cpu_id)) { std::cerr \u003c\u003c \"fail to affinity\" \u003c\u003c GetLastError() \u003c\u003c std::endl; } #elif defined __GNUC__ cpu_set_t cpu_set; CPU_ZERO(\u0026cpu_set); CPU_SET(cpu_id, \u0026cpu_set); int res = pthread_setaffinity_np(t, sizeof(cpu_set), \u0026cpu_set); if (res != 0) { errno = res; std::cerr \u003c\u003c \"fail to affinity\" \u003c\u003c strerror(errno) \u003c\u003c std::endl; } #endif } void affinity_cpu_on_current_thread(int cpu_id) { #ifdef _WIN32 if (!SetThreadAffinityMask(GetCurrentThread(), 1ll \u003c\u003c cpu_id)) { std::cerr \u003c\u003c \"fail to affinity\" \u003c\u003c GetLastError() \u003c\u003c std::endl; } #elif defined __GNUC__ cpu_set_t cpu_set; CPU_ZERO(\u0026cpu_set); CPU_SET(cpu_id, \u0026cpu_set); int res = pthread_setaffinity_np(pthread_self(), sizeof(cpu_set), \u0026cpu_set); if (res != 0) { errno = res; std::cerr \u003c\u003c \"fail to affinity\" \u003c\u003c strerror(errno) \u003c\u003c std::endl; } #endif } void f() { affinity_cpu_on_current_thread(0); } int main() { std::thread t1{[] {}}; affinity_cpu(t1.native_handle(), 1); std::thread t2{f}; t1.join(); t2.join(); } ","date":"2023-11-01","objectID":"/posts/ch02_managing_threads/:6:0","tags":["C++_Concurrency"],"title":"C++ Concurrency in Action [2] | CH02 Managing Threads","uri":"/posts/ch02_managing_threads/"},{"categories":["C++"],"content":"1. 总览 什么是CMake？ CMake是个一个开源的跨平台自动化建构系统，用来管理软件建置的程序，并不相依于某特定编译器。并可支持多层目录、多个应用程序与多个库。 它用配置文件控制建构过程（build process）的方式和Unix的make相似，只是CMake的配置文件取名为CMakeLists.txt。 CMake并不直接建构出最终的软件，而是产生标准的建构档（如Unix的Makefile或Windows Visual C++的projects/workspaces），然后再依一般的建构方式使用。 这使得熟悉某个集成开发环境（IDE）的开发者可以用标准的方式建构他的软件，这种可以使用各平台的原生建构系统的能力是CMake和SCons等其他类似系统的区别之处。 它首先允许开发者编写一种平台无关的CMakeList.txt 文件来定制整个编译流程，然后再根据目标用户的平台进一步生成所需的本地化 Makefile 和工程文件，如 Unix的 Makefile 或 Windows 的 Visual Studio 工程。从而做到“Write once, run everywhere”。 显然，CMake 是一个比上述几种 make 更高级的编译配置工具。“CMake”这个名字是\"Cross platform MAke\"的缩写。虽然名字中含有\"make\"，但是CMake和Unix上常见的“make”系统是分开的，而且更为高端。 它可与原生建置环境结合使用，例如：make、苹果的Xcode与微软的Visual Studio。 CMake is not a build system like Unix Make but a build system generator. Its purpose is to take your description of a project and generate a set of configuration files to build that project. CMake 是构建系统的生成器。它的目标是：根据你对项目的描述信息，去生成一系列的配置文件，来编译构建项目。 As part of the generation of build configuration files, CMake also analyses source code to create a dependency graph of components so that when building the project unnecessary recompilation steps can be omitted to reduce build times. For larger projects this can reduce build times down from tens of minutes or hours, to a few minutes, perhaps even less than one minute. 作为构建配置文件生成的一部分，CMake 还会去分析源码，来创建各个部分之间的依赖图，所以在构建项目时，不必要的重编步骤就会被省略掉。这样节省了大量构建的时间。 CMake Build Process In addition to a build system, over the years CMake has evolved into a family of development tools: CMake, CTest, CPack, and CDash. CMake is the build tool responsible for building software. CTest is a test driver tool, used to run regression tests. CPack is a packaging tool used to create platform-specific installers for software built with CMake. CDash is a web application for displaying testing results and performing continuous integration testing. 除了构建系统，CMake 还发展出一系列工具：CMake 是构建工具，CTest 是用于回归测试的测试工具，CPack 是用于为用 CMake 构建的软件创建指定平台安装器的打包工具，CDash 是展示测试结构和执行持续集成测试的 web 端应用。 ","date":"2023-11-01","objectID":"/posts/cmake_introduction/:1:0","tags":["CMake"],"title":"CMake 简介","uri":"/posts/cmake_introduction/"},{"categories":["C++"],"content":"2. Notion The build tree is the directory hierarchy in which all generated files are placed. Generated files consist of the makefile, the compiled object files, and a dependency file (with a . d extension) for each source file. 构建树是放置所有生成文件的目录层级结构。生成文件包括 makefile、编译出来的目标文件、每个源文件的依赖文件。 ","date":"2023-11-01","objectID":"/posts/cmake_introduction/:2:0","tags":["CMake"],"title":"CMake 简介","uri":"/posts/cmake_introduction/"},{"categories":["C++"],"content":"3. Requirements When CMake was being developed, the normal practice for a project was to have a configure script and Makefiles for Unix platforms, and Visual Studio project files for Windows. This duality of build systems made cross-platform development very tedious for many projects: the simple act of adding a new source file to a project was painful. The obvious goal for developers was to have a single unified build system. The developers of CMake had experience with two approaches of solving the unified build system problem. 在 CMake 被开发之时，常规的项目操作是：一个配置脚本，以及 Makefiles (Unix 平台) 或 Visual Studio 项目文件(Windows 平台)。这样的构建系统导致跨平台开发非常地难受：简单地添加一个文件到项目的操作都很痛苦。对于开发者而言，一个显然的目标就是一个统一的构建系统。 The basic constraints of the new build system would be as follows: 对于新的构建系统的限制如下: Depend only on a C++ compiler being installed on the system. 只依赖系统安装的 c++ 编译器 It must be able to generate Visual Studio IDE input files. 可以生成 VS IDE 的输入文件 It must be easy to create the basic build system targets, including static libraries, shared libraries, executables, and plugins. 很容易创建目标文件 It must be able to run build time code generators. 可以运行编译时代码生成器 It must support separate build trees from the source tree. 可以支持独立于源树的构建树 It must be able to perform system introspection, i.e., be able to determine automatically what the target system could and could not do. 反映系统问题 It must do dependency scanning of C/C++ header files automatically. 自动地进行 C/C++ 头文件的依赖扫描 All features would need to work consistently and equally well on all supported platforms. 所有特性需要协调工作，且良好运行在所有支持的平台 In order to avoid depending on any additional libraries and parsers, CMake was designed with only one major dependency, the C++ compiler (which we can safely assume we have if we’re building C++ code). This did limit CMake to creating its own simple language, which is a choice that still causes some people to dislike CMake. However, at the time the most popular embedded language was Tcl. If CMake had been a Tcl-based build system, it is unlikely that it would have gained the popularity that it enjoys today. 为了避免依赖额外的库或解析器，CMake 只存在一种主要的依赖：C++ 编译器。这限制了 CMake 创建属于自己的语言，引起大家的不满。 The ability to generate IDE project files is a strong selling point for CMake, but it also limits CMake to providing only the features that the IDE can support natively. However, the benefits of providing native IDE build files outweigh the limitations. Although this decision made the development of CMake more difficult, it made the development of ITK and other projects using CMake much easier. Developers are happier and more productive when using the tools they are most familiar with. By allowing developers to use their preferred tools, projects can take best advantage of their most important resource: the developer. 可以生成 IDE 项目文件的能力是 CMake 的一大卖点，但同样也限制了 CMake 只去提供 IDE 本地支持的一些特性。但是，利大于弊。 Another early CMake requirement also came from autotools: the ability to create build trees that are separate from the source tree. This allows for multiple build types to be performed on the same source tree. It also prevents the source tree from being cluttered with build files, which often confuses version control systems. 支持创建独立于源树的构建树。这个可以使相同的源树拥有众多的构建类型，同时也防止源树被构建文件污染，导致版本控制系统的混乱。 CMake Build System ","date":"2023-11-01","objectID":"/posts/cmake_introduction/:3:0","tags":["CMake"],"title":"CMake 简介","uri":"/posts/cmake_introduction/"},{"categories":["C++"],"content":"4. Implementation Environment Variables (or Not) The trouble with this approach is that for the build to work, all of these external variables need to be set each time a build is performed. To solve this problem CMake has a cache file that stores all of the variables required for a build in one place. These are not shell or environment variables, but CMake variables. The first time CMake is run for a particular build tree, it creates a CMakeCache.txt file which stores all the persistent variables for that build. Since the file is part of the build tree, the variables will always be available to CMake during each run. 难点在于在每次编译时，所有的外部变量都需要设置一遍。为了解决这个问题，CMake 用一个 cache 文件保存所有编译所需的变量。这些不是 shell 或环境变量，只是 CMake 的变量。第一次 CMake 运行时，它会创建 CMakeCache.txt 文件来保存这些变量。这个文件就是构建树的一部分，所以对于 CMake 的每次运行都是有效的。 The Configure Step During the configure step, CMake first reads the CMakeCache.txt if it exists from a prior run. It then reads CMakeLists.txt, found in the root of the source tree given to CMake. During the configure step, the CMakeLists.txt files are parsed by the CMake language parser. Each of the CMake commands found in the file is executed by a command pattern object. Additional CMakeLists.txt files can be parsed during this step by the include and add_subdirectory CMake commands. CMake has a C++ object for each of the commands that can be used in the CMake language. Some examples of commands are add_library, if, add_executable, add_subdirectory, and include. In effect, the entire language of CMake is implemented as calls to commands. The parser simply converts the CMake input files into command calls and lists of strings that are arguments to commands. 在配置阶段，CMake 首先读取 CMakeCache.txt 文件(如果存在的话)，然后读取 CMakeLists.txt 来查找源树的根。在配置阶段，CMakeLists.txt 文件会被 CMake 语言解析器解析。每当有 CMake 命令在这个文件中被找到就会被参数模版对象执行。额外的 CMakeLists.txt 文件会在处理 include 和 add_subdirectory 命令之时解析。 The configure step essentially “runs” the user-provided CMake code. After all of the code is executed, and all cache variable values have been computed, CMake has an in-memory representation of the project to be built. This will include all of the libraries, executables, custom commands, and all other information required to create the final build files for the selected generator. At this point, the CMakeCache.txt file is saved to disk for use in future runs of CMake. 配置阶段本质上会运行用户提供的 CMake 的代码。在所有代码执行完成，以及所有变量值计算完成之后，CMake 会有一个项目的内存表示需要构建，它会包含所有的库、可执行文件、指定的命令和所有其他需要去创建最终的构建文件的信息。在此，CMakeCache.txt 文件会被保存到磁盘中，作为 CMake 之后的使用。 The Generate Step CMake Generator Expression Once the configure step has been completed, the generate step can take place. The generate step is when CMake creates the build files for the target build tool selected by the user. At this point the internal representation of targets (libraries, executables, custom targets) is converted to either an input to an IDE build tool like Visual Studio, or a set of Makefiles to be executed by make. CMake’s internal representation after the configure step is as generic as possible so that as much code and data structures as possible can be shared between different built tools. 一旦配置完成，就到生成阶段了。这个阶段 CMake 会创建用户选择的目标构建工具的构建文件。在此，目标的内部表示会被转成 IDE 的构建工具，或者 make 用到的一系列 Makefiles。CMake 的内部表示需要尽可能通用，这样代码和数据结构可以被不同的构建工具所共享。 Generation ","date":"2023-11-01","objectID":"/posts/cmake_introduction/:4:0","tags":["CMake"],"title":"CMake 简介","uri":"/posts/cmake_introduction/"},{"categories":["C++"],"content":"5. The code CMake is an object-oriented system using inheritance, design patterns and encapsulation CMake 是使用了继承的面向对象的系统 Cmake Inheritage System The results of parsing each CMakeLists.txt file are stored in the cmMakefile object. In addition to storing the information about a directory, the cmMakefile object controls the parsing of the CMakeLists.txt file. The parsing function calls an object that uses a lex/yacc-based parser for the CMake language. Since the CMake language syntax changes very infrequently, and lex and yacc are not always available on systems where CMake is being built, the lex and yacc output files are processed and stored in the Source directory under version control with all of the other handwritten files. 解析 CMakeLists.txt 文件的结果被保存到 cmMakefile 对象当中。除了保存目录信息，它还控制文件的解析。解析函数可以使用 CMake 语言的解析器。CMake 语法不怎么变化，解析器在 CMake 构建时并非总是活跃的，解析的结果会被保存在 Source 目录下。 Another important class in CMake is cmCommand. This is the base class for the implementation of all commands in the CMake language. Each subclass not only provides the implementation for the command, but also its documentation. 另一个重要的类是 cmCommand。这是 CMake 命令的基类。每个子类不仅提供命令的实现，还有它们的文档说明。 ","date":"2023-11-01","objectID":"/posts/cmake_introduction/:5:0","tags":["CMake"],"title":"CMake 简介","uri":"/posts/cmake_introduction/"},{"categories":["C++"],"content":"6. Dependency Analysis Since Integrated Development Environments (IDEs) support and maintain file dependency information, CMake skips this step for those build systems. For IDE builds, CMake creates a native IDE input file, and lets the IDE handle the file level dependency information. The target level dependency information is translated to the IDE’s format for specifying dependency information. 由于 IDE 本身支持和持有文件依赖信息，CMake 就可以跳过这个步骤。IDE 构建时，CMake 创建一个本地的 IDE 输入文件，然后让 IDE 去处理文件级别的依赖信息。目标级别的依赖信息会被转成 IDE 的格式来指明依赖信息。 With Makefile-based builds, native make programs do not know how to automatically compute and keep dependency information up-to-date. For these builds, CMake automatically computes dependency information for C, C++ and Fortran files. Both the generation and maintenance of these dependencies are automatically done by CMake. Once a project is initially configured by CMake, users only need to run make and CMake does the rest of the work. 在使用 Makefile 构建，本地 make 程序不需要知道怎么自动计算和保存依赖信息为最新。构建时，CMake 自动的计算这些依赖信息，包括生成和保存。一旦 CMake 初始配置好了项目，用户只需要去运行 make，然后 CMake 会把剩下的工作完成。 CMake does more than just generate the build files used to create object files and executable programs. It will generate a dependency file for each source file in the project. For example a main.cpp file will have a generated main.cpp.d file saved in the build folder hierarchy honouring the directory structure of the source files. CMake 不只是生成构建文件，它会为项目里的每个源文件生成依赖文件。比如 main.cpp 会促使生成 main.cpp.d 文件。 Although users do not need to know how CMake does this work, it may be useful to look at the dependency information files for a project. This information for each target is stored in four files called depend.make, flags.make, build.make, and DependInfo.cmake. depend.make stores the dependency information for all the object files in the directory. flags.make contains the compile flags used for the source files of this target. If they change then the files will be recompiled. DependInfo.cmake is used to keep the dependency information up-to-date and contains information about what files are part of the project and what languages they are in. Finally, the rules for building the dependencies are stored in build.make. If a dependency for a target is out of date then the depend information for that target will be recomputed, keeping the dependency information current. This is done because a change to a .h file could add a new dependency. 依赖信息会被保存在 4 个文件当中，depend.make, flags.make, build.make, DependInfo.cmake 文件。depend.make 保存所有目录下的目标文件的依赖信息。flags.make 含有从源文件到目标的编译参数，如果参数被更改，这个文件也会被重新编译。DependInfo.cmake 是用来保证依赖信息是最新的，保存有哪些文件是项目的一部分以及它们是什么语言的信息。最后，构建这些依赖的规则会被保存在 build.make 文件中。如果目标的依赖过期了，那么依赖信息会被重新计算，保证依赖信息最新。这样做是因为头文件可能会添加新的依赖。 Cmake Dependency Graph ","date":"2023-11-01","objectID":"/posts/cmake_introduction/:6:0","tags":["CMake"],"title":"CMake 简介","uri":"/posts/cmake_introduction/"},{"categories":["C++"],"content":"7. CTest and CPack The ctest executable is used to run regression tests. A project can easily create tests for CTest to run with the add_test command. The tests can be run with CTest, which can also be used to send testing results to the CDash application for viewing on the web. CTest and CDash together are similar to the Hudson testing tool. They do differ in one major area: CTest is designed to allow a much more distributed testing environment. Clients can be setup to pull source from version control system, run tests, and send the results to CDash. With Hudson, client machines must give Hudson ssh access to the machine so tests can be run. ctest 可执行文件用于跑回归测试。一个项目可以通过 add_test 命令很方便地创建测试。由 CTest 来执行，所以也可以把测试结果发给 CDash 来做 web 端展示。 The cpack executable is used to create installers for projects. CPack works much like the build part of CMake: it interfaces with other packaging tools. For example, on Windows the NSIS packaging tool is used to create executable installers from a project. CPack runs the install rules of a project to create the install tree, which is then given to a an installer program like NSIS. CPack also supports creating RPM, Debian .deb files, .tar, .tar.gz and self-extracting tar files. cpack 可执行文件用来创建项目的安装器。 ","date":"2023-11-01","objectID":"/posts/cmake_introduction/:7:0","tags":["CMake"],"title":"CMake 简介","uri":"/posts/cmake_introduction/"},{"categories":["C++"],"content":"8. Reference [1]. CMake 构建工具 [2]. https://aosabook.org/en/cmake.html [3]. https://blog.feabhas.com/2021/07/cmake-part-1-the-dark-arts/ [4]. https://blog.feabhas.com/2021/07/cmake-part-2-release-and-debug-builds/ [5]. 深入理解CMake：优化构建过程，提升开发效率 ","date":"2023-11-01","objectID":"/posts/cmake_introduction/:8:0","tags":["CMake"],"title":"CMake 简介","uri":"/posts/cmake_introduction/"},{"categories":["ObjectDetection"],"content":"Abstract DETR消除了目标检任务中的手工设计痕迹，但是存在收敛慢以及Transformer的自注意力造成的特征图分辨率不能太高的问题，这就导致了小目标检测性能很差。我们的Deformable DETR只在参考点附近采样少量的key来计算注意力，因此我们的方法收敛快并且可以用到多尺度特征。 相对于Transformer那种全局(global)\u0026密集(dense)的注意力机制，这里提出了一种新玩法: 每个参考点仅关注邻域的一组采样点，这些采样点的位置并非固定，而是可学习的(和可变形卷积一样)，从而实现了一种局部(local)\u0026稀疏(sparse)的高效注意力机制。 ","date":"2023-10-27","objectID":"/posts/deformabledetr/:1:0","tags":["draft"],"title":"Deformable DETR论文精读+代码详解","uri":"/posts/deformabledetr/"},{"categories":["ObjectDetection"],"content":"1、Introduction 传统目标检测任务有很多手工设计痕迹，所以不是端到端的网络。DETR运用到了Transformer强大的功能以及全局关系建模能力来取代目标检测中人工设计痕迹来达到端到端的目的。 DETR 的优势: (i). 第一个端到端的目标检测器； (ii). 不需要众多手工设计组件(如anchor、固定规则的标签分配策略、NMS后处理等) (iii). DETR实质上相当于是给出了一个方法论，犹如“普度众生”，告诉大家Transformer可以拿到目标检测中来玩，并没有过多地追求其它方面的成就。 DETR的两大缺点: 收敛速度慢(slow convergence): 因为全局像素之间计算注意力要收敛到几个稀疏的像素点需要消耗很长的时间。 小目标检测差: 目标检测基本都是在大分辨率的特征图上进行小目标的检测，但是Transformer中的Self Attention的计算复杂度是平方级别的，所以只能利用到最后一层特征图。 Transformer在初始化时，分配给所有特征像素的注意力权重几乎是均等的，这就造成了模型需要长时间去学习关注真正有意义的位置，这些位置应该是稀疏的； Transformer在计算注意力权重时，伴随着高计算量与空间复杂度。特别是在编码器部分，与特征像素点的数量成平方级关系，因此难以处理高分辨率的特征(这点也是DETR检测小目标效果差的原因) 可变形卷积DCN是一种注意稀疏空间位置很好的机制，但是其缺乏元素之间关系的建模能力。 综上所述，Deformable Attention模块结合了DCN稀疏采样能力和Transformer的全局关系建模能力。这个模块可以聚合多尺度特征，不需要FPN了，我们用这个模块替换了Transformer Encoder中的Multi-Head Self-Attention模块和Transformer Decoder中的Cross Attention模块。 Deformable DETR的提出可以帮助探索更多端到端目标检测方案，提出了bbox迭代微调策略和两阶段方法，其中iterative bounding box refinement类似Cascade R-CNN方法，two stage类似RPN。 ","date":"2023-10-27","objectID":"/posts/deformabledetr/:2:0","tags":["draft"],"title":"Deformable DETR论文精读+代码详解","uri":"/posts/deformabledetr/"},{"categories":["ObjectDetection"],"content":"2、Related work Transformer中包含了多头自注意力和交叉注意力机制，其中多头自注意力机制对key的数量很敏感，平方级别的复杂度导致不能有太多的key，解决方法主要可以分为三类。 (1)第一类解决方法为在key上使用预定义稀疏注意力模式，例如将注意力限制在一个固定的局部窗口上，这将导致失去了全局信息。 (2)第二类是通过数据学习到相关的稀疏注意力。 (3)第三类是寻找自注意力中低等级的属性，类似限制关键元素的尺寸大小。 图像领域的注意力方法大多数都局限于第一种设计方法，但是因为内存模式原因速度要比传统卷积慢3倍(相同的FLOPs下)。DCN可以看作是一种自注意力机制，它比自注意力机制更加高效有效，但是其缺少元素关系建模的机制。我们的可变形注意力模块来源于DCN，并且属于第二类注意力方法。它只关注从q特征预测得到的一小部分固定数量的采样点。 目标检测任务一个难点就是高效的表征不同尺度下的物体。现在有的方法比如FPN，PA-FPN，NAS-FPN，Auto-FPN，BiFPN等。我们的多尺度可变形注意力模块可以自然的融合基于注意力机制的多尺度特征图，不需要FPN了。 ","date":"2023-10-27","objectID":"/posts/deformabledetr/:3:0","tags":["draft"],"title":"Deformable DETR论文精读+代码详解","uri":"/posts/deformabledetr/"},{"categories":["ObjectDetection"],"content":"3、Revisiting Transformers And DETR ","date":"2023-10-27","objectID":"/posts/deformabledetr/:4:0","tags":["draft"],"title":"Deformable DETR论文精读+代码详解","uri":"/posts/deformabledetr/"},{"categories":["ObjectDetection"],"content":"3.1、Transformer中的Multi-Head Self-Attention 该模块计算复杂度为: $O(N_qC^2+N_kC^2+N_qN_kC)$ ，其中 $C$ 代表特征图维度，$N_q$ 和 $N_k$ 均为图片中的像素(pixel)，因此有 $N_{q}=N_{k}\\gg C$ 。所以计算复杂度可以简化为 $O(N_{q}N_{k}C)$ ，可以得出其与图片像素的数量成平方级别的计算复杂度。 ","date":"2023-10-27","objectID":"/posts/deformabledetr/:4:1","tags":["draft"],"title":"Deformable DETR论文精读+代码详解","uri":"/posts/deformabledetr/"},{"categories":["ObjectDetection"],"content":"3.2、DETR DETR在目标检测领域中引入了Transformer结构并且取得了不错的效果。这套范式摒弃了传统目标检测中的anchor和post processing 机制，而是先预先设定100个object queries然后进行二分图匹配计算loss。其具体流程图(pipeline)如下: 输入图片3×800×1066的一张图片，经过卷积神经网络提取特征，长宽32倍下采样后得到2048×25×34，然后通过一个1×1 Conv进行降维最终得到输出shape为256×25×34. positional encoding为绝对位置编码，为了和特征完全匹配形状也为256×25×34，然后和特征进行元素级别的相加后输入到Transformer Encoder中。 输入到Encoder的尺寸为(25×34)×256=850×256，代表有850个token，每个token的维度为256，Encoder不改变输入的Shape。 Encoder的输出和object queries输入到Decoder中形成cross attention，object queries的维度设置为anchor数量×token数量。 Decoder输出到FFN进行分类和框定位，其中FFN是共享参数的。 Tips: 虽然DETR没有anchor，但是object queries其实就是起到了anchor的作用。 ","date":"2023-10-27","objectID":"/posts/deformabledetr/:4:2","tags":["draft"],"title":"Deformable DETR论文精读+代码详解","uri":"/posts/deformabledetr/"},{"categories":["ObjectDetection"],"content":"4、Method ","date":"2023-10-27","objectID":"/posts/deformabledetr/:5:0","tags":["draft"],"title":"Deformable DETR论文精读+代码详解","uri":"/posts/deformabledetr/"},{"categories":["ObjectDetection"],"content":"4.1、Deformable Attention Module Deformable Attention Module主要思想是结合了DCN和自注意力，目的就是为了通过在输入特征图上的参考点(reference point)附近只采样少数点(deformable detr设置为3个点)来作为注意力的 $k$。因此要解决的问题就是: (1). 确定reference point。 (2). 确定每个reference point的偏移量(offset)。 (3). 确定注意力权重矩阵。 在Encoder和Decoder中实现方法不太一样，加下来详细叙述。 Encoder部分 在Encoder部分，输入的Query Feature $z_q$ 为加入了位置编码的特征图(src+pos)，$value(x)$ 的计算方法只使用了src而没有位置编码(value_proj函数)。 (1). reference point确定方法为用了torch.meshgrid方法，调用的函数如下(get_reference_points)，有一个细节就是参考点归一化到0和1之间，因此取值的时候要用到双线性插值的方法。 不同点: 在Decoder中，参考点的获取方法为object queries通过一个nn.Linear得到每个对应的reference point。 def get_reference_points(spatial_shapes, valid_ratios, device): reference_points_list = [] for lvl, (H_, W_) in enumerate(spatial_shapes): # 从0.5到H-0.5采样H个点，W同理 这个操作的目的也就是为了特征图的对齐 ref_y, ref_x = torch.meshgrid(torch.linspace(0.5, H_ - 0.5, H_, dtype=torch.float32, device=device), torch.linspace(0.5, W_ - 0.5, W_, dtype=torch.float32, device=device)) ref_y = ref_y.reshape(-1)[None] / (valid_ratios[:, None, lvl, 1] * H_) ref_x = ref_x.reshape(-1)[None] / (valid_ratios[:, None, lvl, 0] * W_) ref = torch.stack((ref_x, ref_y), -1) reference_points_list.append(ref) reference_points = torch.cat(reference_points_list, 1) reference_points = reference_points[:, :, None] * valid_ratios[:, None] return reference_points (2)计算offset的方法为对 $z_q$ 做一个nn.Linear，得到多组偏移量，每组偏移量的维度为参考点的个数，组数为注意力头的数量。 (3)计算注意力权重矩阵的方法为过一个nn.Linear和一个F.softmax，得到每个头的注意力权重。 如图2所示，分头计算完的注意力最终会拼接到一起，然后最后过一个nn.Linear得到输入 $x$ 的最终输出。 ","date":"2023-10-27","objectID":"/posts/deformabledetr/:5:1","tags":["draft"],"title":"Deformable DETR论文精读+代码详解","uri":"/posts/deformabledetr/"},{"categories":["ObjectDetection"],"content":"4.2、Multi-Scale Deformable Attention Module Multi-Scale Features \u0026 Scale-Level Embedding 多尺度的Deformable Attention模块也是在多尺度特征图上计算的。多尺度的特征融合方法则是取了骨干网络(ResNet)最后三层的特征图C3，C4，C5，并且用了一个Conv3x3 Stride2的卷积得到了一个C6构成了四层特征图。下采样率对应为8、16、32， $C_6$ 由 $C_5$ 经过步长为2的3x3卷积得到。特别的是会通过卷积操作将通道数量统一为256(也就是token的数量)，然后在这四个特征图上运行Deformable Attention Module并且进行直接相加得到最终输出。其中Deformable Attention Module算子的pytorch实现如下: def ms_deform_attn_core_pytorch(value, value_spatial_shapes, sampling_locations, attention_weights): # for debug and test only, # need to use cuda version instead N_, S_, M_, D_ = value.shape # batch size, number token, number head, head dims # Lq_: number query, L_: level number, P_: sampling number采样点数 _, Lq_, M_, L_, P_, _ = sampling_locations.shape # 按照level划分value value_list = value.split([H_ * W_ for H_, W_ in value_spatial_shapes], dim=1) # [0, 1] -\u003e [-1, 1] 因为要满足F.grid_sample的输入要求 sampling_grids = 2 * sampling_locations - 1 sampling_value_list = [] for lid_, (H_, W_) in enumerate(value_spatial_shapes): # N_, H_*W_, M_, D_ -\u003e N_, H_*W_, M_*D_ -\u003e N_, M_*D_, H_*W_ -\u003e N_*M_, D_, H_, W_ value_l_ = value_list[lid_].flatten(2).transpose(1, 2).reshape(N_*M_, D_, H_, W_) # N_, Lq_, M_, P_, 2 -\u003e N_, M_, Lq_, P_, 2 -\u003e N_*M_, Lq_, P_, 2 sampling_grid_l_ = sampling_grids[:, :, :, lid_].transpose(1, 2).flatten(0, 1) # N_*M_, D_, Lq_, P_ # 用双线性插值从feature map上获取value，因为mask的原因越界所以要zeros的方法进行填充 sampling_value_l_ = F.grid_sample(value_l_, sampling_grid_l_, mode='bilinear', padding_mode='zeros', align_corners=False) sampling_value_list.append(sampling_value_l_) # (N_, Lq_, M_, L_, P_) -\u003e (N_, M_, Lq_, L_, P_) -\u003e (N_, M_, 1, Lq_, L_*P_) attention_weights = attention_weights.transpose(1, 2).reshape(N_*M_, 1, Lq_, L_*P_) # 不同scale计算出的multi head attention 进行相加，返回output后还需要过一个Linear层 output = (torch.stack(sampling_value_list, dim=-2).flatten(-2) * attention_weights).sum(-1).view(N_, M_*D_, Lq_) return output.transpose(1, 2).contiguous() 要知道，DETR仅用了单尺度特征，于是对于特征点位置信息的编码，使用的是三角函数，不同位置的特征点会对应不同的编码值，没问题。但是，注意了，这仅能区分位于单尺度特征点的位置！而在多尺度特征中，位于不同特征层的特征点可能拥有相同的(h,w)坐标，这样就无法区分它们的位置编码了。 针对这个问题，作者增加使用一个称之为scale-level embedding的东东，它仅用于区分不同的特征层，也就是同一特征层中的所有特征点会对应相同的scale-level embedding，于是有几层特征就使用几个不同的scale-level embedding。 另外，不同于三角函数那种固定地利用公式计算出来的编码方式，这个scale-level embedding是随机初始化并且是随网络一起训练的、是可学习的: # scale-level embedding # 对4个特征层每层附加256-dim的embedding # 目的是为了区分query对应到哪个特征层，它会与position embedding相加在一起 # 注意: 位于同一个特征的所有query都会对应到相同的scale-level embedding self.level_embed = nn.Parameter(torch.Tensor(num_feature_levels, d_model)) 在实际使用时，这个 scale-level embedding 与基于三角函数公式计算的 position embedding 相加在一起作为位置信息的嵌入: # 由于 position embedding仅区分h, w的位置，因此对于不同特征层有相同坐标值的特征点来说，是无法区分的，于是这里附加上scale-level embedding作为特征层的区分信息，这样，所有特征点的位置信息就各不相同了 # (bs, c, h, w) =\u003e (bs, h*w, c) pos_embed = pos_embed.flatten(2).transpose(1, 2) # (bs, h*w, c) + (1, 1, 256) # note that c = 256 here lvl_pos_embed = pos_embed + self.level_embed[lvl].view(1, 1, -1) Deformable Attention(\u0026Multi-Scale) 可变形注意力的道理用大白话来说很简单: query不是和全局每个位置的key都计算注意力权重，而是对于每个query，仅在全局位置中采样部分位置的key，并且value也是基于这些位置进行采样插值得到的，最后将这个局部\u0026稀疏的注意力权重施加在对应的value上。 Transformer中多头注意力的公式如下: $$ \\text{MultiHeadAttn}(z_q,x)=\\sum_{m=1}^MW_m\\big[\\sum_{k\\in\\Omega_k}A_{mqk}\\cdot W_m^{\\prime}x_k\\big], $$ 其中，$z_q$ 看作query，由 $x$ 经过线性变换生成，$q$ 是对应的索引，$k$ 是key的索引, $\\Omega_k$ 即所有的 $k$ 集合，$m$ 代表是第几个注意力头部，$W_m$ 是对注意力施加在value后的结果进行线性变换从而得到不同头部的输出结果，$W_m^{’}$用于将 $x_k$ 变换成value，$A_{mqk}$ 代表归一化的注意力权重。 Deformable Attetion公式: $$ \\text{DeformAttn}(z_q,p_q,x)=\\sum_{m=1}^MW_m\\big[\\sum_{k=1}^KA_{mqk}\\cdot W_m’x(p_q+\\Delta p_{mqk})\\big], $$ 和Transformer的很像是不是？(老师我没有抄作业，别凶..)可以看到，这里多了 $p_q$ 和 $\\Delta p_{mqk}$。其中，前者代表 $z_q$ 的位置(理解成坐标即可)，是2d向量，作者称其为参考点(reference points)；而后者是采样集合点相对于参考点的位置偏移(offsets)。 可以看到，每个query在每个头部中采样K个位置，只需和这些位置的特征交互($x(p_q+\\Delta p_{mqk})$ 代表基于采样点位置插值出来的value)，并不需要像Transformer般一开始先从全局位置开始学习才能逐渐过渡到关注局部(\u0026稀疏的)的、真正有意义的位置。 需要注意的是，如可变形卷积一样，位置偏移 $\\Delta p_{mqk}$ 是可学习的，由query经过全连接层得到。并且，注意力权重也一样，直接由query经过全连接层得到(因此，在可变形注意力机制下，其实没有真正所谓的key来与query交互计算，为何可以这样做，后文CW会谈自己的看法)！同时在K","date":"2023-10-27","objectID":"/posts/deformabledetr/:5:2","tags":["draft"],"title":"Deformable DETR论文精读+代码详解","uri":"/posts/deformabledetr/"},{"categories":["ObjectDetection"],"content":"4.3 Deformable Transformer 这里的Transformer和DETR中的大体过程一致，最主要的区别在于用可变形注意力替代了Encoder中的自注意力(self-attention)以及Decoder中的交叉注意力(cross-attention)。在分别解析Encoder和Decoder前，CW先向大家梳理下这里Transformer的整个pipeline(有源码解析哦！)。 1). 为Encoder的输入做准备 主要是将一些输入元素的维度展平(flatten)，这些输入元素包括: 多尺度特征图、各尺度特征图对应的mask(指示哪些部分属于padding)、各尺度特征图对应的位置信息(position embedding + scale-level embedding)，另外还有些辅助信息，比如: 各尺度特征图的宽高、不同尺度特征对应于被flatten的那个维度的起始索引、各尺度特征图中非padding部分的边长占其边长的比例。 # deformable transformer forward函数 def forward(self, srcs, masks, pos_embeds, query_embed=None): assert self.two_stage or query_embed is not None \"\"\"为Encoder的输入作准备: (i). 将各层特征图(已映射到c=256维度)flatten并concat到一起: (bs, h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 +..., 256); (ii). 将各层特征图对应的mask(指示了哪些位置是padding)flatten并concat: (bs, h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 + ...,) (iii). 将各层特征图对应的position embedding加上scale level embedding(用于表明query属于哪个特征层)， 然后flatten并concat: (bs, h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 + ..., 256); (iv). 将各层特征图的宽高由list变为tensor: (n_lvl, 2); (v). 由于将所有特征图的特征点concat在了一起 (h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 + ...), 因此为了区分各层，需要计算对应于被flatten那个维度的起始index(第一层当然是0，后面就是累加...) (vi). 计算各层特征层中非padding的部分边长(高\u0026宽)占特征图边长的比例(bs, n_lvl, 2) \"\"\" # prepare input for encoder # 以下的flatten指的是将h，w两个维度展平为h * w src_flatten = [] mask_flatten = [] # 各层特征图对应的position embedding + scale-level embedding lvl_pos_embed_flatten = [] # 各层特征图的尺寸(h, w) spatial_shapes = [] for lvl, (src, mask, pos_embed) in enumerate(zip(srcs, masks, pos_embeds)): bs, c, h, w = src.shape spatial_shape = (h, w) spatial_shapes.append(spatial_shape) # (bs, c, h, w) =\u003e (bs, h*w, c) src = src.flatten(2).transpose(1, 2) # (bs, h, w) =\u003e (bs, h*w) mask = mask.flatten(1) \"\"\" 由于position embedding仅区分h，w的位置 因此对于不同特征层有相同坐标值的特征点来说，是无法区分的，于是这里附加上scale-level embedding作为特征层的区分信息 这样，所有特征点的位置信息就各不相同了 \"\"\" # (bs, c, h, w) =\u003e (bs, h * w, c) pos_embed = pos_embed.flatten(2).transpose(1, 2) # (bs, h*w, c) + (1, 1, 256)\\ # note that c = 256 here lvl_pos_embed = pos_embed + self.level_embed[lvl].view(1, 1, -1) lvl_pos_embed_flatten.append(lvl_pos_embed) src_flatten.append(src) mask_flatten.append(mask) # (bs, h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 + ..., c) src_flatten = torch.cat(src_flatten, 1) # (bs, h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 + ...) mask_flatten = torch.cat(mask_flatten, 1) # (bs, h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 + ..., c) lvl_pos_embed_flatten = torch.cat(lvl_pos_embed_flatten, 1) # (n_lvl,2) spatial_shapes = torch.as_tensor(spatial_shapes, dtype=torch.long, device=src_flatten.device) # .prod(dim=1)是将dim1的各个元素相乘，在这里就会得到各特征层点数量: h * w # .cumsum(0)代表在dim=0进行累加，在这里就会得到h_lvl1 * w_lvl1, h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2, ... # 因此这里得到的level_start_index是各特征层起始的index(这个索引对应到被flatten的维度) # (n_lvl,) level_start_index = torch.cat((spatial_shapes.new_zeros((1, )), spatial_shapes.prod(1).cumsum(0)[:-1])) # (bs, n_lvl, 2) 各特征层中非padding部分的边长(高\u0026宽)占特征图边长的比例 valid_ratios = torch.stack([self.get_valid_ratio(m) for m in masks], 1) # encoder memory = self.encoder(src_flatten, spatial_shapes, level_start_index, valid_ratios, lvl_pos_embed_flatten, mask_flatten) 2). Encoder编码特征 源码对应上图最后一句。 encoder部分，输出memory(编码后的特征表示)，shape是 (bs, h_lvl1w_lvl1+h_lvl2w_lvl2+.., c=256)，其中h_lvli和w_lvli分别代表第i层特征图的高和宽，于是第二个维度就是所有特征点的数量。编码后，特征的最后一个维度(hidden_dim)为256。 3). 处理Encoder的输出，为Decoder的输入做准备 这一步主要是得到参考点(reference points)。需要说明下，在2-stage模式下，参考点和输入到Decoder的object query及query embedding的生成方式和形式会有所不同: –如果是2-stage模式，那么参考点就是由Encoder预测的top-k得分最高的proposal boxes(注意，这时参考点是4d的，是bbox形式)。然后通过对参考点进行位置嵌入(position embedding)来生成Decoder的object query(target) 和对应的 query embedding； –否则，Decoder的 object query(target )和 query embedding 就是预设的embedding，然后将query embedding经过全连接层输出2d参考点，这时的参考点是归一化的中心坐标形式。 另外，两种情况下生成的参考点数量可能不同: 2-stage时是有top-k(作者设置为300)个，而1-stage时是num_queries(作者也设置为300)个，也就是和object query的数量一致(可以理解为，此时参考点就是object query本身的位置)。 # prepare input for decoder # c = 256 中间那一维等于(所有层)特征点的数量 bs, _, c = memory.shape # 根据是否2-stage分情况进行处理，因为生成的reference points不同 if self.two_stage: # 生成proposals， 并且对Encoder的输出(memory)进行处理(全连接层 + 归一化) #(bs, h_lvl1","date":"2023-10-27","objectID":"/posts/deformabledetr/:5:3","tags":["draft"],"title":"Deformable DETR论文精读+代码详解","uri":"/posts/deformabledetr/"},{"categories":["ObjectDetection"],"content":"4.4、Encoder 这里的Encoder与Transformer中最主要的区别在于使用可变形注意力替代了原生的自注意力。类似地，在每层编码时会将上一层输出的编码特征作为下一层的输入，这个输入与position emebdding结合作为query、而经过线性变换则作为value。 def forward(self, src, spatial_shapes, level_start_index, valid_ratios, pos=None, padding_mask=None): # 这里的pos是position embedding + scale-level embedding output = src # 将各特征点在其所在特征层的归一化坐标映射到所有特征层，使得每个特征点在所有特征层上都会得到一个归一化的坐标 # 这个reference_points 相当于key的角色， 从而每个query都会和其在所有特征层的位置(也就是以下计算出来的坐标)进行交互 # 实现了跨尺度融合的效果，因此不需要FPN # (bs, H_lvl1 * W_lvl1 + H_lvl2 * W_lvl2 + ..., n_lvl, 2) reference_points = self.get_reference_points(spatial_shapes, valid_ratios, device=src.device) for _, layer in enumerate(self.layers): output = layer(output, pos, reference_points, spatial_shapes, level_start_index, padding_mask) return output 现在具体来看看主要有哪些过程: i). 计算参考点的位置 这里的参考点实质就是多尺度特征点的归一化坐标。注意，每个特征点在所有特征层都会计算出一个对应的归一化坐标(后文会谈到为何这样做)。 def get_reference_points(spatial_shapes, valid_ratios, device): reference_points_list = [] for lvl, (H_, W_) in enumerate(spatial_shapes): # (H_, W_), (H_, W_) # 0.5 是为对应到特征点中心 ref_y, ref_x = torch.meshgrid(torch.linspace(0.5, H_ - 0.5, H_, dtype=torch.float32, device=device), torch.linspace(0.5, W_ - 0.5, W_, dtype=torch.float32, device=device)) \"\"\"将各层特征图每个特征点中心坐标根据特征图非padding的边长进行归一化(可能大于1)\"\"\" # (1, H_*W_) / (bs, 1) 后一项是特征图有效(非padding)部分的高 ref_y = ref_y.reshape(-1)[None] / (valid_ratios[:, None, lvl, 1] * H_) # (1, H_*W_) / (bs, 1) 后一项是特征图有效(非padding)部分的宽 ref_x = ref_x.reshape(-1)[None] / (valid_ratios[:, None, lvl, 0] * W_) # (bs, H_*W_, 2) 每一项是xy ref = torch.stack((ref_x, ref_y), -1) reference_points_list.append(ref) # (bs, H_lvl1 * W_lvl1 + H_lvl2 * W_lvl2 + ..., 2) reference_points = torch.cat(reference_points_list, 1) \"\"\"将各特征点在其所在特征层的归一化坐标映射(扩散)到所有特征层， 这样每个特征点在所有特征层上都会得到一个归一化坐标\"\"\" # TODO: 以下这样貌似不妥， 如果各特征层对应的valid_ratio不一致， # TODO: 则坐标值有可能大于1， 而后续没有再对这里的reference_points进行归一化到 0~1 # (bs, H_lvl1 * W_lvl1 + H_lvl2 * W_lvl2 + ..., 1, 2) * (bs, 1, n_lvl, 2) reference_points = reference_points[:, :, None] * valid_ratios[:, None] # (bs, H_lvl1 * W_lvl1 + H_lvl2 * W_lvl2 + ..., n_lvl, 2) return reference_points 通过源码发现有个小问题: 这里在对坐标归一化时使用的是非padding部分的特征图边长，而不同层非padding部分的边长比例有可能由于计算时的舍入误差而不一致，从而导致最终归一化后的坐标值大于1。 ii). self-attention 使用(多尺度)可变形注意力模块替代原生的Transformer自注意力，query和value均来自特征图，只不过query要结合position embedding，注意，这里的position embedding实质是position emebedding + scale-level emebedding。 iii). feed-forward network 前向反馈网络，和Transformer中的一致: 由全连接层、激活函数、Dropout、残差连接以及层归一化(LayerNorm)组成。 def forward(self, src, pos, reference_points, spatial_shapes, level_start_index, padding_mask=None): \"\"\"Deformable DETR的Encoder也是由self-attention + FNN组成 只不过这里self-attention使用Multi-Scale Deformable Attention， 并且位置编码加入了scale-level embedding \"\"\" # self attention # 这里的pos是position embedding + scale-level embedding # padding_mask 就是指示各特征图哪些位置是原图padding的 # reference_points 就是每个特征点本身中心的位置(归一化坐标): (bs, H_lvl1 * W_lvl1 + H_lvl2 * W_lvl2 + ..., n_lvl, 2) # 注意一个特征点不仅在其所有特征层有个坐标， 而且还在其他特征层也都分别映射了一个坐标 # self attention src2 = self.self_attn(self.with_pos_embed(src, pos), reference_points, src, spatial_shapes, level_start_index, padding_mask) src = src + self.dropout1(src2) src = self.norm1(src) # ffn src = self.forward_ffn(src) return src DECODER详细代码注释如下，iterative bounding box refinement和two stage改进方法的Encoder不变。 class DeformableTransformerEncoderLayer(nn.Module): def __init__(self, d_model=256, d_ffn=1024, dropout=0.1, activation=\"relu\", n_levels=4, n_heads=8, n_points=4): super().__init__() # self attention self.self_attn = MSDeformAttn(d_model, n_levels, n_heads, n_points) self.dropout1 = nn.Dropout(dropout) self.norm1 = nn.LayerNorm(d_model) # ffn self.linear1 = nn.Linear(d_model, d_ffn) self.activation = _get_activation_fn(activation) self.dropout2 = nn.Dropout(dropout) self.linear2 = nn.Linear(d_ffn, d_model) self.dropout3 = nn.Dropout(dropout) self.norm2 = nn.LayerNorm(d_model) @staticmethod def with_pos_embed(tensor, pos): return tensor if pos is None else tensor + pos def forward_ffn(self, src): src2 = self.linear2(self.","date":"2023-10-27","objectID":"/posts/deformabledetr/:5:4","tags":["draft"],"title":"Deformable DETR论文精读+代码详解","uri":"/posts/deformabledetr/"},{"categories":["ObjectDetection"],"content":"4.4、Decoder 这里与Transformer中主要的区别在于使用可变形注意力替代了原生的交叉注意力。类似地，每层的解码过程是self-attention+cross-attention+ffn，下一层输入的object query是上一层输出的解码特征。 # 每一层输入的output是上一层输出的结果，而reference_points_input在使用iterative bbox refine策略时， # 每层都会对齐进行校正， 因此下一层用到的也是上一层的输出结果 # (bs， n_query=300，hidden_dim=256) output = layer(output, query_pos, reference_points_input, src, src_spatial_shapes, src_level_start_index, src_padding_mask) 一起具体来看看每层的主要过程: i). 将参考点坐标映射(re-scales)到各尺度特征层 将每个参考点的坐标分别都乘以各特征层非padding部分边长的比例，使得一个参考点在所有尺度特征层上都有相应的归一化坐标值(后文会谈到为何这样做)。 def forward(self, tgt, reference_points, src, src_spatial_shapes, src_level_start_index, src_valid_ratios, query_pos=None, src_padding_mask=None): # 说明一下Decoder一开始得到的tgt, query_pos和reference_points, 分为两种情况: # 1. 2-stage 模式下，reference_points 是Encoder输出的top-k proposal boxes(并归一化)，最后一维为4 # 而tgt和query_pos由其经过position embedding得到； # 2. 1-stage 模式下， tgt和query_pos是预设的embedding， reference_points通过这个query_pos经全连接层得到， # 最后一维为2 # 另外，src是Encoder最终编码输出的特征图，即 memory output = tgt # 中间各层(包括头尾)的解码输出 intermediate = [] # 中间各层(包括头尾)校正的参考点 intermediate_reference_points = [] for lid, layer in enumerate(self.layers): # 2-stage 模式下， 参考点是proposal boxes， 因此最后一维是4 if reference_points.shape[-1] == 4: # (bs, k = 300, n_lvl, 4) # (bs, k = 300, 1, 4) * (bs, 1, n_lvl, 4) reference_points_input = reference_points[:, :, None] \\ * torch.cat([src_valid_ratios, src_valid_ratios], -1)[:, None] else: # 1-stage 模式下 参考点就是通过query embedding 变换而来的中心坐标形式，因此最后一维是2 assert reference_points.shape[-1] == 2 # (bs, k=300, n_lvl, 2) # (bs, k=300, 1, 2) * (bs, 1, n_lvl, 2) reference_points_input = reference_points[:, :, None] * src_valid_ratios[:, None] output = layer(output, query_pos, reference_points_input, src, src_spatial_shapes, src_level_start_index, src_padding_mask) # hack implementation for iterative bounding box refinement if self.bbox_embed is not None: tmp = self.bbox_embed[lid](output) if reference_points.shape[-1] == 4: new_reference_points = tmp + inverse_sigmoid(reference_points) new_reference_points = new_reference_points.sigmoid() else: assert reference_points.shape[-1] == 2 new_reference_points = tmp new_reference_points[..., :2] = tmp[..., :2] + inverse_sigmoid(reference_points) new_reference_points = new_reference_points.sigmoid() reference_points = new_reference_points.detach() if self.return_intermediate: intermediate.append(output) intermediate_reference_points.append(reference_points) if self.return_intermediate: return torch.stack(intermediate), torch.stack(intermediate_reference_points) return output, reference_points ii). self-attention 这一步是为了学习各个目标之间的关系，query和key都是object query+query embedding，value就是object query(注意不需要位置嵌入哦)。 def forward(self, tgt, query_pos, reference_points, src, src_spatial_shapes, level_start_index, src_padding_mask=None): # 若是2-stage， 则tgt 和 query_pos来自Encoder输出的top-k proposal boxes(经过位置嵌入) # 而reference_points 就是这个top-k proposal boxes(归一化) # 否则， tgt和query_pos由预设的embedding产生， 而reference_points由query_pos经过全连接层生成 # self attention # (bs, k = 300, d_model=256) q = k = self.with_pos_embed(tgt, query_pos) # (bs, k = 300, d_model=256) 注意: value就是target本身不需要， 不需要位置编码 tgt2 = self.self_attn(q.transpose(0, 1), k.transpose(0, 1), tgt.transpose(0, 1))[0].transpose(0, 1) tgt = tgt + self.dropout2(tgt2) tgt = self.norm2(tgt) iii). cross-attention 使用(多尺度)可变形注意力模块替代原生的Transformer交叉注意力，object query来自self-attention层的输出，同时也要加上query embedding；value由Encoder编码的特征经过线性变换得到。 # 上续 decoder的 decoder layer forward # cross attention # src是Encoder输出的memory， 即编码后的特征(bs, n_feat_points, d_model=256), 其会经过线性变换得到value, # 这里的tgt来自self-attention的输出，而query_pos依旧如刚传进来Decoder时一样，不变 # reference_points: (bs, k=300, n_feat_lvl, 4 or 2) 在cross-attention中代表key的位置信息 tgt2 = self.cross_attn(self.with_pos_embed(tgt, query_pos), reference_points, src, src_spatial_shapes, level_start_index, src_padding_mask) tgt = tgt + self.dropout1(tgt2) tgt = self.norm1(tgt) iv). feed-forward network 输入来自cross-attention的输出，详细过程就不再阐述了，都是老朋友了~ # ffn tgt = self.forward_ffn(tgt) return tg","date":"2023-10-27","objectID":"/posts/deformabledetr/:5:5","tags":["draft"],"title":"Deformable DETR论文精读+代码详解","uri":"/posts/deformabledetr/"},{"categories":["ObjectDetection"],"content":"4.5、Deformable Transformer 综合模块代码如下 class DeformableTransformer(nn.Module): def __init__(self, d_model=256, nhead=8, num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=1024, dropout=0.1, activation=\"relu\", return_intermediate_dec=False, num_feature_levels=4, dec_n_points=4, enc_n_points=4, two_stage=False, two_stage_num_proposals=300): super().__init__() self.d_model = d_model self.nhead = nhead self.two_stage = two_stage self.two_stage_num_proposals = two_stage_num_proposals encoder_layer = DeformableTransformerEncoderLayer(d_model, dim_feedforward, dropout, activation, num_feature_levels, nhead, enc_n_points) self.encoder = DeformableTransformerEncoder(encoder_layer, num_encoder_layers) decoder_layer = DeformableTransformerDecoderLayer(d_model, dim_feedforward, dropout, activation, num_feature_levels, nhead, dec_n_points) self.decoder = DeformableTransformerDecoder(decoder_layer, num_decoder_layers, return_intermediate_dec) self.level_embed = nn.Parameter(torch.Tensor(num_feature_levels, d_model)) if two_stage: self.enc_output = nn.Linear(d_model, d_model) self.enc_output_norm = nn.LayerNorm(d_model) self.pos_trans = nn.Linear(d_model * 2, d_model * 2) self.pos_trans_norm = nn.LayerNorm(d_model * 2) else: self.reference_points = nn.Linear(d_model, 2) self._reset_parameters() def _reset_parameters(self): for p in self.parameters(): if p.dim() \u003e 1: nn.init.xavier_uniform_(p) for m in self.modules(): if isinstance(m, MSDeformAttn): m._reset_parameters() if not self.two_stage: xavier_uniform_(self.reference_points.weight.data, gain=1.0) constant_(self.reference_points.bias.data, 0.) normal_(self.level_embed) def get_proposal_pos_embed(self, proposals): num_pos_feats = 128 temperature = 10000 scale = 2 * math.pi dim_t = torch.arange(num_pos_feats, dtype=torch.float32, device=proposals.device) dim_t = temperature ** (2 * (dim_t // 2) / num_pos_feats) # N, L, 4 proposals = proposals.sigmoid() * scale # N, L, 4, 128 pos = proposals[:, :, :, None] / dim_t # N, L, 4, 64, 2 pos = torch.stack((pos[:, :, :, 0::2].sin(), pos[:, :, :, 1::2].cos()), dim=4).flatten(2) return pos def gen_encoder_output_proposals(self, memory, memory_padding_mask, spatial_shapes): N_, S_, C_ = memory.shape base_scale = 4.0 proposals = [] _cur = 0 for lvl, (H_, W_) in enumerate(spatial_shapes): mask_flatten_ = memory_padding_mask[:, _cur:(_cur + H_ * W_)].view(N_, H_, W_, 1) valid_H = torch.sum(~mask_flatten_[:, :, 0, 0], 1) valid_W = torch.sum(~mask_flatten_[:, 0, :, 0], 1) grid_y, grid_x = torch.meshgrid(torch.linspace(0, H_ - 1, H_, dtype=torch.float32, device=memory.device), torch.linspace(0, W_ - 1, W_, dtype=torch.float32, device=memory.device)) grid = torch.cat([grid_x.unsqueeze(-1), grid_y.unsqueeze(-1)], -1) scale = torch.cat([valid_W.unsqueeze(-1), valid_H.unsqueeze(-1)], 1).view(N_, 1, 1, 2) grid = (grid.unsqueeze(0).expand(N_, -1, -1, -1) + 0.5) / scale wh = torch.ones_like(grid) * 0.05 * (2.0 ** lvl) proposal = torch.cat((grid, wh), -1).view(N_, -1, 4) proposals.append(proposal) _cur += (H_ * W_) output_proposals = torch.cat(proposals, 1) output_proposals_valid = ((output_proposals \u003e 0.01) \u0026 (output_proposals \u003c 0.99)).all(-1, keepdim=True) output_proposals = torch.log(output_proposals / (1 - output_proposals)) output_proposals = output_proposals.masked_fill(memory_padding_mask.unsqueeze(-1), float('inf')) output_proposals = output_proposals.masked_fill(~output_proposals_valid, float('inf')) output_memory = memory output_memory = output_memory.masked_fill(memory_padding_mask.unsqueeze(-1), float(0)) output_memory = output_memory.masked_fill(~output_proposals_valid, float(0)) output_memory = self.enc_output_norm(self.enc_output(output_memory)) return output_memory, output_proposals def get_valid_ratio(self, mask): _, H, W = mask.shape valid_H = torch.sum(~mask[:, :, 0], 1) valid_W = torch.sum(~mask[:, 0, :], 1) valid_ratio_h = valid_H.float() / H valid_ratio_w = valid_W.float() / W valid_ratio = torch.stack([valid_ratio_w, valid_ratio_h], -1","date":"2023-10-27","objectID":"/posts/deformabledetr/:5:6","tags":["draft"],"title":"Deformable DETR论文精读+代码详解","uri":"/posts/deformabledetr/"},{"categories":["ObjectDetection"],"content":"5、Experiment 由图4可知，Deformable DETR不仅收敛速率比DETR快并且小目标精度也高了许多。 ","date":"2023-10-27","objectID":"/posts/deformabledetr/:6:0","tags":["draft"],"title":"Deformable DETR论文精读+代码详解","uri":"/posts/deformabledetr/"},{"categories":["ObjectDetection"],"content":"6、改进策略 Deformable DETR是怎么让DCN和Transformer一起玩的，CW在上述已基本解析完毕。无奈作者还研究了“高配版”的Deformable DETR，涉及两个提升性能的策略: iterative bounding box refinement \u0026 two-stage。 a. Iterative Bounding Box Refinement 字面意思就是迭代地对bbox进行校正，类似于cascaded head，实质上也是coarse-to-fine不断校正的一个过程。第d层Decoder校正后归一化的bbox用公式表示如下: $$\\hat{b}q^d={\\sigma(\\Delta b{qx}^d+\\sigma^{-1}(\\hat{b}{qx}^{d-1})),\\sigma(\\Delta b{qy}^d+\\sigma^{-1}(\\hat{b}{qy}^{d-1})),\\sigma(\\Delta b{qw}^d+\\sigma^{-1}(\\hat{b}{qw}^{d-1})),\\sigma(\\Delta b{qh}^d+\\sigma^{-1}(\\hat{b}_{qh}^{d-1}))}$$ 其中 $\\Delta b_{q{x,y,w,h}}^d$ 是第d层Decoder利用检测头部的回归分支预测的结果(偏移量)，$\\sigma$，$\\sigma^{-1}$分别代表sigmoid和反sigmoid函数。 在这里需要注意两点: 各层的检测头部是不共享参数的； 校正后的bbox梯度会被阻断(detach)，不会跨层传播 具体实现和解析在上一节讲Decoder的时候已详细说明。 Two-Stage Deformable DETR 2-stage模式下，Encoder会输出一批proposals(并不是基于网络预测，而是像anchor一样计算出来的)，boxes中心就是各特征点的中心，而宽、高的设置则与所在的特征层相关，base值设置为0.05。这时的proposals相对于anchors的角色。 然后，使用检测头部的分类分支对Encoder编码的特征(memory)进行预测，对应各个proposals的分类结果；同时使用回归分支也对编码特征也进行预测，得到相对于proposals(xywh)的偏移量，接着将偏移量加在proposals的中心坐标和宽、高上得到第一阶段预测的proposals。 最后，取top-k分数最高的那批预测proposals作为Decoder的参考点。并且，Decoder的object query和query embedding都由参考点通过位置嵌入(position embedding)来生成。 ","date":"2023-10-27","objectID":"/posts/deformabledetr/:7:0","tags":["draft"],"title":"Deformable DETR论文精读+代码详解","uri":"/posts/deformabledetr/"},{"categories":["ObjectDetection"],"content":"7、Conclusion Deformable DETR效率高并且收敛快，核心是Multi-Scale Deformable Attention Module。解决了DETR中收敛慢以及小目标性能低的问题。 ","date":"2023-10-27","objectID":"/posts/deformabledetr/:8:0","tags":["draft"],"title":"Deformable DETR论文精读+代码详解","uri":"/posts/deformabledetr/"},{"categories":["ObjectDetection"],"content":"8、Q\u0026A 如果认真思考，会发现Deformable DETR中有许多值得考量的地方。 1. 为何不需要FPN也能达到跨层融合的效果？ 作者在paper中说到，多尺度可变形注意力可以在不同尺度的特征之间交换信息，因此不需要FPN: Note that the top-down structure in FPN (Lin et al., 2017a) is not used, because our proposed multi-scale deformable attention in itself can exchange information among multi-scale feature maps. 那么到底是为何？具体是怎么做到的呢？ 其实前文也提到了，每个参考点在各尺度特征层都会进行采样。而且在上述处理参考点坐标的过程中，我们也可以看到，无论在Encoder还是Decoder，都会对参考点进行处理，使得一个参考点在所有尺度特征层上都有相应的归一化坐标值。为什么这样做呢？这样做其实就是为了计算出每个参考点在各尺度特征层对应的采样点位置。 那么你可能又会奇怪了，一个参考点明明是只处于某个特定的特征层，怎么能够把它放到另一个特征层去呢？这样合理吗？ 合理不合理由网络去进行学习，基于最终的匹配效果来证明。但是可不可行我们倒是可分析的，可以这么看: 我们知道，由于特征图是经过原图下采样得到，因此一个像素点无论是处于原图还是各层特征图中，其坐标的归一化值应该是一致的(忽略细微的计算误差)。那么，既然这里参考点坐标是归一化的，它就能够映射(re-scales)到各尺度特征中去，这部分对应以下公式中的 $\\phi_l$ 函数: $$\\text{MSDeformAttn}(z_{q},\\hat{p}{q},{x^{l}}{l=1}^{L})=\\sum_{m=1}^{M}W_{m}\\bigl[\\sum_{l=1}^{L}\\sum_{k=1}^{K}A_{mlqk}\\cdot W_{m}^{\\prime}x^{l}\\bigl[\\phi_{l}(\\hat{p}{q})\\bigr]+\\Delta p{mlqk}\\bigr)\\bigr],$$ 作者在paper中是这么描述的: Function $\\phi_l$ re-scales the normalized coordinates $\\hat{p}_{q}$ to the input feature map of the l-th level. 2. 为何注意力权重可由query直接通过全连接层预测得到？ 我们知道，在Transformer中，注意力权重是由query和key交互计算得到的。然而，在这里却像开挂般直接通过query经全连接层输出得到(好家伙~！)，这节奏是不是不对劲呢？要分析这个问题，不妨先来看看Deformable DETR中参考点(reference points)和query之间的关系。 在Encoder中: 参考点是特征点本身的位置，query embedding是特征图对应的position emebdding(其实还加上了scale-level embedding)，object query则来自于特征图，最终注意力机制中的query就是object query + query embedding。 在Decoder中: 2-stage时，由参考点经过位置嵌入生成query embedding和object query；而1-stage时，object query和query embedding都是预设的embedding，参考点则由query embedding经全连接层生成，最终注意力机制中的query也是object query + query embedding。 综上可知，参考点(reference points)和query之间是存在着对应关系的(就有点“你生我、我生你”的feel~)。 OK，既然这样，那么基于参考点位置采样插值出来的特征(value)自然就能够和通过query经过线性变换得到的注意力权重对应起来了，这就是为什么可变形注意力模块中不需要key与query来交互计算注意力权重了。 打个比方: A与B已建立起了对应关系，之后A再通过某种映射关系得到C，B也通过某种映射关系得到D，那么C与D之间必然会有某种程度的耦合与对应关系。这里A、B、C、D就分别指代query、reference points、attention weights以及value。 还有个问题值得思考，为何在Decoder中，2-stage时由reference points生成query embedding是通过position embedding，而1-stage时由query embedding生成reference points时却用全连接层呢？ 对此，CW是这么想的: 2-stage时，参考点是由Encoder预测出来的proposals，本身一定程度上代表着物体的位置信息了(虽然这个位置可能并不精确)，因此有必要用位置嵌入将这“宝贵\"的信息给记录下来；而1-stage时，预设的query embedding本身就是一个抽象体，盲猜的东西，因此用线性变换来做维度映射得到参考点比较合理，因为毕竟其本身并没有实际意义的位置信息。 3. 为何检测头部的回归分支预测的是偏移量而非绝对坐标值？ 这个问题估计很多人会提出，为何这里不像DETR一样直接预测bbox的坐标而是预测偏移量呢？ 请你想想，Deformable DETR相比于DETR多了一个很显眼的东西是什么？是参考点 (reference points) 啊！(感觉通篇它都在秀存在感..) 采样点的位置是基于参考点和对应的坐标偏移量计算出来的，也就是说采样特征是分布在参考点附近的，既然这里需要由采样特征回归出bbox的位置，那么预测相对于参考点的偏移量就会比直接预测绝对坐标更易优化，更有利于模型学习。 Because the multi-scale deformable attention module extracts image features around the reference point, we let the detection head predict the bounding box as relative offsets w.r.t. the reference point to further reduce the optimization difficulty. 另外，由于采样特征中注入了注意力，而预测框是基于采样特征回归得到的，loss是基于回归结果计算的，梯度是通过loss反向传播的，因此最终学习到的注意力权重就会和预测框有相对较强的联系，这也起到了加速收敛的效果。 In this way, the learned decoder attention will have strong correlation with the predicted bounding boxes, which also accelerates the training convergence. ","date":"2023-10-27","objectID":"/posts/deformabledetr/:9:0","tags":["draft"],"title":"Deformable DETR论文精读+代码详解","uri":"/posts/deformabledetr/"},{"categories":["ObjectDetection"],"content":"9、与其它方法比较 Deformable DETR是在DETR基础上提出的，因此，在这最后一部分CW打算将其与DETR作个比较；另外，CW觉得其与Sparse R-CNN也有值得比较的地方，之前CW也写过一篇文章(目前还在简书，后续会同步到知乎这边来)分析过说Sparse R-CNN像是DETR的小弟哈哈哈。 以下列出的点都是仅出现在 Deformable DETR 中而在 DETR / Sparse R-CNN 中是没有的。 i). vs DETR 多尺度特征； 新增scale-level embedding，用于区分不同特征层(由于第1点)； 使用了多尺度可变形注意力替代Encoder中的自注意力和Decoder中的交叉注意力； 引入了参考点，某种程度上起到先验的作用； 为自己开发了“高配”版: 迭代的框校正策略 和 两阶段模式； 检测头部的回归分支预测的是bbox偏移量而非绝对坐标值 ii). vs Sparse R-CNN 没有使用FPN； 使用了位置嵌入； 2-stage时，proposals是predicted的(而非Sparse R-CNN直接使用learnable embedding)； 使用了Transformer； 注意力机制是one-to-many iteraction(Sparse R-CNN由于‘Sparse’偶像包袱太重，是彻底的sparse，是one-to-one实例级别的交互)； 检测头部的回归分支预测的是bbox偏移量而非绝对坐标值 最后: DETR收敛慢和小目标检测效果差的原因在于Transformer的注意力计算模块——它对全局密集的关系进行建模，这使得模型需要长时间去学习(关注)真正有意义的稀疏位置，同时还带来了高复杂度的计算与空间资源消耗。 联想到稀疏空间位置的学习是DCN的强项，但其又缺乏关系建模能力，于是作者机智地将DCN与Transformer结合在一起，最终提出 Deformable DETR。 ref: [1]. https://zhuanlan.zhihu.com/p/372116181 [2]. https://blog.csdn.net/qq_38253797/article/details/127668593 [3]. https://zhuanlan.zhihu.com/p/596303361 ","date":"2023-10-27","objectID":"/posts/deformabledetr/:10:0","tags":["draft"],"title":"Deformable DETR论文精读+代码详解","uri":"/posts/deformabledetr/"},{"categories":["C++"],"content":"Effective Modern C++ 笔记 ","date":"2023-10-12","objectID":"/posts/effective_modern_c/:1:0","tags":["Effective Modern C++"],"title":"Effective Modern C++ 阅读笔记","uri":"/posts/effective_modern_c/"},{"categories":["C++"],"content":"CH01 Deducing Types Item 1: Understand template type deduction. 大部分简单场景下，我们根据模板调用可能一眼就能推导出来模板类型。但是，对于一些复杂场景，模板类型就没那么明显了，这就需要遵循一些基本原则。 template\u003ctypename T\u003e void f(ParamType param); //..... f(expr); // call f with some expression 考虑以上代码片段，编译器在编译阶段根据调用点 expr 来推导出 T 和 ParamType 的类型。这其中 T 的推导不仅依赖 expr 的类型，也依赖 ParamType 的形式，有3种场景： ParamType 是引用或者指针类型，但不是万能引用。 ParamType 是万能引用。 ParamType 不是引用也不是指针。 Case 1: ParamType is a Reference or Pointer, but not a Universal Reference 对于 ParamType 是引用或者指针类型，但不是万能引用的场景，类型推导方式如下： 如果 expr 是一个引用，忽略其引用部分。 然后对 expr 的类型和 ParamType 进行模式匹配来决定 T。 考虑下面的例子： template\u003ctypename T\u003e void f(T\u0026 param); // param is a reference 我们的变量申明如下： int x = 27; // x is an int const int cx = x; // cx is a const int const int\u0026 rx = x; // rx is a reference to x as a const int 调用点和推导结果如下： f(x); // T is int, param's type is int\u0026 // param's type is int\u0026 f(cx); // T is const int, // param's type is const int\u0026 f(rx); // T is const int, // param's type is const int\u0026 第一个调用，函数调用非常简单，我们很快能得到 T 是 int，param类型是 int\u0026。 第二个调用，cx 是 const int 类型，因此 T 被推导成 const int，param 的类型是 const int\u0026。当我们传一个 const 对象给函数的一个引用类型参数，我们期望这个const 对象不能被修改，因此 param 被推导成常量引用（reference-to-const）。这就是为什么传递一个 const 对象给 T\u0026 模板类型是安全的原因：对象的 constness 属性被推导成了 T 的一部分。 第三个调用，虽然 rx 的类型是一个引用，类型推导过程中将忽略 rx 的引用类型，T 被推导成一个非引用类型，即 const int，param 的类型是 const int\u0026。 如果我们将 param 类型改成 const T\u0026，情况略为有点不同，因为 param 的类型已经是常量引用（reference-to-const），不需要将 const 推导成 T 的一部分，如下： template\u003ctypename T\u003e void f(const T\u0026 param); // param is now a ref-to-const int x = 27; // as before const int cx = x; // as before const int\u0026 rx = x; // as before f(x); // T is int, param's type is const int\u0026 f(cx); // T is int, param's type is const int\u0026 f(rx); // T is int, param's type is const int\u0026 如果 param 是一个指针（或者是指向常量的指针），推导方式其是引用是一样的，如下： template\u003ctypename T\u003e void f(T* param); // param is now a pointer int x = 27; // as before const int *px = \u0026x; // px is a ptr to x as a const int f(\u0026x); // T is int, param's type is int* f(px); // T is const int, // param's type is const int* Case1 场景的模板类型推导和我们设想的应该差不多，还是比较简单的。 Case 2: ParamType is a Universal Reference 模板类型参数是万能引用时，模板类型推导就没有那么明显了，详细介绍将会在 Item24 中展开，这里直接给出处理方式： 如果 expr 是一个左值（lvalue），T 和 ParamType 都被推导成左值的引用。这是非常不寻常的。第一，这是唯一一个在模板类型推导中将 T 推导成一个引用的情况。第二，虽然 ParamType 被申明成语法上的一个右值（rvalue）引用，但它的推导类型却是一个左值引用。 如果 expr 是一个右值，和正常的规则一样（比如Case1的推导方式）。 例如： template\u003ctypename T\u003e void f(T\u0026\u0026 param); // param is now a universal reference int x = 27; const int cx = x; const int\u0026 rx = x; f(x); // x is lvalue, so T is int\u0026, // param's type is also int\u0026 f(cx); // cx is lvalue, so T is const int\u0026, // param's type is also const int\u0026 f(rx); // rx is lvalue, so T is const int\u0026, // param's type is also const int\u0026 f(27); // 27 is rvalue, so T is int, // param's type is therefore int\u0026\u0026 我们将在 Item24 中解释这样推导的原因。 Case 3: ParamType is Neither a Pointer nor a Reference 当 ParamType 不是引用也不是指针，则是通过值传递的方式处理： template\u003ctypename T\u003e void f(T param); // param is now passed by value 这意味着不管传递进来的是啥，param 是实参的拷贝，它将是一个新的对象。推导方式如下： 和之前一样，如果 expr 的类型是一个引用，忽略其引用部分。 在忽略 expr 的引用部分之后，如果 expr 是一个 const，也忽略它。如果 expr 是 volatile 的，也同样忽略。 因此： template\u003ctypename T\u003e void f(T param); // param is now passed by value int x = 27; const int cx = x; const int\u0026 rx = x; f(x); // T's and param's types are both int f(cx); // T's and param's types are again both int f(rx); // T's and param's types are still both int 注意到，虽然 cx 和 rx 是 const 类型，param 也不是 const 的。这是可以理解的，param 是一个新的对象， 独立于 cx 和 rx —— 是 cx 和 rx 的一个拷贝。param 的修改不会影响到 cx 和 rx，这就是为什么在类型推导时 expr 的 constness（以及 volatileness 等）被忽略的原因：因为 expr 不能被修改并不意味着它的拷贝不能。 对于值传递的参数模板，const 和 volatile 是被忽略的，但是对于引用类型或者常量引用类型参数的模板，expr 的 const 在类型推导时被保留下来了。考虑 expr 是一个指向常量的常量指针，通过值传递的参数类型： template\u003ctypename T\u003e void f(T param); // param is still passed by value const char* const ptr = \"Fun with pointers\"; // ptr is const pointer to const object f(ptr); // pass arg of type const char * const 这里，ptr 是常量，ptr 指向的字符串也是常量。当 ptr 传递给 f，组成指针的比特位被拷贝给 param，也就是说指针自己（ptr）是值传递，根据值传递参数模板类型推导规则，ptr 的 constness 将被忽略，param 的类","date":"2023-10-12","objectID":"/posts/effective_modern_c/:1:1","tags":["Effective Modern C++"],"title":"Effective Modern C++ 阅读笔记","uri":"/posts/effective_modern_c/"},{"categories":["C++"],"content":"CH02: auto Item 5: Prefer auto to explicit type declarations. C++ 显式声明可能会产生例如变量未初始化、申明类型冗长、无法形成闭包、截断等问题，通过使用 auto 可以很好解决这些问题。 避免变量未初始化 int x1; // potentially uninitialized auto x2; // error! initializer required auto x3 = 0; // fine, x's value is well-defined x1 未初始化，其值可能是未定义的，这导致程序中可能隐藏着 bug。使用 auto 声明的变量未初始化将导致编译报错。 简化变量申明 考虑下面的代码，通过解引用迭代器初始化局部变量： template\u003ctypename It\u003e // algorithm to dwim (\"do what I mean\") void dwim(It b, It e) // for all elements in range from { // b to e while (b != e) { typename std::iterator_traits\u003cIt\u003e::value_type currValue = *b; … } } 使用 auto 简化上述代码： template\u003ctypename It\u003e // as before void dwim(It b, It e) { while (b != e) { auto currValue = *b; … } } 申明闭包类型 在 Item 2 中介绍过 auto 可以通过类型推到得到实际的类型，考虑下面的代码片段： auto derefUPLess = // comparison func. [](const std::unique_ptr\u003cWidget\u003e\u0026 p1, // for Widgets const std::unique_ptr\u003cWidget\u003e\u0026 p2) // pointed to by { return *p1 \u003c *p2; }; // std::unique_ptrs C++14 lambda 函数参数也可以使用 auto，代码简化如下： auto derefLess = // C++14 comparison [](const auto\u0026 p1, // function for const auto\u0026 p2) // values pointed { return *p1 \u003c *p2; }; // to by anything // pointer-like 使用 auto 的 derefLess 是一个闭包类型。也可以使用 std::function 得到闭包类型： std::function\u003cbool(const std::unique_ptr\u003cWidgey\u003e\u0026, const std::unique_ptr\u003cWidget\u003e\u0026)\u003e derefLess = [] (const std::unique_ptr\u003cWidget\u003e\u0026 p1, const std::unique_ptr\u003cWidget\u003e\u0026 p2) { return *p1 \u003c *p2; }; auto 申明的持有闭包的变量和闭包有相同的类型，并且仅使用闭包需要的内存大小。而 std::function 声明持有闭包的变量有一个固定大小内存，一旦内存大小不足，则需要申请堆内存来存储闭包。因此，std::function 申明的对象要比 auto 申明的对象占更多的内存，由于约束内嵌的使用和提供间接函数的调用，通过 std::function 对象来调用一个封装体比通过 auto 对象要慢。也就是说，std::function 方法通常体积比 auto 大且慢，还有可能导致内存不足的异常。 避免类型截断 auto 还有一个避免内存截断的优点，考虑下面的代码片段： std::vector\u003cint\u003e v; … unsigned sz = v.size(); v.size() 返回类型是 std::vector::size_type ，一个无符号整数类型，很多程序员可能会写出上面的代码。std::vector::size_type 在 32 位机器上是 4个字节，但在 64 位机器上则为 8 字节，但是 unsigned 固定为 4 字节。上面的代码在 32 位机器上运行没有什么问题，但移植到 64 位机器上则会导致类型截断的问题。 避免类型不匹配 auto 还具有一个非常隐蔽的效果，看下面的代码： std::unordered_map\u003cstd::string, int\u003e m; ... for (std::pair\u003cstd::string, int\u003e\u0026 p : m) { ... // do something with p } 看上去没有什么问题？我们很有可能写出以上的迭代代码，但是 unordered_map 的 key 是 const的，即 hash map 中 std::pair 的类型是 std::pair\u003cconst std::string, int\u003e。下面的代码将产生编译报错： #include \u003cunordered_map\u003e #include \u003ciostream\u003e int main() { int p; std::unordered_map\u003cstd::string,int\u003e m; m[\"key\"] = 10; for(std::pair\u003cstd::string,int\u003e\u0026p : m) { p.second = 2; } return 0; } // 编译报错 main.cpp:8:38: error: invalid initialization of reference of type 'std::pair\u003cstd::__cxx11::basic_string\u003cchar\u003e, int\u003e\u0026' from expression of type 'std::pair\u003cconst std::__cxx11::basic_string\u003cchar\u003e, int\u003e' 8 | for(std::pair\u003cstd::string,int\u003e\u0026p : m) { 不知道这个隐蔽的背景知识的情况下，使用 auto 替代则会避免上述问题： for (auto\u0026 p : m) { … // as before } 上面介绍了几条使用 auto 的优势， 使用 auto 也有 Item 2 和 Item 6 介绍的使用陷阱，但是可以通过 Item 4 介绍的一些方法可视化其类型推导结果，auto 还是非常值得使用的。 总结 auto 变量必须初始化，不受类型不匹配导致移植和效率问题。 auto 类型也受 Item2 和 Item6 中介绍的陷阱困扰。 Item 6: Use the explicitly typed initializer idiom when auto deduces undesired types. 在 Item 5 中介绍了使用 auto 申明类型的优势，也在 Item 2 介绍了 auto 类型推导的方式和 auto 类型推导有时候并非如我们所愿的情况，本文继续分析使用 auto 存在的问题。 看下面的例子，函数 features 入参为 Widget 类型，返回一个 std::vector，每一个 bool 代表 Widget 是否提供一个特殊的特性： std::vector\u003cbool\u003e features(const Widget\u0026 w); 假设 bit 5 代表是否有高优先级，可能编码如下： Widget w; … bool highPriority = features(w)[5]; // is w high priority? … processWidget(w, highPriority); // process w in accord // with its priority 如果修改 highPriority 显示申明为 auto ： auto highPriority = features(w)[5]; // is w high priority? 将导致 processWidget 出现不可预测的行为，这是为什么呢？对 vector 的 operator [] 操作，一般我们期望得到 T\u0026 类型。但是对于 vector 的 operator [] 操作，得到的是 std::vector::reference 类型，却不是 bool\u0026 类型。 为什么会有std::vector::reference 类型呢？主要是以下几个原因： 为了节省空间，使用 1 个 bit 代替 1 个字节的 bool 类型。 std::vector 的 operator [] 操作应该返回的是 T\u0026， 但标准库无法返对 bit 的引用。 为了得到接近 bool\u0026 的类型，std::vector::reference 对象能够使用在 bool\u0026 可以使用的场景。 由于以上几点，再看下这段代码： bool highPriority = features(w)[5]; // is w high priority? 这里，features 返回的是 std::vector 对象，然后施加 operator [] 操作得到 std::vector::reference 对象， 最后被隐式转化为 bool 类型来初始化 highPriority，highPriority ","date":"2023-10-12","objectID":"/posts/effective_modern_c/:1:2","tags":["Effective Modern C++"],"title":"Effective Modern C++ 阅读笔记","uri":"/posts/effective_modern_c/"},{"categories":["C++"],"content":"CH03: Moving to Modern C++ Item 7: Distinguish between () and {} when creating objects. 初始化方式 C++11开始变量初始化方式有以下几种： int x(0); // initializer is in parentheses int y = 0; // initializer follows \"=\" int z{ 0 }; // initializer is in braces int z = { 0 }; // initializer uses \"=\" and braces 其中第四种使用等号和花括号方式初始化变量通常认为和第三种花括号的方式相同。使用等号进行初始化可能会被认为是赋值操作，对于内置类型（比如 int），可以忽略它们的区别，但对于用户自定义类型，则需要区别： Widget w1; // call default constructor Widget w2 = w1; // not an assignment; calls copy ctor w1 = w2; // an assignment; calls copy operator= 使用 {} 初始化被称为统一初始化（uniform initialization），期望能够统一应用在所有初始化场景（实际上也有缺陷，后文将介绍）。 () 和 = 初始化方式的限制 圆括号不能用于非静态成员变量的默认初始化： class Widget { ... private: int x{ 0 }; // fine, x's default value is 0 int y = 0; // also fine int z(0); // error! }; // 编译报错信息 main.cpp:10:11: error: expected identifier before numeric constant 10 | int z(0); // error! 成员变量 z 的初始化将会导致编译报错。 另外，C++中不能拷贝的对象则不能使用等号初始化： std::atomic\u003cint\u003e ai1{ 0 }; std::atomic\u003cint\u003e ai2(0); // fine std::atomic\u003cint\u003e ai3 = 0; // error! // 编译报错信息 main.cpp:5:24: error: use of deleted function ‘std::atomic\u003cint\u003e::atomic(const std::atomic\u003cint\u003e\u0026)’ std::atomic\u003cint\u003e a = 0; ^ = 和 () 初始化都有使用的限制，可能就是 {} 初始化被称为统一初始化的原因吧。 {} 初始化的优势 统一初始化可以避免隐式窄化转换（narrowing conversions）： double x, y, z; int sum1{ x + y + z }; // error! sum of doubles may not be expressible as int int sum2(x + y + z); // okay (value of expression truncated to an int) int sum3 = x + y + z; // ditto 统一初始化另外一个好处是避免了 C++ 复杂的语法分析（most vexing parse）： Widget w2(); // most vexing parse! declares a function named w2 that returns a Widget! Widget w1(10); // call Widget ctor with argument 10 Widget w3{}; // calls Widget ctor with no args 第一个例子的问题可以戳 C++‘s most vexing parse 了解更多。 {}初始化的不足 除了 Item 2 介绍的 auto 变量类型声明使用统一初始化时候类型被推导成 std::initializer_list 的特点外，还存在统一初始化和其他初始化行为不一致的情况。 在没有 std::initializer_list 参数类型的构造函数时： class Widget { public: Widget(int i, bool b); // ctors not declaring Widget(int i, double d); // std::initializer_list params ... }; Widget w1(10, true); // calls first ctor Widget w2{10, true}; // also calls first ctor Widget w3(10, 5.0); // calls second ctor Widget w4{10, 5.0}; // also calls second ctor 在增加一个std::initializer_list 参数类型的构造函数时： class Widget { public: Widget(int i, bool b); // as before Widget(int i, double d); // as before Widget(std::initializer_list\u003clong double\u003e il); // added ... }; Widget w1(10, true); // uses parens and, as before, // calls first ctor Widget w2{10, true}; // uses braces, but now calls // std::initializer_list ctor // (10 and true convert to long double) Widget w3(10, 5.0); // uses parens and, as before, // calls second ctor Widget w4{10, 5.0}; // uses braces, but now calls // std::initializer_list ctor // (10 and 5.0 convert to long double) 这里，w2 和 w4 将会使用新增的构造函数（第3个构造函数）。但是很明显， non-std::initializer_list 参数类型构造函数比std::initializer_list 参数类型构造函数更加匹配。 更有甚者，拷贝和移动构造函数也能被 std::initializer_list 构造函数绑架： class Widget { public: Widget(int i, bool b); // as before Widget(int i, double d); // as before Widget(std::initializer_list\u003clong double\u003e il); // as before operator float() const; // convert to float ... }; Widget w5(w4); // uses parens, calls copy ctor Widget w6{w4}; // uses braces, calls std::initializer_list ctor // (w4 converts to float, and float converts to long double) Widget w7(std::move(w4)); // uses parens, calls move ctor Widget w8{std::move(w4)}; // uses braces, calls std::initializer_list ctor // (for same reason as w6) 编译器匹配 std::initializer_list 构造函数的决心很强，甚至导致编译报错，也没有匹配到普通的构造函数： class Widget { public: Widget(int i, bool b); // as before Widget(int i, double d); // as before Widget(std::initializer_list\u003cbool\u003e il); // element type is now bool ... // no implicit conversion funcs }; Widget w{10, 5.0}; // error! requires narrowing conversions 这里，编译器直接忽略前两个构造函数，试图匹配 std::initializer_list 构造函数，但是需要将 int (10) 和 double (5.0) 转换为 bool 类型，这是窄化转化，将会失败（前面有解释），这里就导致错误。 只有花括号中参数无法转换为 std::initializer_list 中类型时，编译器才匹配普通函数： class Widget { public: Widget(int i, bool b); // as before Widget(int ","date":"2023-10-12","objectID":"/posts/effective_modern_c/:1:3","tags":["Effective Modern C++"],"title":"Effective Modern C++ 阅读笔记","uri":"/posts/effective_modern_c/"},{"categories":["C++"],"content":"CH04: Smart Pointers Item 18: Use std::unique_ptr for exclusive-ownership resource management. 原始指针非常灵活，但是使用陷阱多，容易出错，智能指针则更容易使用。本文介绍的智能指针是 std::unique_ptr。 独占所有权 std::unique_ptr 表现出独占所有权的语义。一个非空的 std::unique_ptr 总是对它指向的资源拥有独占所有权，它不共享它指向的资源给其他指针。因此，无法通过值传递 std::unique_ptr 给函数，也不允许复制 std::unique_ptr。看下面的例子，注意 std::make_unique 在 C++14 才开始支持，从报错信息也可以看到拷贝构造函数是 delete 的。 #include\u003ciostream\u003e #include\u003cmemory\u003e int main() { std::unique_ptr\u003cint\u003e pInt(new int(5)); // std::unique_ptr\u003cint\u003e pInt = std::make_unique\u003cint\u003e(5); // C++14 才支持 std::unique_ptr\u003cint\u003e pInt1(pInt); // 报错 } // 报错信息： main.cpp: In function 'int main()': main.cpp:8:36: error: use of deleted function 'std::unique_ptr\u003c_Tp, _Dp\u003e::unique_ptr(const std::unique_ptr\u003c_Tp, _Dp\u003e\u0026) [with _Tp = int; _Dp = std::default_delete\u003cint\u003e]' 8 | std::unique_ptr\u003cint\u003e pInt1(pInt); // 报错 | ^ In file included from /usr/local/include/c++/11.2.0/memory:76, from main.cpp:2: /usr/local/include/c++/11.2.0/bits/unique_ptr.h:468:7: note: declared here 468 | unique_ptr(const unique_ptr\u0026) = delete; | std::unique_ptr 是 move-only 类型，可以 move 它的控制权，原 std::unique_ptr 则变为空指针。看下面的例子： #include\u003ciostream\u003e #include\u003cmemory\u003e int main() { std::unique_ptr\u003cint\u003e pInt(new int(5)); std::unique_ptr\u003cint\u003e pInt2 = std::move(pInt); // 转移所有权 // std::cout \u003c\u003c *pInt \u003c\u003c std::endl; // Segmentation fault (core dumped) ./a.out std::cout \u003c\u003c *pInt2 \u003c\u003c std::endl; std::unique_ptr\u003cint\u003e pInt3(std::move(pInt2)); } std::unique_ptr 虽然不支持复制，但有个例外：可以从函数返回一个 std::unique_ptr。 #include\u003ciostream\u003e #include\u003cmemory\u003e std::unique_ptr\u003cint\u003e func(int x) { std::unique_ptr\u003cint\u003e pInt(new int(x)); return pInt; } int main() { int x = 5; std::unique_ptr\u003cint\u003e p = func(x); std::cout \u003c\u003c *p \u003c\u003c std::endl; } 占用内存的大小 相较于其他智能指针，std::unique_ptr 有一个优势：在不自定义删除器的情况下，std::unique_ptr 的内存占用几乎和原始指针一致。 #include\u003ciostream\u003e #include\u003cmemory\u003e int main() { int *p = new int(5); std::unique_ptr\u003cint\u003e pu(new int(6)); std::cout \u003c\u003c sizeof(p) \u003c\u003c \":\" \u003c\u003c sizeof(pu) \u003c\u003c std::endl; return 0; } // 输出：8:8 std::unique_ptr 内部几乎不用维护其他信息（std::shared_ptr 需要维护引用计数），当它离开作用域，是通过 delete 删除指向的资源。但是，如果自定义了删除器，则会增加内存占用。 #include\u003ciostream\u003e #include\u003cmemory\u003e int main() { int c = 2; int d = 3; // 带参数捕捉的lambda表达式，会导致unique_ptr占用内存变大 auto delint = [\u0026](int *p) { std::cout \u003c\u003c \"c = \" \u003c\u003c c \u003c\u003c std::endl; std::cout \u003c\u003c \"d = \" \u003c\u003c d \u003c\u003c std::endl; std::cout \u003c\u003c \"deleter\" \u003c\u003c std::endl; delete p; }; std::unique_ptr\u003cint, decltype(delint)\u003e p(new int(10), delint); std::cout \u003c\u003c sizeof(p) \u003c\u003c std::endl; return 0; } // 输出： 24 c = 2 d = 3 deleter 一个典型应用 std::unique_ptr 的一个典型应用是作为一个工厂函数的返回类型（指向类层次中的对象）。这里直接使用这里的代码作为例子： #include\u003ciostream\u003e #include\u003cmemory\u003e using namespace std; /*! * \\brief The Investment class 基类 */ class Investment { public: virtual ~Investment() = default; public: virtual void doWork() = 0; }; /*! * \\brief The Stock class 派生类 */ class Stock : public Investment { public: virtual void doWork() override { cout \u003c\u003c \"Stock doWork....\\n\"; } }; /*! * \\brief The Stock class 派生类 */ class Bond : public Investment { public: virtual void doWork() override { cout \u003c\u003c \"Bond doWork....\\n\"; } }; enum class InvestType { INVEST_TYPE_STOCK, INVEST_TYPE_BOND, }; auto makeInvestment(InvestType type) { // 自定义析构器, 这里以lambda表达式的形式给出 auto delInvmt = [](Investment *pInvestment) { // TODO 自定义析构时想干的事 cout \u003c\u003c \"delInvmt called....\" \u003c\u003c endl; delete pInvestment; }; // 待返回的指针, 初始化为空指针，并指定自定义析构器 // decltype(delInvmt) 用于获取自定义析构器的类型 unique_ptr\u003cInvestment, decltype(delInvmt)\u003e pInv(nullptr, delInvmt); // 注意这里用reset来指定pInv获取从new产生的对象的所有权, 不能用=赋值 switch (type) { case InvestType::INVEST_TYPE_STOCK: //pInv = new Stock; // error!! c++11禁止从裸指针到智能指针的隐式转换 pInv.reset(new Stock); break; case InvestType::INVEST_TYPE_BOND: pInv.reset(new Bond); break; } // 返回智能指针 return pInv; } void test() { // 测试工厂函数 { // pInv出作用域后会自己析构 auto pInv = makeInvestment(InvestType::INVEST_TYPE_STOCK); if (pInv) { pInv-\u003edoWork(); } } cout \u003c\u003c \"----------------\\n\"; // 测试move效果 { auto pInv = makeInvestment(InvestType::INVEST_TYPE_BOND); auto pInv2 = move(pInv); cout \u003c\u003c \"after move pInv to pInv2 \\n\"; if (!p","date":"2023-10-12","objectID":"/posts/effective_modern_c/:1:4","tags":["Effective Modern C++"],"title":"Effective Modern C++ 阅读笔记","uri":"/posts/effective_modern_c/"},{"categories":["C++"],"content":"CH05: Rvalue References, Move Semantics, and Perfect Forwarding Item 23: Understand std::move and std::forward. std::move 和 std::forward 并不像他们名字所表达的那样，实际上 std::move 并没有移动数据，std::forward 也并没有转发数据，并且它们在运行期什么也没做。 先说 std::move，我们看下它在 C++11 中简易的实现如下： template\u003ctypename T\u003e // in namespace std typename remove_reference\u003cT\u003e::type\u0026\u0026 move(T\u0026\u0026 param) { using ReturnType = // alias declaration; typename remove_reference\u003cT\u003e::type\u0026\u0026; // see Item 9 return static_cast\u003cReturnType\u003e(param); } std::move 只是返回了右值引用。这里使用了 remove_reference 是为了去除引用标识符。当 T 是一个引用类型的时候，根据引用折叠原理，T\u0026\u0026 会被折叠成一个左值引用类型。所以 remove_reference 是为了去防止 T 是一个引用类型， 它会去除引用进而保证 std::move 返回一个右值引用。因此 std::move 只是做了类型转换，并没有移动数据。由于只有右值是可以被移动的，std::move 更像是说明经过它之后对象可能会被移动（可能，而不是一定，后文会有解释）。 而 C++14 的 std::move 更加简洁： template\u003ctypename T\u003e // C++14; still in decltype(auto) move(T\u0026\u0026 param) // namespace std { using ReturnType = remove_reference_t\u003cT\u003e\u0026\u0026; return static_cast\u003cReturnType\u003e(param); } std::move 的目的就是让编译器把修饰的变量看做是右值，进而就可以调用其移动构造函数。事实上，右值是仅可以被移动的对象，std::move 之后不一定一定调用构造函数。看下面的例子，假如你有这样的一个类： class Annotation { public: explicit Annotation(std::string text) : text_(text) std::string text_; } class Annotation { public: explicit Annotation(std::string text) : text_(std::move(text)) {} std::string text_; }; class Annotation { public: //这里换成了带有const explicit Annotation(const std::string text) : text_(std::move(text)) {} std::string text_; }; 第一个实现会发生两次拷贝，第二个实现会发生一次拷贝和一次移动，那么第三个实现会发生什么呢？ 由于 Annotation 的构造函数传入的是一个 const std::string text，std::move(text) 会返回一个常量右值引用，也就是 const 属性被保留了下来。而 std::string 的 move 构造函数的参数只能是一个非 const 的右值引用，这里不能去调用 move 构造。只能调用 copy 构造，因为 copy 构造函数的参数是一个 const 引用，它是可以指向一个 const 右值。因此，第三个实现也是发生两次拷贝。 也可以用下面的例子验证一下： #include \u003ciostream\u003e #include \u003cboost/type_index.hpp\u003e using boost::typeindex::type_id_with_cvr; class A { public: A(){ std::cout \u003c\u003c \"constructon\" \u003c\u003c std::endl; } A(const A\u0026 a) { std::cout \u003c\u003c \"copy constructon\" \u003c\u003c std::endl; } A(A\u0026\u0026 a) { std::cout \u003c\u003c \"move constructon\" \u003c\u003c std::endl; } }; int main() { const A a1; std::cout \u003c\u003c type_id_with_cvr\u003cdecltype(std::move(a1))\u003e().pretty_name() \u003c\u003c std::endl; auto a2(std::move(a1)); return 0; } // output constructon A const\u0026\u0026 copy constructon 因此，我们可以总结出两点启示： 第一，假如你想对象能够真正被移动，不要声明将其申明为 const，对 const 对象的移动操作会被转换成了拷贝操作。 第二，std::move 不仅不移动任何东西，甚至不能保证被转换的对象可以被移动。唯一可以确认的是应用 std::move 的对象结果是个右值。 再说 std::forward。std::forward 也并没有转发数据，本质上只是做类型转换，与 std::move 不同的是，std::move 是将数据无条件的转换右值，而 std::forward 的转换是有条件的：当传入的是右值的时候将其转换为右值类型。 看一个 std::forward 的典型应用： #include\u003ciostream\u003e #include\u003cchrono\u003e class Widget { }; void process(const Widget\u0026 lvalArg) { std::cout \u003c\u003c \"process(const Widget\u0026 lvalArg)\" \u003c\u003c std::endl; } void process(Widget\u0026\u0026 rvalArg) { std::cout \u003c\u003c \"process(Widget\u0026\u0026 rvalArg)\" \u003c\u003c std::endl; } template\u003ctypename T\u003e void logAndProcess(T\u0026\u0026 param) { auto now = std::chrono::system_clock::now(); process(std::forward\u003cT\u003e(param)); } int main () { Widget w; logAndProcess(w); // call with lvalue logAndProcess(std::move(w)); // call with rvalue } // output process(const Widget\u0026 lvalArg) process(Widget\u0026\u0026 rvalArg) 当我们通过左值去调用 logAndProcess 时，自然期望这个左值可以同样作为一个左值转移到 process 函数，当我们通过右值去调用 logAndProcess 时，我们期望这个右值可以同样作为一个右值转移到 process 函数。 但是，对于 logAndProcess 的参数 param，它是个左值（可以取地址）。在 logAndProcess 内部只会调用左值的 process 函数。为了避免这个问题，当且仅当传入的用来初始化 param 的实参是个右值，我们需要 std::forward 来把 param 转换成一个右值。至于 std::forward 是如何知道它的参数是通过一个右值来初始化的，将会在 Item 28 中会解释这个问题。 总结 std::move 无条件将输入转化为右值。它本身并不移动任何东西。 std::forward 把其参数转换为右值，仅仅在参数被绑定到一个右值时。 std::move 和 std::forward 只是做类型转换，在运行时（runtime）不做任何事。 Item 24: Distinguish universal references from rvalue references. 在 C++11 移动语义出现后，遇到 T\u0026\u0026 ，你可能认为就是右值引用，其实不然，这可能是一个万能引用（universal reference），右值引用和万能引用只是形式上相似而已，二者实际上是两个概念。右值引用只能绑定到一个右值上；而万能引用既可以绑定到一个右值，也可以绑定到一个左值。另外，万能引用能绑定到 const 或非 const 对象，也能绑定到 volatile 或非 volatile 对象，甚至能绑定到 const 加 volatile 的对象。 void f(Widget\u0026\u0026 param); // rvalue reference Widget\u0026\u0026 var1 = Widget(); // rvalue reference auto\u0026\u0026 var2 = var1; // not rvalue reference template\u003ctypename T\u003e void f(std::vector\u003cT\u003e\u0026\u0026 param); // rvalue reference ","date":"2023-10-12","objectID":"/posts/effective_modern_c/:1:5","tags":["Effective Modern C++"],"title":"Effective Modern C++ 阅读笔记","uri":"/posts/effective_modern_c/"},{"categories":["C++"],"content":"CH06: Lambda Expressions Item 31: Avoid default capture modes. C++11 lambda 表达式有两种默认捕获模式：传引用捕获和传值捕获。默认传引用捕获可能导致引用悬挂的问题。默认传值捕获其实也不能避免这个问题，并且你的 lambda 闭包也不是独立的。 先看默认传引用捕获导致引用悬挂的问题。看下面的代码片段： using FilterContainer = std::vector\u003cstd::function\u003cbool(int)\u003e\u003e; FilterContainer filters; // filtering funcs void addDivisorFilter() { auto calc1 = computeSomeValue1(); auto calc2 = computeSomeValue2(); auto divisor = computeDivisor(calc1, calc2); filters.emplace_back( [\u0026](int value) { return value % divisor == 0; } // danger! ref to divisor will dangle！ ); } filters 存放了 lamdba 闭包，闭包引用了 addDivisorFilter 作用域内的局部变量 divisor，当离开 addDivisorFilter 作用域后，局部变量 divisor 将被析构，若此时使用 filters 则导致引用悬挂。 使用显示的传引用捕获也有同样的问题： filters.emplace_back( [\u0026divisor](int value) // danger! ref to { return value % divisor == 0; } // divisor will ); // still dangle! 不过，显示的传引用捕获可以提醒我们 lambda 表达式的生命周期依赖于 divisor 的生命周期，也可以提醒我们需要确保 divisor 的生命周期要长于 lambda 表达式的生命周期。 解决上述问题，可以通过默认传值捕获的方式解决： filters.emplace.back( [=](int value) { return value % divisor == 0; } ) 但是，默认传值捕获也不一定能够解决悬挂问题：例如你通过传值的方式捕获一个指针，也即你拷贝了一个指针给 lambda 闭包了，但是你无法阻止 lambda 闭包外指针被 delete，从而导致指针悬挂的问题。看下面的例子： class Widget { public: … // ctors, etc. void addFilter() const; // add an entry to filters private: int divisor; // used in Widget's filter }; void Widget::addFilter() const { filters.emplace_back( [=](int value) { return value % divisor == 0; } ); } 上面代码貌似是安全的。因为你通过默认传值捕获方式，应该不会有悬挂的问题。但是，lambda 表达式只能捕获作用域内的非静态局部变量，而 divisor 是一个成员变量。那么上面的代码为什么可以编译通过呢？可以先看下面这段代码： void Widget::addFilter() const { filters.emplace_back( [divisor](int value) { return value % divisor == 0; } ); } 这段代码编译无法通过： main.cpp: In member function 'void Widget::addFilter() const': main.cpp:19:6: error: capture of non-variable 'Widget::divisor' 19 | [divisor](int value) { return value % divisor == 0; } 正如我们所设想的，lambda 表达式无法捕获非静态成员变量。前面默认传值捕获之所以能够通过编译，原因其实是这里的 lambda 表达式捕获的是 this 指针，也就是将 this 指针拷贝进了闭包。编译器在内部将 divisor 替换成了 this-\u003edivisor，等价如下： void Widget::addFilter() const { filters.emplace_back( [=](int value) { return value % this-\u003edivisor == 0; } ); } 这里实际捕获的不是 divisor，而是 this 指针。了解了上述真相后，就不难理解默认传值捕获也可能导致指针悬挂的问题了。 using FilterContainer = std::vector\u003cstd::function\u003cbool(int)\u003e\u003e; FilterContainer filters; void doSomeWork() { auto pw = std::make_unique\u003cWidget\u003e(); pw-\u003eaddFilter(); } filters 包含了 Widget 的 this 指针的拷贝。 doSomeWork 执行完成后，Widget 将被析构，导致 filters 包含了一个悬挂的指针。 上述问题可以通过使用一个局部变量拷贝成员变量来解决。如下： void Widget::addFilter() const { auto divisorCopy = divisor; // copy data member filters.emplace_back( [divisorCopy](int value) // capture the copy { return value % divisorCopy == 0; } // use the copy ); } 或者默认传值捕获也是一样： void Widget::addFilter() const { auto divisorCopy = divisor; // copy data member filters.emplace_back( [=](int value) // capture the copy { return value % divisorCopy == 0; } // use the copy ); } c++14 的方式更加简洁： void Widget::addFilter() const { filters.emplace_back( // C++14: [divisor = divisor](int value) // copy divisor to closure { return value % divisor == 0; } // use the copy ); } lambda 表达式只能捕获非静态局部变量，对于 static 或者 global 变量，lambda 表达式不会捕获。所以这些变量发生改变会影响到 lambda 表达的行为。使用默认传值捕获，可能会让你以为你的 lambda 闭包是独立的，不依赖外部变量的变化，其实不然。 void addDivisorFilter() { static auto calc1 = computeSomeValue1(); // now static static auto calc2 = computeSomeValue2(); // now static static auto divisor = // now static computeDivisor(calc1, calc2); filters.emplace_back( [=](int value) // captures nothing! { return value % divisor == 0; } // refers to above static ); ++divisor; // modify divisor } 上述代码可能会让你产生错觉：因为是使用默认传值捕获，lambda 闭包是将 divisor 拷贝进去的。但是 static 变量不会被 lambda 闭包捕获， divisor 的改变会影响到 lambda 表达式的行为。 总结 默认的按引用捕获可能会导致引用悬挂。 默认的按值引用对于悬挂指针很敏感（尤其是this指针），并且它会误导人认为 lambda 是独立的。 Item 32: Use init capture to move objects into closures. 如果你想移动一个对象都 lambda 闭包，值捕获和引用捕获都不能实现该目的。C++ 14 提供了初始化捕获（init capture）模式支持移动捕获。C++11 并不支持，但是可以使用 std::bind 间接模拟。 C++14 使用初始化捕获模式实现移动捕获 C++14 提供了支持移动捕获的机制，但并没有类似值捕获 [=] 或者引用捕获 [\u0026] 的模式直接添加一个移动捕获 [\u0026\u0026] 模式。而是采取了一种更加灵活的机制 —– 初始化捕获模式。移动捕获是采用初始化捕获的机制实现，除了默认捕获模式","date":"2023-10-12","objectID":"/posts/effective_modern_c/:1:6","tags":["Effective Modern C++"],"title":"Effective Modern C++ 阅读笔记","uri":"/posts/effective_modern_c/"},{"categories":["C++"],"content":"CH07: The Concurrency API Item 35: Prefer task-based programming to thread-based. 如果你想异步运行一个函数 donAsyncWork，你有两个基本的选择：基于线程的方法（thread-based）和基于任务的方法（task-based）。 int doAsyncWork(); std::thread t(doAsyncWork); // thread-based auto fut = std::async(doAsyncWork); // task-based 在比较二者优劣前，我们先介绍下 C++ 软件中线程的3个层次： 硬件线程。硬件实际执行计算的并行数。现代计算机架构中，一个硬件核对应一个或多个硬件线程。 软件线程。也被称为系统线程，指的是操作系统管理核调度的所有线程。软件线程运行在硬件线程之上，并且可以创建的软件线程要多于硬件线程。这样的好处是：当某些软件线程处于阻塞状态（等待IO、mutex、condition variable）时，可以执行其他线程以提高吞吐率。 std::thread。C++ 的线程对象，作为句柄对应系统的软件线程。std::thread 也可以是空句柄而不对应系统的软件线程。例如没有执行函数、执行函数被移动其他线程、已经 join 或 detached 的 std::thread 对象。 基于任务的方法一般要优于基于线程的方法。 doAsyncWork 有返回值，可以代表任务的执行状态。基于线程的方法没有提供一个很好的机制获取返回值。而 std::async 返回的 std::future 对象提供了 get 方法可以获取到返回值。并且当 doAsyncWork 返回异常时，基于线程的方法直接抛出 std::terminate，而基于任务的方法可以根据返回值做异常处理。 系统的软件线程是有限的，当请求创建的 std::thread 多于系统提供的最大软件线程数，将抛出 std::system_error，即使 doAsyncWork 被设置成 noexcept。因而基于线程的方法需要处理这种情况，这就需要对线程进行管理。 即使你没有用尽软件线程，基于线程的方法还存在认购超额（oversubscription）的问题，即就绪态的软件线程高于硬件线程。操作系统会采用时间片轮询的方式执行所有的软件线程，而线程的上下文切换会增加线程管理的开销。并且硬件线程被切换到另一个软件线程时，其 cache 上的数据通常会失效，也会增加线程的开销。想要避免认购超额问题还比较困难，软件线程于硬件线程的合理比例取决于多种因素。例如硬件架构的特点、cache的使用方式、任务的特点等。 综上，线程的管理是比较困难的。而基于任务的方法将线程管理交给了 C++ 标准库，而 C++ 标准库可以更好地管理线程。例如，你无需担心软件线程耗尽的问题，因为默认参数的 std::async 不一定会创建线程，它可能在认购超额时将当前任务安排在当前线程上执行。另外 C++ 标准库可能比你更清楚硬件线程的资源，可以很好的避免负载不均衡的问题。 当然，基于线程的方法也有一定的优势： 需要访问实现线程的底层API。std::thread 可以获取底层线程的句柄，可以使用底层线程的API。 需要优化线程的使用。例如，如果你正在开发一个服务软件，而这个软件是这台机器上执行的唯一有意义的进程，并且你清楚这台机器的硬件配置。 需要实现一些高级的线程技术。例如线程池技术，而 C++ 标准库没有提供。 除了上述情况外，建议优先使用基于任务的编程方法。 总结 std::thread API 不能直接访问异步函数执行的结果，如果执行函数有异常抛出，代码终止执行。 基于线程的编程方式存在资源耗尽、认购超额、负载均衡的方案移植性不佳。 通过 std::async 的基于任务的编程方式会默认解决上面的问题。 Item 36: Specify std::launch::async if asynchronicity is essential. 当你使用 std::async() 执行一个函数或可调用对象时，你通常期望这个函数是异步执行。但是， std::async() 不一定如你所愿。其实 std::async() 是根据执行策略决定是否会异步执行。 std::async() 有两种执行策略，定义在 std::launch 作用域中： std::launch::async 函数或可执行对象必须异步执行，也即运行在其他线程上。 std::launch::deferred 函数或可执行对象延迟执行。仅在 std::async() 的返回对象 std::future 调用 get 或 wait 时，才在当前线程同步执行，并且调用者会阻塞直到函数执行完成。 std::async() 的默认策略其实是二者的组合，也即以下两者涵义完全相同： auto fut1 = std::async(f); // run f using default launch policy auto fut2 = std::async(std::launch::async | // run f either std::launch::deferred, // async or f); // deferred 默认的策略下，f 可能是同步执行也可能是异步执行。正如 Item 35: Prefer task-based programming to thread-based. 中讨论的：标准库的线程管理模块承担了线程的创建和释放的职责，可以有效避免超额订阅、保证负载均衡。这极大地方便了 std::async 的使用。 但是，默认策略也会有如下问题： 无法预测 f 是否是并发执行。 无法预测 f 是否运行在 get 或 wait 调用时的线程上。 甚至无法预测 f 是否已经执行了。因为没法保证一定会调用 get 或 wait。 当 f 要访问本地线程存储（TLS，Thread Local Storage）时，无法预测访问的是哪个线程的本地存储。 auto fut = std::async(f); // TLS for f possibly for // independent thread, but // possibly for thread // invoking get or wait on fut std::async 的默认策略还会影响到 wait_for 超时调用写法，可能导致 bug，例如： using namespace std::literals; // for C++14 duration suffixes; see Item 34 void f() // f sleeps for 1 second, then returns { std::this_thread::sleep_for(1s); } auto fut = std::async(f); // run f asynchronously (conceptually) while (fut.wait_for(100ms) != // loop until f has std::future_status::ready) // finished running... { // which may never happen! … } 如果 std::async 是并发执行，也即执行策略为 std::launch::async，以上代码没有问题。但是，如果执行策略为 std::launch::deferred时，fut.wait_for 总是返回 future_status::deferred，以上代码就会有问题。解决办法也很简单，先通过 wait_for 的超时时间为 0 来检测 std::async 是异步执行还是同步执行： auto fut = std::async(f); // as above if (fut.wait_for(0s) == // if task is std::future_status::deferred) // deferred... { // ...use wait or get on fut … // to call f synchronously } else { // task isn't deferred while (fut.wait_for(100ms) != // infinite loop not std::future_status::ready) { // possible (assuming // f finishes) … // task is neither deferred nor ready, // so do concurrent work until it's ready } … // fut is ready } 综上，如果你的使用场景不是以下几种，则需要考虑是否需要替换 std::async 的默认策略： 当调用 get 或 wait 时，任务不需要并发执行。 并不关心访问的是哪个线程的本地存储。 可以保证 get 或 wait 一定会被调用，或者任务不被执行也能接受。 使用 wait_for 或 wait_until 时，需要考虑 std::launch::deferred 策略。 如果不是以上场景，你可能需要指定使用 std::launch::async 策略，也即真正创建一个线程去并发执行任务： aut","date":"2023-10-12","objectID":"/posts/effective_modern_c/:1:7","tags":["Effective Modern C++"],"title":"Effective Modern C++ 阅读笔记","uri":"/posts/effective_modern_c/"},{"categories":["C++"],"content":"CH08: Tweaks Item 41: Consider pass by value for copyable parameters that are cheap to move and always copied. C++ 函数参数传递方式有值传递、指针传递、引用传递的方式。一般地，考虑到拷贝开销，建议使用引用传递的方式。例如： class Widget { public: void addName(const std::string\u0026 newName) // take lvalue; { names.push_back(newName); } // copy it void addName(std::string\u0026\u0026 newName) // take rvalue; { names.push_back(std::move(newName)); } // move it; see ... // Item 25 for use // of std::move private: std::vector\u003cstd::string\u003e names; }; 对于左值，拷贝进 Widget.names 中。对于右值，移动进 Widget.names。上面代码是有效的，但是实现和维护两个函数有点冗余。 另一种方案是使用万能引用（universal reference）传参。例如： class Widget { public: template\u003ctypename T\u003e // take lvalues void addName(T\u0026\u0026 newName) // and rvalues; { // copy lvalues, names.push_back(std::forward\u003cT\u003e(newName)); // move rvalues; } // see Item 25 // for use of ... // std::forward }; 万能引用版本代码量减少了很多，看起来也清爽很多，但也会有其他问题。但模板的实现一般要放到头文件里，也会实例化出多个版本（左值版本、右值版本以及可以转换为 std::string 的类型版本）。于此同时，还存在诸如 Item 30 介绍万能引用和完美转发失效的例子、Item 27 介绍的传参错误时编译报错可读性很差的问题。 那么有没有什么完美的方案可以解决上述两种方案遇到的问题呢？我们来分析下值传递的方案。 class Widget { public: void addName(std::string newName) // take lvalue or { names.push_back(std::move(newName)); } // rvalue; move it ... }; 在 addName 内对 newName 使用 std::move 可以减少一次拷贝。这里使用 std::move 考虑到两点：首先，newName 独立于传入的参数，不会影响到调用者；再者，这里是最后使用 newName 的地方，对其移动不会影响其他代码。 值传递的方案可以解决引用重载版本的源码冗余问题和万能引用版本的不适用场景、传参错误报错信息可读性等问题，那剩下的问题就是值传递方案的性能了。 在 C++98 中，对于值传递的方案，不管传入的左值还是右值，newName 都会通过拷贝构造函数来构造。而到了 C++11，newName 在传入左值时是拷贝构造，传入右值是移动构造。考虑到下面的代码： Widget w; ... std::string name(\"Bart\"); w.addName(name); // call addName with lvalue ... w.addName(name + \"Jenne\"); // call addName with rvalue // (see below) 对于第一个调用，参数 newName 使用左值初始化，是拷贝构造。对于第二个调用，参数 newName 使用右值初始化，是移动构造。 我们把上述三种方案写到一起再对比下性能： class Widget { // Approach 1:overload for public: // lvalues and rvalues. void addName(const std::string\u0026 newName) // take lvalue; { names.push_back(newName); } // copy it void addName(std::string\u0026\u0026 newName) // take rvalue; { names.push_back(std::move(newName)); } // move it; see ... // Item 25 for use // of std::move private: std::vector\u003cstd::string\u003e names; }; class Widget { // Approach 2: use universal reference public: void addName(const std::string\u0026 newName) // take lvalue; { names.push_back(newName); } // copy it void addName(std::string\u0026\u0026 newName) // take rvalue; { names.push_back(std::move(newName)); } // move it; see ... // Item 25 for use // of std::move }; class Widget { // Approach 3: pass by value public: void addName(std::string newName) // take lvalue or { names.push_back(std::move(newName)); } // rvalue; move it ... }; 同样，考虑上面两种调用方式： Widget w; ... std::string name(\"Bart\"); w.addName(name); // call addName with lvalue ... w.addName(name + \"Jenne\"); // call addName with rvalue // (see below) 这里，我们忽略掉编译器根据上下文信息所做的编译优化的干扰，对比下三种方案的性能开销： 引用重载：首先，无论是左值还是右值重载函数， 调用者的实参是被绑定到引用 newName上，没有拷贝或移动开销。再者，对于左值引用重载函数， newName 被拷贝到 Widget::names 内，而对于右值引用重载函数，newName 被移动到 Widget::names 内。总的来说，左值需要一次拷贝，右值需要一次移动。 万能引用：首先，调用者的实参也是被绑定到引用 newName上，也没有拷贝或移动开销。再者，由于使用了 std::forward ，左值实参则被拷贝到 Widget::names 内，而右值实参则被移动到 Widget::names 内。总的来说，左值需要一次拷贝，右值需要一次移动。对于调用者传入的参数不是 std::string 类型，而是可以转换为 std::string 的类型，比如 char* 类型，对于引用重载版本，需要先将 char* 构造成 std::string，这会增加其开销，而万能引用版本则直接将 char* 转发给 std::string 构造函数直接构造 std::string 类型，详见 Item 25 。这里不考虑这种特殊情况。 值传递：首先，对于左值，需要调用拷贝构造 newName，而对于右值，需要移动构造 newName。再者， newName 被无条件移动到 Widget::names 内。总的来说，左值需要一次拷贝加一次移动，右值需要两次移动。相较于前两种引用传参的方法，多了一次移动操作。 再回头看下本 Item 的标题： Consider pass by value for copyable parameters that are cheap to move and always copied。缘于以下四个原因： 只考虑值传递的话，只需要写一个函数，目标代码中也会生成一个函数，并且可以避免万能引用方法的问题。但是引入了一点性能开销。 只对可拷贝的参数使用值传递方法。如果参数是 move-only 的，那值传递的方法肯定会失败。对于 move-only 类型参数，也无须提供左值引用重载函数，只需要一个右值引用的重载函数即可。例如，对于传递 std::unique_ptr 类型参数： class Widget { public: ... void setPtr(std::unique_ptr\u003cstd::string\u003e\u0026\u0026 ptr) { p = std::move(ptr); } private: std::unique_ptr\u003cstd::string\u003e p; }; ... Widget w; ... w.setPtr(std::make_unique\u003cstd::string\u003e(\"Modern C++\")); 上述代码，std::make_unique\u003cstd::string\u003e(\"Modern C++\") 产生一个右值，","date":"2023-10-12","objectID":"/posts/effective_modern_c/:1:8","tags":["Effective Modern C++"],"title":"Effective Modern C++ 阅读笔记","uri":"/posts/effective_modern_c/"},{"categories":["C++"],"content":"前言 Effective-STL总结系列分为七部分，本文为第四部分，涉及原书第四章，内容范围Rule26~29。为方便书写，Rule26简写为R26。 Effective-STL系列List 本博客站点系列内容如下： 💡 Effective STL(第3版) 精读总结(一) 💡 Effective STL(第3版) 精读总结(二) 💡 Effective STL(第3版) 精读总结(三) 💡 Effective STL(第3版) 精读总结(四) ","date":"2023-09-21","objectID":"/posts/effective_stl_part_four/:0:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [4] | 迭代器","uri":"/posts/effective_stl_part_four/"},{"categories":["C++"],"content":"R26: iterator 优先于 const_interator、reverse_interator 及 const_reverse_interator STL中所有的标准容器都提供了4种迭代器类型，对容器类container而言，iterator类型相当于T*，const_iterator相当于const T*。reverse_iterator和const_reverse_iterator递增的效果是从容器的尾部反向遍历到头部。 对于vector容器的insert函数和erase函数，这些函数只接受iterator类型的参数，而不是const_iterator、reverse_iterator或者const_reverse_iterator。下面这张图展示了不同类型迭代器之间的关系。黑色箭头，并且上面未标函数的表示隐式类型转换，标函数的表示显示类型转换，但是需要注意的是，通过base()得到的迭代器或许并非是你期望的迭代器类型。也可以看出想隐式转换const_iterator到iterator是不可行的。从reverse_iterator转换来的iterator在使用之前可能需要进行相应的调整，条款28将更详细地说明这一点。由此可见，尽量使用iterator，而不是const或reverse型的迭代器，可以使容器的使用更为简单有效，并且可以避免潜在的问题。 不同类型的迭代器之间的关系: 假设有个iterator i和一个const_iterator ci指向同一个对象，但是在比较这两个迭代器时，即if(i == ci)的结果却是假，甚至不能通过编译，因为这些STL实现将const_iterator的operator==作为成员函数，而不是一个非成员函数，ci不能隐式转成i，但是i可以隐式转成ci，所以判断if(ci == i)是真。避免这种问题最简单的办法是减少混用不同类型的迭代器，尽量使用iterator来代替const_iterator。 ","date":"2023-09-21","objectID":"/posts/effective_stl_part_four/:1:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [4] | 迭代器","uri":"/posts/effective_stl_part_four/"},{"categories":["C++"],"content":"R27: 使用 distance 和 advance 将容器的 const_interator 转换成 iterator 首先考虑类型转换达到该条款的目的，包括两种代码，Iter i(ci);和Iter i(const_cast(ci));，这两种代码都不能通过编译，原因在于iterator和const_iterator是完全不同的两个类，相当于int和complex之间互转，当然不可能成功。不过对于vector和string来说，上面的代码可能通过编译，因为大多数STL将vector::iterator和vector::const_iterator分别定义为T和const T，string::iterator和string::const_iterator定义为char和const char，因此对于这两个容器强转可能是成功的，但是即使在这两个容器种，reverse_iterator和const_reverse_iterator仍然是两个类，它们之间是不能强转的。 可以通过distance函数进行转换，代码如下： typedef deque\u003cint\u003e IntDeque; typedef IntDeque::iterator Iter; typedef IntDeque::const_iterator ConstIter; IntDeque d; ConstIter ci; Iter i(d.begin()); advance(i, distance(i, ci));//目前不能通过编译，但是思想是通过distance计算出ci和begin之间的距离，然后移动这么多距离 上面这个程序不能通过编译的原因是distance函数只能接受一种类型的迭代器，而i和ci是两种不同的迭代器。要通过编译最简单的方法是显示指定distance使用的类型，即advance(i, distance(i, ci));除了达成效率，再考虑这么做的效率如何，它的执行效率取决于你使用的迭代器，对于随机访问迭代器（vector、string和deque），它是常数时间操作，对于双向迭代器（其他所有），它是线性时间操作。 ","date":"2023-09-21","objectID":"/posts/effective_stl_part_four/:2:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [4] | 迭代器","uri":"/posts/effective_stl_part_four/"},{"categories":["C++"],"content":"R28: 正确理解由reverse_iterator的base()成员函数所产生的iterator的用法 假设通过reverse_iterator查找容器中值为3的元素，ri表示3的位置，但是在调用base()函数将其转换成iterator类型时，因为偏移变成i所指向的位置。假设要在ri的位置插入新元素，我们预期新元素会插入在现在元素3的位置，然后3和其后的元素需要往右移动一个位置，但是因为insert会将新元素插入到迭代器指向位置的前面，而逆序遍历的顺序是由后向前的，所以会将新元素插入在3的“后面”，实际对reverse_iterator来说就是“前面”。所以如果是在reverse_iterator类型ri位置插入，只需要在ir.base()位置插入即可。但是如果是在ri位置删除元素，则需要在ri.base()位置前面的位置执行删除。但是其中还是有坑，请看如下代码： //这段代码通不过编译 vector\u003cint\u003e v; vector\u003cint\u003e::reverse_iterator ri = find(v.rbegin(), v.rend(), 3); v.erase(--ri.base());//iterator的--是左移，reverse_iterator的--是右移 这段代码对于vector和string不能通过编译的原因在于，这两种容器的iterator和const_iterator是以内置指针的方式实现的，所以ri.base()的结果是一个指针，而C和C++都规定了从函数返回的指针不应该被修改。所以必须换个调用方式：v.erase((++ri).base());，先让ri左移再取指针。 ","date":"2023-09-21","objectID":"/posts/effective_stl_part_four/:3:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [4] | 迭代器","uri":"/posts/effective_stl_part_four/"},{"categories":["C++"],"content":"R29: 对于逐个字符的输入请考虑使用istreambuf::iterator 假设你想将一个文本文件中的内容拷贝到一个string对象中，考虑如下的实现方式： ifstream inputFile(\"inputData.txt\"); string fileData((istream_iterator\u003cchar\u003e(inputFile)), istream_iterator\u003cchar\u003e());//注意第一个参数用括号包起来 但是这种读取方式是不包含空白字符的，因为istream_iterator使用operator»完成读操作，而默认情况下operator»会跳过空白字符，假定你要保留空白字符，可以更改这种默认行为，如下代码: ifstream inputFile(\"inputData.txt\"); inputFile.unsetf(ios::skipws); string fileData((istream_iterator\u003cchar\u003e(inputFile)), istream_iterator\u003cchar\u003e());//注意第一个参数用括号包起来 上述代码是可以完成要求的功能的，但是你会发现它并不够快，istream_iterator内部使用的operator»实际上执行了格式化输出，这意味着每次调用operator»操作符，都会执行许多附加的操作。一种更为有效的途径是使用istreambuf_iterator，istreambuf_iterator的使用方法与istream_iterator大致相同，但是istream_iterator使用operator»从输入流中读取单个字符，而istreambuf_iterator从一个输入流的缓冲区读取下一个字符。使用的代码就是将istream_iterator改成istreambuf_iterator。 ifstream inputFile(\"inputData.txt\"); string fileData((istreambuf_iterator\u003cchar\u003e(inputFile)), istreambuf_iterator\u003cchar\u003e());//注意第一个参数用括号包起来 同样对于非格式化的逐个字符的输出，也可以考虑使用ostreambuf_iterator替换ostream_iterator。 ref: [1]. https://www.cnblogs.com/Sherry4869/p/15128250.html [2]. https://blog.csdn.net/zhuikefeng/article/details/108164117#t42 [3]. https://zhuanlan.zhihu.com/p/458156007 ","date":"2023-09-21","objectID":"/posts/effective_stl_part_four/:4:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [4] | 迭代器","uri":"/posts/effective_stl_part_four/"},{"categories":["C++"],"content":"前言 Effective-STL总结系列分为七部分，本文为第一部分，涉及原书第一章，内容范围Rule01~12。为方便书写，Rule12简写为R12。 Effective-STL系列List 本博客站点系列内容如下： 💡 Effective STL(第3版) 精读总结(一) 💡 Effective STL(第3版) 精读总结(二) 💡 Effective STL(第3版) 精读总结(三) 💡 Effective STL(第3版) 精读总结(四) ","date":"2023-09-15","objectID":"/posts/effective_stl_part_three/:0:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [3] | 关联容器","uri":"/posts/effective_stl_part_three/"},{"categories":["C++"],"content":"R19: 理解相等（equality）和等价（equivalence）的区别 find算法和set的insert成员函数都需要比较两个值是否相同，find返回指定元素位置的迭代器，set::insert需要在插入前确定元素是否已经存在于set中了。但是这两个函数是不同的方法判断两个值是否相同。find对相同的定义是相等，基于operator==，set::insert对相同的定义是等价，基于operator\u003c。但是相等也不一定意味着对象的所有成员都相等，因为可以重写operator==，制定我们自己的相等。等价是以在已排序区间中对象值的相对顺序为基础的，对于两个关联容器的对象x和y，如果它们都不在另一个的前面，那么称这两个对象具有等价的值，即!(x \u003c y) \u0026\u0026 !(y \u003c x)成立。但是一般情况下，关联容器的比较函数并不是operator\u003c，甚至不是less，它是用户自定义的判别式。每个关联容器都通过key_comp成员函数使排序判别式可被外界使用，所以更一般的等价是 !c.key_comp() (x, y) \u0026\u0026 !c.key_comp() (y, x)成立，key_comp()返回一个比较函数。 为了进一步理解相等和等价的区别，考虑这样一个不区分大小写的set，它认为STL和stl是等价的，下面是实现： struct CIStringCompare : public binary_function\u003cstring, string, bool\u003e{//该基类信息参考条款40 bool operator()(const string\u0026 lhs, const string\u0026 rhs) const{ return ciStringCompare(lhs, rhs);//不区分大小写的函数对象，具体实现参考条款35 } } set\u003cstring, CIStringCompare\u003e ciss; ciss就是一个不区分大小写的集合，如果在set中插入STL和stl，只有第一个字符串会被插入，因为第二个和第一个等价。如果使用set的find成员函数查找stl，是可以查找成功的，但是如果使用非成员的find算法就会查找失败，因为STL和stl并不相等。这个例子也印证了条款44中的，优先使用成员函数，而不是与之对应的非成员函数算法。 那么为什么关联容器要使用等价，而不是相等呢？标准容器总是保持排列顺序的，所以每个容器必须有一个比较函数（默认是less），如果关联容器使用相等来决定两个对象是否相同的话，意味着要提供另一个比较函数来判断相等。同样是那个不区分大小写的例子，STL和stl因为不相等，所以都会被插入到set中，但是它们之间的顺序是什么呢？因为排序是用的less，所以之间的顺序是判断不了的。 ","date":"2023-09-15","objectID":"/posts/effective_stl_part_three/:1:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [3] | 关联容器","uri":"/posts/effective_stl_part_three/"},{"categories":["C++"],"content":"R20: 为包含指针的关联容器指定比较类型 假定有一个包含string*指针的set，你将一些字符串指针放入其中，你可能期望set会按照字符串的字母顺序来排序，实则不然。如果想要按照期望的形式输出，就必须编写比较函数子类。 struct stringPtrLess : public binary_function\u003cconst string*, const string*, bool\u003e { bool operator()(const string* ps1, const string* ps2) const { return *ps1 \u003c *ps2; } } typedef set\u003cstring*, stringPtrLess\u003e stringPtrSet; stringPtrSet sps; void print(const string* ps){ cout \u003c\u003c *ps \u003c\u003c endl; } for_each(sps.begin(), sps.end(), print);//对sps的每个对象调用print 这里需要注意的是set模板的三个参数都是一个类型，所以给参数传递一个比较函数是不行的，无法通过编译。set不需要函数，它需要一个类型，在内部用它创建函数，所以下面的代码是不能通过编译的。 bool stringPtrLess(const string* ps1, const string* ps2) const { return *ps1 \u003c *ps2; } typedef set\u003cstring*, stringPtrLess\u003e stringPtrSet;//不能通过编译 stringPtrSet sps; 每当创建包含指针的关联容器时，一般同时需要指定容器的比较类型，所以可以准备一个模板比较函数。 struct dereferenceLess{ template \u003ctypename PtrType\u003e bool operator()(PtrType pt1, PtrType pt2) const{ return *pt1 \u003c *pt2; } } set\u003cstring*, dereferenceLess\u003e sps; 最后一件事，本条款是关于关联容器的，但它也同样适用于其他一些容器，这些容器包含指针，智能指针或迭代器，那么同样需要为这些容器指定一个比较类型。 ","date":"2023-09-15","objectID":"/posts/effective_stl_part_three/:2:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [3] | 关联容器","uri":"/posts/effective_stl_part_three/"},{"categories":["C++"],"content":"R21: 总是让比较函数在等值情况下返回false 看一个例子，set\u003cint, less_equal \u003e s;其中less_equal是指定的比较类型，相当于\u003c=。当执行s.insert(10);，容器中有一个10的元素了，然后再执行一次s.insert(10);，容器会先判断内部有没有和10等价的元素，即调用判断 !(10 \u003c= 10) \u0026\u0026 !(10 \u003c= 10)， \u0026\u0026两边都是false，所以结果也是false，意思为容器中没有与当前待插入元素等价的元素！看出问题了吧？相等却不等价。当第二个10被插入到set中，意味着set不是一个set了，就破坏了这个容器。所以一定要保证对关联容器适用的比较函数总是对相等值返回false。 再看一个例子，就是条款20中的stringPtrLess比较类型，实现的是string*按照字母升序排列，加入我们希望按照字幕降序排序，可以直接将它的判断置反吗？不可以！将判断直接置反得到的新判断是\u003e=，而不是\u003e。 struct stringPtrLess : public binary_function\u003cconst string*, const string*, bool\u003e { bool operator()(const string* ps1, const string* ps2) const { return !(*ps1 \u003c *ps2);//这是错误演示 } } ","date":"2023-09-15","objectID":"/posts/effective_stl_part_three/:3:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [3] | 关联容器","uri":"/posts/effective_stl_part_three/"},{"categories":["C++"],"content":"R22: 切勿直接修改set或multiset中的键 所有的关联容器都会按照一定顺序存储自己的元素，如果改变了关联容器的元素的键，那么新的键可能不在原来的位置上，这就会打破容器的有序性。对于map和multimap很简单，因为键的类型是const的，但是set和multiset中的元素却不是const的。首先考虑一下为什么set中的元素不能是const的，加入有一个雇员类，其中有id和salary两个成员，set是按照id的顺序进行排序的，所以更改salary不会影响雇员对象的位置，正因为可以更改雇员对象，这意味着set中存储的对象不能是const的。正因为更改set中的元素是如此简单，所以才要提醒你，如果你改变了set或multiset中的元素，一定不能改变键部分，如果你改变了，那么可能会破坏容器，再使用该容器将导致不确定的结果。 尽管set和multiset的元素不是const，但是STL有办法防止其被修改。有种实现会使set::iterator的operator*返回一个const T\u0026，在这种情况下是无法修改set和multiset中的元素的。 第一条提到可以更改雇员对象中非键的成员变量，但是有的编译器不允许这样的行为，所以修改set或multiset中元素的值是不可移植的代码。如果你不重视移植性，那么就可以更改对象中的非键成员，如果你重视移植性，那么就不能改变set和multiset中的对象。不对不允许改变非键的成员变量，可以先执行const_cast转换之后再改变。但是要注意转换成引用，即const_cast\u003cEmployee\u0026\u003e(i)，如果不是引用的话，类型转换首先会产生一个临时对象，在临时对象上做更改salary的动作，而i本身是并没有被更改的。 对于修改map或multimap情况又有所不同，map\u003cK, V\u003e或multimap\u003cK, V\u003e包含的是pair\u003cconst K, V\u003e类型的元素，如果把const属性去掉，就意味着可以改变键部分。理论上，一种STL实现可以将这样的值卸载一个只读的内存区域，一旦写入后，将由一个系统调用进行写保护，这是若试图修改它，最好的结果就是没有效果。但是如果要坚持C++标准的规则，那就永远不要试图修改map或multimap中的键部分。 除了强制类型转换，还有一种安全的方式完成更改对象的工作。第一步找到要修改的对象的位置。第二步为将被修改的元素做一份拷贝。第三步修改该拷贝。第四步把容器中的元素删除，通常是使用erase。第五步是把新的值插入到容器中，通常是使用insert。 对于一个 map\u003cK, V\u003e 或 map\u003cK, V\u003e 类型的对象，其中的元素类型是 pair\u003cconst K, V\u003e，因为键的类型是 const K，所以它不能修改。 set / multiset 中的值不是 const，所以对这些值进行修改的代码可以通过编译。 ","date":"2023-09-15","objectID":"/posts/effective_stl_part_three/:4:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [3] | 关联容器","uri":"/posts/effective_stl_part_three/"},{"categories":["C++"],"content":"R23: 考虑用排序的vector替代关联容器 1.当你需要一个快速查找功能的数据结构时，一般会立即想到标准关联容器。但是哈希容器的查找速度更快，通常提供常数时间的查找能力，而关联容器时对数时间的查找能力。如果你觉得对数时间的查找能力也可，那么可能排序的vector可能更符合你的要求。这是因为标准关联容器通常被实现为平衡二叉树，这种数据结构对混合的插入、删除和查找做了优化，即它适用于程序插入、删除和查找混在一起，没有明显的阶段的操作。但是很多应用程序使用数据结构的方式并没有这么乱，一般可以明显地分成三个阶段。设置阶段，这个阶段主要是插入和删除，几乎没有查找。查找阶段，这个阶段主要是查找，几乎没有插入和删除。重组阶段，这个阶段主要是插入和删除，几乎没有查找。对于这种方式，vector可能比关联容器提供了更好的性能，但是必须是排序的容器才可以，因为只有对排序的vector容器才能够正确底使用查找算法binary_search、lower_bound和equal_range等。 2. 下面探究为什么排序的vector在查找性能上会比关联容器要快呢？第一个原因是大小，平衡二叉树存储对象，除了对象本身以外，还通常包含了三个指针，一个指向左儿子，一个指向右儿子，通常还有一个指向父节点，而使用vector存储对象的话，除了对象本身以外，就没有多余的开销了。假设我们的数据足够大，它们被分割后将跨越多个内存页面，但是vector将比关联容器需要更少的页面。第二个原因是vector是连续内存容器，关联容器是基于节点的容器，虽然绝大多数STL实现使用了自定义的内存管理器使得二叉树的节点聚集在相对较少的内存页面，但是如果你的STL并没有这样做，那这些节点就会散布在全部地址空间中，这会导致更多的页面错误。与vector这样的内存连续容器不同，基于节点的容器想保证容器中相邻的元素在物理内存中也是相邻是十分困难的。 3. 但是需要注意的是，插入和删除操作对于vector来说是昂贵的，尤其是对于需要保持有序的vector。因为每当有元素被插入，新元素之后的元素都要向后移动一个位置，当有元素被删除，删除位置之后的元素都要向前移动一个位置。所以只有删除插入操作不和查找操作混在一起的才考虑使用排序的vector替代关联容器。 4. 当使用vector替换map或multimap时，存储在vector中的数据必须是pair\u003cK, V\u003e，而不是pair\u003cconst K, V\u003e。因为当对vector进行排序时，他的元素的值将通过赋值操作被移动，这意味着pair的两个部分都必须是可以被赋值的。map和multimap在排序时只看元素的键部分，所以你需要为自己的pair写一个自定义的比较函数，因为pair的operator\u003c对pair的两个部分都会检查。而且你需要另一个比较函数来执行查找，用来做排序的比较函数需要两个pair对象作为参数，但是查找的比较函数的一个参数是与键相同类型的对象，另一个是pair对象，只需要一个键值对。另外你不知道传进来的第一个参数是键还是pair，所以实际上需要两个查找的比较函数，一个是假定键部分作为第一个参数传入，另一个是假定pair先传入。 标准的关联容器通常被实现为平衡二叉树。适合插入、删除、查找的混合操作，提供对数时间的查找能力。但比较浪费内存空间（父指针，左儿子指针，右儿子指针）。如果节点散布在全部地址空间，将会导致更多的页缺失。 散列容器：提供常数时间的查找能力。 使用数据结构的一般过程： 设置阶段：创建一个新的数据结构，并插入大量元素。在这个阶段，几乎所有的操作都是插入和删除操作，很少或几乎没有查找操作。 查找阶段：查询该数据结构以找到特定的信息。在这个阶段，几乎所有的操作都是查找操作，很少或几乎没有插入和删除操作。 重组阶段：改变该数据结构的内容，或许是删除所有的当前数据，再插入新的数据。在行为上，这个阶段与第1阶段类似。但这个阶段结束以后，应用程序又回到了第2阶段。 使用 vector 替代标准关联容器： 在排序的 vector 中存储数据可能比在标准关联容器中存储同样的数据要耗费更少的内存。 考虑到页面错误的因素，通过二分搜索法来查找一个排序的 vector 可能比查找一个标准关联容器要更快一点。 存储在 vector 中的数据必须是 pair\u003cK, V\u003e ，因为排序时它的元素的值将通过赋值操作被移动。 对 vector 做排序时，必须为 pair 写一个自定义的比较类型。（P85） ","date":"2023-09-15","objectID":"/posts/effective_stl_part_three/:5:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [3] | 关联容器","uri":"/posts/effective_stl_part_three/"},{"categories":["C++"],"content":"R24: 当效率至关重要时，请在 map::operator[] 与 map::insert 之间谨慎做出选择。 map::operator[]的功能是添加和更新，当map中没有[]中指定的键时，则加入一个新pair，如果[]中有指定的键时，则更新这个键的值。假如有一个map的值是Widget对象，键是一个简单类型（如int），Widget有一个默认无参构造函数和一个接受一个参数的有参构造函数和赋值构造函数。当map中没有相应的key时，map::insert是比map::operator[]更快的，因为map::operator[]会构造一个临时对象（调用无参构造函数），再将赋给他新值，而map::insert是直接调用有参构造函数。但是当map中有相应的key时，map::operator[]是比map::insert更快的，因为map::insert需要构造和析构对象，而map::operator[]不需要。 总结：当向映射表中添加元素时，要优先选用 insert 而不是 operator[]；当更新已经在映射表中的元素的值时，要优先选择 operator[]。 ","date":"2023-09-15","objectID":"/posts/effective_stl_part_three/:6:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [3] | 关联容器","uri":"/posts/effective_stl_part_three/"},{"categories":["C++"],"content":"R25: 熟悉非标准的散列容器 非标准的散列容器有 hash_map，hash_set，hash_multimap，hash_multiset SGI 的散列容器： template\u003ctypename T, typename HashFunction = hash\u003cT\u003e, typename CompareFunction = equal_to\u003cT\u003e, typename Allocator = allocator\u003cT\u003e \u003e class hash_set; 注意: 与标准关联容器不同， SGI 的散列容器使用 equal_to 作为默认的比较函数，通过测试两个对象是否相等而不是等价来决定容器中的两个对象是否相等。 SGI 的实现把表的元素放在一个单向链表中，而 Dinkumware 的实现则使用了双向链表。 ref: [1]. https://www.cnblogs.com/Sherry4869/p/15128250.html [2]. https://blog.csdn.net/zhuikefeng/article/details/108164117#t42 ","date":"2023-09-15","objectID":"/posts/effective_stl_part_three/:7:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [3] | 关联容器","uri":"/posts/effective_stl_part_three/"},{"categories":["C++"],"content":"前言 Effective-STL总结系列分为七部分，本文为第一部分，涉及原书第一章，内容范围Rule01~12。为方便书写，Rule12简写为R12。 Effective-STL系列List 本博客站点系列内容如下： 💡 Effective STL(第3版) 精读总结(一) 💡 Effective STL(第3版) 精读总结(二) 💡 Effective STL(第3版) 精读总结(三) 💡 Effective STL(第3版) 精读总结(四) ","date":"2023-09-10","objectID":"/posts/effective_stl_part_two/:0:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [2] | vector 和 string","uri":"/posts/effective_stl_part_two/"},{"categories":["C++"],"content":"R13 vector和string优先于动态分配的数组 如果使用动态分配的数组，意味着你需要承担三个责任: 首先必须确保最后会调用delete来释放申请的内存; 其次是必须确保使用了正确的delete形式，如果是分配了数组的话，应该使用delete[]; 最后必须确保只delete了一次，而不是多次。 而使用vector或者string就不需要承担这样的责任。 如果当前使用的string是以引用计数的方式实现的，而又运行在多线程环境中，并且string的引用计数实现会影响效率（有时会出现同步控制所花费的时间比避免内存分配和字符拷贝节约下来的时间还要多），那么你至少有三种选择方案，且没有一种是放弃使用string。 第一种是检查string实现，看看是否有可能禁止引用计数，通常是通过改变某个预处理变量的值。 第二种是寻找或开发不使用引用计数的string实现。 第三是考虑使用vector而不是string。 ","date":"2023-09-10","objectID":"/posts/effective_stl_part_two/:1:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [2] | vector 和 string","uri":"/posts/effective_stl_part_two/"},{"categories":["C++"],"content":"R14: 使用 reserve 来避免不必要的重新分配。 vector 和 string 的自动增长机制： 分配：分配一块大小为当前容量的某个倍数的新内存。vector 和 string 一般为 2. 把容器的所有元素从旧的内存复制到新的内存。 析构掉旧内存中的对象。 释放旧内存。 size()：告诉你该容器中有多少个元素。 capacity()：告诉你该容器利用已经分配的内存可以容纳多少个元素。这是容器所能容纳的元素总数。 resize(Container::size_type n)：强迫容器改变到包含 n 个元素的状态。在调用 resize 之后，size 将返回 n。 reserve(Container::size_type n)：强迫容器把它的容量变为至少是 n，前提是 n 不小于当前的大小。 使用 reserve，简单预留适合大小的空间，避免循环过程中发生重新分配： vector\u003cint\u003e v; v.reserve(1000); for (int i = 1; i \u003c= 1000; ++i) v.push_back(i); 对 push_back 的调用不会使 string 中的迭代器、指针和引用无效： string s; ... if (s.size() \u003c s.capacity()) { s.push_back('x'); } ","date":"2023-09-10","objectID":"/posts/effective_stl_part_two/:2:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [2] | vector 和 string","uri":"/posts/effective_stl_part_two/"},{"categories":["C++"],"content":"R15: 注意 string 实现的多样性。 每个 string 包含的信息： 字符串的大小（size），即它所包含的字符个数。 存储该字符串中字符的内存容量（capacity）。 字符串的值（value)，即构成该字符串的字符。 可选： 分配子的拷贝。 对值的引用计数。 实现A 实现A 实现A 实现A ","date":"2023-09-10","objectID":"/posts/effective_stl_part_two/:3:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [2] | vector 和 string","uri":"/posts/effective_stl_part_two/"},{"categories":["C++"],"content":"R16: 了解如何把 vector 和 string 数据传给旧的 API。 C++标准要求 vector 中的元素存储在连续的内存中，就像数组一样，所以可以直接得到容器中的数据指针。 对于 vector v; 表达式 v[0] 给出了一个引用，它是该向量中的第一个元素，所以 \u0026v[0] 是指向第一个元素的指针。 \u0026*v.begin() 等价于 \u0026v[0] 对于 string，由于 string 中的数据不一定存储在连续的内存中且 string 的内部表示不一定是以空字符结尾，需使用成员函数 c_str()。 ","date":"2023-09-10","objectID":"/posts/effective_stl_part_two/:4:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [2] | vector 和 string","uri":"/posts/effective_stl_part_two/"},{"categories":["C++"],"content":"R17: 使用 “swap 技巧” 除去多余的容量 shrink to fit：为了避免向量仍占用不再需要的内存，你希望有一种方法能把它的容量从以前的最大值缩减到当前需要的数量。 从 contestants 向量中除去多余的容量： vector\u003cContestant\u003e(contestants).swap(contestants); vector 的拷贝构造函数只为说拷贝的元素分配所需要的内存，所以这个临时变量没有多余的容量。 swap：临时变量的数据和 contestents 的数据做 swap 操作。在这之后，contestents 具有了被去除之后的容量，即原先临时变量的容量。临时变量随后被析构，从而释放先前为 contestents 所占据的内存。注意，迭代器、指针和引用也将被交换（string 除外）。 同样适用于 string string s; ... string(s).swap(s); 清除一个容器： vector\u003cContestant\u003e v; string s; ... vector\u003cContestant\u003e().swap(v);// 清除v并把它的容量变为最小 string().swap(s);// 清除s并把它的容量变为最小 ","date":"2023-09-10","objectID":"/posts/effective_stl_part_two/:5:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [2] | vector 和 string","uri":"/posts/effective_stl_part_two/"},{"categories":["C++"],"content":"R18: 避免使用 vector bool vector 是一个假的容器： 它不是一个 STL 容器。 它并不存储 bool。为了节省空间，它储存的是 bool 的紧凑表示——使用了与位域（bitfield）一样的思想，一个 8 位的字节可容纳 8 个 “bool”。你可以创建一个指向 bool 的指针，而指向单个位的指针则是不允许的。指向单个位的引用也是被禁止的。 vector::operator[] 返回一个对象，表现得像是一个指向单个位的引用，即所谓的代理对象（proxy object）。 vector 的替代方案： deque：deque 是一个 STL 容器，而且它确实存储 bool。但 deque 中元素的内存不是连续的。 bitset：bitset 不是 STL 容器，它的大小（元素的个数）在编译时就确定了，所以它不支持迭代器。与 vector 一样，它使用了一种紧凑表示，只为所包含的每个值提供一位空间。 总之，vector 是一个失败了的雄心勃勃的实验，它不完全满足 STL 容器的要求；你最好不要使用它；你可以使用 deque 和 bitset 来替代它，这两个数据结构几乎能做 vector 所能做的一切事情。 ref: [1]. https://www.cnblogs.com/Sherry4869/p/15128250.html [2]. https://blog.csdn.net/zhuikefeng/article/details/108164117#t42 ","date":"2023-09-10","objectID":"/posts/effective_stl_part_two/:6:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [2] | vector 和 string","uri":"/posts/effective_stl_part_two/"},{"categories":["C++"],"content":"一、 基础议题(Basics) ","date":"2023-09-06","objectID":"/posts/more_effective_c/:1:0","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款 1: 仔细区别 pointers和references 没有所谓的 null reference。一个 reference 必须总代表某个对象。所以如果你有一个变量，其目的是用来指向(代表)另一个对象，但是也有可能它不指向(代表)任何对象，那么你应该使用 pointer，因为你可以将 pointer设为 null。换个角度看，如果这个变量总是必须代表一个对象，也就是说如果你的设计并不允许这个变量为 null，那么你应该使用reference。 Pointers 和 references 之间的另一个重要差异就是，pointers 可以被重新赋值，指向另一个对象，reference 却总是指向(代表)它最初获得的那个对象。 一般而言，当你需要考虑“不指向任何对象”的可能性时，或是考虑“在不同时间指向不同对象”的能力时，你就应该采用 pointer。前一种情况你可以将 pointer设为 null，后一种情况你可以改变pointer 所指对象。而当你确定“总是会代表某个对象”，而且“一旦代表了该对象就不能够再改变”，那么你应该选用 reference。 当你知道你需要指向某个东西，而且绝不会改变指向其他东西，或是当你实现一个操作符而其语法需求无法由 pointers 达成，你就应该选择 references。任何其他时候，请采用 pointers。 在任何情况下都不能使用指向空值的引用。一个引用必须总是指向某些对象。在C++里，引用应被初始化。 不存在指向空值的引用这个事实意味着使用引用的代码效率比使用指针的要高。因为在使用引用之前不需要测试它的合法性。 指针与引用的另一个重要的不同是指针可以被重新赋值以指向另一个不同的对象。但是引用则总是指向在初始化时被指定的对象，以后不能改变。 关于引用的更多介绍参考: https://blog.csdn.net/fengbingchun/article/details/69820184 void printDouble(const double\u0026 rd) { std::cout\u003c\u003crd; // 不需要测试rd,它肯定指向一个double值 } void printDouble(const double* pd) { if (pd) { // 检查是否为NULL std::cout\u003c\u003c*pd; } } int test_item_1() { char* pc = 0; // 设置指针为空值 char\u0026 rc = *pc; // 让指针指向空值，这是非常有害的，结果将是不确定的 //std::string\u0026 rs; // 错误，引用必须被初始化 std::string s(\"xyzzy\"); std::string\u0026 rs = s; // 正确,rs指向s std::string* ps; // 未初始化的指针，合法但危险 { std::string s1(\"Nancy\"); std::string s2(\"Clancy\"); std::string\u0026 rs = s1; // rs引用s1 std::string* ps = \u0026s1; // ps指向s1 rs = s2; // rs仍旧引用s1,但是s1的值现在是\"Clancy\" ps = \u0026s2; // ps现在指向s2,s1没有改变 } std::vector\u003cint\u003e v(10); v[5] = 10; // 这个被赋值的目标对象就是操作符[]返回的值，如果操作符[] // 返回一个指针，那么后一个语句就得这样写: *v[5] = 10; return 0; } ","date":"2023-09-06","objectID":"/posts/more_effective_c/:1:1","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款 2: 最好使用 C++转型操作符 C++通过引进四个新的类型转换(cast)操作符克服了C风格类型转换的缺点(过于粗鲁，能允许你在任何类型之间进行转换；C风格的类型转换在程序语句中难以识别)，这四个操作符是: static_cast、const_cast、dynamic_cast、reinterpret_cast。 static_cast在功能上基本上与C风格的类型转换一样强大，含义也一样。它也有功能上限制。例如，不能用static_cast像用C 风格的类型转换一样把struct转换成int类型或者把double类型转换成指针类型，另外，static_cast不能从表达式中去除const属性，因为另一个新的类型转换操作符const_cast有这样的功能。 const_cast用于类型转换掉表达式的const或volatileness属性。如果你试图使用const_cast来完成修改constness或者volatileness属性之外的事情，你的类型转换将被拒绝。 dynamic_cast被用于安全地沿着类的继承关系向下进行类型转换。这就是说，你能用dynamic_cast把指向基类的指针或引用转换成指向其派生类或其兄弟类的指针或引用，而且你能知道转换是否成功。失败的转换将返回空指针(当对指针进行类型转换时)或者抛出异常(当对引用进行类型转换时)。dynamic_cast在帮助你浏览继承层次上是有限制的，它不能被用来缺乏虚函数的类型上，也不能用它来转换掉constness。如你想在没有继承关系的类型中进行转换，你可能想到static_cast。如果是为了去除const，你总得用const_cast。 reinterpret_cast使用这个操作符的类型转换，其转换结果几乎都是执行期定义(implementation-defined)。因此，使用reinterpret_cast的代码很难移植。此操作符最普通的用途就是在函数指针之间进行转换。 关于类型转换更多介绍参考: https://blog.csdn.net/fengbingchun/article/details/51235498 class Widget { public: virtual void func() {} }; class SpecialWidget : public Widget { public: virtual void func() {} }; void update(SpecialWidget* psw) {} void updateViaRef(SpecialWidget\u0026 rsw) {} typedef void (*FuncPtr)(); // FuncPtr是一个指向函数的指针 int doSomething() { return 1; }; int test_item_2() { int firstNumber = 1, secondNumber = 1; double result1 = ((double)firstNumber) / secondNumber; // C风格 double result2 = static_cast\u003cdouble\u003e(firstNumber) / secondNumber; // C++风格类型转换 SpecialWidget sw; // sw是一个非const对象 const SpecialWidget\u0026 csw = sw; // csw是sw的一个引用，它是一个const对象 //update(\u0026csw); // 错误，不能传递一个const SpecialWidget*变量给一个处理SpecialWidget*类型变量的函数 update(const_cast\u003cSpecialWidget*\u003e(\u0026csw)); // 正确，csw的const显示地转换掉(csw和sw两个变量值在update函数中能被更新) update((SpecialWidget*)\u0026csw); // 同上，但用了一个更难识别的C风格的类型转换 Widget* pw = new SpecialWidget; //update(pw); // 错误，pw的类型是Widget*，但是update函数处理的是SpecialWidget*类型 //update(const_cast\u003cSpecialWidget*\u003e(pw)); // 错误，const_cast仅能被用在影响constness or volatileness的地方，不能用在向继承子类进行类型转换 Widget* pw2 = nullptr; update(dynamic_cast\u003cSpecialWidget*\u003e(pw2)); // 正确，传递给update函数一个指针是指向变量类型为SpecialWidget的pw2的指针， 如果pw2确实指向一个对象，否则传递过去的将是空指针 Widget* pw3 = new SpecialWidget; updateViaRef(dynamic_cast\u003cSpecialWidget\u0026\u003e(*pw3)); // 正确，传递给updateViaRef函数SpecailWidget pw3指针，如果pw3确实指向了某个对象，否则将抛出异常 //double result3 = dynamic_cast\u003cdouble\u003e(firstNumber) / secondNumber; // 错误，没有继承关系 const SpecialWidget sw4; //update(dynamic_cast\u003cSpecialWidget*\u003e(\u0026sw4)); // 错误，dynamic_cast不能转换掉const FuncPtr funcPtrArray[10]; // funcPtrArray是一个能容纳10个FuncPtr指针的数组 //funcPtrArray[0] = \u0026doSomething; // 错误，类型不匹配 funcPtrArray[0] = reinterpret_cast\u003cFuncPtr\u003e(\u0026doSomething); // 转换函数指针的代码是不可移植的(C++不保证所有的函数指针都被用一样的方法表示)，在一些情况下这样的转换会产生不正确的结果，所以应该避免转换函数指针类型 return 0; } ","date":"2023-09-06","objectID":"/posts/more_effective_c/:1:2","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款 3: 绝对不要以多态(polymorphically)方式处理数组 C++允许你通过基类指针和引用来操作派生类数组。不过这根本就不是一个特性，因为这样的代码几乎从不如你所愿地那样运行。数组与多态不能用在一起。值得注意的是如果你不从一个具体类(concrete classes)(例如BST)派生出另一个具体类(例如BalancedBST)，那么你就不太可能犯这种使用多态性数组的错误。 原因: derived class 对象一般比base class对象小。所以当使用一个 base class数组存储derived class时，在访问 array[i] 时，会访问array+i*sizeof(base class)的地址，造成访问错误。 由base 指针删除一个derived class 数组，结果未定义。因为删除时，析构从最后一个开始，但是计算地址时跟tips1一样，造成访问错误。 class BST { public: virtual ~BST() { fprintf(stdout, \"BST::~BST\\n\"); } private: int score; }; class BalancedBST : public BST { public: virtual ~BalancedBST() { fprintf(stdout, \"BalancedBST::~BalancedBST\\n\"); } private: int length; int size; // 如果增加此一个int成员，执行test_item_3会segmentation fault，注释掉此变量，运行正常 }; int test_item_3() { fprintf(stdout, \"BST size: %d\\n\", sizeof(BST)); // 16 fprintf(stdout, \"BalancedBST size: %d\\n\", sizeof(BalancedBST)); // 24 BST* p = new BalancedBST[10]; delete [] p; // 如果sizeof(BST) != sizeof(BalancedBST)，则会segmentation fault return 0; } ","date":"2023-09-06","objectID":"/posts/more_effective_c/:1:3","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款 4: 避免无用的缺省构造函数 构造函数能初始化对象，而缺省构造函数则可以不利用任何在建立对象时的外部数据就能初始化对象。有时这样的方法是不错的。例如一些行为特性与数字相仿的对象被初始化为空值或不确定的值也是合理的，还有比如链表、哈希表、图等等数据结构也可以被初始化为空容器。但不是所有的对象都属于上述类型，对于很多对象来说，不利用外部数据进行完全的初始化是不合理的。比如一个没有输入姓名的地址薄对象，就没有任何意义。 利用指针数组代替一个对象数组这种方法有两个缺点: 第一你必须删除数组里每个指针所指向的对象。如果忘了，就会发生内存泄漏。第二增加了内存分配量，因为正如你需要空间来容纳EquipmentPiece对象一样，你也需要空间来容纳指针。 对于类里没有定义缺省构造函数还会造成它们无法在许多基于模板(template-based)的容器类里使用。因为实例化一个模板时，模板的类型参数应该提供一个缺省构造函数。在多数情况下，通过仔细设计模板可以杜绝对缺省构造函数的需求。 class EquipmentPiece { public: EquipmentPiece(int IDNumber) {} }; int test_item_4() { //EquipmentPiece bestPieces[10]; // 错误，没有正确调用EquipmentPiece构造函数 //EquipmentPiece* bestPieces2 = new EquipmentPiece[10]; // 错误，与上面的问题一样 int ID1 = 1, ID2 = 2; EquipmentPiece bestPieces3[] = { EquipmentPiece(ID1), EquipmentPiece(ID2) }; // 正确，提供了构造函数的参数 // 利用指针数组来代替一个对象数组 typedef EquipmentPiece* PEP; // PEP指针指向一个EquipmentPiece对象 PEP bestPieces4[10]; // 正确，没有调用构造函数 PEP* bestPieces5 = new PEP[10]; // 也正确 // 在指针数组里的每一个指针被重新赋值，以指向一个不同的EquipmentPiece对象 for (int i = 0; i \u003c 10; ++i) bestPieces5[i] = new EquipmentPiece(ID1); // 为数组分配raw memory,可以避免浪费内存，使用placement new方法在内存中构造EquipmentPiece对象 void* rawMemory = operator new[](10*sizeof(EquipmentPiece)); // make bestPieces6 point to it so it can be treated as an EquipmentPiece array EquipmentPiece* bestPieces6 = static_cast\u003cEquipmentPiece*\u003e(rawMemory); // construct the EquipmentPiece objects in the memory使用\"placement new\" for (int i = 0; i \u003c 10; ++i) new(\u0026bestPieces6[i]) EquipmentPiece(ID1); // ... // 以与构造bestPieces6对象相反的顺序解构它 for (int i = 9; i \u003e= 0; --i) bestPieces6[i].~EquipmentPiece(); // 如果使用普通的数组删除方法，程序的运行将是不可预测的 // deallocate the raw memory delete [] rawMemory; return 0; } ","date":"2023-09-06","objectID":"/posts/more_effective_c/:1:4","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"二、运算符(操作符) ","date":"2023-09-06","objectID":"/posts/more_effective_c/:2:0","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款 5: 谨慎定义类型转换函数 C++ 允许内置数据类型之间(例如char和int，int和double等)进行隐式转换，对于内置类型之间的隐式转换有详细的规则，但不管怎样，这些都是语言提供的，既相对安全，我们又无法更改。 对于自定义的类类型，隐式转换可以通过单参数构造函数(single-argument constructors)和隐式类型转换操作符来实现。所谓”单一自变量(单参数)指的是可以有多个参数，但除了第一个参数其他参数必须有默认实参)。所谓隐式类型转换操作符，是一个 member function: 关键词operator 之后加一个类型名称，例如: operator double() const; class Rational { public: ... operator double() const; // 将Rational 转换为 double } 这个函数会在以下情况被自动调用: Rational r(1, 2); // r的值是 1/2 double d = 0.5 * r; // 将r的值转换为double，然后执行运算。 但是下面这个情况就会出问题: std::cout \u003c\u003c r; 如果你忘了为 Rational 类重载一个 operator«，那么按道理应该打印不成功。但是编译器面对上述动作，它会想尽办法(包括找出一系列可接受的隐式类型转换)让函数调用动作成功。此时编译器发现 只需调用 Rational::operator double， 将 r 转换为 double，就可以成功调用 std::cout « r;，以浮点数的形式输出。 解决办法就是以功能对等的另一个函数取代类型转换操作符。即: 定义一个 doube asDouble() const;函数。虽然使用时有些许不便，但“可因为不再默默调用那些不打算调用的函数而获得弥补”。C++ 标准库中的 string 类从没有 string 到 char* 的隐式类型转换操作符而采用 c_str 函数可能就是这个原因。 拥有单个参数(或除第一个参数外都有默认值的多参数)构造函数的类，很容易被隐式类型转换，最好加上 explicit 防止隐式类型转换。 template\u003cclass T\u003e class Array{ public: Array(int size); T\u0026 operator[](int index); }; bool operator==(const Array\u003cint\u003e \u0026lhs, const Array\u003cint\u003e \u0026 rhs); Array\u003cint\u003e a(10), b(10); for(int i=0; i\u003c10; ++i){ if(a == b[i]){ //想要写 a[i] == b[i]，但是这时候编译器并不会报错 // do something } else{ // do something } } if(a == b[i]) 并不会报错。因为编译器发现只要调用 Array\\ constructor(需一个 int 作为自变量)，就可以把 int 转为 Array\\ object。就会产生类似这样的代码: if( a == static_cast\u003cArray\u003cint\u003e \u003e(b[i])) 将 b[i] 转为 Array。此时程序会正常运行，但是结果却不尽人意。 解决办法就是使用 C++ 特性: 关键词 explicit。这个特性之所以被导入，就是为了解决隐式类型转换带来的问题。explict Array(int size); 还有一种被称为 proxy classes 的方法: class Array { public: class ArraySize { // 这个类是新的 public: ArraySize(int numElements):theSize(numElements){} int size() const { return theSize;} private: int theSize; }; Array(int lowBound, int highBound); Array(ArraySize size); // 注意新的声明 ... }; 这样写的代码在 Array\\ a(10); 的时候，编译器会先通过类型转换将 int 转换成 ArraySize，然后再进行构造，虽然麻烦很多，效率也低了很多，但是在一定程度上可以避免隐式转换带来的问题。 对于自定义类型的类型转换，有一个规则: “没有任何一个转换程序可以内含一个以上的‘用户定制转换行为’(亦即单自变量constructor亦即隐式类型转换操作符)\"，也就是说，必要的时候编译器可以先进行内置类型之间的转换再调用带单自变量的构造函数或者先调用隐式类型转换操作符在进行内置类型之间的转换，但不可能连续进行两次用户定制的类型转换！ 所以 此时 if(a == b[i]) 就会报错。不能从 int 转换成 ArraySize，再从 ArraySize 转为 Array。 总结允许编译器执行隐式转换弊大于利，所以非必要不要提供转换函数！ ","date":"2023-09-06","objectID":"/posts/more_effective_c/:2:1","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款 6: 区别 increment/decrement 操作符的前置和后置形式s 由于 increment/decrement 操作符的前置和后置式都是一元运算符，没有参数。因此重载时通过在后置式中加一个 int 型参数(哑元参数)加以区分，当后置式被调用时，编译器自动在为该参数指定一个0值。 class UPInt{ public: UPInt\u0026 operator++(); // 前置式++ const UPInt operator++(int); // 后置式++ UPInt\u0026 operator--(); // 前置式-- const UPInt operator++(int); // 前置式-- } 前置累加操作符和后置累加操作符实现: // 前缀形式: 增加然后取回值 UPInt\u0026 UPInt::operator++() { *this += 1; // 增加 return *this; // 取回值 } // postfix form: fetch and increment const UPInt UPInt::operator++(int) { UPInt oldValue = *this; ++(*this); // 取回值 // 增加 return oldValue; // 返回被取回的值 } 前置式返回 reference，后置式返回 const 对象！ 后置 operator++(int) 的叠加是不允许的，即: i++++。 原因有两个: 一是与内建类型行为不一致(内建类型支持前置叠加)；二是其效果跟调用一次 operator++(int) 效果一样，这是违反直觉的。另外，后置式操作符使用 operator++(int)，参数的唯一目的只是为了区别前置式和后置式而已，当函数被调用时，编译器传递一个0作为int参数的值传递给该函数。 处理用户定制类型时，应该尽可能使用前置式。 后置式increment 和decrement 操作符的实现应以其前置式兄弟为基础。如此一来你就只需维护前置式版本，因为后置式版本会自动调整为一致的行为。 ","date":"2023-09-06","objectID":"/posts/more_effective_c/:2:2","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款 7: 千万不要重载\u0026\u0026，|| 和，操作符 C++ 对于“真假值表达式” 采用所谓的“短路” 评估方式(short-circuit evaluation)。意思是一旦该表达式的真价值确定，及时表达式中还以后部分尚未检验，整个评估工作仍然结束。 “函数调用”语义和所谓的“短路” 评估方式语义有两个重大的区别。第一，当函数调用动作被执行，所有参数值都必须评估完成，所以当我们调用 operator\u0026\u0026和 operator||时，两个参数都已评估完成。换句话说没有什么骤死式语义。第二，C++语言规范并未明确定义函数调用动作中各参数的评估顺序，所以没办法知道expression1 和 expression2 哪个会先被评估。这与骤死式评估法形成一个明确的对比，后者总是由左向右评估其自变量。 C++同样也有一些规则用来定义逗号操作符面对内建类型的行为。表达式如果内含逗号，那么逗号左侧会先被评估，然后逗号的右侧再被评估；最后，整个逗号表达式的结果以逗号右侧的值为代表。 你不能重载以下操作符: . .* :: ?: new delete sizeof typeid static_cast dynamic_cast const_cast reinterpret_cast ","date":"2023-09-06","objectID":"/posts/more_effective_c/:2:3","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款8: 了解各种不同意义的 new 和 delete new operator: new操作符，用于动态分配内存并进行初始化, 它的动作分为两方面。第一，它分配足够的内存，用来放置某类型的对象。以上例而言，它分配足够放置一个string 对象的内存。第二，它调用一个 constructor，为刚才分配的内存中的那个对象设定初值。; new operator，不能被重载 当你写出这样的代码: string *ps = new string(“Memory Mangement”); 你所使用的 new 是所谓的 new operator。它的动作分为两个方面: 1、分配足够的内存，用来放置某类型的对象；2、调用 constructor，为刚才的内存中的那个对象设定初值。 operator new: 标准库的函数，只分配内存不进行初始化(或者传递一个可用的内存地址)，可以自己进行重载，也可以主动调用。 和 malloc 一样，operator new 的唯一任务就是分配内存。 void *rawMemory = operator new(sizeof(string)); 返回值类型是 void* ！！！ 可以重载 operator new，但是第一个参数类型必须总是 size_t。 string *ps = new string(\"Memory Mangement\");等价于 void *rawMemory = operator new(sizeof(string)); // 取得原始内存，用来存放有一个string对象 call string::string(\"Memory Mangement\") on *memory; // 将内存中的对象初始化 string *ps = static_cast\u003cstring*\u003e(memory); // 让ps 指向新完成的对象 placement new (定位new): new operator的另外一种用法 ，在已分配的内存上构造对象; 注意 注意: new operator是操作符，placement new是这个操作符的一种用法，而operator new是标准库中的函数，new operator调用了 operator new。 将对象产生与 heap，请使用 new operator。它不但分配内存而且为该对象调用一个 constructor。 如果你只是打算分配内存，请调用 operator new，那就没有任何 constructor 会被调用。 如果你打算在 heap objects 产生时自己决定内存分配方式，请写一个自己的 operator new，并使用 new operator，它会自动调用你所写的 operator new。 如果你打算在已分配并拥有指针的内存中构造对象，请使用 placement new。 ","date":"2023-09-06","objectID":"/posts/more_effective_c/:2:4","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"三、 异常 程序之所以在 exceptions 出现时仍有良好行为，不是因为碰巧如此，而是因为它们加入了 exceptions 的考虑。 exceptions 无法被忽略。如果一个函数利用“设定状态变量”的方式或是利用“返回错误码”的方式发出一个异常信号，无法保证此函数的调用者会检查那个变量或检验那个错误码。于是程序的执行可能会一直继续下去，远离错误发生地点。但是如果函数以抛出 exception 的方式发出异常信号，而该 exception 未被捕捉，程序的执行便会立刻中止。 如果你需要一个“绝对不会被忽略的”异常信号发射方法，而且发射后的 stack处理过程又能够确保局部对象的 destructors 被调用，那么你需要 C++exceptions。它是最简单的方法了。 ","date":"2023-09-06","objectID":"/posts/more_effective_c/:3:0","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款 9: 利用 destructors 避免泄漏资源 每当 new 一个新的对象，一定要确保成功 delete 它，否则就会造成内存泄漏。 void processAdoptions(istream\u0026 dataSource){ while(dataSource){ ALA *pa = readALA(dataSource); // new 新的对象 pa-\u003eprocessAdoption(); // 处理事务 delete pa; // 删除pa指向的对象 } } 但是如果 pa-\u003eprocessAdoption();抛出异常，之后的所有语句都会被跳过，不再执行，这意味着 deleta pa;不会执行，造成内存泄漏。 解决方法1: void processAdoptions(istream\u0026 dataSource){ while(dataSource){ ALA *pa = readALA(dataSource); try{ pa-\u003eprocessAdoption(); } catch(...){ delete pa; //在抛出异常的时候避免泄露 throw; } delete pa; //在不抛出异常的时候避免泄 } } 因为这种情况会需要删除两次pa，代码维护很麻烦，所以需要进行优化: 只要我们能够将 “一定得执行的清理代码” 移到 processAdoptions 函数的某个局部对象的 destructors 内即可。因为局部对象总是会在函数结束时被析构，不论函数如何结束。 如何把 delete 动作从 processAdoptions 函数移到函数内的某个局部对象的 destructor 内: 以一个 “类似指针的对象(智能指针)”取代指针 pa。当这个类似指针的对象被(自动)销毁，我们可以令其 destructor 调用 delete。 void processAdoptions(istream\u0026 dataSource){ while(dataSource){ auto_ptr\u003cALA\u003e pa(readALA(dataSource)); // 现在auto_ptr已被弃用，推荐使用 shared_ptr!!! pa-\u003eprocessAdoption(); } } ","date":"2023-09-06","objectID":"/posts/more_effective_c/:3:1","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款 10: 在 constructors 内阻止资源泄漏(resource leak) 考虑下面的情况: BookEntry::BookEntry():theImage(0), theAudioClip(0){ theImage = new Image(imageFileName); theAudioClip = new AudioClip(audioClipFileName); } BookEntry::~BookEntry(){ delete theImage; delete theAudioClip; } 如果 theAudioClip = new AudioClip(audioClipFileName); 有 exception 抛出，那么函数构造失败，destructor 自然不会被调用。但是 theImage 对象构造成功了，这就导致 BookEntry constructor 所分配的 Image object 还是泄漏了。 由于C++ 不自动清理那些 “构造期间抛出 exceptions” 的对象，所以你必须设计你的 constructor，使得它们能够自动清理。通常只需将所有可能的 exceptions 捕捉起来，执行某种清理工作，然后重新抛出 exception，使它继续传播出去即可。 解决办法一: BookEntry::BookEntry(){ try{ theImage = new Image(imageFileName); theAudioClip = new AudioClip(audioClipFileName); } catch(...){ // 在构造函数内捕捉异常 delete theImage; delete theAudioClip; throw; } } 一个更好的解答是，接收条款9的忠告，将 theImage 和 theAudioClip 所指对象视为资源，交给局部对象来管理。 不论 theImage 和 theAudioClip 都是指向动态分配而得的对象，当指针本身停止活动，那些对象都应该被删除。 class BookEntry{ public:...... private: const auto_ptr\u003cImage\u003e theImage; // 同样的，现在auto_ptr已被弃用，推荐使用 shared_ptr!!! const auto_ptr\u003cAudioClip\u003e theAudioClip; } BookEntry::BookEntry(const string\u0026 imageFileName, const string\u0026 audioClipFileName): theImage(imageFileName != \"\" ? new Image(imageFileName) : 0), theAudioClip(audioClipFileName != \"\" ? new AudiaClip(audioClipFileName) : 0) {} 这样不仅解决了在 constructors 内阻止资源泄漏，而且还大幅简化 destructor。 BookEntry::~BookEntry(){} // 不需要做什么事！ ","date":"2023-09-06","objectID":"/posts/more_effective_c/:3:2","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款 11: 禁止异常(exceptions)流出destructors之外 两种情况下 destructor 会被调用。第一种情况是当对象在正常状态下被销毁，也就是当它离开了它的生存空间(scope)或是被明确地删除；第二种情况是当对象被 exception 处理机制——也就是exception 传播过程中的 stack-unwinding(栈展开)机制——销毁。 因为如果控制权基于 exception 的因素离开 destructor，而此时正有另一个 exception 处于作用状态，C++会调用 terminate 函数。此函数的作为正如其名: 将你的程序结束掉——它会立刻动手，甚至不等局部对象被销毁。 因此，有两个好理由支持我们“全力阻止exceptions传出 destructors之外”。第一，它可以避免 terminate函数在 exception传播过程的栈展开(stack-unwinding)机制中被调用；第二，它可以协助确保 destructors 完成其应该完成的所有事情。 如何避免exception传出destructor之外呢? 在析构函数中使用try{} catch(){}结构, 并且在catch的{}中什么也不做。 ","date":"2023-09-06","objectID":"/posts/more_effective_c/:3:3","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款12: 了解“抛出一个exception”与“传递一个参数”或“调用一个虚函数”之间的差异 你调用函数时，程序的控制权最终还会返回到函数的调用处，但是当你抛出一个异常时，控制权永远不会回到抛出异常的地方。 C++规范要求被作为异常抛出的对象必须被复制。即使被抛出的对象不会被释放，也会进行拷贝操作。抛出异常运行速度比参数传递要慢。 当异常对象被拷贝时，拷贝操作是由对象的拷贝构造函数完成的。该拷贝构造函数是对象的静态类型(static type)所对应类的拷贝构造函数，而不是对象的动态类型(dynamic type)对应类的拷贝构造函数。 catch子句中进行异常匹配时可以进行两种类型转换: 第一种是继承类与基类间的转换。一个用来捕获基类的catch子句也可以处理派生类类型的异常。这种派生类与基类(inheritance_based)间的异常类型转换可以作用于数值、引用以及指针上。 第二种是允许从一个类型化指针(typed pointer)转变成无类型指针(untyped pointer)，所以带有const void*指针的catch子句能捕获任何类型的指针类型异常。 catch子句匹配顺序总是取决于它们在程序中出现的顺序。因此一个派生类异常可能被处理其基类异常的catch子句捕获，即使同时存在有能直接处理该派生类异常的catch子句，与相同的try块相对应。不要把处理基类异常的catch子句放在处理派生类异常的catch子句的前面。 把一个对象传递给函数或一个对象调用虚拟函数与把一个对象作为异常抛出，这之间有三个主要区别: 第一，异常对象在传递时总被进行拷贝；当通过传值方式捕获时，异常对象被拷贝了两次。对象作为参数传递给函数时不一定需要被拷贝。 第二，对象作为异常被抛出与作为参数传递给函数相比，前者类型转换比后者要少(前者只有两种转换形式)。 最后一点，catch子句进行异常类型匹配的顺序是它们在源代码中出现的顺序，第一个类型匹配成功的catch将被用来执行。当一个对象调用一个虚拟函数时，被选择的函数位于与对象类型匹配最佳的类里，即使该类不是在源代码的最前头。 try_catch 介绍参考: https://blog.csdn.net/fengbingchun/article/details/65939258 ","date":"2023-09-06","objectID":"/posts/more_effective_c/:3:4","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款13: 以 by reference方式捕捉 exceptions catch by pointer的问题: 他们是否应该删除他们接受的指针？如果是在堆中建立的异常对象，那他们必须删除它，否则会造成资源泄漏。如果不是在堆中建立的异常对象，他们绝对不能删除它，否则程序的行为将不可预测。通过指针捕获异常，将遇到一个哈姆雷 特式的难题: 是删除还是不删除？这是一个难以回答的问题。所以你最好避开它。 catch by value的问题: 当它们被抛出时系统将对异常对象拷贝两次(参见条款 M12)。 当抛出的是派生类对象，但是用基类捕获，会场生slicing 问题。 catch by reference的优势: 如果 catch by reference，你就可以避开对象删除问题，你也可以避开 exception objects 的切割(slicing)问题；你可以保留捕捉标准 exceptions 的能力；你也约束了 exception objects 需被复制的次数。 通过指针捕获异常不符合C++语言本身的规范。四个标准的异常—-bad_alloc(当operator new不能分配足够的内存时被抛出)；bad_cast(当dynamic_cast针对一个引用(reference)操作失败时被抛出)；bad_typeid(当dynamic_cast对空指针进行操作时被抛出)；bad_exception(用于unexpected异常)—-都不是指向对象的指针，所以你必须通过值或引用来捕获它们。 std::exception的介绍参考: https://blog.csdn.net/fengbingchun/article/details/78303734 ","date":"2023-09-06","objectID":"/posts/more_effective_c/:3:5","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款14: 审慎使用异常规格(exception specifications) 如果一个函数抛出一个不在异常规格范围里的异常，系统在运行时能够检测出这个错误，然后一个特殊函数std::unexpected将被自动地调用(This function is automatically called when a function throws an exception that is not listed in its dynamic-exception-specifier.)。std::unexpected缺省的行为是调用函数std::terminate，而std::terminate缺省的行为是调用函数abort。应避免调用std::unexpected。 避免踏上 unexpected之路的第一个技术是: 不应该将 templates 和 exceptionspecifications 混合使用。 避免踏上 unexpected之路的第二个技术是: 如果A 函数内调用了 B 函数，而B 函数无 exceptionspecifications，那么 A 函数本身也不要设定exception specifications。 避免踏上 unexpected 之路的第三个技术是: 处理“系统”可能抛出的exceptions。其中最常见的就是 bad_alloc，那是在内存分配失败时由operator new和 operator new[]抛出的(见条款8)。 ","date":"2023-09-06","objectID":"/posts/more_effective_c/:3:6","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款15: 了解异常处理的系统开销 异常功能是需要一定开销的,即使是完全没有进行使用,虽然在某些情况下可以进行异常功能的关闭,但前提是,当前的所有代码所有模块都没有进行异常功能的使用,一旦有一个模块使用了异常,将导致程序无法运行. 抛出异常这个工作是比较消耗资源的,相对于平常的函数返回值,大约是3倍的资源消耗,但是不必恐慌,除非将异常作为了一种常规手段,否则偶尔的使用基本是不会影响整体效率的 异常功能整体上会使程序变大 5%~10%,同时也一定比例的减慢程序的运行速度. 这就是异常处理的系统开销。 ","date":"2023-09-06","objectID":"/posts/more_effective_c/:3:7","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"四、效率 本章的内容从两个角度阐述效率的问题。 第一是从语言独立的角度，关注那些你能在任何语言里都能使用的东西。C++为它们提供了特别吸引人的实现途径，因为它对封装的支持非常好，从而能够用更好的算法与数据结构来替代低效的类似实现，同时接口可以保持不变。 第二是关注 C++语言本身。高性能的算法与数据结构虽然非常好，但如果实 际编程中代码实现得很粗糙，效率也会降低得相当多。潜在危害性最大的错误是 既容易犯而又不容易察觉的错误，濒繁地构造和释放大量的对象就是一种这样的 错误。过多的对象构造和对象释放对于你的程序性能来说就象是在大出血，在每 次建立和释放不需要的对象的过程中，宝贵的时间就这么流走了。这个问题在 C++程序中很普遍，我将用四个条款来说明这些对象从哪里来的，在不影响程序 代码正确性的基础上又如何消除它们。 ","date":"2023-09-06","objectID":"/posts/more_effective_c/:4:0","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款16: 谨记 80-20 法则 80-20准则说的是大约20%的代码使用了80%的程序资源；大约20%的代码耗用了大约80%的运行时间；大约20%的代码使用了80%的内存；大约20%的代码执行80%的磁盘访问；80%的维护投入于大约20%的代码上。 基本的观点: 软件整体的性能取决于代码组成中的一小部分。一个程序大量的资源是消耗在少部分的代码上面,所有的程序都符合这个规则,所以,我们要做的并不是对每一处代码都进行优化,虽然这么做固然很好,但是每个人的能力和精力是一个固定值,一味的优化80%部分的代码,提升的效果可能达不到20%中的几行代码,我们要善于利用各种工具,找到真正需要进行优化的逻辑,然后去进行优化. ","date":"2023-09-06","objectID":"/posts/more_effective_c/:4:1","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款17: 考虑使用 lazy evaluation(缓式评估) lazy evaluation(缓式评估)。一旦你采用 lazy evaluation，就是以某种方式撰写你的 classes，使它们延缓运算，直到那些运算结果刻不容缓地被迫切需要为止。如果其运算结果一直不被需要，运算也就一直不执行。 引用计数 这种“数据共享”的行动细节(及相应代码)在条款 29有详细叙述，其观念便是 lazy evaluation：在你真正需要之前，不必着急为某物做一个副本。取而代之的是，以拖延战术应付之——只要能够，就使用其他副本。在某些应用领域，你常有可能永远不需要提供那样一个副本。 区别对待读取和写入 string s = \"Homer's liad\"; ... cout \u003c\u003c s[3]; s[3] = 'x'; 首先调用 operator[]用来读取 string 的部分值，但是第二次调用该函数是为了完成写操作。我们应能够区别对待读调用和写调用，因为读取reference-counted string 是很容易的，而写入这个 string 则需要在写入前对该string 值制作一个新拷贝。 为了能够这样做，需要在 operator[]里采取不同的措施(根据是为了完成读取操作而调用该函数还是为了完成写入操作而调用该函数)。我们如果判断调用 operator[]的 context 是读取操作还是写入操作呢？残酷的事实是我们不可能判断出来。通过使用 lazy evaluation 和条款 M30 中讲述的proxy class，我们可以推迟做出是读操作还是写操作的决定，直到我们能判断出正确的答案。 Lazy Fetching (懒惰提取) 实现 lazy fetching 时，你必须面对一个问题：null 指针可能会在任何 member functions(包括const member functions，如 field1)内被赋值，以指向真正的数据。然而当你企图在 constmember functions 内修改 data members，编译器不会同意。所以你必须用某种方法告诉编译器说：“放轻松，我知道我正在干什么”。说这句话的最好方法就是将指针字段声明为 mutable，意思是这样的字段可以在任何member function 内被修改，甚至是在 const member functions 内(见条款 E21)。 Lazy Expression Evaluation(懒惰表达式计算) lazy evaluation 在许多领域中都可能有用途：可避免非必要的对象复制，可区别 operator[]的读取和写动作，可避免非必要的数据库读取动作，可避免非必要的数值计算动作。 ","date":"2023-09-06","objectID":"/posts/more_effective_c/:4:2","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款18: 分期摊还预期的计算成本 现在我鼓励你改善软件性能的方法是：令你的代码超前进度地做“要求以外”的更多工作。此条款背后的哲学可称为超急评估(over-eager evaluation): 在被要求之前就先把事情做下去。 Over-eager evaluation 背后的观念是，如果你预期程序常常会用到某个计算，你可以降低每次计算的平均成本，办法就是设计一份数据结构以便能够极有效率地处理需求。 Caching 是“分期摊还预期计算之成本”的一种做法,即caching(缓存)那些已经被计算出来而以后还有可能需要的值。 Prefetching(预先取出)是另一种做法。Prefetch需要空间放置被 prefetch 的东西，但是它减少了访问它们所需 的时间。 以上两种方法都是通过以空间换时间的方式来提高代码的运行效率。 可通过over-eager evaluation 如 caching和prefetching 等做法分期摊还预期运算成本——和我在条款 17 所提的 lazy evaluation 并不矛盾。当你必须支持某些运算而其结果并不总是需要的时候，lazy evaluation 可以改善程序效率。当你必须支持某些运算而其结果几乎总是被需要，或其结果常常被多次需要的时候，over-eager evaluation 可以改善程序效率。 ","date":"2023-09-06","objectID":"/posts/more_effective_c/:4:3","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款19: 理解临时对象的来源 size_t countChar(const std::string\u0026 str, char ch) { // 建立一个string类型的临时对象，通过以buffer做为参数调用string的构造函数来初始化这个临时对象, // countChar的参数str被绑定在这个临时的string对象上，当countChar返回时，临时对象自动释放 // 将countChar(const std::string\u0026 str, char ch)修改为countChar(std::string\u0026 str, char ch)则会error return 1; } #define MAX_STRING_LEN 64 int test_item_19() { char buffer[MAX_STRING_LEN]; char c; std::cin \u003e\u003e c \u003e\u003e std::setw(MAX_STRING_LEN) \u003e\u003e buffer; std::cout\u003c\u003c\"There are \"\u003c\u003ccountChar(buffer, c)\u003c\u003c\" occurrences of the character \"\u003c\u003cc\u003c\u003c\" in \"\u003c\u003cbuffer\u003c\u003cstd::endl; return 0; } C++真正的所谓的临时对象是不可见的——不会在你的源代码中出现。只要你产生一个 non-heap object(非堆对象) 而没有为它命名，便诞生了一个临时对象。此等匿名对象通常发生于两种情况：一是当隐式类型转换(implicit type conversions)被施行起来以求函数调用能够成功；二是当函数返回对象的时候。 仅当通过传值(by value)方式传递对象或传递常量引用(reference-to-const)参数时，才会发生这些类型转换。当传递一个非常量引用(reference-to-non-const)参数对象，就不会发生。 C++语言禁止为**非常量引用(reference-to-non-const)**产生临时对象。 在这些优化策略中，最常见也最有用的就是所谓的“返回值优化(return value optimization)”。 临时对象可能很耗成本，所以你应该尽可能消除它们。然而更重要的是，如何训练出锐利的眼力，看出可能产生临时对象的地方。任何时候只要你看到一个 reference-to-const 参数，就极可能会有一个临时对象被产生出来绑定至该参数上。任何时候只要你看到函数返回一个对象，就会产生临时对象(并于稍后销毁)。 ","date":"2023-09-06","objectID":"/posts/more_effective_c/:4:4","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款20: 协助完成返回值优化 (RVO) class Rational20 { public: Rational20(int numerator = 0, int denominator = 1) {} int numerator() const { return 1; } int denominator() const { return 2; } }; const Rational20 operator*(const Rational20\u0026 lhs, const Rational20\u0026 rhs) { // 以某种方法返回对象，能让编译器消除临时对象的开销：这种技巧是返回constructor argument而不是直接返回对象 return Rational20(lhs.numerator() * rhs.numerator(), lhs.denominator() * rhs.denominator()); } int test_item_20() { Rational20 a = 10; Rational20 b(1, 2); Rational20 c = a * b; return 0; } 我们可以用某种特殊写法来撰写函数，使它在返回对象时，能够让编译器消除临时对象的成本。我们的伎俩是：返回所谓的 constructor arguments以取代对象。 此特殊的优化行为——利用函数的 return 点消除一个局部临时对象（并可能用函数调用端的某对象取代）——不但广为人知而且很普遍地被实现出来。它甚至有个专属名称：return value optimization。 ","date":"2023-09-06","objectID":"/posts/more_effective_c/:4:5","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款21: 通过重载避免隐式类型转换 class UPInt21 { // unlimited precision integers class public: UPInt21() {} UPInt21(int value) {} }; const UPInt21 operator+(const UPInt21\u0026 lhs, const UPInt21\u0026 rhs) // add UPInt21+UPInt21 { return UPInt21(1); } const UPInt21 operator+(const UPInt21\u0026 lhs, int rhs) // add UPInt21+int { return UPInt21(1); } const UPInt21 operator+(int lhs, const UPInt21\u0026 rhs) // add int+UPInt21 { return UPInt21(1); } int test_item_21() { UPInt21 upi1, upi2; UPInt21 upi3 = upi1 + upi2; // 正确，没有由upi1或upi2生成临时对象 upi3 = upi1 + 10; // 正确,没有由upi1或10生成临时对象 upi3 = 10 + upi2; // 正确，没有由10或upi2生成临时对象 // 注意：注释掉上面的operator+(UPInt21\u0026, int)和operator+(int, UPInt21\u0026)也正确，但是会通过临时对象把10转换为UPInt21 return 0; } 在C++中有一条规则是每一个重载的operator必须带有一个用户定义类型(user-defined type)的参数。 利用重载避免临时对象的方法不只是用在operator函数上。 没有必要实现大量的重载函数，除非你有理由确信程序使用重载函数以后其整体效率会有显著的提高。 ","date":"2023-09-06","objectID":"/posts/more_effective_c/:4:6","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款22: 考虑用运算符的赋值形式(op=)取代其单独形式(op) class Rational22 { public: Rational22(int numerator = 0, int denominator = 1) {} Rational22\u0026 operator+=(const Rational22\u0026 rhs) { return *this; } Rational22\u0026 operator-=(const Rational22\u0026 rhs) { return *this; } }; // operator+根据operator+=实现 const Rational22 operator+(const Rational22\u0026 lhs, const Rational22\u0026 rhs) { return Rational22(lhs) += rhs; } // operator-根据operator-=实现 const Rational22 operator-(const Rational22\u0026 lhs, const Rational22\u0026 rhs) { return Rational22(lhs) -= rhs; } 就C++来说，operator+、operator=和operator+=之间没有任何关系，因此如果你想让三个operator同时存在并具有你所期望的关系，就必须自己实现它们。同理，operator-, *, /, 等等也一样。 要确保操作符的复合形式（例如，operator+=）和其独身形式（例如，operator+）之间的自然关系能够存在，一个好方法就是以前者为基础实现后者（见条款 6）。 3 个与效率有关的情况值得注意: 第一，一般而言，复合操作符比其对应的独身版本效率高，因为独身版本通常必须返回一个新对象，而我们必须因此负担一个临时对象的构造和析构成本（见条款 19和 20及条款 E23）。至于复合版本则是直接将结果写入其左端自变量，所以不需要产生一个临时对象来放置返回值。 第二，如果同时提供某个操作符的复合形式和独身形式，便允许你的客户在效率与便利性之间做取舍（虽然那是极其困难的抉择）。 第三、自古以来匿名对象总是比命名对象更容易被消除，所以当你面临命名对象或临时对象的抉择时，最好选择临时对象。它应该绝不会比其命名兄弟耗用更多成本，反倒是极有可能降低成本（尤其在搭配旧式编译器时）。 ","date":"2023-09-06","objectID":"/posts/more_effective_c/:4:7","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款23: 考虑使用其他程序库 不同的程序库在效率、可扩展性、移植性、类型安全和其它一些领域上蕴含着不同的设计理念，通过变换使用给予性能更多考虑的程序库，你有时可以大幅度地提供软件的效率。 重点是，不同的程序库即使提供相似的机能，也往往表现出不同的性能取舍策略，所以一旦你找出程序的瓶颈（通过分析器，见条款16），你应该思考是否有可能因为改用另一个程序库而移除了那些瓶颈。 ","date":"2023-09-06","objectID":"/posts/more_effective_c/:4:8","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款24: 理解虚拟函数、多继承、虚基类和RTTI所需的代码 当调用一个虚拟函数时，被执行的代码必须与调用函数的对象的动态类型相一致；指向对象的指针或引用的类型是不重要的。大多数编译器是使用virtual table和virtual table pointers，通常被分别地称为vtbl和vptr。 一个vtbl通常是一个函数指针数组。(一些编译器使用链表来代替数组，但是基本方法是一样的)在程序中的每个类只要声明了虚函数或继承了虚函数，它就有自己的vtbl，并且类中vtbl的项目是指向虚函数实现体的指针。例如，如下这个类定义: class C1 { public: C1(); virtual ~C1(); virtual void f1(); virtual int f2(char c) const; virtual void f3(const string\u0026 s); void f4() const; ... }; C1 的 virtual table 数组看起来如下图所示： vtbl 通常是一个由“函数指针”架构而成的数组。某些编译器会以链表（linked list）取代数组，但其基本策略相同。程序中的每一个class 凡声明（或继承）虚函数者，都有自己的一个 vtbl，而其中的条目（entries）就是该 class 的各个虚函数实现体的指针。 这份讨论带出虚函数的第一个成本：你必须为每个拥有虚函数的class耗费一个vtbl 空间，其大小视虚函数的个数（包括继承而来的）而定。类的vtbl的大小与类中声明的虚函数的数量成正比(包括从基类继承的虚函数)。每个类应该只有一个virtual table，所以virtual table所需的空间不会太大，但是如果你有大量的类或者在每个类中有大量的虚函数，你会发现vtbl会占用大量的地址空间。 Virtual tables 只是虚函数实现机构的一半而已。如果只有它，不能成气候。一旦有某种方法可以指示出每个对象相应于哪一个 vtbl，vtbl 才真的有用。而这正是virtual table pointer（vptr）的任务。 关于虚函数表的介绍参考：https://blog.csdn.net/fengbingchun/article/details/79592347 凡声明有虚函数的 class，其对象都含有一个隐藏的 data member，用来指向该class 的 vtbl。这个隐藏的 data member——所谓的vptr——被编译器加入对象内某个唯编译器才知道的位置。 此刻，只需注意到虚函数的第二个成本：你必须在每一个拥有虚函数的对象内付出“一个额外指针”的代价。 编译器必须产生代码，完成以下动作： 1.根据对象的 vptr 找出其 vtbl。这是一个简单的动作，因为编译器知道到对象的哪里去找出 vptr（毕竟那个位置正是编译器决定的）。成本只有一个偏移调整（offset adjustment，以便获得 vptr）和一个指针间接动作（以便获得 vtbl）。 2.找出被调用函数（本例为 f1）在 vtbl 内的对应指针。这也很简单，因为编译器为每个虚函数指定了一个独一无二的表格索引。本步骤的成本只是一个差移（offset）以求进入 vtbl 数组。 3.调用步骤 2所得指针所指向的函数。 一些原因导致现在的编译器一般总是忽略虚函数的inline指令。虚函数真正的运行时期成本发生在和 inlining 互动的时候。对所有实用目的而言，虚函数不应该 inlined。因为“inline”意味“在编译期，将调用端的调用动作被调用函数的函数本体取代”，而“virtual”则意味着“等待，直到运行时期才知道哪个函数被调用”。(这是因为”内联”是指”在编译期间用被调用的函数体本身来代替函数调用的指令”，但是虚函数的”虚”是指”直到运行时才能知道要调用的是哪一个函数”。) 当编译器面对某个调用动作，却无法知道哪个函数该被调用时，你就可以了解为什么它们没有能力将该函数调用加以 inlining了。这便是虚函数的第三个成本：你事实上等于放弃了 inlining。 运行时期类型辨识（runtime typeidentification，RTTI）的成本。RTTI 让我们得以在运行时期获得 objects 和 classes 的相关信息，所以一定得有某些地方用来存放那些信息才行——是的，它们被存放在类型为 type_info 的对象内。你可以利用 typeid 操作符取得某个class 相应的 type_info 对象。 C++规范书上说，只有当某种类型拥有至少一个虚函数，才保证我们能够检验该类型对象的动态类型。这使得 RTTI 相关信息听起来有点像一个 vtbl：面对一个 class，我们只需一份相关信息，而我们需要某种方法，让任何一个内含虚函数的对象都有能力取得其专属信息。RTTI 和vtbl 之间的这种平行关系并非偶发，RTTI 的设计理念是：根据 class 的 vtbl来实现。 关于typeid的使用参考：https://blog.csdn.net/fengbingchun/article/details/51866559 RTTI被设计为在类的vtbl基础上实现。 ","date":"2023-09-06","objectID":"/posts/more_effective_c/:4:9","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"五、技术 (Techniques，Idioms，Patterns) ","date":"2023-09-06","objectID":"/posts/more_effective_c/:5:0","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款25: 将构造函数和非成员函数虚拟化 由于它产生新对象，所以行为仿若 constructor，但它能够产生不同类型的对象，所以我们称它为一个 virtual constructor。所谓 virtualconstructor 是某种函数，视其获得的输入，可产生不同类型的对象。Virtual constructors 在许多情况下有用，其中之一就是从磁盘（或网络或磁带等）读取对象信息。 有一种特别的 virtual constructor——所谓 virtual copyconstructor——也被广泛地运用。Virtual copy constructor 会返回一个指针，指向其调用者（某对象）的一个新副本。基于这种行为，virtual copy constructors 通常以 copySelf 或cloneSelf 命名，或者像下面一样命名为 clone。 当 derived class 重新定义其base class 的一个虚函数时，不再需要一定得声明与原本相同的返回类型。如果函数的返回类型是个指针（或reference），指向一个base class，那么 derived class 的函数可以返回一个指针（或reference），指向该 base class 的一个 derived class。 既然一个函数能够构造出不同类型的新对象是可以理解的，那么同样也存在这样的非成员函数，可以根据参数的不同动态类型而其行为特性也不同。 ","date":"2023-09-06","objectID":"/posts/more_effective_c/:5:1","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款26: 限制某个类所能产生的对象数量 每当即将产生一个对象，我们确知一件事情：会有一个 constructor被调用。“阻止某个 class 产出对象”的最简单方法就是将其constructors 声明为 private。 ","date":"2023-09-06","objectID":"/posts/more_effective_c/:5:2","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款27: 要求（或禁止）对象产生于 heap之中 所谓 abstract base class是一个不能够被实例化的 base class。也就是说它至少有一个纯虚函数。所谓 mixin（“mix in”）class则提供一组定义完好的能力，能够与其derived class所可能提供的其他任何能力（条款 E7）兼容。如此的 classes几乎总是abstract。我们于是可以形成一个所谓的 abstract mixin base class，用来为 derivedclasses提供“判断某指针是否以 operator new 分配出来”的能力。 ","date":"2023-09-06","objectID":"/posts/more_effective_c/:5:3","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款28: 灵巧(smart)指针 当你以 smart pointers 取代 C++的内建指针（亦即所谓的 dumbpointers），你将获得以下各种指针行为的控制权： 构造和析构（Construction and Destruction）。你可以决定smart pointer 被产生以及被销毁时发生什么事。通常我们会给smart pointers 一个默认值 0，以避免“指针未获初始化”的头痛问题。某些 smart pointers 有责任删除它们所指的对象——当指向该对象的最后一个 smart pointer 被销毁时。这是消除资源泄漏问题的一大进步。 复制和赋值（Copying and Assignment）。当一个 smartpointer 被复制或涉及赋值动作时，你可以控制发生什么事。某些smart pointer 会希望在此时刻自动为其所指之物进行复制或赋值动作，也就是执行所谓的深复制（deep copy）。另一些 smartpointer则可能只希望指针本身被复制或赋值就好。还有一些则根本不允许复制和赋值。不论你希望什么样的行为，smart pointers 都可以让你如愿。 解引（Dereferencing）。当 client 解引（取用）smart pointer所指之物时，你有权决定发生什么事情。例如你可以利用 smartpointers 协助实现出条款 17所说的 lazy fetching 策略。 Smart pointer的构造行为通常明确易解：确定一个目标物（通常是利用smart pointer的 constructor自变量），然后让 smart pointer内部的 dumb pointer指向它。如果尚未决定目标物，就将内部指针设为 0，或是发出一个错误消息（可能是抛出 exception）。 重点很简单：不要提供对 dumb pointers的隐式转换操作符，除非不得已。 大多数灵巧指针模板如下: // 大多数灵巧指针模板 template\u003cclass T\u003e class SmartPtr { public: SmartPtr(T* realPtr = 0); // 建立一个灵巧指针指向dumb pointer(内建指针)所指的对象，未初始化的指针，缺省值为0(null) SmartPtr(const SmartPtr\u0026 rhs); // 拷贝一个灵巧指针 ~SmartPtr(); // 释放灵巧指针 // make an assignment to a smart ptr SmartPtr\u0026 operator=(const SmartPtr\u0026 rhs); T* operator-\u003e() const; // dereference一个灵巧指针以访问所指对象的成员 T\u0026 operator*() const; // dereference灵巧指针 private: T* pointee; // 灵巧指针所指的对象 }; 灵巧指针是一种外观和行为都被设计成与内建指针相类似的对象，不过它能提供更多的功能。它们有许多应用的领域，包括资源管理和重复代码任务的自动化。 在C++11中auto_ptr已经被废弃，用unique_ptr替代。 std::unique_ptr的使用参考：https://blog.csdn.net/fengbingchun/article/details/52203664 ","date":"2023-09-06","objectID":"/posts/more_effective_c/:5:4","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款29: Reference counting（引用计数） class String { public: String(const char* initValue = \"\"); String(const String\u0026 rhs); String\u0026 operator=(const String\u0026 rhs); const char\u0026 operator[](int index) const; // for const String char\u0026 operator[](int index); // for non-const String ~String(); private: // StringValue的主要目的是提供一个空间将一个特别的值和共享此值的对象的数目联系起来 struct StringValue { // holds a reference count and a string value int refCount; char* data; bool shareable; // 标志，以指出它是否为可共享的 StringValue(const char* initValue); ~StringValue(); }; StringValue* value; // value of this String }; String::String(const char* initValue) : value(new StringValue(initValue)) {} String::String(const String\u0026 rhs) { if (rhs.value-\u003eshareable) { value = rhs.value; ++value-\u003erefCount; } else { value = new StringValue(rhs.value-\u003edata); } } String\u0026 String::operator=(const String\u0026 rhs) { if (value == rhs.value) { // do nothing if the values are already the same return *this; } if (value-\u003eshareable \u0026\u0026 --value-\u003erefCount == 0) { // destroy *this's value if no one else is using it delete value; } if (rhs.value-\u003eshareable) { value = rhs.value; // have *this share rhs's value ++value-\u003erefCount; } else { value = new StringValue(rhs.value-\u003edata); } return *this; } const char\u0026 String::operator[](int index) const { return value-\u003edata[index]; } char\u0026 String::operator[](int index) { // if we're sharing a value with other String objects, break off a separate copy of the value fro ourselves if (value-\u003erefCount \u003e 1) { --value-\u003erefCount; // decrement current value's refCount, becuase we won't be using that value any more value = new StringValue(value-\u003edata); // make a copy of the value for ourselves } value-\u003eshareable = false; // return a reference to a character inside our unshared StringValue object return value-\u003edata[index]; } String::~String() { if (--value-\u003erefCount == 0) { delete value; } } String::StringValue::StringValue(const char* initValue) : refCount(1), shareable(true) { data = new char[strlen(initValue) + 1]; strcpy(data, initValue); } String::StringValue::~StringValue() { delete[] data; } // 基类，任何需要引用计数的类都必须从它继承 class RCObject { public: void addReference() { ++refCount; } void removeReference() { if (--refCount == 0) delete this; } // 必须确保RCObject只能被构建在堆中 void markUnshareable() { shareable = false; } bool isShareable() const { return shareable; } bool isShared() const { return refCount \u003e 1; } protected: RCObject() : refCount(0), shareable(true) {} RCObject(const RCObject\u0026 rhs) : refCount(0), shareable(true) {} RCObject\u0026 operator=(const RCObject\u0026 rhs) { return *this; } virtual ~RCObject() = 0; private: int refCount; bool shareable; }; RCObject::~RCObject() {} // virtual dtors must always be implemented, even if they are pure virtual and do nothing // template class for smart pointers-to-T objects. T must support the RCObject interface, typically by inheriting from RCObject template\u003cclass T\u003e class RCPtr { public: RCPtr(T* realPtr = 0) : pointee(realPtr) { init(); } RCPtr(const RCPtr\u0026 rhs) : pointee(rhs.pointee) { init(); } ~RCPtr() { if (pointee) pointee-\u003eremoveReference(); } RCPtr\u0026 operator=(const RCPtr\u0026 rhs) { if (pointee != rhs.pointee) { // skip assignments where the value doesn't change if (pointee) pointee-\u003eremoveReference(); // remove reference to current value pointee = rhs.pointee; // point to new value init(); // if possible, share it else make own copy } return *this; } T* operator-\u003e() const { return pointee; } T\u0026 operator*() const { return *pointee; } private: T* pointee; // dumb pointer this object is emulating void init() // common initialization { if (pointee == 0) // if the dumb pointer is null, so is the smart one return; if (pointee-\u003eisShareable() == false) // if the value isn't shareable copy it pointee = new T(*pointee); pointee-\u003eaddReference(); // note that there is now a new reference to the value } }; // 将StringValue修改为是从RCObject继承 // 将引用计数功能移入一个新类(RCObject)，增加了灵巧指针(RCPtr)来自动处理引用计数 class String2 { public: String2(const char* value = \"\") : value(new StringValu","date":"2023-09-06","objectID":"/posts/more_effective_c/:5:5","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款30: Proxy classes（替身类、代理类） template\u003cclass T\u003e class Array2D { // 使用代理实现二维数组 public: Array2D(int i, int j) : i(i), j(j) { data.reset(new T[i*j]); } class Array1D { // Array1D是一个代理类，它的实例扮演的是一个在概念上不存在的一维数组 public: Array1D(T* data) : data(data) {} T\u0026 operator[](int index) { return data[index]; } const T\u0026 operator[](int index) const { return data[index]; } private: T* data; }; Array1D operator[](int index) { return Array1D(data.get()+j*index); } const Array1D operator[](int index) const { return Array1D(data.get()+j*index); } private: std::unique_ptr\u003cT[]\u003e data; int i, j; }; // 可以通过代理类帮助区分通过operator[]进行的是读操作还是写操作 class String30 { public: String30(const char* value = \"\") : value(new StringValue(value)) {} class CharProxy { // proxies for string chars public: CharProxy(String30\u0026 str, int index) : theString(str), charIndex(index) {} CharProxy\u0026 operator=(const CharProxy\u0026 rhs) { // if the string is haring a value with other String objects, // break off a separate copy of the value for this string only if (theString.value-\u003eisShared()) theString.value = new StringValue(theString.value-\u003edata); // now make the assignment: assign the value of the char // represented by rhs to the char represented by *this theString.value-\u003edata[charIndex] = rhs.theString.value-\u003edata[rhs.charIndex]; return *this; } CharProxy\u0026 operator=(char c) { if (theString.value-\u003eisShared()) theString.value = new StringValue(theString.value-\u003edata); theString.value-\u003edata[charIndex] = c; return *this; } operator char() const { return theString.value-\u003edata[charIndex]; } private: String30\u0026 theString; int charIndex; }; const CharProxy operator[](int index) const // for const String30 { return CharProxy(const_cast\u003cString30\u0026\u003e(*this), index); } CharProxy operator[](int index) // for non-const String30 { return CharProxy(*this, index); } //friend class CharProxy; private: // StringValue的主要目的是提供一个空间将一个特别的值和共享此值的对象的数目联系起来 struct StringValue : public RCObject { // holds a reference count and a string value char* data; StringValue(const char* initValue) { init(initValue); } StringValue(const StringValue\u0026 rhs) { init(rhs.data); } void init(const char* initValue) { data = new char[strlen(initValue) + 1]; strcpy(data, initValue); } ~StringValue() { delete [] data; } }; RCPtr\u003cStringValue\u003e value; // value of this String30 }; int test_item_30() { Array2D\u003cfloat\u003e data(10, 20); fprintf(stdout, \"%f\\n\", data[3][6]); String30 s1(\"Effective C++\"), s2(\"More Effective C++\"); // reference-counted strings using proxies fprintf(stdout, \"%c\\n\", s1[5]); // still legal, still works s2[5] = 'x'; // also legal, also works s1[3] = s2[8]; // of course it's legal, of course it works //char* p = \u0026s1[1]; // error, 通常,取proxy对象地址的操作与取实际对象地址的操作得到的指针，其类型是不同的,重载CharProxy类的取地址运算可消除这个不同 return 0; } 凡“用来代表（象征）其他对象”的对象，常被称为 proxy objects（替身对象），而用以表现 proxy objects者，我们称为 proxy classes。 虽然或许不可能知道operator[] 是在左值或右值情境下被调用，我们还是可以区分读和写——只要将我们所要的处理动作延缓，直至知道operator[] 的返回结果将如何被使用为止。我们需要知道的，就是如何延缓我们的决定（决定对象究竟是被读或被写），直到 operator[] 返回。这是条款 17 的缓式评估（lazyevaluation）例子之一。 Proxy class 让我们得以买到我们所要的时间，因为我们可以修改operator[]，令它返回字符串中字符的 proxy，而不返回字符本身。然后我们可以等待，看看这个 proxy如何被运用。如果它被读，我们可以（有点过时地）将 operator[] 的调用动作视为一个读取动作。如果它被写，我们必须将 operator[] 的调用视为一个写动作。 稍后你会看到代码。首先，重要的是了解我们即将使用的 proxies。对于一个proxy，你只有 3件事情可做： 产生它，本例也就是指定它代表哪一个字符串中的哪一个字符。 以它作为赋值动作（assignment）的目标（接受端），这种情况下你是对它所代表的字符串内的字符做赋值动作。如果这么使用，proxy 代表的将是“调用operator[] 函数”的那个字符串的左值运用。 以其他方式使用之。如果这么使用，proxy 表现的是“调用operator[] 函数”的那个字符串的右值运用。 Proxy classes 允许我们完成某些十分困难或几乎不可能完成的行为。多维数组是其中之一，左值/右值的区分是其中之二，压抑隐式转换（见条款 5）是其中之三。 最后，当 class 的身份从“与真实对象合作”移转到“与替身对象（proxies）合作”，往往会造成 class语义的改变，因为 proxyobjects 所展现的行为常常和真正对象的行为有些隐微差异。 ","date":"2023-09-06","objectID":"/posts/more_effective_c/:5:6","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款31: 让函数根据一个以上的对象类型来决定如何虚化 假设你必须以 C++完成任务，也就是你必须自行想办法完成上述需求（常被称为 double-dispatching）。此名称来自面向对象程序设计社区，在那个领域里，人们把一个“虚函数调用动作”称为一个“message dispatch”（消息分派）。因此某个函数调用如果根据两个参数而虚化，自然而然地就被称为“double dispatch”。更广泛的情况（函数根据多个参数而虚化）则被称为 multiple dispatch。 虚函数+ RTTI（运行时期类型辨识） 只使用虚函数 自行仿真虚函数表格（Virtual Function Tables） 访问者模式 ","date":"2023-09-06","objectID":"/posts/more_effective_c/:5:7","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"六、杂项讨论 ","date":"2023-09-06","objectID":"/posts/more_effective_c/:6:0","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款32: ","date":"2023-09-06","objectID":"/posts/more_effective_c/:6:1","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款33: ","date":"2023-09-06","objectID":"/posts/more_effective_c/:6:2","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款34: ","date":"2023-09-06","objectID":"/posts/more_effective_c/:6:3","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"条款35: Ref: [1]. More Effective C++ [2]. 《More Effective C++》读书笔记 [3]. https://blog.csdn.net/fengbingchun/article/details/102990753 ","date":"2023-09-06","objectID":"/posts/more_effective_c/:6:4","tags":["More Effective C++"],"title":"More Effective C++ 阅读笔记","uri":"/posts/more_effective_c/"},{"categories":["C++"],"content":"函数指针按值传递 C和C++都不允许你真的把函数作为参数传递给其他函数。取而代之的是，你必须传指针给函数。 比如，这里有一个标准库函数qsort的声明: void qsort(void *base, size_t nmemb, size_t size, int (*cmpfcn)(const void*, const void*)); 一旦你忽略了所有的星号，就可以清楚地看出作为cmpfcn传递的实参，一个指向函数的指针，是从调用端拷贝（也就是，值传递）给qsort。这是C和C++标准库都遵循的一般准则:函数指针是值传递。 STL中的习惯是当传给函数和从函数返回时函数对象也是值传递的（也就是拷贝）。 最好的证据是标准的for_each声明，这个算法通过值传递获取和返回函数对象: template\u003cclass InputIterator, class Function\u003e Function // 注意值返回， 注意值传递 for_each(InputIterator first, InputIterator last, Function f); 实际上，值传递的情况并不是完全打不破的，因为for_each的调用者在调用点可以显式指定参数类型。比如，下面的代码可以使for_each通过引用传递和返回它的仿函数: class DoSomething : public unary_function\u003cint, void\u003e { public: void operator()(int x){...} ... }; // 方便的typedef typedef deque\u003cint\u003e::iterator DequeIntIter; deque\u003cint\u003e di; ... // 建立一个函数对象 DoSomething d; ... // 调用for_each，参数类型是DequeIntIter和DoSomething\u0026； // 这迫使d按引用传递和返回 for_each\u003cDequeIntIter, DoSomething \u0026\u003e(di.begin(), di.end(), d); ","date":"2023-09-06","objectID":"/posts/effective_stl_38/:1:0","tags":["Effective STL"],"title":"Effective STL [38] | 把仿函数类设计为用于值传递","uri":"/posts/effective_stl_38/"},{"categories":["C++"],"content":"保证拷贝传递行为正常 因为函数对象以值传递和返回，你的任务就是确保当拷贝传递时你的函数对象行为良好。 这暗示了2个东西: 你的函数对象应该很小。否则它们的拷贝会很昂贵。 你的函数对象必须单态（也就是，非多态）——它们不能用虚函数。那是因为派生类对象以值传递代入基类类型的参数会造成切割问题: 在拷贝时，它们的派生部分被删除。 当然效率很重要，避免切割问题也是，但不是所有的仿函数都是小的、单态的。函数对象比真的函数优越的的原因之一是仿函数可以包含你需要的所有状态。 有些函数对象自然会很重，保持传这样的仿函数给STL算法和传它们的函数版本一样容易是很重要的。 ","date":"2023-09-06","objectID":"/posts/effective_stl_38/:2:0","tags":["Effective STL"],"title":"Effective STL [38] | 把仿函数类设计为用于值传递","uri":"/posts/effective_stl_38/"},{"categories":["C++"],"content":"多态仿函数实现 禁止多态仿函数是不切实际的。C++支持继承层次和动态绑定，这些特性在设计仿函数类和其他东西的时候一样有用。仿函数类如果缺少继承就像C++缺少“++”。 带着你要放进你的仿函数类的数据和/或多态，把它们移到另一个类中。然后给你的仿函数一个指向这个新类的指针。 比如，如果你想要建立一个包含很多数据的多态仿函数类。 // BPFC = “Big Polymorphic Functor Class” template \u003ctypename T\u003e class BPFC : public unary_function\u003cT, void\u003e { // 条款40解释了这个基类 private: Widget w; Int x; // 这个类有很多数据，所以用值传递 ... // 会影响效率 public : virtual void operator()(const T\u0026 val) const; // 这是一个虚函数，所以切割时会出问题 ... }; 建立一个包含一个指向实现类的指针的小而单态的类，然后把所有数据和虚函数放到实现类: // 用于修改的BPFC的新实现类 template \u003ctypename T\u003e class BPFCImpl : public unary_function\u003cT, void\u003e { private: // 以前在BPFC里的所有数据现在在这里 Widget w; int x; ... // 多态类需要虚析构函数 virtual ~BPFCImpl(); virtual void operator()(const T\u0026 val) const; friend class BPFC\u003cT\u003e; // 让BPFC可以访问这些数据 }; // 小的，单态版的BPFC template \u003ctypename T\u003e class BPFC : public unary_function\u003cT, void\u003e { private: BPFCImpl\u003cT\u003e* pImpl; // 这是BPFC唯一的数据 public: // 现在非虚； void operator()(const T\u0026 val) const { // 调用BPFCImpl的真的虚函数 pImpl-\u003eoperator()(val); } ... }; BPFC::operator()的实现例证了BPFC所有的虚函数是怎么实现的: 它们调用了在BPFCImpl中它们真的虚函数。 结果是仿函数类（BPFC）是小而单态的，但可以访问大量状态而且行为多态。 顺便说一句，这种实现方法在《Effective C++》的条款34中有。在Gamma等的《设计模式》中，这叫做“Bridge模式”。Sutter在他的《Exceptional C++》中叫它“Pimpl惯用法”。 ","date":"2023-09-06","objectID":"/posts/effective_stl_38/:3:0","tags":["Effective STL"],"title":"Effective STL [38] | 把仿函数类设计为用于值传递","uri":"/posts/effective_stl_38/"},{"categories":["C++"],"content":"总结 从STL的视角看来，要记住的最重要的东西是使用这种技术的仿函数类必须支持合理方式的拷贝。 唯一你必须担心的是BPFC的拷贝构造函数的行为，因为当在STL中被传递或从一个函数返回时，函数对象总是被拷贝——值传递。 记得吗？那意味着两2件事: 让它们小，而且让它们单态。 ","date":"2023-09-06","objectID":"/posts/effective_stl_38/:4:0","tags":["Effective STL"],"title":"Effective STL [38] | 把仿函数类设计为用于值传递","uri":"/posts/effective_stl_38/"},{"categories":["AutonomousDriving","Perception"],"content":"1. 背景/Motivation ","date":"2023-09-03","objectID":"/posts/bevformer/:1:0","tags":["Robotics"],"title":"BEVFormer 论文解读","uri":"/posts/bevformer/"},{"categories":["AutonomousDriving","Perception"],"content":"1.1 为什么视觉感知要用BEV？ 相机图像描述的是一个2D像素世界，然而自动驾驶中利用相机感知结果的后续决策、路径规划都是在车辆所处的3D世界下进行。由此引入的2D和3D维度不匹配，就导致基于相机感知结果直接进行自动驾驶变得异常困难。 这种感知和决策规划的空间维度不匹配的矛盾，也体现在学开车的新手上。倒车泊车时，新手通过后视镜观察车辆周围，很难直观地构建车子与周围障碍物的空间联系，容易导致误操作剐蹭或需要尝试多次才能泊车成功，本质上还是新手从2D图像到3D空间的转换能力较弱。基于相机图像平面感知结果进行决策规划的自动驾驶AI，就好比缺乏空间理解力的驾驶新手，很难把车开好。 实际上，利用感知结果进行决策和路径规划，问题还出现在多视角融合过程中: 在每个相机上进行目标检测，然后对目标进行跨相机融合。如2021 TESLA AI Day给出的图1，带拖挂的卡车分布在多个相机感知野内，在这种场景下试图通过目标检测和融合来真实地描述卡车在真实世界中的姿态，存在非常大的挑战。 为了解决这些问题，很多公司采用硬件补充深度感知能力，如引入毫米波雷达或激光雷达与相机结合，辅助相机把图像平面感知结果转换到自车所在的3D世界，描述这个3D世界的专业术语叫做BEV map或BEV features(鸟瞰图或鸟瞰图特征)，如果忽略高度信息，就把拍扁后的自车坐标系叫做BEV坐标系(即鸟瞰俯视图坐标系)。 但另外一些公司则坚持不引入深度感知传感器，他们尝试从本质入手，基于视觉学习得到从图像理解空间的能力，让自动驾驶AI系统更像老司机，例如TESLA。Elon Musk认为: 人类不是超人，也不是蝙蝠侠，不能够眼放激光，也没安装雷达，但是通过眼睛捕捉到的图像，人类反复练习就可以构建出对周围世界的3D空间理解能力从而很好地掌握驾驶这项能力，那么要像人一样单纯利用眼睛(相机)进行自动驾驶就必须具备从2D图像平面到3D自车空间(BEV)的转换能力。 传统获取BEV map/features的方法有局限性，它一般是利用相机外参以及地面平面假设，即IPM(Inverse Perspective Mapping)方法，将图像平面的感知结果反投影到自车BEV坐标系。Tesla以前的方案也是这样，然而当车辆周围地面不满足平面假设，且多相机视野关联受到各种复杂环境影响的时候，这类方法就难以应付。 针对IPM方法获取BEV遇到的困难，TESLA自动驾驶感知负责人Andrej Karparthy的团队直接在神经网络中完成图像平面到BEV的空间变换，这一改变成为了2020年10月发布的FSD Beta与之前Autopilot产品最显著的差别。TESLA利用Transformer生成BEV Featrues，得到的Features通道数是256(IPM方法最多保留RGB3个channel)，这样能极大程度地保留图像信息，用于后续基于BEV Features的各种任务，如动、静态目标检测和线检测等。 ","date":"2023-09-03","objectID":"/posts/bevformer/:1:1","tags":["Robotics"],"title":"BEVFormer 论文解读","uri":"/posts/bevformer/"},{"categories":["AutonomousDriving","Perception"],"content":"1.2 生成BEV视角的方法有哪些？为何选用Transformer呢？ 把相机2D平面图像转换成BEV视角的方法有两种: 视觉几何方法和神经网络方法。 视觉几何方法: 基于IPM进行逐像素几何投影转换为BEV视角，再对多个视角的部分BEV图拼接形成完整BEV图。此方法有两个假设: 1.路面与世界坐标系平行，2.车辆自身的坐标系与世界坐标系平行。前者在路面非平坦的情况下并不满足，后者依赖车辆姿态参数(Pitch和Roll)实时校正，且精度要求较高，不易实现。 神经网络方法: 用神经网络生成BEV，其中的关键要找到合适的方法实现神经网络内部Feature Map空间尺寸上的变换。 实现空间尺寸变换的神经网络主流操作有两种方法，如图2所示: MLP中的Fully Connected Layer和Transformer Cross Attention(图片引用自《超长延迟的特斯拉AI Day解析: 讲明白FSD车端感知》) MLP Fully Connected Layer方法: $$O=Act(W_{mlp}*X+b)$$ 忽略非线性激活函数和bias后，可以写成: $$O=W_{mlp}*X$$ Transformer Cross Attention方法: $$O=Softmax(Q*K^T)*V$$ 其中，K和V是输入图像特征X经线性变换后得到的；在最终输出的BEV视角下，把自车周围空间中的索引量称作 $\\boldsymbol{\\Phi}$ $$O=Softmax(\\Phi W_q*(XW_K)^T)*XW_V=W_{transformer}(X,\\Phi)*XW_V$$ BEV变换的本质是将输入的2D图像空间特征图转换成BEV特征图。在进行BEV转换之前，先通过多层CNN(或者任一图像处理backbone网络)在图像上提取特征，得到图像空间特征图层尺寸($h * w$)，即$X$的尺寸。 BEV变换输出O所在的BEV空间尺寸，是以自车位置为原点的前后左右各若干米范围内建立的栅格空间($x * y$)。 MLP Fully Connect Layer和Cross Attention的显著差别在于作用于输入量X的系数W: 全联接层的W，一旦训练结束后在Inference阶段是固定不变的；而Cross Attention的Transformer的系数W，是输入量X和索引量的函数，在Inference阶段会根据输入量X和索引量的不同发生改变。从这个角度来讲，使用Cross Attention来进行空间变换可能使模型获得更强的表达能力。 TESLA在2021年AI Day上仅介绍了用Transformer转换BEV Features的技术思想，并未披露更多实现细节。论文BEVFormer充分研究了TESLA的技术思想后，利用Transformer融合图像的时、空特征，得到BEV Features，与TESLA的关键方法、实现效果都非常接近。BEVFormer既通过论文披露了详尽方法，又在2022年6月开源了工程，接下来就围绕BEVFormer介绍如何通过Transformer获取BEV Features。 ","date":"2023-09-03","objectID":"/posts/bevformer/:1:2","tags":["Robotics"],"title":"BEVFormer 论文解读","uri":"/posts/bevformer/"},{"categories":["AutonomousDriving","Perception"],"content":"2. Method/Strategy——BEVFormer ","date":"2023-09-03","objectID":"/posts/bevformer/:2:0","tags":["Robotics"],"title":"BEVFormer 论文解读","uri":"/posts/bevformer/"},{"categories":["AutonomousDriving","Perception"],"content":"2.1 Overall Architecture 如下图3所示: BEVFormer主体部分有6层结构相同的BEVFormer encoder layers，每一层都是由以transformer为核心的modules(TSA+SCA)，再加上FF、Add和Norm组成。BEVFormer encoder layer结构中有3个特别的设计: BEV Queries， Spatial Cross-attention(SCA)和Temporal Self-attention(TSA)。其中BEV Queries是栅格形可学习参数，承载着通过attention机制在multi-camera views中查询、聚合的features。SCA和TSA是以BEV Queries作为输入的注意力层，负责实施查询、聚合空间features(来自multi-camera images)和时间features(来自历史BEV)的过程。 下面分步骤观察BEV完整模型的前向推理过程: 在t时刻，输入车上多个视角相机的图像到backbone，输出各图像的多尺度特征(multi-scale features): $x = 1$, $F_t = {{F^i_t}}^a_b$, $F_t={{{F_t^i}}}{i=1}^{N{view}}$，其中 $F^i_t$ 是第i个视角相机的feature，$N_{view}$ 是多个相机视角的总数。同时，还要保留t-1时刻的BEV Features ${\\boldsymbol{B}}_{t-1}$。 在每个BEVFormer Encoder layer中，首先用BEV Queries Q通过TSA模块从 ${\\boldsymbol{B}}_{t-1}$ 中查询并融合时域信息(the temporal information)，得到修正后的BEV Queries $Q^{\\prime}$； 然后在同一个BEVFormer Encoder layer中，对TSA“修证”过的BEV Queries $Q^{\\prime}$ ，通过SCA模块从multi-camera features $F_{t}$ 查询并融合空域信息(spatial information)，得到进一步修正的BEV Queries $Q^{^{\\prime\\prime}}$ 。 这一层encoder layer把经过两次修正的BEV features $Q^{^{\\prime\\prime}}$ (也可以叫做BEV Queries)进行FF计算，然后输出，作为下一个encoder layer的输入。 如此堆叠6层，即经过6轮微调，t时刻的统一BEV features $B_{t}$ 就生成了。 最后，以BEV Features $B_{t}$ 作为输入，3D detection head和map segmentation head预测感知结果，例如3D bounding boxes和semantic map。 ","date":"2023-09-03","objectID":"/posts/bevformer/:2:1","tags":["Robotics"],"title":"BEVFormer 论文解读","uri":"/posts/bevformer/"},{"categories":["AutonomousDriving","Perception"],"content":"2.2 BEV Queries BEVFormer采用显性定义BEV的方式，BEV Queries就是其中的显性BEV features。 可从3个概念循序渐进地认识/理解BEV Queries: BEV平面 → BEV 感知空间 → BEV Queries。 BEV 平面 BEV平面($R^{H\\times W\\times1}$)是以自车为中心的栅格化二维平面，H、W是BEV平面在x、y方向的栅格尺寸，此平面显性地与车辆周围横、纵向物理空间关联，一个栅格表示s米，论文中把BEV平面中的栅格叫做2D参考点(2D reference points)。例如论文中定义nuScenes数据集栅格尺寸200x200，对应[-51.2米, 51.2米]，那么s就是0.512米。 BEV 感知空间 BEV感知空间( $R^{H\\times W\\times N_{ref}}$ )把BEV平面在z轴方向选取 $N_{ref}$个3D参考点进行扩展，表示车辆周围有限空间。查看BEV开源工程可知，BEV感知空间的精确表示范围: 在nuScenes数据集中，是以Lidar作为中心点，前后各51.2m、左右各51.2m、向上3m、向下5m的矩形空间。 仔细深究作者这样设置的用意，会发现蛮有意思/意义: nuScenes采集车上安装的Lidar距地面高约1.84m，[-5m, 3m]的设置让BEV Queries感知空间在自车轮胎接地点平面以上部分约4.84m，接地点平面以下部分约3.16m。前者确保不仅能感知高大目标物，如货车等，还能感知覆盖坡度9.5%(4.84m/51.2m100%)上坡场景，后者保证感知覆盖坡度6.2%(3.16m/51.2m100%)下坡场景。备注: 坡度=(高程差/水平距离)x100%，车辆前进100m的垂直上升/下降高度，我国规定城市道路最大纵坡8％，公路9％。 BEV Queries BEV Queries是预定义的一组栅格形(grid-shaped)可学习参数，简称 $Q\\in R^{H\\times W\\times C}$，它是对上述BEV 感知空间的特征描述，可直白地理解为学习完成了，它就变成了BEV features。 BEV Queries的H、W与BEV平面在x、y方向的栅格尺寸定义一致，因此也继承了BEV平面显性地与车辆周围横、纵向物理空间关联的特性。但C是BEV Queries作为features时在channel维度的尺寸，并不显性地对应于BEV平面z轴的物理空间尺寸。特别指出，位于 $p=(x,y)$ 处的某个query $Q_{p}\\in R^{1\\times C}$，表示BEV queries中的一个栅格。在输入到BEVFormer之前，BEV Queries加上了可学习的位置编码(learnable positional embedding)。 论文中多处提及BEV Queries和BEV features，它俩什么关系？本质上描述的是同一个东西么？ 先说答案: 两者本质上是同一个东西。模型中预定义参数BEV Queries 输入到BEV Encoder layer，输出的就是经过1次微调过的BEV features，它作为下一层的输入时，又被看作下一层的BEV Queries。经过所有layers的多次微调，最后一个layer输出的就是BEV features ${\\mathit{B}}_{t}$ ，作为各类感知task heads的输入。 ","date":"2023-09-03","objectID":"/posts/bevformer/:2:2","tags":["Robotics"],"title":"BEVFormer 论文解读","uri":"/posts/bevformer/"},{"categories":["AutonomousDriving","Perception"],"content":"2.3 SCA: Spatial cross-attention 如上图(b)所示，作者设计了一种空间交叉注意力机制，使 BEV queries 从多个相机的image Features中提取所需信息并转换为BEV Features。 每个BEV栅格的query在image features的哪些范围提取信息呢？这里有3个方案: 一、从image features的所有点上提取信息，即global attention。 二、从BEV栅格在image features的投影点上提取信息。 三、从BEV栅格在image features的投影点及其周围提取信息，即deformable attention。 由于使用了多尺度图像特征和高分辨率 BEV 特征(200x200)，如果采用方案一 global attention ，会带来无法负担的计算代价(显存和计算复杂度)。但是，方案一完全用不到相机内外参，这算是它独有的优势。 方案二依赖非常精确的相机内、外参，且不能充分利用image features上的局部区域信息。 因此作者选用了方案三，基于deformable attention 的稀疏注意力机制，使BEV Queries中的每个Query 只与其所代表世界坐标系物理空间投影到图像上的部分区域进行交互，且解除了对相机内、外参的高精度依赖。注意，这里复数BEV Queries表示整个BEV图，而单数Query表示BEV 图中位于 $(x, y)$的一个栅格。 $$\\mathrm{SCA}(Q_p,F_t)=\\frac1{|\\mathcal{V}\\mathrm{hit}|}\\sum{i\\in\\mathcal{V}\\mathrm{hit}}\\sum{j=1}^{N_\\mathrm{ref}}\\mathrm{Deform}\\mathrm{Attn}(Q_p,\\mathcal{P}(p,i,j),F_t^i)\\quad\\quad\\quad\\quad(2)$$ 在DeformAttn()中，$Q_{p}$、$P(p,i,j)$ 和 $F_{t}^{i}$ 分别表示query, reference points和输入特征。 通俗理解公式: 在BEV Query对应的图像2D features 有效区域附近计算注意力，把图像2D features加权融合到BEV Query作为SCA的输出。 参考图(b)和上述公式2，总结Spatial cross-attention的实现方式: 对于每一个位于 $(x, y)$ 位置的 BEV query $Q_{p}$ ，计算其对应真实世界的坐标 $(x^{’},y^{’})$。然后将 BEV query 在z方向进行 lift 操作，设置 $N_{ref}$ 个 3D参考点，即对应 $N_{ref}$ 个世界坐标系下的3D空间参考点。 通过相机内外参，把第j个3D参考点投影到 $v_{hit}$ 个相机图像上。受相机感知范围限制，每个3D参考点一般只在 1-2 个相机上找到有效的投影点(反过来描述，每个相机的features只与部分BEV queries构成有效投影关系)。 基于 Deformable Attention，把像平面上的这些投影点作为2D图像参考点，在其周围对 $F_{t}^{i}$ 进行特征采样，得到sampled features。 最后，对 $V_{hit}$ 、$N_{ref}$ 个sampled features进行加权求和，作为spatial cross-attention的输出来更新BEV query，从而完成 spatial 空间的特征聚合。 详细介绍一下第2步中如何把3D参考点投影到相机图像上获得2D参考点: 首先计算位于 $p = (x, y)$ 的query $Q_{p}$ 在以车辆为中心世界坐标 $(x^{’},y^{’})$ $$x^{^{\\prime}}=(x-W/2)*s; \\quad y^{^{\\prime}}=(y-{H}/2)*s$$ 其中H和W是BEV queries的尺寸，s是BEV中一个栅格所代表的物理空间尺寸; 计算第j个3D参考点投影到第i个相机图像上的2D参考点坐标: $$P(p,i,j)=(x_{i,j},y_{i,j})$$ 其中， $$z_{i,j}[x_{i,j},y_{i,j},1]^T=T_i*[x^{’},y^{’},z^{’},1]^T$$ $T_i$ 是第 $i$ 个相机的投影矩阵。 ","date":"2023-09-03","objectID":"/posts/bevformer/:2:3","tags":["Robotics"],"title":"BEVFormer 论文解读","uri":"/posts/bevformer/"},{"categories":["AutonomousDriving","Perception"],"content":"2.4 TSA: Temporal self-attention 从经典 RNN 网络获得启发，将 BEV 特征 $B_t$ 视为能够传递序列信息的 memory。每一时刻生成的 BEV 特征 $B_t$ 都从上一时刻的 BEV 特征 $B_{t-1}$ 获取所需的时序信息，这样能保证动态地获取所需的时序特征，而非像堆叠不同时刻 BEV 特征那样只能获取定长的时序信息。 $$\\text{TSA}(Q_p,{Q,B’{t-1}})=\\sum{V\\in{Q,B’_{t-1}}}\\text{DeformAttn}(Q_p,p,V),\\quad(5)$$ 参考图4和上述公式5，总结temporal self-attention的实现方法: 给定t-1时刻的 BEV 特征 $B_{t-1}$ ，先根据 ego motion 将 $B_{t-1}$ 对齐到 $t$ 时刻，来确保 $B_{t-1}$ 和 $B_{t}$ 在相同index位置的栅格对应于现实世界的同一位置，把时间对齐后的BEV特征记作 $B_{t-1}^{’}$ 。 $t$ 时刻位于 $(x, y)$ 处的 BEV query所表征的物体可能静态或者动态，它在t-1时刻会出现在 $B_{t-1}^{’}$ 的 $(x, y)$ 周围，因此利用 deformable attention 以 $(x, y)$ 作为参考点在其周围进行特征采样。 上述方法没有显式地设计遗忘门，而是通过 attention 机制中的 attention weights 来平衡历史时序特征和当前 BEV 特征的融合过程。 关于TSA的后记: BEVFormer V2对 BEVFormer的时域融合方法TSA做了修改。 BEVFormer中TSA采用了继承式的时域信息融合方式: 利用attention机制在t时刻融合了t-1时刻的BEV features信息，由于t-1时刻的BEV features 也融合了更早时刻(t-2)的信息，因此t时刻BEV features间接地融合了比t-1时刻更早的信息。 但是这种继承式时域融合方式有遗忘的特点，即不能有效利用较长时间的历史信息。 BEVFormer V2把时域融合改成了: 根据ego motion，把过去多个时刻的BEV features 对齐到当前时刻，然后在channel 维度把这些对齐后的BEV features 与当前时刻BEV features串联，然后用Residual 模块降低channel数，就完成了时域融合。 综合2.3和2.4节，观察6个 BEVFormer Encoder Layers的完整结构会发现， BEV query 既能通过 spatial cross-attention 聚合空间特征，又能通过 temporal self-attention 聚合时序特征，这个过程会重复多次，让时空特征融合能够相互促进，最终得到更好的融合BEV features。 ","date":"2023-09-03","objectID":"/posts/bevformer/:2:4","tags":["Robotics"],"title":"BEVFormer 论文解读","uri":"/posts/bevformer/"},{"categories":["AutonomousDriving","Perception"],"content":"2.5 Application of BEV Features BEV Features $B_{t}\\in R^{H\\times W\\times C}$ 是可用于多种自动驾驶感知任务的2D feature map， 基于2D 感知方法稍加改动就可在 $B_t$ 上开发3D目标检测和map segmentation任务。 3D object detection 参考2D 目标检测器Deformable DETR，论文设计了end-to-end的3D目标检测head，修改部分包括: 用single-scale 的BEV features $B_t$ 作为检测头的输入，预测输出3D b-boxes和速度而不是2D b-boxes，仅用 $L_1$ loss监督3D b-boxes的回归。继承DETR方法的优势，预测有限数目的候选目标集合(开源工程中设为300个)，这种end-to-end的检测头不需要NMS后处理。 map segmentation 参考2D segmentation 方法Panoptic SegFormer，论文设计了map segmentation head。因为基于BEV的map segmentation基本上与常见语义分割相同，作者利用了参考文章[22]中的mask decoder和class-fixed queries设计head来查找每个语义类别，包括car、vehicle、road(可通行区域)和车道线。 ","date":"2023-09-03","objectID":"/posts/bevformer/:2:5","tags":["Robotics"],"title":"BEVFormer 论文解读","uri":"/posts/bevformer/"},{"categories":["AutonomousDriving","Perception"],"content":"2.6 Implementation details 训练时的实施细节: 对于时间t，在过去2s中随机选取3个时刻t-3、t-2和t-1； 在初始3个时刻，循环生成BEV features ${B_{t-3},B_{t-2},B_{t-1}}$，且在此阶段不计算梯度； 计算第一个时刻t-3的temporal self-attention输出时，它并没有前序BEV features，就用它自身作为前序时刻输入，那么temporal self-attention暂时退化成了self-attention。 inference时的实施细节: 按照时间顺序计算图像序列中的每一帧，前序时刻的BEV features被保持下来并用于后一时刻，这种online的inference策略在应用中比较高效。 ","date":"2023-09-03","objectID":"/posts/bevformer/:2:6","tags":["Robotics"],"title":"BEVFormer 论文解读","uri":"/posts/bevformer/"},{"categories":["AutonomousDriving","Perception"],"content":"3. Experiments ","date":"2023-09-03","objectID":"/posts/bevformer/:3:0","tags":["Robotics"],"title":"BEVFormer 论文解读","uri":"/posts/bevformer/"},{"categories":["AutonomousDriving","Perception"],"content":"3.1 experimental settings 采用两种Backbone: ResNet101-DCN，采用来自FCOS3D训练得到的参数；VoVnet-99，采用来自DD3D训练得到的参数。 默认情况下，使用FPN输出的多尺度 features的尺寸包含1/16，1/32，1/64(注意，代码中实际用好的1/8尺寸的features，即nuScenes中的116*200的FPN输出)，同时把dimension C设为256。 在nuScenes数据集试验中，BEV queries尺寸设为200x200，对应感x和y方向的知范围都是[-51.2m, 51.2m]，对应BEV Grid尺寸精度是0.512m。 在Waymo数据集试验中，BEV queries尺寸设为300x220，对应感x方向的感知范围是[-35.0m, 75.0m]，y方向的知范围是[-75.0m, 75.0m]，对应BEV Grid尺寸精度是0.5m。自车中心位于 BEV的(70，150)处。 对每个BEV query，在 spatial cross-attention模块中，设置 $N_{ref}=4$ 个3D参考点，预定义它们对应的高度范围是-5m到3m。 对每个2D图像参考点(3D参考点投影到2D view上的点)，在其周围选取4个采样点送入SCA。 默认情况下，训练24epoches，学习率设为 $12\\times10^{-4}$。 Baselines: 为了合理评估task heads的影响，公平地与其它生成BEV方法对比。选择VPN和Lift-Splat作为baselines，对它们head之前的部分替换BEVFormer，保留task heads和其它设置。 论文中，通过把temporal self-attention修改为普通的self-attention，这样就使BEVFormer变成了一个静态模型，命名为BEVFormer-S，它不使用历史BEV Features。 ","date":"2023-09-03","objectID":"/posts/bevformer/:3:1","tags":["Robotics"],"title":"BEVFormer 论文解读","uri":"/posts/bevformer/"},{"categories":["AutonomousDriving","Perception"],"content":"3.2 3D目标检测结果 BEVFormer的3D检测性能，如Table1、Table2和Table3所示，远超之前最优方法DETR3D。 BEVFormer引入了temporal information，因此它在估计目标速度方面效果也很好。从速度估计指标mean Average Velocity (mAVE)来看，BEVFormer误差为0.378m/s，效果远好于同类基于相机的方法，甚至逼近了基于激光的方法。 ","date":"2023-09-03","objectID":"/posts/bevformer/:3:2","tags":["Robotics"],"title":"BEVFormer 论文解读","uri":"/posts/bevformer/"},{"categories":["AutonomousDriving","Perception"],"content":"3.3 multi-tasks perception results 联合训练3D detection和map segmentation任务，与单独训练比较训练效果，如Table4所示: 对3D目标检测和分割中的车辆类语义感知，联合训练效果有提升；对分割中的road、lane类的语义感知，联合训练效果反而会下降。 ","date":"2023-09-03","objectID":"/posts/bevformer/:3:3","tags":["Robotics"],"title":"BEVFormer 论文解读","uri":"/posts/bevformer/"},{"categories":["AutonomousDriving","Perception"],"content":"3.4 消融试验 Spatial Cross-attention有效性 为了验证SCA的有效性，利用不包含TSA的BEVFormer-S来设计消融试验，结果如Table5所示。 默认的SCA基于deformable attention，在对比试验中构建了基于2种不同attention机制的baselines: 1. 用global attention取代deformable attention；2. 让每个query仅与它的图像参考点交互，而不是像SCA那样query与图像参考点周围区域交互。为了扩大对比范围，把BEVFormer中的BEV生成方法替换为了VPN和Lift-Spalt中的方法。从Table5结果可见Deformable Attention方法显著优于其它方法，且在GPU Memory使用量和query兴趣区域大小之间实现了balance。 Temporal Self-attention有效性 从Table1和Table4可见，在相同的设置下，BEVFormer相比于BEVFormer-S的性能大幅提升，针对有挑战性的检测任务提升更明显。TSA主要是在以下方面影响性能提升的: 1.temporal information的引入对提高目标速度估计精度非常有益；2.利用temporal information，目标预测的location和orientations更精确；3.受益于temporal information包含过去时刻object的信息，如图4所示，严重遮挡目标的recall 更高。根据nuScenes标注的遮挡程度把验证数据集进行划分成4部分，来评估BEVFormer对各种程度遮挡的性能，针对每个数据子集都会计算average recall(匹配时把中心距离的阈值设为2m)。 Model Scale and Latency 针对不同Scale Settings的BEVFormer，对比检测性能和latency，结果如Table6所示。在3方面进行BEVFormer的Scale配置: 1. 输入到BEVFormer Encoder的features是multi-scale还是single-scale；2.BEV Queries/features的尺寸；3. encoder layer数目。 从实验结果看来: Backbone的Latency远大于BEVFormer，因此Latency优化的主要瓶颈在于Backbone而不是BEVFormer(这里指BEVFormer Encoder部分)，BEVFormer可以采用不同的Scale，具备支持灵活平衡性能和efficiency的特性。 ","date":"2023-09-03","objectID":"/posts/bevformer/:3:4","tags":["Robotics"],"title":"BEVFormer 论文解读","uri":"/posts/bevformer/"},{"categories":["AutonomousDriving","Perception"],"content":"4. Discussion 理论上视觉图像的数据比激光数据稠密，但基于视觉的BEV效果还是比基于激光的方法性能差，那么也说明了理论上视觉还有可提升空间。 BEV Features能用于泊车位检测么？ 可能可以用BEVFormer在环视鱼眼相机上生成BEV features，用于泊车位检测或近距离目标的精确检测。 显性地引入BEV 特征，限制了最大检测距离，在高速公路场景，检测远处目标非常重要，如何权衡BEV的大小与检测距离是一个需要考虑的问题。 如何在检测精度和grid大小之间做平衡是一个问题。 针对2、3问题的一个优化方向: 设计自适应尺寸的BEV特征。这里的自适应是指根据场景来调整BEV尺寸或精度。 ","date":"2023-09-03","objectID":"/posts/bevformer/:4:0","tags":["Robotics"],"title":"BEVFormer 论文解读","uri":"/posts/bevformer/"},{"categories":["AutonomousDriving","Perception"],"content":"5. References 论文: 《BEVFormer: Learning Bird’s-Eye-View Representation from Multi-Camera Images via Spatiotemporal Transformers》 开源工程: https://github.com/zhiqi-li/BEVFormer 参考中文解读 使用Transformer融合时空信息的自动驾驶感知框架 3d camera-only detection: BEVFormer BEVFormer，通过一个时空Transformer学习 BEV表征 类似工作: Cross-view Transformers for real-time Map-view Semantic Segmentation 论文: https://arxiv.org/pdf/2205.02833v1.pdf 代码: https://github.com/bradyz/cross REF: [1]. 一文读懂BEVFormer论文 https://zhuanlan.zhihu.com/p/543335939 https://zhuanlan.zhihu.com/p/629792598 ","date":"2023-09-03","objectID":"/posts/bevformer/:5:0","tags":["Robotics"],"title":"BEVFormer 论文解读","uri":"/posts/bevformer/"},{"categories":["AutonomousDriving","Perception"],"content":"近年来，基于鸟瞰图(BEV)表示的感知任务越来越受到关注，BEV表示有望成为下一代自动驾驶车辆(AV)感知的基础。现有大多数的BEV解决方案要么需要大量资源来执行车载推理，要么性能不佳。本文提出了一种简单而有效的框架，称为Fast BEV，它能够在车载芯片上执行更快的BEV感知。为了实现这一目标，作者首先从经验上发现，BEV表示可以足够强大，而无需昂贵的基于transformer的变换或深度表示。Fast BEV由五个部分组成，论文新颖地提出： (1)一种轻量级的、易于部署的视图转换，它将2D图像特征快速传输到3D体素空间; (2)一种利用多尺度信息获得更好性能的多尺度图像编码器; (3)一种高效的BEV编码器，它专门设计用于加快车载推理; (4)针对图像和BEV空间的强大数据增强策略以避免过度拟合; (5)利用时间信息的多帧特征融合机制。 其中，(1)和(3)使Fast BEV能够在车载芯片上快速推理和部署，(2)、(4)和(5)确保Fast BEV具有竞争性能。所有这些都使Fast BEV成为一种具有高性能、快速推理速度和在自动驾驶车载芯片上部署友好的解决方案。通过实验，在2080Ti平台上，R50模型可以在nuScenes验证集上以47.3%的NDS运行52.6 FPS，超过了BEVDepth-R50模型的41.3 FPS和47.5%的NDS，以及BEVDet4DR50模型的30.2 FPS和45.7%的NDS。最大的型号(R101@900x1600)在nuScenes验证集上建立了具有竞争力的53.5%NDS，论文在当前主流的车载芯片上进一步开发了具有相当高精度和效率的基准！ ","date":"2023-09-02","objectID":"/posts/fastbev/:0:0","tags":["Robotics"],"title":"FastBEV:快速而强大的BEV感知基线","uri":"/posts/fastbev/"},{"categories":["AutonomousDriving","Perception"],"content":"领域现状 快速准确的3D感知系统对于自动驾驶至关重要。经典方法依赖于激光雷达点云提供的精确3D信息。然而，激光雷达传感器通常要花费数千美元，阻碍了它们在经济型车辆上的应用。基于纯相机的鸟瞰图(BEV)方法最近显示出其强大的3D感知能力和低成本的巨大潜力。它们基本上遵循这样的范式：将多摄像机2D图像特征转换为自我汽车坐标中的3D BEV特征，然后将特定头部应用于统一BEV表示以执行特定的3D任务，例如，3D检测、分割等。统一BEV表达可以单独处理单个任务或同时处理多个任务，这是高效和灵活的。 为了从2D图像特征执行3D感知，nuScenes上的现有BEV方法使用基于查询的transformation [17]，[18]或基于隐式/显式深度的transformation [13]，[15]，[26]。然而，它们很难部署在车载芯片上，并且推理速度慢： (1) 基于基于查询的transformation 方法如图1(a)所示，由于解码器需要transformer内的注意机制，这些方法通常需要专用芯片来支持。 (2) 基于深度变换的方法如图1(b)所示。 这些方法通常需要加速不友好的体素池操作，甚至多线程CUDA内核也可能不是最佳解决方案。此外，这对于在资源受限或CUDA加速推理库不支持的芯片上运行是不方便的。此外，它们在推理上很耗时，这妨碍了它们的实际部署。本文旨在为车载芯片设计一种具有友好部署、高推理速度和竞争性能的BEV感知框架，例如Xavier、Orin、Tesla T4等。 基于这些观察结果，遵循M2BEV[16]的原理，该原理假设在图像到BEV(2D到3D)视图转换期间沿相机光线的深度分布均匀，我们提出Fast-Ray转换，如图1(c)所示，借助于“查找表”和“多视图到一个体素”操作，将BEV转换加速到一个新的水平。基于Fast Ray变换，论文进一步提出了Fast BEV，这是一种更快、更强的全卷积BEV感知框架，无需昂贵的视图transformer[17]、[18]或深度表示[15]、[23]、[26]。所提出的快速BEV包括五个部分，Fast-Ray变换、多尺度图像编码器、高效BEV编码器、数据增强和时间融合，这些共同构成了一个框架，赋予Fast BEV快速推理速度和有竞争力的性能。 详细展开说，本文提出了Fast Ray变换，这是一种用于快速推理的轻量级和部署友好的视图变换，通过将多视图2D图像特征沿着相机射线的体素投影到3D来获得BEV表示。此外，还提出了两种操作，即“查找表”和“多视图到一个体素”，以优化车载平台的流程。现有工作的视图转换耗时，多尺度投影操作将具有较大的时间开销，因此难以在实践中使用。基于Fast Ray变换，本文的2D到3D投影具有极快的速度，使具有多尺度投影操作的多尺度图像编码器成为可能。具体而言，与大多数使用单尺度特征作为图像编码器输出的现有工作不同，论文在图像编码器输出部分使用了3层多尺度特征金字塔网络(FPN)结构。随后是相应的3级多尺度投影操作。对于BEV编码器，作者使用很少的原始残差网络作为基本BEV编码器。在此基础上，使用三维缩减操作来加速编码器，分别是“空间到信道”(S2C)算子、多尺度级联融合(MSCF)算子和多帧级联融合(MFCF)算子。论文还进一步为图像和BEV空间引入了强大的数据增强策略，如翻转、旋转、调整大小等。分别在图像空间和BEV中执行的数据增强不仅避免了过度拟合，而且实现了更好的性能。最后引入了时间融合[17]，[23]，它通过引入时间特征融合模块将Fast BEV从纯空间扩展到时空空间，使当前关键帧能够利用来自历史帧的信息。 BEV感知在学术界经常更新性能基准，如NuScenes基准，但很少在工业应用方面进行研究。本文首次在当前流行的车载芯片上开发了一个具有相当准确度和效率的基准，从延迟到不同计算能力的车载芯片之间的性能，这为BEV解决方案的实际部署提供了参考。凭借其高效率和具有竞争力的性能，Fast BEV打破了现有BEV解决方案难以在低计算芯片上部署的信念，简单和高效是其主要优势。所提出的Fast BEV表现出了出色的性能，可以轻松部署在车载平台上。在nuScenes数据集上，在2080Ti平台上，R50模型可以在nuScene验证集上运行52.6 FPS和47.3%的NDS，超过了BEVDepth-R50模型的41.3 FPS和47.5%的NDS以及BEVDet4D-R50模型的30.2 FPS和45.7%的NDS。最大的型号(R101@900x1600)在nuScenes验证集上建立了具有竞争力的53.5%NDS。 ","date":"2023-09-02","objectID":"/posts/fastbev/:1:0","tags":["Robotics"],"title":"FastBEV:快速而强大的BEV感知基线","uri":"/posts/fastbev/"},{"categories":["AutonomousDriving","Perception"],"content":"领域的主流方案梳理 1)基于camera的单目3D目标检测 3D目标检测中的检测器旨在预测物体在3D空间中的位置和类别，给定由激光雷达或相机传感器生成的输入。基于LiDAR的方法，例如CenterPoint，倾向于使用3D CNN从LiDAR点提取空间特征，并进一步回归到3D属性，如目标的3D中心。与LiDAR传感器相比，仅将相机图像作为输入不仅成本更低，而且图像包含更丰富的语义信息。单目3D目标检测的一种实用方法是基于3D图像特征学习3D边界框，M3DRPN提出了3D区域建议网络和深度卷积层，以提高3D场景理解。在FCOS之后，FCOS3D[7]通过将3D目标转换为图像域，直接预测每个对象的3D边界框。PGD[9]使用对象之间的关系和概率表示来捕获深度不确定性，以便于3D对象检测的深度估计，DD3D[10]受益于深度预训练，并显著改善端到端3D检测！ 2)基于camera的环视3D目标检测 一些大型基准的最新进展，特别是使用更多的周围视图，进一步推动了3D感知领域。在基于camera的3D目标检测中，新提出的多视图transformation 技术[11]、[12]、[13]、[14]将任务重新表述为立体匹配问题，其中周围的图像特征转换成立体表示，如BEV或3D体素。例如，LSS在预测的深度分布上投影逐像素特征，以生成相机截头体，然后转换截头体进入BEV grid。OFT[14]提出通过将预定义的体素投影到图像特征上来生成体素表示，BEVDet将LSS应用于全卷积方法，并首先验证了显式BEV的性能。M2BEV首先跟随OFT探索BEV多任务感知，BEVDepth进一步扩展了LSS[13]，具有强大的深度监督和高效的池化操作。视图转换的另一个路线图是网格状的BEV查询，DETR3D和Graph-DETR3D将每个BEV查询解码为3D参考点，以从图像中采样相关的2D特征进行细化。BEVFormer在二维到三维转换中引入了空间交叉关注，允许每个查询可以跨相机视图聚合其相关的二维特征。PETR提出3D坐标生成来感知3D位置感知特征，避免生成3D参考点。这些工作的成功激励我们有效和高效地扩展周围的多摄像机检测pipeline。作者发现在类似LSS的方法中，使用深度分布是不必要的，并且可以删除它以进一步加快整个pipeline的速度！ 3)基于camera的多视图时间融合 最近，一些基于相机的方法试图在检测过程中引入多帧融合，这已被证明对基于LiDAR的检测器中的速度估计和box定位有效[20]，[21]，[22]。而BEV作为一种同时组合来自多个相机的视觉信息的中间特征，适合于时间对齐。[40]提出了一种动态模块，该模块使用过去的空间BEV特征来学习时空BEV表示，BEVDet4D通过对齐多帧特征并利用自我运动中的空间相关性来扩展BEVDet[15]。PETRv2基于3D位置嵌入的视角，直接实现3D空间中的时间对齐。BEVFormer设计了一种时间自关注，以递归地融合历史BEV信息，类似于RNN模型中的隐藏状态。本文的工作也受到时间对齐的启发，具体来说，我们应用该技术来进一步提高性能，同时保持高效率。 ","date":"2023-09-02","objectID":"/posts/fastbev/:2:0","tags":["Robotics"],"title":"FastBEV:快速而强大的BEV感知基线","uri":"/posts/fastbev/"},{"categories":["AutonomousDriving","Perception"],"content":"本文的方法 BEV感知中最重要的是如何将2D特征转移到3D空间。如图1所示，基于查询的方法通过变换器中的注意力机制获得3D BEV特征，这个过程可以表示为以下公式(1)，基于深度的方法通过计算2D特征和预测深度的外积来获得3D BEV特征，具体过程如公式(2)所示: $$F_{bev}(x,y,z)=Attn(q,k,v)\\quad(1)$$ $$F_{bev}(x,y,z)=Pool{F_{2D}(u,v)\\otimes D(u,v)}_{x,y,z}\\quad(2)$$ 其中F2D(u,v)表示从图像中提取的2D特征，D(u,v)表示来自2D特征的深度预测。⊗表示out producter，Pool表示体素池操作。x、y、z是三维空间中的平均坐标，u，v在二维空间中的坐标。在CUDA多线程的支持下，这些方法大大提高了GPU平台上的推理速度，但在更大的分辨率和特征维度上会遇到计算速度瓶颈，并且在没有推理库支持的情况下转移到非GPU平台不是很友好。 作者提出了基于光线投影的Fast-Ray transformation方法，借助于查找表和多视图到一个体素操作，以便在GPU平台上实现极高的2D到3D推理速度。此外，由于其标量索引的高效性，当在CPU平台上运行时，它仍然具有优于现有解决方案的速度性能，这使得转移到更多平台成为可能。 M2BEV[16]是解决具有统一BEV表示的多摄像机多任务感知的第一个工作之一，因为它没有昂贵的视图转换器或深度表示，因此在车载平台上具有巨大的应用潜力。受其简单性的启发，本文提出了具有卓越速度和性能的Fast BEV，如图2所示，Fast BEV将多摄像机图像作为输入，并预测3D边界框(包括速度)作为输出。其主要框架可分为五个关键模块：Fast-Ray Transformation、Multi-Scale Image Encoder、Efficient BEV Encoder、Data Augmentation、Temporal Fusion！ 1) Fast-Ray Transformation 视图转换是将特征从2D图像空间转换到3D BEV空间的关键组件，这通常在整个pipelines中花费大量时间。论文按照[16]，[34]假设沿射线的深度分布是均匀的，这种方式优点是，一旦获得了相机的内在/外在参数，就可以很容易地知道2D到3D的投影。由于这里没有使用可学习的参数，可以很容易地计算图像特征图和BEV特征图中的点之间的对应矩阵。基于这一假设，本文从两个角度进一步加速该过程：预计算投影索引(查找表)和密集体素特征生成(多视图到一个体素)。 查找表。投影索引是从2D图像空间到3D体素空间的映射索引，考虑到在构建感知系统时相机位置及其内在/外在参数是固定的，并且本文的方法既不依赖于数据相关的深度预测，也不依赖于transformer，因此每个输入的投影指数都是相同的。所以不需要为每次迭代计算相同的索引，只需预先计算固定投影索引并将其存储。在推断过程中，可以通过查询查找表来获得投影索引，这是边缘设备上的一个超级便宜的操作。此外，如果我们从单个帧扩展到多个帧，还可以很容易地预先计算内部和外部参数，并将它们与当前帧预对齐。如算法1所示，通过相机参数矩阵投影构建了具有与输出三维体素空间相同维度的查找表LUT。迭代每个体素单元，并通过投影计算对应于3D坐标的2D像素坐标。如果获得的2D像素坐标地址是合法的，可以将其填充到LUT中以建立与数据无关的索引映射！ 多视图到一个体素。基本视图变换使用原始体素聚合操作，该操作为每个相机视图存储离散体素特征，然后聚合它们以生成最终体素特征。如图3(a)所示，这是填充的每个离散体素的鸟瞰图。因为每个相机只有有限的视角，所以每个体素特征非常稀疏，例如，只有大约17%的位置是非零的。我们发现这些体素特征的聚集是非常昂贵的，因为它们的巨大尺寸。本文建议生成密集体素特征以避免昂贵的体素聚集，具体来说，让所有相机视图中的图像特征投影到同一个体素特征，从而在最后生成一个密集体素，名为“多视图到一个体元”。如图3(b)所示，这是填充了密集体素的鸟瞰图。如算法2所示的快速射线变换算法，其将输入的多视图2D图像特征转移到一个体素3d空间中，其中每个体素单元由预先计算的LUT填充相应的2D图像特征。对于具有重叠区域的多个视图的情况，直接采用第一个遇到的视图来提高表构建的速度。结合“查找表”和“多视图到一个体素”加速设计，视图转换操作具有极快的投影速度！ 2)多尺度Image Encoder 多尺度图像编码器从多视图图像中提取多层次特征，N个图像∈$R^{H×W×3}$作为输入，F1/4、F1/8、F1/16三级特征作为输出。 3)高效BEV编码器 BEV特征是4D张量，时间融合将叠加特征，这将使BEV编码器具有大量计算量。三维缩减操作用于加快编码器的速度，即“空间到信道”(S2C)算子、多尺度，其中所述多帧融合(MFCF)算子分别是级联融合(MSCF)算子和多帧凹融合(MFF)算子。S2C算子将4D体素张量V∈RX×Y×Z×C转换为3D BEV张量V∈R X×Y×(ZC)，从而避免使用内存昂贵的3D卷积。在MFCF算子之前，值得注意的是，通过多尺度投影获得的BEV特征是不同的尺度。论文将首先对X和Y维度上的多尺度BEV特征进行上采样，使其大小相同，例如200×200。MSCF和MFCF运营商在信道维度中合并多尺度多帧特征，并将它们从较高的参数量融合到较低的参数量。此外，通过实验发现，BEV编码器和3D体素分辨率的大小对性能的影响相对较小，但占用了较大的速度消耗，因此更少的block和更小的体素分辨率也更为关键！ 4)数据增强 数据扩充的好处已在学术界形成共识。此外，3D数据集(如NuScenes、KITTI)很难标记，且成本高昂，这导致数据集中样本数量较少，因此数据增强可以带来更显著的性能提升。本文在图像空间和BEV空间中添加了数据增强，主要遵循BEVDet。 图像增强：由于3D场景中的图像与3D相机坐标有直接关系，因此3D目标检测中的数据增强比2D检测更具挑战性。因此，如果对图像应用数据增强，还需要改变相机固有矩阵。对于增强操作，基本上遵循常见的操作，例如翻转、裁剪和旋转，在图5的左侧部分，展示了一些图像增强的示例。 BEV增强：类似于图像增强，类似的操作可以应用于BEV空间，例如翻转、缩放和旋转。注意，增强变换应应用于BEV特征图和3D GT框，以保持一致性。BEV增强变换可以通过相应地修改相机外部矩阵来控制，在图5的右侧部分，展示了随机旋转增强，一种BEV增强！ 5)时间融合 受BEVDet4D和BEVFormer的启发，作者还将历史帧引入到当前帧中以进行时间特征融合。通过空间对齐操作和级联操作，将历史帧的特征与当前帧的对应特征融合。时间融合可以被认为是帧级的特征增强，在一定范围内较长的时间序列可以带来更多的性能增益。具体来说，用三个历史关键帧对当前帧进行采样;每个关键帧具有0.5s间隔，本文采用了BEVDet4D中的多帧特征对齐方法。如图6所示，在获得四个对齐的BEV特征后，直接将它们连接起来，并将它们馈送到BEV编码器。在训练阶段，使用图像编码器在线提取历史帧特征，在测试阶段，历史帧功能可以离线保存，并直接取出用于加速。与BEVDet4D和BEVFormer进行比较，BEVDet4D只引入了一个历史框架，我们认为这不足以利用历史信息。Fast BEV使用三个历史帧，从而显著提高了性能，通过使用两个历史帧，BEVFormer略优于BEVDet4D。然而，由于记忆问题，在训练阶段，历史特征在没有梯度的情况下被分离，这不是最佳的。此外，BEVFormer使用RNN样式来顺序融合特征，这是低效的。相比之下，Fast BEV中的所有帧都以端到端的方式进行训练，这与普通GPU相比更易于训练！ ","date":"2023-09-02","objectID":"/posts/fastbev/:3:0","tags":["Robotics"],"title":"FastBEV:快速而强大的BEV感知基线","uri":"/posts/fastbev/"},{"categories":["AutonomousDriving","Perception"],"content":"实验 数据集描述：评估了nuScenes数据集上的 Fast BEV，该数据集包含1000个自动驾驶场景，每个场景20秒。数据集被分成850个场景用于训练/验证，其余150个场景用于测试。虽然nuScenes数据集提供来自不同传感器的数据，但我们只使用相机数据。相机有六个视图：左前、前、右前、左后、后、右后。 评估指标。为了全面评估检测任务，使用平均精度(mAP)和nuScenes检测分数(NDS)的标准评估指标进行3D目标检测评估。此外，为了计算相应方面的精度(例如，平移、缩放、方向、速度和属性)，使用平均平移误差(mATE)、平均缩放误差(mASE)、平均方向误差(mAOE)、平均速度误差(mAVE)，以及平均属性误差(mAAE)作为度量。 和主流方法的Latency进行比较： 在可比性能下，Fast BEV、BEVDet4D和BEVDepth方案的端到端延迟比较。表的上部是三种方案的详细设置，包括每个组件的具体配置。表的下半部分是在可比性能下三种方案的每个部分的延迟和总延迟的比较。2D到3D部分包括CPU和CUDA两个平台的延迟，MSO表示多尺度输出。 nuScenes集的比较。“L”表示激光雷达，“C”表示摄像机，“D”表示深度/激光雷达监控。MS表示图像和BEV编码器中的多尺度。“¶”表示我们使用MS、scale NMS和测试时间数据增强的方法。 更多消融实验对比： 高效型号系列：为了满足不同计算能力平台的部署需求，本文设计了一系列从M0到M5的高效模型，如表10所示。设置了不同的图像编码器(从ResNet18到ResNet50)，图像分辨率(从256×704到900×1600)、体素分辨率(从200×200×4到250×250×6)和BEV编码器(从2b-192c到6b-256c)来设计模型尺寸。从表10可以看出，从M0到M5，随着图像编码器、图像分辨率、体素分辨率和BEV编码器逐渐变大，模型性能逐渐提高。 在流行设备上部署：除了注重性能，还将M系列车型部署在不同的车载平台(Xavier、Orin、T4)上，并使用CUDA-TensorRT-INT8加速。具体而言，AGX Xavier在没有使用CUDA11.4-TRTT8.4.0-INT8部署DLA加速的情况下的计算能力为22TOPS，AGX Orin 64G在没有使用CUDA11.4-TTRT8.4.0-INT8部署DLB加速的情况下的计算能力是170TOPS，T4在使用CUDA11.1-TRT7.2.1-INT8部署时的计算能力则是130TOPS。如表11所示，评估了这些车载设备上M系列模型的延迟，并将延迟分解为2D/2D到3D/3D三个部分。 从表11中可以看出：(1)随着M系列型号逐渐变大，性能逐渐提高，同一计算平台上的延迟也基本上逐渐增加，2D和3D部分的延迟也分别增加。(2) 从左到右，随着这三个设备的实际计算能力1逐渐增加，M系列的每个模型的延迟逐渐减少，2D和3D部分的延迟分别减少。(3) 结合表11中M系列的性能，可以发现，仅考虑延迟时，M0模型在Xavier等低计算平台上可以达到19.7FPS，这可以实现实时推理速度。考虑到性能，M2模型在性能和延迟之间具有最合理的权衡。在与表2中R50系列模型的性能相当的前提下，它在Orin平台上可以达到43.3 FPS，这可以实现实际的实时推理要求。 目前，BEV感知解决方案越来越多，但它们主要追求学术领域的性能，很少考虑如何更好地将其部署在车载芯片上，尤其是低计算芯片上。不能否认，BEVDet和BEVDepth等工作是当前考虑的首批可能解决方案，因为它们在部署车载芯片时非常方便。但Fast BEV在以下情况下提供了应用的可能性： 低计算能力芯片：尽管自动驾驶芯片的计算能力在逐渐增加，但一些计算能力较低的芯片，如英伟达Xavier，仍被用于经济型车辆。Fast BEV可以以更快的速度在低计算能力芯片上表现得更好。 非GPU部署：DEVEDepth和BEVDet的成功部署和应用主要依赖于CUDA多线程支持的高效体素池操作。然而，没有CUDA库的非GPU芯片，例如以DSP为计算单元的德州仪器芯片，很难开发DSP多线程处理器，CPU速度不够快，这使得它们的解决方案在此类芯片上失去了优势。Fast BEV以其快速的CPU速度提供了在非GPU芯片上部署的便利。 实践中可扩展：随着技术的发展，许多自动驾驶制造商已经开始放弃激光雷达，只使用纯摄像头进行感知。结果，在真实车辆收集的大量数据中没有深度信息。在实际开发中，模型放大或数据放大通常基于从真实车辆收集的数据，以利用数据潜力提高性能。在这种情况下，基于深度监控的解决方案遇到瓶颈，而Fast BEV不引入任何深度信息，可以更好地应用！ ref: [1]. 论文：https://arxiv.org/abs/2301.12511 [2]. 代码：https://github.com/Sense-GVT/Fast-BEV [3]. https://mp.weixin.qq.com/s/aVbaw2qYc6-i21zbCNhfOg [4]. FastBEV 代码注释 ","date":"2023-09-02","objectID":"/posts/fastbev/:4:0","tags":["Robotics"],"title":"FastBEV:快速而强大的BEV感知基线","uri":"/posts/fastbev/"},{"categories":["C++"],"content":"操作区间的函数 有时候你需要把整个区间提炼成一个单独的数，或，更一般地，一个单独的对象。 对于一般需要的信息，count告诉你区间中有多少等于某个值的元素，而count_if告诉你有多少元素满足一个判断式。 区间中的最小和最大值可以通过min_element和max_element获得。 但有时，你需要用一些自定义的方式统计（summarize）区间，而且在那些情况中，你需要比count、count_if、min_element或max_element更灵活的东西。 你可能想要对一个容器中的字符串长度求和。你可能想要数的区间的乘积。你可能想要point区间的平均坐标。在那些情况中，你需要统计一个区间，但你需要有定义你需要统计的东西的能力。 ","date":"2023-09-02","objectID":"/posts/clause_37/:1:0","tags":["Effective STL"],"title":"Effective STL [37] | 用accumulate或for_each来统计区间","uri":"/posts/clause_37/"},{"categories":["C++"],"content":"accumulate accumulate和inner_product、adjacent_difference和partial_sum算法在头文件中。 accumulate存在两种形式。 带有一对迭代器和初始值的形式可以返回初始值加由迭代器划分出的区间中值的和 // 建立一个list，放一些double进去 list\u003cdouble\u003e ld; ... // 计算它们的和，从0.0开始 double sum = accumulate(ld.begin(), ld.end(), 0.0); 注意 意初始值指定为0.0，不是简单的0。 0.0的类型是double，所以accumulate内部使用了一个double类型的变量来存储计算的和。 如果这么写这个调用: // 计算它们的和，从0开始；这不正确！ double sum = accumulate(ld.begin(), ld.end(), 0); 如果初始值是int 0，所以accumulate内部就会使用一个int来保存它计算的值。那个int最后变成accumulate的返回值，而且它用来初始化和变量。这代码可以编译和运行，但和的值可能不对。不是保存真的double的list的和，它可能保存了所有的double加起来的结果，但每次加法后把结果转换为一个int。 输入迭代器 accumulate只需要输入迭代器，所以你甚至可以使用istream_iterator和istreambuf_iterator // 打印cin中 那些int的和 cout \u003c\u003c \"The sum of the ints on the standard input is\" \u003c\u003c accumulate(istream_iterator\u003cint\u003e(cin), istream_iterator\u003cint\u003e(), 0); 带有一个初始和值与一个任意的统计函数 比如，考虑怎么使用accumulate来计算容器中的字符串的长度和。要计算这个和，accumulate需要知道两个东 西。第一，它必须知道和的开始。在我们的例子中，它是0。第二，它必须知道每次看到一个新的字 符串时怎么更新这个和。要完成这个任务，我们写一个函数，它带有目前的和与新的字符串，而且返回更新的和: // string::size_type的内容 string::size_type stringLengthSum(string::size_type sumSoFar, const string\u0026 s) { return sumSoFar + s.size(); } 每个标准STL容器都有一个typedef叫做size_type，那是容器计量东西的类型。比如，这是容器的size函数的返回类型。对于所有的标准容器，size_type必须是size_t。 stringLengthSum是accmulate使用的统计函数的代表。它带有到目前为止区间的统计值和区间的下一个元素，它返回新的统计值。 set\u003cstring\u003e ss; // 建立字符串的容器，进行一些操作 ... // 把lengthSum设为对 ss中的每个元素调用stringLengthSum的结果，使用0作为初始统计值 string::size_type lengthSum = accumulate(ss.begin(), ss.end(), 0, stringLengthSum); 计算数值区间的积甚至更简单，因为我们不用写自己的求和函数。我们可以使用标准multiplies仿函数类: // 建立float的容器 vector\u003cfloat\u003e vf; // 进行一些操作 ... // 把product设为对vf中的每个元素调用， multiplies\u003cfloat\u003e的结果，用1.0f作为初始统计值 float product = accumulate(vf.begin(), vf.end(),1.0f, multiplies\u003cfloat\u003e()); // 这里唯一需要小心的东西是记得把1.0f作为初始统计值，而不是0。如果我们使用0作为开始值，结果会总是0，因为0乘以任何东西也是0。 寻找point的区间的平均值 寻找point的区间的平均值，point看起来像这样: struct Point { Point(double initX, double initY): x(initX), y(initY) {} double x, y; }; 求和函数应该是一个叫做PointAverage的仿函数类的对象，但在我们察看PointAverage之前，让我们看看它在调用accumulate中的使用方法： list\u003cPoint\u003e lp; ... // 对Ip中的point求平均值 Point avg = accumulate(lp.begin(), lp.end(), Point(0, 0), PointAverage()); 初始和值是在原点的point对象，我们需要记得的是当计算区间的平均值时不要考虑那个点。 PointAverage通过记录它看到的point的个数和它们x和y部分的和的来工作。每次调用时，它更新那些值并返回目前检查过的point的平均坐标，因为它对于区间中的每个点只调用一次，它把x与y的和除以区间中的point的个数，忽略传给accumulate的初始point值，它就应该是这样： class PointAverage : public binary_function\u003cPoint, Point, Point\u003e { public: PointAverage() : numPoints(0), xSum(0), ySum(0) {} const Point operator()(const Point\u0026 avgSoFar, const Point\u0026 p) { ++numPoints; xSum += p.x; ySum += p.y; return Point(xSum / numPoints, ySum / numPoints); } private: size_t numPoints; double xSum; double ySum; }; 成员变量numPoints、xSum和ySum的修改造成了一个副作用，所以，技术上讲，上述例子展示的代码会导致结果未定义。 ","date":"2023-09-02","objectID":"/posts/clause_37/:2:0","tags":["Effective STL"],"title":"Effective STL [37] | 用accumulate或for_each来统计区间","uri":"/posts/clause_37/"},{"categories":["C++"],"content":"for_each for_each带有一个区间和一个函数（一般是一个函数对象）来调用区间中的每个元素，但传给for_each的函数只接收一个实参（当前的区间元素），而且当完成时for_each返回它的函数。（实际上，它返回它的函数的一个拷贝。 首先，accumulate的名字表示它是一个产生区间统计的算法，for_each听起来好像你只是要对区间的每个元素进行一些操作。 用for_each来统计一个区间是合法的，但是它没有accumulate清楚。 accumulate直接返回那些我们想要的统计值，而for_each返回一个函数对象，我们必须从这个对象中提取想要的统计信息。 在C++里，那意味着我们必须给仿函数类添加一个成员函数，让我们找回我们追求的统计信息。 struct Point {...}; // 同上 class PointAverage : public unary_function\u003cPoint, void\u003e { // 参见条款40 public: PointAverage() : xSum(0), ySum(0), numPoints(0) {} void operator()(const Point\u0026 p) { ++numPoints; xSum += p.x; ySum += p.y; } Point result() const { return Point(xSum / numPoints, ySum / numPoints); } private: size_t numPoints; double xSum; double ySum; }; list\u003cPoint\u003e lp; Point avg = for_each(lp.begin(), lp.end(), PointAverage()).result; 就个人来说，我更喜欢用accumulate来统计，因为我认为它最清楚地表达了正在做什么，但是for_each也可以，而且不像accumulate，副作用的问题并不跟随for_each。 ","date":"2023-09-02","objectID":"/posts/clause_37/:3:0","tags":["Effective STL"],"title":"Effective STL [37] | 用accumulate或for_each来统计区间","uri":"/posts/clause_37/"},{"categories":["C++"],"content":"前言 Effective-STL总结系列分为七部分，本文为第一部分，涉及原书第一章，内容范围Rule01~12。为方便书写，Rule12简写为R12。 Effective-STL系列List 本博客站点系列内容如下： 💡 Effective STL(第3版)精读总结(一) 💡 Effective STL(第3版)精读总结(二) 💡 Effective STL(第3版)精读总结(三) 💡 Effective STL(第3版)精读总结(四) ","date":"2023-09-01","objectID":"/posts/effective_stl_part_one/:0:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [1] | 容器","uri":"/posts/effective_stl_part_one/"},{"categories":["C++"],"content":"R01 慎重选择容器类型 STL 容器不是简单的好，而是确实很好。 容器类型如下： 标准 STL 序列容器：vector、string、deque、list。 标准 STL 关联容器：set、multiset、map、multimap。 非标准序列容器 slist 和 rope。slist 是一个单向链表，rope 本质上是一个 “重型” string。 非标准的关联容器：hash_set、hash_multiset、hash_map、hash_multimap。 vector 作为 string 的替代。 vector 作为标准关联容器的替代：有时 vector 在运行时间和空间上都要优于标准关联容器。 几种标准的非 STL 容器：array、bitset、valarray、stack、queue、priority_queue。 容器选择标准: vector、list和deque有着不同的复杂度，vector是默认使用的序列类型。当需要频繁在序列中间做插入和删除操作时，应使用list。当大多数插入和删除操作发生在序列的头部和尾部时，应使用deque。 可以将容器分为连续内存容器和基于节点的容器两类。连续内存容器把元素存放在一块或多块(动态分配的)内存中，当有新元素插入或已有的元素被删除时，同一块内存中的其他元素要向前或向后移动，以便为新元素让出空间，或者是填充被删除元素所留下的空隙。这种移动会影响到效率和异常安全性。标准的连续内存容器有vector、string和deque，非标准的有rope。 基于节点的容器在每一个(动态分配的)内存块中只存放一个元素。容器中元素的插入或删除只影响指向节点的指针，而不影响节点本身，所以插入或删除操作时元素是不需要移动的。链表实现的容器list和slist是基于节点的，标准关联容器也是(通常的实现方式是平衡树)，非标准的哈希容器使用不同的基于节点的实现。 是否需要在容器的任意位置插入新元素？需要则选择序列容器，关联容器是不行的。 是否关心容器中的元素是如何排序的？如果不关心，可以选择哈希容器，否则不能选哈希容器(unordered)。 需要哪种类型的迭代器？如果是随机访问迭代器，那就只能选择vector、deque和string。如果使用双向迭代器，那么就不能选slist和哈希容器。 是否希望在插入或删除元素时避免移动元素？如果是，则不能选择连续内存的容器。 容器的数据布局是否需要和C兼容？如果需要只能选vector。 元素的查找速度是否是关键的考虑因素？如果是就考虑哈希容器、排序的vector和标准关联容器。 是否介意容器内部使用引用计数技术，如果是则避免使用string，因为string的实现大多使用了引用计数，可以考虑用vector\u003cchar\u003e替代。 对插入和删除操作需要提供事务语义吗？就是说在插入和删除操作失败时，需要回滚的能力吗？如果需要则使用基于节点的容器。如果是对多个元素的插入操作(针对区间)需要事务语义，则需要选择list，因为在标准容器中，只有list对多个元素的插入操作提供了事务语义。对希望编写异常安全代码的程序员，事务语义尤为重要。使用连续内存的容器也可以获得事务语义，但是要付出性能上的代价，而且代码也不那么直截了当。 需要使迭代器、指针和引用变为无效的次数最少吗？如果是则选择基于节点的容器，因为对这类容器的插入和删除操作从来不会使迭代器、指针和引用变成无效(除非它们指向一个正在删除的元素)。而对连续内存容器的插入和删除一般会使得指向该容器的迭代器、指针和引用变为无效。 ","date":"2023-09-01","objectID":"/posts/effective_stl_part_one/:1:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [1] | 容器","uri":"/posts/effective_stl_part_one/"},{"categories":["C++"],"content":"R02 不要试图编写独立于容器类型的代码 容器是以类型作为参数的，而试图把容器本身作为参数，写出独立于容器类型的代码是不可能实现的。因为不同的容器支持的操作是不同的，即使操作是相同的，但是实现又是不同的，比如带有一个迭代器参数的erase作用于序列容器时，会返回一个新的迭代器，但作用于关联容器则没有返回值。这些限制的根源在于，对于不同类型的序列容器，使迭代器、指针和引用无效的规则是不同的。 有时候不可避免要从一个容器类型转到另一种，可以使用封装技术来实现。最简单的方式是对容器类型和其迭代器类型使用typedef，如typedef vector\u003cWidget\u003e widgetContainer; typedef widgetContainer::iterator WCIterator; 如果想减少在替换容器类型时所需要修改的代码，可以把容器隐藏到一个类中，并尽量减少那些通过类接口可见的、与容器有关的信息。 一种容器类型转换为另一种容器类型：typedef class Widget{...}; typedef vector\u003cWidget\u003e WidgetContainer; WidgetContainer cw; Widget bestWidget; ... WidgetContainer::iterator i = find(cw.begin(), cw.end(), bestWidget); 这样就使得改变容器类型要容易得多，尤其当这种改变仅仅是增加一个自定义得分配子时，就显得更为方便（这一改变不影响使迭代器/指针/引用无效的规则）。 ","date":"2023-09-01","objectID":"/posts/effective_stl_part_one/:2:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [1] | 容器","uri":"/posts/effective_stl_part_one/"},{"categories":["C++"],"content":"R03 确保容器中的对象拷贝正确而高效 存在继承关系的情况下，拷贝动作会导致剥离（slicing）: 如果创建了一个存放基类对象的容器，却向其中插入派生类对象，那么在派生类对象（通过基类的拷贝构造函数）被拷贝进容器时，它所特有的部分（即派生类中的信息）将会丢失。 vector\u003cWidget\u003e vw; class SpecialWidget: // SpecialWidget 继承于上面的 Widget public Widget{...}; SpecialWidget sw; vw.push_back(); // sw 作为基类对象被拷贝进 vw 中 // 它的派生类特有部分在拷贝时被丢掉了 剥离意味着向基类对象中的容器中插入派生类对象几乎总是错误的。 解决剥离问题的简单方法：使容器包含指针而不是对象。 容器中保存的对象，并不是你提供给容器的那些对象。从容器中取出对象时，也不是容器中保存的那份对象。当通过如insert或push_back之类的操作向容器中加入对象时，存入容器的是该对象的拷贝。当通过如front或back之类的操作从容器中 取出对象时，所得到的是容器中对象的拷贝。进去会拷贝，出来也是拷贝，这就是STL的工作方式。 当对象被保存到容器中，它经常会进一步被拷贝。当对vector、string或deque进行元素的插入或删除时，现有元素的位置通常会被移动（拷贝）。如果使用下列任何算法，next_permutation或previous_permutation，remove、unique，rotate或reverse等等，那么对象将会被移动（拷贝），这就是STL的工作方式。 如果向容器中填充的对象拷贝操作很费时，那么向容器中填充对象这一简单操作将会成为程序的性能瓶颈。而且如果这些对象的拷贝有特殊含义，那么把它们放入容器还将不可避免地会产生错误。 当存在继承关系时，拷贝动作会导致剥离。也就是说，如果创建了一个存放基类对象的容器，却向其中插入派生类的对象，那么派生类对象（通过基类的拷贝构造函数）被拷贝进容器时，它派生类的部分将会丢失。 使拷贝动作高效、正确，并防止剥离问题发生的一个简单办法就是使容器包含对象指针，而不是对象本身。拷贝指针的速度非常快，而且总是会按你期望的方式进行。如果考虑资源的释放，智能指针是一个很好的选择。 ","date":"2023-09-01","objectID":"/posts/effective_stl_part_one/:3:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [1] | 容器","uri":"/posts/effective_stl_part_one/"},{"categories":["C++"],"content":"R04 调用 empty 而不是检查 size()是否为0 empty 通常被实现为内联函数（inline function），并且它做的仅仅是返回 size() 是否为 0. empty 对所有标准容器都是常数时间操作，而对于一些 list 实现，size 耗费线性时间 ","date":"2023-09-01","objectID":"/posts/effective_stl_part_one/:4:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [1] | 容器","uri":"/posts/effective_stl_part_one/"},{"categories":["C++"],"content":"R05 区间成员函数优先于与之对应的单元素成员函数 区间成员函数是使用两个迭代器参数来确定成员操作执行的区间，像STL算法一样。区间成员函数和for循环处理单元素成员函数在功能上是相同的，但是在效率和代码清晰度上要更胜一筹。如将一个元素插入到vector中，而它的内存满了，那么vector将申请更大容量的内容，把它的元素从旧内存拷贝到新内存，销毁旧内存中的元素，并释放旧内存，再把要插入的元素插入进来，因此插入n个新元素最多可导致次新内存的分配。 几乎所有通过插入迭代器(即利用inserter、back_inserter或front_inserter)来操作目标区间的copy调用，都可以应该被替换为对区间成员函数的调用。 对于区间创建，所有的标准容器都提供了如下形式的构造函数：container::container(InputIterator begin, InputIterator end); 对于区间插入，所有的标准序列容器都提供了如下形式的insert：void container::insert(iterator position, InputIterator begin, InputIterator end);表示在position位置插入begin到end的元素。关联容器利用比较函数决定元素的插入位置，所以不需要提供插入位置：void container::insert(InputIterator begin, InputIterator end); 对于区间删除，所有的标准容器都提供了区间形式的erase操作，但是对于序列容器和关联容器，其返回值不同。序列容器提供了如下的形式：iterator container::erase(iterator begin, iterator end);而关联容器则提供了如下形式：void container::erase(iterator begin, iterator end);为什么会有这种区别呢？据说是关联容器的erase如果返回迭代器（指向被删除元素之后的元素）会导致不可接受的性能负担。 对于区间赋值，所有的标准容器都提供了区间形式的assign：void container::assign(InputIterator begin, InputIterator end); ","date":"2023-09-01","objectID":"/posts/effective_stl_part_one/:5:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [1] | 容器","uri":"/posts/effective_stl_part_one/"},{"categories":["C++"],"content":"R06 当心C++编译器最烦人的分析机制 分析这样一段程序：有一个存有整数的文件，你想把这些整数拷贝到一个list中 ifstream dataFile(\"ints.dat\"); list\u003cint\u003e data(istream_iterator\u003cint\u003e(dataFile), istream_iterator\u003cint\u003e());//小心！结果不会是你期望的那样 这样做的思路是把一对istream_iterator传入到list的区间构造函数，从而把文件中的整数拷贝到list中，这段代码可以通过编译，但是在运行时什么也不会做，它也不会创建list，这是因为第二条语句并没有声明创建一个list。 从最基本的说起，int f(double d);声明了一个接收double参数，返回int的函数，下面两种形式是做了同样的事：int f(double (d));还有int f(double);再看int g(double (*pf)());声明了一个函数g，参数是一个函数指针，这个函数指针不接受参数，返回值是double，下面两种形式同样是做了这样的事，int g(double pf());还有int g(double ())，第三种形式省略了函数名，double后有一个空格和()，表示这是一个函数指针。 再来看最开始的例子，第二行其实不是声明了一个变量，而是声明了一个函数，其返回值是list，第一个参数名称是dataFile，类型是istream_iterator，dataFile两边的括号是多余的，会被忽略。第二个参数没有名称，类型是指向不带参数的函数的指针，该函数返回一个istream_iterator。 这符合C++中一个普遍规律，尽可能地解释为函数声明，比如这样一段代码，class Widget{ ... }; Widget w();它并没有声明一个Widget类型的对象w，而是声明了一个名为w的函数。学会识别这类言不达意是成为C++程序员的必经之路。 而为了实现最开始那段代码想要实现的功能，可以为第一个参数参数加上一对括号，即list\u003cint\u003e data((istream_iterator\u003cint\u003e(dataFile)), istream_iterator\u003cint\u003e());不幸地是，并不是所有编译器都知道这一点，几乎有一半都会拒绝上述正确的声明形式，而接收最开始错误的声明形式。更好的方式是在data声明中避免使用匿名的istream_iterator对象，将那句代码分成三句来写。 ","date":"2023-09-01","objectID":"/posts/effective_stl_part_one/:6:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [1] | 容器","uri":"/posts/effective_stl_part_one/"},{"categories":["C++"],"content":"R07 如果容器中包含了通过new操作创建的指针，切记在容器对象析构前将指针delete掉 STL容器很智能，但是还没有智能到知道是否该释放自己所包含的指针的程度。当你使用指针的容器，而其中的指针应该被删除时，为了避免资源泄露，你应该使用引用计数形式的智能指针（如shared_ptr）代替指针（普通指针不具有异常安全性），或者当容器被析构时手动删除其中的每个指针。 分析下面的代码： void doSomething(){ vector\u003cWidget*\u003e vwp; for(int i=0; i\u003cn; ++i){ vwp.push_back(new Widget); } } 当vwp的作用域结束，其中的指针并没有释放，造成了资源泄露。如果希望它们被删除，你可能会写出如下的代码： void doSomething(){ vector\u003cWidget*\u003e vwp; for(int i=0; i\u003cn; ++i){ vwp.push_back(new Widget); } //do something for(auto i=vwp.begin(); i!=vwp.end(); ++i){ delete *i; } } 这样确实可以，只要你不太挑剔的话。一个问题是这段代码做的事情和for_each相同，但是不如for_each更清晰，另一个问题是这段代码不是异常安全的。如果在vwp填充指针和从其中删除指针的过程中有异常抛出的话，同样会有资源泄露。下面就要克服这两个问题。 首先使用for_each替换上面的for循环，为了做到这一点，需要把delete变成一个函数对象。 template \u003ctypename T\u003e struct DeleteObject : public unary_function\u003cconst T*, void\u003e{//条款40会解释为什么有这个继承 void operator()(const T* ptr) const {//这是函数对象，接收一个指针作为参数 delete ptr; } } void doSomething(){ vector\u003cWidget*\u003e vwp; for(int i=0; i\u003cn; ++i){ vwp.push_back(new Widget); } //do something for_each(vwp.begin(), vwp.end(), DeleteObject\u003cWidget\u003e()); } 不幸的是，这种形式的函数对象需要指定要删除的对象类型（这里是Widget），vector中保存的Widget*，DeleteObject当然是要删除Widget*类型的指针。这种形式不仅是多余，同样可能会导致一些难以追踪的错误，比如说有代码很不明智的从string中继承。这样做非常危险，因为同其他标准STL容器一样，string是没有虚析构函数的，从没有虚析构函数的类进行共有继承是一项重要禁忌（Effective C++有详细描述）。先抛开禁忌不谈，假如有人就是写出了这样的代码，在调用for_each(vwp.begin(), vwp.end(), DeleteObject());时，因为通过基类指针删除派生类对象，而基类又没有虚析构函数的话，会产生不确定的行为。所以应该让编译器自己推断出应该删除的指针类型，如下是改进后的代码。 struct DeleteObject { template \u003ctypename T\u003e void operator()(const T* ptr) const {//这是函数对象，接收一个指针作为参数 delete ptr; } } void doSomething(){ vector\u003cWidget*\u003e vwp; for(int i=0; i\u003cn; ++i){ vwp.push_back(new Widget); } //do something for_each(vwp.begin(), vwp.end(), DeleteObject()); } 但是上述代码依然不是类型安全的，如果在创建Widget对象和执行for_each销毁对象之间有异常被抛出，就会有资源泄露，可以使用带引用计数的智能指针来解决这个问题，如下是最终优化的版本。 void doSomething(){ typedef std::shared_ptr\u003cWidget\u003e SPW;//SPW表示指向Widget的shared_ptr vector\u003cSPW\u003e vwp; for(int i=0; i\u003cn; ++i){ vwp.push_back(SPW(new Widget)); } } ","date":"2023-09-01","objectID":"/posts/effective_stl_part_one/:7:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [1] | 容器","uri":"/posts/effective_stl_part_one/"},{"categories":["C++"],"content":"R08 切勿创建包含auto_ptr的容器对象 包含auto_ptr的容器是被禁止的，这样的代码不应该被编译通过（可惜目前有些编译器做不到这一点）。首先是因为这样的容器是不可移植的，其次，拷贝一个auto_ptr意味着它指向的对象的所有权被移交到拷入的auto_ptr上，而它自身被置为NULL（相当于是移动），这种拷贝包括调用拷贝构造函数和赋值构造函数的时候。而STL容器中的拷贝遍地都是，举一个例子，调用sort函数给包含auto_ptr的vector排序时（定义好了排序函数谓词），在排序过程中，Widget的一个或几个auto_ptr可能会被置为NULL。这是因为sort的常见实现算法是，把容器中的某个元素当作“基准元素”，然后对大于或小于等于该元素的其他元素递归调用排序操作，会把待交换的元素首先赋值给一个临时变量，则自身被置为NULL了，该临时对象超过作用域也会被销毁，从而导致结果vector中的元素被置为NULL。 // 对vector所做的排序操作可能会改变它的内容！ vector\u003cauto_ptr\u003cWidget\u003e \u003e widgets;sort(widgets.begin(), widgets.end(), widgetAPcompare()); ","date":"2023-09-01","objectID":"/posts/effective_stl_part_one/:8:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [1] | 容器","uri":"/posts/effective_stl_part_one/"},{"categories":["C++"],"content":"R09 慎重选择删除元素的方法 删除容器中有特定值的所有对象 对标准容器 Container\u003cint\u003e c; 删除其中所有值为 1963 的元素的方法。 erase-remove 习惯用法（连续内存容器 vector，deque，string）： c.erase(remove(c.begin(), c.end(), 1963), c.end()); list: c.remove(1963); 关联容器：c.erase(1963); 对数时间开销，基于等价而不是相等。注意关联容器没有名为 remove 的成员函数，使用任何名为 remove 的操作都是完全错误的。 删除容器中满足特定判别式（条件）的所有对象 删除使下面的判别式返回 true 的每一个对象 bool badValue(int ); // 序列容器(vector,string,deque,list) c.erase(remove_if(c.begin(), c.end(), badValue), c.end()); // list c.remove_if(badValue); 高效方法：写一个循环遍历容器中的元素，并在遍历过程中删除元素。注意，对于关联容器（map，set，multimap，multiset），删除当前的 iterator，只会使当前的 iterator 失效。 原因：关联容器的底层使用红黑树实现，插入、删除一个结点不会对其他结点造成影响。erase 只会使被删除元素的迭代器失效。关联容器的 erase 返回值为 void，可以使用 erase(iter++) 的方式删除迭代器。 AssocContainer\u003cint\u003e c; ofstream logFile; ... for (AssocContainer\u003cint\u003e::iterator i = c.begin(); i != c.end(); /*什么也不做*/) { if (badValue(*i)) { logFile \u003c\u003c \"Erasing \" \u003c\u003c *i \u003c\u003c '\\n'; // 写日志文件 c.erase(i++); // 使用后缀递增删除元素，避免迭代器无效。 } else { ++i; } } 对于序列式容器（vector，string，deque），删除当前的 iterator 会使后面所有元素的 iterator 都失效。 原因： vector、string、deque 使用了连续分配的内存，删除一个元素会导致后面的所有元素都向前移动一个位置。所以不能使用 erase(iter++) 的方式，但可以使用 erase 方法，序列容器的 erase 可以返回下一个有效的 iterator。 ","date":"2023-09-01","objectID":"/posts/effective_stl_part_one/:9:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [1] | 容器","uri":"/posts/effective_stl_part_one/"},{"categories":["C++"],"content":"R10 了解分配器（allocator）的约定和限制 像new操作符和new[]操作符一样，STL内存分配子负责分配和释放原始内存，但是多数标准容器从不向与之关联的分配子申请内存。 2.allocator是一个模板，模板参数T表示为它分配内存的对象的类型，提供类型定义pointer和reference，但是始终让pointer为T*，reference为T\u0026。 千万不能让自定义的allocator拥有随对象而不同的状态，即不应该有非静态成员变量。 4.传给allocator的allocate成员函数的参数是对象的个数，而不是所需字节的大小，这一点和new相同，和operator new，malloc相反。同时allocate的返回值是T指针，即使尚未有T对象被构造出来，而operator new，malloc返回都是void，void*是用来指向未初始化内存的传统方式。 自定义的allocator一定要提供嵌套的rebind模板，因为标准容器依赖该模板 ","date":"2023-09-01","objectID":"/posts/effective_stl_part_one/:10:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [1] | 容器","uri":"/posts/effective_stl_part_one/"},{"categories":["C++"],"content":"R11 理解自定义分配器的正确用法 详细参考:https://jianye0428.github.io/posts/clause_11/ ","date":"2023-09-01","objectID":"/posts/effective_stl_part_one/:11:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [1] | 容器","uri":"/posts/effective_stl_part_one/"},{"categories":["C++"],"content":"R12 切勿对STL容器的线程安全性有不切实际的依赖 详细信息请参考: https://jianye0428.github.io/posts/clause_12/ STL 只支持以下多线程标准： 多个线程读是安全的。 多个线程对不同的容器做写入操作是安全的。 考虑一段单线程可以成功执行的代码。 //将vector中的5都替换成0 vector\u003cint\u003e v; vector\u003cint\u003e::iterator first5(find(v.begin(), v.end(), 5)); if(first5 != v.end()){ *first5 = 0; } 但是在多线程环境中，执行第二行语句后返回的first5的值可能会被改变，导致第三行的判断不准确，甚至一些插入/删除操作会让first5无效。所以必须在操作vector之前，再其上下位置加锁。 vector\u003cint\u003e v; getMutex(v); vector\u003cint\u003e::iterator first5(find(v.begin(), v.end(), 5)); if(first5 != v.end()){ *first5 = 0; } releaseMutex(v); 更为完善的方法是实现一个Lock类，在构造函数中加锁，在析构函数中释放锁，即RAII。 ref: [1]. https://www.cnblogs.com/Sherry4869/p/15128250.html [2]. https://blog.csdn.net/zhuikefeng/article/details/108164117#t42 ","date":"2023-09-01","objectID":"/posts/effective_stl_part_one/:12:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [1] | 容器","uri":"/posts/effective_stl_part_one/"},{"categories":["C++"],"content":"STL中copy算法 STL有很多有趣的地方，其中一个是虽然有11个名字带“copy”的算法，但没有一个是copy_if。 copy copy_backward replace_copy reverse_copy replace_copy_if unique_copy remove_copy rotate_copy remove_copy_if partial_sort_copy unintialized_copy 如果你只是简单地想要拷贝一个区间中满足某个判断式的元素，你只能自己做。 ","date":"2023-08-30","objectID":"/posts/clause_36/:1:0","tags":["Effective STL"],"title":"Effective STL [36] | 了解copy_if的正确实现","uri":"/posts/clause_36/"},{"categories":["C++"],"content":"自己实现 假设你有一个函数来决定一个Widget是否有缺陷的： bool isDefective(const Widget\u0026 w); 而且你希望把一个vector中所有有缺陷的Widget写到cerr。如果存在copy_if，你可以简单地这么做： vector\u003cWidget\u003e widgets; ... // 这无法编译：STL中并没有copy_if copy_if(widgets.begin(), widgets.end(), ostream_iterator\u003cWidget\u003e(cerr, \"\\n\"), isDefective); 一个不很正确的copy_if实现 这里有一个合理的看待copy_if： template\u003ctypename InputIterator, typename OutputIterator, typename Predicate\u003e OutputIterator copy_if(InputIterator begin, InputIterator end, OutputIterator destBegin, Predicate p) { return remove_copy_if(begin, end, destBegin, not1(p)); } 虽然STL并没有让你说“拷贝每个判断式为true的东西”，但它的确让你说了“拷贝除了判断式不为true以外的每个东西”。 要实现copy_if，似乎我们需要做的就只是加一个not1在我们希望传给copy_if的判断式前面，然后把这个结果判断式传给remove_copy_if，结果就是上面的代码。 如果上面的理由有效，我们就可以用这种方法写出有缺陷的Widget： // 不会编译的善意代码 copy_if(widgets.begin(), widgets.end(), ostream_iterator\u003cWidget\u003e(cerr, \"\\n\"), isDefective); 你的STL平台将会敌视这段代码，因为它试图对isDefective应用not1（这个应用出现在copy_if内部）。 not1不能直接应用于一个函数指针，函数指针必须先传给ptr_fun。要调用这个copy_if实现，你必须传递的不仅是一个函数对象，而且是一个可适配的函数对象。 标准STL算法从来不要求它们的仿函数是可适配的，copy_if也不应该要求。 ","date":"2023-08-30","objectID":"/posts/clause_36/:2:0","tags":["Effective STL"],"title":"Effective STL [36] | 了解copy_if的正确实现","uri":"/posts/clause_36/"},{"categories":["C++"],"content":"正确的实现 template\u003ctypename InputIterator, typename OutputIterator, typename Predicate\u003e OutputIterator copy_if(InputIterator begin, InputIterator end, OutputIterator destBegin, Predicate p) { while (begin != end) { if (p(*begin)) *destBegin++ == *begin; ++begin; } return destBegin; } ","date":"2023-08-30","objectID":"/posts/clause_36/:3:0","tags":["Effective STL"],"title":"Effective STL [36] | 了解copy_if的正确实现","uri":"/posts/clause_36/"},{"categories":["C++"],"content":"前言 Effective-STL总结系列分为七部分，本文为第七部分，涉及原书第七章，内容范围Rule43~50。为方便书写，Rule43简写为R43。 Effective-STL系列List 本博客站点系列内容如下： 💡 Effective STL(第3版)精读总结(一) 💡 Effective STL(第3版)精读总结(二) 💡 Effective STL(第3版)精读总结(三) 💡 Effective STL(第3版)精读总结(四) ","date":"2023-08-28","objectID":"/posts/effective_stl_part_seven/:0:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [7] | 在程序中使用STL","uri":"/posts/effective_stl_part_seven/"},{"categories":["C++"],"content":"R43 算法调用优先于手写的循环 调用算法优于手写循环： 效率：算法比手写的循环效率更高。 正确性：手写循环比使用算法容易出错。 可维护性：使用算法的代码更加简洁明了。 例子：P155， 算法的名称表明了它的功能，而 for、while、do 循环不能。 手写循环需要维护迭代器的有效性。 ","date":"2023-08-28","objectID":"/posts/effective_stl_part_seven/:1:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [7] | 在程序中使用STL","uri":"/posts/effective_stl_part_seven/"},{"categories":["C++"],"content":"R44 容器的成员函数优先于同名的算法 原因: 成员函数往往速度快。 成员函数通常与容器结合得更加紧密。（同样的名称做不同的事情） 对于 map 和 multimap 而言: 成员函数可以获得对数时间的性能。 成员函数的相同是等价，而算法是相等。 它们的成员函数只统计检查每个 pair 对象的键部分。而算法同时检查键和值/(key,value)对。 对于 list 而言，list 成员函数只是简单地维护指针，可以提供更好的性能。list 的 remove、remove_if、unqiue 则实实在在的删除了元素。sort 算法不能直接应用于 list，因为 sort 需要随机访问迭代器，而 list 的迭代器是双向迭代器。 ","date":"2023-08-28","objectID":"/posts/effective_stl_part_seven/:2:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [7] | 在程序中使用STL","uri":"/posts/effective_stl_part_seven/"},{"categories":["C++"],"content":"R45 正确区分count、find、binary_search、lower_bound、upper_bound和equal_range 假设你要在容器中查找一些信息，标题列出的几个函数应该怎么选择呢？首先应该考虑区间是否是排序的，如果是排序的，则binary_search、lower_bound、upper_bound和equal_range具有更快的查找速度，如果不是排序的，那么你只能选择count、count_if、find、find_if，这些算法仅提供线性时间的查找效率。但是这些函数还是有区别的，count、count_if、find、find_if使用相等性进行查找，binary_search、lower_bound、upper_bound和equal_range使用等价性进行查找。 考虑count和find的区别，count表示区间是否存在待查找的值，如果存在有多少个？find表示区间是否存在待查找的值，如果存在它在哪里？假设你只想知道区间中是否存在待查找的值，如果是使用count会更方便一些，因为使用find还需要比较find返回的指针是否是容器的end()，但是因为find找到第一个符合查找的值就会返回，count一定会遍历到容器的末尾，所以find的效率更高。 当你的区间是排序的，那么你就可以使用对数时间查找的四种方法。与标准C/C++函数库中的bsearch不同的是，binary_search仅判断区间是否存在待查找的值（返回值是bool），如果你还想知道待查找值得位置，可以使用其他三种方法，先考虑lower_bound，lower_bound查找特定值会返回一个迭代器，同样你需要判断这个迭代器的结果，除了要判断这个迭代器是否是end()，还要判断其指向的值是否是待查找的值，所以很多人会这么写： vector\u003cWidget\u003e::iterator i = lower_bound(vw.begin(), vw.end(), w); if(i != vw.end() \u0026\u0026 *i == w) { ... }//这里有一个错误 这里*i == w是一个相等性测试，但是lower_bound使用等价性进行搜索的，虽然大多数情况下等价性测试和相等性测试的结果相同，但是条款19也说明了违背这个情况也很常见，所以正确也更方便的方式是使用equal_range，equal_range会返回一对迭代器，第一个迭代器等于lower_bound返回的迭代器，第二个迭代器等于upper_bound返回的迭代器，equal_range返回了一个子区间，其中的值与待查找的值等价，如果返回的两个迭代器相同，等说明查找的区间没有待查找的值，而子区间的长度就是等价值的个数，可以使用distance得到。 再考虑lower_bound和upper_bound的使用场景，这次我不是希望查找某个元素，而是想找到第一个比特定值大的元素的位置，这个特定值可能不在容器中，那么可以使用lower_bound，如果希望找到第一个大于或等于特定值的元素的位置，那么可以使用upper_bound。 ","date":"2023-08-28","objectID":"/posts/effective_stl_part_seven/:3:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [7] | 在程序中使用STL","uri":"/posts/effective_stl_part_seven/"},{"categories":["C++"],"content":"R46 考虑使用函数对象而不是函数作为 STL 算法的参数 第一个原因是因为效率。随着抽象程度的提高，所生成代码的效率是在降低的，比如几乎在所有情况下，操作包含一个double的对象比直接操作double都是要慢的，但是可能令你感到惊讶的是，将函数对象传递给STL算法往往比传递函数更加高效。比如说你想生成一个降序排列的vector，你可以使用函数对象，即greater，也可以使用一个自定义的比较函数，而第一种情况往往是更快的，这是因为如果一个函数对象的operator()函数被声明是内联的（可以通过inline显式声明，也可以定义在类中隐式声明），那么它的函数体可被编译器直接优化，但是传递函数指针则不行，编译器不能优化。 sort(v.begin(), v.end(), doubleGreater); sort(v.begin(), v.end(), greater\u003cdouble\u003e()); 使用greater\u003cdouble\u003e()的sort调用比使用doubleGreater的 sort 调用快得多。原因：函数内联，sort 不包含函数调用。 抽象性利益：C++ 的 sort 算法性能总是优于 C 的 qsort。在运行时，sort 算法以内联方式调用它的比较函数，而 qsort 则通过函数指针调用它的比较函数。 使用函数对象，可以让你的程序正确地通过编译，避免语言本身的缺陷。 2. 第二个原因是正确性，有的时候STL平台会拒绝一些完全合法的代码，如下： //完全合法的代码但是不能通过编译 set\u003cstring\u003e s; transform(s.begin(), s.end(), ostream_iterator\u003cstring::size_type\u003e(cout, \"\\n\"), mem_fun_ref(\u0026string::size)); //可以改用函数对象的形式 struct stringSize : public unary_function\u003cstring, string::size_type\u003e{ string::size_type operator()(const string\u0026 s) const { return s.size(); } }; ","date":"2023-08-28","objectID":"/posts/effective_stl_part_seven/:4:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [7] | 在程序中使用STL","uri":"/posts/effective_stl_part_seven/"},{"categories":["C++"],"content":"R47 避免产生 “直写型” （write only）的代码 所谓”直写型“的代码是指一行代码中有过于复杂的嵌套函数调用，可能对于编写代码的人，这行代码看似非常直接和简单，但是对于阅读代码的人则显得难以理解。所以在遇到这种写出“直写型”代码时，应该将其拆分成多行代码，或者使用typedef起别名的形式，让代码更易于阅读。 ","date":"2023-08-28","objectID":"/posts/effective_stl_part_seven/:5:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [7] | 在程序中使用STL","uri":"/posts/effective_stl_part_seven/"},{"categories":["C++"],"content":"R48 总是包含（#include）正确的头文件 有的时候即使漏掉了必要的头文件，程序同样可以编译，这是因为C++标准并没有规定标准库中头文件之间的相互包含关系，这就导致了某个头文件包含了其他头文件，如包含了。但是这种程序往往是不可移植的，即使在你的平台上可以编译，但是在其他平台上就可能会编译不过，所以解决此类问题的一条原则就是总是include必要的头文件 ","date":"2023-08-28","objectID":"/posts/effective_stl_part_seven/:6:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [7] | 在程序中使用STL","uri":"/posts/effective_stl_part_seven/"},{"categories":["C++"],"content":"R49 学会分析与 STL 相关的编译器诊断信息 在程序编译或者运行出错时，有时编译器给出的诊断信息非常混乱和难以阅读。对于这些信息可以使用同义词替换的方法进行简化，比如说将std::basic_string\u003c\u003e替换成string，将std::map\u003c\u003e替换成map，将看不懂的STL内部模板std::_Tree替换成something ","date":"2023-08-28","objectID":"/posts/effective_stl_part_seven/:7:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [7] | 在程序中使用STL","uri":"/posts/effective_stl_part_seven/"},{"categories":["C++"],"content":"R50 熟悉与 STL 相关的 web 站点 SGI STL 站点 STLport 站点 Boost 站点 Ref: [1]. htTps://www.cnblogs.com/Sherry4869/p/15162253.html [2]. https://blog.csdn.net/zhuikefeng/article/details/108164117#t35 [3]. https://zhuanlan.zhihu.com/p/458156007 ","date":"2023-08-28","objectID":"/posts/effective_stl_part_seven/:8:0","tags":["Effective STL"],"title":"Effective STL 精读总结 [7] | 在程序中使用STL","uri":"/posts/effective_stl_part_seven/"},{"categories":["C++"],"content":"怎么使用STL来进行忽略大小写的字符串比较? 如果你忽略国际化问题而且只关注于设计成字符串strcmp那样的类型，这个任务很简单。 如果你要有strcmp不具有的按语言处理字符串中的字符的能力（即，容纳文本的字符串是除了英语以外的语言）或程序使用了区域设置而不是默认的，这个任务很困难。 想要使用忽略大小写比较的程序员通常需要两种不同的调用接口： 一种类似strcmp（返回一个负数、零或正数） 另一种类似operator（返回true或false） ","date":"2023-08-28","objectID":"/posts/clause_35/:1:0","tags":["Effective STL"],"title":"Effective STL [35] | 通过mismatch或lexicographical比较实现简单的忽略大小写字符串比较","uri":"/posts/clause_35/"},{"categories":["C++"],"content":"确定两个字符除了大小写之外是否相等 类似strcmp进行的字符串比较，只考虑类似strcmp的字符串比较： // 忽略大小写比较字符 // c1和c2，如果c1 \u003c c2返回-1， // 如果c1==c2返回0，如果c1 \u003e c2返回1 int ciCharCompare(char c1, char c2) { // 这些语句的解释看下文 int Ic1 = tolower(static_cast\u003cunsigned char\u003e(c1)); int Ic2 = tolower(static_cast\u003cunsigned char\u003e(c2)); if (Ic1 \u003c Ic2) return -1; if (Ic1 \u003e Ic2) return 1; return 0; } 这个函数遵循了strcmp，可以返回一个负数、零或正数，依赖于c1和c2之间的关系。 tolower 与strcmp不同的是，ciCharCompare在进行比较前把两个参数转化为小写，从而忽略大小写的字符比较。 正如\u003ccctype\u003e（也是\u003cctype.h\u003e）里的很多函数，tolower的参数和返回值类型是int，但除非这个int是EOF，它的值必须能表现为一个unsigned char。 在C和C++中，char可能或可能不是有符号的（依赖于实现），当char有符号时，唯一确认它的值可以表现为unsigned char的方式是在调用tolower之前转换一下。 基于mismatch实现 给定了ciCharCompare，就很容易写出我们的第一个忽略大小写的两个字符串比较函数，提供了一个类似strcmp的接口。 ciStringCompare这个函数，返回一个负数、零或正数，依赖于要比较的字符串的关系。 它基于mismatch算法，因为mismatch确定了两个区间中第一个对应的不相同的值的位置。 我们必须确定一个字符串是否比另一个短，短的字符串作为第一个区间传递。 因此我们可以把真正的工作放在一个叫做ciStringCompareImpl的函数，然后让ciStringCompare简单地确保传进去的实参顺序正确，如果实参交换了就调整返回值： int ciStringCompareImpl(const string \u0026s1, const string \u0026s2); // 实现请看下文 int ciStringCompare(const string \u0026s1, const string \u0026s2) { if (s1.size() \u003c= s2.size()) return ciStringCompareImpl(s1, s2); else return -ciStringCompareImpl(s2, s1); } 在ciStringCompareImpl中，大部分工作由mismatch来完成。它返回一对迭代器，表示了区间中第一个对应的字符不相同的位置： int ciStringCompareImpl(const string \u0026si, const strings s2) { // PSCI = “pair of string::const_iterator” typedef pair\u003cstring::const_iterator, string::const_iterator\u003e PSCI; // 下文解释了为什么我们需要not2； PSCI p = mismatch(s1.begin(), s1.end(), s2.begin(), not2(ptr_fun(ciCharCompare))); if (p.first == s1.end()) { // 如果为真，s1等于s2或s1比s2短 if (p.second == s2.end()) return 0; else return -1; } return ciCharCompare(*p.first, *p.second); // 两个字符串的关系 和不匹配的字符一样 } 比较过程 当字符匹配时这个判断式返回true，因为当判断式返回false时mismatch会停止。我们不能为此使用ciCharCompare，因为它返回-1、1或0，而当字符匹配时它返回0，就像strcmp。 如果我们把ciCharCompare作为判断式传给mismatch，C++会把ciCharCompare的返回类型转换为bool，而当然bool中零的等价物是false，正好和我们想要的相反！同样的，当ciCharCompare返回1或-1，那会被解释成true，因为，就像C，所有非零整数值都看作true。这再次和我们想要的相反。 要修正这个语义倒置，我们在ciCharCompare前面放上not2和ptr_fun。 std::not1 和 std::not2 std::not1 和 std::not2是用来把“符合某种条件的函数对象”转换为反义函数对象的函数。 std::ptr_fun用来把函数指针封装为符合某种条件的函数对象的函数，C++11 里可以用std::bind或std::function代替 ","date":"2023-08-28","objectID":"/posts/clause_35/:2:0","tags":["Effective STL"],"title":"Effective STL [35] | 通过mismatch或lexicographical比较实现简单的忽略大小写字符串比较","uri":"/posts/clause_35/"},{"categories":["C++"],"content":"lexicographical_compare 可以在关联容器中用作比较函数的函数，可以把ciCharCompare修改为一个有判断式接口的字符比较函数，然后把进行字符串比较的工作交给STL中名字第二长的算法——lexicographical_compare： // 返回在忽略大小写的情况下c1是否在c2前面； bool ciCharLess(char c1, char c2) { // 条款46解释了为什么一个函数对象可能 比函数好 tolower(static_cast\u003cunsigned char\u003e(c1)) \u003c tolower(static_cast\u003cunsigned char\u003e(c2)); } bool ciStringCompare(const string \u0026s1, const string \u0026s2) { // 算法调用的讨论在下文 return lexicographical_compare(s1.begin(), s1.end(), s2.begin(), s2.end(), ciCharLess); } lexicographical_compare是strcmp的泛型版本。 strcmp只对字符数组起作用，但lexicographical_compare对所有任何类型的值的区间都起作用。 同时，strcmp总是比较两个字符来看看它们的关系是相等、小于或大于另一个。lexicographical_compare可以传入一个决定两个值是否满足一个用户定义标准的二元判断式。 比较过程 在上面的调用中，lexicographical_compare用来寻找s1和s2第一个不同的位置，基于调用ciCharLess的结果。如果，使用那个位置的字符，ciCharLess返回true，lexicographical_compare也是；如果，在第一个字符不同的位置，从第一个字符串来的字符先于对应的来自第二个字符串的字符，第一个字符串就先于第二个。 就像strcmp，lexicographical_compare认为两个相等值的区间是相等的，因此它对于这样的两个区间返回false：第一个区间不在第二个之前。 也像strcmp，如果第一个区间在发现不同的对应值之前就结束了，lexicographical_compare返回true：一个先于任何区间的前缀是一个前缀。 ","date":"2023-08-28","objectID":"/posts/clause_35/:3:0","tags":["Effective STL"],"title":"Effective STL [35] | 通过mismatch或lexicographical比较实现简单的忽略大小写字符串比较","uri":"/posts/clause_35/"},{"categories":["ML"],"content":"一、 基本定义 假设给定事件 $x$, 则我们有以下定义: Probability: 取值0~1 $$p(x) 或 q(x)$$ Information: 对$p(x)$取对数，加符号得正值 $$I(p)=-\\log p(x)$$ 概率越高，包含的信息小，因为事件越来越确定。相反，概率越低，包含的信息越多，因为事件具有很大的不确定性。 (Shannon)Entropy(信息熵): $p(x)$对$I(x)$ 平均 $$ \\begin{aligned} H(p)\u0026 =\\mathbb{E}_{x\\sim P}[I(p)] \\ \u0026=\\sum p(x)I(p) \\ \u0026=-\\sum p(x)\\log p(x) \\end{aligned} $$ 熵是信息的平均，直观上，Shannon熵是信息在同一分布下的平均。 KL散度来源于信息论，信息论的目的是以信息含量来度量数据。信息论的核心概念是信息熵(Entropy)，使用H来表示。概率论中概率分布所含的信息量同样可以使用信息熵来度量。 Note 对于任意概率事件，由于其概率$p(x) \\geq 0$ 且 $p(x) \\leq 0$, 因此 $H(p) \\geq 0$. Cross-Entropy: $p(x)$对$I(q)$平均: $$ \\begin{aligned} H(p,q)\u0026 =\\mathbb{E}_{x\\sim P}[I(q)] \\ \u0026=\\sum p(x)I(q) \\ \u0026=-\\sum p(x)\\log q(x) \\end{aligned} $$ 熵是信息的平均，直观上，交叉熵是信息在不同分布下的平均。 KL divergence(Relative entropy/Information gain): $$ \\begin{aligned} D_{KL}(p||q)\u0026 =H(p,q)-H(p) \\ \u0026=-\\sum p(x)\\log q(x)+\\sum p(x)\\log p(x) \\ \u0026=-\\sum p(x)\\log\\frac{q(x)}{p(x)} \\ \u0026=\\sum p(x)\\log\\frac{p(x)}{q(x)} \\end{aligned} $$ 相对熵 = 交叉熵 - shannon熵 非对称$D_{KL}(p||q)\\neq D_{KL}(q||p)$，亦不满足三角不等式，故不是距离。 $D_{KL}(p||q)$为$p$相对于$q$，值非负，取零若$p=q$。从公式上看，就是拿$q$替代$p$后熵的变化。 $KL = Kullback-Leibler$ 所谓KL散度，是指当某分布q(x)被用于近似p(x)时的信息损失。 $$ D(p||q)=\\sum_{x\\in X}p(x)\\log\\frac{p(x)}{q(x)} $$ 也就是说，q(x)能在多大程度上表达p(x)所包含的信息，KL散度越大，表达效果越差。 ","date":"2023-08-26","objectID":"/posts/kldivergence/:1:0","tags":["KL Divergence"],"title":"KL Divergence 详解","uri":"/posts/kldivergence/"},{"categories":["ML"],"content":"二、 KL divergence 一些性质（非正式）证明 非对称性 $$ D_{KL}(p||q)-D_{KL}(q||p)=\\sum\\left(p(x)+q(x)\\right)\\log\\frac{p(x)}{q(x)} $$ 易知，当$p(x) \\neq q(x)$时，上式不为0。故，$D_{KL}(p||q)$和$D_{KL}(q||p)$非对称，是不同的。（此部分侧重于说明它们不是不同的） 非负性 $$ \\begin{aligned} -D_{KL}(p||q)\u0026 =\\sum p(x)\\log\\frac{q(x)}{p(x)} \\cr \u0026\\leq\\log\\sum p(x)\\frac{q(x)}{p(x)} \\cr \u0026=\\log1 \\cr \u0026=0 \\end{aligned} $$ 其中，不等式部分使用了Jensen’s inequality 凹性 $$ \\begin{aligned} \u0026D_{KL}[\\lambda p_1(x)+(1-\\lambda)p_2(x)||\\lambda q_1(x)+(1-\\lambda)q_2(x)] \\cr \u0026=\\sum\\left[\\lambda p_1(x)+(1-\\lambda)p_2(x)\\right]\\log\\frac{[\\lambda p_1(x)+(1-\\lambda)p_2(x)]}{[\\lambda q_1(x)+(1-\\lambda)q_2(x)]} \\cr \u0026\\leq\\sum\\left[\\lambda p_1(x)\\log\\frac{\\lambda p_1(x)}{\\lambda q_1(x)}+(1-\\lambda)p_2(x)\\log\\frac{(1-\\lambda)p_2(x)}{(1-\\lambda)q_2(x)}\\right] \\cr \u0026=\\lambda\\sum p_1(x)\\log\\frac{p_1(x)}{q_1(x)}+(1-\\lambda)\\sum p_2(x)\\log\\frac{p_2(x)}{q_2(x)} \\cr \u0026=\\lambda D_{KL}[p_1(x)||q_1(x)]+(1-\\lambda)D_{KL}[p_2(x)||q_2(x)] \\end{aligned} $$ 其中，不等式部分用到了log sum inequality ","date":"2023-08-26","objectID":"/posts/kldivergence/:2:0","tags":["KL Divergence"],"title":"KL Divergence 详解","uri":"/posts/kldivergence/"},{"categories":["ML"],"content":"三、最小化KL divergence目标函数 为了方便说明，我们基于定义在某个空间$X$上的分布$P$和$Q$来重写一下KL， 如下所示： $$ D_{KL}(P||Q)=\\mathbb{E}_{x\\sim P}[\\log\\frac{P(X)}{Q(X)}] $$ 假设，$P$为真实的分布函数，我们想要用带参数 $\\theta$ 的分布函数 $Q$，即 $Q_{\\theta}$ ，去近似。也就是说，通过选取参数$\\theta$， 让 $Q_{\\theta}$ 和 $P$ 在某种意义上具有相似性。下面，我们分别将选取正向KL和反向KL做为目标函数进行说明。为了方便，我们假设 $P$ 为双峰分布，$Q_{\\theta}$ 为正太分布，故 $\\theta$ 包含均值和方差两个参数。 最小化正向KL目标函数 目标函数如下： $$ \\begin{aligned} \u0026\\arg\\min_{\\theta}D_{KL}(P||Q_{\\theta}) \\cr \u0026=\\arg\\min_\\theta\\mathbb{E}{x\\sim P}[\\log\\frac{P(X)}{Q(X)}] \\cr \u0026=\\arg\\min\\theta\\mathbb{E}{x\\sim P}[-\\log Q\\theta(X)]-H[P(X)] \\cr \u0026=\\arg\\min_\\theta\\mathbb{E}{x\\sim P}[-\\log Q\\theta(X)] \\cr \u0026=\\arg\\max_\\theta\\mathbb{E}{x\\sim P}[\\log Q\\theta(X)] \\end{aligned} $$ 从此处可以看出最小化正向KL目标函数，其实是等价于通过 $Q_{\\theta}$ 进行最大似然估计。也就是说，数据 $x$ 由 $P$ 产生，基于这些数据，我们选取 $\\theta$ 让平均在 $P(X)$ 上的 $\\log Q_{\\theta}(X)$ 似然函数最大，即: 平均P(X)各个峰太，P(X)概率高的地方，$Q_{\\theta}(X)$ 概率也要高 所以我们有下图mean-seeking的结果 (你也可以从信息/熵的角度去理解，道理是一样的) 最小化反向KL目标函数 目标函数如下： $$ \\begin{aligned} \u0026\\arg\\min_{\\theta}D_{KL}(Q_{\\theta}||P) \\cr \u0026=\\arg\\min_\\theta\\mathbb{E}{x\\sim Q\\theta}[\\log\\frac{Q_\\theta}{P(X)}] \\cr \u0026=\\arg\\min_\\theta\\mathbb{E}{x\\sim Q\\theta}[-\\log P(X)]-H[Q_\\theta(X)] \\cr \u0026=\\arg\\max_\\theta\\mathbb{E}{x\\sim Q\\theta}\\left[\\log P(X)\\right]+H[Q_\\theta(X)] \\end{aligned} $$ 此时，我们需要选取参数 $\\theta$，让平均在 $Q_{\\theta}(X)$ 上的 $\\log P(X)$ 似然函数最大;同时，让Shannon熵 $H(Q_{\\theta}(X))$ 也比较大，即约束 $Q_{\\theta}(X)$ 不要过于集中。总的来看，我们有： 平均 $Q_{\\theta}(X)$ 各个峰太，$Q_{\\theta}(X)$ 概率高的地方，$P(X)$ 概率也要高，但 $Q_{\\theta}(X)$ 不能过于集中 可以想象，如果没有 $H[Q_{\\theta}(X)]$ 的约束，可能会调整 $\\theta$，让 $Q_{\\theta}(X)$ 集中于 $P(X)$ 最大的地方，得到的值也会比较大。所以，$H[Q_{\\theta}(X)]$ 起到了一个正则化（regularization）的效果。 所以我们有下图mode-seeking 的结果: 正向最小化和反向最小化放在一起对比： 正向和反向最小化 此部分代码来自参考文献3，但在调用logsumexp时，有点问题，故做了一个微小改动，代码放在微信公众号MoData文章最后，如果感兴趣，点击此处。 相关参考资料 [1]. Cover, T. M., and J. A. Thomas. “Elements of Information Theory,(2nd edn, 2006).” DOI: https://doi. org/10.1002 X 47174882 (2006). [2]. https://dibyaghosh.com/blog/probability/kldivergence.html [3]. https://www.tuananhle.co.uk/notes/r ref: [1]. KL-Divergence详解 [2]. https://www.zhihu.com/tardis/zm/art/95687720?source_id=1005 [3]. http://hanj.cs.illinois.edu/cs412/bk3/KL-divergence.pdf [4]. KL 进阶 ","date":"2023-08-26","objectID":"/posts/kldivergence/:3:0","tags":["KL Divergence"],"title":"KL Divergence 详解","uri":"/posts/kldivergence/"},{"categories":["C++"],"content":"不是所有算法可以用于任意区间。比如，remove需要前向迭代器和可以通过这些迭代器赋值的能力。所以，它不能应用于由输入迭代器划分的区间，也不能是map或multimap，也不能是set和multiset的一些实现。 同样，很多排序算法需要随机访问迭代器，所以不可能在一个list的元素上调用这些算法。 最常见的就是一些算法需要有序值的区间。无论何时都应该坚持这个需求，因为冒犯它不仅会导致编译器诊断，而且会造成未定义的运行期行为。 既可以和有序又可以和无序区间合作的算法很少，但当操作有序区间的时候它们最有用。 ","date":"2023-08-26","objectID":"/posts/clause_34/:0:0","tags":["Effective STL"],"title":"Effective STL [34] | 注意哪个算法需要有序区间","uri":"/posts/clause_34/"},{"categories":["C++"],"content":"只能操作有序数据的算法的表 binary_search lower_bound upper_bound equal_range set_union set_intersection set_difference set_symmetric_difference merge inplace_merge includes ","date":"2023-08-26","objectID":"/posts/clause_34/:1:0","tags":["Effective STL"],"title":"Effective STL [34] | 注意哪个算法需要有序区间","uri":"/posts/clause_34/"},{"categories":["C++"],"content":"一般用于有序区间，但不强制要求 unique unique_copy ","date":"2023-08-26","objectID":"/posts/clause_34/:2:0","tags":["Effective STL"],"title":"Effective STL [34] | 注意哪个算法需要有序区间","uri":"/posts/clause_34/"},{"categories":["C++"],"content":"binary_search、lower_bound、upper_bound和equal_range 搜索算法binary_search、lower_bound、upper_bound和equal_range需要有序区间，因为它们使用二分法查找来搜索值。像C库中的bsearch，这些算法保证了对数时间的查找，但作为交换的是，你必须给它们已经排过序的值。 实际上，仅当传给它们的是随机访问迭代器时它们才能保证有那样的性能。 如果给它们威力比较小的迭代器（比如双向迭代器），它们仍然进行对数次比较，但运行是线性时间的。那是因为，缺乏进行“迭代器算术（arithmetic）”的能力。它们在搜索的区间中需要花费线性时间来从一个地方移动到另一个地方。 ","date":"2023-08-26","objectID":"/posts/clause_34/:3:0","tags":["Effective STL"],"title":"Effective STL [34] | 注意哪个算法需要有序区间","uri":"/posts/clause_34/"},{"categories":["C++"],"content":"union、set_intersection、set_difference和set_symmetric_difference 算法set_union、set_intersection、set_difference和set_symmetric_difference的四人组提供了线性时间设置它们名字所提出的操作的性能。 为什么它们需要有序区间？因为如果不是的话，它们不能以线性时间完成它们的工作。 你会发现，需要有序区间的算法为了比它们用于可能无序区间提供更好的性能而这么做。 ","date":"2023-08-26","objectID":"/posts/clause_34/:4:0","tags":["Effective STL"],"title":"Effective STL [34] | 注意哪个算法需要有序区间","uri":"/posts/clause_34/"},{"categories":["C++"],"content":"merge和inplace_merge merge和inplace_merge执行了有效的单遍合并排序算法：它们读取两个有序区间，然后产生一个包含了两个源区间所有元素的新有序区间。 它们以线性时间执行，如果它们不知道源区间已经有序就不能完成。 ","date":"2023-08-26","objectID":"/posts/clause_34/:5:0","tags":["Effective STL"],"title":"Effective STL [34] | 注意哪个算法需要有序区间","uri":"/posts/clause_34/"},{"categories":["C++"],"content":"includes includes 用来检测是否一个区间的所有对象也在另一个区间中。 因为includes可能假设它的两个区间都已经有序，所以它保证了线性时间性能。没有那个保证，一般来说它会变慢。 ","date":"2023-08-26","objectID":"/posts/clause_34/:6:0","tags":["Effective STL"],"title":"Effective STL [34] | 注意哪个算法需要有序区间","uri":"/posts/clause_34/"},{"categories":["C++"],"content":"unique和unique_copy unique和unique_copy甚至在无序区间上也提供了定义良好的行为。 看看标准是怎么描述unique的行为的： 从每个相等元素的连续组中去除第一个以外所有的元素。 如果你要unique从一个区间去除所有重复值（也就是，让区间中所有值“唯一”），你必须先确保所有重复值一个接着一个。那是排序完成的东西之一。 实际上，unique一般用于从区间中去除所有重复值，所以你几乎总是要确保你传递给unique（或unique_copy）的区间是有序的。Unix开发者会发现STL的unique和Unix的uniq之间有惊人的相似。 顺便说说，unique从一个区间除去元素的方式和remove一样，也就是说它只是区分出不除去的元素。 ","date":"2023-08-26","objectID":"/posts/clause_34/:7:0","tags":["Effective STL"],"title":"Effective STL [34] | 注意哪个算法需要有序区间","uri":"/posts/clause_34/"},{"categories":["C++"],"content":"排序 因为STL允许你指定用于排序的比较函数，不同的区间可能以不同的方式排序。 比如，给定两个int的区间，一个可能以默认方式排序（也就是升序），而另一个使用greater\u003cint\u003e排序，因此是降序。 给定Widget的两个区间，一个可能以价格排序而另一个可能以年龄排序。因为有很多不同的方式来排序，所以保证给STL所使用的排序相关信息一致是很重要的。 如果你传一个区间给一个也带有比较函数的算法，确保你传递的比较函数行为和你用于排序这个区间的一样。 vector\u003cint\u003e v; // 建立一个vector，把一些数据放进去 ... sort(v.begin(), v.end(), greater\u003cint\u003e()); // 降序排列 ... // 使用这个vector（没有改变它） // 在这个vector中搜索5 bool is3Exists = binary_search(v.begin(), v.end(), 3); // 假设它是升序排列！ 默认情况下，binary_search假设它搜索的区间是以“\u003c”排序（也就是，值是升序），但在本例中，这个vector是降序。当你在值的排列顺序和算法所期望的不同的区间上调用binary_search (或lower_bound等）会导致未定义的结果。 ","date":"2023-08-26","objectID":"/posts/clause_34/:8:0","tags":["Effective STL"],"title":"Effective STL [34] | 注意哪个算法需要有序区间","uri":"/posts/clause_34/"},{"categories":["C++"],"content":"正确排序方式 要让代码行为正确，你必须告诉binary_search要使用和sort同样的比较函数： bool is3Exists = // 搜索3 binary_search(v.begin(), v.end(), 3, greater\u003cint\u003e()); // 比较函数把greater作为 所有需要有序区间的算法（也就是除了unique和unique_copy外本条款的所有算法）通过等价来判断两个值是否“相同”，就像标准关联容器（它们本身是有序的）。相反，unique和unique_copy判断两个对象“相同”的默认方式是通过相等，但是你可以通过传给这些算法一个定义了“相同”的意义的判断式来覆盖这个默认情况。 ","date":"2023-08-26","objectID":"/posts/clause_34/:8:1","tags":["Effective STL"],"title":"Effective STL [34] | 注意哪个算法需要有序区间","uri":"/posts/clause_34/"},{"categories":["C++"],"content":"总结 11个需要有序区间的算法为了比其他可能性提供更好的性能而需要传给它们有序区间，需要保证用于算法的比较函数和用于排序的一致。 ","date":"2023-08-26","objectID":"/posts/clause_34/:9:0","tags":["Effective STL"],"title":"Effective STL [34] | 注意哪个算法需要有序区间","uri":"/posts/clause_34/"},{"categories":["C++"],"content":"删除含有指针的容器元素 如果你在管理一堆动态分配的Widgets，每一个都可能通过检验，你把结果指针保存在一个vector中： class Widget{ public: ... // 这个Widget是否通过检验 bool isCertified() const; ... }; // 建立一个vector然后用动态分配的Widget的指针填充 vector\u003cWidget*\u003e v; ... v.push_back(new Widget); 当和v工作一段时间后，你决定除去未通过检验的Widget，因为你不再需要它们了。 尽量用算法调用代替显式循环和关于remove和erase之间关系的描述，你自然会想到转向erase-remove惯用法，虽然这次你使用了remove_if： v.erase(remove_if(v.begin(), v.end(), // 删除未通过检验的Widget指针 not1(mem_fun(\u0026Widget::isCertified))), v.end()); // 关于mem_fun的信息参见条款41 条款7介绍过摧毁容器中的一个指针也不会删除指针指向的东西的讨论，所以这里当调用erase时，极可能你已经泄漏了资源。 ","date":"2023-08-26","objectID":"/posts/clause_33/:1:0","tags":["Effective STL"],"title":"Effective STL [33] | 提防在指针的容器上使用类似remove的算法","uri":"/posts/clause_33/"},{"categories":["C++"],"content":"资源泄露分析 我们假设在调用remove_if前，v看起来像这样： 在调用remove_if后，一般来说v看起来像这样（包含从remove_if返回的迭代器）： 资源泄漏的理由现在很明朗了。指向Widget B和C的“删除的”指针被vector中后面的“不删除的”指针覆盖。没有什么指向两个未通过检验的Widget，它们也没有被删除，它们的内存和其他资源泄漏了。 一旦remove_if和erase返回后，情况看起来像这样： 现在你也很清楚为什么应该努力避免在动态分配的指针的容器上使用remove和类似算法（remove_if和unique）。 在很多情况下，你会发现partition算法是合理的替代品。 ","date":"2023-08-26","objectID":"/posts/clause_33/:2:0","tags":["Effective STL"],"title":"Effective STL [33] | 提防在指针的容器上使用类似remove的算法","uri":"/posts/clause_33/"},{"categories":["C++"],"content":"正确删除做法 如果你无法避免在那样的容器上使用remove，排除这个问题一种方法是在应用erase-remove惯用法之前先删除指针并设置它们为空，然后除去容器中的所有空指针： void delAndNullifyUncertified(Widget *\u0026pWidget) { // 如果*pWidget是一个未通过检验Widget， if (!pWidget-\u003eisCertified()) { // 删除指针 delete pWidget; // 并且设置它为空 pWidget = 0; } } // 把所有指向未通过检验Widget的指针删除并且设置为空 for_each(v.begin(), v.end(), delAndNullifyUncertified); // 从v中除去空指针0必须映射到一个指针， v.erase(remove(v.begin(), v.end(), static_cast\u003cWidget *\u003e(0)), v.end()); // 让C++可以正确地推出remove的第三个参数的类型 当然，这假设vector并不容纳任何你想保留的空指针。如果有的话，你可能必须自己写循环来按你的方式删除指针。 ","date":"2023-08-26","objectID":"/posts/clause_33/:3:0","tags":["Effective STL"],"title":"Effective STL [33] | 提防在指针的容器上使用类似remove的算法","uri":"/posts/clause_33/"},{"categories":["C++"],"content":"智能指针 如果你把指针的容器替换成执行引用计数的智能指针的容器，删除相关的困难就不存在了，你可以直接使用erase-remove惯用法： template\u003ctypename T\u003e // RCSP = “引用计数智能指针” class RCSP { ...}; // RCSPW = “RCSP to Widget” typedef RCSP\u003c Widget\u003e RCSPW; // 建立一个vector，用动态分配Widget的智能指针填充它 vector\u003cRCSPW \u003e v; v.push_back(RCSPW(new Widget)); ... // erase未通过检验的Widget的指针 v.erase(remove_if(v.begin(), v.end(), not1 (mem_fun(\u0026Widget::isCertified))), v.end()); // 没有资源泄漏 要让这些工作，你的智能指针类型就必须可以（比如RCSP\u003cWidget\u003e）隐式转换为相应的内建指针类型（比如Widget*）。那是因为容器持有智能指针，但被调用的成员函数（比如Widget::isCertified）要的是内建指针。如果不存在隐式转换，你的编译器会抗议的。 ","date":"2023-08-26","objectID":"/posts/clause_33/:3:1","tags":["Effective STL"],"title":"Effective STL [33] | 提防在指针的容器上使用类似remove的算法","uri":"/posts/clause_33/"},{"categories":["C++"],"content":"remove实际作用 ","date":"2023-08-26","objectID":"/posts/clause_32/:1:0","tags":["Effective STL"],"title":"Effective STL [32] | 如果你真的想删除东西的话就在类似remove的算法后接上erase","uri":"/posts/clause_32/"},{"categories":["C++"],"content":"remove的声明 template\u003cclass ForwardIterator, class T\u003e ForwardIterator remove(ForwardIterator first, ForwardIterator last, const T\u0026 value); remove接收指定它操作的元素区间的一对迭代器。它不接收一个容器，所以remove不知道它作用于哪个容器。 此外，remove也不可能发现容器，因为没有办法从一个迭代器获取对应于它的容器。 ","date":"2023-08-26","objectID":"/posts/clause_32/:1:1","tags":["Effective STL"],"title":"Effective STL [32] | 如果你真的想删除东西的话就在类似remove的算法后接上erase","uri":"/posts/clause_32/"},{"categories":["C++"],"content":"remove不做什么 从容器中除去一个元素，唯一的方法是调用那个容器的一个成员函数，几乎都是erase的某个形式，(list有几个除去元素的成员函数不叫erase，但它们仍然是成员函数。)因为唯一从容器中除去一个元素的方法是在那个容器上调用一个成员函数，而且因为remove无法知道它正在操作的容器，所以remove不可能从一个容器中除去元素。 从一个容器中remove元素不会改变容器中元素的个数： vector\u003cint\u003e v; v.reserve(10); // 建立一个vector\u003cint\u003e 用1-10填充它(调用reserve的解释在条款14) for (int i = 1; i \u003c= 10; ++i) { v.push_back(i); } cout \u003c\u003c v.size(); // 打印10 v[3] = v[5] = v[9] = 99; // 设置3个元素为99 remove(v.begin(), v.end(), 99); // 删除所有等于99的元素 cout \u003c\u003c v.size(); // 仍然是10！ remove并不“真的”删除东西，因为它做不到。 remove不知道它要从哪个容器删除东西，而没有容器，它就没有办法调用成员函数。 ","date":"2023-08-26","objectID":"/posts/clause_32/:1:2","tags":["Effective STL"],"title":"Effective STL [32] | 如果你真的想删除东西的话就在类似remove的算法后接上erase","uri":"/posts/clause_32/"},{"categories":["C++"],"content":"remove 做了什么 remove移动指定区间中的元素直到所有“不删除的”元素在区间的开头(相对位置和原来它们的一样)。它返回一个指向最后一个的下一个“不删除的”元素的迭代器。返回值是区间的“新逻辑终点”。 举个例子，这是v在调用remove前看起来的样子： 如果我们把remove的返回值存放在一个叫做newEnd的新迭代器中: vector\u003cint\u003e::iterator newEnd(remove(v.begin(), v.end(), 99)); 这是调用后v看起来的样子: 如果“不删除的”元素在v中的v.begin()和newEnd之间，“删除的”元素就必须在newEnd和v.end()之间。 remove并没有改变区间中元素的顺序，所以不会把所有“删除的”元素放在结尾，并安排所有“不删除的”值在开头。 如果你不想失去任何值，你可能应该调用partition或stable_partition而不是remove。 ","date":"2023-08-26","objectID":"/posts/clause_32/:1:3","tags":["Effective STL"],"title":"Effective STL [32] | 如果你真的想删除东西的话就在类似remove的算法后接上erase","uri":"/posts/clause_32/"},{"categories":["C++"],"content":"remove 实际操作流程 在内部，remove遍历这个区间，把要“删除的”值覆盖为后面要保留的值。这个覆盖通过对持有被覆盖的值的元素赋值来完成。 remove检测v[0]，发现它的值不是要被删除的，然后移动到v[1]。同样的情况发生在v[1]和v[2]。 发现v[3]应该被删除，所以它记录下v[3]的值应该被覆盖，然后它移动到v[4]。这类似记录v[3]是一个需要填充的“洞”。 发现v[4]的值应该被保持，所以它把v[4]赋给v[3]，记录下v[4]应该被覆盖，然后移动到v[5]。继续类似的压缩，它用v[4]“填充”v[3]而且记录v[4]现在是一个洞。 发现v[5]应该被删除，所以忽略并它移动到v[6]。仍然记得v[4]是一个等待填充的洞。 发现v[6]是一个应该保留的值，所以把v[6]赋给v[4]。记得v[5]现在是下一个要被填充的洞，然后移到v[7]。 在某种意义上类似上面的，检查v[7]、v[8]和v[9]。把v[7]赋给v[5]，v[8]赋给v[6]，忽略v[9]，因为v[9]的值是要被删除的。 返回指定下一个要被覆盖的元素的迭代器，在这个例子中这个元素是v[7]。 事实上当remove在删除时覆盖的值是指针时，会有重要的影响。但是对于本条款，知道remove不从容器中除去任何元素因为它做不到就够了。 ","date":"2023-08-26","objectID":"/posts/clause_32/:1:4","tags":["Effective STL"],"title":"Effective STL [32] | 如果你真的想删除东西的话就在类似remove的算法后接上erase","uri":"/posts/clause_32/"},{"categories":["C++"],"content":"应该在remove后面接上erase 只有容器成员函数可以除去容器元素，而那是本条款的整个要点：如果你真的要删除东西的话，你应该在remove后面接上erase。 要除去那些元素，你要做的所有事情就是用那两个迭代器调用erase的区间形式。因为remove本身很方便地返回了区间新逻辑终点的迭代器: vector\u003cint\u003e v; // 正如从前 v.erase(remove(v.begin(), v.end(), 99), v.end()); cout \u003c\u003c v.size(); // 真的删除所有等于99的元素，现在返回7 事实上，remove和erase是亲密联盟，这两个整合到list成员函数remove中。这是STL中唯一名叫remove又能从容器中除去元素的函数： list\u003cint\u003e li; // 建立一个list放一些值进去 li.remove(99); // 除去所有等于99的元素：真的删除元素，所以它的大小可能改变了 调用这个remove函数是一个STL中的矛盾。在关联容器中类似的函数叫erase，list的remove也可以叫做erase。但它没有，所以我们都必须习惯它。 对于list，调用remove成员函数比应用erase-remove惯用法更高效。 ","date":"2023-08-26","objectID":"/posts/clause_32/:2:0","tags":["Effective STL"],"title":"Effective STL [32] | 如果你真的想删除东西的话就在类似remove的算法后接上erase","uri":"/posts/clause_32/"},{"categories":["C++"],"content":"类似remove的算法 remove_if和unique。 remove和remove_if之间的相似性很直截了当。 unique行为也像remove。它用来从一个区间删除东西(邻近的重复值)而不用访问持有区间元素的容器。如果你真的要从容器中删除元素，你也必须成对调用unique和erase，unique在list中也类似于remove。正像list::remove真的删除东西(而且比erase-remove惯用法高效得多)。 list::unique也真的删除邻近的重复值(也比erase-unique高效)。 ","date":"2023-08-26","objectID":"/posts/clause_32/:3:0","tags":["Effective STL"],"title":"Effective STL [32] | 如果你真的想删除东西的话就在类似remove的算法后接上erase","uri":"/posts/clause_32/"},{"categories":["C++"],"content":"稳定排序 VS 不稳定排序 有些排序算法是稳定的。在稳定排序中，如果一个区间中的两个元素有等价的值，它们的相对位置在排序后不改变。不稳定的算法没做这个保证。 例如，在（未排序的）widgets vector中Widget A在Widget B之前，而且两者都有相同的质量等级，那么稳定排序算法会保证在这个vector排序后，Widget A仍然在Widget B之前。 ","date":"2023-08-26","objectID":"/posts/clause_31/:1:0","tags":["Effective STL"],"title":"Effective STL [31] | 了解你的排序选择","uri":"/posts/clause_31/"},{"categories":["C++"],"content":"partial_sort sort是个令人称赞的算法，如果不需要完全排序时，比如有一个存有Widget 的vector，你想选择20个质量最高的Widget发送给客户，20个之外的Widget可以保持无序，也就是你需要的是部分排序，这时就可以用partial_sort。 bool qualityCompare(const Widget\u0026 lhs, const Widget\u0026 rhs) { // 返回lhs的质量是不是比rhs的质量好 } ... // 把最好的20个元素（按顺序）放在widgets的前端 partial_sort(widgets.begin(),widgets.begin() + 20, widgets.end(), qualityCompare); // 使用widgets... ... 调用完partial_sort后，widgets的前20个元素是容器中最好的而且它们按顺序排列，质量最高的Widget是widgets[0]，第二高的是widgets[1]等。 partial_sort是不稳定的。 ","date":"2023-08-26","objectID":"/posts/clause_31/:2:0","tags":["Effective STL"],"title":"Effective STL [31] | 了解你的排序选择","uri":"/posts/clause_31/"},{"categories":["C++"],"content":"nth_element 如果你不关心哪个Widget给哪个客户，你需要的只是任意顺序的20个最好的Widget。STL中nth_element可以精确地完成了你需要的。 nth_element排序一个区间，在n位置（你指定的）的元素是如果区间被完全排序后会出现在那儿的元素。 Example randy[n]; //默认求第m大的元素 std::nth_element(randy, randy+m, randy+n); //定义cmp可求第m小的元素 bool cmp(int a, int b){ return a\u003eb; } std::nth_element(randy, randy+m, randy+n, cmp); 函数是将第 m 大的元素放在 arr 数组数组中适当位置，其他元素按照第 m 元素的大小划分。 在[ 0, n ]这个范围内，在第 m 个元素之前的元素都小于或等于第 m 个元素，而且第 m 个元素后面的每个元素都会比它大。 nth_element()函数仅将第 m 大/小的数在 randy 数组中排好了位置，并不返回值。输出 randy[m] 即是第 m 大/小的数。 排序Widget数组 使用nth_element来保证最好的20个Widget在widgets vector的前端： nth_element(widgets.begin(), widgets.begin() + 19, widgets.end(), qualityCompare); // 把最好的20个元素放在widgets前端，但不用担心它们的顺序 调用nth_element本质上等价于调用partial_sort，两个算法都把20个质量最高的Widget移动到vector前端。 它们结果的唯一区别是partial_sort排序了在位置1-20的元素，而nth_element不排序。 其他用法 除了能帮你找到区间顶部的n个元素，它也可以用于找到区间的中值或者找到在指定百分点的元素： // 迭代器的变量方便地表示widgets的起点和终点 vector\u003cWidget\u003e::iterator begin(widgets.begin()); vector\u003cWidget\u003e::iterator end(widgets.end()); // 这个迭代器指示了下面代码要找的中等质量等级的Widget的位置 vector\u003cWidget\u003e::iterator goalPosition; // 兴趣的Widget会是有序的vector的中间 goalPosition = begin + widgets.size() / 2; // 找到widgets中中等质量等级的值 nth_element(begin, goalPosition, end, qualityCompare); // goalPosition现在指向中等质量等级的Widget ... // 下面的代码能找到质量等级为75%的Widget // 指出兴趣的Widget离开始有多远 vector\u003cWidget\u003e::size_type goalOffset = 0.25 * widgets.size(); // 找到质量值为75%的Widget nth_element(begin, begin + goalOffset, end, qualityCompare); // begin + goalOffset现在指向质量等级为75%的Widget ","date":"2023-08-26","objectID":"/posts/clause_31/:3:0","tags":["Effective STL"],"title":"Effective STL [31] | 了解你的排序选择","uri":"/posts/clause_31/"},{"categories":["C++"],"content":"元素有同样质量 假设有12个元素质量是1级（可能是最好的），15个元素质量是2级（第二好的）。在这种情况下，选择20个最好的Widget就是选择12个1级的和15个中的8个2级的。partial_sort和nth_element怎么判断15个中的哪些要放到最好的20个中？对于这个问题，当多个元素有等价的值时sort怎么判断元素的顺序？ partial_sort和nth_element以任何它们喜欢的方式排序值等价的元素，而且你不能控制它们在这方面行为。 nth_element、sort也没有提供稳定性。 ","date":"2023-08-26","objectID":"/posts/clause_31/:4:0","tags":["Effective STL"],"title":"Effective STL [31] | 了解你的排序选择","uri":"/posts/clause_31/"},{"categories":["C++"],"content":"stable_sort stable_sort 是稳定排序，STL并不包含partial_sort和nth_element的稳定版本。 当指定范围内包含多个相等的元素时，sort() 排序函数无法保证不改变它们的相对位置。那么，如果既要完成排序又要保证相等元素的相对位置，可以使用stable_sort()函数 stable_sort() 函数完全可以看作是 sort() 函数在功能方面的升级版。stable_sort() 和 sort() 具有相同的使用场景，就连语法格式也是相同的（后续会讲），只不过前者在功能上除了可以实现排序，还可以保证不改变相等元素的相对位置。 //对 [first, last) 区域内的元素做默认的升序排序 void stable_sort ( RandomAccessIterator first, RandomAccessIterator last ); //按照指定的 comp 排序规则，对 [first, last) 区域内的元素进行排序 void stable_sort ( RandomAccessIterator first, RandomAccessIterator last, Compare comp ); #include \u003ciostream\u003e // std::cout #include \u003calgorithm\u003e // std::stable_sort #include \u003cvector\u003e // std::vector //以普通函数的方式实现自定义排序规则 bool randy_comp(int i, int j) { return (i \u003c j); } //以函数对象的方式实现自定义排序规则 class kim_comp { public: bool operator() (int i, int j) { return (i \u003c j); } }; int main() { std::vector\u003cint\u003e jeff_num{88, 13, 2, 22, 1, 30, 3, 33}; std::stable_sort(jeff_num.begin(), jeff_num.begin() + 4); // 2 13 22 88 1 30 3 33 //利用STL标准库提供greater\u003cT\u003e进行排序 std::stable_sort(jeff_num.begin(), jeff_num.begin() + 4, std::greater\u003cint\u003e()); // 88 22 13 2 1 30 3 33 //通过自定义比较规则进行排序,这里也可以换成 kim_comp() std::stable_sort(jeff_num.begin(), jeff_num.end(), randy_comp); // 1 2 3 13 22 30 33 88 for (std::vector\u003cint\u003e::iterator it = jeff_num.begin(); it != jeff_num.end(); ++it) { std::cout \u003c\u003c *it \u003c\u003c ' '; } std::cout \u003c\u003c std::endl; return 0; } ","date":"2023-08-26","objectID":"/posts/clause_31/:5:0","tags":["Effective STL"],"title":"Effective STL [31] | 了解你的排序选择","uri":"/posts/clause_31/"},{"categories":["C++"],"content":"partition 但是完全排序需要很多工作，而且对于这个任务做了很多不必要的工作。一个更好的策略是使用partition算法，它重排区间中的元素以使所有满足某个标准的元素都在区间的开头。 比如，移动所有质量等级为2或更好的Widget到widgets前端： bool hasAcceptableQuality(const Widget\u0026 w) { // 返回w质量等级是否是2或更高; } // 把所有满足hasAcceptableQuality的widgets移动到widgets前端， // 并且返回一个指向第一个不满足的widget的迭代器 vector\u003cWidget\u003e::iterator goodEnd = partition(widgets.begin(), widgets.end(), hasAcceptableQuality); 此调用完成后，从widgets.begin()到goodEnd的区间容纳了所有质量是1或2的Widget，从goodEnd到widgets.end()的区间包含了所有质量等级更低的Widget。 如果在分割时保持同样质量等级的Widget的相对位置很重要，我们自然会用stable_partition来代替partition。 list排序 唯一我们可能会但不能使用sort、stable_sort、partial_sort或nth_element的容器是list，list通过提供sort成员函数做了一些补偿。（有趣的是，list::sort提供了稳定排序。） 如果你想要对list中的对象进行partial_sort或nth_element，你必须间接完成： 把元素拷贝到一个支持随机访问迭代器的容器中，然后对它应用需要的算法; 建立一个list::iterator的容器，对那个容器使用算法，然后通过迭代器访问list元素; 使用有序的迭代器容器的信息来迭代地把list的元素接合到你想让它们所处的位置。 ","date":"2023-08-26","objectID":"/posts/clause_31/:6:0","tags":["Effective STL"],"title":"Effective STL [31] | 了解你的排序选择","uri":"/posts/clause_31/"},{"categories":["C++"],"content":"总结 算法sort、stable_sort、partial_sort和nth_element需要随机访问迭代器，所以它们可能只能用于vector、string、deque和数组。 对标准关联容器排序元素没有意义，因为这样的容器使用它们的比较函数来在任何时候保持有序。 partition和stable_partition与sort、stable_sort、partial_sort和nth_element不同，它们只需要双向迭代器。因此你可以在任何标准序列迭代器上使用partition和stable_partition。 如果需要在vector、string、deque或数组上进行完全排序，你可以使用sort或stable_sort。 如果你有一个vector、string、deque或数组，只需要排序前n个元素，应该用partial_sort。 如果你有一个vector、string、deque或数组，需要鉴别出第n个元素或你需要鉴别出最前的n个元素，而不用知道它们的顺序，nth_element是你应该注意和调用的。 如果你需要把标准序列容器的元素或数组分隔为满足和不满足某个标准，你大概就要找partition或stable_partition。 如果你的数据是在list中，你可以直接使用partition和stable_partition，你可以使用list的sort来代替sort和stable_sort。如果你需要partial_sort或nth_element提供的效果，你就必须间接完成这个任务。 你可以通过把数据放在标准关联容器中的方法以保持在任何时候东西都有序。你也可能会考虑标准非STL容器priority_queue，它也可以总是保持它的元素有序。 一般来说，做更多工作的算法比做得少的要花更长时间，而必须稳定排序的算法比忽略稳定性的算法要花更长时间。 本节讨论的算法需要更少资源（时间和空间）的算法排序： partition partial_sort stable_partition sort nth_element stable_sort ","date":"2023-08-26","objectID":"/posts/clause_31/:7:0","tags":["Effective STL"],"title":"Effective STL [31] | 了解你的排序选择","uri":"/posts/clause_31/"},{"categories":["C++"],"content":"前言 Effective-STL总结系列分为七部分，本文为第六部分，涉及原书第六章，内容范围Rule38~42。为方便书写，Rule38简写为R38。 Effective-STL系列List 本博客站点系列内容如下： 💡 Effective STL(第3版)精读总结(一) 💡 Effective STL(第3版)精读总结(二) 💡 Effective STL(第3版)精读总结(三) 💡 Effective STL(第3版)精读总结(四) ","date":"2023-08-22","objectID":"/posts/effective_stl_part_six/:0:0","tags":["Effective STL"],"title":"Effective STL 精度总结 [6] | 仿函数、仿函数类、函数等","uri":"/posts/effective_stl_part_six/"},{"categories":["C++"],"content":"R38: 遵循按值传递的原则来设计函数子类 函数指针是按值传递的。 函数对象往往按值传递和返回。所以，编写的函数对象必须尽可能地小巧，否则复制的开销大；函数对象必须是单态的(不是多态)，不得使用虚函数。 如果你希望创建一个包含大量数据并且使用了多态性的函数子类，该怎么办呢？ template\u003ctypename T\u003e class BPFCImpl: public unary_function\u003cT, void\u003e { private: Widget w; int x; ... virtual ~BPFCImpl(); virtual void operator() (const T\u0026 val) const; friend class BPFC\u003cT\u003e; // 允许BPFC访问内部数据。 } template\u003ctypename T\u003e class BPFC: // 新的BPFC类：短小、单态 public unary_function\u003cT, void\u003e { private: BPFCImpl\u003cT\u003e *pImpl; // BPFC唯一的数据成员 public: void operator() (const T\u0026 val) const // 现在这是一个非虚函数，将调用转到BPFCImpl中 { pImpl-\u003eoperator()(val); } } 那么你应该创建一个小巧、单态的类，其中包含一个指针，指向另一个实现类，并且将所有的数据和虚函数都放在实现类中(“Pimpl Idiom”)。 template\u003ctypename T\u003e class BPFCImpl: public unary_function\u003cT, void\u003e { private: Widget w; int x; ... virtual ~BPFCImpl(); virtual void operator() (const T\u0026 val) const; friend class BPFC\u003cT\u003e; // 允许BPFC访问内部数据。 } template\u003ctypename T\u003e class BPFC: // 新的BPFC类：短小、单态 public unary_function\u003cT, void\u003e { private: BPFCImpl\u003cT\u003e *pImpl; // BPFC唯一的数据成员 public: void operator() (const T\u0026 val) const // 现在这是一个非虚函数，将调用转到BPFCImpl中 { pImpl-\u003eoperator()(val); } } ","date":"2023-08-22","objectID":"/posts/effective_stl_part_six/:1:0","tags":["Effective STL"],"title":"Effective STL 精度总结 [6] | 仿函数、仿函数类、函数等","uri":"/posts/effective_stl_part_six/"},{"categories":["C++"],"content":"R39 确保判别式是 “纯函数” 判别式(predicate)：一个返回值为 bool 类型的函数。 纯函数：指返回值仅仅依赖于其参数的函数。 判别式类(predicate class)：一个函数子类，它的 operator() 函数是一个判别式(返回 true 或 false)。 STL 中凡是可以接受一个判别式类对象的地方，也就可以接受一个判别式函数。 判别式应该是一个纯函数，而纯函数应该没有状态。 ","date":"2023-08-22","objectID":"/posts/effective_stl_part_six/:2:0","tags":["Effective STL"],"title":"Effective STL 精度总结 [6] | 仿函数、仿函数类、函数等","uri":"/posts/effective_stl_part_six/"},{"categories":["C++"],"content":"R40 使仿函数类可适配 对函数指针，要先应用ptr_fun之后再应用not1之后才可以工作。 4 个标准的函数配接器(not1、not2、bind1st、bind2nd)都要求一些特殊的类型定义，提供这些必要类型定义(argument_type、first_argument_type、second_argument_type、result_type)的函数对象被称为可配接(可适配)(adaptable)的函数对象。 提供这些类型定义最简单的方法：让函数子从一个基结构继承。 对于 unary_function，必须指定函数子类 operator() 所带的参数类型，以及 operator() 返回类型。 对于 binary_function，必须指定 3 个类型：operator() 第一个和第二个参数类型，以及 operator() 返回类型。 template\u003ctypename T\u003e class MeetsThreshold: public std::unary_function\u003cWidget, bool\u003e { private: const T threshold; // 包含状态信息，使用类封装。 public: MeetsThreshold(const T\u0026 threshold); bool operator()(const Widget\u0026) const; ... } struct WidgetNameCompare: // STL中所有无状态函数子类一般都被定义成结构。 public std::binary_function\u003cWidget, Widget, bool\u003e { bool operator()(const Widget\u0026 lhs, const Widget\u0026 rhs) const; } 注意，一般情况下，传递给 binary_function 或 unary_function 的非指针类型需要去掉 const 和应用(\u0026)部分。 ","date":"2023-08-22","objectID":"/posts/effective_stl_part_six/:3:0","tags":["Effective STL"],"title":"Effective STL 精度总结 [6] | 仿函数、仿函数类、函数等","uri":"/posts/effective_stl_part_six/"},{"categories":["C++"],"content":"R41 理解 ptr_fun、mem_fun 和 mem_fun_ref 的来由 STL语法惯例：函数或者函数对象被调用时，总是使用非成员函数的语法形式。 for_each(vw.begin(), vw.end(), test); // 调用1：f(x)，f为非成员函数 for_each(vw.begin(), vw.end(), \u0026Widget::test); // 调用2：x.f()，f为成员函数 // x是一个对象或对象的引用 list\u003cWidget *\u003e lpw; for_each(lpw.begin(), lpw.end(), \u0026Widgettest); // 调用3：p-\u003ef()，f为成员函数 // p是一个指向对象x的指针。 mem_fun、mem_fun_t：mem_fun 将语法 3 调整为语法 1。 template\u003ctypename R, typename C\u003e //该mem_fun声明针对不带参数的非const成员函数 mem_fun_t\u003cR,C\u003e //C是类，R是所指向的成员函数返回的类型。 mem_fun(R(C::*pmf)); mem_fun 带一个指向某个成员函数的指针参数 pmf，并且返回一个 mem_fun_t 类型的对象。 mem_fun_t 是一个函数子类，它拥有该成员函数的指针，并提供了 operator() 函数，在 operator() 中调用了通过参数传递进来的对象上的该成员函数。 类似地，mem_fun_ref 将语法 2 调整为语法 1。 总结: std::ptr_fun：将函数指针转换为函数对象。 std::mem_fun：将成员函数转换为函数对象(指针版本)。 std::mem_fun_ref：将成员函数转换为函数对象(引用版本)。 ","date":"2023-08-22","objectID":"/posts/effective_stl_part_six/:4:0","tags":["Effective STL"],"title":"Effective STL 精度总结 [6] | 仿函数、仿函数类、函数等","uri":"/posts/effective_stl_part_six/"},{"categories":["C++"],"content":"R42 确保less与operator\u003c具有相同的语义 尽量避免修改 less 的行为，可能会误导其他程序员。 如果你使用了 less，无论是显式地还是隐式地，都需要确保它与 operator\u003c 具有相同的意义。 如果你希望以一种特殊的方式来排列对象，那么最好创建一个特殊的函数子类。 假设有一个multiset容器，它默认的比较函数是less，而less在默认情况下会调用operator\u003c来完成multiset的排序，而operator\u003c是按照Widget中成员变量weight来排序的，现在特殊情况下需要一个按Widget中成员变量speed来排序的multiset，一种方法是全特化less，但是这种做法并不好，因为用户可能是觉得自己按照weight来排序，但是其实做的却是按照speed来排序，更好的办法是创建一个函数子类，然后用该子类做比较函数，而不是改变less的默认行为。 struct speedCompare : public binary_function\u003cWidget, Widget, bool\u003e { bool operator()(const Widget\u0026 lhs, const Widget\u0026 rhs) const{ return lhs.maxSpeed() \u003c rhs.maxSpeed(); } }; multiset\u003cWidget, speedCompare\u003e widgets; Ref: [1]. https://www.cnblogs.com/Sherry4869/p/15162253.html [2]. https://blog.csdn.net/zhuikefeng/article/details/108164117#t35 [3]. https://zhuanlan.zhihu.com/p/458156007 ","date":"2023-08-22","objectID":"/posts/effective_stl_part_six/:5:0","tags":["Effective STL"],"title":"Effective STL 精度总结 [6] | 仿函数、仿函数类、函数等","uri":"/posts/effective_stl_part_six/"},{"categories":["ML"],"content":"1. 2017年深度学习领域的重大突破是什么？ Transformer。有两方面的原因: 1.1 一方面，Transformer是深度学习领域继MLP、RNN、CNN之后的第4大特征提取器(也被称为基础模型)。 什么是特征提取器？ 特征提取器是计算机模仿大脑，与外部世界(图像、文字、语音等)交互的方式，如图1所示。举例而言: Imagenet数据集中包含1000类图像，人们已经根据自己的经验把这一百万张图像分好1000类，每一类图像(如美洲豹)都有独特的特征。这时，神经网络(如ResNet18)也是想通过这种分类的方式，把每一类图像的特征尽可能提取或识别出来。分类不是最终目的，而是一种提取图像特征的手段，掩码补全图像也是一种提取特征的方式，图像块顺序打乱也是一种提取特征的方式。 1.2 另一方面，Transformer在深度学习领域扮演的角色: 第3次和第4次热潮的基石，如下图2所示。 ","date":"2023-08-21","objectID":"/posts/transformerqanda/:1:0","tags":["Transformer"],"title":"Transformer Q \u0026 A","uri":"/posts/transformerqanda/"},{"categories":["ML"],"content":"2. Transformer的提出背景是什么？ 2.1 在领域发展背景层面: 当时时处2017年，深度学习在计算机视觉领域已经火了几年。从Alexnet、VGG、GoogleNet、ResNet、DenseNet;从图像分类、目标检测再到语义分割;但在自然语言处理领域并没有引起很大反响。 2.2 技术背景层面: (1)当时主流的序列转录任务(如机器翻译)的解决方案如下图3所示，在Sequence to Sequence架构下(Encoder-Decoder的一种)，RNN来提取特征，Attention机制将Encoder提取到的特征高效传递给Decoder。 (2)这种做法有两个不足之处，一方面是在提取特征时的RNN天生从前向后时序传递的结构决定了其无法并行运算，其次是当序列长度过长时，最前面序列的信息有可能被遗忘掉。因此可以看到，在这个框架下，RNN是相对薄弱急需改进的地方。 ","date":"2023-08-21","objectID":"/posts/transformerqanda/:2:0","tags":["Transformer"],"title":"Transformer Q \u0026 A","uri":"/posts/transformerqanda/"},{"categories":["ML"],"content":"3. Transformer到底是什么？ 3.1 Transformer是一种由Encoder和Decoder组成的架构。那么什么是架构呢？最简单的架构就是A + B + C。 3.2 Transformer也可以理解为一个函数，输入是“我爱学习”，输出是“I love study”。 3.3 如果把Transformer的架构进行分拆，如图4所示。 ","date":"2023-08-21","objectID":"/posts/transformerqanda/:3:0","tags":["Transformer"],"title":"Transformer Q \u0026 A","uri":"/posts/transformerqanda/"},{"categories":["ML"],"content":"4. 什么是Transformer Encoder？ 4.1 从功能角度，Transformer Encoder的核心作用是提取特征，也有使用Transformer Decoder来提取特征。例如，一个人学习跳舞，Encoder是看别人是如何跳舞的，Decoder是将学习到的经验和记忆(key和value的匹配程度)，展现出来 4.2 从结构角度，如图5所示，Transformer Encoder = Embedding + Positional Embedding + N * (子Encoder block1 + 子Encoder block2); 子Encoder block1 = Multi head attention + ADD + Norm; 子Encoder block2 = Feed Forward + ADD + Norm; 4.3 从输入输出角度，N个Transformer Encoder block中的第一个Encoder block的输入为一组向量 X = (Embedding + Positional Embedding)，向量维度通常为512*512，其他N个TransformerEncoder block的输入为上一个 Transformer Encoder block的输出，输出向量的维度也为512*512(输入输出大小相同)。 4.4 为什么是512*512？前者是指token的个数，如“我爱学习”是4个token，这里设置为512是为了囊括不同的序列长度，不够时padding。后者是指每一个token生成的向量维度，也就是每一个token使用一个序列长度为512的向量表示。人们常说，Transformer不能超过512，否则硬件很难支撑;其实512是指前者，也就是token的个数，因为每一个token要做self attention操作;但是后者的512不宜过大，否则计算起来也很慢。 ","date":"2023-08-21","objectID":"/posts/transformerqanda/:4:0","tags":["Transformer"],"title":"Transformer Q \u0026 A","uri":"/posts/transformerqanda/"},{"categories":["ML"],"content":"5. 什么是Transformer Decoder？ 5.1 从功能角度，相比于Transformer Encoder，Transformer Decoder更擅长做生成式任务，尤其对于自然语言处理问题。 5.2 从结构角度，如图6所示，Transformer Decoder = Embedding + Positional Embedding + N*(子Decoder block1 + 子Decoder block2 + 子Decoder block3)+ Linear + Softmax; 子Decoder block1 = Mask Multi head attention + ADD + Norm; 子Decoder block2 = Multi head attention + ADD + Norm; 子Decoder block3 = Feed Forward + ADD + Norm; 5.3 从(Embedding+Positional Embedding)(N个Decoder block)(Linear + softmax) 这三个每一个单独作用角度: Embedding + Positional Embedding: 以机器翻译为例，输入“Machine Learning”，输出“机器学习”; 这里的Embedding是把“机器学习”也转化成向量的形式。 N个Decoder block: 特征处理和传递过程。 Linear + softmax: softmax是预测下一个词出现的概率，如图7所示，前面的Linear层类似于分类网络(ResNet18)最后分类层前接的MLP层。 5.4 Transformer Decoder的输入、输出是什么？在Train和Test时是不同的。 在Train阶段，如图8所示。这时是知道label的，decoder的第一个输入是begin字符，输出第一个向量与label中第一个字符使用cross entropy loss。Decoder的第二个输入是第一个向量的label，Decoder的第N个输入对应的输出是End字符，到此结束。这里也可以看到，在Train阶段是可以进行并行训练的。 在Test阶段，下一个时刻的输入是前一个时刻的输出，如图9所示。因此，Train和Test时候，Decoder的输入会出现Mismatch，在Test时候确实有可能会出现一步错，步步错的情况。有两种解决方案: 一种是train时偶尔给一些错误，另一种是Scheduled sampling。 5.5 Transformer Decoder block内部的输入和输出是什么？ 前面提到的是在整体train和test阶段，Decoder的输入和输出，那么Transformer Decoder内部的Transformer Decoder block，如图10所示，的输入输出又是什么呢？ 对于N=6中的第1次循环(N=1时): 子Decoder block1 的输入是 embedding +Positional Embedding，子Decoder block2 的输入的Q来自子Decoder block1的输出，KV来自Transformer Encoder最后一层的输出。 对于N=6的第2次循环: 子Decoder block1的输入是N=1时，子Decoder block3的输出，KV同样来自Transformer Encoder的最后一层的输出。 总的来说，可以看到，无论在Train还是Test时，Transformer Decoder的输入不仅来自(ground truth或者上一个时刻Decoder的输出)，还来自Transformer Encoder的最后一层。 训练时: 第i个decoder的输入 = encoder输出 + ground truth embedding。 预测时: 第i个decoder的输入 = encoder输出 + 第(i-1)个decoder输出. ","date":"2023-08-21","objectID":"/posts/transformerqanda/:5:0","tags":["Transformer"],"title":"Transformer Q \u0026 A","uri":"/posts/transformerqanda/"},{"categories":["ML"],"content":"6. Transformer Encoder和Transformer Decoder有哪些不同？ 6.1 作用上，Transformer Encoder常用来提取特征，Transformer Decoder常用于生成式任务。Transformer Encoder和Transformer Decoder是两条不同的技术路线，Bert采用的前者，GPT系列模型采用的是后者。 6.2 结构上，Transformer Decoder block包括了3个子Decoder block，而Transformer Encoder block 包括2个子Encoder block，且Transformer Decoder中使用了Mask multi-head Attention。 6.3 从二者的输入输出角度，N个Transformer Encoder运算完成之后，它的输出才正式输入进Transformer Decoder，作为QKV中的K和V，给Transformer Decoder使用。那么TransformerEncoder最后层的输出是如何送给Decoder呢？如图11所示。 那么，为什么Encoder和Decoder必须要用这种交互的方式呢？其实也并不一定，后续有不同交互方式的提出，如图12。 ","date":"2023-08-21","objectID":"/posts/transformerqanda/:6:0","tags":["Transformer"],"title":"Transformer Q \u0026 A","uri":"/posts/transformerqanda/"},{"categories":["ML"],"content":"7. 什么是Embedding？ 7.1 Embedding在Transformer架构中的位置如图13所示。 7.2 提出背景: 计算机无法直接处理一个单词或者一个汉字，需要把一个token转化成计算机可以识别的向量，这也就是embedding过程。 7.3 实现方式: 最简单的embedding操作就是one hot vector，但one hot vector有一个弊端就是没有考虑词语前后之间的关系，后来也就产生了WordEmbedding，如图13。 Note wordembedding将单词token向量化，并且考虑的单词与单词之间的相关性。 ","date":"2023-08-21","objectID":"/posts/transformerqanda/:7:0","tags":["Transformer"],"title":"Transformer Q \u0026 A","uri":"/posts/transformerqanda/"},{"categories":["ML"],"content":"8. 什么是Positional Embedding？ 8.1 Positional Embedding在Transformer架构中的位置如图14所示。 8.2 提出背景: RNN作为特征提取器，是自带词的前后顺序信息的;而Attention机制并没有考虑先后顺序信息，但前后顺序信息对语义影响很大，因此需要通过Positional Embedding这种方式把前后位置信息加在输入的Embedding上。 8.3 实现方式: 传统位置编码和神经网络自动训练得到。 ","date":"2023-08-21","objectID":"/posts/transformerqanda/:8:0","tags":["Transformer"],"title":"Transformer Q \u0026 A","uri":"/posts/transformerqanda/"},{"categories":["ML"],"content":"9. 什么是Attention？ 9.1 介绍Transformer，为什么要介绍Attention呢？因为在Transformer中最多的multi head attention和Mask multi head attention来自Scaled dot product attention，而scaled dot product attention来自self attention，而self attention是attention的一种，因此首先需要了解Attention，如图15所示。 9.2 Attention到底是什么意思呢？ 对于图像而言，attention就是人们看到图像中的核心关注的区域，是图像中的重点，如图16所示。对于序列而言，Attention机制本质上是为了找到输入中不同token之间的相互关系，通过权重矩阵来自发地找到词与词之间的关系。 9.3 Attention是如何实现的呢？ 是通过QKV实现的。 那么什么是QKV呢？Q是query，K是keys，V是values。如图17所示，举例而言，Q是大脑发出的信号，我口渴了;K是环境信息，眼睛看到的世界;V是对环境中不同的物品赋予不同的比重，水的比重加大。 总之，Attention就是通过计算QK的相似度，与V相乘得到注意力数值。 $$\\text{Attention}(\\mathrm{Query},\\mathrm{Source})=\\sum\\text{Similarity}(\\mathrm{Query},\\mathrm{Key}\\mathrm{i})*\\mathrm{Value}\\mathrm{i}$$ 9.4 为什么必须要有QKV三者？ 为什么不是只有Q？因为Q1与Q2之间的关系权重，不止需要a12，也需要a21。你可能会问？我们让a12=a21不行吗？也可以尝试，但从原理上讲效果应该没有a12和a21效果好。 为什么不是只有QK？求得的权重系数需要放到输入中，可以乘Q，也可以乘K，为什么要重新乘V呢？我觉得可能是多了一组可训练参数$W_V$，使网络具有更强的学习能力。 ","date":"2023-08-21","objectID":"/posts/transformerqanda/:9:0","tags":["Transformer"],"title":"Transformer Q \u0026 A","uri":"/posts/transformerqanda/"},{"categories":["ML"],"content":"10. 什么是Self Attention？ 10.1 介绍Transformer，为什么要介绍self Attention呢？因为在Transformer中最多的multi head attention和Mask multi head attention来自Scaled dot product attention，而scaled dot product attention来自self attention，如图15所示。 10.2 什么是Self Attention呢？self attention和local attention、stride attention都是attention的一种;self attention是每一个Q与每一个K依次计算注意力系数，如图18所示，而像local attention是Q只与相邻的K计算注意力系数，stride attention是Q通过跳连的方式与K计算注意力系数。 10.3 Self attention为什么可以用于处理像机器翻译这种序列数据? 输入序列中的每一个位置的数据，可以关注其他位置的信息，由此通过Attention score来提取特征或者捕获输入序列每一个token之间的关系。 10.4 Self attention是如何具体实现的? 总共分为4步，如图19所示 ","date":"2023-08-21","objectID":"/posts/transformerqanda/:10:0","tags":["Transformer"],"title":"Transformer Q \u0026 A","uri":"/posts/transformerqanda/"},{"categories":["ML"],"content":"11. 什么是Scaled dot product attention？ 11.1 self attention最常见的有两种，一种是dot product attention、另一种是additive attention，如图20所示，前者的计算效率更高。 11.2 什么是Scaled ? scaled的具体实现方式如图21所示，这一操作的目的是为了防止内积过大，从梯度角度考虑，避免靠近1，易训练;与batch normalization有一些相似的功能。 $$\\text{Attention}(Q,K,V)=\\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V$$ ","date":"2023-08-21","objectID":"/posts/transformerqanda/:11:0","tags":["Transformer"],"title":"Transformer Q \u0026 A","uri":"/posts/transformerqanda/"},{"categories":["ML"],"content":"12. 什么是Multi head attention？ 12.1 Multi head attention在Transformer架构中的位置如图15所示。 12.2 提出背景: CNN具有多个channel，可以提取图像不同维度的特征信息，那么Self attention是否可以有类似操作，可以提取不同距离token的多个维度信息呢？ 12.3 什么是group 卷积？如图22所示，将输入的特征多个channel分成几个group单独做卷积，最后再进行con c操作。 12.4 Multi head attention的实现方式？与self attention根本不同是什么？ 如图23所示，以2个head的为例，将输入的Q、K、V分成两份，每一小份的Q与对应的K、V分别操作，最后计算得到的向量再进行conc操作，由此可以看出，Multi head attention与group卷积有着相似的实现方式。 12.5 如何从输入输出的维度来理解Multi head attention？如图24所示。 ","date":"2023-08-21","objectID":"/posts/transformerqanda/:12:0","tags":["Transformer"],"title":"Transformer Q \u0026 A","uri":"/posts/transformerqanda/"},{"categories":["ML"],"content":"13. 什么是Mask Multi head attention？ 13.1 Mask Multi head attention在transformer架构中的位置如图15所示。 13.2 为什么要有Mask这种操作？ Transformer预测第T个时刻的输出，不能看到T时刻之后的那些输入，从而保证训练和预测一致。 通过 Masked 操作可以防止第 i 个单词知道 i+1 个单词之后的信息，如图25所示。 13.3 Mask操作是如何具体实现的呢？ Q1只跟K1计算，Q2只跟K1、K2计算，而对于K3、K4等，在softmax之前给一个非常大的负数，由此经过softmax之后变为0，其在矩阵上的计算原理实现如图26所示。 ","date":"2023-08-21","objectID":"/posts/transformerqanda/:13:0","tags":["Transformer"],"title":"Transformer Q \u0026 A","uri":"/posts/transformerqanda/"},{"categories":["ML"],"content":"14. 什么是ADD？ 14.1 Add就是残差连接，由2015年ResNet这篇文章发扬光大(目前引用量已超过16万)，与Skip connection的区别在于需要大小维度全部相同。 14.2 作为大道至简想法的极致，几乎每一个深度学习模型都会用到这个技术，可以防止网络退化，常用于解决多层网络难训练的问题。 ","date":"2023-08-21","objectID":"/posts/transformerqanda/:14:0","tags":["Transformer"],"title":"Transformer Q \u0026 A","uri":"/posts/transformerqanda/"},{"categories":["ML"],"content":"15. 什么是Norm？ 15.1 Norm就是layer normalization。 15.2 核心作用: 为了训练更加稳定，和batch normalization有相同的作用，都是为了使输入的样本均值为零，方差为1。 15.3 为什么不使用batch normalization，使用的是layer normalization呢？因为一个时序数据，句子输入长度有长有短，如果使用batch normalization，则很容易造成因样本长短不一造成“训练不稳定”。BN是对同一个batch内的所有数据的同一个特征数据进行操作;而LN是对同一个样本进行操作。 什么是FFN？ 16.1 FFN就是feed forward networks。 16.2 为什么有了Self attention层，还要有FFN？Attention已经有了想要的序列信息特征，MLP的作用是把信息投影到特定的空间里，再做一次非线性映射，和Self attention交替使用。 16.3 结构上: 包括两层MLP，第一层的维度为$5122048$，第二层的维度为$2048512$，且第二层MLP没有使用激活函数，如图29所示。 ","date":"2023-08-21","objectID":"/posts/transformerqanda/:15:0","tags":["Transformer"],"title":"Transformer Q \u0026 A","uri":"/posts/transformerqanda/"},{"categories":["ML"],"content":"17. Transformer是如何训练出来的？ 17.1 数据上，在Transformer论文中有提到，用到了4.5M和36M的翻译句子对。 17.2 硬件上，base模型是8个P100 GPU训练了12个小时，大模型是训练了3.5天。 17.3 模型参数和调参层面: 第一，可训练的参数包括$W_Q$、$W_K$、$W_V$、$W_O$，换包括$FFN$层的参数。 第二，可调的参数包括: 每一个token向量表示的维度(d_model)、head的头数、Encoder和Decoder中block重复的次数N、FFN中间层向量的维度、Label smoothing(置信度0.1)和dropout(0.1)。 ","date":"2023-08-21","objectID":"/posts/transformerqanda/:16:0","tags":["Transformer"],"title":"Transformer Q \u0026 A","uri":"/posts/transformerqanda/"},{"categories":["ML"],"content":"18. Transformer为什么效果好？ 18.1 虽然题目是Attention is all you need，但后续一些研究表明，Attention、残差连接、layer normalization、FFN，这些因素共同成就了Transformer。 18.2 Transformer优点包括: 第一，提出深度学习继MLP、CNN、RNN后的第4大特征提取器。 第二，一开始用在机器翻译，随着GPT和Bert彻底出圈;是一个转折点，在这个点之后，NLP领域快速发展，之后多模态、大模型、视觉Transformer等开始兴起。 第三，给人们信心，原来CNN和RNN之后，还可以有效果更好的特征提取器。 18.3 Transformer的不足之处？ 第一，计算量大，对硬件要求高。 第二，因为无归纳偏置，需要很多数据才可以取得很好的效果。 Ref: [1]. https://mp.weixin.qq.com/s/sNyh3SzhIdsk8feYfQlTSA ","date":"2023-08-21","objectID":"/posts/transformerqanda/:17:0","tags":["Transformer"],"title":"Transformer Q \u0026 A","uri":"/posts/transformerqanda/"},{"categories":["ML"],"content":"解答一 我们直接用torch实现一个SelfAttention来说一说： 首先定义三个线性变换矩阵，query, key, value： class BertSelfAttention(nn.Module): self.query = nn.Linear(config.hidden_size, self.all_head_size) # 输入768， 输出768 self.key = nn.Linear(config.hidden_size, self.all_head_size) # 输入768， 输出768 self.value = nn.Linear(config.hidden_size, self.all_head_size) 注意，这里的query, key, value只是一种操作(线性变换)的名称，实际的Q/K/V是它们三个的输出 假设三种操作的输入都是同一个矩阵(暂且先别管为什么输入是同一个矩阵)，这里暂且定为长度为L的句子，每个token的特征维度是768，那么输入就是(L, 768)，每一行就是一个字，像这样： 乘以上面三种操作就得到了Q/K/V，(L, 768)*(768,768) = (L,768)，维度其实没变，即此刻的Q/K/V分别为： 代码为: class BertSelfAttention(nn.Module): def __init__(self, config): self.query = nn.Linear(config.hidden_size, self.all_head_size) # 输入768， 输出768 self.key = nn.Linear(config.hidden_size, self.all_head_size) # 输入768， 输出768 self.value = nn.Linear(config.hidden_size, self.all_head_size) # 输入768， 输出768 def forward(self, hidden_states): # hidden_states 维度是(L, 768) Q = self.query(hidden_states) K = self.key(hidden_states) V = self.value(hidden_states) 然后来实现这个操作: $$Attention(Q,K_i,V_i)\\color{red}{\\boxed{=softmax(\\frac{Q^TK_i}{\\sqrt{d_k}})V_i}}$$ ① 首先是Q和K矩阵乘，(L, 768)*(L, 768)的转置=(L,L)，看图： 首先用Q的第一行，即“我”字的768特征和K中“我”字的768为特征点乘求和，得到输出(0，0)位置的数值，这个数值就代表了“我想吃酸菜鱼”中“我”字对“我”字的注意力权重，然后显而易见输出的第一行就是“我”字对“我想吃酸菜鱼”里面每个字的注意力权重；整个结果自然就是“我想吃酸菜鱼”里面每个字对其它字(包括自己)的注意力权重(就是一个数值)了~ ② 然后是除以根号dim，这个dim就是768，至于为什么要除以这个数值？主要是为了缩小点积范围，确保softmax梯度稳定性，具体推导可以看这里：莲生三十二：Self-attention中dot-product操作为什么要被缩放，然后就是为什么要softmax，一种解释是为了保证注意力权重的非负性，同时增加非线性，还有一些工作对去掉softmax进行了实验，如PaperWeekly：线性Attention的探索：Attention必须有个Softmax吗？ ③ 然后就是刚才的注意力权重和V矩阵乘了，如图： 注意力权重 x VALUE矩阵 = 最终结果 首先是“我”这个字对“我想吃酸菜鱼”这句话里面每个字的注意力权重，和V中“我想吃酸菜鱼”里面每个字的第一维特征进行相乘再求和，这个过程其实就相当于用每个字的权重对每个字的特征进行加权求和，然后再用“我”这个字对对“我想吃酸菜鱼”这句话里面每个字的注意力权重和V中“我想吃酸菜鱼”里面每个字的第二维特征进行相乘再求和，依次类推~最终也就得到了(L,768)的结果矩阵，和输入保持一致~ 整个过程在草稿纸上画一画简单的矩阵乘就出来了，一目了然~最后上代码： class BertSelfAttention(nn.Module): def __init__(self, config): self.query = nn.Linear(config.hidden_size, self.all_head_size) # 输入768， 输出768 self.key = nn.Linear(config.hidden_size, self.all_head_size) # 输入768， 输出768 self.value = nn.Linear(config.hidden_size, self.all_head_size) # 输入768， 输出768 def forward(self,hidden_states): # hidden_states 维度是(L, 768) Q = self.query(hidden_states) K = self.key(hidden_states) V = self.value(hidden_states) attention_scores = torch.matmul(Q, K.transpose(-1, -2)) attention_scores = attention_scores / math.sqrt(self.attention_head_size) attention_probs = nn.Softmax(dim=-1)(attention_scores) out = torch.matmul(attention_probs, V) return out 为什么叫自注意力网络？ 因为可以看到Q/K/V都是通过同一句话的输入算出来的，按照上面的流程也就是一句话内每个字对其它字(包括自己)的权重分配；那如果不是自注意力呢？简单来说，Q来自于句A，K、V来自于句B即可~ 注意，K/V中，如果同时替换任意两个字的位置，对最终的结果是不会有影响的，至于为什么，可以自己在草稿纸上画一画矩阵乘；也就是说注意力机制是没有位置信息的，不像CNN/RNN/LSTM；这也是为什么要引入positional embeding的原因。 ","date":"2023-08-20","objectID":"/posts/attentionaqkv/:1:0","tags":["Transformer"],"title":"Transformer | 如何理解attention中的Q,K,V？","uri":"/posts/attentionaqkv/"},{"categories":["ML"],"content":"解答二 其实直接用邱锡鹏老师PPT里的一张图就可以直观理解——假设D是输入序列的内容，完全忽略线性变换的话可以近似认为Q=K=V=D(所以叫做Self-Attention，因为这是输入的序列对它自己的注意力)，于是序列中的每一个元素经过Self-Attention之后的表示就可以这样展现： 也就是说，The这个词的表示，实际上是整个序列加权求和的结果——权重从哪来？点积之后Softmax得到——这里Softmax(QK)就是求权重的体现。我们知道，向量点积的值可以表征词与词之间的相似性，而此处的“整个序列”包括The这个词自己(再一次强调这是Self-Attention)，所以最后输出的词的表示，其“主要成分”就主要地包含它自身和跟它相似的词的表示，其他无关的词的表示对应的权重就会比较低。 ","date":"2023-08-20","objectID":"/posts/attentionaqkv/:2:0","tags":["Transformer"],"title":"Transformer | 如何理解attention中的Q,K,V？","uri":"/posts/attentionaqkv/"},{"categories":["ML"],"content":"解答三 首先附上链接：张俊林：深度学习中的注意力模型(2017版) 。这个几乎是我读到过的讲解Attention最为透彻的篇章之一了。 Q(Querry)代表查询值，对应Decoder的H(t-1)状态。这里要正确理解H(t-1)，想要解码出t时刻的输出，你送入Decoder的必然有前一时刻计算出的隐状态。好了，所谓查询，就是你要拿着这个Decoder中的H(t-1)去和Encoder中各个时刻的隐状态H(1), H(2), … , H(T)去比，也就是二者计算相似度(对应于文献中的各种energy函数)。最后算出来的结果用Softmax归一化，这个算出来的权重就是带有注意力机制的权重，其实在翻译任务中，Key和Value是相等的。在Transformer的实现源码中，Key和Value的初始值也是相等的。有了这个权重之后，就可以用这个权重对Value进行加权求和，生成的这个新的向量就是带有注意力机制的语义向量 Context vector，而这个语义向量会权衡Target与Source的token与token的关系，从而实现解码输出时，与Source中“真正有决定意义”的token关联。 姑且画蛇添足的再说几句： 首先，Attention机制是由Encoder-Decoder架构而来，且最初是用于完成NLP领域中的翻译(Translation)任务。那么输入输出就是非常明显的 Source-Target的对应关系，经典的Seq2Seq结构是从Encoder生成出一个语义向量(Context vector)而不再变化，然后将这个语义向量送入Decoder配合解码输出。这种方法的最大问题就是这个语义向量，我们是希望它一成不变好呢？还是它最好能配合Decoder动态调整自己，来使Target中的某些token与Source中的真正“有决定意义”的token关联起来好呢？ 这就是为什么会有Attention机制的原因。说到底，Attention机制就是想生成会动态变化的语义向量来配合解码输出。而新贵 Self-Attention则是为了解决Target与Source各自内部token与token的关系。在Transformer中，这两种注意力机制得到了有机的统一，释放出了异常惊人的潜力。 ref: [1]. https://mp.weixin.qq.com/s/v7N3lhMBSdoGCz4K3TmsmA ","date":"2023-08-20","objectID":"/posts/attentionaqkv/:3:0","tags":["Transformer"],"title":"Transformer | 如何理解attention中的Q,K,V？","uri":"/posts/attentionaqkv/"},{"categories":["C++"],"content":"STL容器在被添加时（通过insert、push_front、push_back等）自动扩展它们自己来容纳新对象。 ","date":"2023-08-19","objectID":"/posts/clause_30/:0:0","tags":["Effective STL"],"title":"Effective STL [30] | 确保目标区间足够大","uri":"/posts/clause_30/"},{"categories":["C++"],"content":"插入数据 尾部插入 back_inserter 当你想向容器中插入对象但并没有告诉STL他们所想的时，问题出现了: int transmogrify(int x); // 自定义的这个函数从x产生一些新值 vector\u003cint\u003e values; ... // 把数据放入values vector\u003cint\u003e results; // 把transmogrify应用于values中的每个对象 // 把这个返回的values附加到results transform(values.begin(), values.end(),results.end(),transmogrify); // 这段代码有bug！ transform被告知它的目的区间是从results.end()开始的，所以那就是开始写在values的每个元素上调用transmogrify的结果的地方。 就像所有使用目标区间的算法，transform通过对目标区间的元素赋值的方法写入结果，transform会把transmogrify应用于values[0]并把结果赋给*results.end()。 然后它会把transmogrify应用于value[1]并把结果赋给*(results.end()+1)。 那只能带来灾难，因为在*results.end()没有对象，*(results.end()+1)也没有！因为transform并没有在尾部创造新的对象。 调用transform是错误的，因为它会给不存在的对象赋值。 正确做法 把transform的结果放入results容器的结尾的方式是调用back_inserter来产生指定目标区间起点的迭代器: vector\u003cint\u003e results; // 把transmogrify应用于values中的每个对象，在results的结尾插入返回的values transform(values.begin(), values.end(),back_inserter(results),transmogrify); 在内部，back_inserter返回的迭代器会调用push_back，所以你可以在任何提供push_back的容器上使用back_inserter(也就是任何标准序列容器: vector、string、deque和list)。 前端插入 front_inserter 如果你想让一个算法在容器的前端插入东西，你可以使用front_inserter。 在内部，front_inserter利用了push_front，所以front_insert只和提供那个成员函数的容器配合(也就是deque和list): ... // 同上 list\u003cint\u003e results; // results现在是list transform(values.begin(), values.end(),front_inserter(results),transmogrify); // 在results前端 以反序 插入transform的结果 因为front_inserter用push_front把每个对象添加到results，results中的对象顺序会和values中对应的对象顺序相反。 vector不提供push_front，所以front_inserter不能用于vector。 同序插入 如果你要transform把输出结果放在results前端，但你也要输出和values中对应的对象顺序相同，只要以相反的顺序迭代values: list\u003cint\u003e results; // 同上 // 在results前端 插入transform的结果 transform(values.rbegin(), values.rend(),front_inserter(results),transmogrify); // 保持相对的对象顺序 任意位置插入 inserter front_inserter让你强制算法在容器前端插入它们的结果，back_inserter让你告诉它们把结果放在容器后端，有点惊人的是inserter允许你强制算法把它们的结果插入容器中的任意位置: vector\u003cint\u003e values; ... vector\u003cint\u003e results; ... // 同上 // 同上，除了现在在调用transform前 results已经有一些数据 transform(values.begin(), values.end(), // 把transmogrify的结果插入results的中间 inserter(results, results.begin() + results.size()/2), transmogrify); ","date":"2023-08-19","objectID":"/posts/clause_30/:1:0","tags":["Effective STL"],"title":"Effective STL [30] | 确保目标区间足够大","uri":"/posts/clause_30/"},{"categories":["C++"],"content":"插入效率 不管你是否使用了back_inserter、front_inserter或inserter，transform会对目的区间每次写入一个值，你无法改变。 当你要插入的容器是vector或string时，你可以最小化这个代价，预先调用reserve。 你仍然要承受每次发生插入时移动元素的开销，但至少你避免了重新分配容器的内在内存: vector\u003cint\u003e values; // 同上 vector\u003cint\u003e results; ... results.reserve(results.size() + values.size()); // 确定results至少还能装得下values.size()个元素 transform(values.begin(), values.end(), // 同上，但results没有任何重新分配操作 inserter(results, results.begin() + results.size() / 2), transmogrify); 当使用reserve来提高一连串插入的效率时，总是应该记住reserve只增加容器的容量：容器的大小仍然没有改变。 即使调用完reserve，当你想要让容器把新元素加入到vector或string时，你也必须对算法使用插入迭代器(比如，从back_inserter、front_inserter或inserter返回的迭代器之一)，因为赋值只在两个对象之间操作时有意义，而不是在一个对象和一块原始的比特之间。 第一个例子正确的写法: vector\u003cint\u003e values; // 同上 vector\u003cint\u003e results; results.reserve(results.size() + values.size()); // 同上 // 把transmogrify的结果写入results的结尾，处理时避免了重新分配 transform(values.begin(), values.end(), back_inserter(results) , transmogrify); ","date":"2023-08-19","objectID":"/posts/clause_30/:2:0","tags":["Effective STL"],"title":"Effective STL [30] | 确保目标区间足够大","uri":"/posts/clause_30/"},{"categories":["C++"],"content":"覆盖原始数据 有时候你要覆盖现有容器的元素而不是插入新的。 当这种情况时，你不需要插入迭代器，但你仍然需要按照本条款的建议来确保你的目的区间足够大。 假设你让transform覆盖results的元素。如果results至少有和values一样多的元素，那很简单。如果没有， 你也必须使用resize来确保它有。 vector\u003cint\u003e values; vector\u003cint\u003e results; ... // 确保results至少和values一样大 if (results.size() \u003c values.size()){ results.resize(values.size()); } // 覆盖values.size()个 results的元素 transform(values.begin(), values.end(), results.begin(), transmogrify); 或者你可以清空results然后用通常的方式使用插入迭代器: ... // 销毁results中的所有元素 results.clear(); // 保留足够空间 results.reserve(values.size()); // 把transform地返回值// 放入results transform(values.begin(), values.end(), back_inserter(results), transmogrify); ","date":"2023-08-19","objectID":"/posts/clause_30/:3:0","tags":["Effective STL"],"title":"Effective STL [30] | 确保目标区间足够大","uri":"/posts/clause_30/"},{"categories":["C++"],"content":"结论 无论何时你使用一个要求指定目的区间的算法，确保目的区间已经足够大或者在算法执行时可以增加大小。 如果你选择增加大小，就使用插入迭代器，比如ostream_iterators或从back_inserter、front_inserter或inserter返回的迭代器。 ","date":"2023-08-19","objectID":"/posts/clause_30/:4:0","tags":["Effective STL"],"title":"Effective STL [30] | 确保目标区间足够大","uri":"/posts/clause_30/"},{"categories":["C++"],"content":"istream_iterator 拷贝文件 假设要把一个文本文件拷贝到一个字符串对象中。似乎可以用一种很有道理的方法完成： ifstream inputFile(\"interestingData.txt\"); string fileData((istream_iterator\u003cchar\u003e(inputFile)), istream_iterator\u003cchar\u003e()); // 把inputFile读入fileData； // 关于为什么它不是很正确请看下文关于这个语法的警告参见条款6 很快你就会发现这种方法无法把文件中的空格拷贝到字符串中。 那是因为istream_iterators使用operator\u003e\u003e函数来进行真的读取，而且operator\u003e\u003e函数在默认情况下忽略空格。 假如你想保留空格，你要的做就是覆盖默认情况。只要清除输入流的skipws标志就行了： ifstream inputFile(\"interestingData.txt\"); inputFile.unset(ios::skipws); // 关闭inputFile的忽略空格标志 string fileData((istream_iterator\u003cchar\u003e(inputFile)), istream_iterator\u003cchar\u003e()); 现在inputFile中的所有字符都拷贝到fileData中了。 拷贝速度 你会发现它们的拷贝速度不像你想象的那么快。 istream_iterators所依靠的operator\u003e\u003e函数进行的是格式化输入，这意味着每次你调用的时候它们都必须做大量工作： 必须建立和销毁岗哨（sentry）对象（为每个operator\u003e\u003e调用进行建立和清除活动的特殊的iostream对象）； 必须检查可能影响它们行为的流标志（比如skipws）； 必须进行全面的读取错误检查； 如果它们遇到问题，它们必须检查流的异常掩码来决定是否该抛出一个异常。 如果进行格式化输入，那些都是重要的活动，但如果你需要的只是从输入流中抓取下一个字符，那就过度了。 ","date":"2023-08-18","objectID":"/posts/clause_29/:1:0","tags":["Effective STL"],"title":"Effective STL [29] | 需要一个一个字符输入时考虑使用istreambuf_iterator","uri":"/posts/clause_29/"},{"categories":["C++"],"content":"istreambuf_iterators 拷贝文件 你可以像istream_iterator一样使用istreambuf_iterator，但istream_iterator\u003cchar\u003e对象使用operator\u003e\u003e来从输入流中读取单个字符。 istreambuf_iterator对象进入流的缓冲区并直接读取下一个字符。（更明确地说，istreambuf_iterator\u003cchar\u003e 对象从一个istream s中读取会调用s.rdbuf()-\u003esgetc()来读s的下一个字符。）把我们的文件读取代码改为使用istreambuf_iterator相当简单，大多数Visual Basic程序员都可以在两次尝试内做对： ifstream inputFile(\"interestingData.txt\"); string fileData((istreambuf_iterator\u003cchar\u003e(inputFile)), istreambuf_iterator\u003cchar\u003e()); 注意这里不需要“unset” skipws标志，istreambuf_iterator不忽略任何字符。它们只抓取流缓冲区的下一个字符。 相对于istream_iterator，它们抓取得更快。 如果你需要一个一个地读取流中的字符，你不需要格式化输入的威力，你关心的是它们花多少时间来读取流，和明显的性能提高相比，为每个迭代器多键入三个字符的代价是微弱的。对于无格式的一个一个字符输入，你总是应该考虑使用istreambuf_iterator。 ","date":"2023-08-18","objectID":"/posts/clause_29/:2:0","tags":["Effective STL"],"title":"Effective STL [29] | 需要一个一个字符输入时考虑使用istreambuf_iterator","uri":"/posts/clause_29/"},{"categories":["C++"],"content":"结论 当你了解它之后，你也应该考虑把ostreambuf_iterator用于相应的无格式一个一个字符输出的作。 它们没有了ostream_iterator的开销（和灵活性），所以它们通常也做得更好。 ","date":"2023-08-18","objectID":"/posts/clause_29/:3:0","tags":["Effective STL"],"title":"Effective STL [29] | 需要一个一个字符输入时考虑使用istreambuf_iterator","uri":"/posts/clause_29/"},{"categories":["C++"],"content":"Example 通过reverse_iterator的base初始化一个iterator: vector\u003cint\u003e v; v.reserve(5); // 参见条款14 for(int i = 0；i \u003c 5; ++ i) { // 向vector插入1到5 v.push_back(i); } vector\u003cint\u003e::reverse_iterator ri = find(v.rbegin(), v.rend(), 3); // 使ri指向3 vector\u003cint\u003e::iterator i(ri.base()); // 使i和ri的base一样 执行上述代码后，可以想到产生的结果就像这样: 上图显示了reverse_iterator和它对应的base iterator之间特有的偏移量，就像rbegin()和rend()与相关的begin()和end()一样，但是它并没有解释怎样在ri上实现你在i上想要完成的操作。 正如条款26解释的，有些容器的成员函数只接受iterator类型的参数，所以如果你想要在ri所指的位置插入一个新元素，你不能直接这么做，因为vector的insert函数不接受reverse_iterator。 如果你想要删除ri所指位置上的元素也会有同样的问题。erase成员函数会拒绝reverse_iterator，坚持要求iterator。 ","date":"2023-08-17","objectID":"/posts/clause_28/:1:0","tags":["Effective STL"],"title":"Effective STL [28] | 了解如何通过reverse_iterator的base得到iterator","uri":"/posts/clause_28/"},{"categories":["C++"],"content":"reverse_iterator转换成iterator 为了完成删除和一些形式的插入操作，你必须先通过base函数将reverse_iterator转换成iterator，然后用iterator来完成工作。 插入操作 假设你要在ri指出的位置上把一个新元素插入v。假设你要插入的值是99。 **ri在上图中遍历的顺序是自右向左，而且插入操作会将新元素插入到ri位置，并且将原先ri位置的元素移到遍历过程的“下一个”位置，我们认为3应该出现在99的左侧。**插入操作之后，v看起来像这样: 我们不能用ri来指定插入的地方，因为它不是一个iterator。我们必须用i来代替。如上所述，当ri指向3时，i（就是ri.base()）指向4。 如果我们用ri来指定插入位置，那么用i指向插入位置，那个假设就是正确的。 结论 要实现在一个reverse_iterator ri指出的位置上插入新元素，在ri.base()指向的位置插入就行了。 对于insert操作而言，ri和ri.base()是等价的，而且ri.base()真的是ri对应的iterator。 删除操作 如果你要删除ri指向的元素，你不能直接使用i了，因为i与ri不是指向同一个元素。因此，你要删除的是i的前一个元素。 vector\u003cint\u003e v; ... // 向v插入1到5，同上 vecot\u003cint\u003e::reverse_iterator ri = find(v.rbegin(), v.rend(), 3); // 同上，ri指向3 v.erase(--ri.base()); // 尝试删除ri.base()前面的元素； // 对于vector，一般来说编译不通过 表达式--ri.base()确实能够指出我们需要删除的元素。而且，它们能够处理除了vector和string之外的其他所有容器。 它可能也能处理vector和string，但对于大多数vector和string的实现，它无法通过编译。 在这样的实现下，iterator(和const_iterator)会采用内建的指针来实现，所以ri.base()的结果是一个指针。 原因剖析 C和C++都规定了不能直接修改函数返回的指针，所以在string和vector的迭代器是指针的STL平台上，像--ri.base()这样的表达式无法通过编译。 要移植从一个由reverse_iterator指出的位置删除元素时，你应该尽量避免修改base的返回值。 所以，如果你不能减少调用base的返回值，只需要先增加reverse_iterator的值，然后再调用base！ ... // 同上 v.erase((++ri).base()); // 删除ri指向的元素； // 这下编译没问题了！ 这个方法适用于所有的标准容器，这是删除一个由reverse_iterator指出的元素时首选的技巧 ","date":"2023-08-17","objectID":"/posts/clause_28/:2:0","tags":["Effective STL"],"title":"Effective STL [28] | 了解如何通过reverse_iterator的base得到iterator","uri":"/posts/clause_28/"},{"categories":["C++"],"content":"结论 reverse_iterator的base成员函数返回一个“对应的”iterator的说法并不准确：对于插入操作而言，的确如此; 但是对于删除操作，并非如此。 当需要把reverse_iterator转换成iterator的时候，有一点非常重要的是你必须知道你准备怎么处理返回的iterator，因为只有这样你才能决定你得到的iterator是否是你需要的。 ","date":"2023-08-17","objectID":"/posts/clause_28/:3:0","tags":["Effective STL"],"title":"Effective STL [28] | 了解如何通过reverse_iterator的base得到iterator","uri":"/posts/clause_28/"},{"categories":["C++"],"content":"把const_iterator转化为iterator 有些容器成员函数只接受iterator作为参数，而不是const_iterator。如果你只有一个const_iterator，要在它所指向的容器位置上插入新元素呢？ 上一条款说并不存在从const_iterator到iterator之间的隐式转换，那该怎么办？ 看看当你把一个const_iterator映射为iterator时会发生什么: typedef deque\u003cint\u003e IntDeque; // 方便的typedef typedef IntDeque::iterator Iter; typedef IntDeque::const_iterator ConstIter; ConstIter ci; // ci是const_iterator ... Iter i(ci); // 错误！没有从const_iterator 到iterator隐式转换的途径 Iter i(const_cast\u003cIter\u003e(ci)); // 仍是个错误！不能从const_iterator 映射为iterator！ 这里只是以deque为例，但是用其它容器类——list、set、multiset、map、multimap甚至条款25描述的散列表容器——的结果一样。使用映射的行也许在vector或string的代码时能够编译，但这是我们马上要讨论的非常特殊的情形。 上述代码不能通过编译的原因在于，对于这些容器而言，iterator和const_iterator是完全不同的类。 在两个毫无关联的类之间进行const_cast映射是荒谬的，所以reinterpret_cast、static_cast甚至C风格的映射也会导致同样的结果。 不能编译的代码对于vector和string容器来说也许能够通过编译 那是因为通常情况下大多数实现都会采用真实的指针作为那些容器的迭代器。 就这种实现而言，vector\u003cT\u003e::iterator是T*的typedef，而vector\u003cT\u003e::const_iterator是const T*的typedef，string::iterator是char的typedef，而string::const_iterator是const char*的typedef。 在这种实现的情况下，用const_cast把const_iterator映射成iterator当然可以编译而且没有问题，因为const_iterator与iterator之间的const_cast映射被最终解释成const T*到T*的映射。但是，即使是在这种实现中，reverse_iterator和const_reverse_iterator也是真正的类，所以你仍然不能直接用const_cast把const_reverse_iterator映射成reverse_iterator。 而且这些实现通常只会在Release模式时才使用指针表示vector和string的迭代器。 所有这些事实表明，把const迭代器映射为迭代器是病态的，即使是对vector和string来说也时，因为移植性很值得怀疑。 ","date":"2023-08-17","objectID":"/posts/clause_27/:1:0","tags":["Effective STL"],"title":"Effective STL [27] | 用distance和advance把const_iterator转化成iterator","uri":"/posts/clause_27/"},{"categories":["C++"],"content":"const_iterator转换为iterator 有一种安全的、可移植的方法获取它所对应的iterator，而且，用不着陷入类型系统的转换。 #include \u003cdeque\u003e #include \u003citerator\u003e typedef deque\u003cint\u003e IntDeque; // 和以前一样 typedef IntDeque::iterator Iter; typedef IntDeque::const_iterator ConstIter; IntDeque d; ConstIter ci; ... // 让ci指向d Iter i(d.begin()); // 初始化i为d.begin() advance(i, distance(i, ci)); // 把i移到指向ci位置（但请留意下面关于为什么在它编译前要调整的原因） 要得到与const_iterator指向同一位置的iterator: 将iterator指向容器的起始位置， 把它向前移到和const_iterator距离容器起始位置的偏移量一样的位置即可 这个任务得到了两个函数模板advance和distance的帮助，它们都在中声明: distance返回两个指向同一个容器的iterator之间的距离； advance则用于将一个iterator移动指定的距离。 如果i和ci指向同一个容器，那么表达式advance(i, distance(i, ci))会将i移动到与ci相同的位置上。 上述代码编译存在问题。 先来看看distance的定义： template\u003ctypename _InputIterator\u003e inline _GLIBCXX17_CONSTEXPR typename iterator_traits\u003c_InputIterator\u003e::difference_type distance(_InputIterator __first, _InputIterator __last) { // concept requirements -- taken care of in __distance return std::__distance(__first, __last, std::__iterator_category(__first)); } 当遇到distance调用时，你的编译器需要根据使用的实参类型推断出InputIterator的类型。 再来看看我所说的不太正确的distance调用: advance(i, distance(i, ci)); // 调整i，指向ci位置 有两个参数传递给distance，i和ci。i的类型是Iter，即deque\u003cint\u003e::iterator的typedef。 对编译器来说，这表明调用distance的InputIterator是deque::iterator。但ci是ConstIter，即deque::const_iterator的typedef。 表明那个InputIterator是deque\u003cint\u003e::const_iterator。 InputIterator不可能同时有两种不同的类型，所以调用distance失败。 一般会造成一些冗长的出错信息，可能会也可能不会说明是编译器无法得出InputIterator是什么类型。 要顺利地调用distance，你需要排除歧义。 最简单的办法就是显式的指明distance调用的模板参数类型，从而避免编译器自己得出它们的类型: advance(i, distance\u003cConstIter\u003e(i, ci)); 我们现在知道了怎么通过advance和distance获取const_iterator相应的iterator了。 效率如何？ 答案很简单。取决于你所转换的究竟是什么样的迭代器。 对于随机访问的迭代器（比如vector、string和deque的）而言，这是常数时间的操作。 对于双向迭代器（也就是，所有其它容器和包括散列容器的一些实现）而言，这是线性时间的操作。 因为它可能花费线性时间的代价来产生一个和const_iterator等价的iterator，并且因为如果不能访问const_iterator所属的容器这个操作就无法完成。 从这个角度出发，也许你需要重新审视你从const_iterator产生iterator的设计。 当处理容器时尽量用iterator代替const和reverse迭代器。 ","date":"2023-08-17","objectID":"/posts/clause_27/:2:0","tags":["Effective STL"],"title":"Effective STL [27] | 用distance和advance把const_iterator转化成iterator","uri":"/posts/clause_27/"},{"categories":["C++"],"content":"4种迭代器 每个标准容器类都提供4种迭代器类型:iterator,const_iterator，reverse_iterator和const_reverse_iterator 对于container\u003cT\u003e而言，iterator的作用相当于T*，而const_iterator则相当于const T*。 增加一个iterator或者const_iterator可以在一个从容器开头趋向尾部的遍历中让你移动到容器的下一个元素。 reverse_iterator与const_reverse_iterator同样相当于对应的T和const T，所不同的是，增加reverse_iterator或者const_reverse_iterator会在从尾到头的遍历中让你移动到容器的下一个元素。 ","date":"2023-08-16","objectID":"/posts/clause_26/:1:0","tags":["Effective STL"],"title":"Effective STL [26] | 尽量用iterator代替const_iterator，reverse_iterator和const_reverse_iterator","uri":"/posts/clause_26/"},{"categories":["C++"],"content":"vector的insert和erase的样式 iterator insert(iterator position, const T\u0026 x); iterator erase(iterator position); iterator erase(iterator rangeBegin, iterator rangeEnd); 这些方法只接受iterator类型的参数，而不是const_iterator、reverse_iterator或const_reverse_iterator。总是iterator。 ","date":"2023-08-16","objectID":"/posts/clause_26/:2:0","tags":["Effective STL"],"title":"Effective STL [26] | 尽量用iterator代替const_iterator，reverse_iterator和const_reverse_iterator","uri":"/posts/clause_26/"},{"categories":["C++"],"content":"迭代器之间存在的转换关系 图中显示了从iterator到const_iterator、从iterator到reverse_iterator和从reverse_iterator到const_reverse_iterator可以进行隐式转换。 并且，reverse_iterator可以通过调用其base成员函数转换为iterator。const_reverse_iterator也可以类似地通过base转换成为const_iterator。 通过base得到的也许并非你所期待的iterator。 而且，没有办法从一个const_iterator转换得到一个iterator，也无法从const_reverse_iterator得到reverse_iterator。 所以，当你需要指出插入位置或删除的元素时，const迭代器几乎没有用。 ","date":"2023-08-16","objectID":"/posts/clause_26/:3:0","tags":["Effective STL"],"title":"Effective STL [26] | 尽量用iterator代替const_iterator，reverse_iterator和const_reverse_iterator","uri":"/posts/clause_26/"},{"categories":["C++"],"content":"尽量使用iterator取代const或者reverse类型的迭代器 insert和erase的一些版本要求iterator。如果你需要调用这些函数，你就必须产生iterator，而不能用const或reverse iterators。 不可能把const_iterator隐式转换成iterator。从一个const_iterator产生一个iterator的技术并不普遍适用，而且不保证高效。 从reverse_iterator转换而来的iterator在转换之后可能需要相应的调整。 iterator与reverse_iterator之间的选择显而易见——依赖于从前到后或从后到前的遍历。 迭代器比较 当在iterator和const_iterator之间作选择的时候，你有更充分的理由选择iterator，即使const_iterator同样可行而且即使你并不需要调用容器类的任何成员函数。其中的令人讨厌的原因包括iterator与const_iterator之间的比较： typedef deque\u003cint\u003e IntDeque; // typedef可以极大地简化STL容器类和iterator的操作。 typedef IntDeque::iterator Iter; typedef IntDeque::const_iterator ConstIter; Iter i; ConstIter ci; ... // 同一个容器 if (i == ci) ... // 比较iterator和const_iterator 唯一的变化是等号的一边的类型是iterator，而另一边的类型是const_iterator。 因为iterator应该在比较之前隐式的转换成const_iterator，真正的比较应该在两个const_iterator之间进行。 如果一些实现将const_iterator的operator==作为const_iterator的一个成员函数而不是非成员函数。 而问题的解决之道显得非常有趣：只要像这样交换两个iterator的位置： if (ci == i)... // 当上面比较无法通过编译时的解决方法 迭代器混用 不仅是比较是否相等，只要你在同一个表达式中混用iterator和const_iterator（或者reverse_iterator和const_reverse_iterator），这样的问题就可能会出现: if (i - ci \u003e= 3) ... // 如果i与ci之间至少有三个元素... 如果迭代器的类型不同，你的正确的代码可能会被错误地拒绝。 本例中最简单的解决方法是通过一个（安全的）映射把iterator转换为const_iterator: if (static_cast\u003cConstIter\u003e(i) - ci \u003e= 3) ... // 当上面的代码无法通过编译时的解决方法 避免这类问题的最简单的方法是减少混用不同类型的迭代器的机会。 ","date":"2023-08-16","objectID":"/posts/clause_26/:4:0","tags":["Effective STL"],"title":"Effective STL [26] | 尽量用iterator代替const_iterator，reverse_iterator和const_reverse_iterator","uri":"/posts/clause_26/"},{"categories":["C++"],"content":"STL没有散列表。 兼容STL的散列关联容器可以从多个来源获得，而且它们甚至有事实上的标准名字：hash_set、hash_multiset、hash_map和hash_multimap。在C++标准委员会的议案中，散列容器的名字是unordered_set、 unordered_multiset、unordered_map和unordered_multimap。 它们在接口、能力、内在数据结构和支持操作的相关效率方面不同。 最常见的两个来自SGI和Dinkumware，STLport也提供散列容器，但是STLport的散列容器是基于来自SGI的。 散列容器是关联容器，它们需要知道储存在容器中的对象类型，用于这些对象的比较函数，以及用于这些对象的分配器。 ","date":"2023-08-16","objectID":"/posts/clause_25/:0:0","tags":["Effective STL"],"title":"Effective STL [25] | 熟悉非标准散列容器","uri":"/posts/clause_25/"},{"categories":["C++"],"content":"散列容器声明 散列容器需要散列函数的说明。下面是散列容器声明： template\u003ctypename T, typename HashFunction, typename CompareFunction, typename Allocator = allocator\u003cT\u003e \u003e class hash_container; 这非常接近于散列容器的SGI声明，主要差别是SGI为HashFunction和CompareFunction提供了默认类型。 SGI 设计举例 hash_set的SGI声明看起来基本上像这样： template\u003ctypename T, typename HashFunction = hash\u003cT\u003e, typename CompareFunction = equa_to\u003cT\u003e, typename Allocator = allocator\u003cT\u003e \u003e class hash_set; SGI设计的一个值得注意的方面是使用equal_to作为默认比较函数。这违背标准关联容器的约定——默认比较函数是less。 SGI的散列容器确定在一个散列容器中的两个对象是否有相同的值是通过相等测试，而不是等价。 因为散列关联容器，不像它们在标准中的（通常基于树）兄弟，不需要保持有序。 Dinkumware 设计举例 Dinkumware设计的散列容器采取一些不同的策略。它仍然允许你指定对象类型、散列函数类型、比较函数类型和分配器类型，但是它把默认的散列和比较函数移进一个单独的类似特性的叫做hash_compare的类，而且它把hash_compare作为容器模板的HashingInfo实参的默认值。 这是Dinkumware的hash_set声明（再次为演示而调整过）: template\u003ctypename T, typename CompareFunction\u003e class hash_compare; template\u003ctypename T, typename HashingInfo = hash_compare\u003cT, less\u003cT\u003e \u003e typename Allocator = allocator\u003cT\u003e \u003e class hash_set; 这种接口设计有趣的地方是HashingInfo的使用。 容器的散列和比较函数储存在HashingInfo中，但HashingInfo类型也容纳了控制表中桶（bucket）最小数量，以及容器元素对桶的最大允许比率的枚举。 当这比率被超过时，表中桶的数量就增加，而表中的一些元素需要重新散列。（SGI提供具有类似控制表中桶和表中元素对桶比率的成员函数。） hash_compare hash_compare（HashingInfo的默认值）看起来或多或少像这样: template\u003ctypename T, typename CompareFunction = less\u003cT\u003e \u003e class hash_compare { public: enum { bucket_size = 4, // 元素对桶的最大比率 min_buckets = 8 // 桶的最小数量 }; size_t operator()(const T\u0026) const; // 散列函数比较函数 bool operator()(const T\u0026, const T\u0026) const; ... // 忽略一些东西，包括 CompareFunction的使用 } 重载operator()（在这里是实现散列和比较函数）是比你可以想象的更经常出现的一个策略。 Dinkumware设计允许你写你自己的类似hash_compare的类（也许通过从hash_compare本身派生而来），而且只要你的类定义了bucket_size、min_buckets、两个operator()函数（一个带有一个实参，一个带有两个），加上已经省去的一些东西，就能使用它来控制Dinkumware的hash_set或hash_multiset的配置和行为。 hash_map和hash_multimap的配置控制也相似。 ","date":"2023-08-16","objectID":"/posts/clause_25/:1:0","tags":["Effective STL"],"title":"Effective STL [25] | 熟悉非标准散列容器","uri":"/posts/clause_25/"},{"categories":["C++"],"content":"决策留给实现 注意不管是SGI还是Dinkumware的设计，你都能把全部决策留给实现: // 建立一个int的散列表 hash_set\u003cint\u003e intTable; 要让这个可以编译，散列表必须容纳一个整数类型（例如int），因为默认散列函数一般局限于整数类型。 实现方法不同 在后端，SGI和Dinkumware的实现方法非常不同。 SGI利用常用的一个元素的单链表的指针数组（桶）组成的开放散列法。 Dinkumware也利用了开放散列法，但是它的设计是基于一种新颖的数据结构——由迭代器（本质是桶）的数组组成的元素双向链表，迭代器的相邻对表示在每个桶里元素的范围。 链表不同 SGI实现在单链表中储存表的元素 Dinkumware实现使用一个双向链表 迭代器种类不同 SGI的散列容器提供了前向迭代器，因此你得放弃进行反向迭代的能力：在SGI的散列容器中没有rbegin或者rend成员函数。 用于Dinkumware散列容器的迭代器是双向的，所以它们可以提供前向和反向遍历。 内存使用量方面不同 SGI的设计比Dinkumware的节俭一点点。 ","date":"2023-08-16","objectID":"/posts/clause_25/:2:0","tags":["Effective STL"],"title":"Effective STL [25] | 熟悉非标准散列容器","uri":"/posts/clause_25/"},{"categories":["C++"],"content":"结论 虽然STL本身缺乏散列容器，兼容STL的散列容器（有不同的接口、能力和行为权衡）不难得到。就SGI和STLport的实现而言，你甚至可以免费下载得到它们。 ","date":"2023-08-16","objectID":"/posts/clause_25/:3:0","tags":["Effective STL"],"title":"Effective STL [25] | 熟悉非标准散列容器","uri":"/posts/clause_25/"},{"categories":["C++"],"content":"Example map插入 假设有一个支持默认构造函数以及从一个double构造和赋值的Widget类: class Widget { public: Widget(); Widget(double weight); Widget\u0026 operator=(double weight); ... } 假设我们想建立一个从int到Widget的map，而且我们想有初始化有特定值的映射: map\u003cint, Widget\u003e m; m[1] = 1.50; m[2] = 3.67; m[3] = 10.5; m[4] = 45.8; m[5] = 0.0003; map operator[] 工作原理 map的operator[]函数是个奇怪的东西。它与vector、deque和string的operator[]函数无关，也和内建的数组operator[]无关。 map::operator[]被设计为简化“添加或更新”功能。即，给定map\u003cK, V\u003e m;这个表达式 m[k] = v; 检查键k是否已经在map里。如果不，就添加上，以v作为它的对应值。如果k已经在map里，它的关联值被更新成v。 这项工作的原理是operator[]返回一个与k关联的值对象的引用。然后v赋值给所引用（从operator[]返回的）的对象。 当要更新一个已存在的键的关联值时很直接，因为已经有operator[]可以用来返回引用的值对象。 但是如果k还不在map里，operator[]就没有可以引用的值对象。那样的话，它使用值类型的默认构造函数从头开始建立一个，然后operator[]返回这个新建立对象的引用。 让我们再次地看看原先例子的第一部分： map\u003cint, Widget\u003e m; m[1] = 1.50; 表达式m[1]是m.operator[](1)的简化，所以这是一个map::operator[]的调用。 这个函数必须返回一个Widget的引用，因为m 的映射类型是Widget。 在这里，m里面还没有任何东西，所以键1在map里没有入口。因此operator[]默认构造一个Widget来作为关联到1的值，然后返回到那个Widget的引用。 最后，Widget成为赋值目标：被赋值的值是1.50。 所以，下面这个语句 m[1] = 1.50; 功能上等价于这个: // 方便的 typedef typedef map\u003cint, Widget\u003e IntWidgetMap; // 用键1建立新映射入口和一个默认构造的值对象； pair\u003cIntWidgetMap::iterator, bool\u003e result = m.insert(IntWidgetMap::value_type(1, Widget())); // 赋值给值类型 result.first-\u003esecond = 1.50; 现在已经很清楚为什么这种方法可能降低性能了：先默认构造一个Widget，然后我们立即赋给它新值。 map insert更高效 如果用想要的值构造Widget比默认构造Widget然后进行赋值显然更高效，就应该用直截了当的insert调用来替换operator[]的使用（包括它的构造加赋值）: m.insert(IntWidgetMap::value_type(1, 1.50)); 这与上面的那些代码有相同的最终效果，除了它通常节省了3次函数调用： 一个建立临时的默认构造Widget对象 一个销毁那个临时的对象 一个对Widget的赋值操作。 这些函数调用越昂贵，你通过使用map-insert代替map::operator[]就能节省越多。 上面的代码利用了每个标准容器都提供的value_type typedef。这typedef没有什么特别重要的，但对于map和multimap（以及非标准容器的hash_map和hash_multimap——参见条款25），记住它是很重要的，容器元素的类型总是某种pair。 之前谈及的operator[]被设计为简化“添加或更新”功能，而且现在我们理解了当“增加”被执行时，insert比operator[]更高效。当做更新时，情形正好相反，也就是，当一个等价的键这已经在map里时。 // 使用operator[]来把k的值更新为v m[k] = v; // 来把k的值更新为v使用insert m.insert(IntWidgetMap::value_type(k, v)).first-\u003esecond = v; ","date":"2023-08-15","objectID":"/posts/clause_24/:1:0","tags":["Effective STL"],"title":"Effective STL [24] | 当关乎效率时应该在map::operator[]和map-insert之间仔细选择","uri":"/posts/clause_24/"},{"categories":["C++"],"content":"operator[] 与 insert 权衡 insert的调用需要IntWidgetMap::value_type类型的实参（即pair\u003cint, Widget\u003e），所以当调用insert时，我们必须构造和析构一个那种类型的对象。那耗费了一对构造函数和析构函数，也会造成一个Widget的构造和析构，因为pair\u003cint, Widget\u003e本身包含了一个Widget对象，operator[]没有使用pair对象，所以没有构造和析构pair和Widget。 Note 情形选择: 因此出于对效率的考虑，当给map添加一个元素时，我们断定insert比operator[]好； 从效率和美学考虑，当更新已经在map里的元素值时operator[]更好。 如果STL提供一个两全其美的函数，即，在句法上吸引人的包中的高效的“添加或更新”功能: // 如果键k不再map m中；高效地把pair(k, v)添加到m中； // 否则高效地把和k关联的值更新为v。 // 返回一个指向添加或修改的pair的迭代器 iterator affectedPair = efficientAddOrUpdate(m, k, v); 但是，在STL内没有像这样的函数，正如下面的代码所演示的，自己写一个并不难。那些注释总结了正在做什么，而且随后的段落也提供了一些附加的解释。 // map的类型KeyArgType和ValueArgtype是类型参数的原因请看下面 template\u003ctypename MapType, typename KeyArgType, typename ValueArgtype\u003e typename MapType::iterator efficientAddOrUpdate(MapType\u0026 m, const KeyArgType\u0026 k, const ValueArgtype\u0026 v) { // 找到k在或应该在哪里； typename MapType::iterator Ib = m.lower_bound(k); // 如果Ib指向一个pair, 它的键等价于k... if(Ib != m.end() \u0026\u0026 !(m.key_comp()(k, Ib-\u003efirst))) { // 更新这个pair的值 Ib-\u003esecond = v; // 并返回指向pair的迭代器 return Ib; } else{ typedef typename MapType::value_type MVT; // 把pair(k, v)添加到m并// 返回指向新map元素的迭代器 return m.insert(Ib, MVT(k, v)); } } 执行一个高效的增加或更新，我们需要能找出k的值是否在map中; 如果是这样，那它在哪里; 如果不是，它该被插入哪里。 这个工作是为low_bound量身定做的，所以在这里我们调用那个函数。确定lower_bound是否用我们要寻找的键找到了一个元素，我们对后半部分进行一个等价测试，一定要对map使用正确的比较函数: 通过map::key_comp提供的比较函数。等价测试的结果告诉我们应该进行增加还是更新。 如果是更新，代码很直截了当。插入分支更有趣，因为它使用了insert的“提示”形式。结构m.insert(Ib，MVT(k，v))“提示”了**Ib鉴别出了键等价于k的新元素正确的插入位置，而且保证如果提示正确，那么插入将在分摊的常数时间内发生，而不是对数时间**。在efficientAddOrUpdate里，我们知道Ib鉴别出了适当的插入位置，因此insert的调用被保证为是一次常数时间操作。 KeyArgType和ValueArgType 这个实现的一个有趣方面是KeyArgType和ValueArgType不必是储存在map里的类型。它们只需要可以转换到储存在map里的类型。 一个可选的方法是去掉类型参数KeyArgType和ValueArgType，改为使用MapType::key_type和MapType::mapped_type。 但是，如果我们那么做，在调用时我们可能强迫发生不必要的类型转换: map\u003cint, Widget\u003e m; // 别忘了Widget接受从一个double赋值： class Widget { public: ... Widget\u0026 operator=(double weight); ... }; 现在考虑efficientAddOrUpdate的调用: efficientAddOrUpdate(m, 10, 1.5); 假设是一次更新操作，即，m已经包含键是10的元素。那样的话，上面的模板推断出ValueArgType是double，函数体直接把1.5作为double赋给与10相关的那个Widget。那是通过调用Widget::operator(double)完成的。 如果我们用了MapType::mapped_type作为efficientAddOrUpdate的第3个参数的类型，在调用时我们得把1.5转化成一个Widget，那样的话我们就得花费本来不需要的一次Widget构造（以及随后的析构）。 ","date":"2023-08-15","objectID":"/posts/clause_24/:2:0","tags":["Effective STL"],"title":"Effective STL [24] | 当关乎效率时应该在map::operator[]和map-insert之间仔细选择","uri":"/posts/clause_24/"},{"categories":["C++"],"content":"结论 当关乎效率时应该在map::operator[]和map-insert之间仔细选择。 如果你要更新已存在的map元素，operator[]更好，但如果你要增加一个新元素，insert则有优势。 ","date":"2023-08-15","objectID":"/posts/clause_24/:3:0","tags":["Effective STL"],"title":"Effective STL [24] | 当关乎效率时应该在map::operator[]和map-insert之间仔细选择","uri":"/posts/clause_24/"},{"categories":["C++"],"content":"当需要一个提供快速查找的数据结构时，很多STL程序员立刻会想到标准关联容器：set、multiset、map和multimap。 如果使用了合适的散列函数，则可以认为散列容器提供了常数时间的查找。 对于多数应用，被认为是常数时间查找的散列容器要好于保证了对数时间查找的set、map和它们的multi同事。 即使你需要的就只是==对数时间==查找的保证，标准关联容器仍然可能不是你的最佳选择。和直觉相反，对于标准关联容器，所提供的性能也经常劣于本该比较次的vector。 ","date":"2023-08-14","objectID":"/posts/clause_23/:0:0","tags":["Effective STL"],"title":"Effective STL [23] | 考虑用有序vector代替关联容器","uri":"/posts/clause_23/"},{"categories":["C++"],"content":"关联容器数据结构 标准关联容器的典型实现是平衡二叉查找树。 一个平衡二叉查找树是一个对插入、删除和查找的混合操作优化的数据结构。 换句话说，它被设计为应用于进行一些插入，然后一些查找，然后可能再进行一些插入，然后也许一些删除，然后再来一些查找，然后更多的插入或删除，然后更多的查找等。这个事件序列的关键特征是插入、删除和查找都是混合在一起的。 一般来说，没有办法预测对树的下一个操作是什么。 使用数据结构的3阶段 建立。通过插入很多元素建立一个新的数据结构。在这个阶段，几乎所有的操作都是插入和删除。几乎没有或根本没有查找。 查找。在数据结构中查找指定的信息片。在这个阶段，几乎所有的操作都是查找。几乎没有或根本没有插入和删除。 重组。修改数据结构的内容，通过删除所有现有数据和在原地插入新数据。从动作上说，这个阶段等价于阶段1。一旦这个阶段完成，应用程序返回阶段2。 ","date":"2023-08-14","objectID":"/posts/clause_23/:1:0","tags":["Effective STL"],"title":"Effective STL [23] | 考虑用有序vector代替关联容器","uri":"/posts/clause_23/"},{"categories":["C++"],"content":"有序vector更高效 一个vector可能比一个关联容器能提供更高的性能（时间和空间上都是）。 但不是任意的vector都会，只有有序vector。因为只有有序容器才能正确地使用查找算法——binary_search、lower_bound、equal_range等。 Q: 为什么一个（有序的）vector的二分法查找比一个二叉树的二分法查找提供了更好的性能？ A: 其中的一个是大小问题，其中的一个是引用局部性问题。 大小问题 假设我们需要一个容器来容纳Widget对象，而且，因为查找速度对我们很重要，我们考虑一个Widget的关联容器和一个有序vector\u003cWidget\u003e。 关联容器数据结构 如果选择一个关联容器，我们几乎确定了要使用平衡二叉树。这样的树是由树节点组成，每个都不仅容纳了一个Widget，而且保存了一个该节点到左孩子的指针，一个到它右孩子的指针，和（典型的）一个到它父节点的指针。 这意味着在关联容器中用于存储一个Widget的空间开销至少会是三个指针。 vector数据结构 与之相对的是，当在vector中存储Widget并没有开销：简单地存储一个Widget。 当然，vector本身有开销，在vector结尾也可能有空的（保留）空间，但是每个vector开销是可以忽略的（通常是三个机器字，比如，三个指针或两个指针和一个int），而且如果必要的话，末尾空的空间可以通过“交换技巧”去掉。即使这个附加的空间没有去掉，也并不影响下面的分析，因为当查找时不会引用那段内存。 内存大小 假设我们的数据结构足够大，它们可以分成多个内存页面，但是vector比关联容器需要的页面要少。 因为vector不需要每个Widget的开销，而关联容器给每个Widget上附加了三个指针。 假设在你使用的系统上一个Widget的大小是12个字节，指针是4个字节，一个内存页面是4096（4K）字节。 忽略每个容器的开销，当用vector保存时，你可以在一页面上放置341个Widget $(4096\\div12\\approx341)$，但使用关联容器时你最多只能放170个 $4096\\div(12+4\\times3)\\approx170)$。 因此关联容器和vector比起来，你将会使用大约两倍的内存。 如果你使用的环境可以用虚拟内存，就很可以容易地看出那会造成大量的页面错误，因此一个系统会因为大数据量而明显慢下来。 引用局部性问题 假设在二叉树中的节点都群集在一个相关的小内存页面集中，实际情况下关联容器很乐观的。 大部分STL实现使用自定义内存管理器来达到这样的群集，但是如果你的STL实现没有改进树节点中的引用局部性，这些节点会分散在所有你的内存空间。那会导致更多的页面错误。 即使使用了自定义群集内存管理器，关联容器也会导致很多页面错误，因为，不像连续内存容器，比如vector，基于节点的容器更难保证在容器的遍历顺序中一个挨着一个的元素在物理内存上也是一个挨着一个。 当进行二分查找时那种内存组织方式（译注：遍历顺序中一个挨着一个的元素在物理内存上也是一个挨着一个）正好是页面错误最少的。 ","date":"2023-08-14","objectID":"/posts/clause_23/:2:0","tags":["Effective STL"],"title":"Effective STL [23] | 考虑用有序vector代替关联容器","uri":"/posts/clause_23/"},{"categories":["C++"],"content":"vector的缺点 有序vector的大缺点是必须保持有序！ 因为vector中所有的元素都必须拷贝，所以： 当一个新元素插入时，大于这个新元素的所有东西都必须向上移一位，非常昂贵； 如果vector必须重新分配它的内在内存，则会更昂贵； 如果一个元素从vector中被删除，所有大于它的元素都要向下移动。 vector的插入和删除都很昂贵，但是关联容器的插入和删除则很轻量。 这就是为什么只有当你知道你的数据结构使用的时候查找几乎不和插入和删除混合时，使用有序vector代替关联容器才有意义。 概要 在有序vector中存储数据很有可能比在标准关联容器中保存相同的数据消耗更少的内存； 当页面错误值得重视的时候，在有序vector中通过二分法查找可能比在一个标准关联容器中查找更快。 ","date":"2023-08-14","objectID":"/posts/clause_23/:3:0","tags":["Effective STL"],"title":"Effective STL [23] | 考虑用有序vector代替关联容器","uri":"/posts/clause_23/"},{"categories":["C++"],"content":"Example vector代替set // 代替set\u003cWidget\u003e vector\u003cWidget\u003e vw; // 建立阶段：很多插入，几乎没有查找 ... // 结束建立阶段。（当模拟一个multiset时，你可能更喜欢用stable_sort 来代替； sort(vw.begin(), vw.end()); // 用于查找的值的对象 Widget w; ...// 开始查找阶段 // 通过binary_search查找 if (binary_search(vw.begin(), vw.end(), w))... // 通过lower_bound查找 vector\u003cWidget\u003e::iterator i = lower_bound(vw.begin(), vw.end(), w); // 条款19解释了“!(w \u003c *i)”测试 if (i != vw.end() \u0026\u0026 !(w \u003c *i))... // 通过equal_range查找 pair\u003cvector\u003cWidget\u003e::iterator, vector\u003cWidget\u003e::iterator\u003e range = equal_range(vw.begin(), vw.end(), w); if (range.first != range.second)... ... // 结束查找阶段，开始重组阶段 // 开始新的查找阶段... sort(vw.begin(), vw.end()); 里面最难的东西就是怎么在搜索算法中做出选择（比如，binary_search、lower_bound等） vector代替map或multimap 当你决定用vector代替map或multimap时，事情会变得更有趣，因为vector必须容纳pair对象。 但是要注意，如果你声明一个map\u003cK, V\u003e的对象（或者等价的multimap），保存在map中的元素类型是pair\u003cconst K, V\u003e。 如果要用vector模拟map或者multimap，必须去掉const，因为当你对vector排序时，元素的值将会通过赋值移动，那意味着pair的两个组件都必须是可赋值的。 当使用vector来模拟map\u003cK, V\u003e时，保存在vector中数据的类型将是pair\u003cK, V\u003e，而不是pair\u003cconst K, V\u003e。 map和multimap以顺序的方式保存他们的元素，但用于排序目的时它们只作用于元素的key部分（pair的第一个组件），所以当排序vector时你必须做一样的事情。 你需要为你的pair写一个自定义比较函数，因为pair的operator\u003c作用于pair的两个组件。 2个比较函数来进行查找 用来排序的比较函数将作用于两个pair对象，但是查找只用到key值。 必须传给用于查找的比较函数一个key类型的对象（要查找的值）和一个pair（存储在vector中的一个pair）——两个不同的类型。 还有一个附加的麻烦，你不会知道key还是pair是作为第一个实参传递的，所以你真的需要两个用于查找的比较函数：一个key值先传递，一个pair先传递 typedef pair\u003cstring, int\u003e Data; // 在这个例子里\"map\"容纳的类型 class DataCompare { // 用于比较的类 public: // 用于排序的比较函数keyLess在下面 bool operator()(const Data\u0026 lhs, const Data\u0026 rhs) const { return keyLess(lhs.first, rhs.first); } // 用于查找的比较函数（形式1） bool operator()(const Data\u0026 Ihs, const Data::first_type\u0026 k) const { return keyLess(lhs.first, k); } // 用于查找的比较函数（形式2） bool operator()(const Data::first_type\u0026 k, const Data\u0026 rhs) const { return keyLessfk, rhs.first); } private: // “真的”比较函数 bool keyLess(const Data::first_type\u0026 k1, const Data::first_type\u0026 k2) const { return k1 \u003c k2; } }; 我们假设有序vector将模拟map\u003cstring, int\u003e。 这段代码几乎是上面讨论的字面转换，除了存在成员函数keyLess。 那个函数的存在是用来保证几个不同的operator()函数之间的一致性。 每个这样的函数只是简单地比较两个key的值，所以我们把这个测试放在keyLess中并让operator()函数返回keyLess所做的事情，这比复制那个逻辑要好。 这个软件工程中绝妙的动作增强了DataCompare的可维护性，但有一个小缺点，它提供了有不同参数类型的operator()函数，这将导致函数对象无法适配。 把有序vector用作map本质上和用作set一样。 唯一大的区别是必须把DataCompare对象用作比较函数: // 代替map\u003cstring, int\u003e vector\u003cData\u003e vd; // 建立阶段：很多插入，几乎没有查找 ... // 结束建立阶段。（当模拟multimap时，你可能更喜欢用stable_sort来代替）； sort(vd.begin(), vd.end(), DataCompare()); // 用于查找的值的对象 string s; ... // 开始查找阶段 // 通过binary_search查找 if (binary_search(vd.begin(), vd.end(), s, DataCompare()))... // 再次通过lower_bound查找， vector\u003cData\u003e::iterator i = lower_bound(vd.begin(), vd.end(), s, DataCompare()); // 条款45解释了“!DataCompare()(s, *i)”测试 if (i != vd.end() \u0026\u0026 !DataCompare()(s, *i))... // 通过equal_range查找 pair\u003cvector\u003cData\u003e::iterator, vector\u003cData\u003e::iterator\u003e range = equal_range(vd.begin(), vd.end(), s, DataCompare()); if (range.first != range.second)... ... // 结束查找阶段，开始重组阶段 // 开始新的查找阶段... sort(vd.begin(), vd.end(), DataCompare()); 正如你所见，一旦你写了DataCompare，东西都很好地依序排列了。 而一旦位置合适了，它们往往比相应的使用真的map的设计运行得更快而且使用更少内存。 如果你的程序不是按照阶段的方式操作数据结构，那么使用有序vector代替标准关联容器几乎可以确定是在浪费时间。 ","date":"2023-08-14","objectID":"/posts/clause_23/:4:0","tags":["Effective STL"],"title":"Effective STL [23] | 考虑用有序vector代替关联容器","uri":"/posts/clause_23/"},{"categories":["C++"],"content":"所有标准关联容器，set和multiset保持它们的元素有序，这些容器的正确行为依赖于它们保持有序。 如果你改了关联容器里的一个元素的值（例如，把10变为1000），新值可能不在正确的位置，而且那将破坏容器的有序性。 ","date":"2023-08-14","objectID":"/posts/clause_22/:0:0","tags":["Effective STL"],"title":"Effective STL [22] | 避免原地修改set和multiset的键","uri":"/posts/clause_22/"},{"categories":["C++"],"content":"修改map和multimap值 试图改变这些容器里的一个键值的程序将不能编译: map\u003cint, string\u003e m; ... m.begin()-\u003efirst = 10; // 错误！map键不能改变 multimap\u003cint, string\u003e mm; ... mm.begin()-\u003efirst = 20; // 错误！multimap键也不能改变 Note 因为map\u003cK, V\u003e或multimap\u003cK, V\u003e类型的对象中元素的类型是pair\u003cconst K, V\u003e。因为键的类型const K，它不能改变。 template \u003ctypename _Key, typename _Tp, typename _Compare = std::less\u003c_Key\u003e, typename _Alloc = std::allocator\u003cstd::pair\u003cconst _Key, _Tp\u003e \u003e \u003e class map { public: typedef _Key key_type; typedef _Tp mapped_type; typedef std::pair\u003cconst _Key, _Tp\u003e value_type; typedef _Compare key_compare; typedef _Alloc allocator_type; ... } 如果你使用一个const_cast，或许能改变它，后面会讨论到。 ","date":"2023-08-14","objectID":"/posts/clause_22/:1:0","tags":["Effective STL"],"title":"Effective STL [22] | 避免原地修改set和multiset的键","uri":"/posts/clause_22/"},{"categories":["C++"],"content":"修改set和multiset值 对于set\u003cT\u003e或multiset\u003cT\u003e类型的对象来说，储存在容器里的元素类型只不过是T，并非const T。因此，set或multiset里的元素可能在你想要的任何时候改变。不需要映射。 template\u003ctypename _Key, typename _Compare = std::less\u003c_Key\u003e, typename _Alloc = std::allocator\u003c_Key\u003e \u003e class set { public: // typedefs: ///@{ /// Public typedefs. typedef _Key key_type; typedef _Key value_type; typedef _Compare key_compare; typedef _Compare value_compare; typedef _Alloc allocator_type; ///@} ... } 为什么set或multiset里的元素不是常数？ 假设我们有一个雇员的类: class Employee { public: ... const string\u0026 name() const; // 获取雇员名 void setName(const string\u0026 name); // 设置雇员名 const string\u0026 getTitle() const; // 获取雇员头衔 void setTitle(string\u0026 title); // 设置雇员头衔 int idNumber() const; // 获取雇员ID号 ... } 让我们做合理的假设，每个雇员有唯一的ID号，就是idNumber函数返回的数字。然后，建立一个雇员的set，很显然应该只以ID号来排序set: struct IDNumberLess { public binary_function\u003cEmployee, Employee, bool\u003e { // 参见条款40 bool operator()(const Employees lhs, const Employee\u0026 rhs) const { return lhs.idNumber() \u003c rhs.idNumber(); } }; typedef set\u003cEmployee, IDNumberLess\u003e EmpIDSet; EmpIDSet se; // se是雇员的set， 按照ID号排序 实际上，雇员的ID号是set中元素的键。其余的雇员数据只是虚有其表。在这里，没有理由不能把一个特定雇员的头衔改成某个有趣的东西: Employee selectedID; // 容纳被选择的雇员 ... // ID号的变量 EmpIDSet::iterator i = se.find(selectedID); if (i != se.end()){ i-\u003esetTitle(\"Corporate Deity\"); // 给雇员新头衔 } 因为在这里我们只是改变雇员的一个与set排序的方式无关的方面（一个雇员的非键部分），所以这段代码不会破坏set。那是它合法的原因。但它的合法排除了set/multiset的元素是const的可能。而且那是它们为什么不是的原因。 因为set或multiset里的值不是const，所以试图改变它们可以编译。 如果你改变set或multiset里的元素， 你必须确保不改变一个键部分——影响容器有序性的元素部分。如果你做了，你会破坏容器，再使用那个容器将产生未定义的结果， 而且那是你的错误。另一方面，这个限制只应用于被包含对象的键部分。对被包含元素的所有其他部分来说，是开放的: 随便改变！ ","date":"2023-08-14","objectID":"/posts/clause_22/:2:0","tags":["Effective STL"],"title":"Effective STL [22] | 避免原地修改set和multiset的键","uri":"/posts/clause_22/"},{"categories":["C++"],"content":"阻止修改set和multiset值 即使set和multiset的元素不是const，实现仍然有很多方式可以阻止它们被修改。 例如，实现可以让用于set\u003cT\u003e::iterator的operator*返回一个常数T\u0026。即，它可以让set的迭代器解引用的结果是set元素的常量引用。 在这样的实现下，将没有办法修改set或multiset的元素，因为所有访问那些元素的方法都将在让你访问之前加一个const。 ","date":"2023-08-14","objectID":"/posts/clause_22/:3:0","tags":["Effective STL"],"title":"Effective STL [22] | 避免原地修改set和multiset的键","uri":"/posts/clause_22/"},{"categories":["C++"],"content":"要不要修改set和multiset值 如果不关心移植性，你想要改变set或multiset中元素的值，而且你的STL实现让你侥幸成功，继续做。只是要确定不要改变元素的键部分，即，会影响容器有序性的元素部分。 如果在乎移植性，就认为set和multiset中的元素不能被修改，至少不能在没有映射的情况下 Solution: 映射到一个引用 有时候完全有理由改变set或multiset元素的非键部分。例如刚看的不能在一些实现下编译的setTitle调用: EmpIDSet::iterator i = se.find(selectedID); if (i != se.end()) { i-\u003esetTitle(\"Corporate Deity\"); // 有些STL实现会拒绝这样，因为*i是const } 为了让它可以编译并且行为正确，我们必须映射掉*i的常量性。这是那么做的正确方法: if (i != se.end()) { const_cast\u003cEmployee\u0026\u003e(*i).setTitle(\"Corporate Deity\"); // 映射掉*i的常量性 } 这可以得到i指向的对象，告诉你的编译器把映射的结果当作一个（非常数）Employee的引用，然后在那个引用上调用setTitle。 错误版本的映射 if (i != se.end()){ static_cast\u003cEmployee\u003e(*i).setTitle(\"Corporate Deity\"); // 把*i映射到一个Employee } 它也等价于如下内容: if (i != se.end()) { ((Employee)(*i)).setTitle(\"Corporate Deity\"); // 使用C映射语法 } 这两个都能编译，而且因为它们等价，所以它们错的原因也相同。 在运行期，它们不能修改*i！ 在这两个情况里，映射的结果是一个*i副本的临时匿名对象，而setTitle是在匿名的物体上调用，不在*i上！*i没被修改，因为setTitle从未在那个对象上调用，它在那个对象的副本上调用。 两个句法形式等价于这个: if (i != se.end()){ Employee tempCopy(*i); // 把*i拷贝到tempCopy tempCopy.setTitle(\"Corporate Deity\"); // 修改tempCopy } 通过映射到引用，我们避免了建立一个新对象。 取而代之的是，映射的结果是一个现有对象的引用，i指向的对象。 当我们在有这个引用指定的对象上调用setTitle时，我们是在*i上调用setTitle，而且那正是我们想要的。 为什么不能去掉map和multimap的常量性 注意map\u003cK, V\u003e或multimap\u003cK, V\u003e包含pair\u003cconst K, V\u003e类型的元素。 那个const表明pair的第一个组件被定义为常量，而那意味着试图修改它是未定义的行为（即使映射掉它的常量性）。 理论上，一个STL实现可能把这样的值写到一个只读的内存位置（比如，一旦写了就通过系统调用进行写保护的虚拟内存页），而且试图映射掉它的常量性，最多，没有效果。 如果你是一个坚持遵循标准拟定的规则的人，你绝不会试图映射掉map或multimap键的常量性。 ","date":"2023-08-14","objectID":"/posts/clause_22/:4:0","tags":["Effective STL"],"title":"Effective STL [22] | 避免原地修改set和multiset的键","uri":"/posts/clause_22/"},{"categories":["C++"],"content":"安全修改元素步骤 想要总是可以工作而且总是安全地改变set、multiset、map或multimap里的元素，按5个简单的步骤去做： 定位你想要改变的容器元素。如果你不确定最好的方法， 条款45提供了关于怎样进行适当搜寻的指导。 拷贝一份要被修改的元素。对map或multimap而言，确定不要把副本的第一个元素声明为const。毕竟，你想要改变它！ 修改副本，使它有你想要在容器里的值。 从容器里删除元素，通常通过调用erase（参见条款9）。 把新值插入容器。如果新元素在容器的排序顺序中的位置正好相同或相邻于删除的元素，使用insert的“提示”形式把插入的效率从对数时间改进到分摊的常数时间。使用你从第一步获得的迭代器作为提示。 一句话概括就是：先删除，再插入新的。 Example: 这是同一个累人的雇员例子，这次以安全、可移植的方式写: EmpIDSet se; // 同前，se是一个以ID号排序的雇员set Employee selectedID; // 同前，selectedID是一个带有需要ID号的雇员 ... EmpIDSet::iterator i = se.find(selectedID); // 第一步：找到要改变的元素 if (i!=se.end()) { Employee e(*i); // 第二步：拷贝这个元素 se.erase(i++); // 第三步：删除这个元素； // 自增这个迭代器以 // 保持它有效（参见条款9） e.setTitle(\"Corporate Deity\"); // 第四步：修改这个副本 se.insert(i, e); // 第五步：插入新值；提示它的位置和原先元素的一样 } ","date":"2023-08-14","objectID":"/posts/clause_22/:5:0","tags":["Effective STL"],"title":"Effective STL [22] | 避免原地修改set和multiset的键","uri":"/posts/clause_22/"},{"categories":["C++"],"content":"Example set 建立一个set，比较类型用less_equal，然后插入整型数字33(称为 $33_{A}$): set\u003cint, less_equal\u003cint\u003e \u003e s; // s以“\u003c=”排序 s.insert(33); // 插入33 现在尝试再插入一次33(称为 $33_{B}$): s.insert(33); 对于这个insert的调用，set必须先要判断出 $33_{A}$ 是否已经位于其中了，查找哪儿适合插入 $33_{B}$。最终，它总要检查 $33_{B}$是否与 $33_{A}$ 相同。 关联容器对“相同”的定义是等价，因此set测试 $33_{B}$是否等价于 $33_{A}$。 当执行这个测试时，它自然是使用set的比较函数。在这一例子里，是operator\u003c=，因为我们指定set的比较函数为less_equal，而less_equal意思就是operator\u003c=。 可以看看less_equal的源码实现： /// One of the @link comparison_functors comparison functors@endlink. template\u003ctypename _Tp\u003e struct less_equal : public binary_function\u003c_Tp, _Tp, bool\u003e { _GLIBCXX14_CONSTEXPR bool operator()(const _Tp\u0026 __x, const _Tp\u0026 __y) const { return __x \u003c= __y; } // 此处是 \u003c= }; 于是，set将计算这个表达式是否为真: !(33A \u003c= 33B) \u0026\u0026 !(33B \u003c= 33A) // 测试33A和33B是否等价 $33_{A}$ 和 $33_{B}$ 都是33，因此， $33_{A}$\u003c=$33_{B}$ 肯定为真。同样清楚的是，$33_{B}$ \u003c= $33_{A}$。于是上述的表达式简化为: !(true) \u0026\u0026 !(true) 再简化就是 false \u0026\u0026 false 结果当然是false。 也就是说，set得出的结论是 $33_{B}$ 与 $33_{B}$ 不等价，因此不一样，于是它将 $33_{B}$ 插入容器中的旁边。 在技术上而言，这个做法导致未定义的行为，但是通常的结果是set以拥有了两个为33的值的拷贝而告终，也就是说它不再是一个set了。通过使用less_equal作为我们的比较类型，我们破坏了容器！ 测试 template\u003ctypename T\u003e void print(const T t) { cout \u003c\u003c t \u003c\u003c endl; } int main(int argc, char** argv) { set\u003cint, less_equal\u003cint\u003e \u003e snumber; snumber.insert(33); snumber.insert(33); for_each(snumber.begin(), snumber.end(), print\u003cint\u003e); } 结果: 33 33 ","date":"2023-08-11","objectID":"/posts/clause_21/:1:0","tags":["Effective STL"],"title":"Effective STL [21] | 永远让比较函数对相等的值返回false","uri":"/posts/clause_21/"},{"categories":["C++"],"content":"Example string* 条款20描述了该如何写一个比较函数以使得容纳string*指针的容器根据string的值排序，而不是对指针的值排序。那个比较函数是按升序排序的，但现在假设你需要string*指针的容器的降序排序的比较函数。 自然是抓现成的代码来修改了。如果不细心，可能会这么干: struct StringPtrGreater: public binary_function\u003cconst string*, const string*, bool\u003e { // 这代码是有瑕疵的！ bool operator()(const string *ps1, const string *ps2) const { return !(*ps1 \u003c *ps2); // 只是相反了旧的测试；这是不对的！ } }; 这里的想法是通过将比较函数内部结果取反来达到反序的结果。很不幸，取反“\u003c”不会给你（你所期望的）“\u003e”，它给你的是 “\u003e=”。 而你现在知道，因为它将对相等的值返回true，对关联容器来说，它是一个无效的比较函数。 你真正需要的比较类型是这个: struct StringPtrGreater: // 对关联容器来说这是有效的比较类型 public binary_function\u003cconst string*, const string*, bool\u003e { bool operator()(const string *ps1, const string *ps2) const { return *ps2 \u003c *ps1; // 返回*ps2是否大于*ps1（也就是交换操作数的顺序） } }; 要避免掉入这个陷阱，你所要记住的就是比较函数的返回值表明的是在此函数定义的排序方式下，一个值是否大于另一个。 相等的值绝不该一个大于另一个，所以比较函数总应该对相等的值返回false ","date":"2023-08-11","objectID":"/posts/clause_21/:2:0","tags":["Effective STL"],"title":"Effective STL [21] | 永远让比较函数对相等的值返回false","uri":"/posts/clause_21/"},{"categories":["C++"],"content":"Example multiset multiset和multimap那些容器可以容纳复本可能包含副本，如果容器认为两个值相等的对象不等价，它将会把两个都存储进去的，这正是multi系列容器的所要支持的事情。 multiset\u003cint, less_equal\u003cint\u003e \u003e msnum; // 仍然以“\u003c=”排序 msnum.insert(22); // 插入22A msnum.insert(22); // 插入22B for_each(msnum.begin(), msnum.end(), print\u003cint\u003e); 结果: 22 22 s里有两个22的拷贝，因此我们期望如果我们在它上面做一个equal_range，我们将会得到一对指出包含这两个拷贝的范围的迭代器。但那是不可能的。 equal_range，虽然叫这个名字，但不是指示出相等的值的范围，而是等价的值的范围。在这个例子中，s的比较函数说22A和22B是不等价的，所以不可能让它们同时出现在equal_range所指示的范围内。 pair\u003cmultiset\u003cint\u003e::iterator, multiset\u003cint\u003e::iterator\u003e range2; //在 myvector 容器中找到所有的元素 22 range2 = equal_range(msnum.begin(), msnum.end(), 22, less_equal\u003cint\u003e{}); cout \u003c\u003c \"\\nmy multiset：\"; for (auto it = range2.first; it != range2.second; ++it) { cout \u003c\u003c *it \u003c\u003c \" \"; } 结果没有得到期望结果: my multiset: 如果改为less比较: range2 = equal_range(msnum.begin(), msnum.end(), 22, less\u003cint\u003e{}); 结果: my multiset：22 22 除非你的比较函数总是为相等的值返回false，你将会打破所有的标准关联型容器，不管它们是否允许存储复本。 ","date":"2023-08-11","objectID":"/posts/clause_21/:3:0","tags":["Effective STL"],"title":"Effective STL [21] | 永远让比较函数对相等的值返回false","uri":"/posts/clause_21/"},{"categories":["C++"],"content":"总结 从技术上说，用于排序关联容器的比较函数必须在它们所比较的对象上定义一个“严格的弱序化(strict weakordering)”。（传给sort等算法（参见条款31）的比较函数也有同样的限制）。 任何一个定义了严格的弱序化的函数都必须在传入相同的值的两个拷贝时返回false。 ","date":"2023-08-11","objectID":"/posts/clause_21/:4:0","tags":["Effective STL"],"title":"Effective STL [21] | 永远让比较函数对相等的值返回false","uri":"/posts/clause_21/"},{"categories":["C++"],"content":"Example 假定你有一个string*指针的set，你把一些动物的名字插入进set: set\u003cstring*\u003e ssp; ssp.insert(new string(\"Anteater\")); ssp.insert(new string(\"Wombat\")); ssp.insert(new string(\"Lemur\")); ssp.insert(new string(\"Penguin\")); // ssp = “set of string ptrs” 然后你写了下列代码打印set的内容，希望字符串按字母顺序出现。毕竟，确定set保持它们的内容有序。 for (set\u003cstring*\u003e::const_iterator i = ssp.begin();i != ssp.end();++i) { cout \u003c\u003c *i \u003c\u003c endl; } 你期望看到 Anteater Wombat Lemur Penguin 实际运行结果: 0x5566364b5eb0 0x5566364b5f10 0x5566364b5f70 0x5566364b5fd0 结果是4个十六进制的数，代表指针的值。 因为set容纳指针，*i不是一个string，是一个string的指针。 如果你已经改为调用copy算法， copy(ssp.begin(), ssp.end(), ostream_iterator\u003cstring\u003e(cout, \"\\n\"));// 把ssp中的字符串拷贝到cout（但这不能编译） 这个copy的调用将不能编译，因为ostream_iterator需要知道被打印的对象的类型，所以当你告诉它是一个string时（通过作为模板参数传递），编译器检测到那和ssp中储存的对象类型(是string*)之间不匹配，它们会拒绝编译代码。 把显式循环中的*i改为**i，你可能可以得到你想要的输出，但也可能不。动物名字将被打印，但它们按字母顺序出现的机会只是24份之1。ssp保持它的内容有序，但是它容纳的是指针，所以它以指针的值排序，而不以string值。对于四个指针值可能有24种排列（），所以指针被储存时有24种可能的顺序。因此你看见字符串按字母排序有24份之1的几率。 或者打印 *string的char*数组 for (set\u003cstring*\u003e::const_iterator i = ssp.begin(); i != ssp.end(); ++i) { cout \u003c\u003c (*i)-\u003ec_str() \u003c\u003c endl; } ","date":"2023-08-11","objectID":"/posts/clause_20/:1:0","tags":["Effective STL"],"title":"Effective STL [20] | 为指针的关联容器指定比较类型","uri":"/posts/clause_20/"},{"categories":["C++"],"content":"Solution 当我们写下set\u003cstring*\u003e ssp;，其实省略了一个默认参数set\u003cstring*, less\u003cstring*\u003e \u003e ssp;，实际上还有个默认参数: set\u003cstring*, less\u003cstring*\u003e, allocator\u003cstring*\u003e \u003e ssp; ","date":"2023-08-11","objectID":"/posts/clause_20/:2:0","tags":["Effective STL"],"title":"Effective STL [20] | 为指针的关联容器指定比较类型","uri":"/posts/clause_20/"},{"categories":["C++"],"content":"自定义仿函数 如果想要string*指针以字符串值确定顺序被储存在set中，不能使用默认比较仿函数类less\u003cstring*\u003e。 必须改为写自己的比较仿函数类，它的对象带有string*指针并按照指向的字符串值来进行排序: struct StringPtrLess: public binary_function\u003cconst string*, const string*, bool\u003e { bool operator()(const string *ps1, const string *ps2) const { return *ps1 \u003c *ps2; } }; 然后可以使用StringPtrLess作为ssp的比较类型: typedef set\u003cstring*, StringPtrLess\u003e StringPtrSet; StringPtrSet ssp; // 建立字符串的集合， // 按照StringPtrLess定义的顺序排序 ... // 和前面一样插入 // 同样四个字符串 现在循环最后将做想要它做的（也就是前面你使用*i代替**i所修正的问题）: for (StringPtrSet::const_iterator i = ssp.begin(); i != ssp.end(); ++i) { cout \u003c\u003c **i \u003c\u003c endl; } 指针之前对它们解引用的函数，然后和for_each联用那个函数: void print(const string *ps) { cout \u003c\u003c *ps \u003c\u003c endl; } for_each(ssp.begin(), ssp.end(), print);// 在ssp中的每个元素上调用print 或者你想象并写出了泛型的解引用仿函数类，然后让它和transform与ostream_iterator连用: // 当本类型的仿函数被传入一个T*时，它们返回一个const T\u0026 struct Dereference { template \u003ctypename T\u003e const T\u0026 operator()(const T *ptr) const { return *ptr; } }; // 通过解引用“转换” ssp中的每个元素，把结果写入cout transform(ssp.begin(), ssp.end(), ostream_iterator\u003cstring\u003e(cout, \"\\n\"), Dereference()); 要点是无论何时你建立一个指针的标准关联容器，你必须记住容器会以指针的值排序。这基本上不是你想要的，所以你几乎总是需要建立自己的仿函数类作为比较类型。 比较类型 vs 比较函数 注意到这里写的是“比较类型”。 你可能奇怪为什么必须特意创造一个仿函数类而不是简单地为set写一个比较函数: bool stringPtrLess(const string* ps1, const string* ps2) { // 将成为用于按字符串值排序的string*指针的比较函数 return *ps1 \u003c *ps2; } set\u003cstring*, stringPtrLess\u003e ssp;// 假设使用stringPtrLess 作为ssp的比较函数； // 这不能编译 这里的问题是每个set模板的第三个参数都是一种类型，而stringPtrLess不是一种类型，它是一个函数。这就是为什么尝试使用stringPtrLess作为set的比较函数不能编译的原因，set不要一个函数，它要的是能在内部用实例化建立函数的一种类型。 无论何时你建立指针的关联容器，注意你也得指定容器的比较类型。 大多数时候，你的比较类型只是解引用指针并比较所指向的对象（就像上面的StringPtrLess做的那样）。 鉴于这种情况，你手头最好也能有一个用于那种比较的仿函数模板。像这样: struct DereferenceLess { template \u003ctypename PtrType\u003e bool operator()(PtrType pT1, PtrType pT2) const { // 参数是值传递的因为我们希望它们是（或行为像）指针 return *pT1 \u003c *pT2; } }; 这样的模板消除了写像StringPtrLess那样的类的需要，因为我们可以改为使用DereferenceLess: set\u003cstring*, DereferenceLess\u003e ssp; // 行为就像 set\u003cstring*, StringPtrLess\u003e ","date":"2023-08-11","objectID":"/posts/clause_20/:3:0","tags":["Effective STL"],"title":"Effective STL [20] | 为指针的关联容器指定比较类型","uri":"/posts/clause_20/"},{"categories":["C++"],"content":"总结 本条款是关于指针的关联容器，但它也可以应用于表现为指针的对象的容器，例如，智能指针和迭代器。 如果你有一个智能指针或迭代器的关联容器，那也得为它指定比较类型。幸运的是，指针的这个解决方案也可以用于类似指针的对象。正如DereferenceLess适合作为T*的关联容器的比较类型一样，它也 可以作为T对象的迭代器和智能指针容器的比较类型。 实际上，这24种排列很可能不是平等的，所以“24份之1”的陈述有点使人误解。确实，有24个不同的顺序，而且你可能得到它们中的任何一个。 ","date":"2023-08-11","objectID":"/posts/clause_20/:4:0","tags":["Effective STL"],"title":"Effective STL [20] | 为指针的关联容器指定比较类型","uri":"/posts/clause_20/"},{"categories":["C++"],"content":"比较对象 STL充满了比较对象是否有同样的值。比如，当你用find来定位区间中第一个有特定值的对象的位置，find必须可以比较两个对象，看看一个的值是否与另一个相等。同样，当你尝试向set中插入一个新元素时，set::insert必须可以判断那个元素的值是否已经在set中了。 find算法和set的insert成员函数是很多必须判断两个值是否相同的函数的代表。但它们实现方式不同，find对“相同”的定义是相等，基于operator==。set::insert对“相同”的定义是等价，通常基于operator\u003c。因为有定义不同，所以有可能一个定义规定了两个对象有相同的值而另一个定义判定它们没有。结果，如果你想有效使用STL，那么你必须明白相等和等价的区别。 相等 操作上来说，相等的概念是基于operator的。如果表达式“x == y”返回true，x和y有相等的值，否则它们没有。 x和y有相等的值并不意味着所有它们的成员有相等的值。比如，我们可能有一个内部记录了最后一次访问的Widget类。 class Widget { public: ... private: TimeStamp lastAccessed; ... }; 我们可以有一个用于Widget的忽略这个域的operator: bool operator(const Widget\u0026 lhs, const Widget\u0026 rhs) { // 忽略lastAccessed域的代码 } 在这里，两个Widget即使它们的lastAccessed域不同也可以有相等的值。 一般而言，相等意味着两个变量的值相同，但是如果比较2个对象，因为比较函数可以自定义，因此有时候对象的某些成员变量值不同也会设定2个对象相等。 等价 ==等价是基于在一个有序区间中对象值的相对位置==。 等价一般在每种标准关联容器（比如，set、multiset、map和multimap）的一部分——排序顺序方面有意义。注意这里的应用场景是==排序==。 两个对象x和y如果在关联容器c的排序顺序中没有哪个排在另一个之前，那么它们关于c使用的排序顺序有等价的值。 举一个例子，一个set s。两个Widget w1和w2，如果在s的排序顺序中没有哪个在另一个之前，那么关于s它们有等价的值。set的默认比较函数是less，而默认的less简单地对Widget调用operator\u003c，所以w1和w2关于operator\u003c有等价的值如果下面表达式为真： !(w1 \u003c w2) // w1 \u003c w2时它非真 \u0026\u0026 // 而且 !(w2\u003cw1) // w2 \u003c w1时它非真 这个有意义：两个值如果没有哪个在另一个之前（关于某个排序标准），那么它们等价（按照那个标准）。在一般情况下，用于关联容器的比较函数不是operator\u003c或甚至less，它是用户定义的判断式。每个标准关联容器通过它的key_comp成员函数来访问排序判断式，所以如果下式求值为真，两个对象x和y关于一个关联容器c的排序标准有等价的值： !c.key_comp()(x, y) \u0026\u0026 !c.key_comp()(y, x) // 在c的排序顺序中 // 如果x在y之前它非真，同时在c的排序顺序中,如果y在x之前它非真 要完全领会==相等==和==等价==的含义，考虑一个忽略大小写的set\u003cstring\u003e，也就是set的比较函数忽略字符串中字符大小写的set\u003cstring\u003e。这样的比较函数会认为“STL”和“stL”是等价的。条款35演示了怎么实现一个函数，ciStringCompare，它进行了忽略大小写比较，但set要一个比较函数的类型，不是真的函数。要填平这个鸿沟，我们写一个operator()调用了ciStringCompare的仿函数类: struct CIStringCompare: // 用于忽略大小写 public // 字符串比较的类； binary_function\u003cstring, string, bool\u003e { bool operator()(const string\u0026 lhs, const string\u0026 rhs) const { return ciStringCompare(lhs, rhs); // 关于ciStringCompare } } 具体实现为: int ciCharCompare(char c1, char c2) // 忽略大小写比较字符 { // c1和c2，如果c1 \u003c c2返回-1， // 如果c1==c2返回0，如果c1 \u003e c2返回1 int Ic1 = tolower(static_cast\u003cunsigned char\u003e(c1));// 转成小写 int Ic2 = tolower(static_cast\u003cunsigned char\u003e(c2)); if (Ic1 \u003c Ic2) return -1; if (lc1 \u003e Ic2) return 1; return 0; } 给定CIStringCompare，要建立一个忽略大小写的set就很简单了: set\u003cstring, CIStringCompare\u003e ciss; // ciss = “case-insensitive // string set” 如果我们向这个set中插入“Persephone”和“persephone”，只有第一个字符串加入了，因为第二个等价于第一个： ciss.insert(\"Persephone\"); // 一个新元素添加到set中 ciss.insert(\"persephone\"); // 没有新元素添加到set中 如果我们现在使用set的find成员函数搜索字符串“persephone”，搜索会成功， if (ciss.find(\"persephone\") != ciss.end())... // 这个测试会成功 但如果我们用非成员的find算法，搜索会失败： if (find(ciss.begin(), ciss.end(), \"persephone\") != ciss.end())... // 这个测试会失败 那是因为“persephone”等价于“Persephone”（关于比较仿函数CIStringCompare），但不等于它（因为string(“persephone”) != string(“Persephone”)）。你可能会奇怪为什么标准关联容器是基于等价而不是相等。毕竟，大多数程序员对相等有感觉而缺乏等价的感觉。 标准关联容器保持有序，所以每个容器必须有一个定义了怎么保持东西有序的比较函数（默认是less）。等价是根据这个比较函数定义的，所以标准关联容器的用户只需要为他们要使用的任意容器指定一个比较函数（决定排序顺序的那个）。 如果关联容器使用相等来决定两个对象是否有相同的值，那么每个关联容器就需要，除了用于排序的比较函数，还需要一个用于判断两个值是否相等的比较函数。（默认的，这个比较函数大概应该是equal_to，但有趣的是equal_to从没有在STL中用做默认比较函数。当在STL中需要相等时，习惯是简单地直接调用operator==。比如，这是非成员find算法所作的。） 说白了，就是等价是为容器排序服务的，如果容器想要插入多个转化为小写后相等的单词，容器会判定这些单词等价，虽然它们本身不相等，这样就能够很好地保持容器内单词的唯一性和单词的有序性。否则通过查找或插入该单词的时候，容器内部就会发生歧义，造成不符合使用者逻辑。 让我们假设我们有一个类似set的STL容器叫做set2CF，“set with two comparison functions”。第一个比较函数用来决定set的排序顺序，第二个用来决定是否两个对象有相同的值。 现在考虑这set2CF： set2CF\u003cstring, CIStringCompare, equal_to\u003cstring\u003e \u003e s; 在这里，s内部排序它的字符串时不考虑大小写，等价标准直觉上是这样：如果两个字符串中一个等于另一个，那么它们有相同的值。让我们向s中插入哈迪斯强娶的新娘（Persephone）的两个拼写: s.insert(\"Persephone\"); s.insert(\"persephone\"); 如果我们说\"Persephone\" != \"persephone\"然后两个都插入s，它们应该是什么顺序？ 记住排序函数不能分别告诉它们。我们可以以任意顺序插入，因此放弃以确定的顺序遍历set内容的能力吗？（不能以确定的顺序遍历关联容器元素已经折磨着multiset和multimap了，因为标准没有规定等价的值（对于multiset）或键（对于multimap）的相对顺序。）或者我们坚持s的内容的一个确定顺序并忽略第二次插入的尝试（“persephone”的那个）? 如果我们那么做，这里会发生什么？ if (s.find(\"persephone\") != s.end())... // 这个测试成功或失败？ 大概**find使用了等价检查**，但如果我们为了维护s中元素的一个确定顺序而忽略了第二个insert的调用，这个find会失败，即使“persephone”的插入由于它是一个重复的值的原则而被忽略！ ","date":"2023-08-10","objectID":"/posts/clause_19/:1:0","tags":["Effective STL"],"title":"Effective STL [19] | 了解相等和等价的区别","uri":"/posts/clause_19/"},{"categories":["C++"],"content":"总结 通过只使用一个比较函数并使用等价作为两个值“相等”的意义的仲裁者，标准关联容器避开了很多会由允许两个比较函数而引发的困难。 一开始行为可能看起来有些奇怪（特别是当你发现成员和非成员find可能返回不同结果），但最后，它避免了会由在标准关联容器中混用相等和等价造成的混乱。 ","date":"2023-08-10","objectID":"/posts/clause_19/:2:0","tags":["Effective STL"],"title":"Effective STL [19] | 了解相等和等价的区别","uri":"/posts/clause_19/"},{"categories":["C++"],"content":"vector 问题 作为一个STL容器，vector确实只有1个问题: 它不是一个STL容器； 它并不容纳bool。 ","date":"2023-08-09","objectID":"/posts/clause_18/:1:0","tags":["Effective STL"],"title":"Effective STL [18] | 避免使用vector\u003cbool\u003e","uri":"/posts/clause_18/"},{"categories":["C++"],"content":"剖析 一个东西要成为STL容器就必须满足所有在C++标准23.1节中列出的容器必要条件。 如果c是一个T类型对象的容器，且c支持operator[]，那么以下代码必须能够编译: T *p = \u0026c[0]; // 无论operator[]返回什么，都可以用这个地址初始化一个T* 换句话说，如果你使用operator[]来得到Container中的一个T对象，你可以通过取它的地址而获得指向那个对象的指针。(假设T没有倔强地重载一些操作符。) 然而如果vector是一个容器，这段代码必须能够编译： vector\u003cbool\u003e v; bool *pb = \u0026v[0]; // 用vector\u003cbool\u003e::operator[]返回的东西的地址初始化一个bool* 但它不能编译。 test_vector.cpp:154:19: error: taking address of rvalue [-fpermissive] 154 | bool *pb = \u0026r2[0]; | ^ test_vector.cpp:154:14: error: cannot convert ‘std::vector\u003cbool\u003e::reference*’ {aka ‘std::_Bit_reference*’} to ‘bool*’ in initialization 154 | bool *pb = \u0026r2[0]; | ^~~~~~ | | | std::vector\u003cbool\u003e::reference* {aka std::_Bit_reference*} 因为vector\u003cbool\u003e是一个伪容器，并不保存真正的bool，而是打包bool以节省空间。在一个典型的实现中，每个保存在“vector”中的“bool”占用一个单独的比特，而一个8比特的字节将容纳8个“bool”。 在内部，vector\u003cbool\u003e使用了与位域（bitfield）等价的思想来表示它假装容纳的bool。 位域也只表现为两种可能的值，但真的bool和化装成bool的位域之间有一个重要的不同：你可以创建指向真的bool的指针，但却禁止有指向单个比特的指针。 ","date":"2023-08-09","objectID":"/posts/clause_18/:2:0","tags":["Effective STL"],"title":"Effective STL [18] | 避免使用vector\u003cbool\u003e","uri":"/posts/clause_18/"},{"categories":["C++"],"content":"实际实现 vector::operator[]返回一个对象，其行为类似于比特的引用，也称为代理对象。 template\u003ctypename _Alloc\u003e class vector\u003cbool, _Alloc\u003e : protected _Bvector_base\u003c_Alloc\u003e { typedef _Bvector_base\u003c_Alloc\u003e _Base; typedef typename _Base::_Bit_pointer _Bit_pointer; typedef typename _Base::_Bit_alloc_traits _Bit_alloc_traits; #if __cplusplus \u003e= 201103L friend struct std::hash\u003cvector\u003e; #endif public: typedef bool value_type; typedef size_t size_type; typedef ptrdiff_t difference_type; typedef _Bit_reference reference; typedef bool const_reference; typedef _Bit_reference* pointer; typedef const bool* const_pointer; typedef _Bit_iterator iterator; typedef _Bit_const_iterator const_iterator; typedef std::reverse_iterator\u003cconst_iterator\u003e const_reverse_iterator; typedef std::reverse_iterator\u003citerator\u003e reverse_iterator; typedef _Alloc allocator_type; allocator_type get_allocator() const { return _Base::get_allocator(); } protected: using _Base::_M_allocate; using _Base::_M_deallocate; using _Base::_S_nword; using _Base::_M_get_Bit_allocator; reference operator[](size_type __n) { return *iterator(this-\u003e_M_impl._M_start._M_p + __n / int(_S_word_bit), __n % int(_S_word_bit)); } const_reference operator[](size_type __n) const { return *const_iterator(this-\u003e_M_impl._M_start._M_p + __n / int(_S_word_bit), __n % int(_S_word_bit)); } } 上述代码不能编译的原因很明显：bool *pb = \u0026v[0]右边的表达式是vector\u003cbool\u003e::reference*类型，不是bool*。 ","date":"2023-08-09","objectID":"/posts/clause_18/:3:0","tags":["Effective STL"],"title":"Effective STL [18] | 避免使用vector\u003cbool\u003e","uri":"/posts/clause_18/"},{"categories":["C++"],"content":"替代品 ","date":"2023-08-09","objectID":"/posts/clause_18/:4:0","tags":["Effective STL"],"title":"Effective STL [18] | 避免使用vector\u003cbool\u003e","uri":"/posts/clause_18/"},{"categories":["C++"],"content":"1. deque deque提供了几乎所有vector所提供的（唯一值得注意的是reserve和capacity），而deque\u003cbool\u003e是一个STL容器，它保存真正的bool值。 deque内部内存不是连续的。所以不能传递deque\u003cbool\u003e中的数据给一个希望得到bool数组的C API。 条款16中用于vector的技术不能在vector\u003cbool\u003e上通过编译，因为它们依赖于能够取得指向容器中包含的元素类型的指针。 ","date":"2023-08-09","objectID":"/posts/clause_18/:4:1","tags":["Effective STL"],"title":"Effective STL [18] | 避免使用vector\u003cbool\u003e","uri":"/posts/clause_18/"},{"categories":["C++"],"content":"2. bitset bitset不是一个STL容器，但它是C++标准库的一部分。与STL容器不同，它的大小（元素数量）在编译期固定，因此它不支持插入和删除元素。 因为它不是一个STL容器，它也不支持iterator。但就像vector\u003cbool\u003e，它使用一个压缩的表示法，使得它包含的每个值只占用一比特。 它提供vector\u003cbool\u003e特有的flip成员函数，还有一系列其他操作位集(collection of bits)所特有的成员函数。 ","date":"2023-08-09","objectID":"/posts/clause_18/:4:2","tags":["Effective STL"],"title":"Effective STL [18] | 避免使用vector\u003cbool\u003e","uri":"/posts/clause_18/"},{"categories":["C++"],"content":"总结 vector\u003cbool\u003e不满足STL容器的必要条件，你最好不要使用它； 而deque\u003cbool\u003e和bitset是基本能满足你对vector\u003cbool\u003e提供的性能的需要的替代数据结构。 ","date":"2023-08-09","objectID":"/posts/clause_18/:5:0","tags":["Effective STL"],"title":"Effective STL [18] | 避免使用vector\u003cbool\u003e","uri":"/posts/clause_18/"},{"categories":["C++"],"content":" 注意: 这里的容量指的是capacity 假如有一个海选，需要从申请者中挑选一些人进入到下一轮比赛当中，我们可能会建立一个vector用来存储申请者： class Contestant {...}; vector\u003cContestant\u003e contestants; vector会很快获得很多元素，你可能会将能够进入到下一轮的申请者放到 vector 的前端（可能通过 partial_sort或partition），如果没有参与到下一轮的申请者就会从vector 中删除（典型的方法就是调用 erase 的区间形式，具体见条款5）。 这样很好地减少了 vector 的大小，但是没有减少它的容量。 当然可以通过resize方法去改变，但是如果我不知道大概要多少，我只知道有一些符合我的要求，如果直接用resize可能大了很多，或者抛弃了原本符合要求的元素。所以最好有一种shrink_to_fit的方式。 vector\u003cContestant\u003e contestants; vector\u003cContestant\u003e(contestants).swap(contestants); 具体工作原理： 表达式vector\u003cContestant\u003e(contestants)建立一个临时vector，它是contestants的一份拷贝：vector的拷贝构造函数做了这个工作。vector的拷贝构造函数只分配拷贝的元素需要的内存，就是说contestants真实包含多少元素，就分配多少内存空间，按照size()的个数，而不是capicatiy个数，所以这个临时vector没有多余的容量。 让临时vector和contestants交换数据，这时contestants只有临时变量的修整过的容量(size)，而这个临时变量则持有了曾经在contestants中的发胀的容量(capacity)。在这里（这个语句结尾），临时vector被销毁，因此释放了以前contestants使用的内存。 收缩到合适。 完成收缩内存的同时，也拷贝了实际size()个内存，也有性能消耗。 TEST int main() { std::vector\u003cint\u003e r1(100, 1); // r1 包含100个1，即100个申请者 std::cout \u003c\u003c \"r1 size: \" \u003c\u003c r1.size() \u003c\u003c \" capacity: \" \u003c\u003c r1.capacity() \u003c\u003c std::endl; r1.resize(50); // 只保留前50名申请者进入下一轮 std::cout \u003c\u003c \"r1 size: \" \u003c\u003c r1.size() \u003c\u003c \" capacity: \" \u003c\u003c r1.capacity() \u003c\u003c std::endl; std::vector\u003cint\u003e(r1).swap(r1); // shrink to fit std::cout \u003c\u003c \"r1 size: \" \u003c\u003c r1.size() \u003c\u003c \" capacity: \" \u003c\u003c r1.capacity() \u003c\u003c std::endl; return 0; } 结果: r1 size: 100 capacity: 100 r1 size: 50 capacity: 100 r1 size: 50 capacity: 50 r1 size: 0 capacity: 0 string也同样适用： vector\u003cContestant\u003e v; string s; ... vector\u003cContest\u003e().swap(v); //清楚v并把它的容量变为最小 string().swap(s); //清楚s并把它的容量变为最小 另外，在swap的时候，不仅仅容器内容被交换，其迭代器、指针和引用也被交换(string除外)。因此，在发生交换后，原来的迭代器、指针和引用依然有效，并指向同样的元素——但这些元素已经在另外一个容器中。 ","date":"2023-08-08","objectID":"/posts/clause_17/:0:0","tags":["Effective STL"],"title":"Effective STL [17] | 使用“交换技巧”来修整过剩容量(仅适用于vector和string)","uri":"/posts/clause_17/"},{"categories":["C++"],"content":"清空容器并减少容量到最小 交换技巧的变体可以用于清除容器和减少它的容量到你的实现提供的最小值。 可以简单地和一个默认构造的临时vector或string做个交换： vector\u003cContestant\u003e v; string s; ... // 使用v和s vector\u003cContestant\u003e().swap(v); // 清除v而且最小化它的容量 string().swap(s); // 清除s而且最小化它的容量 测试代码： std::vector\u003cint\u003e r1(100, 1); // r1 包含100个1，即100个申请者 std::cout \u003c\u003c \"r1 size: \" \u003c\u003c r1.size() \u003c\u003c \" capacity: \" \u003c\u003c r1.capacity() \u003c\u003c std::endl; std::vector\u003cint\u003e().swap(r1); // 清空 r1 std::cout \u003c\u003c \"r1 size: \" \u003c\u003c r1.size() \u003c\u003c \" capacity: \" \u003c\u003c r1.capacity() \u003c\u003c std::endl; 结果: r1 size: 100 capacity: 100 r1 size: 0 capacity: 0 ref: [1]. https://blog.csdn.net/u011058765/article/details/51205757?spm=1001.2101.3001.6650.2\u0026utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-2-51205757-blog-18826.235%5Ev38%5Epc_relevant_anti_t3\u0026depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-2-51205757-blog-18826.235%5Ev38%5Epc_relevant_anti_t3\u0026utm_relevant_index=3 ","date":"2023-08-08","objectID":"/posts/clause_17/:1:0","tags":["Effective STL"],"title":"Effective STL [17] | 使用“交换技巧”来修整过剩容量(仅适用于vector和string)","uri":"/posts/clause_17/"},{"categories":["C++"],"content":"string 和 vector 传递给C API ","date":"2023-08-07","objectID":"/posts/clause_16/:1:0","tags":["Effective STL"],"title":"Effective STL [16] | 如何将vector和string的数据传给遗留的API","uri":"/posts/clause_16/"},{"categories":["C++"],"content":"vector传递指针 C风格API接受的是数组和char*指针，这样的API还会存在很长时间，如果有1个vector对象randy， 则使用\u0026v[0]就可以得到一个指向randy中数据的指针。对于string对象sesame，则传递sesame.c_str()即可。 表达式randy[0]生产一个指向vector中第一个元素的引用，所以，\u0026randy[0]是指向那个首元素的指针。 vector中的元素被C++标准限定为存储在连续内存中，就像是一个数组。 所以我们可能会这么传递 // C API void doSomething(const int* pInts, size_t numInts); // 调用 doSomething(\u0026randy[0], randy.size()); 唯一的问题就是，如果randy是空的，randysize()是0，而\u0026randy[0]试图产生一个指向根本就不存在的东西的指针。 可以提前判断一下randy的大小： if (!randy.empty()) { doSomething(\u0026randy[0], randy.size()); } randy.begin()代替\u0026randy[0]? 对于vector，其迭代器实际上是指针。 begin的返回类型是iterator，而不是一个指针，当你需要一个指向vector内部数据的指针时绝不该使用begin。如果你基于某些原因决定键入randy.begin()，就应该键入\u0026*randy.begin()，因为这将会产生和\u0026v[0]相同的指针。 ","date":"2023-08-07","objectID":"/posts/clause_16/:1:1","tags":["Effective STL"],"title":"Effective STL [16] | 如何将vector和string的数据传给遗留的API","uri":"/posts/clause_16/"},{"categories":["C++"],"content":"string 传递指针 类似从vector上获取指向内部数据的指针的方法，对string不是可靠的: string中的数据并没有保证被存储在独立的一块连续内存中 string的内部表示形式并没承诺以一个null字符结束。这解释了string的成员函数c_str存在的原因 即使是字符串的长度为0，c_str将返回一个指向null字符的指针。 在两种形式下，指针都被传递为指向const的指针。vector和string的数据只能传给只读取而不修改它的API。 如果你将randy传给一个修改其元素的C风格API的话，典型情况都是没问题，但被调用的函数绝不能试图改变vector中元素的个数。否则，randy的内部状态将会变得不一致，v.size()将会得到一个不正确的结果。 把一个vector传递给需要修改vector数据的API，一定要确保这些额外限制继续被满足，比如是否需要保持原来vector中元素的顺序。 ","date":"2023-08-07","objectID":"/posts/clause_16/:1:2","tags":["Effective STL"],"title":"Effective STL [16] | 如何将vector和string的数据传给遗留的API","uri":"/posts/clause_16/"},{"categories":["C++"],"content":"C风格API返回的元素初始化STL容器 ","date":"2023-08-07","objectID":"/posts/clause_16/:2:0","tags":["Effective STL"],"title":"Effective STL [16] | 如何将vector和string的数据传给遗留的API","uri":"/posts/clause_16/"},{"categories":["C++"],"content":"初始化vector 利用vector和数组潜在的内存分布兼容性将存储vecotr的元素的空间传给API函数： // C API：此函数需要一个指向数组的指针，数组最多有arraySize个double // 而且会对数组写入数据。它返回写入的double数，不会大于arraySize size_t fillArray(double *pArray, size_t arraySize); vector\u003cdouble\u003e vd(maxNumDoubles); // 建立一个vector，它的大小是maxNumDoubles vd.resize(fillArray(\u0026vd[0], vd.size())); // 让fillArray把数据写入vd，然后调整vd的大小为fillArray写入的元素个数 这个技巧只能工作于vector，因为只有vector承诺了与数组具有相同的潜在内存分布。 ","date":"2023-08-07","objectID":"/posts/clause_16/:2:1","tags":["Effective STL"],"title":"Effective STL [16] | 如何将vector和string的数据传给遗留的API","uri":"/posts/clause_16/"},{"categories":["C++"],"content":"初始化string 只要让API将数据放入一个vector\u003cchar\u003e，然后从vector中将数据拷到string： // C API：此函数需要一个指向数组的指针，数组最多有arraySize个char // 而且会对数组写入数据。它返回写入的char数，不会大于arraySize size_t fillString(char *pArray, size_t arraySize); vector\u003cchar\u003e vc(maxNumChars); // 建立一个vector，它的大小是maxNumChars size_t charsWritten = fillString(\u0026vc[0], vc.size()); // 让fillString把数据写入vc string s(vc.begin(), vc.begin() + charsWritten); // 从vc通过范围构造函数拷贝数据到s ","date":"2023-08-07","objectID":"/posts/clause_16/:2:2","tags":["Effective STL"],"title":"Effective STL [16] | 如何将vector和string的数据传给遗留的API","uri":"/posts/clause_16/"},{"categories":["C++"],"content":"初始化其他STL容器 通用方法：C风格API把数据放入一个vector，然后拷到实际想要的STL容器 size_t fillArray(double *pArray, size_t arraySize); // 同上 vector\u003cdouble\u003e vd(maxNumDoubles); // 一样同上 vd.resize(fillArray(\u0026vd[0], vd.size())); deque\u003cdouble\u003e d(vd.begin(), vd.end()); // 拷贝数据到deque list\u003cdouble\u003e l(vd.begin(), vd.end()); // 拷贝数据到list set\u003cdouble\u003e s(vd.begin(), vd.end()); // 拷贝数据到set ","date":"2023-08-07","objectID":"/posts/clause_16/:2:3","tags":["Effective STL"],"title":"Effective STL [16] | 如何将vector和string的数据传给遗留的API","uri":"/posts/clause_16/"},{"categories":["C++"],"content":"STL容器传递给C API STL容器将它们的数据传给C风格API，只要将容器的每个数据拷到vector，然后将vector传给API: void doSomething(const int*pints, size_t numInts); // C API (同上) set\u003cint\u003e intSet; // 保存要传递给API数据的set ... vector\u003cint\u003e v(intSet.begin(), intSet.end()); // 拷贝set数据到vector if (!v.empty()) doSomething(\u0026v[0], v.size()); // 传递数据到API 如果在编译期就知道容器的大小，可以将数据拷进一个数组，然后将数组传给C风格的API，否则不得不分配动态数组。 ","date":"2023-08-07","objectID":"/posts/clause_16/:2:4","tags":["Effective STL"],"title":"Effective STL [16] | 如何将vector和string的数据传给遗留的API","uri":"/posts/clause_16/"},{"categories":["C++"],"content":"sizeof(string)的值 如果想知道sizeof(string)的值是多少，答案不一定。 string和char*指针一样大的实现很常见，也很容易找到string是char*7 倍大小的string实现。 所以得了解一下string的实现 ","date":"2023-08-04","objectID":"/posts/clause_15/:1:0","tags":["Effective"],"title":"Effective STL [15] | 小心string实现的多样性","uri":"/posts/clause_15/"},{"categories":["C++"],"content":"string的实现 基本实现 字符串的大小，也就是包含的字符的数目。 容纳字符串字符的内存容量。 字符串的值，也就是，构成这个字符串的字符。 可能实现 配置器的拷贝 依赖引用计数的string实现s 包含这个值的引用计数 ","date":"2023-08-04","objectID":"/posts/clause_15/:2:0","tags":["Effective"],"title":"Effective STL [15] | 小心string实现的多样性","uri":"/posts/clause_15/"},{"categories":["C++"],"content":"4种不同的string实现数据结构 以下是原作者看到的4个源码的string的实现 A 每个string对象包含一个配置器的拷贝，字符串的大小(size)，容量(capacity)，一个指向包含引用计数（“RefCnt”）和字符串值的动态分配的缓冲区的指针。 在这个实现中，一个使用默认配置器的字符串对象是指针大小的4倍。对于一个自定义的配置器，string对象会随配置器对象的增大而变大： B B的string对象和指针一样大，因为在结构体中只包含一个指针。再次，这里假设使用默认配置器。正如实现A，如果使用自定义配置器，这个string对象的大小会增加大约配置器对象的大小。 在这个实现中，使用默认配置器不占用空间，这归功于这里用了一个在实现A中没有的使用优化。 B的string指向的对象包含字符串的大小、容量和引用计数，以及容纳字符串值的动态分配缓冲区的指针及\"其他\"。“其他”指对象包含在多线程系统中与并发控制有关的一些附加数据。 在实现B中，用于并发控制的数据是一个指针大小的6倍。 C C的string对象总是等于指针的大小，但是这个指针指向一个包含所有与string相关的东西的动态分配缓冲器：大小、容量、引用计数和值。没有每物体配置器（per-object allocator）的支持。缓冲区也容纳一些关于值可共享性的数据，标记为“X”。 D D的string对象是一个指针大小的7倍（仍然假设使用了默认配置器）。这个实现没有使用引用计数，但每个string包含了一个足以表现最多15个字符的字符串值的内部缓冲区。 因此小的字符串可以被整个保存在string对象中，一个有时被称为“小字符串优化”的特性。 当一个string的容量超过15时，缓冲器的第一部分被用作指向动态分配内存的一个指针，而字符串的值存放在那块内存中： g++ 9.4.0中的实现 template\u003ctypename _CharT, typename _Traits, typename _Alloc\u003e class basic_string { typedef typename __gnu_cxx::__alloc_traits\u003c_Alloc\u003e::template rebind\u003c_CharT\u003e::other _Char_alloc_type; typedef __gnu_cxx::__alloc_traits\u003c_Char_alloc_type\u003e _Alloc_traits; // Types: public: typedef _Traits traits_type; typedef typename _Traits::char_type value_type; typedef _Char_alloc_type allocator_type; typedef typename _Alloc_traits::size_type size_type; typedef typename _Alloc_traits::difference_type difference_type; typedef typename _Alloc_traits::reference reference; typedef typename _Alloc_traits::const_reference const_reference; typedef typename _Alloc_traits::pointer pointer; typedef typename _Alloc_traits::const_pointer const_pointer; typedef __gnu_cxx::__normal_iterator\u003cpointer, basic_string\u003e iterator; typedef __gnu_cxx::__normal_iterator\u003cconst_pointer, basic_string\u003e const_iterator; typedef std::reverse_iterator\u003cconst_iterator\u003e const_reverse_iterator; typedef std::reverse_iterator\u003citerator\u003e reverse_iterator; /// Value returned by various member functions when they fail. static const size_type npos = static_cast\u003csize_type\u003e(-1); } sizeof(string) 举例： string s(\"Randy\"); // 5个字符 实现A有32个字符的最小分配大小，所以虽然s的大小是5，在实现A下容量是31。（第32个字符大概被保留作尾部的null，因此可以容易地实现c_str成员函数。） 实现C最小量16，而且没有为尾部null保留空间。所以在实现C下，s的容量是16。 实现D的最小缓冲区大小也是16，包括尾部null的空间。当然，在这里区别出实现D是因为容量小于16的字符串使用的内存包含在本身字符串对象中。 实现B没有最小分配，在实现B下，s的容量是7。 动态分配 在实现D下将会没有动态分配，在实现A和C 1次，而在实现B 2次（一次是string对象指向的对象，一次是那个对象指向的字符缓冲区）。 如果关心动态分配和回收内存的次数，或如果关心经常伴随这样分配的内存开销，你可能想要避开实现B。 另一方面， 实现B的数据结构包括了对多线程系统并发控制的特殊支持的事实意味着它比实现A或C更能满足你的需要，尽管动态分配次数较多。 实现D不需要对多线程的特殊支持，因为它不使用引用计数。 在基于引用计数的设计中，字符串对象之外的每个东西都可以被多个字符串共享（如果它们有相同的值），所以我们可以从图中观察到的其他东西是实现A比B或C提供更少的共享性。 特别是，实现B和C能共享一个字符串的大小和容量，因此潜在地减少了每物体分摊的的储存数据的开销。 有趣的是，实现C不能支持每对象配置器的事实意味着它是唯一可以共享配置器的实现：所有字符串必须使用同一个！ 实现D在字符串对象间没有共享数据。 ","date":"2023-08-04","objectID":"/posts/clause_15/:3:0","tags":["Effective"],"title":"Effective STL [15] | 小心string实现的多样性","uri":"/posts/clause_15/"},{"categories":["C++"],"content":"总结 不同的实现以不同的方式从它们的设计灵活性中得到好处： 字符串值可能是或可能不是引用计数的。默认情况下，很多实现的确是用了引用计数，但它们通常提供了关闭的方法，一般是通过预处理器宏。比如，引用计数只对频繁拷贝的字符串有帮助，而有些程序不经常拷贝字符串，所以没有那个开销 string对象的大小可能从1到至少7倍char*指针的大小 新字符串值的建立可能需要0、1或2次动态分配 string对象可能是或可能不共享字符串的大小和容量信息 string可能是或可能不支持每对象配置器 不同实现对于最小化字符缓冲区的配置器有不同策略 string是标准库中的最重要的组件之一，鼓励应该要多用。 如果要有效使用STL，需要小心string实现的多样性，特别是如果你正在写必须在不同STL平台上运行的代码并且你面临严格的性能需求。 ","date":"2023-08-04","objectID":"/posts/clause_15/:4:0","tags":["Effective"],"title":"Effective STL [15] | 小心string实现的多样性","uri":"/posts/clause_15/"},{"categories":["C++"],"content":"自动扩容 STL 容器只要存储的对象不超过「最大大小」，就可以自动增长到足以容纳放进去的数据。这个最大值，只要调用名叫max_size的成员函数就可以查询到。 对于vector和string，只要需要更多空间，就以realloc等价的思想来增长。 realloc的操作有4个部分： 「分配新的内存块」。在大部分实现中，vector和string的容量每次以「2」为因数增长，即容量每次翻倍。 「把所有元素从容器的旧内存拷贝到新内存」。 「销毁旧内存中的对象」。 「回收旧内存」。 这就是分配，回收，拷贝和析构4个步骤，这些步骤代价都很昂贵。 即便是简单地把一个元素插入vector或string的动作也可能因为需要更新其他使用了指向vector或string中的迭代器、指针或引用的数据结构而膨胀。 ","date":"2023-08-03","objectID":"/posts/clause_14/:1:0","tags":["Effective"],"title":"Effective STL [14] | 使用reserve来避免不必要的重新分配","uri":"/posts/clause_14/"},{"categories":["C++"],"content":"4个成员函数 这4个STL容器成员函数，只有vector和string提供了所有这些函数。 成员函数 说明 size() 「容器中有多少元素」。没有说明容器为容纳的元素分配了多少内存。 capacity() 「容器已经分配的内存中可以容纳多少元素」。那是容器在那块内存中总共可以容纳多少元素，而不是还可以容纳多少元素。如果想知道一个vector或string中有多少没有被占用的内存，必须从capacity()中减去size()。如果size和capacity返回同样的值，容器中就没有剩余空间了，而下一次插入（通过insert或push_back等）会引发上面的重新分配步骤。 resize(Container::size_type n) 「强制把容器改为容纳n个元素」。调用resize之后，size将会返回n。如果n小于当前大小，容器尾部的元素会被销毁。如果n大于当前大小，新默认构造的元素会添加到容器尾部。如果n大于当前容量，在元素加入之前会发生重新分配。 reserve(Container::size_type n) 「强制容器把它的容量改为至少n，提供的n不小于当前大小」。这一般强迫进行一次重新分配，因为容量需要增加。 reserve成员函数允许你最小化必须进行的重新分配的次数，因而可以避免真分配的开销和迭代器/指针/引用失效。 「调用reserve不改变容器中对象的个数。」 ","date":"2023-08-03","objectID":"/posts/clause_14/:2:0","tags":["Effective"],"title":"Effective STL [14] | 使用reserve来避免不必要的重新分配","uri":"/posts/clause_14/"},{"categories":["C++"],"content":"提前 reserve 「只要有元素需要插入而且容器的容量不足时就会发生重新分配」（包括它们维护的「原始内存分配和回收」，「对象的拷贝和析构」和「迭代器、指针和引用的失效」）。 「避免重新分配的关键」是使用reserve尽快把容器的容量设置为足够大，最好在容器被构造之后立刻进行。 Example 假定你想建立一个容纳1-1000值的vector\u003cint\u003e。没有使用reserve： vector\u003cint\u003e v; for (int i = 1; i \u003c= 1000; ++i) { v.push_back(i); } 在大多数STL实现中，这段代码在循环过程中「将会导致2到10次重新分配」。（「vector在重新分配时一般把容量翻倍」，$1000 \\approx 2^{10}$。） 把代码改为使用reserve： vector\u003cint\u003e v; v.reserve(1000); for (int i = 1; i \u003c= 1000; ++i) { v.push_back(i); } 「这在循环中不会发生重新分配。」 ","date":"2023-08-03","objectID":"/posts/clause_14/:3:0","tags":["Effective"],"title":"Effective STL [14] | 使用reserve来避免不必要的重新分配","uri":"/posts/clause_14/"},{"categories":["C++"],"content":"结论 通常有2种情况使用reserve来避免不必要的重新分配: 可用的情况是「当你确切或者大约知道有多少元素将最后出现在容器中」。可以提前reserve适当数量的空间。 2.「保留可能需要的最大的空间」，然后，一旦添加完全部数据「修整掉任何多余的容量」。 ","date":"2023-08-03","objectID":"/posts/clause_14/:4:0","tags":["Effective"],"title":"Effective STL [14] | 使用reserve来避免不必要的重新分配","uri":"/posts/clause_14/"},{"categories":["C++"],"content":"使用new动态分配内存时的注意事项 必须确保以后会delete这个分配。如果后面没有delete，「new就会产生一个资源泄漏」。 你须确保使用了delete的正确形式: 如果使用了delete的错误形式，结果会未定义。在一些平台上，程序在运行期会当掉。另一方面，有时候会造成资源泄漏，一些内存也随之而去。 对于分配一个单独的对象，必须使用“delete”。 对于分配一个数组，必须使用“delete []”。 必须确保只delete一次。如果一个分配被删除了不止一次，结果也会未定义。 ","date":"2023-08-03","objectID":"/posts/clause_13/:1:0","tags":["Effective"],"title":"Effective STL [13] | 尽量使用vector和string来代替动态分配的数组","uri":"/posts/clause_13/"},{"categories":["C++"],"content":"vector和string vector和string消除了上面的负担，因为它们管理自己的内存。 当元素添加到那些容器中时它们的内存会增长，而且当一个vector或string销毁时，它的析构函数会自动销毁容器中的元素，回收存放那些元素的内存。 vector和string是羽翼丰满的序列容器。 虽然数组也可以用于STL算法，但没有提供像begin、end和size这样的成员函数，也没有内嵌像iterator、reverse_iterator或value_type那样的typedef。而且char*指针当然不能和提供了专用成员函数的string竞争。STL用的越多，越会歧视内建的数组。 ","date":"2023-08-03","objectID":"/posts/clause_13/:2:0","tags":["Effective"],"title":"Effective STL [13] | 尽量使用vector和string来代替动态分配的数组","uri":"/posts/clause_13/"},{"categories":["C++"],"content":"string 计数问题 很多string实现在后台使用了引用计数，「一个消除了不必要的内存分配和字符拷贝的策略，而且在很多应用中可以提高性能」。 事实上，一般认为通过引用计数优化字符串很重要，所以C++标准委员会特别设法保证了那是一个合法的实现。 多线程使用 如果你在多线程环境中使用了引用计数的字符串，你可能发现「避免分配和拷贝所节省下的时间都花费在后台并发控制上」了，会因为线程安全性导致的性能下降。 如果用到的string实现是引用计数的，而且已经确定string的引用计数在多线程环境中运行，那么至少有3个合理的选择，而且没有一个放弃了STL： 「看看库实现是否可以关闭引用计数，通常是通过改变预处理变量的值」； 寻找或开发一个不使用引用计数的string实现（或部分实现）替代品； 「考虑使用vector来代替string，vector实现不允许使用引用计数，所以隐藏的多线程性能问题不会出现了」。 当然，使用了vector，就相当于放弃了string的专用成员函数，但大部分功能仍然可以通过STL算法得到，所以从一种语法切换到另一种不会失去很多功能。 ","date":"2023-08-03","objectID":"/posts/clause_13/:3:0","tags":["Effective"],"title":"Effective STL [13] | 尽量使用vector和string来代替动态分配的数组","uri":"/posts/clause_13/"},{"categories":["C++"],"content":"结论 如果你在使用动态分配数组，你可能比需要的做更多的工作。 要减轻你的负担，就使用vector或string来代替。 ","date":"2023-08-03","objectID":"/posts/clause_13/:4:0","tags":["Effective"],"title":"Effective STL [13] | 尽量使用vector和string来代替动态分配的数组","uri":"/posts/clause_13/"},{"categories":["C++"],"content":"多线程维护的规则 多线程程序是很普遍的，所以大部分STL厂商努力使他们的实现在线程环境中可以正常工作。 但是，即使他们做得很好，「大部分负担仍在你肩上，而理解为什么会这样是很重要的」。 在STL容器（和大多数厂商的愿望）里对多线程支持的黄金规则已经由SGI定义，并且在它们的STL网站上发布： 「多个读取者是安全的」。多线程可能同时读取一个容器的内容，在读取时「不能有任何写入者操作这个容器」。 「对不同容器的多个写入者是安全的」。多线程可以同时写不同的容器。对同一个容器同时多线程写入是不安全的。 ","date":"2023-08-02","objectID":"/posts/clause_12/:1:0","tags":["Effective","STL"],"title":"Effective STL [12] | 对STL容器线程安全性的期待现实一些","uri":"/posts/clause_12/"},{"categories":["C++"],"content":"完全线程安全？ 很多程序员希望STL实现是完全线程安全，这非常难以实现。 一个库可能试图以下列方式实现这样完全线程安全的容器： 每次调用容器的成员函数期间都要锁定该容器」 在「每个容器返回的迭代器(例如通过调用begin或end)的生存期之内都要锁定该容器」 在「每个在容器上调用的算法执行期间锁定该容器」。（这事实上没有意义，因为算法没有办法识别出它们正在操作的容器） ","date":"2023-08-02","objectID":"/posts/clause_12/:2:0","tags":["Effective","STL"],"title":"Effective STL [12] | 对STL容器线程安全性的期待现实一些","uri":"/posts/clause_12/"},{"categories":["C++"],"content":"Example 多线程修改 搜寻一个vector中第一次出现3这个值的地方，如果它找到了，就把这个值改为2。 vector\u003cint\u003e v; vector\u003cint\u003e::iterator first3(find(v.begin(), v.end(), 3)); // line 1 if (first3 != v.end()){ // line 2 *first3 = 2; // line 3 } 多线程访问时，会有很多「问题」: 在多线程环境里，另一个线程可能在行1完成之后立刻修改v中的数据。如果是那样，行2对first3和v.end的检测将是无意义的，因为v的值可能和它们在行1结束时的值不同。 这样的检测会产生未定义的结果，因为另一线程可能插在行1和行2之间，使first3失效，或许通过进行一次插入操作造成vector重新分配它的内在内存。（那将使vector全部的迭代器失效） 行3中对*first3的赋值是不安全的，因为另一个线程可能在行2和行3之间执行，并以某种方式使first3失效，可能通过删除它指向（或至少曾经指向）的元素。 解决办法：加锁 要让上面的代码成为线程安全的，「v必须从行1到行3保持锁定」，让最多一个线程在1-3行的过程中能访问v。很难想象STL实现怎么能自动推断出这个。 而「同步原语（例如，信号灯，互斥量，等等）通常开销很大」，更难想象怎么实现在程序没有明显性能损失的情况下做到前面所说的。 因此你必须「手工对付」这些情况中的同步控制 vector\u003cint\u003e v; ... getMutexFor(v); vector\u003cint\u003e::iterator first3(find(v.begin(), v.end(), 3)); if (first3 != v.end()) { // 这里现在安全了 *first3 = 2; // 这里也是 } releaseMutexFor(v); 「改进：」一个更面向对象的解决方案是「创建一个Lock类」，在它的「构造函数里获得互斥量并在它的析构函数里释放它」，这样使getMutexFor和releaseMutexFor的「调用不匹配的机会减到最小」: template\u003ctypename Container\u003e // 获取和释放容器的互斥量的类的模板核心； class Lock { / public: // 忽略了很多细节 Lock(const Containers container): c(container) { getMutexFor(c); // 在构造函数获取互斥量 } ~Lock() { releaseMutexFor(c); // 在析构函数里释放它 } private: const Container\u0026 c; }; 使用一个类（像Lock）来管理资源的生存期（例如互斥量）的办法通常称为资源获得即初始化。 应用到上述例子： vector\u003cint\u003e v; ... { // 建立新块； Lock\u003cvector\u003cint\u003e \u003e lock(v); // 获取互斥量 vector\u003cint\u003e::iterator first3(find(v.begin(), v.end(), 3)); if (first3 != v.end()) { *first3 = 2; } } // 关闭块，自动 // 释放互斥量 基于Lock的方法在有异常的情况下是稳健的 因为Lock对象在Lock的析构函数里释放容器的的互斥量，所以在互斥量需要释放是就销毁Lock是很重要的。为了让这件事发生，我们建立一个里面定义了Lock的新块，而且当我们不再需要互斥量时就关闭那个块。 C++保证如果抛出了异常，局部对象就会被销毁，所以即使当我们正在使用Lock对象时有异常抛出，Lock也将释放它的互斥量。如果我们依赖手工调用getMutexFor和releaseMutexFor，那么在调用getMutexFor之后releaseMutexFor之前如果有异常抛出，我们将不会释放互斥量。 ","date":"2023-08-02","objectID":"/posts/clause_12/:3:0","tags":["Effective","STL"],"title":"Effective STL [12] | 对STL容器线程安全性的期待现实一些","uri":"/posts/clause_12/"},{"categories":["C++"],"content":"结论 当涉及到线程安全和STL容器时，你可以确定库实现允许在一个容器上的多读取者和不同容器上的多写入者。 「你不能希望库消除对手工并行控制的需要，而且你完全不能依赖于任何线程支持」 ","date":"2023-08-02","objectID":"/posts/clause_12/:4:0","tags":["Effective","STL"],"title":"Effective STL [12] | 对STL容器线程安全性的期待现实一些","uri":"/posts/clause_12/"},{"categories":["ML"],"content":"一、引入 近年AIGC的爆火离不开人工智能在图像生成、文本生成以及多模态等领域的不断累积，其中生成模型的发展占据了很大功劳，如：生成对抗网络 GAN 及其一系列变体、变分自编码器 VAE 及其一系列变体、自回归模型 AR、流模型 flow ，以及近年大火的扩散模型 Diffusion Model 等。 扩散模型的大火并非横空出世，早在2015年就有人提出了类似的想法，直到2020年才提出了经典的 Denoising Diffusion Probabilistic Models（DDPM），像OpenAI、NovelAI、NVIDIA和Google成功的训练了大规模模型之后，它们吸引了很多人注意，后续有了很多基于扩散模型的变体，比如有：GLIDE、DALLE-2、Imagen和年底爆火的完全开源的稳定扩散模型（Stable Diffusion）。 扩散模型与之前所有的生成方法有着本质的区别： 直观的说它是将图像生成过程（采样）分解为许多小的去噪步骤，其实 Diffusion 的含义本质上就是一个迭代过程，实线箭头用于扩散步骤中添加随机噪声，虚线箭头代表的是通过学习逆向扩散过程从噪声中重构所需的数据样本。引入噪声导致了信息的衰减，再通过噪声尝试还原原始数据，多次迭代最小化损失后，能够使模型在给定噪声输入的情况下学习生成新图像。 所以Diffusion模型和其它生成模型的区别是，它不是直接的图像-\u003e潜变量、潜变量-\u003e图像的一步到位，它是一步一步的逐渐分解、逐渐去噪的过程。 当然有关Diffusion的理解和变体有很多，但是扩散模型从本质上讲就是DDPM，所以本文主要对DDPM的原理进行讲解，并给出DDPM的扩散过程、去噪过程、训练损失的详细推导，对于掌握Diffusion算法原理只需要抓住以下四点即可： 前向过程（扩散）； 反向过程（去噪、采样）； 如何训练； 如何推断。 ","date":"2023-07-31","objectID":"/posts/ddpm/:1:0","tags":["draft"],"title":"Diffusion 扩散模型（DDPM）","uri":"/posts/ddpm/"},{"categories":["ML"],"content":"二、扩散原理阐述 扩散模型包括 前向扩散过程 和 反向去噪过程(采样)，前向阶段对图像逐步施加噪声，直至图像被破坏变成完全的高斯噪声，然后在反向阶段学习从高斯噪声还原为原始图像的过程。 ","date":"2023-07-31","objectID":"/posts/ddpm/:2:0","tags":["draft"],"title":"Diffusion 扩散模型（DDPM）","uri":"/posts/ddpm/"},{"categories":["ML"],"content":"2.1、直观理解 扩散模型的目的是什么？ 学习从纯噪声生成图片的方法。 扩散模型是怎么做的？ 训练一个UNet，接受一系列加了噪声的图片，学习预测所加的噪声。 前向过程在干什么？ 逐步向真实图片添加噪声最终得到一个纯噪声； 对于训练集中的每张图片，都能生成一系列的噪声程度不同的加噪图片； 在训练时，这些 【不同程度的噪声图片 + 生成它们所用的噪声】 是实际的训练样本。 反向过程在干什么？ 训练好模型后，采样、生成图片。 ","date":"2023-07-31","objectID":"/posts/ddpm/:2:1","tags":["draft"],"title":"Diffusion 扩散模型（DDPM）","uri":"/posts/ddpm/"},{"categories":["ML"],"content":"2.2、前向过程（扩散） 前向过程在原始输入图像$x_0$上逐步添加随机噪声，这个噪声服从高斯分布$N(0, 1)$，每一步得到的图像$x_t$只和上一步的加噪结果$x_{t-1}$相关，逐步添加噪声至$T$步，可以得到趋向于纯粹噪声的图像，如下图所示： 后面有详细的推导，公式比较多，这里先提前把主要的列一下方便阐述。 对于将一张图片，从$x_{t-1}\\rightarrow x_{t}$的逐步加噪破坏的公式为： $$x_t=\\sqrt{\\alpha_t}\\left.x_{t-1}+\\sqrt{1-\\alpha_t}\\right.\\varepsilon_t\\quad\\quad\\quad\\quad\\quad\\quad(1)$$ 其中: $x_t$表示第$t$步的图像； $\\varepsilon$ 是一个满足正态分布的随机噪声，$\\varepsilon \\sim N(0, 1)$； $\\sqrt{\\alpha_{t}}$ 是图片的权重，$\\sqrt{1 - \\alpha_{t}}$ 是噪声的权重； 定义： $\\alpha_t=1-\\beta_t$ $\\overline{\\alpha}=\\prod_{s=1}^t\\alpha_s$ 随着$t$的增加，噪声的占比会越来越大，所以添加的噪声强度也会越来越大，也就是说图片的权重要越来越小，噪声的权重要越来越大。因为随着扩散过程的增加，图像中噪声的占比也会越来越大，我们想要进一步破坏它的结构，就需要添加更多的噪声。 换句话说，一开始图像比较清晰，这个时候添加的噪声小一些，随着图像的噪声越来越多，这个时候再加一点噪声的话，对原来的图像就没什么影响了，因为它本身就有好多噪声了，所以随着图像的噪声越来越多，后面的步骤就要加更多的噪声。 实际训练过程中会比较大（DDPM原文中为1000），所以会有从$x_0$递推到$x_t$的公式： $$x_t=\\sqrt{\\overline{\\alpha}_t}\\left.x_0+\\sqrt{1-\\overline{\\alpha}_t}\\right.\\varepsilon\\quad\\quad\\quad\\quad(2)$$ 其中： $\\alpha_t$、$\\beta_t$ 有一个固定的已知函数，是可以直接进行计算的； $\\varepsilon$ 为随机产生的噪声； 所以整个式子是已知的，式 $(1)$、$(2)$ 就可以描述前向过程了，$(1)$ 用于将一张图片的逐步破坏，$(2)$ 用于一步到位的破坏。 ","date":"2023-07-31","objectID":"/posts/ddpm/:2:2","tags":["draft"],"title":"Diffusion 扩散模型（DDPM）","uri":"/posts/ddpm/"},{"categories":["ML"],"content":"2.3、反向过程（去噪） 反向过程则是不断去除噪声的过程，给定一个噪声图片 $x_T$，对它一步步的去噪还原，直至最终将原始图像 $x_0$ 给恢复出来，如下图所示： 去噪的过程，$x_t$、$\\alpha_t$、$\\beta_t$ 都是已知的，只有公式 $(2)$ 中的真实噪声是未知的，因为它是随机采样的。所以需要一个神经网络把 $\\varepsilon$ 给学出来，也就是说训练一个由 $x_t$ 和 $t$ 估测噪声的模型: $$x_{t-1}=\\frac{1}{\\sqrt{\\alpha_t}}(x_t-\\frac{\\beta_t}{\\sqrt{1-\\overline{\\alpha}t}}\\varepsilon\\theta(x_t,t))$$ 其中 $\\theta$ 就是模型的参数，通常使用UNet作为预估噪声的模型。 ","date":"2023-07-31","objectID":"/posts/ddpm/:2:3","tags":["draft"],"title":"Diffusion 扩散模型（DDPM）","uri":"/posts/ddpm/"},{"categories":["ML"],"content":"2.4、模型训练 所以说反向过程其实就是训练网络去学习分解过程每一步的噪声，当网络训练好之后，输入一张噪声图片，通过网络就能把加的噪声给求出来，噪声有了代入公式，就能把 $x_{t-1}$ 步的比较清晰的图给求出来了，一步步往前迭代就行了。 采用L2距离刻画相近程度就可以，DDPM的关键是训练 $\\varepsilon_{\\theta}(x_t, t)$，目的就是使预测的噪声与真实用于破坏的噪声相近： $$Loss=\\mid\\mid\\varepsilon-\\varepsilon_\\theta(x_t,t)\\mid\\mid^2=\\mid\\mid\\varepsilon-\\varepsilon_\\theta(\\sqrt{\\overline{\\alpha}_t}~x_0+\\sqrt{1-\\overline{\\alpha}_t}~\\varepsilon_t,t)\\mid\\mid^2$$ 模型训练完后，只要给定随机高斯噪声，就可以生成一张从未见过的图像。 UNet本文不做介绍，结构图为： 额外强调的是：Unet里有一个位置编码，是关于时间步的，每个时间步是有一个线性调度器的，每个时间添加的噪声的方差是不一样的，所以将时间步作为编码嵌入的话，可以将模型预测的噪声更加的准确。 ","date":"2023-07-31","objectID":"/posts/ddpm/:2:4","tags":["draft"],"title":"Diffusion 扩散模型（DDPM）","uri":"/posts/ddpm/"},{"categories":["ML"],"content":"三、算法流程概述 再次总结，扩散模型两个步骤如下： 一个固定的（预先定义好的）前向扩散过程 $q(x_t | x_{t-1})$：逐步向图片增加噪声直到最终得到一张纯粹的噪声图； 一个学习得到的去噪过程 $p_{\\theta}(x_{t-1} | x_t)$：训练一个神经网络去逐渐的从一张纯噪声中消除噪声，直到得到一张真正的图片。 算法1 为训练流程： line2：从数据中采样 $x_0$，$q(x_0)$ 的意思是给 $x_0$ 加上噪声； line3：随机选取 time step $t$； 真实训练过程中我们不可能一步步的从 $t$ 到 $T$，因为会很大，这就意味着每输入一张图片 $x$，就会产生张噪声图像，也就是一张图像的网络要训练 $T$ 个噪声样本，非常耗时。 所以对 $T$ 进行了采样，$t$ 就是从 $T$ 里采集若干个的意思。 举个例子：假设采集 $t$ 的分别为100、20、3，对应的 $x$ 为 $x_{100}$、$x_{20}$、$x_{3}$，对应噪声为 $\\varepsilon_{100}$、$\\varepsilon_{20}$、$\\varepsilon_{3}$，对于的预测噪声为 $\\hat{\\varepsilon}{100}$、$\\hat{\\varepsilon}{20}$、$\\hat{\\varepsilon}_{3}$, 只需要将 $\\varepsilon$ 和 $\\hat{\\varepsilon}$ 代入MSE公式即可（相减、平方、最小化）。 line 4：生成随机高斯噪声； line 5：调用模型估计 $\\varepsilon_{\\theta}(\\sqrt{\\overline{\\alpha}_t}~x_0+\\sqrt{1-\\overline{\\alpha}_t}~\\varepsilon_t,t)$ ，计算真实噪声与估计噪声之间的MSE Loss，反向传播更新模型。 网络的作用是预测噪声，随着的增加，噪声强度会越来越大，因此预测的噪声是和迭代是直接相关的，所以要把作为参数送入到网络当中。 直到收敛。 算法2 为采样流程： line 1：从高斯分布采样 $x_T$； line 2：按照 $T, …, 1$ 的顺序进行迭代； line 3：如果 $t = 1$ 令 $z = 0$；如果 $t \u003e 1$ ，从高斯分布中采样； line 4：利用公式求出均值和方差，进而求得 $x_{t-1}$； 经过上述迭代，恢复 $x_0$。 ","date":"2023-07-31","objectID":"/posts/ddpm/:3:0","tags":["draft"],"title":"Diffusion 扩散模型（DDPM）","uri":"/posts/ddpm/"},{"categories":["ML"],"content":"四、数学描述 我们来推导如何从原始图像直接到第t时刻的图像 $(X_0 - X_t)$。 首先回顾 2.1小节 的两个定义： $\\alpha_t = 1 - \\beta_{t}$, $\\beta_t$ 要越大越好，论文中从0.0001到0.02; $\\overline{\\alpha}=\\prod_{s=1}^t\\alpha_s$累乘，下面会用到； $x_t=\\sqrt{\\alpha_t}x_{t-1}+\\sqrt{1-\\alpha_t}\\varepsilon_t\\text{,}\\varepsilon_t\\sim N(0,1)$ 每一时刻添加的噪声均独立； 我们要求$x_t$时刻的图像，它需要一步步的加噪迭代，这样太慢了。因为每一步添加的噪声独立且服从正太分布，我们可以做如下推导： 为了不混淆，只需要记住：下标越小，噪声越小，即 $x_{t-1}$ 的噪声是小于 $x_t$ 的。 $$ \\begin{aligned} q(x_{t}\\mid x_{t-1})\u0026 =N(x_t;\\sqrt{\\alpha_t}x_{t-1},(1-\\alpha_t)I) \\cr \u0026=\\underbrace{\\sqrt{\\alpha_t}x_{t-1}}{x{t-2}\\text{来表示}x_{t-1}}+\\sqrt{1-\\alpha_t}\\varepsilon_t \\cr \u0026=\\sqrt{\\alpha_t}\\left(\\sqrt{\\alpha_{t-1}}\\right.x_{t-2}+\\sqrt{1-\\alpha_{t-1}}\\left.\\varepsilon_{t-1}\\right)+\\sqrt{1-\\alpha_t}\\left.\\varepsilon_t\\right. \\cr \u0026=\\sqrt{\\alpha_t\\alpha_{t-1}}x_{t-2}+\\underbrace{\\sqrt{\\alpha_t-\\alpha_t\\alpha_{t-1}}\\varepsilon_{t-1}+\\sqrt{1-\\alpha_t}\\varepsilon_t}{\\text{两个独立正太分布相加}} \\cr \u0026=\\sqrt{\\alpha_t\\alpha{t-1}}\\left.x_{t-2}+\\sqrt{1-\\alpha_t\\alpha_{t-1}}\\right.\\varepsilon \\cr \u0026\\text{…} \\ \u0026=\\sqrt{\\overline{\\alpha}_t}\\left.x_0+\\sqrt{1-\\overline{\\alpha}_t}\\right.\\varepsilon \\cr \u0026\\therefore q(x_t\\mid x_0)=N(x_t;\\sqrt{\\overline{\\alpha}_t}x_0,\\sqrt{1-\\overline{\\alpha}_t}I) \\end{aligned} $$ 上述用的就是重参数化技巧。 方差参数 $\\beta_{t}$ 可以固定为一个常数，也可以选择作为 $T$ 时间段的一个时间表。事实上，人们可以定义一个方差表，它可以是线性的、二次的、余弦的等等。最初的DDPM作者利用了一个从 $\\beta_1 = 10^{-4}$ 到$\\beta_T = 0.02$增加的线性时间表。Nichol等人2021年的研究表明，采用余弦时间表效果更好。 ","date":"2023-07-31","objectID":"/posts/ddpm/:4:0","tags":["draft"],"title":"Diffusion 扩散模型（DDPM）","uri":"/posts/ddpm/"},{"categories":["ML"],"content":"4.2、反向过程（去噪） 接下来是反向过程的推导： $$p(x_{t-1}\\mid x_t)=N(x_{t-1};\\underbrace{\\mu_\\theta(x_t,t)}\\text{要反预测这个},\\overbrace{\\Sigma\\theta(x_t,t)}^{fixed})$$ 给定$x_t$要预测 $x_{t-1}$，它是一个高斯分布，$x_t$和$t$的方差是固定的，论文作者使用原始的噪声调度器作为方差，也就是说噪声调度器一旦确立，方差的大小也就固定了。所以我们只需要预测这个均值就好了，下面给出具体的推导过程： 我们先看整个损失函数，是个负对数似然： $$-\\log{p_{\\theta}(x_0)}$$ 希望神经网络的参数 $\\theta$，可以使得生成 $x_0$的概率越大越好。 但问题在于 $x_0$ 的概率不好计算，因为它依赖于 $x_0$ 之前的所有步长，从 $x_T$ 开始。作为一种解决方案，我们可以计算这个目标的变分下界，并得到一个更易于计算的公式： $$-log(p_\\theta(x_0))\\leq-log(p_\\theta(x_0))+D_{KL}(q(x_{1:T}\\mid x_0)\\parallel p_\\theta(x_{1:T}\\mid x_0))$$ 其中： $x_{1:T}$ 指的是 $x_1, …, x_T$ 整个序列。 现在依然无法计算，我们继续推导： $$ \\begin{gathered} -log(p_\\theta(x_0)) \\leq-log(p_\\theta(x_0))+D_{KL}(q(x_{1:T}\\mid x_0)\\mid\\mid p_\\theta(x_{1:T}\\mid x_0)) \\cr \\leq-log(p_\\theta(x_0))+log(\\frac{q(x_{1:T}\\mid x_0)}{p_\\theta(x_{1:T}\\mid x_0)}) \\end{gathered} $$ 我们将 KL divergence 改写后，再利用贝叶斯公式进行变形，即分母可以改写为： $$ \\begin{aligned} p_\\theta(x_{1:T}\\mid x_0) \u0026=\\frac{p_\\theta(x_0\\mid x_{1:T})\\mathrm{~}p_\\theta(x_{1:T})}{p_\\theta(x_0)} \\cr \u0026=\\frac{p_\\theta(x_0,x_{1:T})}{p_\\theta(x_0)} \\cr \u0026=\\frac{p_\\theta(x_{0:T})}{p_\\theta(x_0)} \\end{aligned} $$ 将其代回原式： $$ \\begin{aligned} log(\\frac{q(x_{1:T}\\mid x_0)}{p_\\theta(x_{1:T}\\mid x_0)})\u0026 =log(\\frac{q(x_{1:T}\\mid x_0)}{\\frac{p_\\theta(x_{0:T})}{p_\\theta(x_0)}}) \\cr \u0026=log(\\frac{q(x_{1:T}\\mid x_0)}{p_\\theta(x_{0:T})})+log(p_\\theta(x_0)) \\end{aligned} $$ 所以原式可简化为： $$-log(p_\\theta(x_0))\\leq\\underbrace{log(\\frac{q(x_{1:T}\\mid x_0)}{p_\\theta(x_{0:T})})}_{\\text{变分下界,可以优化它}}$$ 分子，就是前向过程，它是固定的，从 $x_0$ 到 $x_{1:T}$ 的采样，换句话说就是从我们数据中的一些图像开始； 分母，$p_\\theta(x_{0:T})=p(x_T)\\prod_{t=1}^Tp_\\theta(x_{t-1}\\mid x_t)$； 将 $p(x_T)$ 提出来，是因为 $p(x_T)$ 是指当前图像，它是不依赖于网络参数 $\\theta$ 的. $$ \\begin{aligned} log(\\frac{q(x_{1:T}\\mid x_0)}{p_{\\theta}(x_{0:T})})\u0026 =log(\\frac{\\prod_{t=1}^Tq(x_t\\mid x_{t-1})}{p(x_T)\\prod_{t=1}^Tp_\\theta(x_{t-1}\\mid x_t)}) \\cr \u0026=-log(p(x_T))+log(\\frac{\\prod_{t=1}^Tq(x_t\\mid x_{t-1})}{\\prod_{t=1}^Tp_\\theta(x_{t-1}\\mid x_t)}) \\cr \u0026=-log(p(x_T))+\\sum_{t=1}^Tlog(\\frac{q(x_t\\mid x_{t-1})}{p_\\theta(x_{t-1}\\mid x_t)}) \\cr \u0026=-log(p(x_T))+\\sum_{t=2}^Tlog(\\frac{q(x_t\\mid x_{t-1})}{p_\\theta(x_{t-1}\\mid x_t)})+\\underbrace{log(\\frac{q(x_1\\mid x_0)}{p_\\theta(x_0\\mid x_1)})}_{t=1} \\end{aligned} $$ $q(x_t|x_{t-1})$ 根据贝叶斯公式可以变换如下： $$q(x_t\\mid x_{t-1})=\\frac{q(x_{t-1}\\mid x_t)q(x_t)}{q(x_{t-1})}$$ $q(x_{t-1}|x_{t})$具有比较高的方差，因为根据这张照片，我们无法确定它来自哪里，但是引入 $x_0$，我们就可以容易的预测出 $x_{t-1}$， 因此我们使用： $$\\frac{q(x_{t-1}\\mid x_t,x_0)\\mathrm{~}q(x_t\\mid x_0)}{q(x_{t-1}\\mid x_0)}$$ 替换贝叶斯重写后的式子，我们得到： $$ \\begin{aligned} log(\\frac{q(x_{1:T}\\mid x_0)}{p_{\\theta}(x_{0:T})})\u0026 =-log(p(x_T))+\\sum_{t=2}^Tlog(\\frac{q(x_{t-1}\\mid x_t,x_0)q(x_t\\mid x_0)}{p_\\theta(x_{t-1}\\mid x_t)q(x_{t-1}\\mid x_0)})+log(\\frac{q(x_1\\mid x_0)}{p_\\theta(x_0\\mid x_1)}) \\cr \u0026=-log(p(x_T))+\\sum_{t=2}^Tlog(\\frac{q(x_{t-1}\\mid x_t,x_0)}{p_\\theta(x_{t-1}\\mid x_t)})+\\underbrace{\\sum_{t=2}^Tlog(\\frac{q(x_t\\mid x_0)}{q(x_{t-1}\\mid x_0)})}+log(\\frac{q(x_1\\mid x_0)}{p_\\theta(x_0\\mid x_1)}) \\end{aligned} $$ 上述标记的式子，也可以简化，我们假设 $t=4$： $$ \\begin{gathered} \\begin{aligned}\\sum_{t=2}^{T=4}log(\\frac{q(x_t\\mid x_0)}{q(x_{t-1}\\mid x_0)})\\end{aligned} =log(\\frac{q(x_2\\mid x_0)}{q(x_1\\mid x_0)}\\cdot\\frac{q(x_3\\mid x_0)}{q(x_2\\mid x_0)}\\cdot\\frac{q(x_4\\mid x_0)}{q(x_3\\mid x_0)}) \\ =log(\\frac{q(x_4\\mid x_0)}{q(x_1\\mid x_0)}) \\end{gathered} $$ 因此我们可以简化为： $$ \\begin{aligned} \u0026=-log(p(x_T))+\\sum_{t=2}^Tlog(\\frac{q(x_{t-1}\\mid x_t,x_0)}{p_\\theta(x_{t-1}\\mid x_t)})+log(\\frac{q(x_t\\mid x_0)}{q(x_1\\mid x_0)})+log(\\frac{q(x_1\\mid x_0)}{p_\\theta(x_0\\mid x_1)}) \\cr \u0026=-log(p(x_T))+\\sum_{t=2}^Tlog(\\frac{q(x_{t-1}\\mid x_t,x_0)}{p_\\theta(x_{t-1}\\mid x_t)})+log(q(x_t\\mid x_0))-log(p_\\theta(x_0\\mid x_1)) \\cr \u0026=log(\\frac{q(x_t\\mid x_0)}{p(x_T)})+\\sum_{t=2}^Tlog(\\frac{q(x_{t-1}\\mid x_t,x_0)}{p_\\theta(x_{t-1}\\mid x_t)})-log(p_\\theta(x_0\\mid x_1))\\cr \u0026=\\overbrace{\\underbrace{D_{KL}(q(x_t\\mid x_0)\\mid\\mid p(x_T))}{q\\text{只是个正向过程没有可学习参数}}}^{\\text{可以忽略}} + \\sum{t=2}^TD_{KL}(q(x_{t-1}\\mid x_t,x_0)\\mid\\mid p_\\theta(x_{t-1}\\mid x_t))-log(p_\\theta(x_0\\mid x_1)) \\","date":"2023-07-31","objectID":"/posts/ddpm/:4:1","tags":["draft"],"title":"Diffusion 扩散模型（DDPM）","uri":"/posts/ddpm/"},{"categories":["ML"],"content":"4.3、训练损 下面我们来看损失的推导，我们来回顾第二项： 我们需要减小KL散度，由于方差是固定的，我们无法优化，所以需要将它们的均值之差减小，原论文中使用的是简单的均方误差： 将$\\mu$表达式代入： $$ \\begin{aligned} L_{t}\u0026 =\\frac1{2\\sigma_t^2}\\mid|\\tilde{\\mu}t(x_t,x_0)-\\mu\\theta(x_t,t)||^2 \\cr \u0026=\\frac1{2\\sigma_t^2}\\mid\\mid\\frac1{\\sqrt{\\alpha_t}}(x_t-\\frac{\\beta_t}{\\sqrt{1-\\overline{\\alpha}t}}\\left.\\varepsilon\\right)-\\frac1{\\sqrt{\\alpha_t}}(x_t-\\frac{\\beta_t}{\\sqrt{1-\\overline{\\alpha}t}}\\left.\\varepsilon\\theta(x_t,t)\\right)\\mid\\mid^2 \\cr \u0026=\\frac{\\beta_t^2}{2\\sigma_t^2\\alpha_t(1-\\overline{\\alpha}t)}\\underbrace{\\mid\\mid\\varepsilon-\\varepsilon\\theta(x_t,t)\\mid\\mid^2}{mse} \\cr \u0026-\u003e\\mid\\mid\\varepsilon-\\varepsilon_\\theta(x_t,t)\\mid\\mid^2=\\mid\\mid\\varepsilon-\\varepsilon_\\theta(\\sqrt{\\overline{\\alpha}_t}\\left.x_0+\\sqrt{1-\\overline{\\alpha}_t}\\left.\\varepsilon_t,t\\right)\\mid\\mid^2\\right. \\end{aligned} $$ 研究人员发现，忽略前面的系数项会变得更简单，采样质量也会得到提高，所以前面这个系数项我们直接忽略，它是和噪声调度器有关的，我们加噪的话也会使计算复杂。 我们最小化 $\\mid\\mid\\varepsilon-\\varepsilon_\\theta(x_t, t)\\mid\\mid^2$ 也就是最小化了KL散度，KL散度变小了也就是变分上限优化到最小，所以那个负对数似然也会变小。 上面还剩了最后一项 $-log(p_\\theta(x_0\\mid x_1))$ ，这个作者决定去掉它，即在 $t=1$ 时，我们不添加噪声。也就是下面横线的地方，只有 $t\u003e1$ 的时候才服从高斯分布，如果 $t\\leq {1}$，直接让 $z=0$，即噪声设置为0。 回顾上面整个推导过程：我们从负对数似然 -\u003e 优化下界 -\u003e 简化下界 -\u003e 预测噪声。 ","date":"2023-07-31","objectID":"/posts/ddpm/:4:2","tags":["draft"],"title":"Diffusion 扩散模型（DDPM）","uri":"/posts/ddpm/"},{"categories":["ML"],"content":"五、torch复现 https://wangguisen.blog.csdn.net/article/details/128821008 ref: [1]. https://arxiv.org/abs/2006.11239 [2]. https://kexue.fm/archives/9119 [3]. https://zhuanlan.zhihu.com/p/576475987 [4]. https://zhuanlan.zhihu.com/p/525106459 [5]. https://www.bilibili.com/video/BV1b541197HX [6]. https://www.bilibili.com/video/BV1WD4y1E7X5 [7]. https://huggingface.co/blog/annotated-diffusion [8]. https://www.datalearner.com/blog/1051664857725795 [9]. https://lilianweng.github.io/posts/2021-07-11-diffusion-models [10]. https://mp.weixin.qq.com/s?__biz=Mzk0MzIzODM5MA==\u0026mid=2247486128\u0026idx=1\u0026sn=7ffef5d8c1bbf24565d0597eb5eaeb16\u0026chksm=c337b729f4403e3f4ca4fcc1bc04704f72c1dc02876a2bf83c330e7857eba567864da6a64e18\u0026scene=21#wechat_redirect [11]. paper link ","date":"2023-07-31","objectID":"/posts/ddpm/:5:0","tags":["draft"],"title":"Diffusion 扩散模型（DDPM）","uri":"/posts/ddpm/"},{"categories":["C++"],"content":" 前言 Effective-C++总结系列分为四部分，本文为第二部分，涉及原书第3~4章，内容范围Rule13~25。为方便书写，Rule13简写为R13。 Effective-C++系列List 本博客站点系列内容如下： 💡 Effective C++(第3版)精读总结(一) 💡 Effective C++(第3版)精读总结(二) 💡 Effective C++(第3版)精读总结(三) 💡 Effective C++(第3版)精读总结(四) 由于原书在C++11之前写成，有些现代C++特性不会提及，所以会根据本人开发经验新增一些个人感悟👉By the way环节。 ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_four/:0:0","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [4]","uri":"/posts/effective_cpp_part_four/"},{"categories":["C++"],"content":"CH7 模板与泛型编程 ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_four/:1:0","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [4]","uri":"/posts/effective_cpp_part_four/"},{"categories":["C++"],"content":"R41 了解隐式接口和编译期多态 面向对象编程的通常做法： 显式定义接口（参数和返回值类型都是确定的，函数签名 就是确定的） 虚函数实现运行时多态 那么编译期多态呢？在面向对象编程中，我们的答案通常是函数重载。 在Templates 及泛型编程中，更为注重的是隐式接口和编译期多态： 隐式接口: Template的接口属于隐式接口，因为它类型不确定，所以是基于有效表达式来区分。再加上运算符重载等特性，隐式接口的自由度非常大。 编译期多态: Template的多态是通过Template具现化和函数重载决议发生于编译期。 上述描述看起来有点抽象，分析下方Template函数代码： template\u003ctypename T\u003e void doProcessing(T\u0026 w){ if(w.size() \u003e 10 \u0026\u0026 w != someNastyWidget){ ... } } doProcessing属于隐式接口，类型不定，传入不同类型T，就得到不同的函数。 由于 操作符重载(operator overloading) 的存在，隐式接口对传入的 T 类型的要求比较宽松，列举如下： T类型或其父类型具有 size() 接口，size() 接口返回类型S为整型或者S类型有 bool operator\u003e(int) 接口； T类型有 bool operator != (const T\u0026)接口；或T类型可以隐式转换为某S类型，S可以与someNastyWidget进行 != 比较，或者干脆someNastyWidget就是T类型； 上述1 、 2 点的描述没有将 operator \u0026\u0026 考虑进来，否则情况会更为复杂，这里不赘述了。 ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_four/:1:1","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [4]","uri":"/posts/effective_cpp_part_four/"},{"categories":["C++"],"content":"R42 了解typename的双重意义 typename 和 class 关键字在声明 Template 参数的时候，没有任何区别 如下示例，效果是一致的： template\u003cclass T\u003e class Widget ; //早期C++使用这个声明Template参数 template\u003ctypename T\u003e class Widget; //现在更推荐用这个，暗示参数不一定是个class类型 使用关键字 typename 标识 嵌套从属类型名称 模板内的从属类型，是指在模板函数/模板类中，需要依赖传入的 template 参数间接表示的类型，如果呈嵌套状，就叫嵌套从属名称/类型。 如下示例的 C::const_iterator 就是嵌套从属类型。 template\u003ctypename C\u003e void printContainer2ndVal(const C\u0026 container) { if (container.size() \u003e= 2) { typename C::const_iterator iter(container.begin()); std::cout \u003c\u003c \"this container's second value is: \" \u003c\u003c *++iter \u003c\u003c std::endl; } } 此时，typename 的作用就是告诉编译器 C::const_iterator 是个类型，否则会编译报错。此时可以用 class 关键字替代，但是不建议。 typename 使用范围不只是 template 函数内部，也包括了函数入参 ： template\u003ctypename C\u003e void foo(const C\u0026 container, // 不允许使用 \"typename\" typename C::iterator iter); // 必须使用 \"typename\" ⚠️ 其他特殊情况：不要在 基类列表base class list 或 成员初始化列member initialization list 使用 typename template\u003ctypename T\u003e class Derived: public Base\u003cT\u003e::Nested{ //基类列表不允许使用typename public: explicit Derived(int x):Base\u003cT\u003e::Nested(x){// 成员初值列也不允许typename typedef typename Base\u003cT\u003e::Nested NestedType;//结合typedef定义，常规用法 NestedType temp; ...// 其他操作 } }; ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_four/:1:2","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [4]","uri":"/posts/effective_cpp_part_four/"},{"categories":["C++"],"content":"R43 学习处理模板化基类内的名称 模板化基类：指定义 template 模板类时，继承于某基类 Base，这个 Base 类就是模板化基类。 🤔 那么 Base 类有关的函数等名称该如何处理，在子类中直接使用吗？还是有注意事项？这，就是本节要讨论的问题。示例如下： template\u003ctypename Company\u003e class MsgSender{ public: void SendPlain(){ std::cout \u003c\u003c \"send plain\\n\";} void SendEncrypted(){ std::cout \u003c\u003c \"send encrypted\\n\";} }; // 基类 template\u003ctypename Company\u003e class LoggingMsgSender: public MsgSender\u003cCompany\u003e{//子类 public: void SendPlainMsg(){ SendPlain();// ==\u003e 这样直接调用是不行的，想想为什么？ } }; 上述注释中问题的原因：因为当全特化时可随意去除 MsgSender 内的函数，那么编译器无法确定基类是否仍有 SendPlain 这个方法。所以，编译器干脆拒绝在编译时去模板化基类中主动寻找继承而来的名称。 解决方法有三个： 使用 this-\u003e 调用SendPlain()，即可转化为运行时的问题，推荐这个方法； 使用 using MsgSender::SendPlain; 这样的 using 声明式，我们在 Rule 33: 避免遮掩由继承得来的名称 中用过这种方法，显式地告诉编译器扩大名称搜索范围，尝试去基类找找； 使用显式调用，即 MsgSender::SendPlain(); ，但这样做的坏处是直接断绝了 virtual 函数的灵活性和可能，不太推荐 ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_four/:1:3","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [4]","uri":"/posts/effective_cpp_part_four/"},{"categories":["C++"],"content":"R44 将与参数无关的代码抽离templates 通常，在非模板代码中，我们很容易看出重复的代码或者类，一般采用抽取公共部分为单独函数，或者采用类的继承/聚合等面向对象设计方式。 但是， template 有关的代码，有时代码重复是隐晦的。 这一节是为了解决 template 的 代码膨胀(code bloat) 问题，主要原则为 共性与差异性分析(commonality and variability analysis) 。 **某些不恰当的设计，会导致无畏的代码膨胀。**先看下方这个反面教材： template\u003ctypename T, std::size_t n\u003e class SquareMatrix { public: void invert() { std::cout \u003c\u003c \"size is \" \u003c\u003c n \u003c\u003c std::endl; }; }; 应用代码如下： //下面这2句，模板类实例化 1 次。 invert函数有 1 份实现 SquareMatrix\u003cint, 5\u003e mat5; SquareMatrix\u003cint, 5\u003e mat5New; //换成下面这2句，模板类实例化 2 次。invert函数有 2 份实现(问题暴露) SquareMatrix\u003cint, 5\u003e mat5; SquareMatrix\u003cint, 10\u003e mat10; 膨胀原因：在编译器看来，SquareMatrix\u003cint, 5\u003e 和 SquareMatrix\u003cint, 10\u003e 是2个完全不同的 C++ 类，实例化了2次，生成了这2个类。试想，如果代码中还需要其他 size 的SquareMatrix ，都会再生成一个新类，那么最后二进制文件就多了许多重复的目标代码，也就是膨胀。 如果能抽离参数相关代码，做到尺寸无关，便可解决这个问题。 解决思路：新建一个基类 BaseMatrix ，将尺寸参数传入给到基类作为成员变量保管，具体的数据可以用数组指针形式托管。不论有多少个与尺寸有关的派生类，一个 T 类型就只有一个基类，所以基类 baseInvert 函数实现只有一份。 基类实现代码如下： template\u003ctypename T\u003e class BaseSqaureMatrix { public: BaseSqaureMatrix(std::size_t n,T* dataPtr) :n_(n), dataPtr_(dataPtr) {} protected: void baseInvert() { std::cout \u003c\u003c \"invert: pData = \" \u003c\u003c dataPtr_ \u003c\u003c \" , size = \" \u003c\u003c n_ \u003c\u003c std::endl; } void SetDataPtr(T* dataPtr) { dataPtr_ = dataPtr; }; std::size_t n_ = 0; T* dataPtr_ = nullptr; }; 目标派生类实现如下： template\u003ctypename T,std::size_t n\u003e class SquareMatrix : public BaseSqaureMatrix\u003cT\u003e { public: SquareMatrix() :BaseSqaureMatrix\u003cT\u003e(n,nullptr), data_(std::shared_ptr\u003cT\u003e(new T[n*n])) { this-\u003eSetDataPtr(data_.get()); } void invert() { this-\u003ebaseInvert(); }// 参考Rule43 private: std::shared_ptr\u003cT\u003e data_ ;// RAII管理资源 }; 最终效果：相同 T 类型的template实例类(比如SquareMatrix\u003cfloat,5\u003e和SquareMatrix\u003cfloat,6\u003e)，共享实现码，祛除代码膨胀。 ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_four/:1:4","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [4]","uri":"/posts/effective_cpp_part_four/"},{"categories":["C++"],"content":"R45 运用模板成员函数接受所有兼容类型 众所周知，Base *pBase = pDerived; 这样普通类型裸指针的隐式转换是被 C++ 所认可的。 那么如果换成智能指针模板类 SmartPtr 和 SmartPtr 呢，还能这样不需额外配置就随意转换吗，答案显然是不行的（纵然 Base 和 Derived 是兼容类型也不行）。 本节，就采用模板成员函数来解决这一问题。 使用模板成员函数，接受所有兼容类型的“泛化构造”/“泛化赋值” 泛化(generalized)Copy构造，是指接受其他兼容类型进行模板函数的Copy构造。举例一个粗糙的 RAII 智能指针实现，代码如下👇: template\u003cclass T\u003e class SmartPtr { public: SmartPtr(T* origPtr) :originPtr_(origPtr) {} SmartPtr(const SmartPtr\u0026 smt) :originPtr_(smt.get()) {}// 正常Copy构造函数 //正常copy操作符函数: 简单演示，就浅复制吧 SmartPtr\u0026 operator=(const SmartPtr\u0026 smt) { originPtr_ = smt.get(); return *this; } template\u003cclass U\u003e //泛化构造函数 SmartPtr(const SmartPtr\u003cU\u003e\u0026 other):originPtr_(other.get()) { } //为了隐式转换不加 explict template\u003cclass U\u003e //泛化赋值操作符 SmartPtr\u0026 operator=(const SmartPtr\u003cU\u003e\u0026 other) { originPtr_ = other.get(); return *this; }//简单演示，浅复制 T* get() const { return originPtr_; } ~SmartPtr() { delete originPtr_;} private: T* originPtr_ = nullptr; }; 有上述的代码支持，我们就能写出如下的应用代码： class BaseObj{}; class DerivedObj:public BaseObj {};//DerivedObj是BaseObj兼容类型 SmartPtr\u003cDerivedObj\u003e smDerived(new DerivedObj()); SmartPtr\u003cBaseObj\u003e smBase(smDerived); SmartPtr\u003cBaseObj\u003e smBase2 = smDerived; 即使有 “泛化构造/ 赋值”，也需要正常的 Copy构造/赋值 注意，模板成员函数不会改变语言规则，也就是说“泛化构造”不能代替正常的 copy 构造函数。所以，需要同时声明正常的 Copy 构造函数和 Copy 赋值操作符函数。 ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_four/:1:5","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [4]","uri":"/posts/effective_cpp_part_four/"},{"categories":["C++"],"content":"R46 需要类型转换时请为模板定义非成员函数 有时我们希望 class 支持类型转换，类似本书的另外一节👉 Rule24:若所有参数皆需类型转换，请采用non-member 。 如果 Rule24 中的 Rational 类是 template 模板类，直接仿照 Rule24 利用 non-member 函数做混合运算是行不通的，原因是 template 实参推导是不采纳 “通过构造函数而发生的”隐式类型转换。 解决办法如下: 使用 “template class 内部的friend函数” 完成参数隐式转换 将 Rule24 的 non-member 的 operator *函数改为 inline-friend 函数，因为 template 实例化的时候需要找到该 friend 函数的定义实现，类外定义实现是会链接错误的，所以需要 inline 。 参考代码实现如下： template\u003ctypename T\u003e class RationalNew { public: RationalNew(T numerator = 0, T denominator = 1) :numerator_(numerator), denominator_(denominator) {} T numerator()const { return numerator_; } T denominator()const { return denominator_; } friend const RationalNew\u003cT\u003e operator*(const RationalNew\u003cT\u003e\u0026lhs, const RationalNew\u003cT\u003e\u0026rhs) { return RationalNew\u003cT\u003e(lhs.numerator()*rhs.numerator(),lhs.denominator()*rhs.denominator()); } private: T numerator_ = 0; T denominator_ = 1; }; 那么，对如下的应用代码，就使用自如了： RationalNew\u003cfloat\u003e oneHalf(1.0,2.0); RationalNew\u003cfloat\u003e res = oneHalf * 2; RationalNew\u003cfloat\u003e res2 = 3 * oneHalf; 若inline-friend函数体太大，可以抽离出类外辅助函数供inline调用 上述的 operator* 函数体只有一行，实现简单，但如果实现过程复杂代码量大，考虑 inline 带来的冲击以及代码可读性，可以抽取个函数出来供 inline-friend 调用。 修改方式如下： template\u003ctypename T\u003e class RationalNew { public: // 其他部分略。注意 operator* 函数体实现，改为调用doMultiply friend const RationalNew\u003cT\u003e operator*(const RationalNew\u003cT\u003e\u0026lhs, const RationalNew\u003cT\u003e\u0026rhs) { return doMultiply(lhs,rhs); } }; // 类外函数 doMultiply template\u003ctypename T\u003e const RationalNew\u003cT\u003e doMultiply(const RationalNew\u003cT\u003e\u0026lhs, const RationalNew\u003cT\u003e\u0026rhs) { return RationalNew\u003cT\u003e(lhs.numerator()*rhs.numerator(), lhs.denominator()*rhs.denominator()); } ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_four/:1:6","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [4]","uri":"/posts/effective_cpp_part_four/"},{"categories":["C++"],"content":"R47 请使用traits classes表现类型信息 C++ 中通常把 Traits 称为类型萃取技术，即：在 template 编程中，获取模板参数的类型信息，并在编译阶段针对不同的类型响应不同的处理。同时，这个技术要求对C++内置类型built-in 和 用户自定义user-defined 类型的表现必须一样好。 本节讨论此议题，并且以一个 C++ 标准的模板函数作为切入口进行讨论(std::advance，作用是兼容不同类型迭代器，用于后续取用指定偏移量的元素 )。 下方 “By the way” 环节简单展示了 std::advance 标准C++的声明式和基本用法： 👇（单击展开） By the way std::advance 需要的头文件包含为 #include\u003citerator\u003e ，再看下它的函数原型声明： template\u003c class InputIt, class Distance \u003e void advance( InputIt\u0026 it, Distance n ); // C++17 之前 template\u003c class InputIt, class Distance \u003e constexpr void advance( InputIt\u0026 it, Distance n ); // 自C++17 开始 再看下示例应用代码： std::vector\u003cint\u003e nums{1,2,3,4,5}; auto vIter = nums.begin(); std::advance(vIter, 3); std::cout \u003c\u003c \"after advance 3 offset: *vIter = \" \u003c\u003c *vIter \u003c\u003c std::endl; std::deque\u003cfloat\u003e fNums{0.1,0.2,0.3,0.4,0.5,0.6}; auto dIter = fNums.end(); std::advance(dIter,-2); std::cout \u003c\u003c \"after advance -2 offset: *dIter = \" \u003c\u003c *dIter \u003c\u003c std::endl; std::list\u003cchar\u003e chList{10,20,30,40}; auto cIter = chList.begin(); std::advance(cIter,2); std::cout \u003c\u003c \"after advance 2 offset: *cIter = \" \u003c\u003c int(*cIter) \u003c\u003c std::endl; 最终输出信息如下： after advance 3 offset: *vIter = 4 after advance -2 offset: *dIter = 0.5 after advance 2 offset: *cIter = 30 背景知识 👉 STL 迭代器按照功能分为 5 类，如下方表格所述： 描述 特点 应用 input 迭代器 只向前移动，一次一步，只读 istream_iterators output迭代器 只向前移动，一次一步，只写 ostream_iterators forward迭代器 只向前移动，一次一步，可读写 single-list iterator Bidirectional迭代器 双向移动，一次一步，可读写 set/multiset/map/multimap random-access迭代器 双向移动，一次多步，可读写 vetor/deque/string 如何设计一个 trait_class 并运用起来呢？ Step1： 确认若干个希望获取的类型信息 (本例只有一个 iterator 类别信息) 针对5 种迭代器分类，C++ 提供了专属的 卷标结构tag struct 加以区分(可以理解为编译期的枚举作用)，继承关系如下： struct input_iterator_tag{}; struct output_iterato_tag{}; struct forward_iterator_tag:public input_iterator_tag {}; struct bidirectional_iterator_tag: public forward_iterator_tag{}; struct random_access_iterator_tag: public bidirectional_iterator_tag{};` Step2：为该信息选一个名称 (例如 iterator_category) 那么 vector，set之类的目标容器类，如何与上述 iterator_tag 联系起来呢，需要一个名称传递出去： template\u003c ... \u003e //省略template 参数 class vector { public: class iterator{ public: // ps: C++11 之后使用的都是 using 定义式 typedef random_access_iterator_tag iterator_category; }; }; Step3：提供一个 template 类和一组特化版本（特化版本支持某些特殊情况） Traits 技术针对于迭代器的关键模板类 iterator_traits 定义如下： template\u003ctypename IterT\u003e // 注意：使用的是 struct struct iterator_traits { //这里的 IterT 就可以传入vector等容器类 typedef typename IterT::iterator_category iterator_category; } 注意，这里的 IterT 类型不能是指针类型，因为 pointer 不能后续嵌套。那么就需要一个特化版本了，代码如下： template\u003ctypename IterT\u003e struct iterator_traits\u003cIterT*\u003e{ // 指针类型和 random 迭代器类似 typedef random_access_iterator_tag iterator_category; } 至此，iterator_traits 的基本实现就完成了，也就是说 iterator_traits\u003cIterT\u003e::iterator_category 可以在编译期确定，接下来看看advance 函数如何使用它。 💗 正确做法：利用 函数重载overloading 技术，使得 trait classes 在编译期对类型执行 if … else 测试。 回顾我们的 advance 函数，只有迭代器类型 IterT 和 偏移量 DistT 。可以重载其子函数 doAdvance ，完成类型萃取后的自适应： template\u003ctypename IterT, typename DistT\u003e void doAdvance(IterT\u0026 iter, DistT d, std::random_access_iterator_tag) { iter += d; } template\u003ctypename IterT, typename DistT\u003e void doAdvance(IterT\u0026 iter, DistT d, std::bidirectional_iterator_tag) { if (d \u003e= 0) { while (d--) ++iter; } else { while (d++) --iter; } } template\u003ctypename IterT, typename DistT\u003e void doAdvance(IterT\u0026 iter, DistT d, std::input_iterator_tag) { if (d \u003c 0) {throw std::out_of_range(\"Negative distance\");}//ps: msvc中的C++实现是采用编译期间的asset判定 while (d--) ++iter; } 自然地，advance 函数的实现如下所示： template\u003ctypename IterT, typename DistT\u003e void advance(IterT\u0026 iter, DistT d){ doAdvance(iter,d, /*不论 category 的tag类型是什么，重载能找到匹配函数。即编译期的 if...else 测试*/ typename std::iterator_traits\u003cIterT\u003e::iterator_category()); } 至此，一个完整的 (以 iterator_traits 为例)Traits 技术实现与运用的过程就完成了。 By the way 关于 iterator_traits ，不止有 iterator_category，还有 difference_type, value_type, pointer, reference 等4个成员，详细可参考 cpp参考手册：iterator_traits 。 C++ 标准库中类似 iterator_traits 应用了 Traits 技术的模板有十几个。 举例常用的数值类型萃取 numeric_limits ，需要注意2个细节： 头文件是 #include; 成员函数 lowest/min/max 按照顺序，分别代表给定类型的 最低有限值、最小非负值、最大有限值。尤其是 float/double，取最小值是 lowest() ，不是 min(). ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_four/:1:7","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [4]","uri":"/posts/effective_cpp_part_four/"},{"categories":["C++"],"content":"R48 认识Template模板元编程 TMP，模板元编程template metaprogramming ，是编写 template-based C++ 程序并执行于编译期的过程。TMP 过程结束后，若干 C++ 源码会被 templates 具现化出来，便会一如往常地被编译。 TMP 有 2 个强大的作用： 可以完成非 TMP 的常规编程做不到的事情 比如代码生成，类型适配等。 可以将某些工作从运行期转移到编译期 可以将运行期的错误提前暴露在编译期，可以获得更小的可执行文件，更快地运行，更少地内存需求，缺点是明显增加编译时间。 TMP 已被证明是个“图灵完备”的机器，意思是它强大到可以计算任何事物。使用 TMP 可以声明变量、执行循环、编写及调用函数…等等。 比较特别的是，TMP 实现上述各类功能的方式不同于常规 C++ 程序。比如上一节 Rule47 中使用重载完成了编译期的 if…else 条件分支。TMP 循环功能也通常会使用 “递归具现化” 来完成的。 下方代码示范如何使用 TMP 的方式来计算阶乘： template\u003cunsigned n\u003e struct Factorial { // 递归的形式体现: f(n) = n * f(n -1) enum {value = n* Factorial\u003cn-1\u003e::value}; }; template\u003c\u003e struct Factorial\u003c0\u003e { // 模板全特化: 实际是初始化 f(0) = 1 enum {value = 1}; }; 那么阶乘计算在编译期就完成了，运行时就是直接取用了： std::cout \u003c\u003c \"Factorial(\" \u003c\u003c 5 \u003c\u003c \") = \" \u003c\u003c Factorial\u003c5\u003e::value \u003c\u003c std::endl; std::cout \u003c\u003c \"Factorial(\" \u003c\u003c 7 \u003c\u003c \") = \" \u003c\u003c Factorial\u003c7\u003e::value \u003c\u003c std::endl; ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_four/:1:8","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [4]","uri":"/posts/effective_cpp_part_four/"},{"categories":["C++"],"content":"CH8 定制new和delete ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_four/:2:0","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [4]","uri":"/posts/effective_cpp_part_four/"},{"categories":["C++"],"content":"R49 了解new-handler的行为 当 operator new 无法满足某个内存分配需求时，一般会抛出 std::bad_alloc 异常。 如果用 std::nothrow 修饰 new 操作符，使得内存分配阶段不会抛异常，失败了就返回 null 指针。举例 : int *pArr = new (std::nothrow) int[0x1fffffff]; //即使分配失败，也不抛异常，而是得到null指针. // nothroow-new 不能保证 class 后续的构造函数不抛异常 new-hanlder 的使用示例如下： //先定义一个函数 void OutOfMemTip() { std::cerr \u003c\u003c \"new memory fail,out of memory!\\n\"; std::abort();//终止程序，若调试模式会弹窗提示 } // 故意制造new失败的情形，程序会调用 OutOfMemTip，触发std::abort() std::set_new_handler(OutOfMemTip); int *pArr = new int[0x1fffffff];//约2GB,如果扛的住，调大这个数 可以看出这样的函数指针给了使用者非常大的设计弹性，可以做到以下事情： 提前申请内存，让 new_handler 触发下一次分配使用； 安装另一个 new_handler ，或许新的 handler 可以申请到内存； 卸载 new_handler ，只要传 null 指针即可； 手动抛 std::bad_alloc 的异常； 不返回，通常调用 std::abort() 或 std::exit() ; 🤔 我们思考另外一个问题：是否可以 让不同的 C++ 类拥有自己的 new-handler 呢？ C++ 标准机制是不支持的，我们可以自己实现。有两个实现途径，列举如下： 针对某个特定类 ，类内重载 static 类型的 operator new 以及 set_new_handler方法 具体实现略，只想指出这样做法有个明显弊端，就是每个类都得这么做，比较麻烦，也容易代码冗余。 使用 CRTP 方法（即 怪异的循环模板模式curiously recurring template pattern ）将上述方法 1 塞进 template 类 这样做的好处是使用模板类赋予上述 operator new 和 set_new_hanler 的操作，使用起来方便。 CRTP 方法中的基类 NewHandlerSupport 实现如下 👇(点击打开折叠) ： template\u003ctypename T\u003e class NewHandlerSupport { public: static std::new_handler set_new_handler(std::new_handler p)noexcept { std::new_handler oldHandler = currentHandler_; currentHandler_ = p; return oldHandler; } static void* operator new(std::size_t size) throw(std::bad_alloc) { std::new_handler oldHandle = std::set_new_handler(currentHandler_); void *res = ::operator new(size); //new完后复原global-new-handler std::set_new_handler(oldHandle);//原书使用RAII手法在还原这个handler，这里作用类似 return res; } private: static std::new_handler currentHandler_;//初始化动作放到类外cpp文件里去 }; 那么目标类 TestNewHandler 只要基于 CRTP 方法继承于基类就可以了，实现如下： class TestNewHandler : public NewHandlerSupport\u003cTestNewHandler\u003e { //不必声明 set_new_handler 或 operator new }; //最终应用时也非常简单 TestNewHandler::set_new_handler(OutOfMemTip); TestNewHandler* pTestHandle = new TestNewHandler(); ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_four/:2:1","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [4]","uri":"/posts/effective_cpp_part_four/"},{"categories":["C++"],"content":"R50 了解new和delete的合理替换时机 替换编译器提供的 operator new 和 operator delete 的 常见理由 如下： 检测运用上的错误 自定义的new/delete可以很方便地校验实际控制的区段内存，比如可以在目标区块前后额外空间添加内存签名(比如写入特定 int 值)，监测越界的问题。 越界分2种：underruns (区块内存起点之前) 和 overruns (区块内存末尾之后)。 时间或内存使用的优化 通用的 new/delete 需要适用各种分配形态和场景，对于内存碎片或时间性能都是中庸水平。 对特定的需求和场景，定制化地内存管理会有很好的优化效果。 收集内存使用的统计数据 对内存分配细节的把控，例如分配区块的大小分布、存续周期、FIFO/LIFO次序分配回收、内存峰值等情况。 弥补默认内存分配器的 非最佳对齐位suboptimal alignment 例如x86体系结构CPU上访问double都是8bytes对齐，如果能在内存分配时就做好内存对齐，可提升访问效率。 将相关对象成簇集中 比如已知某个数据结构往往一起使用，那么分配的时候应该尽量让所有数据的内存集中一些，避免频繁触发 换页中断page faults ，提升访问效率。 其他的非传统行为 想完成一些系统编译器办不到的事情。比如希望分配释放共享内存的区块，但是只有 C-API 能做到，那就需要定制版的 new/delete 去包裹封装这样的API。 ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_four/:2:2","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [4]","uri":"/posts/effective_cpp_part_four/"},{"categories":["C++"],"content":"R51 编写new和delete时需固守常规 上一个条款讲了重写 new/delete 的原因，这一节将讲述具体需要遵守的几个规则。 正确处理 new 失败的情况 如果分配正常，直接返回区块对应的指针即可。可如果失败，就必须得正确调用 new-handler 函数，参考 R49 了解new-handler的行为。 如果要求分配 0 byte 空间 C++规定，如果客户要求分配 0 byte 内存申请，就返回 1byte 空间申请，并返回该有效地址。 理解 operator new 内部的无穷循环 operator new 有个 while(true) 循环，分配成功可以return，或由 new-handler 为 nullptr 时抛出 std::bad_alloc 异常。伪代码pseudocode 如下： void* operator new(std::size_t size) throw(std::bad_alloc){ using namespace std; if (size == 0){ size = 1; } while (true){ 尝试分配 size bytes; if (分配成功) return target_pointer; new_handler globalHandler = set_new_handler(0); set_new_handler(globalHandler);//分配失败了 if(globalHandler) (*globalHanler)(); else throw std::bad_alloc(); } } 当基类的 operator new 被子类继承时 当基类被继承时，成员 operator new 也一起被继承了，要注意的是基类和子类的 size 通常是不一样的。推荐实现如下： class Base{ public: static void* operator new(std::size_t size)throw (std::bad_alloc){ if (size != sizeof(Base)) return ::operator new(size);//子类走这里 } }; 值得注意的是，operator new[] 不能这样在基类中区分。因为即使在Base类，也无法假定每个元素是 sizeof(Base)，通常还有额外内存空间来保存元素个数。 operator delete 的注意事项 C++ 需要保证 “删除NULL指针永远安全”，所以必须兑现这个规则。针对null指针，就什么也不做，直接return。 ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_four/:2:3","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [4]","uri":"/posts/effective_cpp_part_four/"},{"categories":["C++"],"content":"R52 写了placement-new 也要写placement-delete placement-new，是指“除size参数以外，接受一个额外参数参与构造”的 特定 operator-new。 其中，“接受一个指针指向对象该被构造之处”是最常使用的 placement-new，即“一个特定位置上的new”，形式如下为： //这个特殊的也是最常涉及的 placement-new 已被纳入C++标准程序库 void * operator new(std::size_t size,void* pMemory) noexcept; 先暂时考虑一个调用了placement-new的正常构造过程： // 有这样一个placement-new,接收一个ostream来log分配时的相关信息 void* operator new(std::size_t size,std::ostream\u0026 logStream) throw (std::bad_alloc); Widget* pw = new (std::cerr) Widget;//传入ostream 对于任何的new对象构造过程，至少可分为下述2个过程： operator new 分配对象需要的内存空间； 执行对应的构造函数 如果上述过程 1 成功了，过程 2 抛异常，已经申请的内存就需要及时回收避免memory-leak，运行期系统就会尝试寻找并调用“额外参数个数和类型都与operator new 一致的operator delete”，完成内存回收。 那么上述事实，就是 placement-new 和 placement-delete 需要成对实现的理由。 针对上例额外参数是 std::ostream 的operator new，operator delete，类声明形式如下: class Widget{ public: static void* operator new(std::size_t size,std::ostream\u0026 logStream) throw (std::bad_alloc); //不抛异常时，最后对象析构时正常调用这个 static void operator delete(void *pMemory) noexcept; //new抛异常时，调用这个 额外参数个数和类型都一致的 placement-delete static void operator delete(void *pMemory,std::ostream\u0026 logStream); }; ⚠️ One More Thing : C++ 在global 作用域提供以下形式的 operator new: void * operator new(std::size_t size) throw (std::bad_alloc); void * operator new(std::size_t size,void*) noexcept; void * operator new(std::size_t size,const std::nothrow_t \u0026) noexcept;//见条款49 new-Handler的行为 😎 所以，如果在class 内声明了上述 operator new， 则global作用域的 operator new 会被名称遮掩。 🤔 解决办法：在基类对global作用域的 ::operator new 进行封装调用，然后在子类中使用using 声明式破除名称遮掩。 ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_four/:2:4","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [4]","uri":"/posts/effective_cpp_part_four/"},{"categories":["C++"],"content":"CH9 杂项讨论 ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_four/:3:0","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [4]","uri":"/posts/effective_cpp_part_four/"},{"categories":["C++"],"content":"R53 不要轻易忽略编译器的警告 严肃对待编译器发出的警告信息 编译器发出的警告信息，经常会被忽略。No-Warning是值得追崇的，除非你对编译 warning 信息是充分了解并确信是无关紧要的。 下面举一个较为常见的例子： class BaseWarn { public: virtual std::string GetWarnInfo() const { return \"Base\"; } }; class DerivedWarn :public BaseWarn { public: virtual std::string GetWarnInfo() {//缺了const return \"Derived\"; } }; 如上代码所示，没有成功实现虚函数重写，而是造成了“名称遮掩”。 这样的错误较为隐蔽，有些编译器会给出警告信息，有些甚至连警告信息都没有（Ps：我自行测试了VS2017，没有warning信息）。 如果编译器给出了警告信息，请认真对待。 不要过度依赖编译器的报警能力 还是上面的例子，不同编译器处理态度不同，警告信息甚至可能换个编译器就消失了。 ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_four/:3:1","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [4]","uri":"/posts/effective_cpp_part_four/"},{"categories":["C++"],"content":"R54 熟悉包括TR1在内的标准程序库 C++ Technical Report 1 (TR1) 并非标准，而是一份草稿文件，对C++标准库的第一次扩展，它提出了对C++标准函式库的追加项目。 这份文件的目标在于「为扩充的C++标准函式库建立更为广泛的现实作品」。 我的理解：200x 年发布的 C++ 称为 “C++0x”，持续修改中，所有修改将合并于 TR1，最终绝大部分都定版、收录发布于 C++11。 TR1详细叙述了许多新特性，都放在 std::tr1 命名空间内（以下简称 tr1:: ），列举如下 智能指针：tr1::shared_ptr 和 tr1::weak_ptr ，RAII 基础，不赘述； tr1::function：表示 可调用物callable entity，即任何函数或函数对象，只要签名一致即可； tr1::bind：对函数调用的封装，将函数和其参数绑定一起； Hash tables：采哈希表形式参与构成，名称以 unordered_ 开头的 set/multiset/map/multimap； 正则表达式：头文件在 ； Tuple 元组(或叫变量组)：不定长变量组，是 std::pair 的一种泛化； tr1::array: 和 C 语言数组一样，是个定长数组，包裹了 STL 用法； tr1::mem_fn: 传入一个函数指针（支持对成员函数取址）作为入参，构造一个函数对象，进而调用，类似地还有 mem_fn_ref; tr1::reference_wrapper：“封装引用为一个对象”，通常用于对引用进行封装然后装入标准容器(直接往容器塞引用是不行的)； 随机数生成工具：random_device，可以直接生成或者使用不同的 随机数引擎 和 随机分布算法进行生成，头文件是 ； 数学特殊函数：包括Laguerre多项式、Bessel 函数、完全椭圆积分等特殊数学函数，注意，这些 在 C++17 才引入C++标准，可参考cppreference: special math ，头文件在 ； C99兼容扩充 ：C99标准是C语言的官方标准第二版，1999年发布，TR1对其进行了兼容； Type traits 类型萃取：template编程的精华之一，参考 Rule47:使用trait表现类型信息，头文件为 \u003ctype_traits\u003e，功能十分丰富，可参考cppreference: type_traits； tr1::result_of ：可以对函数返回值做推断，得到返回值类型，头文件为 \u003ctype_traits\u003e ，示例用法如下： c++ // 假设有个函数 double calcDaySale(int); std::tr1::result_of\u003ccalcDaySale(int)\u003e::type x = 3.14;//x就是double类型. C++11中直接 std::result_of 更详细的定版TR1信息可以参考Effective-C++：TR1 information。 ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_four/:3:2","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [4]","uri":"/posts/effective_cpp_part_four/"},{"categories":["C++"],"content":"R55 让自己熟悉Boost Boost是一个C++开发者集结的社群，也是个可自由下载的程序库集，网址是 http://boost.org。 其特殊性：和C++标准委员会有着独一无二的密切关系，且具有很深影响力；接纳程序库非常严谨，需要一次以上的同行专家评审。 Boost 程序库集可处理的场景有许多（且囊括了TR1的实现），可区分出数十个类别，并且还在持续增加，列举一小部分如下： 字符串与文本处理 容器 函数对象与高级编程 泛型编程：覆盖一大组 traits classes 模板元编程：覆盖一个针对编译器 assertions 而写的程序库，以及 Boost MPL程序库 数学和数值:包括有理数、八元数、四元数、公约数、多重运算、随机数等等 正确性与测试性 数据结构 语言间的支持：允许 C++ 和 Python 之间的无缝互联 内存：覆盖Pool程序库和智能指针等 杂项：包括 CRC 校验、日期和时间的处理、文件系统等内容 总的来说，Boost 是一个社群，也是个网站。致力于免费、源码开放、同行复审的 C++ 程序库开发，非常值得经常访问与学习。 ref: [1]. https://blog.csdn.net/cltcj/category_12098441.html [2]. https://kissingfire123.github.io/2022/05/17_effective-c-%e4%b9%8b%e9%98%85%e8%af%bb%e6%80%bb%e7%bb%93%e5%9b%9b/ ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_four/:3:3","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [4]","uri":"/posts/effective_cpp_part_four/"},{"categories":["C++"],"content":" 前言 Effective-C++总结系列分为四部分，本文为第二部分，涉及原书第3~4章，内容范围Rule13~25。为方便书写，Rule13简写为R13。 Effective-C++系列List 本博客站点系列内容如下： 💡 Effective C++(第3版)精读总结(一) 💡 Effective C++(第3版)精读总结(二) 💡 Effective C++(第3版)精读总结(三) 💡 Effective C++(第3版)精读总结(四) 由于原书在C++11之前写成，有些现代C++特性不会提及，所以会根据本人开发经验新增一些个人感悟👉By the way环节。 ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_three/:0:0","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [3]","uri":"/posts/effective_cpp_part_three/"},{"categories":["C++"],"content":"CH5. 实现 ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_three/:1:0","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [3]","uri":"/posts/effective_cpp_part_three/"},{"categories":["C++"],"content":"R26 尽可能延后变量定义式的出现时间 尽可能延后变量定义式的出现，可增加程序清晰度和效率 定义后，在使用前就遭遇抛异常 这种情况，如果是定义了对象ObjectA a，便白白地浪费了对象a的构造和析构成本。 不只是延后变量定义到使用时，而是尽量延后到能给它初值时 std::string encryptPassword(const std::string\u0026 password){ if(password.length() \u003c 8){ throw std::logic_error(\"Password is too short\"); }// 考虑1：在异常之后定义变量 std::string encrypted(password);//考虑2：定义延后至变量能赋初值的时机 encrypt(encrypted); return encrypted; } 思考变量定义是否该在循环内 方法A：定义于循环外 Widget w; for(int i = 0 ; i\u003c n; ++i) { w = foo(i); // other... } 方法B：定义于循环内 for (int i = 0; i \u003c n; ++i) { Widget w(foo(i)); // other... } 究竟是A还是B方法好，取决于 一个赋值成本和一组构造+析构成本，这2者之间，如果是赋值成本低，那么A更好，否则B更好。 ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_three/:1:1","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [3]","uri":"/posts/effective_cpp_part_three/"},{"categories":["C++"],"content":"R27 尽量少做转型动作 通常的转型是可能会这样写：函数风格的int(expression)或者C风格的(int)expression，这都被成为“旧式转型”。 在C++中，有4种新式转型操作符： const_cast (expression) 作用是移除变量的常量性(cast away the constness)，是唯一有此能力的操作符。 dynamic_cast(expression) 作用是“安全向下转型”(safe downcasting)，决定某个对象是否属于某继承体系。耗费重大运行成本（原因：需要查询RTTI信息，而且不同编译器实现的方法和效率有所不同）。 reinterpret_cast(expression) 执行低级转型，实际结果取决于编译器，移植性差。（比如int* 转为int）要清楚自己在做什么，慎用。 static_cast(expression) 强迫隐式类型转换，代替C风格的\"旧式转换\"。也可以给变量加上const特性。 新式转换的好处：很容易在代码找到“类型系统在何处转变或破坏”；对const特性的严控，让类型系统更健壮。 派生类里直接调用基类成员函数时，不要用转型 class SpecialWindow:public Window{ public: virtual void onResize(){ Window::onResize();//不要使用 static_cast\u003cWindow\u003e(*this).onResize(); } }; 关于dynamic_cast需要注意的 如何替代和避免 一般是持有一个Base *pBase，但是指向的是DerivedObj，于是转型为pDerived 可以这样修改： 修改设计，窄化类型，持有一个pDerived即可；或者将想做的事放到虚函数中，利用多态去完成。 避免串联 避免下方这样的代码，一连串的dynamic_cast： class Window{ ... }; // 定义子类 SpecialWindow1,SpecalWindow2,SpecialWindow3 Window* winPtr; // 省略winPtr的其他操作 ... if(SpecialWindow1 *psw1 = dynamic_cast\u003cSpecialWindow1*\u003e(winPtr)){ ... } else if(SpecialWindow2 *psw2 = dynamic_cast\u003cSpecialWindow2*\u003e(winPtr)){ ... } else if(SpecialWindow3 *psw3 = dynamic_cast\u003cSpecialWindow3*\u003e(winPtr)){ ... } 这样的代码又大又慢，每次继承体系有所改变，代码就需要重新检阅判断。这样的代码应该用“基于virtual函数调用”取代它。 By the way 自 C++11 起，针对智能指针 shared_ptr 的转型，推出了另外 4 个模版函数： std::static_pointer_cast 函数的原型声明为： template\u003c class T, class U \u003e std::shared_ptr\u003cT\u003e static_pointer_cast( const std::shared_ptr\u003cU\u003e\u0026 r ) noexcept; 含义以及应用场景与 static_cast 类似，比如子类型指针转为父类型： auto basePtr = std::make_shared\u003cBase\u003e(); auto derivedPtr = std::make_shared\u003cDerived\u003e(); basePtr = std::static_pointer_cast\u003cBase\u003e(derivedPtr); 或许我们会有疑问，是否有必要用这个函数进行转型呢，如下实现不是一样的吗? basePtr = std::shared_ptr\u003cBase\u003e(static_cast\u003cBase*\u003e(derivedPtr.get())); 🤔 当然不一样，static_cast\u003cT*\u003e((U*)nullptr)是未定义行为，而且就语法描述上来看，哪个更简洁不言自明。 另外，自 C++20 起支持右值引用，也就是如下形式： template\u003c class T, class U \u003e std::shared_ptr\u003cT\u003e static_pointer_cast( std::shared_ptr\u003cU\u003e\u0026\u0026 r ) noexcept; std::dynamic_pointer_cast 含义以及应用场景与 dynamic_cast 类似，用法传参与 std::static_pointer_cast 类似，且自 C++20 起支持右值引用，不赘述。 std::const_pointer_cast：与前 2 者类似，不赘述。 std::reinterpret_pointer_cast：与前 3 者类似，不赘述。 ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_three/:1:2","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [3]","uri":"/posts/effective_cpp_part_three/"},{"categories":["C++"],"content":"R28 避免返回handles指向对象内部成分 这里的handles（号码牌）包括指向对象内部的指针、迭代器、引用。 以下讲述当返回对象内部的handles时，存在的2个问题： 可能会破坏封装性 考虑一个场景：public函数返回一个private成员的非const引用，就让外界有了修改private的机会，破坏了封装性。 此时，需要将非const引用改为const引用，只读属性。 struct Pixel { float r,g,b; } class Image { public: //注意：后面这const只保证成员变量vPixPtrs_不改 Pixel\u0026 GetThePixel(int idx) const{ return vPixPtrs_[i];}//隐患：其实外部调用者仍能直接修改Pixel的rgb值 // 上一句的返回值应该改为 \"const Pixel\u0026\" private: std::vector\u003cstd::shared_ptr\u003cPixel\u003e\u003e vPixPtrs_; } 可能会引起“空悬handles” 即使用const解决了封装性的问题，因为很容易出现**“handles比其所指对象更长寿”**，可能存在对象已析构，但handles还留存的问题。尤其是临时变量的析构，不太容易察觉。 class SceneGraph{ ... }; const Image CaptureImage(const SceneGraph\u0026 graph); //那么调用方可能会这样使用 SceneGraph Grap; //下面这句之后，Image临时对象被销毁，pPix指向一个不存在的对象 const Pixel *pPix = \u0026(CaptureImage(Grap).GetThePixel(0)); 注意，CaptureImage的确能返回一个临时Image对象，能成功调用GetThePixel，但这句结束后，临时对象立马会被销毁，造成空悬现象，或叫虚吊(dangling) ！ ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_three/:1:3","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [3]","uri":"/posts/effective_cpp_part_three/"},{"categories":["C++"],"content":"R29 为“异常安全”而努力是值得的 “异常安全”是指，当异常抛出时，代码依然能做到如下2点： 不泄露任何资源 包括内存资源，锁资源。 不允许数据败坏 不会因为异常而导致空悬指针等未定义行为。 考虑下方的示例代码，（如果new Image抛std::bad_alloc异常）则会同时违背了上述2条： class PrettyMenu{ private: Mutex mutex_; //互斥器 Image* bgImage_ = nullptr; int imageChangeCnt_ = 0; public: void PrettyMenu::changeBackground(std::ifstream\u0026 imgSrc){ lock(\u0026mutex_);// 这个可以改为RAII的锁，来保证异常安全 delete bgImage_; ++imageChangeCnt_; //这里new Image抛异常，导致无法解锁；且bgImage_指向资源已经释放，空悬指针 bgImage_ = new Image(imageSrc_); unlock(\u0026mutex_); } }; 异常安全的3个等级 异常安全的函数，有3个等级的异常安全保证，会满足三者之一： 基本承诺 如果异常被抛出，程序内的任何事务仍然保持在有效状态下，也没有任何数据败坏。比如上例中如果抛异常，会另外添加实现，使bgImage_持有某个默认图像，或保持原值，让程序继续有效运行。 强烈保证 如果异常被抛出，程序状态不改变。这样的函数要么成功，要么退回到执行前的状态。 上述案例则应该会被修改成如下形式： class PrettyMenu{ private: std::shared_ptr\u003cImage\u003e bgImage_; //RAII避免了异常发生时的资源泄漏和数据败坏 //... 省略其他成员 public: void PrettyMenu::changeBackground(std::ifstream\u0026 imgSrc){ CLock ml(\u0026mutex_);//RAII封装的Lock类，详细可参考 阅读总结(二)-Rule14 bgImage_.reset(new Image(imgSrc));//若new失败，则不会reset ++imageChangeCnt_;//把事情做完再++count } }; 不抛异常 在原书中，这个“No Throw”不是绝对不抛异常，而是一旦意外抛异常，就会调用unexpected函数进而abort（例如int doSomething() throw();//空白的异常明细）。 By the way 原书中例子的 throw() 在不同编译器表现不一致，现在已经 不推荐使用。 更详细资料可参考A Pragmatic Look at Exception Specifications和Should I use an exception specifier in C++ 在C++11中，有了更可靠有效的关键字noexcept，使用也很简单，有操作符和异常提示符两种作用，下方展示简单用法： void f() noexcept; // 函数 f() 不会抛出 void (*fp)() noexcept(false); // fp 指向可能会抛出的函数 void g(void pfa() noexcept); // g 接收指向不会抛出的函数的指针 // typedef int (*pf)() noexcept; // 错误 更详细的noexcept介绍可以访问cppreference：noexcept操作符和cppreference：noexcept异常说明符 使用copy-and-swap保障异常安全 copy-and-swap技术：先拷贝一份想修改的对象，等修改彻底完成后（过程中不抛异常），再与原对象交换。 为了更形象展示这一过程，使用pIml手法对bgImage_封装一下： struct ImgPimpl{ //选用struct而非Class：方便；最后被private成员形式使用，封装性不用担心 std::shared_ptr\u003cImage\u003e bgImage_; int imageChangeCnt_ = 0; }; 那么PrettyMenu类可以改为如下： class PrettyMenu{ private: Mutex mutex_; std::shared_ptr\u003cImgPimpl\u003e pImpl_; public: //构造略 void PrettyMenu::changeBackground(std::ifstream\u0026 imgSrc){ using std::swap; //参考 阅读总结(二)-Rule25 CLock ml(\u0026mutex_);//RAII封装的Lock类，详细可参考总结(二)-Rule14 std::shared_ptr\u003cImgPimpl\u003e pNewCopy(new ImgPimpl(*pImpl_)); pNewCopy-\u003ebgImage_.reset(new Image(imgSrc)); //修改副本 ++pNewCopy-\u003eimageChangeCnt_; swap(pImpl_,pNewCopy);//改完之后swap } }; 异常安全的连带影响(side effects) 函数提供的“异常安全保证等级”只取决于其调用的各个子函数的“最不安全者”。 考虑以下函数SomeFunc代码： void SomeFunc{ ... // 对local状态做一份副本 f1(); f2(); ... //将修改后的状态置换过来 } 分析：显然copy-and-swap在尽力强烈保证异常安全，但是，f1或者f2的异常安全如果比较低，那么可能需要单独对f1，f2进行copy-and-swap，来尝试保证“强烈异常安全”；即使如此，如果f1能成功做了修改，但是f2修改失败了并回退，那么f1、f2整体看起来还是“改了一部分”。 这也告诫我们，如果引入了异常不安全的旧代码，那么这种特性会波及其他代码。 就设计者而言，只能根据实际情况，尽可能保证“异常安全”，选择3个异常安全等级之一实施。 ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_three/:1:4","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [3]","uri":"/posts/effective_cpp_part_three/"},{"categories":["C++"],"content":"R30 透彻了解inline的里里外外 inline是C++的关键字，表示内联函数。直接在对应位置展开代码，免去函数调用的开销，难以避免 “代码膨胀”问题。 使用inline时应该注意以下问题： inline只是对编译器的申请 inline只是对编译器的申请/建议，不是强制命令，编译器有权利 对其认为不适合inline的函数拒绝inline。 （原书说：如果编译器拒绝，通常它会给出warning信息。实际本人实测VS2017没看到） inline有2种申请方式 ： 在函数定义 时使用关键字inline显式强调 实现在Class内的成员函数或friend函数，属于隐式inline inline和Template没有任何必然联系 虽然有不少简短的Template函数是带有inline（例如下方的std::max），但不是必然为之，两者没有因果关系。 template\u003ctypename T\u003e inline const T\u0026 std::max(const T\u0026 a, const T\u0026 b){ //可以申请inline，但不是必须申请 return a \u003c b ? b : a; } 编译器拒绝复杂函数进行inline 复杂函数的inline会带来较严重的“代码膨胀”问题，并且可能会更慢，因为增加了运行时的“额外换页”行为，降低了指令cache命中率。 inline函数内不要出现循环或递归 虚函数也不适合做inline 因为inline是编译期间决定的事，而虚函数是运行时决定的事，两者就不是同一个场景的。 构造/析构函数也不适合做inline 编译器可能会在构造/析构函数内部做精妙复杂的异常处理；以及在继承体系下，Base类函数体到处inline膨胀。 以函数指针形式的调用通常不能inline 对绝大多数编译器而言，是否inline是compile阶段决定的事情，少数编译器放到了link阶段。 讨论大多数情况：需要在编译时得知inline的本体，而函数指针办不到，示例代码如下： inline void f() {...} //假设编译器有意愿inline “对f的调用” void (* pf)() = f;//pf 执行f ... f(); //这个调用将被inlined，因为是个正常调用 pf(); //这个很可能不被inlined 过度inline对调试和发布带来困难 inline是代码嵌入与展开，而非函数调用，所以某些编译器不支持inline的单步Debug（就像宏展开一样不支持调试）；另外，inline只要已修改，涉及调用它的代码全都要编译，如果是non-inline则可能只需要重新link即可。 ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_three/:1:5","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [3]","uri":"/posts/effective_cpp_part_three/"},{"categories":["C++"],"content":"R31 将文件间的编译依赖关系降至最低 C++的Class定义式包括了成员变量，假设某成员变量是类对象ClassObjA a，如果ClassObjA类的内部实现发生了改变（哪怕这个ClassObjA.h内只在某处加了一个空格 ），那么include了ClassObjA.h的所有.h文件.cpp文件都会重新编译。 👆这就是由“编译依赖”关系带来的问题。 使用 PIMPL 手法(pointer to implementation)可以很好地分离声明和定义： //Person.h文件 不需要include \"PersonImpl.h\"和\"BirthDay.h\" class PersonImpl; class BirthDay;// 前置声明代替include class Person { public:// 构造函数这里放实现无所谓，因为是函数指针，不需知道PersonImpl本体实现 Person(const std::shared_ptr\u003cPersonImpl\u003e\u0026 pImpl);//构造函数的实现也放到cpp里去 const BirthDay\u0026 GetBirthDay();// 注意：这里只声明，把实现部分放到cpp里 std::string GetName();//实现细节由pImpl_转发实现 private: std::shared_ptr\u003cPersonImpl\u003e pImpl_; }; //Person.cpp文件 #include \"PersonImpl.h\" //在\"PersonImpl.h\"文件内include那个\"BirthDay.h\" #include \"Person.h\" 注意：Impl用法，相关的头文件里不要放置任何函数实现代码 。 上述做法可以让使用Person类的客户不需要再关心PersonImpl以及BirthDay的实现细节了，做到了“接口与实现分离”，关键点在于把“定义的依赖性” 换成 $\\Rightarrow$ “声明的依赖性”。 这里突出了如何最小化编译依赖性的本质：让头文件尽可能自我满足，如果不行，也要依赖于其他文件的声明式而非定义式。 具体到设计策略上，有以下几种做法： 如果能用object references 或 object pointers完成任务，就别用objects 如果要定义某类型的objects，就要使用定义式，指针和应用则可以只用声明式。 尽量以class声明式替换class定义式 函数声明种的Class类型可以只用声明式，即使以by-object-value形式传值也是如此。 为声明式和定义式提供不同的文件 比如Date类，分为只包含声明式的\"Datefwd.h\"和包含定义式的\"Date.h\"，那么使用时用声明式头文件代替前置声明，在需要应用代码client.cpp里include定义式头文件。这种方式在标准库里采用较多，参考和,,等。 By the way C/C++可以使用编译器预处理指令#pragma message，打印出该文件是否参与此次编译，以及参与编译时被哪个文件所依赖。 //比如可以在 testEffective.h 文件内加上这句，就能在编译输出信息里看到打印信息，观察到依赖关系 #pragma message(\"testEffective.h 参与重新编译\") //还可以用于测试某些宏是否真的生效，有时IDE的高亮显示不准确而令人生疑。 关于头文件include的其他编写规范，可以参考：Google-C++风格指南：1.头文件 使用 Interface Class 也能做到接口和实现的真正分离： 这种方式常见于输出动态库给到客户使用，客户能见到接口定义和使用，但无法看到内部实现。 用法较为常见，不赘述，直接show-code： //VirtualPerson.h //和 lib文件一起提供给到客户 class VirtualPerson { public: //create的返回值还可以根据需求，换成RAII的智能指针 static VirtualPerson * create(int level, int salary); virtual int Level() = 0; virtual int Salary() = 0; virtual ~VirtualPerson();// avoid memory leak }; //VirtualPerson.cpp //源码不提供给客户，而是编译好的二进制 lib文件 VirtualPerson* VirtualPerson::create(int level, int salary) { if (level == 3) { //工厂方法，还可以生成其他子类 return new Engineer(level, salary); } return nullptr; } VirtualPerson::~VirtualPerson() { } // Engineer.h //Engineer也是参与编译到 lib文件中 class Engineer: public VirtualPerson { public: Engineer(int level,int salary); virtual int Level() ; virtual int Salary() ; private: int level_ = 3; int salary_ = 0; }; ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_three/:1:6","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [3]","uri":"/posts/effective_cpp_part_three/"},{"categories":["C++"],"content":"CH6. 继承与面向对象设计 ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_three/:2:0","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [3]","uri":"/posts/effective_cpp_part_three/"},{"categories":["C++"],"content":"R32 确定你的public继承塑造出is-a关系 原书标题：Make sure public inheritance models “is-a”. 侯捷老师翻译为“塑模”，我个人更愿意称为“塑造”。 “public继承”意味着is-a is-a，即“是一种”，就是说，适用于Base Class身上的每一件事，也一定适用于Derived Class身上。 By the way 面向设计对象的设计有著名的5大原则， SOLID 原则，每个字母分别代表一种原则： S–单一责任原则(SRP) –Single Responsibility Principle O–开放封闭原则(OCP)– Open-Closed Principle L–里式替换原则(LSP)– Liskov Substitution Principle I –- 接口分离原则(ISP)–Interface Segregation Principle D–-依赖倒置原则(DIP)– Dependency Inversion Principle 更详细的叙述可以参考：腾讯云：SOLID原则 本节条款的中心思想即里氏替换原则：一个对象出现的地方都可以由其子类代替并且不会出错。 继承关系有时候听起来很好理解，比如 Class Student: public Person理所应当，但有时也会导致误解。比如企鹅属于鸟类，但企鹅不会飞，那么基类Bird::Fly方法又当如何处理，下方满足设计意图： class Bird{ //... 不声明Fly()方法 }; class FylingBird:public Bird{ public: virtual void Fly(); }; class Penguin: public Bird{ //... 不声明Fly()方法 }; // 注：如果Bird类以及子类都不考虑Fly()方法，那么Penguin直接继承于Bird即可 还有另一种场景，父类和子类对于同一个方法的数据修改规则不同，导致了继承体系的缺陷。 比如Class Square:public Rectangle $\\rightarrow$ 正方形继承于长方形，但是考虑这样一个类外方法: void makeBigger(Rectangle\u0026 r){ //普通非成员函数 int oldHeight = r.height(); r.setWidth(r.width() + 10);//如果r是Squqre，可能内部自动就长宽一起变了 assert(r.height() == oldHeight);//这个assert对于正方形就不合适了,贸然去除又违背设计本意 } 应对上述这样的情况，就需要修改设计或修改继承体系了。 ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_three/:2:1","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [3]","uri":"/posts/effective_cpp_part_three/"},{"categories":["C++"],"content":"R33 避免遮掩由继承得来的名称 首先，什么是名称的遮掩，通俗地说，是指由于作用域不同带来的变量名覆盖。考虑下方代码： int x = 10; void someFunc(){ double x = 0.1; std::cout\u003c\u003c\"x is\" \u003c\u003c x \u003c\u003c std::endl; // local作用域找到了x，直接覆盖全局的x，输出0.1 } 那么如果将继承体系考虑进来呢：Derived的作用域会覆盖Base的作用域，包括virtual和non-virtual。考虑下方代码： class Base { public: virtual void mf1() = 0; virtual void mf1(int x) { std::cout \u003c\u003c \"Base::mf1():x =\" \u003c\u003c x \u003c\u003c std::endl; } virtual void mf2() { std::cout \u003c\u003c \"Base::mf2()\\n\"; } void mf3() { std::cout \u003c\u003c \"Base::mf3()\\n\"; } void mf3(int x) { std::cout \u003c\u003c \"Base::mf3():x =\" \u003c\u003c x \u003c\u003c std::endl; } virtual ~Base() {} }; class Derived :public Base { public: virtual void mf1() { std::cout \u003c\u003c \"Derived::mf1()\\n\"; } void mf3(){ std::cout \u003c\u003c \"Derived::mf3()\\n\"; } }; 很明显存在名称遮掩的问题，Derived的mf1，mf3会遮掩子类的所有同名函数，测试结果如下： Derived d; d.mf1(); //OK，输出: Derived::mf1() //d.mf1(100); 编译报错，因为名称被遮掩 d.mf2(); //OK，输出: Base::mf2() d.mf3(); //OK，输出: Derived::mf3() //d.mf3(300); 编译报错，同理 d.Base::mf3(300); //OK，输出: Base::mf3():x =300 . 但是不太建议这么写，丑！！ 为解决上述问题，可以采用using声明式或转发函数 using 声明式 可以使用using声明式，让Derived可以忽略名称遮掩，看到Base作用域内的函数。可以让上方代码的“编译报错”消失，正常调用d.mf1(100)和d.mf3(300)。 class Derived :public Base { public: //修改本节内容中上方代码的Derived类的声明 using Base::mf1; using Base::mf3; //这2个using使得Base类作用域内所有mf1,mf3函数都可见 // ... 其他，略 } 转发函数(forwarding function) 应用场景: 在private继承下，强调的是继承实现而非继承接口，如果想在子类的成员中调用父类函数，此时可以通过函数转发来实现。 class Derived: private Base{ //改写本节上方代码，注意，是私有继承 public: virtual void mf1(){ Base::mf1(); //拿到了父类的函数实现 // ... 该函数其他部分 } }; // 应用代码 Derived d; d.mf1(); //调用成功，Derived::mf1 d.mf1(100); //编译失败 当然，public继承也能使用转发函数，写出d.Base::mf3(300); 这样的代码。但是，一来public继承理应遵循\"is-a\"规则，using声明拿到所有被遮掩的接口；二来明显代码不美观。 ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_three/:2:2","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [3]","uri":"/posts/effective_cpp_part_three/"},{"categories":["C++"],"content":"R34 区分接口继承和实现继承 当一个子类Derived继承于父类Base，那么要时刻清楚，对于类中的成员函数，是想继承父类的接口，还是想继承父类的实现。 对于Public继承，接口总是会被继承 基于“is-a”的关系，作用于父类的任何事情也一定要适用于子类。 声明纯虚函数(pure-virtual)的目的是让子类只继承函数接口 对于纯虚函数，子类必须重新实现该接口。注意，父类可以选择性给出纯虚函数的实现，但是一般不会给。 隐患：从非纯虚函数(impure-virtual)同时继承接口和缺省实现 非纯虚函数，可以让子类选择是否重新实现该接口。那么，如果子类是有必要重写，但是忘记写了却默默用父类版本，便事与愿违了。 举例：父类Airplane有子类PlaneModelA、PlaneModelB、PlaneModelC，其中C型飞机不同于AB型，是新式飞机： class Airport {...};//机场类，实现略 class Airplane{ public: virtual void fly(const Airport\u0026 destination);//父类还会给出默认的fly实现 }; class PlaneModelA: public Airplane{ ... }; // 不重写fly，继承父类的fly实现 class PlaneModelB: public Airplane{ ... }; // B和A一样 class PlaneModelC: public Airplane{ ... }; //新型飞机，本来要重写fly，结果忘了 那么这个隐患该如何解决呢，也就是说，在实现C型飞机类时别忘了fly方法？ 核心思想是“切断virtual函数接口和其默认实现之间的连接”。 方法1：设置fly为纯虚函数，并新增一个defaultyFly方法 注意细节：defaultFly方法要设置为protected属性的non-virtual函数，代码如下： class Airplane{ public: virtual void fly(const Airport\u0026 destination) = 0;// 父类不给出实现 protected: void defaultFly(const Airport\u0026 destination){ ... }//默认的fly实现 }; class PlaneModelA: public Airplane{ public: //纯虚接口,子类必须给出实现 virtual void fly(const Airport\u0026 destination){ defaultFly(destination); //调用父类的缺省实现 } };//PlaneModelB 和 PlaneModelA 类似,略 class PlaneModelC: public Airplane{ ...};// 重写fly方法 这样写还有个好处：fly()和defaultFly()享有不同的保护级别。 方法2： 父类的默认实现塞到纯虚接口fly中 这样就不需要定义defaultFly方法了，因为子类必须实现fly方法，对于A 型、B型飞机，子类fly()转发一次父类的fly()即可，C类飞机实现新式的fly()。缺点是让原本在defaultFly内的实现内容暴露在外了(指public属性)。 Note 个人认为，这方法2还有个缺点：它让虚基类的纯虚接口承载了接口实现，不够纯粹(比如需要输出给到客户，应该只继承接口)。 non-virtual函数具体指定接口继承和强制性实现继承 如果成员函数是non-virtual，表示它不打算在子类中有不同的行为，或者说，不变性凌驾于特异性。对应地，绝不应该在子类中重写non-virtual函数。 ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_three/:2:3","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [3]","uri":"/posts/effective_cpp_part_three/"},{"categories":["C++"],"content":"R35 考虑virtual函数的替代选择 假设这样一个场景：设计一款游戏，不同人物以不同方式计算生命值，那么$\\Longrightarrow$ 设计继承体系，子类共同继承父类的public-virtual方法healthValue()，子类各自重新实现healthValue()接口。 😄很好，中规中矩，那么，有没有其他方式呢？ NVI手法(non-virtual interface)实现Template Method模式 思路就是父类定义个non-virtual的public方法healthValue()，调用virtual的private方法healthValueImpl。子类直接重写healthValueImpl，达到类似模版方法设计模式的效果。 父类GameCharacter设计如下： class GameCharacter{//构造函数和虚析构均略去 public: int healthValue()const{ //ps:方便展示，而写在了头文件里，成了inline std::cout\u003c\u003c \"Do prepare works...\\n\";//事前，如加锁,写log,验证条件等 int retVal = healthValueImpl(); std::cout\u003c\u003c \"\\nDo post works...\\n\";//事后,如解锁,更新数据 return retVal; } private: virtual int healthValueImpl() const{ int val=0; std::cout \u003c\u003c \"default caculate process... GetValue:\" \u003c\u003c val;//随后进行计算，过程略 return val; } }; 子类GoodGuy和BadGuy设计如下： class GoodGuy:public GameCharacter{ private: virtual int healthValueImpl() const{ int val = 60; std::cout \u003c\u003c \"goodGuy caculate ... GetValue: \" \u003c\u003c val \u003c\u003c \" \";//过程略 return val; } }; class BadGuy:public GameCharacter{ private: virtual int healthValueImpl() const{ int val = 80; std::cout \u003c\u003c \"badGuy caculate ... GetValue: \" \u003c\u003c val \u003c\u003c \" \";//过程略 return val; } }; 应用端代码如下： std::shared_ptr\u003cGameCharacter\u003e pGood = std::make_shared\u003cGoodGuy\u003e(); pGood-\u003ehealthValue(); //得到60 std::shared_ptr\u003cGameCharacter\u003e pBad = std::make_shared\u003cBadGuy\u003e(); pBad-\u003ehealthValue();//得到80 用函数指针实现Strategy模式 主体思想是添加一个函数指针为private成员变量pFunc，这个函数通过外部传入，从而实现不同的行为。 class GameCharacter;//forward declaration int defaultHealthCalc(const GameCharacter\u0026 gc);//默认算法实现 class GameCharacter{ public: typedef int (*HealthCalcFunc)(const GameCharacter\u0026 gc); explicit GameCharacter(HealthCalcFunc hcf = defaultHealthCalc):calcFunc_(hcf){}//传入函数指针,自定义实现 int healthValue()const{ return calcFunc_(*this); } private: HealthCalcFunc calcFunc_ = nullptr; }; 这个设计有2个有趣的设计弹性： 即使同一个人物类型的不同实体，允许拥有不同的生命值计算方法； 某个人物对象的生命值计算方法，在其生命期内可以任意修改，只要添加一个set方法即可； 用std::function实现Strategy模式 private成员变量由上文的函数指针替换成std::function对象，相当于是指向函数的泛化指针。就更具设计弹性了。std::function可以传入函数指针、仿函数、std::bind函数对象。GameCharacter的类实现修改为： class GameCharacter{ public: typedef std::function\u003cint (const GameCharacter\u0026)\u003e healthCalcFunc; explicit GameCharacter(healthCalcFunc hcf = defaultHealthCalc):healthValueImpl_(hcf){} int healthValue()const{ std::cout\u003c\u003c \"Do prepare works...\\n\"; int retVal = healthValueImpl_(*this); // 这里改了 std::cout\u003c\u003c \"\\nDo post works...\\n\"; return retVal; } private: healthCalcFunc healthValueImpl_ = nullptr; }; 传入函数指针 gameChashort quickHurtHealthCalc(const GameCharacter2\u0026 gc);//返回值不是int,可隐式转换;实现略去 //应用端代码如下： GameCharacter quickGuy(quickHurtHealthCalc); quickGuy.healthValue();//内部调用quickHurtHealthCalc 传入仿函数 仿函数：即函数对象，而且重载了operator() 。 struct HealthCalculator{// int operator()(const GameCharacter2\u0026 gc) const{ return 180;//省略实现 } }; //应用端代码如下： GameCharacter functorGuy( (HealthCalculator()) );//用括号将仿函数括起来 functorGuy.healthValue(); 传入std::bind函数对象 std::bind是函数对象模板，接收一个函数指针f和若干函数入参得到fObj，调用fObj等同于调用带参数的f。本例代码如下： class GameLevel{ public: //用类内函数作为函数指针f float health(const GameCharacter\u0026 gc) const{ return -20.3; } }; //应用端代码如下： GameLevel curLevel; GameCharacter levelGuy(std::bind(\u0026GameLevel::health, curLevel,std::placeholders::_1)); levelGuy.healthValue();//内部调用等价于curLevel.health(leveGuy); By the way 其实这里传入C++11新增的Lambda表达式作为std::function也是可以的，而且更方便，示例代码如下： ```c++ GameCharacter lamGuy([\u0026](const GameCharacter\u0026 gc){ std::cout\u003c\u003c \"value is \" \u003c\u003c 75 \u003c\u003c std::endl;//具体计算略 return 75; }); lamGuy.healthValue(); ``` 关于Strategy设计模式更多参考： - [Strategy设计模式-原理讲解](https://refactoringguru.cn/design-patterns/strategy) - [Strategy设计模式-C++代码参考](https://refactoringguru.cn/design-patterns/strategy/cpp/example) ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_three/:2:4","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [3]","uri":"/posts/effective_cpp_part_three/"},{"categories":["C++"],"content":"R36 绝不重新定义继承而来的non-virtual函数 由于名称遮掩，不要重新定义继承而来的non-virtual函数 看个反例： class B{ public: void mf(){ std::cout \u003c\u003c \"B::mf()\"; } } class D: public B{ public: void mf(){//重新定义mf()，违反了Rule33 std::cout \u003c\u003c \"D::mf()\"; } }; 那么看这样的应用代码： D d; D* pD = \u0026d; B* pB = \u0026d; d.mf(); // 输出 D::mf() pD -\u003e mf();// 输出 D::mf() pB -\u003e mf();// 输出 B::mf() 这就很诡异了！都通过对象d调用成员函数mf，调用结果应该相同。 另外一点，出于public继承的“is-a”特性，这样重新定义non-virtual函数也是对\"is-a\"的严重违背。 ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_three/:2:5","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [3]","uri":"/posts/effective_cpp_part_three/"},{"categories":["C++"],"content":"R37 绝不重新定义继承而来的缺省入参值 这里说的缺省入参，指的是函数入参的默认值，在重写带有缺省入参的virtual函数时，不要修改那个默认参数的默认值。 原因：virtual函数为动态绑定特性，而缺省参数值是静态绑定特性。修改后会造成一些令人费解的现象。 请看下方反面教材： enum class Color { RED = 0,GREEN ,BLUE }; class Shape { public: // ：父类默认入参是RED virtual void draw(Color col = Color::RED) { std::cout \u003c\u003c \"Shape:col is \" \u003c\u003c int(col) \u003c\u003c std::endl; } }; class Rectangle : public Shape{ // ：子类类修改默认入参为GREEN virtual void draw(Color col = Color::GREEN) { std::cout \u003c\u003c \"Rectangle:col is \" \u003c\u003c int(col) \u003c\u003c std::endl; } }; 那么当出现典型应用场景Base* pB=new Derived时，就会造成“父类子类各出一半力”的情形： Shape *pRec = new Rectangle(); pRec-\u003edraw(); // 输出：Rectangle:col is 0 （0是RED） 结果确实调用子类draw，但是默认入参取的是基类的 RED，而非子类的GREEN。 那怎么修改合适呢，都带默认参数，且子类父类相同？带来一个耦合问题，如果父类改了，所有子类都得改。 正如Rule35提到的NVI(non-virtual interface)手法，此处便是绝佳的应用场景$\\Longrightarrow$ draw方法改为默认参数的non-virtual，把virtual函数放到private里去，代码修改如下： class Shape { public: //子类继承该默认入参的non-virtual接口，别重写 void draw(Color col = Color::RED) { drawImpl(col); } private: //纯虚函数是强制子类重写，看具体情况，impure-virtual也行 virtual void drawImpl(Color col) = 0;//子类重写这个drawImpl }; ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_three/:2:6","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [3]","uri":"/posts/effective_cpp_part_three/"},{"categories":["C++"],"content":"R38 通过复合塑造出has-a或\"根据某物实现出” 原书标题：Model “has-a” or “is-implemented-in-terms-of” through composition，同Rule32，侯捷老师翻译为“塑模”。 复合关系（composition）是一种常见的类关系，当某种类型的对象内含有它种类型的对象时，便是此种关系。 复合关系分为2种：\"has-a\" 和 “is-implemented-in-terms-of\"。 “has-a”关系： 指的是应用域部分，不参与内的具体各项实现。是一种单纯的完备对象的包含关系，比如Person类有Address、PhoneNumber、Job等类型的成员变量，又或是Image类有Buffer、Mutexx、SearchTree等类型的成员。 “is-implemented-in-terms-of“关系： 指的是实现域部分，参与类的各类实现，比如数据结构的设计中，想用现有的 std::list来实现Set类，这样可能效率不高(通常更具效率的实现是采用平衡查找树 )，但是可行。 📌：此处不能让Set以public继承于std::list，因为list允许重复元素，而Set不行，不满足“is-a”关系。 正确实现部分代码示例如下： template\u003cclass T\u003e class Set { public: bool contains(const T\u0026 item)const{ return std::find(rep_.begin(),rep_.end(),item) != rep_.end(); } void insert(const T\u0026 item){ if(!contains(item)) rep_.push_back(item); } void remove(const T\u0026 item);// 实现略 std::size_t size() const; // 实现略 private: std::list\u003cT\u003e rep_; //用来表述Set的数据 }; ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_three/:2:7","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [3]","uri":"/posts/effective_cpp_part_three/"},{"categories":["C++"],"content":"R39 明智而审慎地使用private继承 “明智而审慎”的意思是👉当考虑了其他方案对比后，仍然觉得private继承是最合适的，才使用它。 首先明确private继承的2个特性： 编译器不会自动将一个derived-class对象隐式转换为base-class对象(函数入参时)； 继承而来的成员，在derived-class中都会变成private属性； private继承的意义：意味着implemented-in-terms-of，在类关系设计上没有太大意义，只看重软件实现。 考虑以下使用private的2个应用场景： derived-class想继承base-class的某public接口实现，但又想隐藏此接口 考虑如下应用场景：对于一个已知的类Widget，想用另一个已知的计时类Timer辅助性能分析，在尽量小改动已有代码的情况下，如何启用Timer？ private继承做法：让Widget类private继承于Timer，重写父类Timer的onTick函数。 具体代码如下： class Timer{ public: explicit Timer(int tickFrequency); virtual void onTick() const;//定时器滴答一次，自动被调用一次 }; class Widget:private Timer{ private: // private继承而来的所有成员都是private属性 virtual void onTick() const;//查看并记录Widget数据，资源等 }; 该问题除了上方的private继承，能不能用其他方案替代private继承呢？ 👉👉“public继承+复合”替代private继承：在Widget内部嵌套定义private属性的新类WidgetTimer:private Timer，即可同样启用Timer且隐藏了Timer。代码如下： class Widget{ private: class WidgetTimer:public Timer{// 类内嵌套定义 public: virtual void onTick() const; }; WidgetTimer wTimer_; }; ⭐⭐ WidgetTimer也可以不定义在Widget类内,类内只放WidgetTimer* 和WidgetTimer的前置声明，完全解耦合，降低编译依赖性。而这样的设计自由度是单纯的private继承不具备的。 空白基类最优化(EBO,empty base optimization) ⚡值得一提：空类(Empty Class)是指不含non-static数据成员和virtual-func的类。 空类的size会被C++强制要求至少为1，通常是用1个char占位。如果让Empty-Class作为数据成员，因为内存对齐而导致Derived-Class浪费内存。 示例代码 👇： class Empty { // 空类，1字节. 不含non-static数据，不含virtual void privteFoo() { std::cout \u003c\u003c \"private non-virtual.\";} public: typedef char* pChar; typedef void(*pFuncReadData)(std::string url); enum class clolr { red,green,blue }; void foo() { std::cout \u003c\u003c \"public non-virtual!\"; } static int count ;//static 数据也不属于class实体 }; class HoldsIntsAndEmpty { //内存对齐后12字节 int x_; // 4字节 Empty e_; // 1字节 int y_; // 4字节 }; class HoldsInts:private Empty {//使用EBO,类大小8字节 int x_;//4字节 int y_;//4字节 }; EBO优化可以减少Derived-Class的内存大小，注意EBO只适用于单继承。 ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_three/:2:8","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [3]","uri":"/posts/effective_cpp_part_three/"},{"categories":["C++"],"content":"R40 明智而审慎地使用多重继承 多重继承(multiple inheritance)是指继承一个以上的父类。但是这些父类应该避免拥有共同的祖父类，会形成比较麻烦的“菱形继承”(或者叫钻石继承)。 多重继承的成本以及副作用 上面说“菱形继承”比较麻烦，主要原因是如果祖父类如果拥有某个成员变量x，那么2个父类分别public形式继承了x，到了目标子类就有了2份x。 解决问题的办法是虚继承(virtual inheritance)，如此，上述子类只有一份x。为保证虚继承的正确性，编译器在背后需要付出更多代价，可能造成子类内存更大或运行速度更慢。 👉如果存在菱形继承，那么祖父类尽量不要持有数据成员。 虚继承示例代码如下： class File{...}; //祖父类最好不要持有non-static数据成员 class InputFile: virtual public File{...}; class OutputFile: virtual public File{...}; class IOFile:public InputFile,public OutputFile{...}; 应用场景：public继承接口+private继承实现 思考这样的应用场景，PersonBase类是虚基类，RealPerson是目标子类（需要继承接口），但是获取name和birthDate信息的函数在另一个PersonInfo类都有了现成的实现（只需要简单修改该实现）。 两者结合后，即让RealPerson类public继承于PersonBase，private继承于PersonInfo。 class PersonBase { public: virtual ~PersonBase(){} virtual std::string name() const = 0; virtual std::string birthDate() const = 0; }; class PersonInfo { public: virtual ~PersonInfo() {} explicit PersonInfo(int pID):id_(pID) {} virtual const char* theName() const{ static char value[1024]; static const char* exampleName = \"Luka\";// 计算过程略,用固定字符串替代 std::strcpy(value, valueDelimLeft()); // 获取左界定符 std::strcat(value, exampleName); std::strcat(value, valueDelimRight());// 获取右界定符 return value; } virtual const char* theBirthDate() const { return \"1990-1-1\"; } virtual const char* valueDelimLeft() const { return \"[\"; }; virtual const char* valueDelimRight() const { return \"]\"; }; private: int id_ = 0; }; 多重继承的代码为👇: class RealPerson : public PersonBase, private PersonInfo {//多重继承 public: explicit RealPerson(int pID) :PersonInfo(pID) {} // 委托构造 virtual std::string name() const{ //实现必要的虚基类Person的pure-virtual成员函数 return PersonInfo::theName(); } virtual std::string birthDate() const { return PersonInfo::theBirthDate(); } private: virtual const char* valueDelimLeft() const { return \"\"; };//重写界定符函数 virtual const char* valueDelimRight() const { return \"\"; }; }; 最后应用端代码： RealPerson rPerson(613); std::cout \u003c\u003c rPerson.name(); //输出Luka ,而不是[Luka] 可以看到，多重继承体系完美解决该问题。 回到本节开头，明智和审慎的意思是👉即使多重继承可以用单继承方案替代解决，思考后，如果多重继承依然是最简洁、最易维护、最合理的做法，那就选择它。 ref: [1]. https://blog.csdn.net/cltcj/category_12098441.html [2]. https://kissingfire123.github.io/2022/02/14_effective-c-%E4%B9%8B%E9%98%85%E8%AF%BB%E6%80%BB%E7%BB%93%E4%B8%89/ ","date":"2023-07-31","objectID":"/posts/effective_cpp_part_three/:2:9","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [3]","uri":"/posts/effective_cpp_part_three/"},{"categories":["C++"],"content":"前言 Effective-C++总结系列分为四部分，本文为第二部分，涉及原书第3~4章，内容范围Rule13~25。为方便书写，Rule13简写为R13。 Effective-C++系列List 本博客站点系列内容如下： 💡 Effective C++(第3版)精读总结(一) 💡 Effective C++(第3版)精读总结(二) 💡 Effective C++(第3版)精读总结(三) 💡 Effective C++(第3版)精读总结(四) 由于原书在C++11之前写成，有些现代C++特性不会提及，所以会根据本人开发经验新增一些个人感悟👉By the way环节。 ","date":"2023-07-30","objectID":"/posts/effective_cpp_part_two/:0:0","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [2]","uri":"/posts/effective_cpp_part_two/"},{"categories":["C++"],"content":"CH3.资源管理 ","date":"2023-07-30","objectID":"/posts/effective_cpp_part_two/:1:0","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [2]","uri":"/posts/effective_cpp_part_two/"},{"categories":["C++"],"content":"R13 以对象管理资源 为防止资源泄露，尽量使用RAII对象(资源获取即初始化，Resource Acquisition Is Initialization) 如果用老式的new-delete组合手动管理资源，可能会遇到这样的场景，处理代码中有多处return/break之类的分支语句，每处都手动添加delete回收资源难免会有遗漏风险。 auto_ptr 本书提及的智能指针对象std::auto_ptr可以在资源A初始化化时接管对象A，对象脱离作用域，析构时释放接管的A。 为避免重复删除资源，std::auto_ptr特性: 通过copy构造函数或copy-assignment操作符，操作它们，它们自身会失去资源所有权，变成NULL ！ shared_ptr 为解决上述问题，后来推出了引用计数管理资源，即RCSP(Reference-counting smart poiner)，std::shared_ptr 。(书中当时还是tr1::shared_ptr)特点是shared_ptr在使用copy构造函数或copy-assignment操作符时，不会失去资源所有权，而是自身引用计数加1。 Note auto_ptr目前已经被弃用，转而使用 std::unique_ptr来指涉独占资源的智能指针，不可被复制和赋值。 shared_ptr存在的问题是环形循环应用，互相持有对方，则无法释放，针对这一问题，需要引入std::weak_ptr来破局。 这些智能指针的头文件支持：#include 常用的RAII方式存在的问题 上述的shared_ptr是不支持数组资源的释放的，在析构时默认调用delete，而不是delete[] 。如果要能释放，需要手动传入析构函数。 std::shared_ptr\u003cInvestment\u003e instSpMan(new Investment[5], [](Investment* p) {delete[] p; }); // 使用lamda函数，还可以传入普通函数指针 std::shared_ptr\u003cInvestment[]\u003e instSp(new Investment[5]);// shared_ptr重载了[] std::unique_ptr\u003cint[]\u003e intUp(new int[5]); // unique_ptr重载了[] PS: 通常情况下，如果能用vector代替的场景，就不需要这样使用对象数组。 ","date":"2023-07-30","objectID":"/posts/effective_cpp_part_two/:1:1","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [2]","uri":"/posts/effective_cpp_part_two/"},{"categories":["C++"],"content":"R14 在资源管理类中小心coping行为 并非所有资源都是堆上管理(heap-based)，所以也有智能指针不适合的场景，这时需要自己实现一个资源管理类。 比如有个类CMutex ，只有2个函数lock和unlock，可以新建一个管理类CLock，来管理Mutex类，代码如下： class CMutex {/*省略类实现*/}; void lock(CMutex *mtx) { std::cout \u003c\u003c \"has lock...\\n\";/*other operation...*/ } void unlock(CMutex *mtx) { std::cout \u003c\u003c \"release lock...\\n\";/*other operation...*/ } class CLock { public: explicit CLock(CMutex *mtx) :mtx_(mtx) { lock(mtx_); } ~CLock() { unlock(mtx_); } private: CMutex *mtx_; }; 如果涉及CLock的coping相关函数，那么有以下几种选择： 禁止复制 参考本书Part1-Rule06，禁止coping函数的生成。 对底层资源使用“引用计数法” 以shared_ptr代替裸指针，并且传入unlock函数作为该指针的“删除器”。 复制底部资源 即“深度拷贝”，复制资源管理对象时，同时复制其包裹的资源。 转移底部资源所有权 即浅复制，不拷贝包裹的资源，而是转移所有权，和前文提到的auto_ptr非常契合。 ","date":"2023-07-30","objectID":"/posts/effective_cpp_part_two/:1:2","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [2]","uri":"/posts/effective_cpp_part_two/"},{"categories":["C++"],"content":"R15 在资源管理类中提供对原始资源的访问 智能指针auto_ptr, unique_ptr, shared_ptr都提供了接口访问原始资源，方法名称为get()，对类A资源得到裸指针A*。 智能指针也重载了操作符operator -\u003e 和 operator * ，访问类成员函数都可以像普通指针那样使用。 如果自行设计资源管理类，也要像上述的智能指针那样，做到能够轻松访问原始资源。 某些情况，也可以不使用get成员函数显式转换，转而使用隐式类型转换，方便客户调用: class Font{ public: // 隐式转换 operator FontHandle() const{ return f;} // 显式转换 FontHandle get() const { return f;} private: FontHandle f; } ","date":"2023-07-30","objectID":"/posts/effective_cpp_part_two/:1:3","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [2]","uri":"/posts/effective_cpp_part_two/"},{"categories":["C++"],"content":"R16 成对使用new和delete时要采取相同形式 先看一段错误代码： std::string *stringArray = new std::string[100]; delete stringArray;// undefined behavior,未定义行为；有可能只删除了第一个元素 注意 new 和 delete对应 new[] 和 delete[]对应 不可遗漏或者交叉错配！ 简单探究 delete[]的原理：实际上，在编译器的实现中，对象数组的起始内存会存放“数组长度”这一变量，以便告知delete[]应该调用多少次析构，删除多少资源。 👉 谨慎对数组使用typedef，容易产生new-delete的匹配误解，示例如下： typedef std::string AddressLines[4]; std::string *pal = new AddressLines;//注意：这里其实就是 new string[4] delete pal; // 行为未定义！！ delete [] pal; // 正解！ // 这里建议的替代方法：vector\u003cstring\u003e ","date":"2023-07-30","objectID":"/posts/effective_cpp_part_two/:1:4","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [2]","uri":"/posts/effective_cpp_part_two/"},{"categories":["C++"],"content":"R17 以独立语句将newed对象置入智能指针 不要将申请资源的new语句直接当作函数入参，而是应该先以单独语句申请后传入。 考虑下述问题代码： int priority(); void processWidget(std::shared_ptr\u003cWidget\u003e pw,int pri); //函数调用 processWidget(std::shared_ptr\u003cWidget\u003e(new Widget),priority()); 上述代码第4行，在processWidget函数体执行之前，至少有3个步骤(并非严格次序)： 执行\"new Widget\" 调用std::shared_ptr的构造函数 调用priority函数 C++编译器能保证1-\u003e2的次序(2需要1做入参)，但是无法保证3的次序不在1，2之间，如果步骤3抛出异常，将会直接导致内存泄漏。正确示例如下： std::shared_ptr\u003cWidget\u003e pw(new Widget); processWidget(pw,priority()); ","date":"2023-07-30","objectID":"/posts/effective_cpp_part_two/:1:5","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [2]","uri":"/posts/effective_cpp_part_two/"},{"categories":["C++"],"content":"CH4.设计与声明 ","date":"2023-07-30","objectID":"/posts/effective_cpp_part_two/:2:0","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [2]","uri":"/posts/effective_cpp_part_two/"},{"categories":["C++"],"content":"R18 让接口容易被正确使用，不易被误用 要想设计一个不容易误用的接口，就要先考虑使用者可能犯什么错误。 避免“接口误用”，可以导入新类型进行限制 比如设计一个Date类，参数传递就可能出错，如下所示： class Date{ public: Date(int month,int day,int year); }; 实际使用时，使用者可能写出Date date(30,4,2021);这样的错误代码，如何防范呢？ 方法之一：封装出Month,Day,Year这3个Struct/Class，作为参数入参，并添加月份限制，代码： class Month{ public: static Month Jan() { return Month(1);} // ...省略其他11个月份 private: int val; explicit Month(int m):val(m){} //可被class-static调用，不能被外部调用 }; struct Day {explicit Day(int d) :day(d){} int day; }; //省略 struct Year定义，和Day类似 class Date{ public: Date(const Month\u0026 month,const Day\u0026 day,const Year\u0026 year){} }; 最终客户代码使用的情况如下： Date date(Month::Jan(),Day(13),Year(2022)); By the way C++11 支持对枚举的强化，即类型安全的`enum class`，它不能隐式地转换为整数；也无法与整数数值做比较。此处可以考虑定义一个MonthEm来代替Month： ```c++ enum class MonthEm { Jan = 1, Feb = 2, //... 省略其它的月份定义 }; // 修改Date的构造函数，MonthEm来代替Month Date(const MonthEm\u0026 monthEm, const Day\u0026 day, const Year\u0026 year) {} // 构造对象 Date date2(MonthEm::Feb, Day(23), Year(2021)); ``` 限制类型内什么事是可不可做的 常见操作是加上const限制，比如“以const 修饰operator * 的返回类型”可以阻止这个错误： //本意是想做比较，写成了赋值，但是赋给const，报错！ if (a * b = c) 智能指针传入删除器可避免\"Cross-dll-problem\" std::shared_ptr管理资源时，传入删除器，可避免在A-Dll中new，结果在另一个B-Dll中delete的情况，这会导致Runtime-Error。 ","date":"2023-07-30","objectID":"/posts/effective_cpp_part_two/:2:1","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [2]","uri":"/posts/effective_cpp_part_two/"},{"categories":["C++"],"content":"R19 设计Class犹如设计Type 设计一个优秀的Class并不容易，很多C++书籍都像本书一样提到“Check-Table”，设计Class/Type前，问自己一些重要问题： 新type的对象应该如何被创建和销毁？ 对象的初始化和赋值该有什么差别？ 新type的对象如果值传递(pass-by-value)，意味着什么？ copy构造函数用来定义一个type的值传递具体实现。 什么是新type的“合法值”？ 想清楚约束条件，特别是构造函数、赋值操作符以及setter函数，涉及的错误检查与非法值拦截。 新type需要配合某个继承图谱吗？ 如果继承自某Base类，那么就会收到virtual,non-virtual函数的约束；如果要做后续类的基类，则该type就要注意虚析构的设计。 新type涉及什么样的转换？ 与其他type之间如有转换需求，则需要自行实现相关函数，可参考Rule15。 新type需要怎样的操作符和函数？ 确定哪些是member函数，哪些不是。参考Rule23，Rule24，Rule26。 是否有需要立即驳回的标准函数？ 比如是否禁止copy构造，copy-assignment操作符等函数，可以声明为private；或者使用C++新特性\"=delete\"。参考Rule6。 新type成员的访问属性控制？ 成员变量都应为private，考虑其他member函数该为private/public/protected。以及启用友元friend的考虑。 什么是新type的“未声明接口”? 参考Rule29。 新type有多么一般化？ 如果是一般化的问题处理，该考虑是否该定义Class-Template。 真的需要一个新type吗？ ","date":"2023-07-30","objectID":"/posts/effective_cpp_part_two/:2:2","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [2]","uri":"/posts/effective_cpp_part_two/"},{"categories":["C++"],"content":"R20 以pass-by-reference-to-const代替pass-by-value 尽量以pass-by-reference-to-const代替pass-by-value 前者通常更高效，并可避免“对象切割”问题。 如果对象入参以值传递，就会在入参时创建临时对象，函数完成后临时对象析构，涉及构造函数和析构函数的调用，这些都可能是不小的开销！ 如果是以const reference形式，则不会有任何构造/析构的开销。const的作用是让使用者放心，不会改变入参的值。 “对象切割\"问题： 如果是值传递，Derived-Obj传递给Base-Param，会丢失Derived独有的特性，只保留Base的那部分。 对于C++内置类型，值传递往往更高效 从C++编译器的底层实现角度来看，references引用往往是以指针的形式实现。所以如果是内置数据类型，比如int类型 ，直接值传递反而效率更高。 此规则还适用于STL迭代器和函数对象。 ","date":"2023-07-30","objectID":"/posts/effective_cpp_part_two/:2:3","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [2]","uri":"/posts/effective_cpp_part_two/"},{"categories":["C++"],"content":"R21 必须返回对象时，不要随意返回reference 不要返回指针或引用指向以下对象: 局部栈对象(local stack) 函数内部新建的栈变量对象，出了函数就面临消亡，仍持有它的引用/指针，是典型的未定义行为。 堆分配对象(heap allocated) 内部new，然后return出去使用，一来会增加外部delete的负担，二来可能delete的机会都没有。代码如下： const Rational\u0026 operator*(const Rational\u0026 lhs, const Rational\u0026 rhs){ Rational *result = new Rational(lhs.n * rhs.n,lhs.d * rhs.d); return *result; } // 如下使用连乘，则没有delete的机会 Rational w,x,y,z; w = x * y * z; // 内存泄漏！！！ 上述代码返回的是引用，返回指针也是一样的负作用。 局部static对象(local static) 函数内部的static对象，只初始化一次，且只有一份，有记忆功能，可以被更新。那么下述代码就会出现问题： const Rational\u0026 operator*(const Rational\u0026 lhs,const Rational\u0026 rhs){ static Rational result; result = Rational(lhs.n * rhs.n,lhs.d * rhs.d) return result; //在调用者看来，因为是引用，永远只看到独一份的result的“最新值 ” } // 下方的比较永远都是true，永远走if分支 ！！ Rational a,b,c,d; if((a*b) == (c*d)){ //乘积相等，走if分支 }else{ //乘积不相等，走else分支 } Tips 那是不是永远不能以reference作为返回值呢 ？ 当然不是，*this可以返回其引用，参考Rule10；或者类成员作为返回值时，可以返回其引用，但最好是const。 ","date":"2023-07-30","objectID":"/posts/effective_cpp_part_two/:2:4","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [2]","uri":"/posts/effective_cpp_part_two/"},{"categories":["C++"],"content":"R22 将成员变量声明为private 成员变量为private获得的好处 客户访问数据的一致性。都是用getter函数（需要加括号），而不是混用函数获取和直接访问； 细化成员变量的访问权限。根据是否有getter、setter函数可以精准控制read/write/none这样的细化。 保持实现弹性。比如获取某系统指标，可以在getter函数中修改各种灵活的策略和算法，而调用者感知不到。 封装性。封装性是指☞ 越多函数可以访问该数据，封装性越低。 客户调用端感知不到class内部的实现，这些确实也是不必暴露的。并且，如果是要修改某个变量，使用setter函数也更方便调试，不至于被随意修改。 protected和public差不多，都不具备封装性 如果某个public/protected变量权限被取消（比如改为private），将会导致大面积的编译错误，能访问的变成unaccessible，需要对应修改许多代码。 ","date":"2023-07-30","objectID":"/posts/effective_cpp_part_two/:2:5","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [2]","uri":"/posts/effective_cpp_part_two/"},{"categories":["C++"],"content":"R23 宁可用non-member,non-friend代替member函数 实际上，non-member/non-friend函数具有更大的封装性 考虑下述一个类WebBrowser，member函数和non-member函数，实际上，member函数WebBrowser::clearEverything具有其他private数据的访问权限，封装性是更差的！ class WebBrowser { public: void clearCache() {/*to clear cache*/} void clearHistory() {/*to clear history*/} void removeCookies() {/*to clear cookies*/} void clearEverything() { clearCache(); clearHistory(); removeCookies();} }; void clearBrowser(WebBrowser \u0026wb) { wb.clearCache(); wb.clearHistory(); wb.removeCookies(); } 工程结构安排 对于上述WebBrowser的例子，non-member函数放哪里呢，除了可以是其他class的member函数，更适用自然的答案是用namespace包裹起来。代码如下： namespace WebBrowserStuff{ class WebBrowser {}; void clearBrowser(WebBrowser \u0026wb); } 注意：namespace可以跨越多个源码文件，而class不能。 通常的组织方式：多个.h头文件都使用同一个namespace，管理不同的功能模块。除了让模块更清晰，还能降低不必要的编译依赖关系。 对于private数据，member和friend函数具有相同的访问权限 基于此，这里讨论的封装性不在于member与否，而是member和non-member ，non-friend函数之间。 ","date":"2023-07-30","objectID":"/posts/effective_cpp_part_two/:2:6","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [2]","uri":"/posts/effective_cpp_part_two/"},{"categories":["C++"],"content":"R24 若所有参数皆需类型转换，请采用non-member 标题需明晰：所有参数，是指包含了被this指针所指向的那个隐含参数（non-explicit构造函数调用隐式类型转换时）。 应对具体场景：构造函数允许隐式类型转换，且需要这个构造好的对象立即调用某member函数foo(比如operator函数)，此时这个foo函数应该改为non-member的foo函数。 考虑一个有理数类Rational，允许隐式类型转换构造（即non-explicit），如果operator*是member函数则会出现问题。Rational类实现代码示例如下： class Rational { public: Rational(int numerator = 0, int denominator = 1) :numerator_(numerator), denominator_(denominator) {} const Rational operator* (const Rational\u0026 rhs)const { return Rational(numerator_*rhs.numerator_, denominator_*rhs.denominator_); } int numerator()const { return numerator_; } int denominator()const { return denominator_; } private: int numerator_ = 0; int denominator_ = 1; }; 上述代码存在一个问题，就是不能混合运算，举例如下： Rational rat(2, 5); Rational rat3Tm = rat * 3; //能成功调用member-operator* Rational rat3Tm2 = 3 * rat; //编译报错！！！ 本节的场景就在于此. 如果要让这种混合运算无障碍，把operator*函数改成non-member即可，注意要删掉原来member内的operator*，不能同时存在这2个operator*。 class Rational { //... 注意，要删除类内的member函数operator* }; const Rational operator* (const Rational\u0026 lhs, const Rational\u0026 rhs) { return Rational(lhs.numerator() * rhs.numerator(), lhs.denominator() * rhs.denominator()); } ","date":"2023-07-30","objectID":"/posts/effective_cpp_part_two/:2:7","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [2]","uri":"/posts/effective_cpp_part_two/"},{"categories":["C++"],"content":"R25 考虑写一个不抛异常的swap函数 当 std::swap对某个类型效率不高时，提供一个swap成员函数，且该swap不抛异常 先看一下效率不高的std::swap实现： namespace std { template\u003ctypename T\u003e //std::swap的典型实现 void swap(T\u0026 a,T\u0026 b) { //置换 a 和 b 的值 T temp(a); //若T是class，此处调用copy构造函数 a = b; //若T是class，此处调用copy assignment操作符 b = temp; } } 考虑这样的使用场景：需要swap一个\"pimpl手法”(pointer to implementation)实现的类，这种传统的std::swap必然是效率不高(深复制impl类的数据耗时较长)。 class WidgetSwImpl { private: int a, b, c; std::vector\u003cdouble\u003e v; //很大的vector,意味着复制时间很长 }; class WidgetSw { public: WidgetSw(WidgetSwImpl* pImpl) :pImpl_(pImpl) {} WidgetSw(const WidgetSw\u0026 rhs) {/*其他copy\u0026initial操作*/} WidgetSw\u0026 operator=(const WidgetSw\u0026 rhs) { *pImpl_ = *(rhs.pImpl_); } void swap(WidgetSw\u0026 other) { //public-member函数swap using std::swap; //令std::swap在此函数可用 swap(pImpl_,other.pImpl_); } private: WidgetSwImpl* pImpl_ = nullptr; }; 调用时代码如下： WidgetSw wSw1(new WidgetSwImpl); WidgetSw wSw2(new WidgetSwImpl); wSw1.swap(wSw2); //成功运行 如果提供了member swap，需提供一个non-member的swap调用前者 注意，其实上述swap成员函数使用起来不算直观和统一，可以全特化std::swap让使用更直观方便，代码如下： namespace std { template\u003c\u003e void swap\u003cWidgetSw\u003e(WidgetSw\u0026 a, WidgetSw\u0026 b) { a.swap(b); } } // 客户端应用代码可以如下调用 // 注意，不应该，也没必要加 std::，会限制编译器只使用std命名空间的swap swap(wSw1,wSw2);//编译器会优先挑中全特化版本的std::swap 如果是Class-Template，则不要特化std命名空间的swap，而是移到其它命名空间 namespace WidgetStuff{ template\u003ctypename T\u003e class WidgetSw{ /*省略类定义*/} // 类内含有swap成员函数 template\u003ctypename T\u003e void swap(WidgetSw\u003cT\u003e\u0026 a, WidgetSw\u003cT\u003e\u0026 b) { a.swap(b); } } Notice std命名空间的函数不要尝试重载，也不要增加任何新东西 C++只允许对Class-Template直接偏特化，不能对Function-Template偏特化(函数模板可以通过重载间接实现“偏特化”的作用) 成员版swap绝对不要抛出异常，非成员swap可以(因为成员swap的一个最好应用就是提供异常安全性) ref: [1]. https://blog.csdn.net/cltcj/category_12098441.html [2]. https://kissingfire123.github.io/2022/01/11_effective-c-%e4%b9%8b%e5%ad%a6%e4%b9%a0%e6%80%bb%e7%bb%93%e4%ba%8c/ ","date":"2023-07-30","objectID":"/posts/effective_cpp_part_two/:2:8","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [2]","uri":"/posts/effective_cpp_part_two/"},{"categories":["C++"],"content":"自定义分配器 很多时候，你会有建立自定义分配器的想法： allocator\u003cT\u003e对线程安全采取了措拖，但是你只对单线程的程序感兴趣，你不想花费不需要的同步开销 在某些容器里的对象通常一同被使用，所以你想在一个特别的堆里把它们放得很近使引用的区域性最大化 你想建立一个相当共享内存的唯一的堆，然后把一个或多个容器放在那块内存里，因为这样它们可以被其他进程共享。 ","date":"2023-07-30","objectID":"/posts/clause_11/:1:0","tags":["Effective","STL"],"title":"Effective STL [11] | 理解自定义分配器的正确用法","uri":"/posts/clause_11/"},{"categories":["C++"],"content":"管理共享内存 假定你有仿效malloc和free的特别程序，用于管理共享内存的堆 void* mallocShared(size_t bytesNeeded); void freeShared(void *ptr); 并且你希望能把STL容器的内容放在共享内存中: template\u003ctypename T\u003e class SharedMemoryAllocator { public: ... pointer allocate(size_type numObiects, const void *localityHint = 0) { return static_cast\u003cpointer\u003e(mallocShared(numObiects * sizeof(T))); } void deallocate(pointer ptrToMemory, size_type numObjects) { freeShared(ptrToMiemory); } ... }; 使用SharedMemoryAllocator： // 方便的typedef typedef vector\u003cdouble, SharedMemoryAllocator\u003cdouble\u003e \u003e SharedDoubleVec; ... { // 开始一个块 SharedDoubleVec v; // 建立一个元素在共享内存中的vector ... // 结束这个块 } 「问题：」v使用SharedMemoryAllocator，所以v分配来容纳它元素的内存将来自共享内存，但v本身——包括它的全部数据成员——几乎将肯定不被放在共享内存里，v只是一个普通的基于堆的对象，所以它将被放在运行时系统为所有普通的基于堆的对象使用的任何内存。那几乎不会是共享内存。 为了把v的内容和v本身放进共享内存，必须这么做: void *pVectorMemory = mallocShared(sizeof(SharedDoubleVec));// 分配足够的共享内存来容纳一个SharedDoubleVec对象 SharedDoubleVec *pv = new (pVectorMemory) SharedDoubleVec; // 使用“placement new”来 在那块内存中建立 一个SharedDoubleVec对象； // 参见下面这个对象的使用（通过pv） ... pv-\u003e~SharedDoubleVec(); // 销毁共享内存中的对象 freeShared(pVectorMemory); // 销毁原来的共享内存块 这就是「手工的四步分配/建造/销毁/回收的过程」：获得一些共享内存 ——\u003e 在里面建立一个用共享内存为自己内部分配的vector ——\u003e 用完这个vector时，调用它的析构函数 ——\u003e 释放vector占用的内存。 这段代码有2点需要注意： 忽略了mallocShared可能返回一个null指针。 共享内存中的vector的建立由“placement new”完成。 ","date":"2023-07-30","objectID":"/posts/clause_11/:1:1","tags":["Effective","STL"],"title":"Effective STL [11] | 理解自定义分配器的正确用法","uri":"/posts/clause_11/"},{"categories":["C++"],"content":"管理分配和回收的堆 假设有2个堆，类Heap1和Heap2。 每个堆类有用于进行「分配」和「回收」的「静态成员函数」： class Heap1 { public: ... static void* alloc(size_t numBytes, const void *memoryBlockToBeNear); static void dealloc(void *ptr); ... }; class Heap2 { ... }; // 有相同的alloc/dealloc接口 你想在不同的堆里联合定位一些STL容器的内容。 首先，设计一个分配器，使用像Heap1和Heap2那样用于真实内存管理的类： template\u003ctypenameT, typename Heap\u003e class SpecificHeapAllocator { public: pointer allocate(size_type numObjects, const void *localityHint = 0) { return static_cast\u003cpointer\u003e(Heap::alloc(numObjects * sizeof(T), localityHint)); } void deallocate(pointer ptrToMemory, size_type numObjects) { Heap::dealloc(ptrToMemory); } ... }; 然后，使用SpecificHeapAllocator来把容器的元素集合在一起： vector\u003cint, SpecificHeapAllocator\u003cint, Heap1 \u003e\u003e v; // 把v和s的元素放进Heap1 set\u003cint, SpecificHeapAllocator\u003cint Heap1 \u003e\u003e s; list\u003cWidget, SpecificHeapAllocator\u003cWidget, Heap2\u003e\u003e L; // 把L和m的元素 放进Heap2 map\u003cint, string, less\u003cint\u003e, SpecificHeapAllocator\u003cpair\u003cconst int, string\u003e, Heap2\u003e\u003e m; 在这个例子里，很重要的一点是「Heap1和Heap2是类型而不是对象」。 STL为用不同的分配器对象初始化相同类型的不同STL容器提供了语法。那是「因为如果Heap1和Heap2是对象而不是类型，那么它们将是不等价的分配器，那就违反了分配器的等价约束」。 只要遵循「相同类型的所有分配器都一定等价的限制条件」，你将毫不费力地使用自定义分配器来「控制一般内存管理策略，群集关系和使用共享内存以及其他特殊的堆」。 ","date":"2023-07-30","objectID":"/posts/clause_11/:1:2","tags":["Effective","STL"],"title":"Effective STL [11] | 理解自定义分配器的正确用法","uri":"/posts/clause_11/"},{"categories":["C++"],"content":"序言 这本C++的经典之作，作者是大佬Scott Meyers👉大佬主页，还写过其他几本影响深远的C++经典，例如《Effective STL》,《More Effective C++》,《Effective Mordern C++》,《Overview of the New C++(C++11/14)》等等。本人看的是中文版，侯捷老师翻译的，精读分析并实践推敲后，整理成博客记录下来。 (Effective-C++总结系列分为四部分，本文为第一部分，涉及原书第1~2章，内容范围Rule01~12。为方便书写，Rule01简写为R01)。 Effective-C++系列List 本博客站点系列内容如下： 💡 Effective C++(第3版)精读总结(一) 💡 Effective C++(第3版)精读总结(二) 💡 Effective C++(第3版)精读总结(三) 💡 Effective C++(第3版)精读总结(四) ","date":"2023-07-29","objectID":"/posts/effective_cpp_part_one/:0:0","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [1]","uri":"/posts/effective_cpp_part_one/"},{"categories":["C++"],"content":"CH1.让自己习惯C++ ","date":"2023-07-29","objectID":"/posts/effective_cpp_part_one/:1:0","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [1]","uri":"/posts/effective_cpp_part_one/"},{"categories":["C++"],"content":"R01 视C++为一个语言联邦 如今的C++已经是个多重范式(multiparadigm)语言，同时支持面向过程形式、面向对象形式、函数形式、泛型形式、元编程形式。 要理解这么多特性，可以简单的归结为四种次语言(sublanguage)组成： C语言: C++仍以C为基础。C++是C的超集, 仍然以 C 为基础。区块、语句、预处理器、内置数据类型 、数组、指针等统统来自C，许多时候C++对问题的解决其实不过就是较高级的 C 解法，但当你C++内的 C 成分工作时，高效编程守则映照出 C 语言的局限：没有模板(template) ，没有异常(exceptions)，没有重载(overloading)…… Object-Oriented C++: 面向对象特性。这部分也就是 C with classes 所诉求的: classes(包括构造函数和析构函数)，封装(encapsulation)、继承(inheritance)、多态(polymorhpism)、virtual函数(动态绑定)……等等，这一部分是面向对象设计之古典守则在C++ 上的直接实施。 Template C++: C++的泛型(generic)编程的部分，也带来了黑魔法-模板元编程(TMP,Metaprogramming)； STL： STL(Standard Temlate Library)即标准模板库，它是template程序库。封装了各类容器(container)、配置器(allocator)、迭代器(iterator)、算法以及常用对象。 总结: C++高效编程守则视状况而变化，取决于你使用C++的哪一部分 ","date":"2023-07-29","objectID":"/posts/effective_cpp_part_one/:1:1","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [1]","uri":"/posts/effective_cpp_part_one/"},{"categories":["C++"],"content":"R02 尽量以const,enum,inline替换#define 对于宏定义的常量，建议用const常量或者枚举enum替换 这样做的好处是方便调试，因为宏报错就是个常数值，没有符号表；并且宏不具有封装性(宏的作用域是在编译时是其定义之事)。 // 举例：MAX_DATA_COUNT在预处理阶段就会被替换，编译器不会见到它，所以一旦有相关报错，给的是100这个值 #define MAX_DATA_COUNT 100 const int MAX_DATA_COUNT = 100 ;// 常量只有一份，宏会导致多份常量值 class Buffer{ public://...类其他部分省略 static const double factor_ ;// static常量,类内声明 static const int times_ = 2;// int类型允许类内初始化,规范上还是建议拿到类外 private: static const int ArrLength = 5; int arr[ArrLength]; }; const double Buffer::factor_ = 0.1;// 类外初始化,一般写在实现文件*.cpp,*.cc中 如果编译器不允许声明时\"in-class初值设定\",如果是整形常量，可以让枚举值来替代，而且枚举值不能被取地址。 对于宏定义的函数，建议用内联inline函数替换 宏函数没办法单行debug调试，而内联函数可以； 宏的写法即使小心翼翼的加好了括号，也可能造成意想不到的宏函数重复计算的问题。 #define GET_MAX(a,b) ((a)\u003e(b) ? (a) :(b)) int a = 5, b = 0; GET_MAX(++a,b); // a累加二次 GET_MAX(++a,b+10); // a累加一次 // 定义个inline函数就不会有这个问题,(a,b)作为函数入参就只会计算一次 By the way 上述情况，从纯C语言角度，想避免“宏函数重复计算”，其实还有个方法，就是使用GNU C 扩展的 typeof 或 GCC 的 __auto_type 关键字，详细可参考GCC官方文档页面。2者都适用于GCC和Clang，都不适用MSVC），示例如下： #define GET_MAX_ONCE(a,b) \\ ( {typeof(a) _a = (a); \\ typeof(b) _b = (b); \\ (_a) \u003e (_b) ? (_a) : (_b); } ) 测试代码如下： int a = 10,b = 20; int c = GET_MAX(++a, b++); std::cout \u003c\u003c \"a = \" \u003c\u003c a \u003c\u003c \", b = \"\u003c\u003c b \u003c\u003c \", c = \" \u003c\u003c c \u003c\u003c std::endl; a = 10 , b = 20; c = GET_MAX_ONCE(++a, b++); std::cout \u003c\u003c \"a = \" \u003c\u003c a \u003c\u003c \", b = \"\u003c\u003c b \u003c\u003c \", c = \" \u003c\u003c c \u003c\u003c std::endl; 测试代码输出： a = 11, b = 22, c = 21 a = 11, b = 21, c = 20 🤔 使用 __auto_type 来取代时要赋初值，关键的 typeof 那行用法改为__auto_type _a = (a); 。 __auto_type 比 typeof 的优势之处在于面对变长数组(VLA)，只解析1次；以及面对嵌套宏定义时也是只严格解析一次。 ","date":"2023-07-29","objectID":"/posts/effective_cpp_part_one/:1:2","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [1]","uri":"/posts/effective_cpp_part_one/"},{"categories":["C++"],"content":"R03 尽可能用const 说起const，先复习个面试高频题😁 //类型char在哪里没关系，关键看const和*的相对位置： //const在*左边，指针所指物为常量; //const在*右边，指针为常量； const char* p; // 指针p所指的字符串为常量，但是p可以修改 char* const p; // 指针p是常量，指向的字符串可修改 const修饰函数返回值时的防御性 const修饰函数的返回值，可以避免一些错误，如下： const Rational operator* (const Rational\u0026 lhs,const Rational\u0026 rhs); //存在Rational a,b,c; if(a*b = c) //例如手误 \"==\"打成了\"=\"，编译器会直接报错 const成员函数的限制 const成员函数有2个好处：(1). 明确理解函数是否修改对象内容；(2). 使“操作const对象”成为可能。 可以通过const特性让对象自动调用正确的版本： class TextBlock{//...类其他部分省略 const char\u0026 operator[](std::size_t index) const{ return text[index];} char\u0026 operator[](std::size_t index) { return text[index];} private: std::string text; } void print(const TextBlock\u0026 ctb){ std::cout \u003c\u003c ctb[0] ;//根据const特性，调用 const TextBlock::operator[] } 思考：const成员函数不修改成员对象，那么，如果成员对象为指针char *p，仅修改p指向的内容，那它还是const成员函数吗？ 实测：const成员函数是允许p[2]= 'x'这一操作的，但是不允许p++； bitwise-constness(又称为physical constness)理念认为不是，不能更改任何对象内的任何一个bit。这种说法也有纰漏，const函数返回一个引用就失控了,外部可改； logical-constness理念则允许const成员函数修改成员变量的bits，但只有在客户端侦测不出的情况下; const成员函数如果一定要修改成员变量，成员变量使用 mutable 修饰即可. const与non-const的成员函数实现完全相同时 这种情况，如何去除代码冗余是个问题。不要封装出一个private函数然后一起调用，多了层调用。 正确做法👉 使用转型,让non-const调用const成员函数，如下为示例： class Rawdata { public: Rawdata(char *src):p_(src),length_(strlen(src)) {} const int\u0026 GetLength()const{ p_[1] = 'a';//为求简便,不作检查了。p_内容修改编译器是允许的. return length_; } int GetLength() { return const_cast\u003cint\u0026\u003e( (static_cast\u003cconst Rawdata\u0026\u003e(*this)).GetLength()); } private: char *p_ = nullptr; int length_ = 0; }; ","date":"2023-07-29","objectID":"/posts/effective_cpp_part_one/:1:3","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [1]","uri":"/posts/effective_cpp_part_one/"},{"categories":["C++"],"content":"R04 确定对象使用前先初始化 分清\"赋值\"和\"初始化\"，在类的构造函数体内使用等号\"=“赋值并非\"初始化”。成员变量的初始化是在构造函数的成员初始化列表实现，效率更高。 C++初始化的次序: Base class总是早于Derived Class被初始化； Class内的成员变量总是以声明次序被初始化； 举例: 下图中的代码初始化顺序为声明顺序\"age_$\\rightarrow$name_$\\rightarrow$gender_ $\\rightarrow$isVip_” class Customer { public: //这里只是为了验证，如果是实际工程代码，建议初值列表尽量和声明顺序保持一致 Customer(std::string gender, uint8_t age, std::string name, bool isVip = false) :isVip_(isVip), gender_(gender), name_(name), age_(age) {} private: uint8_t age_; std::string name_; std::string gender_; bool isVip_; }; By the way 💡：任何一个成员变量a的初始化流程：类内声明赋初值(C++11)-\u003e构造函数初始化列表-\u003e构造函数体内赋值. 函数体外static变量称为non-local static变量，这种变量可以在各自的编译单元正常工作，但C++无法保证初始化次序，当编译单元之间需要共享变量时，而该变量依赖non-local static，就可能会出问题。 解决办法是将这样的变量放回函数体内，成为local static，因为C++确保在函数被调用时一定会初始化这个static变量。 ","date":"2023-07-29","objectID":"/posts/effective_cpp_part_one/:1:4","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [1]","uri":"/posts/effective_cpp_part_one/"},{"categories":["C++"],"content":"CH2.构造/析构/赋值运算 ","date":"2023-07-29","objectID":"/posts/effective_cpp_part_one/:2:0","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [1]","uri":"/posts/effective_cpp_part_one/"},{"categories":["C++"],"content":"R05 了解C++默认编写并调用哪些函数 编译器可以暗自为Class创建default构造函数，copy构造函数(复制构造)，copy assigment(赋值构造)操作符，以及default析构函数。 class EmptyClass{}; 等价于: class EmptyClass { public: EmptyClass() {} // default构造函数 EmptyClass(const EmptyClass\u0026 rhs) {}//copy构造函数 ~EmptyClass() {}//default析构函数，注意是non-virtual EmptyClass\u0026 operator=(const EmptyClass\u0026 rhs) {}//copy assignment操作符 }; 如果一个非空Class自行声明了构造函数，编译器就不再为它创建default构造函数; 如果一个Class内有引用变量或const变量，编译器不会为其生成copy-assignment函数，需要自己实现. class NameObject { public: NameObject(std::string\u0026 name, const int value) :nameValue_(name), objectVal_(value) {} private: std::string\u0026 nameValue_; const int objectVal_; };//考虑以下应用代码 std::string name(\"Mike\"), name2(\"Nicky\"); NameObject nObj(name,22), nObj2(name2,33); nObj2 = nObj;//这一句会导致编译失败，因为引用不能指向2个对象，且const不可改 ","date":"2023-07-29","objectID":"/posts/effective_cpp_part_one/:2:1","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [1]","uri":"/posts/effective_cpp_part_one/"},{"categories":["C++"],"content":"R06 不想编译器的自动生成的函数,明确拒绝 某些场景，类对象本身是认为独一无二的，比如描述人物性格的类Personality(可能不恰当)，不同的人性格不同，肯定是不希望能复制/赋值的。 如果不想编译器自动生成那几个函数，比如不想要复制构造或赋值构造，就明确在代码中禁止，也防止外部用户使用。 技巧1：可以声明为private函数但是不给出实现，让编译器报错； 技巧2：可以设立基类Base，让复制构造和赋值构造都为private函数，让目标类继承于Base类。 By the way C++11针对此类情况，给予了delete关键字一个新功能，在成员函数后面新增\"=delete\"，即可显式地拒绝这个函数的生成和调用.举例如下: class A { public: A(const A\u0026) = delete; // 拷贝构造 A\u0026 operator=(const A\u0026) = delete; // 拷贝赋值 }; ","date":"2023-07-29","objectID":"/posts/effective_cpp_part_one/:2:2","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [1]","uri":"/posts/effective_cpp_part_one/"},{"categories":["C++"],"content":"R07 为多态基类声明virtual析构函数 针对Base* pBase= new DerivedObj()，释放pBase时，如果Base基类的析构函数None-Virtual，则会导致Derived的析构函数不会被调用，造成内存不完全释放，即内存泄漏； Non-Virtual的Class不要做基类； 如果不做基类，就不要声明析构函数为virtual函数，避免虚表为其分配vptr造成浪费； 如果想要抽象类，又暂时没有合适接口，可以让先虚析构成为纯虚函数，例如 class RawData{ public: virtual ~RawData() = 0; }; // 这里特殊的是，需要为这个纯虚函数提供定义 ~RawData::RawData(){} ","date":"2023-07-29","objectID":"/posts/effective_cpp_part_one/:2:3","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [1]","uri":"/posts/effective_cpp_part_one/"},{"categories":["C++"],"content":"R08 别让异常逃离析构函数 析构函数最好不要吐出异常 对于某个Widget类，如果析构函数抛出异常，那么vector\u003cwidget\u003e析构时可能连续抛出多个异常以至于无法处理，直接导致提前程序结束或者未定义行为。 如果有某个函数可能会抛出异常，并需要对异常做出反应，应该提供一个非析构的函数来处理 注意，在析构中抛异常并吞下(catch后go-on-execute)，会掩盖错误，也不是个好办法;抛异常后catch住并std::abort()反而可以提前终结『未定义行为』。 ","date":"2023-07-29","objectID":"/posts/effective_cpp_part_one/:2:4","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [1]","uri":"/posts/effective_cpp_part_one/"},{"categories":["C++"],"content":"R09 绝不在构造和析构过程中调用virtual函数 在Derived-Class的Base-Class构造期间，对象的类型是Base-Class，而非Derived，即使dynamic_cast也是这样认为的，因为此时virtual函数不会下降到Derived-Class的阶层；换句话说==\u003e “在Base-Class构造期间，virtual函数不是virtual函数”； 在析构的时候也是类似道理，也不要在析构函数中调用virtual函数，间接调用也不行(比如non-Virtual-\u003evirtual)； 那么替代方案是？ 如果有这样一种情况，希望在子类构造时能调用父类的foo函数(下方logTransaction函数)，那么将foo改为non-Virtual函数，并且子类构造时调用父类构造函数，有参数时一并传过去； class Transaction { public: explict Transaction(const std::string\u0026 info,int id):id_(id) { logTransaction(info); } void logTransaction(const std::string\u0026 info) { std::cout \u003c\u003c info.c_str(); }//non-Virtual函数 private: int id_; }; class BuyTransaction :public Transaction { public: //将log信息传递给 基类Transaction构造函数； 并初始化了基类成员 BuyTransaction(const std::string\u0026 info, int id) :Transaction(info,id) {/**/} }; By the way 上述代码中，如果有几个Base构造函数，就得写几个Derived构造函数传参。为了简化这一步骤， 在现代C++11，推出了继承构造函数(Inheriting Constructor)，子类可以一个都不用写，直接写一句using声明即可，使用using BaseClass::BaseClass的形式，如下👇 class BuyTransaction :public Transaction { public: using Transaction::Transaction; //其他 }; ","date":"2023-07-29","objectID":"/posts/effective_cpp_part_one/:2:5","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [1]","uri":"/posts/effective_cpp_part_one/"},{"categories":["C++"],"content":"R10 令operator=返回一个reference to *this 关于赋值操作符operator=，主流做法是: class Widget { public: Widget\u0026 operator=(const Widget \u0026rhs) { //... do some thing return *this; } }; 上述做法不局限于operator=，还有operator += ,-=,*=,/=等其他赋值运算符。 该主流协议/做法不是强制性的，只是个建议，因为这样可以允许连续赋值($x=y=z$的形式)。 该协议被内置类型，以及STL的类型(如string,vector,complex,shared_ptr)共同遵守。 ","date":"2023-07-29","objectID":"/posts/effective_cpp_part_one/:2:6","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [1]","uri":"/posts/effective_cpp_part_one/"},{"categories":["C++"],"content":"R11 在operator=中处理\"自我赋值\" 一个对象赋值给自己，这种看起来有点傻的做法，有时候会比较难以发觉。比如：a[i] = a[j]，如果 $i$ 和 $j$ 相等，就是“自我赋值”的经典场景了。 所以，我们需要一个尽量完备的赋值操作符函数🤔。 考虑如下类MapWidget，内有数据裸指针BitMap *pb_，在赋值时同时考虑异常安全和 “自我赋值” 安全(认同测试保障自我赋值安全)，是一个相对不错的实现。但是，认同测试会降低运行效率，根据实际工程实践情况(自我赋值概率极低 )可以酌情去掉。 class BitMap {/*省略类声明\u0026实现*/}; class MapWidget { private: BitMap * pb_ = nullptr; public: explicit MapWidget(BitMap *pb) :pb_(pb) {} MapWidget\u0026 operator=(const MapWidget\u0026 rhs) { if (this == \u0026rhs) return *this; //这一句为认同测试(identity test) BitMap *pOrig = pb_;//不要一上来就delete，而是保存this-\u003epb_ pb_ = new BitMap(*rhs.pb_);//因为这一句可能抛异常 delete pOrig; return *this; } }; Copy and Swap技术 上文中保障异常安全和 **“自我赋值”**安全的技术手段，另外一个办法，就是Copy and Swap技术。这个技术的关键在于“修改对象数据的副本，然后在一个不抛异常的函数中将修改的数据和原件置换 ”。 void MapWidget::Swap(MapWidget\u0026 rhs){std::swap(rhs.pb_,pb_);} MapWidget\u0026 MapWidget::operator=(const MapWidget\u0026 rhs) { MapWidget temp(rhs); Swap(temp); return *this; } ","date":"2023-07-29","objectID":"/posts/effective_cpp_part_one/:2:7","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [1]","uri":"/posts/effective_cpp_part_one/"},{"categories":["C++"],"content":"R12 复制对象时别忘记其每一个成分 编写类的Copying函数时需要做到2点 这里的Copying函数是指有copy属性的特殊函数==\u003e copy构造函数和copy赋值操作符。 复制所有Local成员变量 如果成员复制的时候有遗漏，编译器并不会有怨言，这就埋下了隐患。如果新增了成员，要对应修改Copying函数。 调用所有Base-Class内部的适当的Copy函数 具体代码的推荐实现 如下👇： class Customer { public: Customer(std::string name, float money):name_(name),money_(money) {} private: std::string name_; float money_; }; class VipCustomer :public Customer { public: //注意：派生类要复制基类那部分的成员变量 using Customer::Customer; //参考R09 VipCustomer(const VipCustomer\u0026 rhs) :priority_(rhs.priority_),Customer(rhs){} VipCustomer\u0026 operator=(const VipCustomer\u0026 rhs){ Customer::operator=(rhs); priority_ = rhs.priority_; return *this; } void setPriority(int priority) { priority_ = priority; }; private: int priority_;//子类独有成员可以单独set函数赋值，或者构造函数初始化列表赋值 }; 不要用一个Copying函数去实现另一个 令copy-assignment操作符调用copy构造函数是不合理的；反之，后者调用前者也是无意义的。 如果2者有大量的代码是相同的，可以剥离一个类内private类型的init函数出来，提供给上述2者调用。 ","date":"2023-07-29","objectID":"/posts/effective_cpp_part_one/:2:8","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [1]","uri":"/posts/effective_cpp_part_one/"},{"categories":["C++"],"content":"ref: [1]. https://blog.csdn.net/cltcj/category_12098441.html [2]. https://kissingfire123.github.io/2021/12/06_effective-c-%e4%b9%8b%e5%ad%a6%e4%b9%a0%e6%80%bb%e7%bb%93%e4%b8%80/ ","date":"2023-07-29","objectID":"/posts/effective_cpp_part_one/:3:0","tags":["Effective"],"title":"Effective C++ (第3版) 精读总结 [1]","uri":"/posts/effective_cpp_part_one/"},{"categories":["draft"],"content":"分配器 分配器最初是为抽象内存模型而开发的，允许库开发者忽略在某些16位操作系统上near和far指针的区别，也被设计成促进全功能内存管理器的发展，但事实表明那种方法在STL的一些部分会导致效率损失。 分配器最初被设想为抽象内存模型，在那种情况下，分配器在它们定义的内存模型中提供指针和引用的typedef才有意义。在C++标准里，类型T的对象的默认分配器（巧妙地称为allocator\u003cT\u003e）提供typedef allocator\u003cT\u003e::pointer和allocator\u003cT\u003e::reference，而且也希望用户定义的分配器也提供这些typedef。 建立行为像引用的对象是使用代理对象的例子，而代理对象会导致很多问题。 实际上标准明确地允许库实现假设每个分配器的pointer typedef是T*的同义词，每个分配器的reference typedef与T\u0026相同。对，库实现可以忽视typedef并直接使用原始指针和引用！ 分配器是对象，那表明它们可能有成员功能，内嵌的类型和typedef（例如pointer和reference）等等，但标准允许STL实现认为所有相同类型的分配器对象都是等价的而且比较起来总是相等。 template\u003ctypename T\u003e // 一个用户定义的分配器 class SpecialAllocator {...}; // 模板 typedef SpecialAllocator\u003cWidget\u003e SAW; // SAW = “SpecialAllocator for Widgets” list\u003cWidget, SAW\u003e L1; list\u003cWidget, SAW\u003e L2; ... L1.splice(L1.begin(), L2); // 把L2的节点移到 L1前端 记住当list元素从一个list被接合到另一个时，没有拷贝什么。取而代之的是，调整了一些指针，曾经在一个list中的节点发现他们自己现在在另一个list中。这使接合操作既迅速又异常安全。 当L1被销毁时，当然，它必须销毁它的所有节点（以及回收它们的内存），而因为它现在包含最初是L2一部分的节点，L1的分配器必须回收最初由L2的分配器分配的节点。 现在清楚为什么标准允许STL实现认为相同类型的分配器等价。所以由一个分配器对象（比如L2）分配的内存可以安全地被另一个分配器对象（比如L1）回收。 STL实现可以认为相同类型的分配器等价是多严厉的约束。那意味着可移植的分配器对象——不能有状态。让我们明确这一点：它意味着可移植的分配器不能有任何非静态数据成员，至少没有会影响它们行为的。 ","date":"2023-07-29","objectID":"/posts/clause_10/:1:0","tags":["draft"],"title":"Effective STL [10] | 注意分配器的协定和约束","uri":"/posts/clause_10/"},{"categories":["draft"],"content":"分配原始内存 分配器在分配原始内存方面类似operator new，但它们的接口不同。如果你看看operator new和allocator::allocate最普通形式的声明，就会很清楚。 void* operator new(size_t bytes); pointer allocator\u003cT\u003e::allocate(size_type numObjects); // 记住事实上“pointer”总是 T*的typedef 两者都带有一个指定要分配多少内存的参数，但对于operator new，这个参数指定的是字节数，而对于allocator::allocate，它指定的是内存里要能容纳多少个T对象。 通常allocator::size_type是一个size_t的typedef。 operator new和allocator::allocate的返回类型也不同。operator new返回void，那是C++传统的表示一个到未初始化内存的指针的方式。allocator::allocate返回一个T（通过pointer typedef），不仅不传统，而且是有预谋的欺诈。从allocator::allocate返回的指针并不指向一个T对象，因为T还没有被构造！ ","date":"2023-07-29","objectID":"/posts/clause_10/:2:0","tags":["draft"],"title":"Effective STL [10] | 注意分配器的协定和约束","uri":"/posts/clause_10/"},{"categories":["draft"],"content":"大多数标准容器从未调用它们例示的分配器 list\u003cint\u003e L; // 和list\u003cint, allocator\u003cint\u003e \u003e一样； allocator\u003cint\u003e从未用来分配内存！ set\u003cWidget, SAW\u003e s; // 记住SAW是一个 SpecialAllocator\u003cWidget\u003e的typedef； SAW从未分配内存！ 因为set、multiset、map和multimap是基于节点的容器，即，这些容器所基于的数据结构是每当值被储存就动态分配一个新节点。对于list，节点是列表节点。 对于标准关联容器，节点通常是树节点，因为标准关联容器通常用平衡二叉搜索树实现。 list本身由节点组成，每个节点容纳一个T对象和到list中后一个和前一个节点的指针： template\u003ctypename T, // list的可能 typename Allocator = allocator\u003cT\u003e \u003e // 实现 class list{ private: Allocator alloc; // 用于T类型对象的分配器 struct ListNode{ // 链表里的节点 T data: ListNode *prev; ListNode *next; }; ... }; 当添加一个新节点到list时，我们需要从分配器为它获取内存，我们要的不是T的内存，我们要的是包含了一个T的ListNode的内存。那使我们的Allocator对象没用了，因为它不为ListNode分配内存，它为T分配内存。现在你理解list为什么从未让它的Allocator做任何分配了：分配器不能提供list需要的。 list需要的是从它的分配器类型那里获得用于ListNode的对应分配器的方法。 template\u003ctypename T\u003e // 标准分配器像这样声明， class allocator { // 但也可以是用户写的分配器模板 public: template\u003ctypename U\u003e struct rebind{ typedef allocator\u003cU\u003e other; } ... }; 在list的实现代码里，需要确定我们持有的T的分配器所对应的ListNode的分配器类型。我们持有的T的分配器类型是模板参数Allocator。 在本例中，ListNodes的对应分配器类型是： Allocator::rebind\u003cListNode\u003e::other 每个分配器模板A（例如，std::allocator，SpecialAllocator等）都被认为有一个叫做rebind的内嵌结构体模板。rebind带有一个类型参数U, 并且只定义一个typedef A\u003cU\u003e other. other是A\u003cU\u003e的一个简单名字。 结果，List可以通过Allocator::rebind\u003cListNode\u003e::other从它用于T对象的分配器（叫做Allocator）获取对应的ListNode对象分配器。 ","date":"2023-07-29","objectID":"/posts/clause_10/:3:0","tags":["draft"],"title":"Effective STL [10] | 注意分配器的协定和约束","uri":"/posts/clause_10/"},{"categories":["draft"],"content":"结论 如果你想要写自定义分配器，让我们总结你需要记得的事情。 把你的分配器做成一个模板，带有模板参数T，代表你要分配内存的对象类型。 提供pointer和reference的typedef，但是总是让pointer是T*，reference是T\u0026。 决不要给你的分配器每对象状态。通常，分配器不能有非静态的数据成员。- 记得应该传给分配器的allocate成员函数需要分配的对象个数而不是字节数。也应该记得这些函数返回T*指针（通过pointer typedef），即使还没有T对象被构造。 一定要提供标准容器依赖的内嵌rebind模板。 ","date":"2023-07-29","objectID":"/posts/clause_10/:4:0","tags":["draft"],"title":"Effective STL [10] | 注意分配器的协定和约束","uri":"/posts/clause_10/"},{"categories":["draft"],"content":"删除指定值对象 假定你有一个容纳int标准STL容器: Container\u003cint\u003e c; 而你想把c中所有值为2023的对象都去掉。 令人吃惊的是，完成这项任务的方法因不同的容器类型而不同：没有一种方法是通用的。 当c是连续内存容器（vector、deque或string），最好的方法是erase-remove惯用法 c.erase(remove(c.begin(), c.end(), 2023), c.end()); // 当c是vector、string或deque时， // erase-remove惯用法是去除特定值的元素的最佳方法 Note STL 和 vector中的remove的作用是将等于value的元素放到vector的尾部，但并不减少vector的size； vector中erase的作用是删除掉某个位置position或一段区域(begin, end)中的元素，减少其size，返回被删除元素下一个元素的位置。 这方法也适合于list，但是list的成员函数remove更高效： // 当c是list时，remove成员函数是去除特定值的元素的最佳方法 c.remove(1963); 当c是标准关联容器（即set、multiset、map或multimap）时，使用任何叫做remove的东西都是完全错误的。这样的容器没有叫做remove的成员函数，而且使用remove算法可能覆盖容器值，潜在地破坏容器。对于关联容器，解决问题的适当方法是调用erase： // 当c是标准关联容器时,erase成员函数是去除特定值的元素的最佳方法 c.erase(2023); 这很高效，只花费对数时间，序列容器的基于删除的技术需要线性时间。并且，关联容器的erase成员函数有基于等价而不是相等的优势。 ","date":"2023-07-28","objectID":"/posts/clause_9/:1:0","tags":["draft"],"title":"Effective STL [9] | 在删除选项中仔细选择","uri":"/posts/clause_9/"},{"categories":["draft"],"content":"消除判断式 消除下面判断式，返回真的每个对象: bool badValue(int x); // 返回x是否是“bad” 对于序列容器（vector、string、deque和list），把每个remove替换为remove_if： c.erase(remove_if(c.begin(), c.end(), badValue), // 当c是vector、string或deque时 c.end()); // 这是去掉badValue返回真的对象的最佳方法 c.remove_if(badValue); // 当c是list时这是去掉badValue返回真的对象的最佳方法 对于标准关联容器，有两种方法处理该问题，一个更容易编码，另一个更高效。 AssocContainer\u003cint\u003e c; // c现在是一种标准关联容器 AssocContainer\u003cint\u003e goodValues; // 用于容纳不删除的值的临时容器 remove_copy_if(c.begin(), c.end(),inserter(goodValues, goodValues.end()), badValue); c.swap(goodValues); // 交换c和goodValues的内容 对这种方法的缺点是它拷贝了所有不删除的元素。 因为关联容器没有提供类似remove_if的成员函数，所以必须写一个循环来迭代c中的元素，和原来一样删除元素。不幸的是，那些正确工作的代码很少是跃出脑海的代码。例如，这是很多程序员首先想到的： AssocContainer\u003cint\u003e c; ... for (AssocContainer\u003cint\u003e::iterator i = c.begin(); i!= c.end(); ++i) { // 清晰，直截了当而漏洞百出的,用于删除c中badValue返回真的每个元素的代码 if (badValue(*i)) { c.erase(i); } } // 不要这么做！ 这有未定义的行为。当容器的一个元素被删时，指向那个元素的所有迭代器都失效了。 当c.erase(i)返回时，i已经失效。那对于这个循环是个坏消息，因为在erase返回后，i通过for循环的++i部分自增。为了避免这个问题，我们必须保证在调用erase之前就得到了c中下一元素的迭代器。最容易的方法是当我们调用时在i上使用后置递增： AssocContainer\u003cint\u003e c; ... for (AssocContainer\u003cint\u003e::iterator i = c.begin(); i != c.end();/*nothing*/ ){// for循环的第三部分是空的；i现在在下面自增 if (badValue(*i)) { c.erase(i++); // 对于坏的值，把当前的i传给erase，然后作为副作用增加i； } else { ++i; // 对于好的值，只增加i } } 精髓的地方在于：这种调用erase的解决方法可以工作，因为表达式i++的值是i的旧值，但作为副作用，i增加了。 因此，我们把i的旧值（没增加的）传给erase，但在erase开始执行前i已经自增了。 现在不仅删除badValue返回真的每个元素，而且每当一个元素被删掉时，我们也想把一条消息写到日志文件中。 可以通过直接从原容器删除元素来避开拷贝。 “更容易但效率较低”的解决方案用remove_copy_if把需要的值拷贝到一个新容器中，然后把原容器的内容和新的交换： 对于关联容器，这说多容易就有多容易，因为只需要对刚才开发的循环做一个微不足道的修改就行了： ofstream logFile; // 要写入的日志文件 AssocContainer\u003cint\u003e c; ... for (AssocContainer\u003cint\u003e::iterator i = c.begin(); i !=c.end();){// 循环条件和前面一样 if (badValue(*i)){ logFile \u003c\u003c \"Erasing \" \u003c\u003c *i \u003c\u003c'\\n'; // 写日志文件 c.erase(i++); // 删除元素 } else { ++i; } } 现在是vector、string和deque不能再使用erase-remove惯用法，因为没有办法让erase或remove写日志文件。 而且，我们不能使用刚刚为关联容器开发的循环，因为它为vector、string和deque产生未定义的行为！ 要记得对于那样的容器，调用erase不仅使所有指向被删元素的迭代器失效，也使被删元素之后的所有迭代器失效。 包括所有i之后的迭代器。我们写i++，++i或你能想起的其它任何东西都没有用，因为没有能导致迭代器有效的。必须利用erase的返回值。那个返回值正是我们需要的：一旦删除完成，它就是指向紧接在被删元素之后的元素的有效迭代器。 我们这么写： for (SeqContainer\u003cint\u003e::iterator i = c.begin(); i != c.end();){ if (badValue(*i)){ logFile \u003c\u003c \"Erasing \" \u003c\u003c *i \u003c\u003c '\\n'; i = c.erase(i); // 通过把erase的返回值 } // 赋给i来保持i有效 else { ++i; } } 这可以很好地工作，但只用于标准序列容器。 标准关联容器的erase的返回类型是void。对于那些容器，你必须使用“后置递增你要传给erase的迭代器”技术。为了避免你奇怪list的适当方法是什么，事实表明对于迭代和删除，你可以像vector/string/deque一样或像关联容器一样对待list；两种方法都可以为list工作。 ","date":"2023-07-28","objectID":"/posts/clause_9/:2:0","tags":["draft"],"title":"Effective STL [9] | 在删除选项中仔细选择","uri":"/posts/clause_9/"},{"categories":["draft"],"content":"结论 去除一个容器中有特定值的所有对象： 如果容器是vector、string或deque，使用erase-remove惯用法 如果容器是list，使用list::remove 如果容器是标准关联容器，使用它的erase成员函数 去除一个容器中满足一个特定判定式的所有对象： 如果容器是vector、string或deque，使用erase-remove_if惯用法 如果容器是list，使用list::remove_if 如果容器是标准关联容器，使用remove_copy_if和swap，或写一个循环来遍历容器元素，当你把迭代器传给erase时记得后置递增它 在循环内做某些事情（除了删除对象之外）： 如果容器是标准序列容器，写一个循环来遍历容器元素，每当调用erase时记得都用它的返回值更新你的迭代器。 如果容器是标准关联容器，写一个循环来遍历容器元素，当你把迭代器传给erase时记得后置递增它。 如你所见，与仅仅调用erase相比，有效地删除容器元素有更多的东西。 解决问题的最好方法取决于你是怎样鉴别出哪个对象是要被去掉的，储存它们的容器的类型，和当你删除它们的时候你还想要做什么（如果有的话）。 这仅对带有迭代器实参的erase形式是正确的。关联容器也提供一个带有一个值的实参的erase形式，而那种形式返回被删掉的元素个数。但这里，我们只关心通过迭代器删除东西。 ","date":"2023-07-28","objectID":"/posts/clause_9/:3:0","tags":["draft"],"title":"Effective STL [9] | 在删除选项中仔细选择","uri":"/posts/clause_9/"},{"categories":["ML"],"content":"引入 Notes 本文也是为写 Stable Diffusion 相关文章做的铺垫，主要参考了李宏毅老师的视频课以及B站的白板推导系列。有关GMM、蒙特卡洛、ELBO、变分推断、重参数化的细节本文不做详细介绍，主要围绕VAE的结构以及loss优化推导做讲解。 我们先来简单的引入一下： V：变分推断，它的意思来自于概率图模型，本文会给出变分下界的详细推导； AE：Auto-Encoder，自编码器； VAE：Variational Auto-Encoder，变分自编码器，将概率图模型和神经网络相结合的模型； ","date":"2023-07-27","objectID":"/posts/vae_1/:1:0","tags":["VAE"],"title":"变分自编码器 VAE 详解","uri":"/posts/vae_1/"},{"categories":["ML"],"content":"一、AE 先来介绍一下自编码器(Auto-Encoder)，它是一种无监督学习方法，如上图所示，原理可概述为： 将高维原始数据(如图片)送入 Encoder，利用 Encoder 将高维数据映射到一个低维空间，将n维压缩到m维($m«n$)，我们用隐变量来表示； 然后将低维空间的特征送入 Decoder 进行解码，以此来重建原始输入数据。 Note Encoder、Decoder网络可以为普通的全连接、也可以为CNN、或者类似于Unet都可以，没有固定的要求。 这里为和后文的推导联系起来，我们将 Encoder 网络的映射函数定义为 $q_{\\phi}$ 、Decoder 网络定义为 $p_{\\theta}$，其中 $\\phi$、$\\theta$ 皆为网络参数。 那么对于输入 $x$，我们可以通过Encoder得到 Latent Variable：$z = q_{\\phi}(x)$，然后Decoder可以从隐变量z中对原始数据进行重建：$x’ = p_{\\theta}(z) = p_{\\theta}(q_{\\phi}(x))$。 我们希望重建的数据和原来的数据近似一致，即最小化输入和输出之间的重构误差，那么AE的训练损失可以采用简单的MSE： $$L_{\\text{AE}}(\\theta, \\phi) = \\frac{1}{n}\\sum_{i=1}^{n} (x^{(i)} - x’^{(i)})^2 =\\frac{1}{n}\\sum_{i=1}^{n} (x^{(i)} - p_{\\theta}(q_{\\phi}(x^{(i)})))^2$$ Note 可以理解为比较输入和重构输入的像素点的误差。 ","date":"2023-07-27","objectID":"/posts/vae_1/:2:0","tags":["VAE"],"title":"变分自编码器 VAE 详解","uri":"/posts/vae_1/"},{"categories":["ML"],"content":"二、AE 存在的问题 上面我们通过AE可以构建一个重构图像的模型，但是这个模型并不能满足要求，或者说它并不是真正意义上的生成模型。对于一个生成模型而言，它满足： Encoder 和 Decoder 可以独立拆分(类比 GAN 的 Generator 和 Discriminator)； 固定维度下任意采样出来的编码，都应该能通过 Decoder 产生一张清晰且逼真的图片。 当然对于第一点它是满足的，我们主要分析第二点，也就是AE存在的问题，从而引出VAE。 如上图所示，用一张全月图和一张半月图去训练一个AE，经过训练模型是能够很好的还原出这两张图片。 接下来，我们在 latent code 中任取一点，将其交给 Decoder 进行解码，直觉上我们会得到一张介于全月和半月之前的图片(比如阴影面积覆盖的样子)。然而实际上的输出图片不仅模糊而且还是乱码的。 对于这个现象，一个直观的解释就是AE的 Encoder 和 Decoder 都用了DNN，那么NN只会干一件事情：学习、记住、用记住的东西预测，我们从 latent space 中采样的点，编码器都没有学习过，怎么能够指望它生成希望的值呢? 换句话说，NN只记住了左边全月图片的隐向量和右边半月图片的隐向量，并不能泛化到中间就是$\\frac{3}{4}$月亮的图片。 为了解决这个问题，一个最直接的思想就是引入噪声，扩大图片的编码区域，从而能够覆盖到失真的空白编码区，如下图所示： 其实说白了就是通过增加输入的多样性从而增强输出的鲁棒性。 当我们给输入图片进行编码之前引入一点噪声，使得每张图片的编码点出现在绿色箭头范围内，这样一来所得到的 latent space 就能覆盖到更多的编码点。此时我们再从中间点抽取还原便可以得到一个比较希望的输出。 虽然我们给输入的图片增加了一些噪声，使得 latent space 能够覆盖到比较多的区域，但是还有不少地方没有覆盖到，比如上图的黄色点位置。 因此，我们是不是可以尝试利用更多的噪声，使得对于每一个输入样本，它的编码都能够覆盖到整个编码空间？只不过我们这里需要保证的是：对于编码附近的我们应该给定一个高的概率值，对于距离原编码点远的应该给定一个低的概率值。 这样总体来说，我们就是要将原先的一个单点拉伸到整个编码空间，即将离散的编码点拉伸为一条连续的接近正太分布的编码曲线，如下图所示： 这个其实就是VAE的思想，熟悉GMM的同学应该知道，它是K个高斯分布(Gaussian Distribution)的混合，其实VAE可以说是无限个高斯分布的混合。 ","date":"2023-07-27","objectID":"/posts/vae_1/:3:0","tags":["VAE"],"title":"变分自编码器 VAE 详解","uri":"/posts/vae_1/"},{"categories":["ML"],"content":"三、VAE 结构预览 如上图所示VAE的结构，我们可以看到VAE里的编码器不是输出隐向量$z$，而是一个概率分布，分布的均值为$m$、方差为$\\sigma$，$e$ 即为给编码添加的噪声，来自于正态分布。 tips VAE的Encoder的输出不是隐向量，而是均值为$m$, 方差为$\\sigma$的正态分布。 公式怎么得到的后面会给出推导，我们先来描述一下这个过程： $$z_{i} = c_{i} = \\exp(\\sigma_i) * e_i + m_i$$ $e$ 为噪声，$m$ 为均值， $\\sigma$ 为控制噪声$e$的方差; Encoder会计算出两组编码，一组为均值m、一组为控制噪声干扰程度的方差$\\sigma$; 方差$\\sigma$主要用来为噪声编码 $e$ 分配权重; 取指数主要是为了保证分配到的权重是正值; 也就是说数据分布会在 $\\exp(\\sigma_i) * e$ 方差范围内采样一个值，得到一个偏移量，就是相当于把原始的样本加上了一个噪声。从结构图中我们可以看到，损失除了AE的 重构损失(reconstruction error)外，还多出了下面这一项: $$c = (c_1, c_2, c_3) = \\sum_{i=1}^{3} (e^{\\sigma_i} - (1 + \\sigma_i) + (m_i)^2)$$ 这个辅助loss可以认为是一个约束，也就是说生成的 $\\sigma$ 要满足这个约束。 为什么要加这个辅助loss？ 我们最小化了 reconstruction error，如果不加这个辅助loss的话，Encoder肯定希望噪声对自身生成的图片干扰越小越好，为了保证生成图片的质量，于是分配给噪声的权重也就是越低。如果不加这个约束的话，网络只需要将方差设置为接近负无穷大的值 $\\exp ^ {-\\infty} = 0$，即可消除噪声带来的影响，这样必然会过拟合导致鲁棒性不佳。 tips 添加辅助loss是为了防止过拟合，提高模型的鲁棒性。 为什么加这个辅助loss有用？ 我们对 $\\sigma$ 求导可得 $c = e^{\\sigma} - 1$，令其等于0可求出 $\\sigma = 0$ 时取得极小值，这样一来便可以约束方差不会一路走向负无穷，从而起到正则化约束的作用； 如下图所示，$e^{\\sigma}$ 是蓝色曲线，$1 + \\sigma$ 是红色线条，那么 $e^{\\sigma} - (1 + \\sigma)$就是蓝色曲线减去红色直线，得到绿色曲线，显而易见的可以发现它的最小值为0。 ","date":"2023-07-27","objectID":"/posts/vae_1/:4:0","tags":["VAE"],"title":"变分自编码器 VAE 详解","uri":"/posts/vae_1/"},{"categories":["ML"],"content":"四、数学描述 ","date":"2023-07-27","objectID":"/posts/vae_1/:5:0","tags":["VAE"],"title":"变分自编码器 VAE 详解","uri":"/posts/vae_1/"},{"categories":["ML"],"content":"4.1、作者的 Intuition 借用作者原文的表述，我们来引入定义。如上图所示，首先我们会有一个高维的随机变量，与之相关联的我们叫它隐变量 $z$，$z$ 的维度一般要比 $x$ 低很多，用来描述 $x$ 中所包含的信息。 我们假设 $z$ 满足分布 $p_{\\theta}(z)$，$x$ 也是一个条件概率，也就是说： 在已知 $z$ 的情况下，$p_{\\theta}(z)$能生成一个sample $x$ ； 给定一个sample $x$，$q_{\\phi}(x)$ 就可以尝试推测出这个来。 Note 因为假设$z$满足一定分布，所以也有从$\\theta$到$z$的箭头； 之后提到的$z$都是Decoder里的参数。 这么说可能有点抽象，我们举个例子： 如上图所示，假设有一个图像，里面有3个颜色不一致的形状，这个就是我们的输入$x$。通过右图的参数，可以控制$x$，这就是隐变量$z$。 那么回到实际的应用场景，我们想要通过$x$获得$z$，又想通过$z$得到相应的$x$，也就是图中的双箭头就是我们想要做的事情。 那么对于生成模型而言，VAE的数据产生包括两个过程： 从一个先验分布 $p_{\\theta}(z)$ 中采样一个 $z^{(i)}$； 根据条件分布 $p_{\\theta}(x|z)$，用 $z^{(i)}$ 生成 $x^{(i)}$。 我们希望找到一个参数 $\\theta^*$ 来最大化生成真实数据的概率： $$\\theta^*=\\argmax_{\\theta} \\prod_{i=1}^{n}p_{\\theta}(x^{(i)})$$ 这里 $p_{\\theta}(x^{(i)})$ 可以通过对 $z$ 积分得到： $$p_{\\theta}(x^{(i)}) = \\int_{z} p_{\\theta}(x, z) \\mathrm{d}{z} = \\int_{z} p_{\\theta}(z) p_{\\theta}(x^{(i)}|z)\\mathrm{d}{z}$$ 实际上我们要根据上述积分是不可能实现的，先验分布 $p_{\\theta}(z)$ 是未知的，而且如果分布比较复杂且高维，对其穷举计算也是不现实的。 变分推断引入后验概率来联合建模，即given $x$ 想要得到它的 $z$，根据贝叶斯公式表示为： $$p_{\\theta}(z | x) = \\frac{p_{\\theta}(x|z) p_{\\theta}(z)}{p_{\\theta}(x)}$$ 我们又回到最上面的图： 实线箭头就是我们要得到的生成模型 $p_{\\theta}(z) p_{\\theta}(x|z)$，这里 $p_{\\theta} (z)$ 往往是事先定义好的，比如标准正态分布，而 $p_{\\theta}(x|z)$ 可以用一个网络来学习，它就可以看成是 Probabilistic Decoder。 虚线箭头代表对后验分布 $p_{\\theta}(z|x)$ 的变分估计，它也可以用一个网络去近似，我们记为 $q_{\\phi}(z|x)$，则这个网络称为 Probabilistic Encoder。 所以VAE的优化目标就有了，为了达到从x估计z的过程，对于估计的后验 $q_{\\phi}(z|x)$，我们希望它接近真实的后验分布 $p_{\\theta}(z|x)$ ，即： $$p_{\\theta}(z|x) \\cong q_{\\phi}(z|x)$$ 说白了就是使用另一个模型，参数由 $\\phi$ 表示，在参数 $\\phi$ 的帮助下，有了一个分布 $q$ ，现在希望分布 $q$ 能够尽量接近 $p$，从而达到从 $x$ 估计 $z$ 的过程。 Note 可以看到VAE和AE架构上还是相似的，VAE的最终目标是得到生成模型即Decoder，Encoder只是辅助建模。 而AE常常是为了得到Encoder来进行特征提取或压缩。 ","date":"2023-07-27","objectID":"/posts/vae_1/:5:1","tags":["VAE"],"title":"变分自编码器 VAE 详解","uri":"/posts/vae_1/"},{"categories":["ML"],"content":"4.2、变分下界 为了衡量两个 distribution 的相似程度，我们应该很自然的想到了KL divergence，因为我们实际上计算的是分布 $q$ ，所以我们从 $q$ 的视角来计算它到 $p$ 的KL散度： $$q_{\\phi}(z|x) \\cong p_{\\theta}(z|x) \\rightarrow D_{\\text{KL}}(q_{\\phi}(z|x) || p_{\\theta}(z|x))$$ Note 需要再次强调的是： $\\theta$ 为 decoder 的参数； $\\phi$ 为 encoder 的参数。 根据定义我们将KL divergence展开，对 $z$ 求和，表示如下： $$ \\begin{align} D_{\\text{KL}}(q_{\\phi}(z|x) || p_{\\theta}(z|x)) \u0026= \\sum_{z} q_{\\phi}(z | x) \\log (\\frac{q_{\\phi}(z | x)}{p_{\\theta}(z | x)}) \\cr \u0026= - \\sum_{z} q_{\\phi}(z | x) \\log (\\frac{p_{\\theta}(z | x)}{q_{\\phi}(z | x)})\\cr \u0026= - \\sum_{z} q_{\\phi}(z | x) \\log (\\frac{\\frac{p_{\\theta}(z,x)}{p_{\\theta}(x)}}{q_{\\phi}(z | x)})\\cr \u0026= - \\sum_{z} q_{\\phi}(z | x) [\\log({\\frac{p_{\\theta}(x, z)}{p_{\\theta}(x)}}) - \\log({q_{\\phi}(z | x)})]\\cr \u0026= - \\sum_{z} q_{\\phi}(z | x) [\\log({\\frac{p_{\\theta}(x, z)}{q_{\\phi}(z|x)}}) - \\log({p_{\\theta}(x)})]\\cr \\end{align} $$ Note $p_{\\theta}(z | x)$ 是根据条件概率公式拆开的。 这个时候我们注意到 $\\log(p_{\\theta}(x))$ 是和 $z$ 没有关系的，并且log项是常数，所以在乘求和的时候直接提到 $\\sum$ 外面去就可以了，并且 $q_{\\phi} (z | x)$ 对 $z$ 求和的结果是1，那所以 $-\\sum_{z}(q_{\\phi}(z|x))(-\\log(p_{\\theta}(x)))$ 的结果就是 $\\log(p_{\\theta}(x))$，它是个const。 我们将它移到等式的左边，表示如下： $$ \\begin{align} \\log(p_{\\theta}(x)) \u0026= D_{KL}(q_{\\phi}(z|x) || p_{\\theta}(z|x)) + \\sum_{z}q_{\\phi}(z|x)\\log(\\frac{p_{\\theta}(x, z)}{q_{\\phi}(z|x)}) \\cr \u0026= D_{KL}(q_{\\phi}(z|x) || p_{\\theta}(z|x)) + L(\\theta, \\phi; x) \\end{align} $$ 我们将 $\\sum_{z}q_{\\phi}(z|x)\\log(\\frac{p_{\\theta}(x, z)}{q_{\\phi}(z|x)})$ 写成 $L(\\theta, \\phi; x)$ ，等式左边是一个const，也就是说不管 $x$ 的分布是什么样，它对 $\\theta$ 来说没什么影响。等式右边，KL divergence是一个非负的，所以我们只要把 $L(\\theta, \\phi; x)$ 的值尽可能的拉大，那么KL divergence的值就会随之缩小。 想要最大化的$L(\\theta, \\phi; x)$，就被称为变分下界(Variational lower bound)。 ","date":"2023-07-27","objectID":"/posts/vae_1/:5:2","tags":["VAE"],"title":"变分自编码器 VAE 详解","uri":"/posts/vae_1/"},{"categories":["ML"],"content":"4.3、Loss Function 现在我们只要想办法将这个 lower bound 提升就可以了，那么这个 lower bound 就可以作为我们的 loss function： $$ \\begin{aligned} L(\\theta, \\phi; x) \u0026= \\sum_{z}q_{\\phi}(z|x)\\log(\\frac{p_{\\theta}(x, z)}{q_{\\phi}(z|x)}) \\cr \u0026= \\sum_{z}q_{\\phi}(z|x)\\log(\\frac{p_{\\theta}(x|z) p_{\\theta}(z)}{q_{\\phi}(z|x)}) \\cr \u0026= \\sum_{z}q_{\\phi}(z|x)[\\log(p_{\\theta}(x|z)) + \\log(\\frac{p_{\\theta}(z)}{q_{\\phi}(z | x)})] \\cr \u0026= {E}{q{\\phi}(z|x)}[\\log(p_{\\theta}(x|z))] - D_{KL}(q_{\\theta}(z | x) || p_{\\theta}(z)) \\end{aligned} $$ 上述等式，我们将 lower bound 再展开，将 $p_{\\theta}(x, z)$ 展成条件概率，然后再将log拆分。 第三行中括号内，左边的可以写成期望的形式，右边的因为都有 $q_{\\phi}$ 和 $p_{\\theta}$ 所以符合KL divergence的公式。 我们将 ${E}{q{\\phi}(z|x)}[\\log(p_{\\theta}(x|z))]$ 称为Reconstruction Loss， 将 $-D_{KL}(q_{\\theta}(z | x) || p_{\\theta}(z))$ 称为 Regularization Loss。 所以我们只需要估计出这两项的梯度来，就可以对 lower bound 进行优化了。 Note 我们的目的是想让 Probabilistic Encoder 接近于 $p_{\\theta}(z)$，因为两个损失，这样KL divergence就越大越好，实际-KL才是训练用的loss。 ","date":"2023-07-27","objectID":"/posts/vae_1/:5:3","tags":["VAE"],"title":"变分自编码器 VAE 详解","uri":"/posts/vae_1/"},{"categories":["ML"],"content":"4.4、蒙特卡洛法求梯度 接下来讲如何求出这两项的导数，来优化提升 lower bound。我们看到想要优化的这个loss，其实是可以写成期望的形式的，假定期望里的这一项是 $f(z)$，对于估计这种期望它的导数，最直接的我们就想到了蒙特卡洛的方法。 Note 虽然这里有个 $\\phi$，但我们假定这个 $f(z)$ 和 $\\phi$ 是没有关系的。(假设！！！！) 使用蒙特卡洛方法，对 $f(z)$ 在 $q_{\\phi}$ 上的期望，对 $\\phi$ 求导数，表示如下： $$ \\begin{aligned} \\eta \u0026= \\triangle_{\\phi} E_{q_{\\phi}(z)}[f(z)]\\cr \u0026= \\triangle_{\\phi} \\int {q_{\\phi}(z)}f(z) \\mathrm{d}z\\cr \u0026= \\int \\triangle_{\\phi}{q_{\\phi}(z)}f(z) \\mathrm{d}z\\cr \u0026= \\int {q_{\\phi}(z)}f(z)\\triangle_{\\phi} \\log {q_{\\phi}(z)}\\mathrm{d}z\\cr \u0026= E_{q_{\\phi}(z)}[f(z)\\triangle_{\\phi} \\log {q_{\\phi}(z)}] \\end{aligned} $$ $line 1 \\sim 2:$ 根据期望的定义展开，因为我们假设 $f(z)$ 和 $\\phi$ 没有关系，所以可以将导数符号拿进来； $line 3: $ 根据变换 $\\triangle_{\\phi} \\log q_{\\phi}(z) = \\frac{\\triangle_{\\phi}q_{\\phi}(z)}{q_{\\phi}(z)}$ 带入可得; 套用蒙特卡洛公式，最终表示如下： $$ \\begin{aligned} \\triangle_{\\phi}E_{q_{\\phi}(z)}[f(z)] \u0026= E_{q_{\\phi}(z)}[f(z) \\triangle_{q_{\\phi}(z)} \\log{q_{\\phi}(z)}] \\cr \u0026\\cong \\frac{1}{L}\\sum_{l=1}^{L} f(z) \\triangle_{q_{\\phi}(z^{(l)})} \\log{q_{\\phi}(z^{(l)})}, where z^{(l)} \\sim q_{\\phi}(z|x^{(i)}) \\end{aligned} $$ 但是作者实验发现使用这个 estimator 是有很高的 variance 的，就是直观上来说会导致训练很不稳定。 在此基础上作者提出了 Generic Stochastic Gradient Variational Bayes (SGVB) estimator，并使用**重参数化(Reparameterization)**trick，我们先来说下重参数化。 ","date":"2023-07-27","objectID":"/posts/vae_1/:5:4","tags":["VAE"],"title":"变分自编码器 VAE 详解","uri":"/posts/vae_1/"},{"categories":["ML"],"content":"4.5、重参数化 Trick 上面我们用蒙特卡洛的时候，有一个非常强的假设，那就是假设 $f(z)$ 和 $\\phi$ 是没有关系的，但实际表达式中： 我们可以看到它还是有关系的，所以我们得考虑它们之间存在的关系、这个关系会带来什么样的问题。 我们把它打开来看： $$ \\begin{aligned} \\triangle_{\\phi}E_{q_{\\phi}}[f(z)] \u0026= \\triangle_{\\phi}\\int q_{\\phi}(z)f(z) \\mathrm{d}z \\cr \u0026= \\int \\triangle_{\\phi}[q_{\\phi}(z)f(z)] \\mathrm{d}z\\cr \u0026= \\int f(z) \\triangle_{\\phi}q_{\\phi}(z) \\mathrm{d}z + \\int q_{\\phi}(z)\\triangle_{\\phi}f(z) \\mathrm{d}z\\cr \u0026= \\underbrace{\\int f(z) \\triangle_{\\phi}q_{\\phi}(z) \\mathrm{d}z}{what \\ about \\ this \\ ?} + E{q_{\\phi}(z)}[\\triangle_{\\phi}f(z)] \\end{aligned} $$ 分别求导之后，后面一项可以写成期望的形式，但是前面这一项就无法处理了，为了解决这个问题，作者使用了重参数化技巧(Reparameterization Trick)。 核心思想就是引入一个辅助的随机变量 $\\epsilon$，$\\epsilon \\in p(\\epsilon)$，这个随机变量和其它变量没有关系，它是一个独立的随机变量，用来表示产生 $z$ 的过程中所有的随机性。也就是说抽样产生 $z$ 的过程中，所有的随机性都是由这个 $\\epsilon \\in p(\\epsilon)$ 产生的。 这样我们就可以把 $z$ 写成这种形式： $z = g_{\\phi}(\\epsilon, x)$，从而可以把 $q_{\\phi}(z)$ 这个概率分布转移到 $p_{\\epsilon}$ 上，而 $\\epsilon$ 有一个非常好的特性，那就是和 $\\phi$ 是没有关系的。 这种 trick 就是重参数化，得到新的变形后重新对 $\\phi$ 求导： $$ \\begin{aligned} E_{q_{\\phi(z)}}[f(z^{(i)})] \u0026= E_{p(\\epsilon)}[f(g_{\\phi}(\\epsilon, x^i))] \\cr \\triangle_{\\phi}E_{q_{\\phi(z)}}[f(z^{(i)})] \u0026= \\triangle_{\\phi}E_{p(\\epsilon)}[f(g_{\\phi}(\\epsilon, x^i)]\\cr \u0026=E_{p(\\epsilon)}[\\triangle_{\\phi}f(g_{\\phi}(\\epsilon, x^i)]\\cr \u0026\\approx \\frac{1}{L} \\sum_{l=1}^{L} \\triangle_{\\phi}f(g_{\\phi}(\\epsilon^{(l)}, x^{(i)})) \\end{aligned} $$ 估计这个期望也是采样然后求平均得到最后的式子，这样就可以把loss的梯度给估计出来了。 以上是从数学角度来分析的重参数化技巧，这里作者给出了一个更加直观的表达： 左图为原来的形式，我们使用 $\\phi$ 和 $x$ 产生一个distribution，然后在这个distribution中抽样产生一个z，然后再得到最终的 $f$ 。但是在传递梯度的时候，怎么把梯度通过抽样这个过程传递回来呢？这个是没法传递梯度的。 在使用了重参数化trick后，随机性移动到了 $\\epsilon$ 上，之前所有抽样的过程包括的随机性，都让 $\\epsilon$ 包括了，这样就可以顺利地将梯度通过 $z$ 传递到 $\\phi$，这是一个非常巧妙的方法. Note 可以理解成用多余参数逼近抽样的过程。 ","date":"2023-07-27","objectID":"/posts/vae_1/:5:5","tags":["VAE"],"title":"变分自编码器 VAE 详解","uri":"/posts/vae_1/"},{"categories":["ML"],"content":"4.6 Generic SGVB 简单说完重参数化，我们回到SGVB: 这里是想求这一串期望，它就是我们的 $f(z)$ ，根据之前的 Reparameterization Trick，我们把 $z$ 写成这样的形式： $$z^{(i, l)} = g_{\\phi} (\\epsilon^{(i,l)}, x^{(i)}) \\ and \\ \\epsilon^{(l)} \\sim p(\\epsilon)$$ 让 $\\epsilon$ 从这个 distribution 中抽样产生，$\\epsilon$ 是一个与 $\\phi$ 、$\\theta$ 都没有关系的随机变量，然后 loss 就变成： $$L(\\theta, \\phi, x^{(i)}) = \\frac{1}{L} \\sum_{l=1}^{L} \\log p_{\\theta}(x^{(i)}, z^{(i,l)}) - \\log q_{\\phi}(z^{(i,l)} | x^{(i)})$$ 想要求它对 $\\phi$ 的导数，只需要两边同时求导即可。 note 因为期望这个积分已经被替换成了 $\\epsilon$ 的distribution，它跟 $\\phi$ 是没有关系的，所以我们在估计整个loss的导数的时候，我们直接对 $\\phi$ 求导就可以了。 这个就是作者提出的第一种估计梯度的方法。 ","date":"2023-07-27","objectID":"/posts/vae_1/:5:6","tags":["VAE"],"title":"变分自编码器 VAE 详解","uri":"/posts/vae_1/"},{"categories":["ML"],"content":"4.7、Another SGVB 在此基础上作者还发现，有一些好的性质可以直接拿来利用，比如期望的一些性质。 在 4.3 节中我们讲到原来的 loss 可以写成 KL散度 + 期望 的形式： $$L(\\theta, \\phi, x^{(i)}) = -D_{KL}(q_{\\phi}(z|x^{(i)})||p_{\\theta}(z)) + E_{q_{\\phi}(z|x)}[\\log(p_{\\theta}(x^{(i)}|z))]$$ 这里我们假设这两个distribution：$q_{\\phi}$ 、$p_{\\theta}$ 都是 Gaussian distribution，说白了就是0均值1方差，根据定义： $$ \\begin{cases} D_{KL}(P||Q) = E_{x \\sim P}[\\log(\\frac{P(x)}{Q(x)})]\\cr E_{x\\sim P(x)} = \\int P(x)Q(x)\\mathrm{d}x \\end{cases} $$ 我们根据上述定义打开这个KL divergence： $$-D_{KL}(q_{\\phi}(z|x)||p_{\\theta}(z)) = \\int q_{\\phi}(z|x)(\\log p_{\\theta}(z)) - \\log q_{\\phi}(z|x) \\mathrm{d}z$$ 我们先来看 $\\int q_{\\phi}(z|x)\\log p_{\\theta}(z) \\mathrm{d}z$: $$ \\begin{align} \\int q_{\\phi}(z|x)\\log p_{\\theta}(z) \\mathrm{d}z \u0026= \\int N(z; \\mu, \\sigma^2) \\log N(z; 0, 1)\\mathrm{d}z\\cr \u0026= \\int N(z; \\mu, \\sigma^2) (-\\frac{1}{2}z^2 - \\frac{1}{2}\\log(2\\pi))\\mathrm{d}z\\cr \u0026= -\\frac{1}{2} \\int N(z; \\mu, \\sigma^2) z^2\\mathrm{d}z - \\frac{J}{2}\\log(2\\pi) \\cr \u0026= -\\frac{J}{2} \\log (2\\pi) - \\frac{1}{2}(E_{z \\sim N(z;\\mu, \\sigma^2)}[z]^2 + Var(z))\\cr \u0026= -\\frac{J}{2} \\log (2\\pi) - \\frac{1}{2}\\sum_{J}^{j=1}(\\mu^2 + \\sigma_j^2) \\end{align} $$ $line 1\\sim 2:$ 我们让左面分布 $N(z; \\mu, \\sigma^2)$ 保持不动，将 normal distribution 的PDF带进去； normal distribution 的PDF为: 将常数项直接拿出来，指数的部分也通过log直接拿下来了； $line 3:$ 因为 $\\frac{1}{2}\\log(2\\pi)$ 是个常数、$N(z; \\mu, \\sigma^2)$ 这个分布积分之后是1，所以可以直接把常数项拿到积分外面；但是因为 $z$ 是一个向量，我们假设 $z$ 有 $J$ 个元素element，那么每个元素都会积出一个值来，所以要乘上 $J$，即 $\\frac{J}{2}\\log(2\\pi)$; $line 4:$ 对于积分 $\\int N(z;\\mu,\\sigma^2) z^2\\mathrm{d}z$ 我们可以换个角度理解它：这里我们把它就当成一个概率分布，所以整个这个积分其实也是一个期望的形式，不过它是对 $z^2$ 的期望，经过变形可以写成 $-\\frac{1}{2} E_{z \\sim N(z; \\mu, \\sigma^2)}[z]^2$ 。在这个基础上我们使用期望的性质 $E[z^2] = E[z]^2 + variance(z)$，即 $z^2$ 的期望等于期望的平方加上 $z$ 的方差； 那么对于一个 normal distribution 来说它的期望和方差是显而易见的：$\\mu$ 和 $\\sigma$，对于 $z$ 里的每个元素(脚标是 $j$)都加起来就好了，这样最开始的积分就可以简化成最后的形式。 我们再来看 $\\int q_{\\phi}(z|x)\\log q_{\\phi}(z|x)\\mathrm{d}z$: $$ \\begin{aligned} \\int q_{\\phi}(z|x)\\log q_{\\phi}(z|x)\\mathrm{d}z \u0026=\\int N(z; \\mu, \\sigma^2)\\log N(z;\\mu,\\sigma^2)\\mathrm{d}z\\cr \u0026= \\int N(z; \\mu, \\sigma^2)(-\\frac{1}{2}(\\frac{z - \\mu}{\\sigma})^2- \\frac{1}{2}\\log (2 \\pi) - \\frac{1}{2}\\log(\\sigma^2))\\mathrm{d}z\\cr \u0026=-\\frac{1}{2}\\int N(z;\\mu,\\sigma^{2})(\\frac{z-\\mu}{\\sigma})^{2}\\mathrm{d}z-\\frac{J}{2}log(2\\pi)-\\frac{1}{2}\\sum_{j=1}^{J}log(\\sigma_{j}^{2}) \\cr \u0026=-\\frac J2log(2\\pi)-\\frac12\\sum_{j=1}^{J}log(\\sigma_{j}^{2})-\\frac12E_{z\\sim N(z;\\mu,\\sigma^{2})}[(\\frac{z-\\mu}\\sigma)^{2}] \\cr \u0026=-\\frac{J}{2}log(2\\pi)-\\frac{1}{2}\\sum_{j=1}^{J}log(\\sigma_{j}^{2})-\\frac{1}{2}(E_{z\\sim N(z;\\mu,\\sigma^{2})}[\\frac{z-\\mu}{\\sigma}]^{2}+Var(\\frac{z-\\mu}{\\sigma})) \\cr \u0026=-\\frac{J}{2}log(2\\pi)-\\frac{1}{2}\\sum_{j=1}^{J}(1+log(\\sigma_j^2)) \\end{aligned} $$ 同样的还是把它的PDF带进来，展成上面相似的形式，但是这个地方的常数项和变量要显得复杂一点，相似的是我们一样可以把常数部分拿到积分外面去，然后对于前面这项积分也把它理解成期望的形式，同样利用期望的性质将平方化简，就可以得到最后的结果。 随后我们把 KL散度 这两项给合并起来： $$ \\begin{aligned} -D_{KL}(q_{\\phi}(z\\mid x)\\mid\\mid p_{\\theta}(z))\u0026 =\\int q_\\phi(z\\mid x)(logp_\\theta(z))-logq_\\phi(z\\mid x))\\mathrm{d}z \\cr \u0026=\\frac12\\sum_{j=1}^J(1+log((\\sigma_j)^2)-(\\mu_j)^2-(\\sigma_j)^2) \\end{aligned} $$ 把刚刚上面的结果带进来做减法即可得到这个等式，也就是说可以通过这个式子来估计出KL散度。 对于另一部分的loss $E_{q_{\\phi}(z|x)}[\\log(p_{\\theta}(x^{(i)} | z))]$，就像我们上面说的，这部分的概率我们希望given $z$ 产生的 $x$ 尽量的接近输入 $x$，为了实现这个逼近，我们使用MSE来让$f(z)$逼近这个x，就可以最大化这个loss： 以上就是最终使用的SGVB，作者通过 KL散度 的性质和 Regularization Loss 的近似，给我们提供了一种相对稳定的估计loss和梯度的方法。 ","date":"2023-07-27","objectID":"/posts/vae_1/:5:7","tags":["VAE"],"title":"变分自编码器 VAE 详解","uri":"/posts/vae_1/"},{"categories":["ML"],"content":"五、VAE 结构回顾 总的来看 Variational Auto-Encoder 的model就是： 输入一个 $x$，进了Encoder，这个 Encoder 是由参数来决定的，Encoder 会产生 $μ$和 $σ$； $μ$和 $σ$首先被我们用来计算 KL divergence，作为辅助损失； 同时在 $μ$ 和 $σ$之后我们对它抽样产生一个 $z$，加上 $\\epsilon$ 帮我们产生随机的项； 得到隐变量 $z$后，放到 Decoder 里，它是由参数 $\\theta$ 来决定的； 经过这个 Decoder 之后，我们重建出了一个 $x$； 对比重建后的 $x$ 和输入 $x$ 之间的 MSE 就构成了loss的另一部分， 两个loss加起来就是最终的loss。 这个就是最经典的 Variational Auto-Encoder。 对比第一大节AE的图，可以画成一下形式： ","date":"2023-07-27","objectID":"/posts/vae_1/:6:0","tags":["VAE"],"title":"变分自编码器 VAE 详解","uri":"/posts/vae_1/"},{"categories":["ML"],"content":"六、原文实验 作者基于MNIST 和 Frey Face做了实验验证，看下原文的结果图： 首先作者说了使用不同的学习方法能把这个 lower bound 提升多少，lower bound 的提升越大，说明 Encoder 和我们想要逼近的这个Distruction，它的KL散度是越来越小。 Note 由图中可以看出AEVB与wake-sleep算法的比较，可以看出AEVB训练效果更好。且随着隐变量维度增大，并未出现过拟合现象。 图4是限定2个维度的隐变量 $z$，并调节两个维度的值，生成的图片。 图5是不同维度的隐变量随机采样的图片。 ","date":"2023-07-27","objectID":"/posts/vae_1/:7:0","tags":["VAE"],"title":"变分自编码器 VAE 详解","uri":"/posts/vae_1/"},{"categories":["ML"],"content":"七、torch复现 AE、VAE https://wangguisen.blog.csdn.net/article/details/128476638 ","date":"2023-07-27","objectID":"/posts/vae_1/:8:0","tags":["VAE"],"title":"变分自编码器 VAE 详解","uri":"/posts/vae_1/"},{"categories":["ML"],"content":"References [1]. https://arxiv.org/abs/1312.6114 [2]. http://www.gwylab.com/note-vae.html [3]. https://zhuanlan.zhihu.com/p/452743042 [4]. https://www.bilibili.com/video/BV1q64y1y7J2/ [5]. https://www.bilibili.com/video/av15889450/?p=33 [6]. https://gregorygundersen.com/blog/2018/04/29/reparameterization/ [7]. https://mp.weixin.qq.com/s?__biz=Mzk0MzIzODM5MA==\u0026mid=2247486014\u0026idx=1\u0026sn=2ff34f72c869907408ed1b08bec1a238\u0026chksm=c337b7a7f4403eb14a1b5cdc3e1a1b11dca6f957591957cc29a4c270f0ace0a4674a7ae33214\u0026scene=21#wechat_redirect ","date":"2023-07-27","objectID":"/posts/vae_1/:9:0","tags":["VAE"],"title":"变分自编码器 VAE 详解","uri":"/posts/vae_1/"},{"categories":["C++"],"content":"拷贝一个auto_ptr将改变它的值 当你拷贝一个auto_ptr时，auto_ptr所指向对象的所有权被转移到拷贝的auto_ptr，而被拷贝的auto_ptr被设为NULL。 class Widget { public: explicit Widget(int in) : randy(in) {} inline bool operator\u003c(Widget\u0026 in) { return randy \u003c in.randy; } public: int randy; }; auto_ptr\u003cWidget\u003e pw1(new Widget); // pw1指向一个Widget auto_ptr\u003cWidget\u003e pw2(pw1); // pw2指向pw1的Widget; pw1被设为NULL。（Widget的所有权从pw1转移到pw2。） pw1 = pw2; // pw1现在再次指向Widget； pw2被设为NULL 有意思的是，如果你建立一个auto_ptr\u003cWidget\u003e的vector，然后使用一个指向的Widget的值的函数对它进行排序： bool widgetAPCompare(const auto_ptr\u003cWidget\u003e\u0026 lhs, const auto_ptr\u003cWidget\u003e\u0026 rhs) { return *lhs \u003c *rhs; // 假设Widget 存在operator\u003c } auto_ptr\u003cWidget\u003e w1(new Widget(3)); auto_ptr\u003cWidget\u003e w2(new Widget(2)); widgets.push_back(w1); widgets.push_back(w2); vector\u003cauto_ptr\u003cWidget\u003e \u003e widgets; // 建立一个vector，然后用Widget的auto_ptr填充它； // 记住这将不能编译！ sort(widgets.begin(), widgets.end(), widgetAPCompare);// 排序这个vector 这段代码将不能编译 warning: ‘template\u003cclass\u003e class std::auto_ptr’ is deprecated [-Wdeprecated-declarations] 30 | std::vector\u003cauto_ptr\u003cWidget\u003e \u003e | ^~~~~~~~ In file included from /usr/include/c++/9/memory:80, from temp.cpp:10: /usr/include/c++/9/bits/unique_ptr.h:53:28: note: declared here 53 | template\u003ctypename\u003e class auto_ptr; | ^~~~~~~~ temp.cpp:33:3: warning: ‘template\u003cclass\u003e class std::auto_ptr’ is deprecated [-Wdeprecated-declarations] 33 | auto_ptr\u003cWidget\u003e w1(new Widget(3)); | ^~~~~~~~ 从概念上看所有东西也都很合理，但结果却完全不合理。例如，在排序过程中widgets中的一个或多个auto_ptr可能已经被设为NULL。 排序这个vector的行为可能已经改变了它的内容！ ","date":"2023-07-27","objectID":"/posts/clause_8/:1:0","tags":["STL"],"title":"Effective STL [8] | 永不建立auto_ptr的容器","uri":"/posts/clause_8/"},{"categories":["C++"],"content":"剖析 实现sort的方法是使用了快速排序算法的某种变体。 排序一个容器的基本思想是，选择容器的某个元素作为“主元”，然后对大于和小于或等于主元的值进行递归排序。 在sort内部，这样的方法看起来像这样： template\u003cclass RandomAccessIterator, class Compare\u003e// 这个sort的声明直接来自于标准 void sort(RandomAccessIterator first, RandomAccessIterator last, Compare comp) { // 这个typedef在下面解释 typedef typename iterator_traits\u003cRandomAccessIterator\u003e::value_type ElementType; RandomAccessIterator i; ... // 让i指向主元 ElementType pivotValue(*); // 把主元拷贝到一个局部临时变量中； ... // wor } 源码为： template\u003ctypename _RandomAccessIterator, typename _Compare\u003e inline void sort(_RandomAccessIterator __first, _RandomAccessIterator __last, _Compare __comp) { // concept requirements __glibcxx_function_requires(_Mutable_RandomAccessIteratorConcept\u003c _RandomAccessIterator\u003e) __glibcxx_function_requires(_BinaryPredicateConcept\u003c_Compare, typename iterator_traits\u003c_RandomAccessIterator\u003e::value_type, typename iterator_traits\u003c_RandomAccessIterator\u003e::value_type\u003e) __glibcxx_requires_valid_range(__first, __last); __glibcxx_requires_irreflexive_pred(__first, __last, __comp); std::__sort(__first, __last, __gnu_cxx::__ops::__iter_comp_iter(__comp)); } // 上面 __gnu_cxx::__ops::__iter_comp_iter(__comp) 的实现如下 template\u003ctypename _Compare, typename _Iterator\u003e inline _Iter_comp_to_iter\u003c_Compare, _Iterator\u003e __iter_comp_iter(_Iter_comp_iter\u003c_Compare\u003e __comp, _Iterator __it) { return _Iter_comp_to_iter\u003c_Compare, _Iterator\u003e( _GLIBCXX_MOVE(__comp._M_comp), __it); // 这里有move } 当涉及iterator_traits\u003cRandomAccessIterator\u003e::value_type时，必须在它前面写上typename，因为它是一个依赖于模板参数类型的名字，在这里是RandomAccessIterator。 上面代码中棘手的是这一行: ElementType pivotValue(*i); 因为它把一个元素从保存的区间拷贝到局部临时对象中。 在例子里，这个元素是一个auto_ptr\u003cWidget\u003e，所以这个拷贝操作默默地把被拷贝的auto_ptr——vector中的那个——设为NULL。 另外，当pivotValue出了生存期，它会自动删除指向的Widget。这时sort调用返回了，vector的内容已经改变了，而且至少一个Widget已经被删除了。 也可能有几个vector元素已经被设为NULL，而且几个widget已经被删除，因为快速排序是一种递归算法，递归的每一层都会拷贝一个主元。 ","date":"2023-07-27","objectID":"/posts/clause_8/:2:0","tags":["STL"],"title":"Effective STL [8] | 永不建立auto_ptr的容器","uri":"/posts/clause_8/"},{"categories":["C++"],"content":"结论 智能指针的容器是很好的， 但是auto_ptr完全不是那样的智能指针。 ","date":"2023-07-27","objectID":"/posts/clause_8/:3:0","tags":["STL"],"title":"Effective STL [8] | 永不建立auto_ptr的容器","uri":"/posts/clause_8/"},{"categories":["C++"],"content":"STL容器能够做的事情 提供了前向和逆向遍历的迭代器（通过begin、end、rbegin等）； 能告诉你所容纳的对象类型（通过value_type的ttypedef）； 在插入和删除中，负责任何需要的内存管理； 报告容纳了多少对象和最多可能容纳的数量（分别通过size和max_size）； 当容器自己被销毁时会自动销毁容纳的每个对象。 ","date":"2023-07-26","objectID":"/posts/clause_7/:1:0","tags":["STL"],"title":"Effective STL [7] | 当使用new得指针的容器时，记得在销毁容器前delete那些指针","uri":"/posts/clause_7/"},{"categories":["C++"],"content":"容器内包含指针 虽然STL容器被销毁时，能够自动销毁容纳的每个对象，但是如果这些对象是通过new分配的对象的指针时，它不会调用delete，销毁指针所指向的对象。 Example void doSomething() { vector\u003cWidget*\u003e vwp; for (int i = 0; i \u003c SOME_MAGIC_NUMBER; ++i) vwp.push_back(new Widget); ... // work } // Widgets在这里泄漏！ 这段代码将直接导致内存泄露。 当vwp结束其生命周期后，vwp的每个元素都被销毁，但不会delete每个new得到的对象。 那样的删除是你的职责，而不是vector的。这是一个特性。只有你知道一个指针是否应该被删除。 可以很简单地实现： void doSomething() { vector\u003cWidget*\u003e vwp; ... // work for (vector\u003cWidget*\u003e::iterator i = vwp.begin(); i != vwp.end(), ++i) { delete *i; } } 这段销毁的代码，仍然有2个问题： 新的for循环代码比for_each多得多，没有使用for_each来的清楚 这段代码不是异常安全的。如果在用指针填充了vwp的时候和你要删除它们之间抛出了一个异常，你会再次资源泄漏。 for_each删除对象 要把你的类似for_each的循环转化为真正使用for_each，你需要把delete转入一个函数对象中。 template\u003ctypename T\u003e struct DeleteObject : public unary_function\u003cconst T*, void\u003e { // 这里有这个继承 void operator()(const T* ptr) const { delete ptr; } }; 现在可以这么删除对象 void HappyWork() { ... // work for_each(vwp.begin(), vwp.end(), DeleteObject\u003cWidget\u003e); } 问题 如果有人编写了一个类，该类继承了 string class SpecialString: public string { ... }; 这是很危险的行为，因为string，就像所有的标准STL容器，缺少虚析构函数，而从没有虚析构函数的类公有继承是一个大的C++禁忌。 当他删除 SpecialString 时就会资源泄露 void doSomething() { deque\u003cSpecialString*\u003e dssp; ... for_each(dssp.begin(), dssp.end(), // 行为未定义！通过没有 DeleteObject\u003cstring\u003e()); // 虚析构函数的基类 } // 指针来删除派生对象 解决 可以通过编译器推断传给DeleteObject::operator()的指针的类型来消除这个错误（也减少DeleteObject的用户需要的击键次数）。 把模板化从DeleteObject移到它的operator()： struct DeleteObject { // 删除这里的 // 模板化和基类 template\u003ctypename T\u003e // 模板化加在这里 void operator()(const T* ptr) const { delete ptr; } } 通过传给DeleteObject::operator()的指针的类型，自动实例化一个operator()。这种类型演绎下降让我们放弃使DeleteObject可适配的能力 现在删除 SpecialString 就会正常了 void doSomething() { deque\u003cSpecialString*\u003e dssp; ... for_each(dssp.begin(), dssp.end(), DeleteObject()); // good！ } 现在仍不是异常安全的。 果在SpecialString被new但在调用for_each之前抛出一个异常，就会发生泄漏。 这个问题可以以多种方式被解决，但最简单的可能是用智能指针的容器来代替指针的容器，典型的是引用计数指针。 ","date":"2023-07-26","objectID":"/posts/clause_7/:2:0","tags":["STL"],"title":"Effective STL [7] | 当使用new得指针的容器时，记得在销毁容器前delete那些指针","uri":"/posts/clause_7/"},{"categories":["C++"],"content":"Boost库中的shared_ptr 利用Boost的shared_ptr，本条款的原始例子可以重写为这样： void doSomething() { typedef boost::shared_ ptr\u003cWidget\u003e SPW; //SPW = \"shared_ptr to Widget\" vector\u003cSPW\u003e vwp; for (int i = 0; i \u003c SOME_MAGIC_NUMBER; ++i) vwp.push_back(SPW(new Widget)); // 从一个Widget建立SPW,然后进行一次push_back ... // work } // 这里没有Widget泄漏，甚至在上面代码中抛出异常 ","date":"2023-07-26","objectID":"/posts/clause_7/:3:0","tags":["STL"],"title":"Effective STL [7] | 当使用new得指针的容器时，记得在销毁容器前delete那些指针","uri":"/posts/clause_7/"},{"categories":["C++"],"content":"结论 STL容器很智能，但它们没有智能到知道是否应该删除它们所包含的指针。 当你要删除指针的容器时要避免资源泄漏，你必须用智能引用计数指针对象（比如Boost的shared_ptr）来代替指针，或者你必须在容器销毁前手动删除容器中的每个指针。 ","date":"2023-07-26","objectID":"/posts/clause_7/:4:0","tags":["STL"],"title":"Effective STL [7] | 当使用new得指针的容器时，记得在销毁容器前delete那些指针","uri":"/posts/clause_7/"},{"categories":["ML"],"content":"一、GAN的引入 GAN（Generative Adversarial Networks）是一种无监督的深度学习模型，提出于2014年，被誉为“近年来复杂分布上无监督学习最具前景的方法之一”。 quote Yann Lecun对其的评价是：对抗式训练是迄今为止最酷的一件事情。 Adversarial training is the coolest thing since sliced bread. 我们来看下原文的标题： Generative：我们知道机器学习模型有两大类，第一个是分辨模型：对于一个数据去分辨它的类别，或者是预测一个实数值；另一类是生成模型，意思是怎么样生成这个数据本身。显然GAN是属于生成模型。 Adversarial：对抗的，这里指的是GAN提出的这种 framework 采用对抗训练的方式来work。 Nets：Network的简写。 ","date":"2023-07-26","objectID":"/posts/gan_1/:1:0","tags":["GAN"],"title":"生成对抗网络GAN","uri":"/posts/gan_1/"},{"categories":["ML"],"content":"二、GAN的应用举例 数据生成：生成一些假的图像数据，比如海报中的人脸、文本生成图像等； 数据增强：从分割图生成假的真实街景，比如可以方便训练无人汽车等； 风格化和艺术的图像创造：比如转换图像风格、AI换脸、修补图像等； 声音的转换：比如一个人的声音转为另一个的声音、去除噪声等； …… ","date":"2023-07-26","objectID":"/posts/gan_1/:2:0","tags":["GAN"],"title":"生成对抗网络GAN","uri":"/posts/gan_1/"},{"categories":["ML"],"content":"三、GAN的快速概述 比如人脸检测、图像识别、语音识别等，机器总是在现有事物的基础上，做出描述和判断。能不能创造这个世界不存在的东西？ GAN就是为此而来，它包含三个部分：生成、判别、对抗。其中 生成 和 判别 是它的结构组成，对抗则是它的训练过程。 生成：生成 和 判别 指的是两个独立的模型，生成器会根据随机向量产生假数据，这些假数据既可以是图片、也可以是文本，并试图欺骗判别网络； 判别：判别器负责判断接受到的数据是否是真实的，即对生成数据进行真伪鉴别，试图正确识别所有假数据，它其实是一个二分类问题，会给出一个概率，代表着内容的真实程度；两者使用哪种网络并没有明确的规定，所以原文中作者称其为framework。比如可以使用擅长处理图片的CNN、常见的全连接等等，只要能够完成相应的功能就可以了。 对抗：这指的是 GAN 的交替训练过程。以图片生成为例，先让生成器产生一些假图片，和收集到的真图片一起交给辨别器，让它学习区分两者，给真的高分，给假的低分，当判别器能够熟练判断现有数据后；再让 生成器 以从 判别器 处获得高分为目标，不断生成更好的假图片，直到能骗过判别器，重复进行这个过程，直到辨别器对任何图片的预测概率都接近0.5，也就是无法分辨图片的真假，就停止训练。 也就是说在训练迭代的过程中，两个网络持续地进化和对抗，直到到达一个平衡状态，即判别网络无法识别真假。虽说是对抗，但是生成器和辨别器的关系更像是朋友，最初大家都是“无名之辈”，随着不断的训练“切磋”，共同成为“一代高手”。 我们训练GAN的最终目标是获得好用的生成器，也就是生成足够以假乱真的内容，能完成类似功能的还有波尔斯曼机、变分自编码器等，它们被称为生成模型。 ","date":"2023-07-26","objectID":"/posts/gan_1/:3:0","tags":["GAN"],"title":"生成对抗网络GAN","uri":"/posts/gan_1/"},{"categories":["ML"],"content":"四、原文的摘要 quote 到底什么是GAN？ 首先作者提出一个新的framework，通过一个对抗过程来估计一个生成模型。 同时会训练两个模型： 第一个模型叫做 生成模型G，用来捕获整个数据的分布，其实就是通过 生成器 去拟合和逼近真实的数据分布； 第二个是 辨别模型D，它是用来估计一个样本是来自真正的数据、还是来自于G生成的。 Note 这里稍微解释一下：生成模型 它就是对整个数据的分布进行建模，使得能够生成各种分布。这里“分布”是一个很一般化的词，比如生成图片、生成文本、生成视频等。在统计学眼里，整个世界是通过采样不同的分布来得到的，所以想要生成东西，目的就是要抓住整个数据的一个分布。 生成模型的任务是尽量的想让辨别模型犯错，这个过程是一个最大最小的博弈。在任何函数空间的G和D里面，存在一个独一无二的解，这个解是代表：G能够找出训练数据的真实分布（生成的数据分布趋向于真实数据分布），此时辨别器就判别不出来了，所以概率值为$\\frac{1}{2}$。 如果G和D是一个MLP的话，那么整个系统就可以通过误差反向传播来进行训练。作者说这里不需要使用任何的马尔科夫链，或者说是对一个近似的推理过程展开（说白了意思好像就是和别人的方法比比较简单一点），最后就是说实验的效果非常好。 ","date":"2023-07-26","objectID":"/posts/gan_1/:4:0","tags":["GAN"],"title":"生成对抗网络GAN","uri":"/posts/gan_1/"},{"categories":["ML"],"content":"五、原文的例子 在对抗网络的框架里有两类模型：一个是生成模型、一个是判别模型： 生成模型比喻成造假的人，它要去产生假币； 判别模型比喻成警察，警察的任务就是很好的鉴别假币和真币； 造假者和警察会不断的学习，造假者会提升自己的造假技能，警察也会提升自己判别真币和假币的性能。最后希望造假者能够赢，就是说造的假钱和真钱一模一样，然后警察没有能力去区分真币和假币，那么这个时候就可以使用生成器生成和真实数据一样的数据了。 ","date":"2023-07-26","objectID":"/posts/gan_1/:5:0","tags":["GAN"],"title":"生成对抗网络GAN","uri":"/posts/gan_1/"},{"categories":["ML"],"content":"六、GAN模型结构 \u0026 训练GAN的目的 摘要说的已经很清楚了，GAN由两部分组成： 生成器G（Generator）； 判别器D（Discriminator）； 我们的最终目的是希望生成器G，能够学习到样本的真实分布$P_{\\text{data}}(x)$，那么就能生成之前不存在的、但是却又很真实的样本。 那再啰嗦的说明白一点就是： 我们把随机向量（随机噪声）定义为 $z$，$z \\in F$，可以是任意分布，比如正态分布、均匀分布。 将随机噪声输入到 生成器G 中，G其实看成一个函数就可以，它可以是任意的一个神经网络，因为神经网络可以逼近任何形式的函数。 随机噪声 $z$ 经过生成器G后会产生一个 $G(z)$，生成的这个新的向量 $G(z)$，它可以记为服从$P_G(x)$。但是$P_G(x)$这个分布不是我们想要的，我们想要的是生成器G生成一个满足于真实分布$P_{\\text{data}}(x)$的数据。 通过不断的训练迭代，更新调整生成器G的参数，使得$P_G(x)$近似于 $P_{\\text{data}}(x)$。 通过调整 生成器G 的参数，使得它生成的分布和真实的分布尽可能的像，这个就是最终要达到的目的，可以通过 生成器G 生成一些满足真实分布，但又不是真实存在的数据。 我们以手写数字识别为例，图例如下： GAN模型结构图如下示例： 我们将随机噪声输入到生成器G中，产生 $G(z)$，我们把它叫做$x_{\\text{fake}}$，$x_{\\text{fake}}$为生成的图片，就是假的图片； 我们还有满足于真实分布$P_{\\text{data}}(x)$的数据，记为$x_{\\text{real}}$； 我们把 $x_{\\text{real}}$ 和 $x_{\\text{fake}}$ 同时送到判别器D中去训练，做一个二分类任务，判断是真还是假； ","date":"2023-07-26","objectID":"/posts/gan_1/:6:0","tags":["GAN"],"title":"生成对抗网络GAN","uri":"/posts/gan_1/"},{"categories":["ML"],"content":"七、举例理解GAN的原理 Note 因为原文举的例子比较敏感，我们以李宏毅老师的例子（中央电视台鉴宝节目：一槌定音）来进行GAN原理的阐述。 假设现在有一个人，我们称它为小王，小王是一个收藏家，它的收藏室里收藏了很多“国宝”。但是小王不想只做一个收藏家，他还想高仿这些“国宝”，我们这里将高仿的赝品定义为“工艺品”。 基于GAN的目标，我们知道： 小王最终想成为一个水平很高的“工艺品大师”； 但是如果想成为一个“工艺品”方面的专家，小王自己在家闭门造车肯定是行不通的，因为我们的总目标是想让小王成为一个高水平的、可以以假乱真的工艺品大师。为了达到这个目标，首先需要一个高水平的鉴赏专家（高水平的对手），其次小王本身就要是个高水平的工艺品大师。所以小王还需要找一个水平很高的国宝鉴赏专家。鉴赏专家负责辨别出真的“国宝”和小王的“工艺品”，小王负责高仿生产“工艺品”。 概述来说：小王需要先有一个高水平的专家，然后才可能成为一个高水平的大师。高水平的专家可以看成一种手段，成为高水平的大师才是我们的目标。 ","date":"2023-07-26","objectID":"/posts/gan_1/:7:0","tags":["GAN"],"title":"生成对抗网络GAN","uri":"/posts/gan_1/"},{"categories":["ML"],"content":"八、数学描述 ","date":"2023-07-26","objectID":"/posts/gan_1/:8:0","tags":["GAN"],"title":"生成对抗网络GAN","uri":"/posts/gan_1/"},{"categories":["ML"],"content":"8.1 相关符号 基于上述鉴宝例子，我们来看一下GAN的数学描述，首先需要强调的是： 工艺品经过鉴赏专家判断后，是会受到一个 feedback 的； 对于鉴赏专家而言，它也会从工艺品受到一个 feedback ，当然这是潜在的； 我们就来看一下，这个例子如何用数学符号去表示： “国宝\"是静态的，它相当于我们的真实样本 ${x_{\\text{real}i}}^N{i=1}$ ，这里我们以 $P_{data}$ 表示； 工艺品也是从一个概率分布里抽样出来的，我们将工艺品记作 ${x_{\\text{fake}i}}^N{i=1}$ ，我们把这个概率分布称作 $P_g(x;\\theta_{g})$，g就代表Generator的意思； Note 注意我们并不直接对 $P_g$ 建模，即不直接对生成模型本身进行建模，我们用一个神经网络去逼近这个分布，纯粹的神经网络它是不具备随机性的，所以我们会假设它有一个 $z$，就是前面提到的随机噪声，是来自于一个简单的分布，比如高斯分布： $z \\sim P_Z(z)$ ； 原始的GAN里，神经网络就用NN表示，它本身就是一个确定性变换，即是一个复杂函数，表示为 $G(z;\\theta_{g})$； Note $\\theta_g$ 在NN里就是表示权重参数，在 $P_g$ 里就是代表概率分布参数。 鉴赏专家也可以看成一个概率分布，我们也用一个NN来描述它：$D(x; \\theta_{d})$，代表 $x$ 是国宝的概率 对于鉴赏专家 (判别器D) 接收到的来说： 可以是来自国宝、也可以是来自于工艺品，是无所谓的，重要的是本身是代表是国宝的概率。 对于判别器D的输出来说： $D(x)$ 的值越趋近于1，说明它是国宝的概率就越大；越趋近于0，说明它是工艺品的概率就越大。 上图又可简化为： 一方面是从 $P_{data}$ 里来的 $x_{real}$，一方面是 $z$ 输入到生成器后的输出 $x_{fake}$，$z$ 为噪声。 Note 换句话说, $z$ 是从简单分布中采样，经过生成器后变成 $x$，此时生成的由的先验分布和生成器共同决定。 ","date":"2023-07-26","objectID":"/posts/gan_1/:8:1","tags":["GAN"],"title":"生成对抗网络GAN","uri":"/posts/gan_1/"},{"categories":["ML"],"content":"8.2、“高专家”的目标函数 符号描述表述清楚后，我们看一下GAN的目标函数，首先回顾一下GAN的目标：成为一个高水平的、可以以假乱真的大师。为了达到这个目标，我们又可以分为一个手段和一个目标： 手段：需要一个高水平的鉴别专家； 目标：成为高水平的工艺品大师。 也就是说我们需要先成就一个高水平的专家，才有可能成就一个高水平的大师，所以它们的关系是：(高大师(高专家))。 首先看高专家，高专家水平高体现在：国宝判别为真、工艺品判别为假： $$ 高专家： \\begin{equation} \\left{ \\begin{aligned} %\\nonumber if \\ x \\ is \\ from \\ P_{data}, \\ then D(x) \\uparrow\\ if \\ x \\ is \\ from \\ P_{g}, \\ then D(x) \\downarrow\\ (z \\ is \\ from \\ P_{z}) \\ \\end{aligned} \\right. \\end{equation} $$ 为了将式子统一起来，我们改写为： $$ 高专家： \\begin{equation} \\left{ \\begin{aligned} %\\nonumber if \\ x \\ is \\ from \\ P_{data}, \\ then D(x) \\uparrow\\ if \\ x \\ is \\ from \\ P_{g}, \\ then \\ 1-D(x) \\uparrow\\ (z \\ is \\ from \\ P_{z}) \\ \\end{aligned} \\right. \\end{equation} $$ Note 因为 $D(x)$ 是一个概率值分布，范围是0~1， $D(x)$ 偏小， $1-D(x)$ 则相应的就偏大。 对于工艺品，$x$ 是从生成器G来的，所以可以表示成 $G(z)$： $$ 高专家： \\begin{equation} \\left{ \\begin{aligned} %\\nonumber if \\ x \\ is \\ from \\ P_{data}, \\ then D(x) \\uparrow\\ if \\ x \\ is \\ from \\ P_{g}, \\ then \\ 1 - D(G(z)) \\uparrow\\ (z \\ is \\ from \\ P_{z}) \\ \\end{aligned} \\right. \\end{equation} $$ 为了使目标函数更容易表达，或者说计算更加方便，我们加上，所以进一步表达为： $$ 高专家： \\begin{equation} \\left{ \\begin{aligned} %\\nonumber if \\ x \\ is \\ from \\ P_{data}, \\ then \\ \\log{D(x)} \\uparrow\\ if \\ x \\ is \\ from \\ P_{g}, \\ then \\ \\log{(1 - D(G(z)))} \\uparrow\\ (z \\ is \\ from \\ P_{z}) \\ \\end{aligned} \\right. \\end{equation} $$ Note $\\log$ 为增函数，$\\log(x)$ 与 $x$ 的增减性保持一致，在极大化参数的时候，与原始求解是一样的。 所以对于成就一个高专家来说，目标函数如下： $$\\max_{D} E_{x \\sim P_{data}}[\\log{D(x)}] + E_{z \\sim P_{z}}[\\log (1 - D(G(z)))]$$ note 可能有同学不明白为什么原文这里用期望，其实很简单，我们假设数据分布总共有个样本，那么它的期望可以表示为： $$E_{x \\sim P_{data}}[\\log(D(x))] = \\frac{1}{N} \\sum_{i=1}^{N} \\log(D(x_i)), x_i \\sim P_{data}$$ ","date":"2023-07-26","objectID":"/posts/gan_1/:8:2","tags":["GAN"],"title":"生成对抗网络GAN","uri":"/posts/gan_1/"},{"categories":["ML"],"content":"8.3、“高大师”的目标函数 我们再来看高大师的目标函数，高大师是建立在高专家的水平之上，对于高大师来讲，希望高专家将所有的工艺品都判断为真： $$高大师: if \\ x \\ from \\ P_g,\\ then \\ D(G(z)) \\uparrow $$ 为了统一起来，我们改写为: $$高大师: if \\ x \\ from \\ P_g,\\ then \\ (1 - D(G(z))) \\downarrow $$ 所以对于高大师来讲，目标函数为: $$\\min_{G} E_{z \\sim P_z}[\\log (1 - D(G(z)))]$$ ","date":"2023-07-26","objectID":"/posts/gan_1/:8:3","tags":["GAN"],"title":"生成对抗网络GAN","uri":"/posts/gan_1/"},{"categories":["ML"],"content":"8.4、总目标函数 本着先成就 高专家, 再成就 高大师的原则，GAN的目标函数为： $$\\min_{G} \\max_{D} V(D, G) = \\mathbb{E_{x\\sim p_{data}(x)}}[\\log(D(x))] + \\mathbb{E_{z\\sim p_{z}(z)}}[\\log(1 - D(G(z)))]$$ Note 通过目标函数我们也能看出，GAN模型的复杂度，不在于模型的定义，而在于模型的traning，也就是D和G的学习。 Note 还有一点需要强调的是，自始至终我们都没有去直接面对 $P_g$，我们实际上使用一个可微神经网络 $G(z)$ 去逼近这个 $P_g$ ，而且是从采样的角度去逼近，换句话说，对于生成网络 $P_g$，GAN是绕过了它，并没有直接去解决 $P_g$，而是从采样的角度去逼近它。所以GAN又被称做：Implicit Density Model. 公式比较多，所以对目标函数再啰嗦的介绍下： 我们可以得出，它实际上就要对价值函数 $V(D, G)$ 进行min、max的博弈，还有需要注意的是：$D(x)$ 是判别器的输出，它要做二分类，所以经过sigmoid之后 $D(x) \\in [0, 1]$； 我们来看一下它是怎么工作的： 首先固定住G不动，通过调整D的参数，来最大化价值函数 $V(D, G)$： 要想最大化 $V$ ，左边的 $D(x)$ 要趋近于1（这样才能保证log的值尽可能大），同时要让右边的 $D(G(z))$ 趋近于0（这样才能保证 $log(1-D(G(z)))$ 尽可能大）； $\\max V(D, G)$ 其实就是把真实数据和假数据区分的一个过程. $$\\min_{G} \\max_{D} V(D, G) = \\mathbb{E_{x\\sim p_{data}(x)}}[\\log(D(x))] + \\mathbb{E_{z\\sim p_{z}(z)}}[\\log(1 - D(G(z)))]$$ 然后固定住D不动，此时公式的左部分已经是个定值了，我们调整G的参数，来最小化价值函数 $V(D, G)$： 要让 $V(D, G)$ 最小，那么就要让 $D(G(z))$ 趋近于1，只有 $V(G(z))$ 趋近于1的时候，定义域里的值才能趋近于0，也就是log会变得越来越小，达到最小化 $V$ 的过程； 这个过程就是想让 $D(G(z))$ 趋近于1，z满足生成数据的分布，它是假的，那么 $min_G$ 的过程就是想要调整生成器，来骗过判别器，从而使得假数据被判别为真。 $$\\min_{G} \\max_{D} V(D, G) = \\mathbb{E_{x\\sim p_{data}(x)}}[\\log(D(x))] + \\mathbb{E_{z\\sim p_{z}(z)}}[\\log(1 - D(G(z)))]$$ 总结如下： 固定G, 调整D, 最大化 $V(D, G)$, 导致 $D(x) \\rightarrow 1, D(G(z)) \\rightarrow 0$ 固定D, 调整G, 最小化 $\\max_{D}V(D, G)$, 导致 $D(G(z)) \\rightarrow 1$ 想必肯定有同学会发现这里出现的一个矛盾：上面的趋近于0，下面的趋近于1，这个矛盾、冲突，就理解为GAN中的对抗的意思。 ","date":"2023-07-26","objectID":"/posts/gan_1/:8:4","tags":["GAN"],"title":"生成对抗网络GAN","uri":"/posts/gan_1/"},{"categories":["ML"],"content":"九、全局最优解推导 因为公式多、篇幅长，所以在推导最优解之前，我们先回顾一下GAN里的三个角色： 真实样本分布$P_{data}$； 生成器 Generator 对应概率分布为:$P_g$，即代表生成器生成数据的概率分布； 判别器 Discriminator 对应的条件概率分布是离散的，就是0-1分布（伯努利分布），给定x的情况下，1代表正品、0代表工艺品（赝品）； 我们的最终目标，就是想让生成器生成的样本的概率分布$P_g$无限的接近于$P_{data}$，即：$P_g \\rightarrow P_{data}$； note 我们常规的生成模型（不是GAN），是直接对$P_g$进行建模: $P_g \\rightarrow \\theta_{g}$, 极大似然估计表示如下： $$\\theta_g = \\argmax_{\\theta_g} \\sum_{i=1}^N \\log{P_g}(x_i) = \\argmin KL(P_{data} || P_g)$$ 从距离的角度讲，是最小化KL散度，最终想让$P_{data} = P_g$，这就是原先如何把参数求出来的策略。 ","date":"2023-07-26","objectID":"/posts/gan_1/:9:0","tags":["GAN"],"title":"生成对抗网络GAN","uri":"/posts/gan_1/"},{"categories":["ML"],"content":"9.1、关于 D 的最大值 GAN从对抗学习的角度去构造目标函数，我们上面构造的目标函数，只是从逻辑上觉得它没有问题，那么我们可能会考虑： 这个最大最小问题，它的最优解存在不存在？ 如果最优解 $P_g$（就是G）存在，那么全局最优的情况下，$P_g$是否等于$P_{data}$？ 如果这个不成立的话，那么其实这个目标函数是没有意义的，我们来看一下，方便记作，直接用论文中的符号来描述： 我们记： $$V(D, G) = \\mathbb{E}{x\\sim p{data}(x)}[\\log{D(x)}] + \\mathbb{E}{z\\sim p{z}}[\\log{1 - D(G(z))}]$$ 我们先求max，根据期望的定义：$E_{x \\sim P(x)} = \\int_x p(x)f(x)dx$，将其展为积分的形式： $\\quad For \\quad fixed \\quad G, 求： \\max_D(V(D, G))$ $$ \\begin{align} \\max_D V(D, G) \u0026= \\int P_{data} \\cdot \\log D dx + \\int P_g \\cdot \\log (1 - D) dx \\ \u0026= \\int {[P_{data} \\cdot \\log D + P_g \\cdot \\log(1 - D)]} dx \\end{align} $$ note 这里两个积分中的x确实是不同的变量，但是积分微元的符号可以做任意变换，不用纠结这里。 我们要求里面函数关于x积分的最大值，那么就看一下它的导数： $$ \\begin{align} \\frac{\\partial}{\\partial{D}}(\\max V(D, G)) \u0026= \\frac{\\partial}{\\partial D}\\int {[P_{data} \\cdot \\log D + P_g \\cdot \\log(1 - D)]} \\ \u0026= \\int \\frac{\\partial}{\\partial D} {[P_{data} \\cdot \\log D + P_g \\cdot \\log(1 - D)]} \\ \u0026= \\int {[P_{data} \\cdot \\frac{1}{D} + P_g \\cdot \\frac{-1}{\\log(1 - D)}]} \\Longleftrightarrow 0\\ \\end{align} $$ note 因为积分是对x积的，求导是对D求的，两者互不干扰可以交换词序。 最优的时候导数为0。 $$\\therefore P_{data} \\cdot \\frac{1}{D} = P_g \\cdot \\frac{1}{1-D}$$ 所以当固定G时，最优的D为: $$D^*G = \\frac{P{data}}{P_{data} + P_g}$$ ","date":"2023-07-26","objectID":"/posts/gan_1/:9:1","tags":["GAN"],"title":"生成对抗网络GAN","uri":"/posts/gan_1/"},{"categories":["ML"],"content":"9.2 关于 G 的最小值 最大值求出来之后，我们再来看关于G的最小值，我们将$D^*$带进去： $$ \\begin{align} \\min_G \\max_D V(D, G) \u0026= \\min_G V(D^*G, G) \\ \u0026= \\min_G E{x \\sim P_{data}}[\\log(\\frac{P_{data}}{P_{data} + P_g})] + E_{x \\sim P_{g}}[\\log(1 - \\frac{P_{data}}{P_{data} + P_g})] \\ \u0026= \\min_G E_{x \\sim P_{data}}[\\log(\\frac{P_{data}}{P_{data} + P_g})] + E_{x \\sim P_{g}}[\\log(\\frac{P_{g}}{P_{data} + P_g})]\\ \\end{align} $$ 这里 $P_{data}$ 和 $P_g$，和KL散度的定义非常类似，KL divergence定义： $$KL(P||Q) = E_{x \\sim P}[\\log(\\frac{P(x)}{Q(x)})]$$ 但是我们不能直接这么写，我们需要保证分子和分母必须同时为两个概率分布，但是分母是$P_{data} + P_g$，是两个概率分布相加，那它的取值就变成[0, 2]了。 所以我们给它再除以个2就可以了，取值范围就又变成[0, 1]了。换句话说，可以把它看成概率密度函数，具体什么样子无所谓，它的取值在[0, 1]之间，并且是连续的。 $$ \\begin{align} \\min_G \\max_D V(D, G) \u0026= \\min_G V(D^*G, G) \\ \u0026= \\min_G E{x \\sim P_{data}}[\\log(\\frac{P_{data}}{P_{data} + P_g})] + E_{x \\sim P_{g}}[\\log(1 - \\frac{P_{data}}{P_{data} + P_g})] \\ \u0026= \\min_G E_{x \\sim P_{data}}[\\log(\\frac{P_{data}}{P_{data} + P_g})] + E_{x \\sim P_{g}}[\\log(\\frac{P_{g}}{P_{data} + P_g})]\\ \u0026= \\min_G E_{x \\sim P_{data}}[\\log(\\frac{P_{data}}{(P_{data} + P_g)/2} \\cdot\\frac{1}{2})] + E_{x \\sim P_{g}}[\\log(\\frac{P_{g}}{(P_{data} + P_g)/2}\\cdot\\frac{1}{2})]\\ \u0026= \\min_{G} KL (P_{data} || \\frac{P_{data} + P_g}{2}) + KL (P_{g} || \\frac{P_{data} + P_g}{2}) - \\log4\\ \\end{align} $$ tips 将两个$\\log(\\frac{1}{2})$拿出去，$\\log(\\frac{1}{2}) = \\log1 - \\log2 = -\\log2,$，$-\\log2$的期望就是它自己，两个就是$-\\log2-\\log2 = -\\log4$ 我们得出上式，发现它又满足 JS divergence 的定义： $$JSD(P||Q) = \\frac{1}{2} KL(P || M) + \\frac{1}{2} KL (Q||M), 其中 M = \\frac{P + Q}{2}$$ 所以上式又可写成： $$\\min_G - \\log 4 + 2 JSP(P_{data}||P_g)$$ JS divergence是衡量两个分布之间的距离，所以只有当这两个分布越来越相等的时候，就找到这个式子的最小值了，故： 当$P_g(x) = P_{data}(x)$时，上式可得最小值。 所以我们只需要优化： $$\\min_G\\max_D V(D, G) = \\mathbb{E}{x\\sim{p{data}(x)}}[\\log D(x)] + \\mathbb{E}{z\\sim{p{z}(z)}}[1 - \\log D(G(z))]$$ 就可以得到$P_g(x) = P_{data}(x)$. tips 另外，当 $P_g(x) = P_{data}(x)$ 时，又因为 $D^G = \\frac{P{data}}{P_{data} + P_g}$， 所以此时 $D^ = \\frac{1}{2}$ 。意思是，在最优的情况下，鉴赏专家已经没有分辨真假的能力了，概率都0.5，这个时候判别器对于生成器而言，已经没有继续学习的必要了。 ","date":"2023-07-26","objectID":"/posts/gan_1/:9:2","tags":["GAN"],"title":"生成对抗网络GAN","uri":"/posts/gan_1/"},{"categories":["ML"],"content":"十、原文给出的训练步骤 在每一个step里先采样m个噪音样本； 再采样m个来自于真实数据的样本；这样就组成了一个大小为2m的小批量； 将样本分别放到 生成器 和 辨别器 去求梯度，更新 辨别器 参数； 做完之后： 再采样m个噪音样本，放到公式的第二项里面（因为我们要更新生成器，生成器与第一项无关），算出它的梯度； 然后对生成器进行参数更新。 这样就完成了一次迭代，可以看到每次迭代里，我们是先更新辨别器，再更新生成器。 tips k是一个超参数，不能太小也不能太大，要保证辨别器有足够的更新，但也不要更新太好了。如果没有足够好的更新，就是生成器变换了之后，没有把辨别器更新的足够好， G已经做了变化，但是D没有做什么改变，再更新G来糊弄D，其实意义不大。 反过来讲，如果一更新就把D训练到完美，那么1-D就会变成0，对一个0的东西求导，那么就会在生成模型上更新有困难。 回到原文的例子，辨别器是警察，生成器就是造假者，假设警察特别厉害，造假者产一点假钞出来就被连锅端了，那造假者就没能力改进和提升自己了，但反过来讲，如果警察无力，造假者随便造点东西，警察也看不出来，那造假者就不会有动力去改进和提升自己。 所以最好是两者实力相当、相爱相杀，大家一起进步。所以k的调参，要使得D的更新和G的更新进度都差不多。 ","date":"2023-07-26","objectID":"/posts/gan_1/:10:0","tags":["GAN"],"title":"生成对抗网络GAN","uri":"/posts/gan_1/"},{"categories":["ML"],"content":"十一、GAN原理及训练过程总结 ","date":"2023-07-26","objectID":"/posts/gan_1/:11:0","tags":["GAN"],"title":"生成对抗网络GAN","uri":"/posts/gan_1/"},{"categories":["ML"],"content":"11.1、GAN原理总结 GAN主要包括了两部分： 生成器（Generator）：生成器主要用来学习真实数据的分布，从而让自身生成的数据更加真实，骗过判别器； 判别器（Discriminator）：判别器则需要对接受的数据进行真假判断。 在训练过程中，生成器努力地让生成的数据更加真实，而判别器则努力地去识别出数据的真假，这个过程相当于一个二人博弈，随着时间的推移，生成器和判别器在不断的进行对抗，这就是它对抗的含义。 最终两个网络达到了一个动态均衡：生成器生成的数据接近于真实数据分布，而判别器识别不出真假数据，对于给定数据的预测为真的概率基本接近0.5（相当于随机猜测类别）。 GAN设计的关键在于损失函数的处理： 对于判别模型，损失函数是容易定义的，判断一张图片是真实的还是生成的，显然是一个二分类问题。 对于生成模型，损失函数的定义就不是那么容易，我们希望生成器可以生成接近于真实的图片，对于生成的图片是否像真实的，我们人类肉眼容易判断，但具体到代码中，是一个抽象的，难以数学公里化定义的范式。 针对这个问题，我们不妨把生成模型的输出，交给判别模型处理，让判别器判断这是一个真实的图像还是假的图像，因为深度学习模型很适合做分类，这样就将生成器和判别器紧密地联合在了一起。 tips 假如我们直接用生成器训练，它的训练结果并不会得到一个真实的图像，而会得到一个比较模糊的图像，因为我们无法构建一个合适的损失去判断它是否像真实图片，所以它会将所有训练样本做平均，产生一个比较糊的图片。这就是为什么要将生成器的样本交给判别器来构建损失。 ","date":"2023-07-26","objectID":"/posts/gan_1/:11:1","tags":["GAN"],"title":"生成对抗网络GAN","uri":"/posts/gan_1/"},{"categories":["ML"],"content":"11.2、GAN算法流程总结 $G$ 是一个生成图片的网络，它接收一个随机的噪声z，通过这个噪声生成图片$G(z)$，记作； $D$ 是一个判别网络，判别一张图片是不是“真实的”，它的输入参数是x，x代表一张图片，输出$D(x)$，代表x为真实图片的概率，如果为1，就代表100%是真实的图片，输出为0，就代表不是真实图片。 在训练过程中，将随机噪声输入生成网络G，得到生成的图片；判别器接受生成的图片和真实的图片，并尽量将两者区分开来。在这个计算过程中，能否正确区分生成的图片和真实的图片将作为判别器的损失；而能否生成近似真实的图片、并使得判别器将生成的图片判定为真，将作为生成器的损失。 生成器的损失是通过判别器的输出来计算的，而判别器的输出是一个概率值，我们可以通过交叉熵来计算。 ","date":"2023-07-26","objectID":"/posts/gan_1/:11:2","tags":["GAN"],"title":"生成对抗网络GAN","uri":"/posts/gan_1/"},{"categories":["ML"],"content":"十二、torch复现 https://wangguisen.blog.csdn.net/article/details/127820071 ref: [1]. https://arxiv.org/abs/1406.2661 [2]. https://www.bilibili.com/video/BV1eE411g7xc [3]. https://www.bilibili.com/video/BV1rb4y187vD [4]. https://www.bilibili.com/video/BV1HD4y1S7Pe ","date":"2023-07-26","objectID":"/posts/gan_1/:12:0","tags":["GAN"],"title":"生成对抗网络GAN","uri":"/posts/gan_1/"},{"categories":["ML"],"content":"Transformer 详解 Transformer 是谷歌大脑在 2017 年底发表的论文 attention is all you need 中所提出的 seq2seq 模型。现在已经取得了大范围的应用和扩展，而 BERT 就是从 Transformer 中衍生出来的预训练语言模型 这篇文章分为以下几个部分 Transformer 直观认识 Positional Encoding Self Attention Mechanism 残差连接和 Layer Normalization Transformer Encoder 整体结构 Transformer Decoder 整体结构 总结 参考文章 ","date":"2023-07-24","objectID":"/posts/transformerdetailedexplanation/:1:0","tags":["Transformer"],"title":"Transformer 详解","uri":"/posts/transformerdetailedexplanation/"},{"categories":["ML"],"content":"0. Transformer 直观认识 Transformer 和 LSTM 的最大区别，就是 LSTM 的训练是迭代的、串行的，必须要等当前字处理完，才可以处理下一个字。而 Transformer 的训练时并行的，即所有字是同时训练的，这样就大大增加了计算效率。Transformer 使用了位置嵌入 (Positional Encoding) 来理解语言的顺序，使用自注意力机制(Self Attention Mechanism)和全连接层进行计算，这些后面会讲到。 Transformer 模型主要分为两大部分，分别是 Encoder 和 Decoder。Encoder 负责把输入(语言序列)映射成隐藏层(下图中第 2 步用九宫格代表的部分)，然后解码器再把隐藏层映射为自然语言序列。例如下图机器翻译的例子(Decoder 输出的时候，是通过 N 层 Decoder Layer 才输出一个 token，并不是通过一层 Decoder Layer 就输出一个 token)。 本篇文章大部分内容在于解释 Encoder 部分，即 **把自然语言序列映射为隐藏层的数学表达**的过程。理解了 Encoder 的结构，再理解 Decoder 就很简单了 上图为 Transformer Encoder Block 结构图，注意：下面的内容标题编号分别对应着图中 1,2,3,4 个方框的序号 ","date":"2023-07-24","objectID":"/posts/transformerdetailedexplanation/:1:1","tags":["Transformer"],"title":"Transformer 详解","uri":"/posts/transformerdetailedexplanation/"},{"categories":["ML"],"content":"1. Positional Encoding 由于 Transformer 模型没有循环神经网络的迭代操作，所以我们必须提供每个字的位置信息给 Transformer，这样它才能识别出语言中的顺序关系。 现在定义一个 位置嵌入 的概念，也就是 Positional Encoding，位置嵌入的维度为 [max_sequence_length, embedding_dimension], 位置嵌入的维度与词向量的维度是相同的，都是 embedding_dimension。max_sequence_length 属于超参数，指的是限定每个句子最长由多少个词构成。 注意，我们一般以字为单位训练 Transformer 模型。首先初始化字编码的大小为 [vocab_size, embedding_dimension]，vocab_size 为字库中所有字的数量，embedding_dimension 为字向量的维度，对应到 PyTorch 中，其实就是 nn.Embedding(vocab_size, embedding_dimension) 在论文中使用了 sin 和 cos 函数的线性变换来提供给模型位置信息: $$\\left\\{\\begin{aligned} PE(pos, 2i) = \\sin (pos/10000^{2i/d_{model}}) \\cr PE(pos, 2i + 1) = \\cos (pos/10000^{2i/d_{model}}) \\cr \\end{aligned}\\right.$$ 上式中 $pos$ 指的是一句话中某个字的位置，取值范围是 $[0, \\text{max_sequence_length}]$ ， $i$ 指的是字向量的维度序号，取值范围是 $[0, \\text{embedding_dimension} / 2]$ ， $d_{model}$ 指的是 embedding_dimension​的值 上面有 sin 和 cos 一组公式，也就是对应着 embedding_dimension 维度的一组奇数和偶数的序号的维度，例如 0,1 一组，2,3 一组，分别用上面的 sin 和 cos 函数做处理，从而产生不同的周期性变化，而位置嵌入在 embedding_dimension​维度上随着维度序号增大，周期变化会越来越慢，最终产生一种包含位置信息的纹理，就像论文原文中第六页讲的，位置嵌入函数的周期从 $ 2\\pi $ 到 $10000 * 2 \\pi$ 变化，而每一个位置在 embedding_dimension ​维度上都会得到不同周期的 $ \\sin $ 和 $ \\cos $ 函数的取值组合，从而产生唯一的纹理位置信息，最终使得模型学到位置之间的依赖关系和自然语言的时序特性。 如果不理解这里为何这么设计，可以看这篇文章 Transformer 中的 Positional Encoding 下面画一下位置嵌入，纵向观察，可见随着 embedding_dimension​序号增大，位置嵌入函数的周期变化越来越平缓 import numpy as np import matplotlib.pyplot as plt import seaborn as sns import math def get_positional_encoding(max_seq_len, embed_dim): # 初始化一个positional encoding # embed_dim: 字嵌入的维度 # max_seq_len: 最大的序列长度 positional_encoding = np.array([ [pos / np.power(10000, 2 * i / embed_dim) for i in range(embed_dim)] if pos != 0 else np.zeros(embed_dim) for pos in range(max_seq_len)]) positional_encoding[1:, 0::2] = np.sin(positional_encoding[1:, 0::2]) # dim 2i 偶数 positional_encoding[1:, 1::2] = np.cos(positional_encoding[1:, 1::2]) # dim 2i+1 奇数 return positional_encoding positional_encoding = get_positional_encoding(max_seq_len=100, embed_dim=16) plt.figure(figsize=(10,10)) sns.heatmap(positional_encoding) plt.title(\"Sinusoidal Function\") plt.xlabel(\"hidden dimension\") plt.ylabel(\"sequence length\") plt.figure(figsize=(8, 5)) plt.plot(positional_encoding[1:, 1], label=\"dimension 1\") plt.plot(positional_encoding[1:, 2], label=\"dimension 2\") plt.plot(positional_encoding[1:, 3], label=\"dimension 3\") plt.legend() plt.xlabel(\"Sequence length\") plt.ylabel(\"Period of Positional Encoding\") ","date":"2023-07-24","objectID":"/posts/transformerdetailedexplanation/:1:2","tags":["Transformer"],"title":"Transformer 详解","uri":"/posts/transformerdetailedexplanation/"},{"categories":["ML"],"content":"2. Self Attention Mechanism 对于输入的句子 $ X $，通过 WordEmbedding 得到该句子中每个字的字向量，同时通过 Positional Encoding 得到所有字的位置向量，将其相加(维度相同，可以直接相加)，得到该字真正的向量表示。第 $ t $ 个字的向量记作 $ x_t $。 接着我们定义三个矩阵 $ W_Q $, $ W_K $, $ W_V $，使用这三个矩阵分别对所有的字向量进行三次线性变换，于是所有的字向量又衍生出三个新的向量 $ q_t $, $ k_t $, $ v_t $。我们将所有的 $ q_t $ 向量拼成一个大矩阵，记作查询矩阵 $ Q $ ，将所有的 $ k_t $ 向量拼成一个大矩阵，记作键矩阵 $ K $ ，将所有的 $ v_t $ 向量拼成一个大矩阵，记作值矩阵 $ V $ (见下图) 为了获得第一个字的注意力权重，我们需要用第一个字的查询向量 $ q_1 $ 乘以键矩阵 $ K $(见下图) [0, 4, 2] [1, 0, 2] x [1, 4, 3] = [2, 4, 4] [1, 0, 1] 之后还需要将得到的值经过 softmax，使得它们的和为 1(见下图) softmax([2, 4, 4]) = [0.0, 0.5, 0.5] 有了权重之后，将权重其分别乘以对应字的值向量 $ v_t $(见下图) 0.0 * [1, 2, 3] = [0.0, 0.0, 0.0] 0.5 * [2, 8, 0] = [1.0, 4.0, 0.0] 0.5 * [2, 6, 3] = [1.0, 3.0, 1.5] 最后将这些权重化后的值向量求和，得到第一个字的输出(见下图) [0.0, 0.0, 0.0] + [1.0, 4.0, 0.0] + [1.0, 3.0, 1.5] ----------------- = [2.0, 7.0, 1.5] 对其它的输入向量也执行相同的操作，即可得到通过 self-attention 后的所有输出 矩阵计算 上面介绍的方法需要一个循环遍历所有的字$ x_t $，我们可以把上面的向量计算变成矩阵的形式，从而一次计算出所有时刻的输出 第一步就不是计算某个时刻的$ q_t $, $ k_t $, $ v_t $了，而是一次计算所有时刻的 $ Q $, $ K $, $ V $。计算过程如下图所示，这里的输入是一个矩阵 $ X $，矩阵第 $ t $ 行为第 $ t $ 个词的向量表示 $x_t$ 接下来将 $ Q $ 和 $K_T$ 相乘，然后除以 $ \\sqrt{d_k} $(这是论文中提到的一个 trick)，经过 softmax 以后再乘以 $ V $ 得到输出 Multi-Head Attention 这篇论文还提出了 Multi-Head Attention 的概念。其实很简单，前面定义的一组 $Q $, $ K $, $ V $, 可以让一个词 attend to 相关的词，我们可以定义多组 $Q $, $ K $, $ V $，让它们分别关注不同的上下文。计算 $Q $, $ K $, $ V $ 的过程还是一样，只不过线性变换的矩阵从一组 $ W^Q $, $ W^K $, $ W^V $ 变成了多组$ W^Q_0 $, $ W^K_0 $, $ W^V_0 $ ，$ W^Q_1 $, $ W^K_1 $, $ W^V_1 $ ，… 如下图所示: 对于输入矩阵 $ X $ ，每一组 $ Q $ 、$ K $ 和 $ V $ 都可以得到一个输出矩阵 $ Z $ 。如下图所示 Padding Mask 上面 Self Attention 的计算过程中，我们通常使用 mini-batch 来计算，也就是一次计算多句话，即 $ X $ 的维度是 [batch_size, sequence_length]，sequence_length​是句长，而一个 mini-batch 是由多个不等长的句子组成的，我们需要按照这个 mini-batch 中最大的句长对剩余的句子进行补齐，一般用 0 进行填充，这个过程叫做 padding 但这时在进行 softmax 就会产生问题。回顾 softmax 函数 $\\sigma(z_i) = \\frac{e^{z_i}}{\\sum_K^{j=i} e^{z_j}}$，$e^0$ 是 1，是有值的，这样的话 softmax 中被 padding 的部分就参与了运算，相当于让无效的部分参与了运算，这可能会产生很大的隐患。因此需要做一个 mask 操作，让这些无效的区域不参与运算，一般是给无效区域加一个很大的负数偏置，即 $$ \\begin{aligned}Z_{illegal}\u0026=Z_{illegal}+bias_{illegal}\\cr bias_{illegal}\u0026\\to-\\infty\\end{aligned} $$ ","date":"2023-07-24","objectID":"/posts/transformerdetailedexplanation/:1:3","tags":["Transformer"],"title":"Transformer 详解","uri":"/posts/transformerdetailedexplanation/"},{"categories":["ML"],"content":"3. 残差连接和 Layer Normalization 残差连接 我们在上一步得到了经过 self-attention 加权之后输出，也就是$\\text{Self-Attention(Q, K, V)}$，然后把他们加起来做残差连接 $$X_{\\text{embedding}} + \\text{Self-Attention(Q, K, V)}$$ Layer Normalization Layer Normalization 的作用是把神经网络中隐藏层归一为标准正态分布，也就是 $i.i.d$ 独立同分布，以起到加快训练速度，加速收敛的作用 $$\\mu_j=\\frac1m\\sum_{i=1}^mx_{ij}$$ 上式以矩阵的列(column)为单位求均值； $$\\sigma^2_{j} = \\frac{1}{m}\\sum^m_{i=1}(x_{ij} - \\mu_j)^2$$ 上式以矩阵的列(column)为单位求方差 $$LayerNorm(x) = \\frac{x_{ij} - \\mu_{j}}{\\sqrt{\\sigma^2 + \\epsilon}}$$ 然后用每一列的每一个元素减去这列的均值，再除以这列的标准差，从而得到归一化后的数值，加 $\\epsilon$ 是为了防止分母为 0。 下图展示了更多细节：输入 $x_1, x_2$ 经 self-attention 层之后变成 $z_1, z_2$，然后和输入 $x_1, x_2$ 进行残差连接，经过 LayerNorm 后输出给全连接层。全连接层也有一个残差连接和一个 LayerNorm，最后再输出给下一个 Encoder(每个 Encoder Block 中的 FeedForward 层权重都是共享的) ","date":"2023-07-24","objectID":"/posts/transformerdetailedexplanation/:1:4","tags":["Transformer"],"title":"Transformer 详解","uri":"/posts/transformerdetailedexplanation/"},{"categories":["ML"],"content":"4. Transformer Encoder 整体结构 经过上面 3 个步骤，我们已经基本了解了 Encoder 的主要构成部分，下面我们用公式把一个 Encoder block 的计算过程整理一下： (1). 字向量与位置编码 $$X = \\text{Embedding-Lookup(X)} + \\text{Positional-Encoding}$$ (2). 自注意力机制 $$Q = Linear_{q}(X) = XW_{Q}$$ $$K = Linear_{k}(X) = XW_{K}$$ $$V = Linear_{v}(X) = XW_{V}$$ $$X_{attention} = \\text{Self-Attention(Q, K, V)}$$ (3). self-attention 残差连接与 Layer Normalization $$X_{attention} = X + X_{attention}$$ $$X_{attention} = LayerNorm(attention)$$ (4). 下面进行 Encoder block 结构图中的第 4 部分，也就是 FeedForward，其实就是两层线性映射并用激活函数激活，比如说 $ReLU$ $$X_{hidden} = Linear(ReLU(Linear(X_{attention})))$$ (5). FeedForward 残差连接与 Layer Normalization $$X_{hidden} = X_{attention} + X_{hidden}$$ $$X_{hidden} = LayerNorm(X_{hidden})$$ 其中 $$X_{hidden} \\in \\mathbb{R}^{batch_size * seq_len * embed_dim}$$ ","date":"2023-07-24","objectID":"/posts/transformerdetailedexplanation/:1:5","tags":["Transformer"],"title":"Transformer 详解","uri":"/posts/transformerdetailedexplanation/"},{"categories":["ML"],"content":"5. Transformer Decoder 整体结构 我们先从 HighLevel 的角度观察一下 Decoder 结构，从下到上依次是： Masked Multi-Head Self-Attention Multi-Head Encoder-Decoder Attention FeedForward Network 和 Encoder 一样，上面三个部分的每一个部分，都有一个残差连接，后接一个 Layer Normalization。Decoder 的中间部件并不复杂，大部分在前面 Encoder 里我们已经介绍过了，但是 Decoder 由于其特殊的功能，因此在训练时会涉及到一些细节 Masked Self-Attention 具体来说，传统 Seq2Seq 中 Decoder 使用的是 RNN 模型，因此在训练过程中输入 $t$ 时刻的词，模型无论如何也看不到未来时刻的词，因为循环神经网络是时间驱动的，只有当 $t$ 时刻运算结束了，才能看到 $t + 1$ 时刻的词。而 Transformer Decoder 抛弃了 RNN，改为 Self-Attention，由此就产生了一个问题，在训练过程中，整个 ground truth 都暴露在 Decoder 中，这显然是不对的，我们需要对 Decoder 的输入进行一些处理，该处理被称为 Mask 举个例子，Decoder 的 ground truth 为 “ I am fine”，我们将这个句子输入到 Decoder 中，经过 WordEmbedding 和 Positional Encoding 之后，将得到的矩阵做三次线性变换 $(W_Q, W_K, W_V)$。然后进行 self-attention 操作，首先通过得到 Scaled Scores，接下来非常关键，我们要对 Scaled Scores 进行 Mask，举个例子，当我们输入 “I” 时，模型目前仅知道包括 “I” 在内之前所有字的信息，即 “” 和 “I” 的信息，不应该让其知道 “I” 之后词的信息。道理很简单，我们做预测的时候是按照顺序一个字一个字的预测，怎么能这个字都没预测完，就已经知道后面字的信息了呢？Mask 非常简单，首先生成一个下三角全 0，上三角全为负无穷的矩阵，然后将其与 Scaled Scores 相加即可 之后再做 softmax，就能将 - inf 变为 0，得到的这个矩阵即为每个字之间的权重 Multi-Head Self-Attention 无非就是并行的对上述步骤多做几次，前面 Encoder 也介绍了，这里就不多赘述了 Masked Encoder-Decoder Attention 其实这一部分的计算流程和前面 Masked Self-Attention 很相似，结构一模一样，唯一不同的是这里的 K, V为 Encoder 的输出，Q 为 Decoder 中 Masked Self-Attention 的输出 ","date":"2023-07-24","objectID":"/posts/transformerdetailedexplanation/:1:6","tags":["Transformer"],"title":"Transformer 详解","uri":"/posts/transformerdetailedexplanation/"},{"categories":["ML"],"content":"6. 总结 到此为止，Transformer 中 95% 的内容已经介绍完了，我们用一张图展示其完整结构。不得不说，Transformer 设计的十分巧夺天工。 下面有几个问题，是我从网上找的，感觉看完之后能对 Transformer 有一个更深的理解 Transformer 为什么需要进行 Multi-head Attention？ 原论文中说到进行 Multi-head Attention 的原因是将模型分为多个头，形成多个子空间，可以让模型去关注不同方面的信息，最后再将各个方面的信息综合起来。其实直观上也可以想到，如果自己设计这样的一个模型，必然也不会只做一次 attention，多次 attention 综合的结果至少能够起到增强模型的作用，也可以类比 CNN 中同时使用多个卷积核的作用，直观上讲，多头的注意力有助于网络捕捉到更丰富的特征信息 Transformer 相比于 RNN/LSTM，有什么优势？为什么？ RNN 系列的模型，无法并行计算，因为 T 时刻的计算依赖 T-1 时刻的隐层计算结果，而 T-1 时刻的计算依赖 T-2 时刻的隐层计算结果 Transformer 的特征抽取能力比 RNN 系列的模型要好 为什么说 Transformer 可以代替 seq2seq？ 这里用代替这个词略显不妥当，seq2seq 虽已老，但始终还是有其用武之地，seq2seq 最大的问题在于将Encoder端的所有信息压缩到一个固定长度的向量中，并将其作为 Decoder 端首个隐藏状态的输入，来预测 Decoder 端第一个单词 (token) 的隐藏状态。在输入序列比较长的时候，这样做显然会损失 Encoder 端的很多信息，而且这样一股脑的把该固定向量送入 Decoder 端，Decoder 端不能够关注到其想要关注的信息。 Transformer 不但对 seq2seq 模型这两点缺点有了实质性的改进 (多头交互式 attention 模块)，而且还引入了 self-attention 模块，让源序列和目标序列首先 “自关联” 起来，这样的话，源序列和目标序列自身的 embedding 表示所蕴含的信息更加丰富，而且后续的 FFN 层也增强了模型的表达能力，并且 Transformer 并行计算的能力远远超过了 seq2seq 系列模型 ","date":"2023-07-24","objectID":"/posts/transformerdetailedexplanation/:1:7","tags":["Transformer"],"title":"Transformer 详解","uri":"/posts/transformerdetailedexplanation/"},{"categories":["ML"],"content":"7. 参考文章 Transformer The Illustrated Transformer TRANSFORMERS FROM SCRATCH Seq2seq pay Attention to Self Attention: Part 2 ref: [1]. B站讲解视频 [2]. https://wmathor.com/index.php/archives/1438/ [3]. Transformer的pytorch实现 ","date":"2023-07-24","objectID":"/posts/transformerdetailedexplanation/:1:8","tags":["Transformer"],"title":"Transformer 详解","uri":"/posts/transformerdetailedexplanation/"},{"categories":["C++"],"content":"函数声明的几种方式 声明一个函数f带有一个double而且返回一个int： int f(double d); 名为d的参数左右的括号是多余的，被忽略： int f(double (d)); // 同上；d左右的括号被忽略 省略了参数名： int f(double); // 同上；参数名被省略 第一个声明了一个函数g，它带有一个参数，那个参数是指向一个没有参数、返回double的函数的指针： int g(double (*pf)()); // g带有一个指向函数的指针作为参数 唯一的不同是pf使用非指针语法来声明(一个在C和C++中都有效的语法): int g(double pf()); // 同上；pf其实是一个指针 照常，参数名可以省略，所以这是g的第三种声明，去掉了pf这个名字： int g(double ()); // 同上；参数名省略 注意参数名左右的括号（就像f的第二种声明中的d）和单独的括号（正如本例）之间的区别。 参数名左右的括号被忽略，但单独的括号指出存在一个参数列表：它们声明了存在指向函数的指针的参数。 ","date":"2023-07-24","objectID":"/posts/clause_6/:1:0","tags":["Effective STL"],"title":"Effective STL [6] | 警惕C++最令人恼怒的解析","uri":"/posts/clause_6/"},{"categories":["C++"],"content":"问题探讨 假设有一个int的文件，想要把那些int拷贝到一个list中，可能会使用下面代码： ifstream dataFile(\"ints.dat\"); // 警告！这完成的并不是像你想象的那样 list\u003cint\u003e data(istream_iterator\u003cint\u003e(dataFile), istream_iterator\u003cint\u003e()); 这里的想法是传一对istream_iterator给list的区间构造函数，因此把int从文件拷贝到list中。 这段代码可以编译，但是运行时什么都不会做，不会从文件中读出任何数据，甚至不会构建1个list。 第二句并不声明list，也不调用构造函数。 这声明了一个函数data，它的返回类型是list\u003cint\u003e。这个函数data带有两个参数： ● 第1个参数叫做dataFile。它的类型是istream_iterator\u003cint\u003e。dataFile左右的括号是多余的而且被忽略。 ● 第2个参数没有名字。它的类型是指向一个没有参数而且返回istream_iterator\u003cint\u003e的函数的指针。 就像下面具有这条规则的代码： class Widget {...}; // 假设Widget有默认构造函数 Widget w(); 这并没有声明一个叫做w的Widget，它声明了一个叫作w的没有参数且返回Widget的函数。 本来代码的初衷，是用一个文件的内容来初始化一个list\u003cint\u003e对象，现在并没有达到我们的期望。 ","date":"2023-07-24","objectID":"/posts/clause_6/:2:0","tags":["Effective STL"],"title":"Effective STL [6] | 警惕C++最令人恼怒的解析","uri":"/posts/clause_6/"},{"categories":["C++"],"content":"解决办法 函数调用前后增加括号 用括号包围一个实参的声明是不合法的，但用括号包围一个函数调用的观点是合法的，所以通过增加一对括号，代码变为： list\u003cint\u003e data((istream_iterator\u003cint\u003e(dataFile)), // 注意在list构造函数的第一个实参左右的新括号 istream_iterator\u003cint\u003e()); 这是可能的声明数据方法，给予istream_iterators的实用性和区间构造函数。 命名迭代器对象 ifstream dataFile(\"ints.dat\"); istream_iterator\u003cint\u003e dataBegin(dataFile); istream_iterator\u003cint\u003e dataEnd; list\u003cint\u003e data(dataBegin, dataEnd); 命名迭代器对象的使用和普通的STL编程风格相反，但是你得判断这种方法对编译器和必须使用编译器的人都模棱两可的代码是一个值得付出的代价。 ","date":"2023-07-24","objectID":"/posts/clause_6/:3:0","tags":["Effective STL"],"title":"Effective STL [6] | 警惕C++最令人恼怒的解析","uri":"/posts/clause_6/"},{"categories":["C++"],"content":"Example Q：给定两个vector，v1和v2，使v1的内容和v2的后半部分一样的最简单方式是什么？ A： v1.assign(v2.begin() + v2.size() / 2, v2.end()); 这个测验设计为做两件事: 它提供给我一个机会来提醒你assign成员函数的存在 太多的程序员没注意到这是一个很方便的方法。它对于所有标准序列容器（vector，string，deque和list）都有效。 无论何时你必须完全代替一个容器的内容，你就应该想到赋值。 如果你只是拷贝一个容器到另一个同类型的容器，operator=就是选择的赋值函数，但对于示范的那个例子，当你想要给一个容器完全的新数据集时，assign就可以利用，但operator=做不了。 演示为什么区间成员函数优先于它们的单元素替代品。 区间成员函数是一个像STL算法的成员函数，使用两个迭代器参数来指定元素的一个区间来进行某个操作。 不用区间成员函数来解决这个条款开头的问题，你就必须写一个显式循环，可能就像这样: vector\u003cRandy\u003e v1, v2; // 假设v1和v2是Randy的vector v1.clear(); for (vector\u003cRandy\u003e::const_iterator ci = v2.begin() + v2.size() / 2; ci != v2.end(); ++ci) { v1.push_back(*ci); } 写这段代码比写assign的调用要做多得多的工作。 copy 替代循环 v1.clear(); copy(v2.begin() + v2.size() / 2, v2.end(), back_inserter(v1)) 虽然在这段代码中没有表现出循环，在copy中的确存在一个循环 。 效率损失仍然存在。 几乎所有目标区间是通过插入迭代器（比如，通过inserter，back_inserter或front_inserter）指定的copy的使用都可以——应该——通过调用区间 成员函数来代替。 比如这里，这个copy的调用可以用一个insert的区间版本代替： v1.insert(v1.end(), v2.begin() + v2.size() / 2, v2.end()); 这个输入量稍微比调用copy少，但它发生的也比说的要直接：数据插入v1。 这里insert 也比 copy 好，因为字面上insert 表示有数据插入到了 v1中，而copy 的使用把它变得晦涩。 关于东西被拷贝这个事实并没有什么好关注的，因为STL构建在东西会被拷贝的假定上。拷贝对STL来说很基本。 小结 我们已经确定3个尽量使用区间成员函数代替它们的单元素兄弟的理由。 ● 一般来说使用区间成员函数可以输入更少的代码。 ● 区间成员函数会导致代码更清晰更直接了当。 ","date":"2023-07-24","objectID":"/posts/clause_5/:1:0","tags":["Effective STL"],"title":"Effective STL [5] | 尽量使用区间成员函数代替它们的单元素兄弟","uri":"/posts/clause_5/"},{"categories":["C++"],"content":"效率 当处理标准序列容器时，应用单元素成员函数比完成同样目的的区间成员函数需要更多地内存分配，更频繁地拷贝对象，而且/或者造成多余操作。 对此，我之前还做了个单元素兄弟插入和批量插入的效率比较的文章《vector 用 insert 批量插入效率高还是emplace_back效率高》，也证实了这个观点。 标准要求区间insert函数直接把现有元素移动到它们最后的位置，也就是，开销是每个元素一次移动。总共开销是n次移动，numValues次容器中的对象类型的拷贝构造函数，剩下的是类型的赋值操作符。 相比单元素插入策略，区间insert少执行了n*(numValues-1)次移动。 花一分钟想想。这意味着如果numValues是100，insert的区间形式会比重复调用insert的单元素形式的代码少花费99%的移动！ 仅当可以不用失去两个迭代器的位置就能决定它们之间的距离时，一个区间insert函数才能在一次移动中把一个元素移动到它的最终位置。 这几乎总是可能的，因为所有前向迭代器提供了这个功能，而且前向迭代器几乎到处都是。 所有用于标准容器的迭代器都提供了前向迭代器的功能。非标准的散列容器的迭代器也是。 在数组中表现为迭代器的指针也提供了这样的功能。事实上，唯一不提供前向迭代器能力的标准迭代器是输入和输出迭代器。 单元素插入的问题 当你试图去把一个元素插入内存已经满了的vector时，这个vector会分配具有更多容量的新内存，从旧内存把它的元素拷贝到新内存，销毁旧内存里的元素，回收旧内存。然后它添加插入的元素。 每当用完内存时，大部分vector实现都使它们的容量翻倍，所以插入numValues个新元素会导致最多$\\log_2{numValues}$次新内存的分配。 每次一个地插入1000个元素会导致10次新的分配（包括它们负责的元素拷贝）。 与之对比的是，一个区间插入可以在开始插入东西前计算出需要多少新内存（假设给的是前向迭代器），所以它不用多于一次地重新分配vector的内在内存。 刚才进行分析是用于vector的，但同样的理由也作用于string。 deque 对于deque，理由也很相似，但deque管理它们内存的方式和vector和string不同，所以重复内存分配的论点不能应用。 但是，关于很多次不必要的元素移动的论点通常通过对函数调用次数的观察也应用到了（虽然细节不同）。 list 在这里使用insert区间形式代替单元素形式也有一个性能优势。 关于重复函数调用的论点当然继续有效，但因为链表的工作方式，拷贝和内存分配问题没有发生。 取而代之的是，这里有一个新问题：过多重复地对list中的一些节点的next和prev指针赋值。 每当一个元素添加到一个链表时，持有元素的链表节点必须有它的next和prev指针集，而且当然新节点前面的节点（我们叫它B，就是“before”）必须设置它的next指针，新节点后面的节点（我们叫它A，就是“after”）必须设置它的prev指针 当一系列新节点通过调用list的单元素insert一个接一个添加时，除了最后一个以外的其他新节点都会设置它的next指针两次，第一次指向A，第二次指向在它后面插入的元素。每次在A前面插入时，它都会设置它的prev指针指向一个新节点。 如果numValues个节点插入A前面，插入节点的next指针会发生次多余的赋值，而且A的prev指针会发生numValues-1次多余的赋值。合计次没有必要的指针赋值。当然，指针赋值很轻量，但如果不是必须，为什么要为它们花费呢？ **避免开销的关键是使用list的insert区间形式。**因为那个函数知道最后有多少节点会被插入，它可以避免多余的指针赋值，对每个指针只使用一次赋值就能设置它正确的插入后的值 ","date":"2023-07-24","objectID":"/posts/clause_5/:2:0","tags":["Effective STL"],"title":"Effective STL [5] | 尽量使用区间成员函数代替它们的单元素兄弟","uri":"/posts/clause_5/"},{"categories":["C++"],"content":"区间函数 参数类型iterator意思是容器的迭代器类型，也就是container::iterator。 参数类型InputIterator意思是可以接受任何输入迭代器。 区间构造 所有标准容器都提供这种形式的构造函数： container::container(InputIterator begin, // 区间的起点 InputIterator end); // 区间的终点 如果传给这个构造函数的迭代器是istream_iterators或istreambuf_iterators，你可能会遇到C++的最惊异的解析，原因之一是你的编译器可能会因为把这个构造看作一个函数声明而不是一个新容器对象的定义而中断。 区间插入 所有标准序列容器都提供这种形式的insert: void container::insert(iterator position, // 区间插入的位置 InputIterator begin, // 插入区间的起点 InputIterator end); // 插入区间的终点 关联容器使用它们的比较函数来决定元素要放在哪里，所以它们了省略position参数。 void container::insert(lnputIterator begin, InputIterator end); 当寻找用区间版本代替单元素插入的方法时，不要忘记有些单元素变量用采用不同的函数名伪装它们自己。比如，push_front和push_back都把单元素插入容器，即使它们不叫insert。如果你看见一个循环调用push_front或push_back，或如果你看见一个算法——比如copy——的参数是front_inserter或者back_inserter，你就发现了一个insert的区间形式应该作为优先策略的地方。 区间删除 每个标准容器都提供了一个区间形式的erase，但是序列和关联容器的返回类型不同。 序列容器提供了这个： iterator container::erase(iterator begin, iterator end); 关联容器提供这个: void container::erase(iterator begin, iterator end); Q：为什么不同？ A：解释是，如果erase的关联容器版本返回一个迭代器（被删除的那个元素的下一个）会招致一个无法接受的性能下降。 这个条款的对insert的性能分析大部分也同样可以用于erase。单元素删除的函数调用次数仍然大于一次调用区间删除。当使用单元素删除时，每一次元素值仍然必须向它们的目的地移动一位，而区间删除可以在一个单独的移动中把它们移动到目标位置。 关于vector和string的插入和删除的一个论点是必须做很多重复的分配。（当然对于删除，会发生重复的回收。）那是因为用于vector和string的内存自动增长来适应于新元素，但当元素的数目减少时它不自动收缩。 区间赋值 所有标准列容器都提供了区间形式的assign: void container::assign(InputIterator begin, InputIterator end); ","date":"2023-07-24","objectID":"/posts/clause_5/:3:0","tags":["Effective STL"],"title":"Effective STL [5] | 尽量使用区间成员函数代替它们的单元素兄弟","uri":"/posts/clause_5/"},{"categories":["C++"],"content":"结论 几乎所有目标区间被插入迭代器指定的copy的使用都可以用调用的区间成员函数的来代替 。 尽量使用区间成员函数来代替单元素兄弟的三个可靠的论点。区间成员函数更容易写，它们更清楚地表达你的意图，而且它们提供了更高的性能。那是很难打败的三驾马车。 ref: [1]. https://mp.weixin.qq.com/s?__biz=MzUyMDc2MDMxNg==\u0026mid=2247490705\u0026idx=1\u0026sn=830797e69b61fe9693bf4aaea72df4b3\u0026chksm=f9e42202ce93ab1437ad36c37e141b0794328495c0c584d808d0f4ad36251680dbfba257b060\u0026cur_album_id=3009999611861975043\u0026scene=189#wechat_redirect ","date":"2023-07-24","objectID":"/posts/clause_5/:4:0","tags":["Effective STL"],"title":"Effective STL [5] | 尽量使用区间成员函数代替它们的单元素兄弟","uri":"/posts/clause_5/"},{"categories":["draft"],"content":"判断容器是否为空 对于任意容器 randy, 当判断是否为空的时候，会使用到以下判断语句： if(randy.size() == 0) { ... // work } // or if(randy.empty()) { ... // work } 应该首选empty的构造，而且理由很简单：对于所有的标准容器，empty是一个常数时间的操作，但对于一些list实现，size花费线性时间 ","date":"2023-07-24","objectID":"/posts/clause_4/:1:0","tags":["draft"],"title":"Effective STL [4] | 用empty来代替检查size()是否为0","uri":"/posts/clause_4/"},{"categories":["draft"],"content":"list size耗时 Q：但是什么造成list这么麻烦？为什么不能也提供一个常数时间的size？ A：对于list特有的splice有很多要处理的东西。 考虑这段代码： list\u003cint\u003e list1; list\u003cint\u003e list2; ... list1.splice( // 把list2中 list1.end(), list2, // 从第一次出现5到 find(list2.begin(), list2.end(), 5), // 最后一次出现10 find(list2.rbegin(), list2.rend(), 10).base() // 的所有节点移到list1的结尾。 ); 除非list2在5的后面有一个10，否则这段代码无法工作，但是咱们假设这不是问题。 Q：假设上述代码可以正常运行，那么接合后list1有多少元素？ A：结合后list1的元素个数=接合之后前list1的元素个数 + 接合进去的元素个数 Q：有多少元素接合进去了？ A：元素个数为find(list2.rbegin(), list2.rend(), 10).base()所定义的区间的元素个数。 到底有多少？ 在没有遍历这个区间并计数之前无法知道。 问题剖析 如果size是一个常数时间操作，当操作时每个list成员函数必须更新list的大小。也包括了splice。 让区间版本的splice更新它所更改的list大小的唯一的方法是算出接合进来的元素的个数，但那么做就会使它不可能有你所希望的常数时间的性能。 如果你去掉了splice的区间形式要更新它所修改的list的大小的需求，splice就可以是常数时间，但size就变成线性时间的操作。 一般来说，必须遍历它的整个数据结构来才知道包含多少元素。 不同的list实现用不同的方式解决这个矛盾，依赖于他们的作者选择的是让size或splice的区间形式达到最高效率。 如果你碰巧使用了一个常数时间的splice的区间形式比常数时间的size优先级更高的list实现，调用empty比调用size更好，因为empty总是常数时间操作。 ","date":"2023-07-24","objectID":"/posts/clause_4/:2:0","tags":["draft"],"title":"Effective STL [4] | 用empty来代替检查size()是否为0","uri":"/posts/clause_4/"},{"categories":["draft"],"content":"结论 不同的list实现用不同的方式解决这个矛盾，依赖于它们的作者选择的是让size或splice的区间形式达到最高效率。 如果你碰巧使用了一个常数时间的splice的区间形式比常数时间的size优先级更高的list实现，调用empty比调用size更好，因为empty总是常数时间操作。 ","date":"2023-07-24","objectID":"/posts/clause_4/:3:0","tags":["draft"],"title":"Effective STL [4] | 用empty来代替检查size()是否为0","uri":"/posts/clause_4/"},{"categories":["draft"],"content":"STL vector 和 list的empty 及 size 实现源码 vector // vector size_type size() const _GLIBCXX_NOEXCEPT { return size_type(end() - begin()); } bool empty() const _GLIBCXX_NOEXCEPT { return begin() == end(); } list // list /** Returns the number of elements in the %list. */ size_type size() const _GLIBCXX_NOEXCEPT { return _M_node_count(); } // return the stored size size_t _M_node_count() const { return this-\u003e_M_get_size(); } // size() 调用 _M_get_size size_t _M_get_size() const { return _M_impl._M_node._M_size; } // [23.2.2.2] capacity /** * Returns true if the %list is empty. (Thus begin() would equal * end().) */ _GLIBCXX_NODISCARD bool empty() const _GLIBCXX_NOEXCEPT { return this-\u003e_M_impl._M_node._M_next == \u0026this-\u003e_M_impl._M_node; } ","date":"2023-07-24","objectID":"/posts/clause_4/:4:0","tags":["draft"],"title":"Effective STL [4] | 用empty来代替检查size()是否为0","uri":"/posts/clause_4/"},{"categories":["C++"],"content":"拷贝对象是STL的方式 当一个对象进入一个容器，它已经不是你添加（insert或push_back等）的那个对象了，进入容器的是你指定的对象的拷贝； 当从容器中取出一个对象时，所得到的也不是容器里的对象； 如果从vector、string或deque中插入或删除了什么，现有的容器元素会移动（拷贝） 如果使用了任何排序算法：next_permutation或者previous_permutation； remove、unique或它们的同类； rotate或reverse等，对象会移动（拷贝） 拷进去，拷出来。这就是STL的方式. 因为拷贝，还解决了一个 double free 的 bug点击查看 ","date":"2023-07-24","objectID":"/posts/clause_3/:1:0","tags":["STL"],"title":"Effective STL [3] | 使容器里对象的拷贝操作轻量而正确","uri":"/posts/clause_3/"},{"categories":["C++"],"content":"How Copy? 如何完成拷贝 Notice 通过拷贝构造函数和拷贝复制操作符完成！ 一个对象通过使用它的拷贝成员函数来拷贝，特别是它的拷贝构造函数和它的拷贝赋值操作符。 对于用户自定义类，比如Widget，这些函数传统上是这么声明的： class Widget { public: ... Widget(const Widget\u0026); // 拷贝构造函数 Widget\u0026 operator=(const Widget\u0026); // 拷贝赋值操作符 ... }; 如果你自己没有声明这些函数，你的编译器始终会为你声明它们。 拷贝内建类型（比如int、指针等）也始终是通过简单地拷贝他们的内在比特来完成的。（请参考《Effective C++》中，条款11和27专注于这些函数的行为。） ","date":"2023-07-24","objectID":"/posts/clause_3/:2:0","tags":["STL"],"title":"Effective STL [3] | 使容器里对象的拷贝操作轻量而正确","uri":"/posts/clause_3/"},{"categories":["C++"],"content":"拷贝带来的问题 性能瓶颈 拷贝会导致把对象放进容器也会被证明为是一个性能瓶颈。 容器中移动越多的东西，你就会在拷贝上浪费越多的内存和时钟周期。 切片分割 当然由于继承的存在，拷贝会导致分割。 如果以基类对象建立一个容器，而你试图插入派生类对象，那么当对象（通过基类的拷贝构造函数）拷入容器的时候对象的派生部分会被删除： vector\u003cWidget\u003e randy; class SpecialWidget: public Widget {...}; // SpecialWidget从上面的Widget派生 SpecialWidget sw; randy.push_back(sw); // sw被当作基类对象拷入randy，当拷贝时它的特殊部分丢失了 分割问题暗示了把一个派生类对象插入基类对象的容器几乎总是错的。 如果你希望结果对象表现为派生类对象，比如，调用派生类的虚函数等，总是错的。 ","date":"2023-07-24","objectID":"/posts/clause_3/:3:0","tags":["STL"],"title":"Effective STL [3] | 使容器里对象的拷贝操作轻量而正确","uri":"/posts/clause_3/"},{"categories":["C++"],"content":"解决 一个使拷贝更高效、正确而且对分割问题免疫的简单的方式是建立指针的容器而不是对象的容器。 也就是说，不是建立一个Widget的容器，建立一个Widget*的容器。 拷贝指针很快，它总是严密地做你希望的（指针拷贝比特），而且当指针拷贝时没有分割，就是int类型的地址。 但是一定要记得在销毁容器的时候，使用delete 销毁里面保存的每个指针。而且一定要定义对象的深拷贝构造函数和深拷贝拷贝赋值操作符，否则delete 的时候会报错。 ","date":"2023-07-24","objectID":"/posts/clause_3/:4:0","tags":["STL"],"title":"Effective STL [3] | 使容器里对象的拷贝操作轻量而正确","uri":"/posts/clause_3/"},{"categories":["C++"],"content":"和数组对比，STL容器更文明 STL容器只建立（通过拷贝）你需要的个数的对象，而且它们只在你指定的时候做。 STL进行了大量拷贝，但它通常设计为避免不必要的对象拷贝，实际上，它也被实现为避免不必要的对象拷贝。 数组在声明的时候，会默认先构造好每个元素；STL容器可以实现动态扩展 Widget randy[maxNumWidgets]; // 建立一个大小为maxNumWidgets的Widgets数组 // 默认构造每个元素 即使只使用其中的一些或者我们立刻使用从某个地方获取（比如，一个文件）的值覆盖每个默认构造的值，这也得构造maxNumWidgets个Widget对象。 使用STL来代替数组，你可以使用一个可以在需要的时候增长的vector，就是动态数组的概念： vector\u003cWidget\u003e randy; // 建立一个0个Widget对象的vector // 需要的时候可以扩展 建立一个可以足够包含maxNumWidgets个Widget的空vector，但不去构造Widget，需要时再构造： vector\u003cWidget\u003e randy; randy.reserve(maxNumWidgets); // reserve的详细信息请参见条款14 即便需要知道STL容器使用了拷贝，但是别忘了一个事实：比起数组它们仍然是一个进步。 ","date":"2023-07-24","objectID":"/posts/clause_3/:5:0","tags":["STL"],"title":"Effective STL [3] | 使容器里对象的拷贝操作轻量而正确","uri":"/posts/clause_3/"},{"categories":["C++"],"content":"STL 容器特点 STL是建立在泛化之上的 数组泛化为容器，参数化了所包含的对象的类型 函数泛化为算法，参数化了所用的迭代器的类型 指针泛化为迭代器，参数化了所指向的对象的类型 独立的容器类型泛化为序列或关联容器，而且类似的容器拥有类似的功能。 标准的内存相邻容器都提供随机访问迭代器，标准的基于节点的容器都提供双向迭代器。 序列容器支持push_front或push_back，但关联容器不支持。关联容器提供对数时间复杂度的lower_bound、upper_bound和equal_range成员函数，但序列容器却没有。 举例: 标准序列容器: vector、string、deque 和 list 标准关联容器: set、multiset、map 和 multimap ","date":"2023-07-20","objectID":"/posts/clause_2/:1:0","tags":["STL"],"title":"Effective STL [2] | 小心对“容器无关代码”的幻想","uri":"/posts/clause_2/"},{"categories":["C++"],"content":"推行自己的容器 很多人会试图在他们的软件中泛化容器的不同，而不是针对容器的特殊性编程，他们会想在vector 中使用 deque 或者 list的特性，这往往会带来麻烦。 比如： 只有序列容器支持push_front或push_back，只有关联容器支持count和lower_bound 即便是 insert和erase这样的操作在名称和语义上也有差别 当把对象插入序列容器中，该对象会保留在你放置的位置上; 当你把对象插入到一个关联容器中，容器会按照排列顺序把对象移到它应该在的位置; 在序列容器上用一个迭代器作为参数调用 erase，会返回一个新的迭代器；在关联容器上什么都不返回。 容器能力的交集 如果你想写一个可以用在常用序列容器上的代码—— 包含vector, deque和list。你必须使用它们能力的交集来编写。 但要考虑几点： deque和list不支持reserve或capacity list不支持operator[]操作，且受限于双向迭代器的性能 不能使用需要随机访问迭代器的算法，包括sort，stable_sort，partial_sort和nth_element 如果想支持vector的规则，则不能使用push_front和pop_front vector和deque都会使splice和成员函数方式的sort失败 因为deque::insert会使所有迭代器失效，而且因为缺少capacity，vector::insert也必须假设使所有指针和引用失效，而deque是唯一一个在迭代器失效的情况下, 指针和引用仍然有效的东西 不能把容器里的数据传递给C风格的界面，只有vector支持这么做 不能用bool作为保存的对象来实例化你的容器，因为vector 并非总表现为一个vector，实际上它并没有真正保存bool值。 不能期望享受到list的常数时间复杂度的插入和删除，vector和deque的插入和删除操作是线性时间复杂度的 所以，真正开发时，如果都考虑到上面几点，那想开发的容器只剩下一个\"泛化的序列容器\"，但是你不能调用reserve、capacity、operator[]、push_front、pop_front、splice或任何需要随机访问迭代器的算法；调用insert和erase会有线性时间复杂度而且会使所有迭代器、指针和引用失效；而且不能兼容C风格的界面，不能存储bool。 如果你放弃了序列容器，把代码改为只能和不同的关联容器配合，这情况并没有什么改善。 要同时兼容set和map几乎是不可能的，因为set保存单个对象，而map保存对象对。 甚至要同时兼容set和multiset（或map和multimap）也是很难的。 set/map的insert成员函数只返回一个值，和他们的multi兄弟的返回类型不同，而且你必须避免对一个保存在容器中的值的拷贝份数作出任何假设。 对于map和multimap，你必须避免使用operator[]，因为这个成员函数只存在于map中。 ","date":"2023-07-20","objectID":"/posts/clause_2/:2:0","tags":["STL"],"title":"Effective STL [2] | 小心对“容器无关代码”的幻想","uri":"/posts/clause_2/"},{"categories":["C++"],"content":"封装 如果想改变容器类型，就使用封装。 Method 1: typedef 一种最简单的方法是通过自由地对容器和迭代器类型使用typedef class Widget {...}; vector\u003cWidget\u003e vw; Widget bestWidget; ... // 给bestWidget一个值 vector\u003cWidget\u003e::iterator i = // 寻找和bestWidget相等的Widget find(vw.begin(), vw.end(), bestWidget); 可以简化上述写法 class Widget { ... }; typedef vector\u003cWidget\u003e WidgetContainer; typedef WidgetContainer::iterator WCIterator; WidgetContainer cw; Widget bestWidget; ... WCIterator i = find(cw.begin(), cw.end(), bestWidg 如果需要加上用户的allocator，也特别方便。（一个不影响对迭代器/指针/参考的失效规则的改变） class Widget { ... }; template\u003ctypename T\u003e // 关于为什么这里需要一个template SpecialAllocator { ... }; // 请参见条款10 typedef vector\u003cWidget, SpecialAllocator\u003cWidget\u003e \u003e WidgetContainer; typedef WidgetContainer::iterator WCIterator; WidgetContainer cw; // 仍然能用 Widget bestWidget; ... WCIterator i = find(cw.begin(), cw.end(), bestWidget); // 仍然能用 typedef只是其它类型的同义字，所以它提供的的封装是纯的词法（译注：不像#define是在预编译阶段替换的）。typedef并不能阻止用户使用（或依赖）任何他们不应该用的（或依赖的）。 Method 2: class 要限制如果用一个容器类型替换了另一个容器可能需要修改的代码，就需要在类中隐藏那个容器，而且要通过类的接口限制容器特殊信息可见性的数量。 比如需要隐藏 真实的容器 list 建立客户列表： class CustomerList { private: typedef list\u003cCustomer\u003e CustomerContainer; typedef CustomerContainer::iterator CCIterator; CustomerContainer customers; public: // 通过这个接口 ... // 限制list特殊信息的可见性 }; 如果使用过程中，你发现从列表的中部插入和删除客户并不像你想象的那么频繁，仅仅需要快速确定客户列表顶部的20%——一个为nth_element算法量身定做的任务。 但nth_element需要随机访问迭代器，不能兼容list。 在这种情况下，你的客户\"list\"可能更应该用\"vector\"或\"deque\"来实现 当你决定作这种更改的时候，你仍然必须检查每个CustomerList的成员函数和每个友元，看看他们受影响的程度（根据性能和迭代器/指针/引用失效的情况等等）。 但如果你做好了对CustomerList地实现细节做好封装的话，那对CustomerList的客户的影响将会很小。 ","date":"2023-07-20","objectID":"/posts/clause_2/:3:0","tags":["STL"],"title":"Effective STL [2] | 小心对“容器无关代码”的幻想","uri":"/posts/clause_2/"},{"categories":["C++"],"content":" quote 选择容器需要注意的几个方面 ","date":"2023-07-19","objectID":"/posts/clause_1/:0:0","tags":["STL"],"title":"Effective STL [1] | 仔细选择你的容器","uri":"/posts/clause_1/"},{"categories":["C++"],"content":"迭代器 输入迭代器 每个迭代位置只能被读1次的只读迭代器，通常表现为 istream_iterator 输出迭代器 每个迭代位置只能被写1次的只写迭代器，通常表现为 ostream_iterator 前向迭代器 有输入和输出迭代器的能力，可以反复读写1个位置，不支持 operator–，可以高效地向前移动任意次数 散列容器的一种设计可以产生前向迭代器； 单链表容器也提供前向迭代器 双向迭代器 像前向迭代器一样，后退很容易。标准关联容器都提供双向迭代器，list也有 随机访问迭代器 可以做双向迭代器一样的事情，但也提供“迭代器算术”，即迭代器有一步向前或向后跳的能力。 vector、string 和 deque 都提供随机访问迭代器。 指针数组的指针可以作为数组的随机访问迭代器。 ","date":"2023-07-19","objectID":"/posts/clause_1/:1:0","tags":["STL"],"title":"Effective STL [1] | 仔细选择你的容器","uri":"/posts/clause_1/"},{"categories":["C++"],"content":"容器 STL有迭代器、算法和函数对象，但对于大多数C++程序员，容器是最突出的。 它们比数组更强大更灵活，可以动态增长（也常是缩减），可以管理属于它们自己的内存，可以跟踪它们拥有的对象数目，可以限制它们支持操作的算法复杂度等等。 分类 类别 说明 标准STL序列容器 vector、string、deque和list 标准STL关联容器 set、multiset、map和multimap 非标准序列容器slist和rope slist是一个单向链表，rope本质上是一个重型字符串。(“绳子(rope)“是重型的\"线(string)”) 非标准关联容器 hash_set、hash_multiset、hash_map和hash_multimap vector 可以作为string的替代品 vector作为标准关联容器的替代品 有时候vector可以在时间和空间上都表现得比标准关联容器好 标准非STL容器 包括数组、bitset、valarray、stack、queue和priority_queue 。值得注意的是，数组可以和STL算法配合，因为指针可以当作数组的迭代器使用 vector、list和deque提供给程序员不同的复杂度，因此应该这么用： vector是一种可以默认使用的序列类型 当很频繁地对序列中部进行插入和删除时应该用list 当大部分插入和删除发生在序列的头或尾时可以选择deque这种数据结构 连续内存容器和基于节点的容器的区别 连续内存容器（也叫做基于数组的容器） 在一个或多个（动态分配）的内存块中保存它们的元素。 如果一个新元素被查入或者已存元素被删除，其他在同一个内存块的元素就必须向上或者向下移动来为新元素提供空间或者填充原来被删除的元素所占的空间。 这种移动影响了效率和异常安全。 标准的连续内存容器是vector、string和deque。 非标准的rope也是连续内存容器。 基于节点的容器 在每个内存块（动态分配）中只保存一个元素。 容器元素的插入或删除只影响指向节点的指针，而不是节点自己的内容。 所以当有东西插入或删除时，元素值不需要移动。 表现为链表的容器——比如list和slist——是基于节点的，所有的标准关联容器也是（它们的典型实现是平衡树）。 非标准的散列容器使用不同的基于节点的实现。 ","date":"2023-07-19","objectID":"/posts/clause_1/:2:0","tags":["STL"],"title":"Effective STL [1] | 仔细选择你的容器","uri":"/posts/clause_1/"},{"categories":["C++"],"content":"如何选择容器? 你需要“可以在容器的任意位置插入一个新元素”的能力吗？ 如果是，你需要序列容器，关联容器做不到。 你关心元素在容器中的顺序吗？ 如果不，散列容器就是可行的选择。否则，你要避免使用散列容器。 必须使用标准C++中的容器吗? 如果是，就可以除去散列容器、slist和rope。 你需要哪一类迭代器？ 如果必须是随机访问迭代器，在技术上你就只能限于vector、deque和string，但你也可能会考虑rope。 如果需要双向迭代器，你就用不了slist 和散列容器的一般实现。 当插入或者删除数据时，是否非常在意容器内现有元素的移动？ 如果是，你就必须放弃连续内存容器。 容器中的数据的内存布局需要兼容C吗？ 如果是，你就只能用vector。 查找速度很重要吗？ 如果是，你就应该看看散列容器，排序的vector和标准的关联容器——大概是这个顺序。 你介意如果容器的底层使用了引用计数吗？ 如果是，你就得避开string，因为很多string的实现是用引用计数。 你也不能用rope，因为权威的rope实现是基于引用计数的。 于是你得重新审核你的string，你可以考虑使用vector 你需要插入和删除的事务性语义吗？也就是说，你需要有可靠地回退插入和删除的能力吗？ 如果是，你就需要使用基于节点的容器。 如果你需要多元素插入（比如，以范围的方式）的事务性语义，你就应该选择list，因为list是唯一提供多元素插入事务性语义的标准容器。 事务性语义对于有兴趣写异常安全代码的程序员来说非常重要。（事务性语义也可以在连续内存容器上实现，但会有一个性能开销，而且代码不那么直观） 你要把迭代器、指针和引用的失效次数减到最少吗？ 如果是，你就应该使用基于节点的容器，因为在这些容器上进行插入和删除不会使迭代器、指针和引用失效（除非它们指向你删除的元素）。 一般来说，在连续内存容器上插入和删除会使所有指向容器的迭代器、指针和引用失效。 你需要具有以下特性的序列容器吗：1） 可以使用随机访问迭代器；2） 只要没有删除而且插入只发生在容器结尾，指针和引用的数据就不会失效？ 这个一个非常特殊的情况，但如果你遇到这种情况，deque就是你梦想的容器。 有趣的是，当插入只在容器结尾时，deque的迭代器也可能会失效，deque是**唯一一个“在迭代器失效时不会使它的指针和引用失效”**的标准STL容器。 ","date":"2023-07-19","objectID":"/posts/clause_1/:3:0","tags":["STL"],"title":"Effective STL [1] | 仔细选择你的容器","uri":"/posts/clause_1/"},{"categories":["C++"],"content":"结语 当面对容器时，STL给了你很多选项。如果你的视线超越了STL的范围，那就会有更多的选项。在选择一个容器前，要保证考虑了所有你的选项。 ","date":"2023-07-19","objectID":"/posts/clause_1/:4:0","tags":["STL"],"title":"Effective STL [1] | 仔细选择你的容器","uri":"/posts/clause_1/"},{"categories":["Prediction"],"content":"Novel Highlights (1) 使用矢量化的高精地图以及障碍物的历史轨迹，从而避免有损渲染以及ConvNet编码(计算开销比较大)。 (2) 设计子图网络以及全局图网络，建模低阶以及高阶交互 (3) auxiliary task 提高网络性能 ","date":"2023-07-16","objectID":"/posts/vectornet/:1:0","tags":["draft"],"title":"VectorNet 论文解读","uri":"/posts/vectornet/"},{"categories":["Prediction"],"content":"VecotorNet 网络介绍 ","date":"2023-07-16","objectID":"/posts/vectornet/:2:0","tags":["draft"],"title":"VectorNet 论文解读","uri":"/posts/vectornet/"},{"categories":["Prediction"],"content":"轨迹和地图的向量表示 Representing trajectories and HD maps lane可以表示为splines，人行道可以表示为一个很多个点组成的polygon，stop sign标记可以表示为单一个点。 对于agent来说，他们的轨迹也是一种splines。 这些元素都可以向量表示。 对于地图的特征：选择一个start point和朝向，等间距均匀采样关键点，并于相邻的关键点相连为向量 对于agent轨迹，按照0.1s sample关键点，并将它们连接成向量。 通过向量化的过程，可以得到折线polylines，这个polylines和轨迹、地图标注之间是一一对应的。如果给定的时空间隔足够小，得到的这些折线就与原始地图和轨迹十分接近。 我们将属于折线 $P_j$​ 的每一个向量$v_i$看作图中的一个节点，节点特征如下: $$v_i = [d_i^s, d_i^e, a_i, j]$$ 其中前两个vector分别是vector的start point和end point的坐标，可以是(x,y)或者(x,y,z)三维的形式 第三个向量则是attribute属性的特征，比如object的类型，轨迹的时间戳，道路的特征，道路限速等 最后一个是障碍物id，表示 $v_i$ ​属于 $P_j$ ","date":"2023-07-16","objectID":"/posts/vectornet/:2:1","tags":["draft"],"title":"VectorNet 论文解读","uri":"/posts/vectornet/"},{"categories":["Prediction"],"content":"Polyline 子图构建 对于一个Polyline P, 它的节点有 ${v_1,v_2,…,v_p}$， 可以定义一个子图网络： $$v_i^{l+1} = \\varphi_{rel}(g_{enc}(v_i^{(l)}), \\varphi({g_{enc}(v_j^{(l)})}))$$ $v_i^{(l)}$​ 代表第i个节点第L层的节点特征。 $g_{enc}(\\cdot)$代表节点的变换，实践中采用MLP来实现。 $\\varphi_{agg}(\\cdot)$代表特征聚合，用来从相邻的节点来获取信息，实践中采用的是max_pooling。 $\\varphi_{rel}(\\cdot)$代表vi和周围节点的关系，实践中采用的是concate的操作。 最后经过多层的堆叠，来获取整个Polyline级别的特征： $$P = \\varphi_{agg}(v_i^{L_p})$$ 这里， $φ_{agg}(⋅)$也是max pooling操作. ","date":"2023-07-16","objectID":"/posts/vectornet/:2:2","tags":["draft"],"title":"VectorNet 论文解读","uri":"/posts/vectornet/"},{"categories":["Prediction"],"content":"全局图的高阶交互 Global graph for high-order interactions 经过上面的子图进行低阶模型建模后，现在有了polyline级别节点的特征${p_1,p_2,…,p_P}$. 为了建立高阶的交互，需要建立一个global的交互图，详见论文图2的第3个子图。 $$P_i^{l+1} = GNN(p^l_i, A)$$ $p_i^l$​代表polyline节点的集合 A代表邻接矩阵，实践中采用全链接 $GNN(⋅)$代表一层的GNN网络，实践中采用的是self attention layer： $$GNN(P) = softmax(P_Q P_K^T)P_V$$ 其中，P是node的feature matrix， $P_Q$,$P_k$,$P_v$ ​则是它的线性投影。 经过了全局的网络之后，就生成了节点的特征$P^{L_t}_i$，其中Lt是全局GNN网络的层数。然后将$P^{(L_t)}_i$放入decoder进行轨迹的生成: $$v_i^{future} = \\varphi_{traj}(P_i^{L_t})$$ 论文中，decoder $φ_{traj}(⋅)$ 使用的是MLP，当然也可以用MultiPath中anchor-based的方法或者variational RNNs 来进行多模态轨迹预测。 ","date":"2023-07-16","objectID":"/posts/vectornet/:2:3","tags":["draft"],"title":"VectorNet 论文解读","uri":"/posts/vectornet/"},{"categories":["Prediction"],"content":"辅助任务训练 auxiliary graph completion task 为了让全局交互图能更好地捕捉不同轨迹和地图元素之间的交互信息，论文还提出了一个辅助的任务：在训练过程中，随机mask掉一些节点的特征，然后尝试去还原被掩盖的节点特征: $$\\hat{P}_i = \\varphi_{node}(P_i^{L_t})$$ 这里节点的decoder $φ_{node}(⋅)$ 也是一个MLP，只在训练的时候使用,在inference过程中不使用。 ","date":"2023-07-16","objectID":"/posts/vectornet/:2:4","tags":["draft"],"title":"VectorNet 论文解读","uri":"/posts/vectornet/"},{"categories":["Prediction"],"content":"损失函数 Loss Function 多任务训练目标， multi-task training task: $$\\mathcal{L} = \\mathcal{L_{traj}} + \\alpha \\mathcal{L_{node}}$$ $L_{traj}​$: negative Gaussian log-likelihood loss $L_{node}$​: 是预测的节点和被掩盖节点的huber损失函数 其中， negative Gaussian Log Likelihood 损失函数为: $$L(x, y) = -\\log P(y) = - \\log P(y|\\mu(x), \\sum(x))$$ where, $$p(y) = p(y∣μ,Σ)=1(2π)n/2∣Σ∣1/2exp−12(y−μ)⊤Σ−1(y−μ)$$ Huber 损失函数为: $$ L(Y|f(x))= \\begin{cases} \\frac{1}{2} (Y-f(x))^2, \u0026 |Y-f(x)|\u003c= \\delta \\\\ \\delta |Y-f(x)| - \\frac{1}{2}\\delta^2, \u0026 |Y-f(x)| \u003e \\delta \\end{cases} $$ ","date":"2023-07-16","objectID":"/posts/vectornet/:2:5","tags":["draft"],"title":"VectorNet 论文解读","uri":"/posts/vectornet/"},{"categories":["Prediction"],"content":"整理 VectorNet数据处理部分: 对actor的处理: 输入: 取轨迹点，每两个轨迹点构建vector, 形式为(x1, x2, y1, y2), 其他特征(object type, timestamp, track_id) 对lane node的处理: 输入: 针对lane segment 的点，求polyline，原则上求lane segment的左右边界的点的向量(x_start, x_end, y_start, y_end, turn_direction, traffic_control, is_intersection, lane_id) 网络部分: 构建subgraphnet: 针对每一个polyline，通过mlp和maxpool构建subgraphnet 构建globalgraphnet: 以每个polyline作为graph node，构建全局图网络，采用全链接，通过自注意力机制$GNN(P) = softmax(P_Q, P_K)^T(P_V)$ 轨迹生成: 将全局网络的节点特征，通过mlp进行轨迹生成。 ref link: [1] https://blog.csdn.net/qq_41897558/article/details/120087113 [2] https://zhuanlan.zhihu.com/p/355131328 ref code: [1]https://github.com/xk-huang/yet-another-vectornet [2]https://github.com/DQSSSSS/VectorNet ","date":"2023-07-16","objectID":"/posts/vectornet/:3:0","tags":["draft"],"title":"VectorNet 论文解读","uri":"/posts/vectornet/"},{"categories":["Prediction"],"content":"Overview paper link:https://arxiv.org/pdf/2202.04488.pdf ","date":"2023-07-16","objectID":"/posts/crat_pred/:1:0","tags":["draft"],"title":"CRAT-Prediction","uri":"/posts/crat_pred/"},{"categories":["Prediction"],"content":"论文概览 文章提出了一种结合Crystal Graph Convolutional Neural Network和Multi-Head Self-Attention Mechanism对交通agent处理的方式 在argoverse数据集上进行验证，实现了map-free预测模型的SOTA效果; 相比较于其他模型，模型参数更少。 证明: 可以通过 Self-Attention Mechanism 学习到交通参与者之间的交互关系。 ","date":"2023-07-16","objectID":"/posts/crat_pred/:2:0","tags":["draft"],"title":"CRAT-Prediction","uri":"/posts/crat_pred/"},{"categories":["Prediction"],"content":"网络结构 数据处理: 以argoverse2数据为例，取前50帧数据，两两作差值，取49组位移向量数据为输入 首先用EncoderLSTM作为encoder 再将每一个agent作为node，通过Crystal Graph Convolutional Neural Network构建图神经网络 通过Multi-Head Self-Attention学习node之间的交互关系 ","date":"2023-07-16","objectID":"/posts/crat_pred/:3:0","tags":["draft"],"title":"CRAT-Prediction","uri":"/posts/crat_pred/"},{"categories":["Prediction"],"content":"实现原理 ","date":"2023-07-16","objectID":"/posts/crat_pred/:4:0","tags":["draft"],"title":"CRAT-Prediction","uri":"/posts/crat_pred/"},{"categories":["Prediction"],"content":"Input Encoder 输入编码器 输入数据为过去5秒的离散位移: $$s_i^t = (\\Delta{\\tau_i^t} || b_i^t)$$ 其中， $\\Delta \\tau_i^t = \\tau_i^{t-1}$. ","date":"2023-07-16","objectID":"/posts/crat_pred/:4:1","tags":["draft"],"title":"CRAT-Prediction","uri":"/posts/crat_pred/"},{"categories":["Prediction"],"content":"Interaction Module 交互模块 ","date":"2023-07-16","objectID":"/posts/crat_pred/:4:2","tags":["draft"],"title":"CRAT-Prediction","uri":"/posts/crat_pred/"},{"categories":["Prediction"],"content":"Output Decoder 输出编码器 ","date":"2023-07-16","objectID":"/posts/crat_pred/:4:3","tags":["draft"],"title":"CRAT-Prediction","uri":"/posts/crat_pred/"},{"categories":["Prediction"],"content":"Training 训练过程 ","date":"2023-07-16","objectID":"/posts/crat_pred/:4:4","tags":["draft"],"title":"CRAT-Prediction","uri":"/posts/crat_pred/"},{"categories":["Prediction"],"content":"代码实现结构 数据处理结构 input = dict() input['argo_id'] = list() input['city'] = list() input['past_trajs'] = list() input['fut_trajs'] = list() input['gt'] = list() input['displ'] = list() input['centers'] = list() input['origin'] = list() input['rotation'] = list() 29 + 32 = 61 argo_id: [‘01d7deae-31e9-4657-843f-c30009b09f1c’, ‘01ca1736-ec51-41aa-8c73-3338c574a83a’] city: [‘austin’, ‘austin’] past_trajs: torch.Size([29, 50, 3]) torch.Size([32, 50, 3]) fut_trajs: torch.Size([29, 60, 3]) torch.Size([32, 60, 3]) gt: torch.Size([29, 60, 2]) torch.Size([32, 60, 2]) displ: torch.Size([29, 49, 3]) torch.Size([32, 49, 3]) centers: torch.Size([29, 2]) torch.Size([32, 2]) origin: torch.Size([2]) torch.Size([2]) rotation: torch.Size([2, 2]) torch.Size([2, 2]) 网络输入输出结构详解 In Inference with two sample data: displ_cat: 61 x 49 x 3 centers_cat: 61 x 2 agents_per_sample: [32, 29] ","date":"2023-07-16","objectID":"/posts/crat_pred/:5:0","tags":["draft"],"title":"CRAT-Prediction","uri":"/posts/crat_pred/"},{"categories":["Prediction"],"content":"encoder_lstm input: displ_cat(61 x 49 x 3), agents_per_sample [32,29] $\\downarrow$ input_size = 3; hidden_size = 128; num_layers = 1 $\\downarrow$lstm_hidden_state = torch.randn(num_layers, lstm_in.shape[0], hidden_size) = torch.randn(1, 61, 128) $\\downarrow$lstm_cell_state = torch.randn(num_layers, lstm_in.shape[0], hidden_size) = torch.randn(1, 61, 128) $\\downarrow$lstm_out, lstm_hidden = self.lstm(lstm_in, lstm_hidden) =\u003e lstm((61, 49, 3), (torch((1, 61, 128)), torch(1, 61, 128))) $\\downarrow$ lstm_out(61 x 49 x 128) output: lstm_out[:,-1,:](61 x 128) ","date":"2023-07-16","objectID":"/posts/crat_pred/:5:1","tags":["draft"],"title":"CRAT-Prediction","uri":"/posts/crat_pred/"},{"categories":["Prediction"],"content":"agent_gnn input: out_encoder_lstm(61 x 128), centers_cat (61 x 2) agents_per_sample [32,29] $\\downarrow$ x = gnn_in =\u003e (61 x 128) $\\downarrow$ edge_index = build_fully_connected_edge_idx(agents_per_sample).to(gnn_in.device) =\u003e (2, 1804) 1804 = (29 x 29-1) + (32 x (32-1)) $\\downarrow$ $\\downarrow$ edge_attr = build_edge_attr(edge_index, centers).to(gnn_in.device) =\u003e (1804, 2) $\\downarrow$ x = F.relu(self.gcn1(x, edge_index, edge_attr)) =\u003e (61 x 128) output: gnn_out = F.relu(self.gcn2(x, edge_index, edge_attr)) =\u003e (61 x 128) $$\\mathbf{x}^{\\prime}i = \\mathbf{x}i + \\sum{j \\in \\mathcal{N}(i)} \\sigma \\left( \\mathbf{z}{i,j} \\mathbf{W}_f + \\mathbf{b}f \\right) \\odot g \\left( \\mathbf{z}{i,j} \\mathbf{W}_s + \\mathbf{b}_s \\right)$$ ","date":"2023-07-16","objectID":"/posts/crat_pred/:5:2","tags":["draft"],"title":"CRAT-Prediction","uri":"/posts/crat_pred/"},{"categories":["Prediction"],"content":"multihead_self_attention input: out_agent_gnn (61 x 128) agents_per_sample[32,29] $\\downarrow$ max_agents = max(agents_per_sample) =\u003e 32 $\\downarrow$ padded_att_in = torch.zeros((len(agents_per_sample), max_agents, self.latent_size), device=att_in[0].device) =\u003e torch: (2 x 32 x 128) $\\downarrow$ mask = torch.arange(max_agents) \u003c torch.tensor(agents_per_sample)[:, None] \u0026\u0026 padded_att_in[mask] = att_in =\u003e torch: (2 x 32 x 128) $\\downarrow$ padded_att_in_swapped = torch.swapaxes(padded_att_in, 0, 1) =\u003e torch: (32, 2, 128) $\\downarrow$ padded_att_in_swapped, _ = self.multihead_attention(padded_att_in_swapped, padded_att_in_swapped, padded_att_in_swapped, key_padding_mask=mask_inverted) =\u003e torch: (32, 2, 128) $\\downarrow$ padded_att_in_reswapped = torch.swapaxes(padded_att_in_swapped, 0, 1) =\u003e torch: (2, 32, 128) $\\downarrow$ att_out_batch = [x[0:agents_per_sample[i]] for i, x in enumerate(padded_att_in_reswapped)] =\u003e list: 2 output: att_out_batch =\u003e list: 2 for each with shape (29, 128) and (32, 128) ","date":"2023-07-16","objectID":"/posts/crat_pred/:5:3","tags":["draft"],"title":"CRAT-Prediction","uri":"/posts/crat_pred/"},{"categories":["Prediction"],"content":"torch.stack() input: out_self_attention: list: 2 for each with shape (29, 128) and (32, 128) $\\downarrow$ out_self_attention = torch.stack([x[0] for x in out_self_attention]) output: out_self_attention: torch: (2, 128) ","date":"2023-07-16","objectID":"/posts/crat_pred/:5:4","tags":["draft"],"title":"CRAT-Prediction","uri":"/posts/crat_pred/"},{"categories":["Prediction"],"content":"PredictionNet(out_self_attention) ","date":"2023-07-16","objectID":"/posts/crat_pred/:5:5","tags":["draft"],"title":"CRAT-Prediction","uri":"/posts/crat_pred/"},{"categories":["Prediction"],"content":"decoder_residual input: out_self_attention(torch: (2, 128)) frozen = False $\\downarrow$ [condition: frozen = False] sample_wise_out.append(PredictionNet(out_self_attention)) =\u003e torch: (2, 120) $\\downarrow$ decoder_out = torch.stack(sample_wise_out) =\u003e torch: (1, 2, 120) $\\downarrow$ decoder_out = torch.swapaxes(decoder_out, 0, 1) =\u003e torch: (2, 1, 120) output: decoder_out =\u003e torch: (2, 1, 120) ","date":"2023-07-16","objectID":"/posts/crat_pred/:5:6","tags":["draft"],"title":"CRAT-Prediction","uri":"/posts/crat_pred/"},{"categories":["Prediction"],"content":"out = out_linear.view(len(displ), 1, -1, self.config[’num_preds’], 2) input: decoder_out: torch: (2, 1, 120) $\\downarrow$ out = out_linear.view(len(displ), 1, -1, self.config[’num_preds’], 2) =\u003e torch: (2, 1, 1, 60, 2) output: out =\u003e torch: (2, 1, 1, 60, 2) ","date":"2023-07-16","objectID":"/posts/crat_pred/:5:7","tags":["draft"],"title":"CRAT-Prediction","uri":"/posts/crat_pred/"},{"categories":["Prediction"],"content":"将预测轨迹转换到全局坐标 for i in range(len(out)): out[i] = torch.matmul(out[i], rotation[i]) + origin[i].view( 1, 1, 1, -1 ) ","date":"2023-07-16","objectID":"/posts/crat_pred/:5:8","tags":["draft"],"title":"CRAT-Prediction","uri":"/posts/crat_pred/"},{"categories":["Prediction"],"content":"TNT: Target-driveN Trajectory Prediction **ref link:** https://zhuanlan.zhihu.com/p/435953928 https://blog.csdn.net/weixin_40633696/article/details/124542807?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-2-124542807-blog-122758833.pc_relevant_vip_default\u0026spm=1001.2101.3001.4242.2\u0026utm_relevant_index=5 ","date":"2023-07-16","objectID":"/posts/densetnt_tnt/:1:0","tags":["draft"],"title":"DenseTNT and TNT 论文解读","uri":"/posts/densetnt_tnt/"},{"categories":["Prediction"],"content":"概览 在预测车辆的轨迹时, 需要尽可能考虑到车辆不同的情况，即不同的模态，如前行或左转，并预测出对应的概率。 模态的定义是比较模糊的，例如，有不同的速度前行，左转可以以不同的转弯角度实现。为了能够更加通用且精确地定义每条轨迹的模态，我们直接将每条轨迹的模态定义在每条轨迹的终点上。这里的一个重要假设是，轨迹的模态基本由终点所决定，当终点确定后，轨迹的形状也大体确定了。这样我们就把轨迹预测变成了终点预测问题，极大地简化了问题的复杂度。 TNT的预测方式: 首先预测轨迹的终点，然后基于这个终点补充完整条轨迹。 TNT 基于终点的轨迹预测流程图: TNT使用VectorNet对高精地图和车辆信息进行编码，得到要预测的车辆的全局特征，以用于接下来的解码，从而完成轨迹预测： (1). 终点预测: 为每个Anchor预测一个偏移，得到终点，这些Anchor从道路的中心线上采样得到; (2). 轨迹补全: 基于上一步预测的终点将整条轨迹补充完整; (3). 轨迹打分和筛选: 根据场景特征，为每条轨迹进行打分，并筛选出最有可能的若干条轨迹。 ","date":"2023-07-16","objectID":"/posts/densetnt_tnt/:1:1","tags":["draft"],"title":"DenseTNT and TNT 论文解读","uri":"/posts/densetnt_tnt/"},{"categories":["Prediction"],"content":"TNT 实现 原理 给定一个单个障碍物的观测状态序列 $S_P = [s_{-T^{’}+1}, s_{-T^{’}+2}, …, s_0]$。我们的目标是预测它的未来状态 $S_F = [s_1, s_2, …, s_T]$ 到某个固定时间步 T。自然地，障碍物与由其它障碍物和场景元素组成的环境交互作为背景: $C_P​=[c_{-T′+1}​,c_{-T′+2}​,…,c_0​]$。为简洁起见，我们记 $X = (s_P, c_P)$，因此我们想捕捉的整体概率分布是 $p(S_F|X)$ 。 实际上， $p(S_F|X)$ 可以是高度多模态的。例如，车辆驶近十字路口时可能左转、直行或改变车道。直观上，未来状态的不确定性可以被分解为两部分：目标或者意图的不确定性，比如左右转的决定；以及控制的不确定性，比如转弯时需要的细粒度运动。因此，我们可以通过对目标设定条件，然后将其边缘化，从而对概率分布进行分解： $$p(S_F​∣X)=∫_{τ∈τ(C_P​)}​p(τ∣X)p(S_F​∣τ,X)d_τ​, \\tag{1}$$ 其中 $\\tau(C_P)$ 表示取决于观察到的背景 $C_P$ ​的合理目标空间。 在这个公式下，我们的主要见解是，对于轨迹预测等应用，通过正确设计目标空间 $\\tau τ ( C_P )$（如目标位置），目标分布 $ p(\\tau|X)$ 可以很好地捕捉意图不确定性。一旦目标确定，我们会进一步证明控制不确定性（如轨迹）可以通过简单的单模态分布可靠地建模。我们用一组离散位置来模拟目标空间 $\\tau{C_P}$，将 $p(\\tau|X)$ 的估计主要转化为一个分类任务。与隐变分模型相比，我们的模型以明确的目标分布的形式提供了更好的可解释性，并且在设计目标空间 $\\tau{C_P}$ 时可以自然地结合专家知识（如道路拓扑）。 我们的整体框架有三个概念阶段。第一阶段是障碍物意图预测，其目标是用基于观察背景 $X$ 的目标空间 $\\tau$ 的离散集合对意图不确定性进行建模，并且输出目标分布 $p(\\tau|X)$ 。第二个阶段是障碍物条件运动估计，它用单模态分布对从初始状态到目标可能的未来运动进行建模。前两个阶段产生了以下概率预测 $p(S_F|X) = \\sum_{\\tau\\in\\tau(C_P)}p(\\tau|X)p(S_F|\\tau, X)$。 许多下游应用，例如实时行为预测，需要一小组具有代表性的未来预测，而不是所有可能未来的完整分布。我们的最终阶段，评分和选择，就是为此目的量身定制的。我们从所有代表性预测上学习一个评分函数 $\\phi(S_F)$，并选择一个最终的多样化预测集。 场景编码VectorNet 建模场景背景是轨迹预测的第一步，以获取车辆-道路和车辆-车辆之间的交互。TNT可以使用任何合适的背景编码器：当高清地图可用时，我们使用最优秀的层次图神经网络 VectorNet 对背景进行编码。具体来说，使用多段线来抽象出高清地图元素 $C_P$(车道，交通标志) 和代理轨迹 $S_P$​；采用子图（subgraph）网络对多段线进行编码，多段线包含可变数量的向量；然后使用全局图（global graph）对多段线之间的交互进行建模。输出是每个建模代理的全局背景特征 $X$。如果场景背景只在自上而下的图像形式中可用，则使用卷积网络作为背景编码器。 目标预测 在我们的公式中，目标 $\\tau$ 被定义为一个预测目标可能在固定时间范围 $T$ 上的位置 $(x,y)$ 。在第一步目标预测阶段，我们的目的是提供一个预测目标的未来目标的分布 $p( \\tau ∣ X )$ 。我们通过一组$N$个离散的、带有连续偏移的量化位置来建模潜在的未来目标： $\\tau ={\\tau^n}={(x^n,y^n)+(\\Delta x^n,\\Delta y^n)}^N_{n=1}$​。然后这个目标上分布可以通过一个离散-连续分解来建模： $$p(τ^n∣X)=π(τ^n∣X)⋅N(Δx^n∣v^x_n​(X))⋅N(Δ_y^n∣v_y^n​(X)),\\tag{2}$$ 中 $\\pi(\\tau^n|X)=\\frac{e^{f(\\tau^n,X)}}{\\sum_{\\tau^{’}}e^{f(\\tau^{’},X)}}$ 是在位置选择 $(x^n,y^n)$上的离散分布。术语 $N(·|v(·))$ 表示一个广义正态分布，其中我们选择Huber作为距离函数。我们将均值表示为 $v(·)$并假设单位方差。 可训练函数 $f(·)$ 和 $v(·)$ 由一个2层的多层感知机(MLP)实现，目标坐标 $(x^k,y^k)$ 和场景背景特征 $X$ 作为输入。它们预测目标位置上的离散分布及其最可能的偏移量。这一阶段的训练损失函数由以下公式给出： $$L_{S1}​=L_{cls​}(π,u)+L_{offset}​(v_x​,v_y​,Δx^u,Δy^u),\\tag{3}$$ 其中 $L_{cls}$ 是交叉熵损失， $L_{offset}$​ 是 Huber 损失；$u$ 是离真实位置最近的目标，并且 $\\Delta x^u,\\Delta y^u$ 是 $u$ 相对于真值的空间偏移量。 离散目标空间的选择在不同应用中是灵活的，如图3所示。在车辆轨迹预测问题中，我们从高清地图里均匀地采样车道中心线上的点并且将他们作为目标候选点(标记为黄色菱形)，假设车辆从未远离车道线；对于行人，我们在代理周围生成了一个虚拟网格并将网格点作为目标候选点。对每个候选目标，TNT目标预测器生成了一个 $(\\pi,\\Delta x, \\Delta y)$ 的元组；回归后的目标以橙色五角星标记。与直接回归相比，将未来建模成一组离散目标的最显著的优势在于，它不受模态平均的影响，模态平均是阻止多模态预测的主要因素。 基于目标的运动估计 在第二阶段，我们将给定目标轨迹的可能性建模为 $p(S_F|\\tau,X)=\\prod^T_{t=1}p(s_t|\\tau,X)$，同样采用了广义正态分布。这里有两个假设。首先，未来时间步是条件独立的，这使得我们的模型通过避免顺序预测提高了计算效率。其次，我们正在作出有力但合理的假设，即给定目标的轨迹分布是单模态(正态)的。对于短的时间范围来说，这当然是正确的；对于更长的时间范围，可以在(中间)目标预测和运动估计之间迭代，以便假设仍然成立。 这一阶段使用2层的MLP实现。它将背景特征 X 和目标位置 $\\tau$ 作为输入，并且每个目标输出一条最可能的轨迹 $[\\hat{s_1},…,\\hat{s_T}] [s1​^​,…,sT​^​]$。由于它以第一阶段的预测目标为条件，为了实现平滑的学习过程，我们在训练时采用teacher forcing Technique[36]，将真实位置 $(x^n,y^n)$ 作为目标。该阶段的损失项是预测状态 $\\hat{s_t}$​ 和真值 $s_t$​ 之间的距离： $$L_{S2}​ = \\sum_{t=1}^{T}​L_{reg}​(\\hat{s},s_t​),\\tag{4}$$ 其中， $L_{reg}$​ 作为每一步坐标偏移的 Huber 损失来实现。 轨迹评分和选择 我们的最终阶段估计未来完整轨迹 S F S_F SF​ 的可能性。这和第二阶段不同，第二阶段分解时间步和目标，也和第一阶段不同，第一阶段只知道目标，但没有完整的轨迹——例如，一个目标可能被估计有很高的可能性，但到达该目标完整轨迹的可能性可能不是。 我们使用最大熵模型对第二阶段的所有 M 条轨迹进行评分: $$\\phi (S_F | X) = \\frac{e^{g(S_F, X)}}{{\\sum}_{m=1}^{M} e^{g(S_F^m, X)}}​$$, 其中 $g(·)$ 被建模为一个2层的 MLP。这一阶段训练的损失项是预测分数和真值分数之间的交叉熵， $$L_{S3} = L_{CE}(\\phi (S_F | X), \\psi(S_F))$$ 其中每个预测轨迹的真值评分由预测轨迹到真值轨迹的距离 $\\psi(S_F)=\\frac{exp(-D(S,S_{GT})/\\alpha)}{\\sum_{s^{’}}exp(-D(S^{’},S_{GT})/\\alpha)}$ 定义，其中 $D(·)$ 单位为米， $\\alpha$ 是温度。距离度量定义为 $D(S^i,S^j)=max(||s^i_1-s^j_1||^2_2,…,||s^i_t-s^j_t||^2_2)$。 为了从已评分的 $M$ 个轨迹获得最终一小组 $K$ 个预测轨迹，我们实现了一个轨迹选择算法来排除近似重复的轨迹。我们首先根据他们的分数对轨迹进行降序排列，并且贪婪地选择轨迹； 如果一个轨迹距离所有的选择轨迹都足够远，我们也会选择它，否则排除它。这里使用的距离度量和评分过程相同。这个过程的灵感来源于通常应用于计算机视觉问题（如目标检测）的非极大值抑制算法。 训练和推理细节 上述的 TNT 公式产生全监督的端到端训练，具有损失函数 $$L = \\lambda_1 L_{S1} + \\lambda_2 L_{S2} + \\lambda_3 L_{S3}$$ 其中，选择 $\\lambda_1,\\lambda_2,\\lambda_3$ 来平衡训练过程。 在推理时，TNT 的工作原理如下： (1) 工作场景编码； (2) 采样 N 个候选目标作为目标预测器的输入，取由 $\\pi(\\tau|X)$ 估计的前 M 个目标； (3) 从运动估计模型 $p(S_F|\\tau,X)$ 中获取 M 个目标","date":"2023-07-16","objectID":"/posts/densetnt_tnt/:1:2","tags":["draft"],"title":"DenseTNT and TNT 论文解读","uri":"/posts/densetnt_tnt/"},{"categories":["Prediction"],"content":"DenseTNT: ref link: https://blog.csdn.net/weixin_39397852/article/details/122764880 ","date":"2023-07-16","objectID":"/posts/densetnt_tnt/:2:0","tags":["draft"],"title":"DenseTNT and TNT 论文解读","uri":"/posts/densetnt_tnt/"},{"categories":["Prediction"],"content":"Comparison between DenseTNT and TNT TNT(左图)是根据lane定义一些anchor，再regress和classify获得最终的位置，之后还要通过NMS的筛选法选出最后的轨迹。 DenseTNT(右图)是通过密集地采点避免了定义anchor，同时也避免了使用NMS等规则来筛选轨迹。 意图预测中非常重要的一个问题是ground truth只有一个，而对于多意图的预测来说，多个方向的预测都是允许的，这导致了label中有很多都是无效的，因为gt只包含了一个意图下的结果。此处设计了一个offline的model来提供多个意图下的label。这个model使用了一个优化算法从goal的分布里取出了一个set作为online model的label。 ","date":"2023-07-16","objectID":"/posts/densetnt_tnt/:2:1","tags":["draft"],"title":"DenseTNT and TNT 论文解读","uri":"/posts/densetnt_tnt/"},{"categories":["Prediction"],"content":"Method 具体实现方法 sparse context encoding – VectorNet 本文使用VectorNet来提取地图的feature。(没有的高精地图的话也可使用CNN) Dense goal probability estimation TNT对于一个goal只预测一条轨迹的概率是有问题的：一个goal只有一条预测(可能通向这个goal的别的预测概率很高)，一个goal获取的feature不够丰富(goal附近的点的信息也用上会更好)。 我们使用了dense goal encoder。它以一定的采样频率获取了地图上在道路上的所有点。然后预测了这些密集点的概率分布。 Lane Scoring 在论文实现中，可以用point scoring代替，效果更好。目的在与选出距离final pos(gt)更近的点。 为了减少需要sample的点，我们先预测goal落在不同lane上的概率，这样能过滤掉明显不在candidate lane附近的点，提升运算速度。 这是一个二分类问题。因此使用了二分类的交叉熵计算loss。对于label，使用离gt的goal最近的lane作为1，别的lane为0。对于别的lane $l$，假设gt的goal是$y_{gt}$​，定义一个distance $$d(l,y_{gt}) = min(||l_1 - y_{gt}||^2, ||l_2 - y_{gt}||^2, …, ||l_t - y_{gt}||^2,)$$ 直觉上就是gt的goal到这条lane的最短距离的平方。 Probability Estimation 获得概率分布的做法是self-attention。首先agent的feature经过两次MLP。然后把goal的feature $F$作为需要query的变量，从地图上所有元素 (lane，agent)的feature中去查找索引对应的键和值。目的就是建立goal的feature与地图上所有元素的联系。直观上，这一步是把agent的未来状态(goal)表示成由历史的信息作为变量的函数，这个函数采用的是self-attention的做法。 轨迹目标点(goals)和道路的局部信息可以用以下注意力机制表示: $$\\mathbf{Q} = \\mathbf{FW}^{\\mathbf{Q}}, \\mathbf{K} = \\mathbf{LW}^{\\mathbf{K}}, \\mathbf{V}=\\mathbf{LW}^{\\mathbf{V}}$$ $$\\mathbf{A}(\\mathbf{Q},\\mathbf{K},\\mathbf{V}) = softmax(\\frac{\\mathbf{QK^\\top}}{\\sqrt{d_k}})\\mathbf{V}$$ where $\\mathbf{W}^Q, \\mathbf{W}^{K}, \\mathbf{W}^{V} \\in \\mathbb{R}^{d_h \\times d_k}$ are the matrices for linear projection, $d_k$ is the dimension of query / key / value vectors, and $\\mathbf{F}, \\mathbf{F}$ are feature matrices of the dense goal candidates and all map elements (i.e., lanes or agents), respectively. 这一步之后的结果是goal新的feature $\\mathbf{F}$。再通过两次MLP，即下图中的 $g(.)$.用softmax中的方法获得每个goal的概率。将所有goal在地图上表示出来的话就是一个概率分布heatmap。 $$\\phi_i = \\frac{\\exp(g(\\mathbf{F}i))}{\\sum{n=1}^{N}\\exp(g(\\mathbf{F}_n))}$$ 对于Loss的计算，离gt的goal最近的goal的label定为1，其余都为0.采取二分类交叉熵的算法。 $$\\mathcal{L}\\text{goal} = \\mathcal{L}{\\text{CE}}(\\phi, \\psi)$$ Goal Set Prediction 对于多意图的预测，在TNT中，预先设定好target，采用NMS(non-maximum suppression)(靠的近或概率低的过滤掉)。而DenseTNT的上一步获得是heatmap，因此不能简单使用NMS，因为用于筛选的阈值比较难定。这是因为TNT中采用的是从高到低排序概率，而DenseTNT中的概率分布是针对于整个鸟瞰图的，一旦意图的可能性变多了，平均分布到每一个意图的概率就低了(对于概率分布，所有的点的概率加起来需要为1)。 heatmap，输出是goal set，这个有点像目标检测的框生成。但和目标检测不同，对于一个输入，我们的label只有一个，即gt。这样的话可能会有别的意图的结果在训练中被忽略。为此，设计了一个offline model来制造这些label。它和online model的区别就在这一步中。没有使用goal set predictor而是采用了优化算法。 Offline Optimization 上一步heatmap的输出，实际上是对于地图上众多goal每个点的一个函数。设定 $C={c_1,c_2,…,c_m}$ 为所有dense goal的candidate，heatmap就把 $C$ 映射到一个0到1的集合，写成 $h(c_i)$ ，这也是每个goal的概率。 接下来定义一个目标函数: $$E[d(\\hat{y}, Y)] = \\sum^m_{i=1}h(c_i)d(\\hat{y}, c_i)$$ 其中，$d(\\hat{y}, c_i) = \\mathop{\\min}\\limits_{y_i \\in \\hat{y}}||y_j - y_{c_i}||$ 从直观上讲，目标是有M个goal（大池子），要从中选取K个靠谱的goal（小池子）。 $d$ 是针对于大池子的，对于大池子里所有candidate都有一个 $d$。这每个candidate都与小池子中的goal计算距离，取最近的作为 d d d，即寻找小池子中离candidate最近的点。对于所有的 $d$，用概率加权计算期望。总体的话在收敛情况，大池子中的所有goal到距离自己最近的小池子中的goal乘上概率加权应当达到最小。以下是这个优化算法的实现。 翻译成中文： 初始化K个goal，从M个goal的大池子里随机选 小池子里的每个goal做随机扰动，变为别的goal 计算原来的和现在的小池子的d的期望e和e’ 如果现在的小池子d的期望更小，则使用现在的小池子。否则以1%的概率采用现在的小池子。（避免局部最优） 不停循环2-4直到步数达到阈值（或时间太长） 优化算法之后得到的就是全局最优的选中的小池子。这个小池子里的结果能作为训练online模型的伪label。 Goal Set Predictor (online) 模型采用了encode+decode的办法。encoder部分是一层self-attention加上max pooling，decoder部分是2层MLP，输入是heatmap，输出是2K+1个值，分别对应K个2维坐标（goal set）和一个当前goal set的confidence。 考虑到heatmap的概率分布比较散，可以采用N头同时运算。即N个goal set predictor输出N个2K+1的值，从当中选取confidence最高的那个goal set预测。为了运算效率的提升，这N头使用相同的self-attention层，但是不同的2个MLP。 在训练过程中，采用了offline模型的伪label作为监督。上述offline中讲到的初始选定的小池子，在这里采用的是online模型的K个goal的set的预测。然后经过L次随机扰动（即不停随机选取邻居点，L=100），选取当中expected error（offline里的期望项）最小的那个set作为伪label。 标记 $\\dot{y}$ ​为预测结果， $\\hat{y}$ ​为伪label，则loss的计算如下。即一一对应后的L1距离之和。 $$\\mathcal{L_{set}(\\dot{y}, \\hat{y})} = \\sum_{i=1}^{k}\\mathcal{L}_{\\text{reg}}(\\dot{y}, \\hat{y})$$ 再考虑到采用了N头预测，这部分的loss将采用二分类的交叉熵。其中 $\\mu$ 为所有head的confidence，$\\nu$ 为label，只有expected error最低的label为1，别的为0。 $$\\mathcal{L}\\text{head} = \\mathcal{L}{\\text{CE}}(\\mu, \\nu)$$ Trajectory Completion 这一步和TNT做法类似。类似于dense goal encoding（2层MLP后过self-attention）最后过2层MLP来decode得到整条预测轨迹的state。采用teacher forcing技巧（因为只有一条gt）训练时只用gt的goal来算这条预测轨迹。Loss的算法和TNT一样，用的是点点之间的Huber loss。 $$\\mathcal{L}{\\text{completion}}","date":"2023-07-16","objectID":"/posts/densetnt_tnt/:2:2","tags":["draft"],"title":"DenseTNT and TNT 论文解读","uri":"/posts/densetnt_tnt/"},{"categories":["Prediction"],"content":"paper link: https://arxiv.org/abs/2007.13732 PPT: https://www.cs.toronto.edu/~byang/slides/LaneGCN.pdf ","date":"2023-07-16","objectID":"/posts/lanegcn/:0:0","tags":["LaneGCN"],"title":"LaneGCN 论文解读","uri":"/posts/lanegcn/"},{"categories":["Prediction"],"content":"Architechture Lane Graph + Actor Map: construct lane graph from vectorized map data to preserve the map structure and can avoid information loss 构建矢量化地图信息，避免地图信息丢失 LaneGCN: extends graph convolutions with multiple adjacency matrices and along-lane dilation to capture complex topology and long range dependencies of the lane graph. exploit a fusion network consisting of four types of interactions: actor-to-lane, lane-to-actor, actor-to-actor, lane-to-lane. present both actors and lanes as nodes in the graph and use a 1D CNN and LaneGCN to extract the features for the actor and lane nodes respectively, and then exploit spatial attention and another LaneGCN to model four types of interactions. Difference between VectorNet and LaneGCN: VecotrNet uses vanilla graph networks with undirected full connections; LaneGCN uses connected lane graph following the map topology and propose task specific multi-type and dilated graph operators. VectorNet uses polyline-level nodes for interactions; LaneGCN uses polyline segments as map nodes to capture higher resolution. ","date":"2023-07-16","objectID":"/posts/lanegcn/:1:0","tags":["LaneGCN"],"title":"LaneGCN 论文解读","uri":"/posts/lanegcn/"},{"categories":["Prediction"],"content":"Lane Graph Representations for Motion Forecasting ","date":"2023-07-16","objectID":"/posts/lanegcn/:2:0","tags":["LaneGCN"],"title":"LaneGCN 论文解读","uri":"/posts/lanegcn/"},{"categories":["Prediction"],"content":"ActorNet: Extracting Traffic Participant Representations Each Trajctory is represented as a sequence of displacement ${ \\bigtriangleup{p_{-(T-1)},…,\\bigtriangleup{p_{-1}}, \\bigtriangleup{p_0}}}$, where $\\bigtriangleup{p_t}$ is the 2D displacement from time step $t-1$ to t, and T is the trajectory size. For trajectories with sizes smaller than $T$ , we pad them with zeros. We add a binary $1 × T$ mask to indicate if the element at each step is padded or not and concatenate it with the trajectory tensor, resulting in an input tensor of size $3 × T$. 1D CNN is used to process the trajectory input for its effectiveness in extracting multi-scale features and efficiency in parallel computing. The output of ActorNet is a temporal feature map, whose element at $t = 0$ is used as the actor feature. The network has 3 groups/scales of 1D convolutions. Each group consists of 2 residual blocks, with the stride of the first block as 2. We then use a Feature Pyramid Network (FPN) to fuse the multi-scale features, and apply another residual block to obtain the output tensor. For all layers, the convolution kernel size is 3 and the number of output channels is 128. Layer Normalization and the Rectified Linear Unit (ReLU) are used after each convolution. ","date":"2023-07-16","objectID":"/posts/lanegcn/:2:1","tags":["LaneGCN"],"title":"LaneGCN 论文解读","uri":"/posts/lanegcn/"},{"categories":["Prediction"],"content":"MapNet: Extracting Structured Map Representation General Architecture: part 1: building a lane graph from vectorized map data; part 2: applying our novel LaneGCN to the lane graph to output the map features. Map Data: In this paper, we adopt a simple form of vectorized map data as our representation of HD maps. Specifically, the map data is represented as a set of lanes and their connectivity. Each lane contains a centerline, i.e., a sequence of 2D BEV points, which are arranged following the lane direction (see Fig. 3, top). For any two lanes which are directly reachable, 4 types of connections are given: predecessor, successor, left neighbour and right neighbour. Lane Graph Construction: first define a lane node as the straight line segment formed by any two consecutive points (grey circles in Fig. 3) of the centerline. The location of a lane node is the averaged coordinates of its two end points. Following the connections between lane centerlines, we also derive 4 connectivity types 4 connectivity types for the lane nodes, i.e., predecessor, successor, left neighbour and right neighbour. We denote the lane nodes with $V ∈ \\mathbb R^{N ×2}$ , where $N$ is the number of lane nodes and the $i$-th row of $V$ is the BEV coordinates of the $i$-th node. We represent the connectivity with 4 adjacency matrices ${\\lbrace A_i \\rbrace}_{i \\in {pre,suc,left,right}}$ , with $A_i \\in \\mathbb R^{N ×N}$. We denote $A_{i,j,k}$, as the element in the $j$-th row and $k$-th column of $A_i$. Then $A_{i,j,k} = 1$ if node $k$ is an $i$-type neighbor of node $j$. LaneConv Operator: Node Feature: Each lane node corresponds to a straight line segment of a centerline. To encode all the lane node information, we need to take into account both the shape (size and orientation) and the location (the coordinates of the center) of the corresponding line segment. We parameterize the node feature as follows, $$x_i = MLP_{shape} (v_{i}^{end} - v_{i}^{start}) + MLP_{loc}(v_i) $$ where $MLP$ indicates a multi-layer perceptron and the two subscripts refer to shape and location, respectively. $v_i$ is the location of the i-th lane node, i.e., the center between two end points, $v_i^{start}$ and $v_i^{end}$ are the BEV coordinates of the node $i’s$ starting and ending points, and $x_i$ is the $i$-th row of the node feature matrix $X$, denoting the input feature of the $i$-th lane node. LaneConv: To aggregate the topology information of the lane graph at a larger scale, we design the following LaneConv operator: $$Y = XW_0 + \\sum_{i\\in{pre, suc, left, right}}A_iXW_i,\\tag{2}$$ where $A_i$ and $W_i$ are the adjacency and the weight matrices corresponding to the $i$-th connection type respectively. Since we order the lane nodes from the start to the end of the lane, $A_{suc}$ and $A_{pre}$ are matrices obtained by shifting the identity matrix (diagnal 1) one step towards upper right (non-zero superdiagonal) and lower left (non-zero subdiagonal). $A_{suc}$ and $A_{pre}$ can propagate information from the forward and backward neighbours whereas $A_{left}$ and $A_{right}$ allow information to flow from the cross-lane neighbours. It is not hard to see that our LaneConv builds on top of the general graph convolution and encodes more geometric (e.g., connection type/direction) information. As shown in our experiments this improves over the vanilla graph convolution. Dilated LaneConv: Functionality: The model needs to capture the long range dependency along the lane direction for accurate prediction. the k-dilation LaneConv operator is defined as follows: $$Y = XW_0 + A_{pre}^k XW_{pre,k} + A_{suc}^k X W_{suc,k} \\tag{3}$$ where $A_{pre}^k$ is the $k$-th matrix power of $A_{pre}$. This allows us to directly propagate information along the lane for $k$ steps, with $k$ a hyperparameter. Since $A_{pre}^k$ is highly sparse, one can efficiently compute it using sparse matrix multiplication. Note that the dilated LaneConv is only used for predecessor and successor, as the long range","date":"2023-07-16","objectID":"/posts/lanegcn/:2:2","tags":["LaneGCN"],"title":"LaneGCN 论文解读","uri":"/posts/lanegcn/"},{"categories":["Prediction"],"content":"Fusion Net Four types fusion modules: A2L: introduces real-time traffic information to lane nodes, such as blockage or usage of the lanes. L2L: updates lane node features by propagating the traffic information over the lane graph. -\u003e LaneGCN L2A: fuses updated map features with real-time traffic information back to the actors. A2A: handles the interactions between actors and produces the output actor features, which are then used by the prediction header for motion forecasting. We implement L2L using another LaneGCN, which has the same architecture as the one used in our MapNet (see Section 3.2). In the following we describe the other three modules in detail. We exploit a spatial attention layer for A2L, L2A and A2A. The attention layer applies to each of the three modules in the same way. Taking A2L as an example, given an actor node i, we aggregate the features from its context lane nodes j as follows: $$y_i = x_i W_0 + \\sum_j \\phi (concat(x_i, \\Delta_{i,j}, x_j)W_1)W_2, \\tag{5}$$ with $x_i$ the feature of the $i$-th node, $W$ a weight matrix, $\\phi$ the compositon of layer notmalization and RelU, and $\\Delta_{ij} = MLP(v_j - v_i)$, where $v$ denotes the node location. ","date":"2023-07-16","objectID":"/posts/lanegcn/:2:3","tags":["LaneGCN"],"title":"LaneGCN 论文解读","uri":"/posts/lanegcn/"},{"categories":["Prediction"],"content":"Prediction Header Take after-fusion actor features as input, a multi-modal prediction header outputs the final motion forecasting. For each actor, it predicts $K$ possible future trajectories and their confidence scores. The header has two branches, a regression branch to predict the trajectory of each mode and a classification branch to predict the confidence score of each mode. For the m-th actor, we apply a residual block and a linear layer in the regression branch to regress the K sequences of BEV coordinates: $$O_{m,reg} = \\lbrace (p_{m,1}^k, p_{m,2}^k, …, p_{m,T}^k) \\rbrace _{k\\in[0,K-1]}$$ where $p_{m,i}^k$ is the predicted $m$-th actor’s BEV coordinates of the $k$-th mode at the $i$-th time step. For the classification branch, we apply an MLP to $p^k_{m,T} − p_{m,0}$ to get $K$ distance embeddings. We then concatenate each distance embedding with the actor feature, apply a residual block and a linear layer to output $K$ confidence scores, $O_{m,cls} = (c_{m,0}, c_{m,1}, …, c_{m,K−1})$. ","date":"2023-07-16","objectID":"/posts/lanegcn/:2:4","tags":["LaneGCN"],"title":"LaneGCN 论文解读","uri":"/posts/lanegcn/"},{"categories":["Prediction"],"content":"Learning use the sum of classification and regreesion losses to train the model: $$ L = L_{cls} + \\alpha L_{reg},$$ where $\\alpha = 1.0$. For classification, we use the max-margin loss: $$L_{cls} = \\frac{1}{M(K-1)}\\sum_{m=1}^M \\sum_{k \\neq \\hat{k}} \\max(0, c_{m,k} + \\epsilon - c_{m, \\hat{k}}) \\tag{6}$$ where $\\epsilon$ is the margin and $M$ is the total number of actors. For regression, we apply the smooth $l1$ loss on all predicted time steps: $$L_{reg} = \\frac{1}{MT} \\sum_{m=1}^M \\sum_{t=1}^T reg(p_{m,y}^{\\hat{k}} - p_{m,t}^*) \\tag{7}$$ where $p_t^*$ is the ground truth BEV coordinates at time step $t$, $reg(x) = \\sum\\limits_i d(x_i)$, $x_i$ is the $i$-th element of $x$, and $d(x_i)$ is the smooth $\\ell1$ loss defined as: $$d(x_i) = \\begin{cases} 0.5x_i^2 \u0026\\text{if} ||x|| \u003c 1, \\ ||x_i|| - 0.5 \u0026 \\text{otherwise,} \\end{cases} \\tag{8}$$ where $||x_i||$ denotes the $\\ell1$ norm of $x_i$. ","date":"2023-07-16","objectID":"/posts/lanegcn/:2:5","tags":["LaneGCN"],"title":"LaneGCN 论文解读","uri":"/posts/lanegcn/"},{"categories":["Prediction"],"content":" Neural Network Layout ","date":"2023-07-16","objectID":"/posts/lanegcn/:2:6","tags":["LaneGCN"],"title":"LaneGCN 论文解读","uri":"/posts/lanegcn/"},{"categories":["Prediction"],"content":"Data Process And Network Construction 以官方的2645.csv数据集为例子 agent node: data['city']:城市名称 data['trajs'] = [agt_traj] + ctx_trajs:轨迹点，(agent + context vehicles) data['steps'] = [agt_step] + ctx_steps:在原始数据中的位置 data['feats'] = feats: (13 X 20 X 3) 前20预测轨迹 + 一维是否存在点 data['ctrs'] = ctrs: (13 X 2) 中心点 data['orig'] = orig: AGENT 当前点坐标 data['theta'] = theta: AGENT 偏转角 data['rot'] = rot: (2 X 2) 旋转矩阵 data['gt_preds'] = gt_preds:(13 X 30 X 2) 后30帧真实轨迹 data['has_preds'] = has_preds: (13 X 30) 标识后30帧轨迹是否存在 lane node: graph['ctrs'] = np.concatenate(ctrs, 0): lane node的中心点坐标 graph['num_nodes'] = num_nodes: lane node的数量 graph['feats'] = np.concatenate(feats, 0): lane node 方向向量 graph['turn'] = np.concatenate(turn, 0): lane node 转向标识 graph['control'] = np.concatenate(control, 0): lane node 的 has_traffic_control 标识 graph['intersect'] = np.concatenate(intersect, 0): lane node 的 is_intersection 标识 graph['pre'] = [pre]: pre[‘u’] 和 pre[‘v’], v 是 u 的pre， 这里表述的是lane node之间的关系 graph['suc'] = [suc]: suc[‘u’] 和 suc[‘v’], v 是 u 的suc， 这里表述的是lane node之间的关系 graph['lane_idcs'] = lane_idcs: lane node index 0 0 0 ... 0 1 1 1 ... 1 ... 83 83 83 ... 83 graph['pre_pairs'] = pre_pairs: pair 表述的是lane之间的关系 graph['suc_pairs'] = suc_pairs: pair 表述的是lane之间的关系 graph['left_pairs'] = left_pairs: pair 表述的是lane之间的关系 graph['right_pairs'] = right_pairs: pair 表述的是lane之间的关系 对于pre['u']和pre['v'], v 是 u 的 pre 对于suc['u']和suc['v'], v 是 u 的 suc 对于left['u']和left['v'], v 是 u 的 left 对于right['u']和right['v'], v 是 u 的 right Net结构 ActorNet input: M x 3 x 20 output: M x 128 x 20 解释: MapNet: 把 v 按照 u 加到center上 input: N x 4 output: N x 128 A2M input: N x 128 output: N x 128 M2M input: N x 128 output: N x 128 M2A input: N x 128 output: M x 128 A2A input: N x 128 output: N x 128 Prediction Header: input M x 128 MLP Regression MLP Classification ref link: https://zhuanlan.zhihu.com/p/447129428 ","date":"2023-07-16","objectID":"/posts/lanegcn/:2:7","tags":["LaneGCN"],"title":"LaneGCN 论文解读","uri":"/posts/lanegcn/"},{"categories":["draft"],"content":"paper link: https://arxiv.org/abs/2012.11717 论文解读参考: [1] https://zhuanlan.zhihu.com/p/434650863 [2] https://www.gushiciku.cn/pl/amod ","date":"2023-07-16","objectID":"/posts/social_nce/:0:0","tags":["draft"],"title":"Social_NCE 论文解读","uri":"/posts/social_nce/"},{"categories":["draft"],"content":"Issue to solve and its Solution Due to the ill-distributed training Data, it’s difficult to capture the notion of the “negative” examples like collision. Solution: Modeling the negative samples through self-supervision: a social contrastive loss: regularizes the extracted motion representation by discerning the ground-truth positive events from synthetic negative ones; Construct negative samples based on prior knowledge of rare but dangerous circumstances. a social sampling strategy (informed): construct the positive event from the ground-truth location of the primary agent and the negative events from the regions of other neighbors. given that one location cannot be occupied by multiple agents at the same time. ","date":"2023-07-16","objectID":"/posts/social_nce/:1:0","tags":["draft"],"title":"Social_NCE 论文解读","uri":"/posts/social_nce/"},{"categories":["draft"],"content":"Method: Contrastive Learning + Social NCE ","date":"2023-07-16","objectID":"/posts/social_nce/:2:0","tags":["draft"],"title":"Social_NCE 论文解读","uri":"/posts/social_nce/"},{"categories":["draft"],"content":"Contrastive Representation Learning Functionality: Representation Learning: to learn a parametric function that maps the raw data into a feature space to extract abstract and useful information for downstream tasks. NCE(Noise Contrastive Estimation): to train encoder $$\\mathcal{L_{NCE}} = -\\log \\frac{\\exp(sim(q,k^+)/\\tau)}{\\sum_{n=0}^N \\exp(sim(q,k_n)/ \\tau)}$$ where the encoded query $q$ is brought close to one positive key $k_0 = k^+$ and pushed apart from $N$ negative keys ${ k_1, k_2, … , k_N}$, $\\tau$ is a temperature hyperparameter, and $sim(u,v) = u^{\\mathsf{T}}v/(||u||||v||)$ is the cosine similarity between two feature vectors. ","date":"2023-07-16","objectID":"/posts/social_nce/:2:1","tags":["draft"],"title":"Social_NCE 论文解读","uri":"/posts/social_nce/"},{"categories":["draft"],"content":"Social NCE Social NCE Description: 智能体 $i$ 在时刻 $t$ 上的位置记为 $s^i_t=(x^i_t,y^i_t)$ 。那么 $M$ 个智能体的联合状态记为 $s_t = { s_t^1, …, s^M_t}$ 。给定一个历史观测序列 ${s_1, s_2, …, s_t}$ ，任务是预测所有智能体未来直至 $T$ 时刻的轨迹 ${s_{t+1}, …, s_T}$，许多最近的预测模型被设计为编码器 - 解码器神经网络，其中运动编码器 $f(\\cdot)$ 首先提取与 $i$ 相关的紧密表示 $h_t^i$ ，然后解码器 $g(\\cdot)$ 随后推测出其未来的轨迹 $\\hat{s}^i_{t+1,T}$ : $$h^i_t = f(s_{1:t}, i), $$ $$\\hat{s}^i_{t+1:T} = g(h^i_t)$$ 为了多智能体之间的社交互动，$f(\\cdot)$通常包含两个子模块：一个序列建模模块 $f_S(\\cdot)$ 用于编码每个单独的序列，以及一个交互模块 $f_I(\\cdot)$ 用于在多智能体之间共享信息： $$z^i_t = f_S(h^i_{t-1}, s^i_t),$$ $$h^i_t = f_I(z_t, i)$$ 其中， $z^i_t$ 是给定智能体 $i$ 在时间 $t$ 观察其自身状态的潜在表示， $z_t = {z^1_t,…,z^M_t}$ 。很多方法已经探索了各种架构，并验证了其准确性。尽管如此，它们的鲁棒性仍然是一个悬而未决的问题。 最近的几项工作表明，现有模型预测的轨迹通常会输出社会不可接受的解决方案（例如，碰撞），表明缺乏关于社会准则的常识。 query: embedding of history observations $q = \\psi(h^i_t)$, where $\\psi(\\cdot)$ is an MLP projection head; key: embedding of a future event $k = \\phi(s^i_{s+\\delta t}, \\delta t)$, where $\\phi(\\cdot)$ is an event encoder modeled by an MLP, $s_{t+\\delta t}^i$ is a sampled spatial location and $\\delta_t \u003e 0$ is the sampling horizon. tuning $\\delta_t \\in \\Lambda$, e.g. $\\Lambda = {1,…,4}$, then future events in the next few step can be taken in account simultaneously. Nevertheless, when $\\delta_t$ is a fixed value, then $\\phi(\\cdot)$ can be simplified as a location encoder, i.e., $\\phi(s^i_{t+\\delta t})$. 给定一个场景，包括感兴趣的主智体（蓝色）和附近多个相邻智体（灰色），Social-NCE 损失鼓励在嵌入空间中提取的运动表示，接近未来的正样本事件，并远离可能导致碰撞或不适的合成负样本事件. Social NCE的损失函数如下: $$\\mathcal{L_{SocialNCE}} = -\\log\\frac{\\exp(\\psi(h^i_t)\\cdot\\phi(s^{i,+}{t+\\delta t}, \\delta t)/\\tau)}{\\sum{\\delta t\\in\\Lambda}\\sum_{n=0}^{N}\\exp(\\psi(h^i_t)\\cdot\\phi(s^{i,n}_{t+\\delta t}, \\delta t)/\\tau))}$$ 最终的训练损失函数为Social-NCE和传统任务损失项之和，即轨迹预测的mean squared error (MSE) 或者negative log-likelihood (NLL)： $$\\mathcal{L}(f,g,\\psi, \\phi) = \\mathcal{L}{task}(f,g) + \\lambda \\mathcal{L}{SocialNCE}(f, \\psi, \\phi)$$ 其中，$\\lambda$ 为超参数，控制SocialNCE损失函数的重要程度。 ","date":"2023-07-16","objectID":"/posts/social_nce/:2:2","tags":["draft"],"title":"Social_NCE 论文解读","uri":"/posts/social_nce/"},{"categories":["draft"],"content":"sampling strategy in multi-agent context 采样策略 在其他智能体附近寻求更多信息的负样本: $$s^{i,n-}{t+\\delta t} = s^{j}{t+\\delta t} + \\bigtriangleup{s_p} + \\epsilon$$ 其中， $j\\in{1,2,…,M} \\backslash i$ 是其他agent的index, $\\bigtriangleup{s_p}$ 是适合社交距离的局部位移。 对于positive sample, 对该agent周围直接采样获得: $$s^{i,n-}{t+\\delta t} = s^{i}{t+\\delta t} + \\epsilon$$ ","date":"2023-07-16","objectID":"/posts/social_nce/:2:3","tags":["draft"],"title":"Social_NCE 论文解读","uri":"/posts/social_nce/"},{"categories":["Prediction"],"content":"paper link: https://arxiv.org/abs/2002.11927?from=leiphonecolumn_paperreview0323 ","date":"2023-07-16","objectID":"/posts/social_stgcnn/:0:0","tags":["draft"],"title":"Social_STGCNN 论文解读","uri":"/posts/social_stgcnn/"},{"categories":["Prediction"],"content":"网络结构 特点: Social STGCNN不同于其他方法只是聚合各种学习的行人状态，而是对行人交互做图建模。其中提出一种kernel function把行人社交交互嵌入一个adjacency matrix。 代码显示，图建模一般在数据前处理完成。 ","date":"2023-07-16","objectID":"/posts/social_stgcnn/:1:0","tags":["draft"],"title":"Social_STGCNN 论文解读","uri":"/posts/social_stgcnn/"},{"categories":["Prediction"],"content":"Model Description 两部分：时空图卷积神经网络ST-GCNN、时间外推器TXP-CNN。 ST-GCNN对行人轨迹的图表示进行时空卷积操作以提取特征。这些特征是观察到的行人轨迹历史的紧凑表示。 TXP-CNN将这些特征作为输入，并预测所有行人作为一个整体的未来轨迹。我们使用时间外推器的名字是因为TXP-CNN期望通过卷积运算外推未来的轨迹。 给定T帧，构造表示 $G=(V,A)$ 的时空图. 然后，$G$ 通过时空图卷积神经网络(ST-GCNNs)转发，创建一个时空嵌入。 之后，TXP-CNNs 预测了未来的轨迹。 $P$ 是行人位置的维数，$N$ 是行人的数目，$T$ 是时间步长, $\\hat{P}$是来自ST-GCNN的嵌入的维数. (1) Graph Representation of Pedestrian Trajectories 我们首先构造一组空间图 $G_t$，表示每个时间步长 $t$ 在场景中行人的相对位置，$G_t = (V_t, E_t)$ 。 $V_t$是图 $G_t$ 的顶点集，观察到的位置 $(x^i_t，y^i_t)$ 是顶点 $v^i_t$ 的属性; $E_t$ 是边集，如果顶点 $v^i_t$ 和顶点 $v^j_t$ 相连 $e^{ij}_t = 1$ ，否则 $=0$。 为了建模两个节点之间相互影响的强度，我们附加了一个值$a^{ij}_t$, 它是由每个$ e^{ij}_t$ 的某种核函数计算得到。$a^{ij}_t$ 被组织为带权邻接矩阵$A_t$。 $a^{ij}_{sim,t}$是要在邻接矩阵$A_t$中使用的内核函数。 定义为: $$\\begin{equation} a^{ij}_{sim,t}= \\left { \\begin{aligned} 1/||v^i_t - v^j_t||_2 , ||v^i_t - v^j_t||_1\\neq0 \\ 0, Otherwise \\end{aligned} \\right. \\end{equation}$$ (2) Graph Convolution Neural Network 对于在二维网格地图或特征地图上定义的卷积运算，定义如下: $$z^{(l+1)} = \\sigma(\\sum_{h=1}^{k}\\sum_{\\omega=1}^{k}(p(z^{(l)},h, \\omega) \\cdot \\boldsymbol{W}^{(l)}(h, \\omega))$$ 其中，$k$是内核大小，$p(.)$ 是采样函数，其聚集以$z$为中心的邻居的信息， $\\sigma$ 是激活函数。${l}$表示神经网络层。 图卷积定义如下: $$v^{i(l+1)} =\\sigma (\\frac{1}{\\Omega}\\sum_{v^{j(l)}\\in B(v^{j(l)})}p(v^{i(l)}, v^{j(l)}) \\cdot \\boldsymbol{W}(v^{i(l)}, v^{j(l)}))$$ 其中$\\frac{1}{\\Omega}$ 是正则化项，$B(v^i) = { v^j|d(v^i,v^j)≤D }$是顶点的邻居集，而$d(v^i,v^j)$表示连接$v^i$和$v^j$的最短距离， $\\Omega$是邻居集的基数。 (3) Spatio-Temporal Graph Convolution Neural Network(ST-GCNNs) 通过定义一个新的图G，其属性是$G_t$属性的集合，ST-GCNN将空间图卷积扩展到时空图卷积。 $G$结合了行人轨迹的时空信息。值得注意的是，$G_1，…，G_T$的拓扑结构是相同的，而当t变化时，不同的属性被分配给$v^i_t$。 因此，我们将$G$定义为$(V,E)$，其中$V={v_i|i\\in { 1，…，N }}$ 和 $E={e_{ij}|i，j，{1，…，N}}$。 顶点$v_i$在G中的属性是$v^i_t$的集合，$∀t∈{0，…，T}$。 另外， 加权邻接矩阵A对应于$G$ 是${ A_1，…，A_T}$的集合。 我们将ST-GCNN产生的嵌入表示为 $\\overline{V}$. (4) Time-Extrapolator Convolution Neural Network (TXP-CNN) ST-GCNN的功能是从输入图中提取时空节点嵌入。然而，我们的目标是预测行人未来的进一步位置。 TXP-CNN直接作用于图嵌入 $\\overline{V}$ 的时间维度，并将其扩展为预测的必要条件。 由于TXP-CNN依赖于特征空间的卷积运算，因此与递归单元相比，它的参数较小。需要注意的一个特性是， TXP-CNN层不是置换不变的，因为在TXP-CNN之前，图嵌入的变化会导致不同的结果。Other than this, if the order of pedestrians is permutated starting from the input to Social-STGCNN then the predictions are invariant. ","date":"2023-07-16","objectID":"/posts/social_stgcnn/:1:1","tags":["draft"],"title":"Social_STGCNN 论文解读","uri":"/posts/social_stgcnn/"},{"categories":["Prediction"],"content":"model(Social STGCNN) Implementation Adjacency Matrix Normalization $$ A_t = \\Lambda_t^{-\\frac{1}{2}}\\hat{A}\\Lambda_t^{-\\frac{1}{2}}$$ where $\\hat{A_t} = A_t + I$ and $\\Lambda_t$ is the diagonal node degree matric of $\\hat{A_t}$. We use $\\hat{A}$ and $\\Lambda$ to denote the stack of $\\hat{A_t}$ and $\\Lambda_t$ repectively. The normalization of adjacency is essential for the graph CNN to work properly. STGCNN Network Mechanism $$f(V^{l}, A) = \\sigma(\\Lambda_t^{-\\frac{1}{2}}\\hat{A}\\Lambda_t^{-\\frac{1}{2}}V^{(l)}W^{(l)})$$ where, $V^{(l)}$ denotes the stack of $V^{(l)}_t$, and $W^{(l)}$ denotes the trainable parameters. ","date":"2023-07-16","objectID":"/posts/social_stgcnn/:1:2","tags":["draft"],"title":"Social_STGCNN 论文解读","uri":"/posts/social_stgcnn/"},{"categories":["Prediction"],"content":"Data Processing 数据处理以及图构建 obs_traj - 前8帧观察轨迹(绝对坐标) pred_traj_gt - 后12帧预测轨迹(ground truth)(绝对坐标) obs_traj_rel - 前8帧观察轨迹(相对坐标) pred_traj_gt_rel - 后12帧预测轨迹(ground truth)(相对坐标) non_linear_ped - 非线性轨迹 (剔除) loss_mask V_obs - graph nodes A_obs - graph Adjacency Matrix V_tr - 预测轨迹 graph nodes A_tr - 预测轨迹 graph Adjacency Matrix ","date":"2023-07-16","objectID":"/posts/social_stgcnn/:2:0","tags":["draft"],"title":"Social_STGCNN 论文解读","uri":"/posts/social_stgcnn/"},{"categories":["Math"],"content":"一、 最小二乘法拟合直线 最小二乘拟合 是一种数学上的近似和优化，利用已知的数据得出一条直线或者曲线，使之在坐标系上与已知数据之间的距离的平方和最小。 TLS(Total Least Squares) vs OLS(Ordinary Least Squares) TSL vs OLS 如上图，TLS 和 OLS 都是最小二乘拟合，只是在偏差评估上采取了不同的方式。 最小二乘法是一种较为简单的回归分析方法。 最常用的是 OLS(Ordinary Least Square，普通最小二乘法): 所选择的回归模型应该使所有观察值的残差平方和达到最小（如上图左）。 OLS // Gary: O-Least-Square最小二乘拟合 Segment::LocalLine Segment::fitLocalLine(const std::list\u003cBin::MinZPoint\u003e \u0026points) { const unsigned int n_points = points.size(); // 构造 X/Y 矩阵 Eigen::MatrixXd X(n_points, 2); Eigen::VectorXd Y(n_points); unsigned int counter = 0; for (auto iter = points.begin(); iter != points.end(); ++iter) { X(counter, 0) = iter-\u003ed; X(counter, 1) = 1; Y(counter) = iter-\u003ez; ++counter; } // 计算 B const Eigen::MatrixXd X_t = X.transpose(); const Eigen::VectorXd result = (X_t * X).inverse() * X_t * Y; LocalLine line_result; line_result.first = result(0); line_result.second = result(1); return line_result; } Eigen 是C++中可以用来调用并进行矩阵计算的一个库，里面封装了一些类。 BP Network 通过解 $XB=Y$ 我们就能解出 $B=[m b]$： $$\\begin{gathered} m = \\frac{\\sum x_{i}^{2}\\sum y_{i}-\\sum x_{i}(\\sum x_{i}y_{i})}{n\\sum x_{i}^{2}-(\\sum x_{i})^{2}} \\\\ b = \\frac{n\\sum x_{i}\\sum y_{i}-\\sum x_{i}(\\sum x_{i}y_{i})}{n\\sum x_{i}^{2}-(\\sum x_{i})^{2}} \\end{gathered}$$ OrdinaryLeastSquare(const vector\u003cdouble\u003e\u0026 x, const vector\u003cdouble\u003e\u0026 y) { double t1=0, t2=0, t3=0, t4=0; for(int i=0; i\u003cx.size(); ++i) { t1 += x[i]*x[i]; t2 += x[i]; t3 += x[i]*y[i]; t4 += y[i]; } m = (t3*x.size() - t2*t4) / (t1*x.size() - t2*t2); b = (t1*t4 - t2*t3) / (t1*x.size() - t2*t2); } OLS 这种 least square 存在问题，比如针对垂直线段就不行，于是引入第二种 Total Least Square。 BP Network BP Network 其中，$U=\\begin{bmatrix}x_1-\\overline{x}\u0026y_1-\\overline{y}\\\\\\vdots\u0026\\vdots\\\\x_n-\\overline{x}\u0026y_n-\\overline{y}\\end{bmatrix}$; $\\frac{dE}{dN}=\\frac{d(N^TU^TUN)}{dN}=U^TUN+N^TU^TU$ ,因为 $U^TU $ 是一个对称矩阵 $(U^TU=(U^TU)^T)$, $U^TUN=N^TU^TU$, 所以 $\\frac{dE}{dN}=2(U^TU)N$; 此外，$U^TU=\\begin{bmatrix}\\sum(x_i-\\overline x)^2\u0026\\sum(x_i-\\overline x)(y_i-\\overline y)\\\\\\sum(x_i-\\overline x)(y_i-\\overline y)\u0026\\sum(y_i-\\overline y)^2\\end{bmatrix}$ 是关于 X、Y 的一个二阶矩(随机变量平方的期望)矩阵(second-moment matrix); 二阶矩矩阵 $U^{T}U$ 的最小特征值对应的特征向量即为求解的 $N=[a b]$ 特征值 \u0026 特征向量 设 A为 n 阶矩阵 $(n × n)$，若存在常数 λ 及 n 维非零向量 x(n × 1)，使得 $Ax = λx$，则称 λ是矩阵 A 的 特征值，x 是 A 属于特征值 λ 的 特征向量。 $eig(U^T U) = [V, D]$, $V$ 是特征向量阵（每列为一个特征向量），D特征值对角阵 ⟹ 寻找 D 中特征值最小的对角元素对应的特征向量即为 $U^TU$ 最小特征值对应的特征向量 特征值分解： $U^T U = V D V^{-1}$ 通过 SVD（奇异值）求解: $SVD(A)=[U,S,V]$,即 $A=USV^T$ 其中 $U$ 是一个m*m的正交阵（Orthogonal matrix：满足 $UU^T=I$ 或者 $U^TU=I$ 的 n 阶方阵，其中 I 为 n 阶单位阵），$S$ 是一个m*n的对角阵（Diagonal matrix：主对角线之外的元素皆为 0 的矩阵，对角线上的元素可以为 0 或其他值），对角线上的元素为 $A$ 的奇异值（Singular value），$V$ 是一个n*n的正交阵。$U$ 的 m 个列向量为 $A$ 的左奇异向量（Left singular vector），$V$ 的 n 个列向量为 $A$ 的右奇异向量（Right singular vector）。$S$ 完全由 $A$ 决定和 $U$、$V$ 无关； $A$ 的左奇异向量（$U$）是 $AA^T$ 的特征向量；$A$ 的右奇异向量是 $A^TA$ 的特征向量。 $A$ 的非零奇异值是 $A^TA$ 特征值的平方根，同时也是 $AA^T$ 特征值的平方根。 寻找 $S$ 中最小奇异值对应的 $V$ 的右奇异向量即为 $A^TA$ 最小特征值对应的特征向量。 #include \u003ciostream\u003e #include \u003cEigen/Dense\u003e #include \u003cEigen/Eigenvalues\u003e using namespace Eigen; using namespace std; int main() { // Eigenvalue // typedef Matrix\u003cint, 3, 3\u003e Matrix3d Matrix3d A; A \u003c\u003c 1, 2, 3, 4, 5, 6, 7, 8, 9; cout \u003c\u003c \"Here is a 3x3 matrix, A:\" \u003c\u003c endl \u003c\u003c A \u003c\u003c endl \u003c\u003c endl; EigenSolver\u003cMatrix3d\u003e es(A.transpose() * A); // 对角矩阵，每一个对角线元素就是一个特征值，里面的特征值是由大到小排列的 Matrix3d D = es.pseudoEigenvalueMatrix(); // 特征向量（每一列）组成的矩阵 Matrix3d V = es.pseudoEigenvectors(); cout \u003c\u003c \"The eigenvalue matrix D is:\" \u003c\u003c endl \u003c\u003c D \u003c\u003c endl \u003c\u003c endl; cout \u003c\u003c \"The eigenvector matrix V is:\" \u003c\u003c endl \u003c\u003c V \u003c\u003c endl \u003c\u003c endl; // 特征值分解 // cout \u003c\u003c \"Finally, V * D * V^(-1) = \" \u003c\u003c endl \u003c\u003c V * D * V.inverse() \u003c\u003c endl; // 特征值\u0026特征向量 cout \u003c\u003c \"min-eigenvector \u0026 min-eigenvalue\" \u003c\u003c endl; cout \u003c\u003c \" \u003c1\u003e The min-eigenvalue for A^T*A:\" \u003c\u003c endl \u003c\u003c D(D.rows()-1, D.rows()-1) \u003c\u003c endl; cout \u003c\u003c \" \u003c2\u003e The min-eigenvector for A^T*A:\" \u003c\u003c endl \u003c\u003c V.col(V.cols()-1) \u003c\u003c endl; cout \u003c\u003c \" \u003c3\u003e (A^T*A)*min-eigenvector =\" \u003c\u003c endl \u003c\u003c (A.transpose()*A) * V.col(V.cols()-1) \u003c\u003c endl; cout \u003c\u003c \" \u003c4\u003e min-eigenvalue*min-eigenvector =\" \u003c\u003c endl \u003c\u003c D(D.rows()-1, D.rows()-1)*","date":"2023-07-16","objectID":"/posts/linefitting/:1:0","tags":["曲线拟合"],"title":"曲线拟合","uri":"/posts/linefitting/"},{"categories":["Math"],"content":"二、 三次样条曲线 根据起始点和终点求三次样条曲线的系数 已知三次样条曲线的方程为 $y = a_0 + a_1 \\cdot x + a_2 \\cdot x ^ 2 + a_3 \\cdot x ^ 3$ ， 并且已知起始点坐标 $(x_0, y_0)$, 起始点导数k_1, 终点坐标(x_1, y_1), 终点导数k_2, 求三次样条曲线的系数 解: 通过平移变换可知， 将起始点置于零点，则终点为$(x_1 - x_0, y_1 - y_0)$，那么根据点和相关点之间的导数可以求相应的系数。方程如下: $a_0 = y_0$ $a_1 = k_0$ $(y_1 - y_1) = a_1 * (x_1 - x_0) + a_2 * (x_1 - x_0) ^ 2 + a_3 * (x_1 - x_0) ^ 3$ $k_1 = a_1 + 2 * a_2 * (x_1 - x_0) + 3 * a_3 * (x_1 - x_0) ^ 2$ 或者也可以设三次样条曲线方程为:$y = a_0 + a_1 * (x - x_0) + a_2 * (x - x_1) ^ 2 + a_3 * (x - x_2) ^ 3$ 代码参考: void PredictorManager::GetCubicPolynomialCofficients(double start_s, double start_ds, double end_s, double end_ds, double start_t, double end_t, std::array\u003cdouble, 4\u003e* coeffs) { coeffs-\u003eoperator[](0) = start_s; coeffs-\u003eoperator[](1) = start_ds; double p = end_t - start_t; double p2 = p * p; double p3 = p2 * p; double tmp_var1 = (end_ds - start_ds) * p; double tmp_var2 = end_s - start_s - start_ds * p; coeffs-\u003eoperator[](2) = (3.0 * tmp_var2 - tmp_var1) / p2; coeffs-\u003eoperator[](3) = (tmp_var1 - 2.0 * tmp_var2) / p3; } double EvaluateQuarticPolynomial(const std::array\u003cdouble, 5\u003e\u0026 coeffs, const double t, const uint32_t order, const double end_t, const double end_v) { if (t \u003e= end_t) { switch (order) { case 0: { double end_value = (((coeffs[4] * end_t + coeffs[3]) * end_t + coeffs[2]) * end_t + coeffs[1]) * end_t + coeffs[0]; return end_value + (t - end_t) * end_v; } case 1: { return end_v; } default: { return 0.0; } } } switch (order) { case 0: { return (((coeffs[4] * t + coeffs[3]) * t + coeffs[2]) * t + coeffs[1]) * t + coeffs[0]; } case 1: { return ((4.0 * coeffs[4] * t + 3.0 * coeffs[3]) * t + 2.0 * coeffs[2]) * t + coeffs[1]; } case 2: { return (12.0 * coeffs[4] * t + 6.0 * coeffs[3]) * t + 2.0 * coeffs[2]; } case 3: { return 24.0 * coeffs[4] * t + 6.0 * coeffs[3]; } case 4: { return 24.0 * coeffs[4]; } default: return 0.0; } } ","date":"2023-07-16","objectID":"/posts/linefitting/:1:1","tags":["曲线拟合"],"title":"曲线拟合","uri":"/posts/linefitting/"},{"categories":["Math"],"content":"三、Bezier曲线 参考文献: [1]. [三次样条曲线求系数1](https://huaweicloud.csdn.net/63a571ddb878a5454594788c.html?spm=1001.2101.3001.6650.2\u0026utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Eactivity-2-90477388-blog-118017126.pc_relevant_vip_default\u0026depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Eactivity-2-90477388-blog-118017126.pc_relevant_vip_default\u0026utm_relevant_index=3#devmenu7) [2]. [三次样条曲线求系数2](https://blog.csdn.net/ymj7150697/article/details/105713587) [3]. [三次样条曲线求系数3](https://blog.csdn.net/weixin_37722026/article/details/103778202) ","date":"2023-07-16","objectID":"/posts/linefitting/:1:2","tags":["曲线拟合"],"title":"曲线拟合","uri":"/posts/linefitting/"},{"categories":["Math"],"content":"References: [1].最小二乘法拟合直线 ","date":"2023-07-16","objectID":"/posts/linefitting/:2:0","tags":["曲线拟合"],"title":"曲线拟合","uri":"/posts/linefitting/"},{"categories":["C++"],"content":"C++ STL (Standard Template Library) 总结 C++ STL 容器是使用频率超高的基础设施，只有了解各个容器的底层原理，才能得心应手地用好不同的容器，做到用最合适的容器干最合适的事情。 本文旨在对 C++ 标准模板库的 array, vector, deque, list, forward_list, queue, priority_queue, stack, map, multimap, set, multi_set, unordered_map, unordered_multimap, unordered_set, unordered_multiset 共十六类容器进行系统的对比分析，重点关注各个容器的底层原理与性能特点。本文唯一参考资料为C++官方文档，若有其它参考则会指明出处。 ","date":"2023-07-16","objectID":"/posts/datastructrue/:1:0","tags":["draft"],"title":"C++ STL Containers","uri":"/posts/datastructrue/"},{"categories":["C++"],"content":"1. array Container properties: Sequence | Contiguous storage | Fixed-size aggregate 容器属性：顺序容器（支持随机访问），连续内存空间，固定大小；//连续内存 类模板头：template \u003c class T, size_t N \u003e class array; array 即数组，其大小固定，所有的元素严格按照内存地址线性排列，array 并不维护元素之外的任何多余数据，甚至也不会维护一个size这样的变量，这保证了它在存储性能上和C++语法中的数组符号[]无异。尽管其它大部分标准容器都可以通过 std::allocator 来动态的分配和回收内存空间，但 Array 并不支持这样做。 Array 和其它标准容器一个很重要的不同是：对两个 array 执行 swap 操作意味着真的会对相应 range 内的元素一一置换，因此其时间花销正比于置换规模；但同时，对两个 array 执行 swap 操作不会改变两个容器各自的迭代器的依附属性，这是由 array 的 swap 操作不交换内存地址决定的。 Array 的另一个特性是：不同于其它容器，array 可以被当作 std::tuple 使用，因为 array 的头文件重载了get()以及tuple_size()和tuple_element()函数（注意这些函数非 array 的成员函数，而是外部函数）。 最后需要注意，虽然 array 和 C++语法中的[]符号无限接近，但两者是两个存在，array 毕竟是标准模板库的一员，是一个class，因此支持 begin(), end(), front(), back(), at(), empty(), data(), fill(), swap(), ... 等等标准接口，而[]是真正的最朴素的数组。 ","date":"2023-07-16","objectID":"/posts/datastructrue/:1:1","tags":["draft"],"title":"C++ STL Containers","uri":"/posts/datastructrue/"},{"categories":["C++"],"content":"2. vector Container properties: Sequence | Dynamic array | Allocator-aware 容器属性：顺序容器（支持随机访问），动态调整大小，使用内存分配器动态管理内存；//连续内存 类模板头：template \u003c class T, class Alloc = allocator \u003e class vector; 一句话来说，vector 就是能够动态调整大小的 array。和 array 一样，vector 使用连续内存空间来保存元素，这意味着其元素可以用普通指针的++和--操作来访问；不同于 array 的是，其存储空间可以自动调整。 在底层上，vector 使用动态分配的 array，当现有空间无法满足增长需求时，会重新分配（reallocate）一个更大的 array 并把所有元素移动过去，因此，vector 的 reallocate 是一个很耗时的处理。所以，每次 reallocate 时都会预留多余的空间，以满足潜在的增长需求，也就是说，vector的capacity()通常会大于size()。vector 什么时候做 reallocate，reallocate 多少多余空间，是有具体策略的，按下不表。总体来说，vector 比 array 多了一些内存消耗，以换取更灵活的内存管理。 和其它的动态顺序容器（deque, list, forward_list）相比，vector 在元素访问上效率最高，在尾部增删元素的效率也相对最高。如果调用者有在尾部以外的地方增删元素的需求，vector 则不如其它容器，并且迭代器的一致性也较差（have less consistent iterators and references than lists and forward_lists）。 ","date":"2023-07-16","objectID":"/posts/datastructrue/:1:2","tags":["draft"],"title":"C++ STL Containers","uri":"/posts/datastructrue/"},{"categories":["C++"],"content":"3. queue 容器属性：容器适配器(adapter)，先进先出型容器（FIFO）；//C++设计模式之适配器模式 template \u003cclass T, class Container = deque \u003e class queue; queue（普通队列）是一个专为 FIFO 设计的容器适配器，也即只能从一端插入、从另一端删除；所谓容器适配器，是指它本身只是一个封装层，必须依赖指定的底层容器（通过模板参数中的class Container指定）才能实现具体功能。 **容器适配器(Adapter)**实际上是C++设计模式的一种 – 称为 Adapter 模式（适配器模式），Adapter 模式的目的是将第三方库提供的接口做一个封装和转化，使其适配自己工程中预留的接口，或者适应自己工程的调用风格。换句话说，Adapter 模式的目的是将被调用类（如第三方库）的接口转化为希望的接口。 回到正题，queue 可以接纳任何一个至少支持下列接口的容器作为底层容器： empty(); size(); front(); back(); push_back(); pop_front(). 在标准模板库容器中，deque 和 list 满足上述要求，当然用户也可以自定义一个满足上述要求的容器。通过模板参数可以看出，默认情况下，queue 使用 deque 作为底层容器。 ","date":"2023-07-16","objectID":"/posts/datastructrue/:1:3","tags":["draft"],"title":"C++ STL Containers","uri":"/posts/datastructrue/"},{"categories":["C++"],"content":"4. deque Container properties: Sequence | Dynamic array | Allocator-aware 容器属性：顺序容器（支持随机访问），动态调整大小，使用内存分配器动态管理内存；//分段连续内存 类模板头：template \u003c class T, class Alloc = allocator \u003e class deque; deque（读作\"deck\"）是 double-ended queue 的缩写，是一个可以在首尾两端进行动态增删的顺序容器。 不同的库对 deque 的实现可能不同，但大体上都是某种形式的动态 array，且都支持随机访问。deque 的功能和 vector 比较接近，但 deque 额外支持在头部动态增删元素。和 vector 不一样的是，deque 不保证存储区域一定是连续的! 因此用指向元素的普通指针做++和--操作是非常危险的行为。 从底层机理上能更透彻地理解 deque 的特点：vector 使用的是单一的 array，deque 则会使用很多个离散的 array 来组织数据「the elements of a deque can be scattered in different chunks of storage」！如果说 vector 是连续的，deque 则是分段连续。deque 会维护不同 array 之间的关联信息，使用户无需关心分段这个事实。这样做的好处是很明显的：deque 在 reallocate 时，只需新增/释放两端的 storage chunk 即可，无需移动已有数据（vector 的弊端），极大提升了效率，尤其在数据规模很大时，优势明显。 相比于 vector 和 list，deque 并不适合遍历！因为每次访问元素时，deque 底层都要检查是否触达了内存片段的边界，造成了额外的开销！deque 的核心优势是在双端都支持高效的增删操作，程序员选择使用 deque 时需要有双端操作的明确理由。 ","date":"2023-07-16","objectID":"/posts/datastructrue/:1:4","tags":["draft"],"title":"C++ STL Containers","uri":"/posts/datastructrue/"},{"categories":["C++"],"content":"5. priority_queue 容器属性：容器适配器，严格弱序（Strict Weak Ordering），优先级队列； template \u003cclass T, class Container = vector, class Compare = less \u003e class priority_queue; 和 queue 类似，priority_queue（术语叫作优先级队列）也只是一个容器适配器，需要指定底层容器才能实例化，参见模板参数中的class Container形参。priority_queue 的核心特点在于其严格弱序特性（strict weak ordering）：也即 priority_queue 保证容器中的第一个元素始终是所有元素中最大的！为此，用户在实例化一个 priority_queue 时，必须为元素类型（class T）重载\u003c运算符，以用于元素排序！ priority_queue 的原理可以用一个大顶堆来解释：priority_queue 在内部维护一个基于二叉树的大顶堆数据结构，在这个数据结构中，最大的元素始终位于堆顶部，且只有堆顶部的元素（max heap element）才能被访问和获取，大顶堆的具体原理可参见任何一本数据结构书籍。 为了支持这种工作原理，priority_queue 对底层容器也是有要求的，priority_queue 的底层容器必须支持随机访问和至少以下接口： empty(); size(); front(); push_back(); pop_back(). 标准模板库中的 vector 和 deque 能够满足上述需求，默认情况下，priority_queue 使用 vector 作为底层容器。 某种程度上来说，priority_queue 默认在 vector 上使用堆算法将 vector 中元素构造成大顶堆的结构，因此 priority_queue 就是堆 ，所有需要用到堆的位置，都可以考虑使用 priority_queue。priority_queue 默认是大顶堆，用户也可以通过自定义模板参数中的 class Compare 来实现一个小顶堆。 相比于 queue（普通队列）的先进先出FIFO，priority_queue 实现了最高优先级先出。 ","date":"2023-07-16","objectID":"/posts/datastructrue/:1:5","tags":["draft"],"title":"C++ STL Containers","uri":"/posts/datastructrue/"},{"categories":["C++"],"content":"6. list Container properties: Sequence | Doubly-linked list | Allocator-aware 容器属性：顺序容器（可顺序访问，但不支持随机访问），双链表，使用内存分配器动态管理内存；//离散内存 类模板头：template \u003c class T, class Alloc = allocator \u003e class list; list 是一种支持在任意位置都可以快速地插入和删除元素的容器，且支持双向遍历。list 容器能够做到这些的原因在于其底层结构是双链表，双链表允许把各个元素都保存在彼此不相干的内存地址上，但每个元素都会与前后相邻元素关联。 和其它的顺序容器（array, vector, deque）相比，list 的最大优势在于支持在任意位置插入、删除和移动元素，对 list 来说，在哪个位置进行操作并没有区别。list 在部分算法（如 sorting）中的效率可能优于其它顺序容器。 list 的主要缺点是不支持元素的随机访问！如果我们想要访问某个元素，则必须从一个已知元素（如 begin 或 end）开始朝一个方向遍历，直至到达要访问的元素。此外，list 还要消耗更多的内存空间，用于保存各个元素的关联信息。 [另说] list 对内存空间的使用效率并不高，一方面元素内存地址是离散的而非连续，另一方面，list 需要保存额外的关联信息。 ","date":"2023-07-16","objectID":"/posts/datastructrue/:1:6","tags":["draft"],"title":"C++ STL Containers","uri":"/posts/datastructrue/"},{"categories":["C++"],"content":"7. forward_list Container properties: Sequence | Linked list | Allocator-aware 容器属性：顺序容器（可顺序访问，但不支持随机访问），单链表，使用内存分配器动态管理内存； 类模板头：template \u003c class T, class Alloc = allocator \u003e class list; forward_list 也是一种支持在任意位置快速插入和删除元素的容器，forward_list 相比于 list 的核心区别是它是一个单链表，因此, 每个元素只会与相邻的下一个元素关联！由于关联信息少了一半，因此 forward_list 占用的内存空间更小，且插入和删除的效率稍稍高于 list。作为代价，forward_list 只能单向遍历。 相比于其它顺序容器（array, vector, deque），forward_list 的优缺点和 list 基本相同。 既然已经有了 list，为什么 C++ STL 又设计了 forward_list 这一容器呢？设计 forward_list 的目的是为了达到不输于任何一个C风格手写链表的极值效率！为此，forward_list 是一个最小链表设计，它甚至没有size()接口，因为内部维护一个size变量会降低增删元素的效率。如果想要获取 forward_list 的 size，一个通常的做法是，用 std::distance 计算 begin 到 end 的距离得出 size。一句话总结：list 兼顾了接口丰富性牺牲了效率，而 forward_list 舍弃了不必要的接口只为追求极致效率。 ","date":"2023-07-16","objectID":"/posts/datastructrue/:1:7","tags":["draft"],"title":"C++ STL Containers","uri":"/posts/datastructrue/"},{"categories":["C++"],"content":"8. stack 容器属性：容器适配器，后进先出型容器（LIFO）； template \u003cclass T, class Container = deque \u003e class stack; stack（栈）是一个专为 LIFO 设计的容器适配器，也即只能从一端插入和删除；作为适配器，需要指定底层容器才能实例化，参见模板参数中的class Container形参。 stack 的特点是后进先出（一端进出），不允许遍历；任何时候外界只能访问 stack 顶部的元素；只有在移除 stack 顶部的元素后，才能访问下方的元素。stack 需要底层容器能够在一端增删元素，这一端也即 stack 的“栈顶”；stack 可以接纳任何一个至少支持下列接口的容器作为底层容器： empty(); size(); back(); push_back(); pop_back() 在标准模板库容器中，vector、deque 和 list 满足上述要求，当然用户也可以自定义一个满足上述要求的容器。通过模板参数可以看出，默认情况下，stack 使用 deque 作为底层容器。 stack 容器应用广泛，例如，编辑器中的 undo （撤销操作）机制就是用栈来记录连续的操作。stack 的设计场景和自助餐馆中堆叠的盘子、摞起来的一堆书类似。 ","date":"2023-07-16","objectID":"/posts/datastructrue/:1:8","tags":["draft"],"title":"C++ STL Containers","uri":"/posts/datastructrue/"},{"categories":["C++"],"content":"9. map Container properties: Associative | Ordered | Map | Unique keys | Allocator-aware 容器属性：关联容器，有序，元素类型\u003ckey, value\u003e，key是唯一的，使用内存分配器动态管理内存 ； template \u003c class Key, // map::key_type class T, // map::mapped_type class Compare = less, // map::key_compare class Alloc = allocator\u003cpair\u003cconst Key,T\u003e \u003e // map::allocator_type class map; map 是一个关联型容器，其元素类型是由 key 和 value 组成的 std::pair，实际上 map 中元素的数据类型正是 typedef pair\u003cconst Key, T\u003e value_type;，这就看的很清楚了。 所谓关联容器，是指对所有元素的检索都是通过元素的 key 进行的（而非元素的内存地址），map 通过底层的「红黑树」数据结构来将所有的元素按照 key 的相对大小进行排序，所实现的排序效果也是严格弱序特性（strict weak ordering），为此，开发者需要重载 key 的\u003c运算符或者模板参数中的 class Compare。所提到的红黑树是一种自平衡二叉搜索树，它衍生自B树，这里推荐两篇文章（记一次腾讯面试：有了二叉查找树、平衡树（AVL）为啥还需要红黑树？，图解：什么是红黑树？）作为更深入的参考。 大体来说，map 访问元素的速度要稍慢于下文的 unordered_map，这是因为虽然都叫“map”，但两者的底层机制完全不一样。但是，相比于后者，map 支持在一个子集合上进行直接迭代器访问，原因在于 map 中的元素是被有序组织的。 最后，map 也支持通过operator[]的方式来直接访问 value。 ","date":"2023-07-16","objectID":"/posts/datastructrue/:1:9","tags":["draft"],"title":"C++ STL Containers","uri":"/posts/datastructrue/"},{"categories":["C++"],"content":"10. multimap Container properties: Associative | Ordered | Map | Multiple equivalent keys | Allocator-aware 容器属性: 关联容器，有序，元素类型\u003ckey, value\u003e，允许不同元素key相同，使用内存分配器管理内存； template \u003c class Key, // map::key_type class T, // map::mapped_type class Compare = less, // map::key_compare class Alloc = allocator\u003cpair\u003cconst Key,T\u003e \u003e // map::allocator_type class map; map 中不允许出现 key 相同的两个元素，但 multimap 则可以这样做！ multimap 与 map 底层原理完全一样，都是使用「红黑树」对元素数据按 key 的比较关系，进行快速的插入、删除和检索操作；所不同的是 multimap 允许将具有相同 key 的不同元素插入容器（这个不同体现了 multimap 对红黑树的使用方式的差异）。在 multimap 容器中，元素的 key 与元素 value 的映射关系，是一对多的，因此，multimap 是多重映射容器。 注意，在向 multimap 中新增元素时，multimap 只会判断 key 是否相同，而完全不会判断 value 是否相同！这意味着如果相同的 \u003ckey, value\u003e 插入了多次，multimap 会对它们悉数保存！ 在使用中，我们可以通过迭代器配合 lower_bound() 和 upper_bound() 来访问一个 key 对应的所有 value，也可以使用equal_range()来访问一个 key 对应的所有 value，也可以通过find()配合count()来访问一个 key 对应的所有 value，个人认为前两种方法使用起来更方便一点。 下文中将要提到的 multiset 之于 set 类似于这里的 multimap 之于 map。 ","date":"2023-07-16","objectID":"/posts/datastructrue/:1:10","tags":["draft"],"title":"C++ STL Containers","uri":"/posts/datastructrue/"},{"categories":["C++"],"content":"11. set Container properties: Associative | Ordered | Set | Unique keys | Allocator-aware 容器属性：关联容器，有序，元素自身即key，元素有唯一性，使用内存分配器动态管理内存； template \u003c class T, // set::key_type/value_type class Compare = less, // set::key_compare/value_compare class Alloc = allocator // set::allocator_type class set; set 是一个关联型容器，和 map 一样，它的底层结构是「红黑树」，但和 map 不一样的是，set 是直接保存 value 的，或者说，set 中的 value 就是 key。 set 中的元素必须是唯一的，不允许出现重复的元素，且元素不可更改，但可以自由插入或者删除。 由于底层是红黑树，所以 set 中的元素也是严格弱序（strict weak ordering）排序的，因此支持用迭代器做范围访问（迭代器自加自减）。 实际使用中，set 和 map 是近亲，性能相似，他们的差别是元素的 value 本身是否也作为 key 来标识自己。 ","date":"2023-07-16","objectID":"/posts/datastructrue/:1:11","tags":["draft"],"title":"C++ STL Containers","uri":"/posts/datastructrue/"},{"categories":["C++"],"content":"12. multi_set Container properties: Associative | Ordered | Set | Multiple equivalent keys | Allocator-aware 容器属性：关联容器，有序，元素自身即key，允许不同元素值相同，使用内存分配器动态管理内存 ； template \u003c class T, // multiset::key_type/value_type class Compare = less, // multiset::key_compare/value_compare class Alloc = allocator \u003e // multiset::allocator_type class multiset; multiset 之于 set 就如同 multimap 之于 map： multiset 和 set 底层都是红黑树，multiset 相比于 set 支持保存多个相同的元素； multimap 和 map 底层都是红黑树，multimap 相比于 map 支持保存多个key相同的元素。 鉴于以上近亲关系，multiset 的性能特点与其它三者相似，不再赘述。 ","date":"2023-07-16","objectID":"/posts/datastructrue/:1:12","tags":["draft"],"title":"C++ STL Containers","uri":"/posts/datastructrue/"},{"categories":["C++"],"content":"13. unordered_map Container properties: Associative | Unordered | Map | Unique keys | Allocator-aware 容器属性：关联容器，无序，元素类型\u003ckey, value\u003e，key是唯一的，使用内存分配器动态管理内存 ； template \u003c class Key, // unordered_map::key_type class T, // unordered_map::mapped_type class Hash = hash, // unordered_map::hasher class Pred = equal_to, // unordered_map::key_equal class Alloc = allocator\u003c pair\u003cconst Key,T\u003e \u003e // unordered_map::allocator_type class unordered_map; unordered_map 和 map 一样，都是关联容器，以键值对儿 \u003ckey, value\u003e 作为元素进行存储；但是，除此之外，两者可以说是完全不一样！ 这是由底层的数据结构决定的，map 以红黑树作为底层结构组织数据，而 unordered_map 以哈希表(hash table)作为底层数据结构来组织数据，这造成了两点重要影响： 1. unordered_map 不支持排序，在使用迭代器做范围访问时（迭代器自加自减）效率更低； 2. 但 unordered_map 直接访问元素的速度更快（尤其在规模很大时），因为它通过直接计算 key 的哈希值来访问元素，是O(1)复杂度！ 网络上有对 map VS unordered_map 效率对比的测试，通常 map 增删元素的效率更高，unordered_map 访问元素的效率更高，可以参见这篇文章。另外，unordered_map 内存占用更高，因为底层的哈希表需要预分配足量的空间。 综上，unordered_map 更适用于增删操作不多，但需要频繁访问，且内存资源充足的场合。 比如在机器人领域的SLAM技术中，可以选择 unordered_map 来维护体素形式的 local map？ 当然 deque 应该也是不错的选择。 ","date":"2023-07-16","objectID":"/posts/datastructrue/:1:13","tags":["draft"],"title":"C++ STL Containers","uri":"/posts/datastructrue/"},{"categories":["C++"],"content":"14. unordered_multimap Container properties: Associative | Unordered | Map | Multiple equivalent keys | Allocator-aware 容器属性：关联容器，无序，元素类型\u003ckey, value\u003e，允许不同元素key相同，使用内存分配器管理内存 ； template \u003c class Key, // unordered_multimap::key_type class T, // unordered_multimap::mapped_type class Hash = hash, // unordered_multimap::hasher class Pred = equal_to, // unordered_multimap::key_equal class Alloc = allocator\u003c pair\u003cconst Key,T\u003e \u003e // unordered_multimap::allocator_type class unordered_multimap; unordered_multimap 是对 unordered_map 的拓展，唯一区别在于 unordered_multimap 允许不同元素的 key 相同，但两者无论是在底层结构还是在容器特性上都是相通的，仅仅是对底层哈希表的使用方式稍有不同。 在 unordered_multimap 中想要访问同一个 key 下对应的所有元素的话，可以使用equal_range()轻松做到；当然，也可以使用find()和count()配合的方式来访问。 unordered_multimap 的容器特性参见 unordered_map，不再赘述。 ","date":"2023-07-16","objectID":"/posts/datastructrue/:1:14","tags":["draft"],"title":"C++ STL Containers","uri":"/posts/datastructrue/"},{"categories":["C++"],"content":"15. unordered_set Container properties: Associative | Unordered | Set | Unique keys | Allocator-aware 容器属性：关联容器，无序，元素自身即key，元素有唯一性，使用内存分配器动态管理内存 ； template \u003c class Key, // unordered_set::key_type/value_type class Hash = hash, // unordered_set::hasher class Pred = equal_to, // unordered_set::key_equal class Alloc = allocator // unordered_set::allocator_type class unordered_set; 所有unordered_XXX类容器的特点都是以哈希表作为底层结构；所有 XXX_set 类容器的特点都是「元素自身也作为key」来标识自己。我们在把两类特性叠加到一起，就得到了 unordered_set。 在 unordered_set 中，元素自身同时也作为 key 使用；既然是作为 key 使用，那么元素就不能被更改，也即 unordered_set 中的元素都是 constant 的，但我们可以自由的插入和删除元素，这也是所有XXX_set类容器的性质。既然底层结构是哈希表，意味着 unordered_set 中的元素是无序的，不能按照大小排序，这也是所有unordered_XXX类容器的性质。 和所有的unordered_XXX类容器一样： 1. unordered_set 直接用迭代器做范围访问时（迭代器自加自减）效率更低，低于 set； 2. 但 unordered_set 直接访问元素的速度更快（尤其在规模很大时），因为它通过直接计算 key 的哈希值来访问元素，是O(1)复杂度！ ","date":"2023-07-16","objectID":"/posts/datastructrue/:1:15","tags":["draft"],"title":"C++ STL Containers","uri":"/posts/datastructrue/"},{"categories":["C++"],"content":"16. unordered_multiset Container properties: Associative | Unordered | Set | Multiple equivalent keys | Allocator-aware 容器属性：关联容器，无序，元素自身即key，允许不同元素值相同，使用内存分配器动态管理内存 ； template \u003c class Key, // unordered_multiset::key_type/value_type class Hash = hash, // unordered_multiset::hasher class Pred = equal_to, // unordered_multiset::key_equal class Alloc = allocator // unordered_multiset::allocator_type class unordered_multiset; unordered_multiset，顾名思义，就是集齐了“哈希表为底层结构”，“元素自身即key”，“允许不同元素值相同”这三个特性的容器，是对 unordered_set 的简单拓展。 unordered_multiset 的效率特性与所有基于哈希表的容器相似，参见 unordered_set，不再赘述。 ","date":"2023-07-16","objectID":"/posts/datastructrue/:1:16","tags":["draft"],"title":"C++ STL Containers","uri":"/posts/datastructrue/"},{"categories":["C++"],"content":"17. pair \u0026\u0026 tuple template \u003cclass… Types\u003e class tuple; template \u003cclass T1, class T2\u003e struct pair; std::pair 和 std::tuple 并不是stl容器库中的容器，不过鉴于经常用到，就顺便整理一下。先从 tuple 说起，pair 相当于 tuple 的特例。 tuple 叫作元组，它可以把一组类型相同或不同的元素组合到一起，且元素的数量不限。tuple 的底层原理与 stl 中的容器完全不同，但在功能上，tuple 是对容器的有效补充，因为所有的容器都只能组合相同类型的元素，但tuple 可以组合任意不同类型的元素。在使用上，可以用std::make_tuple()来构造 tuple 对象，可以用std::get()来获取 tuple 对象的某个元素，注意std::get()返回的是 tuple 对象中某个元素的索引，因此是可以用作左值的！此外，也可以用std::tie()打包一组变量来作为左值接受 tuple 对象的赋值。 tuple 的底层原理大概是一个层层继承的类，详情可以参考这篇文章，写的非常透彻。 pair 可以看作是把 tuple 的 size 限制为 2 的一个特例，pair 只能把一对儿元素组合到一起。在使用上，可以用std::make_pair()来直接构建 pair 对象，可以用std::get\u003c0\u003e()和std::get\u003c1\u003e()来分别获取 pair 对象的两个元素，但更方便的做法是直接访问 pair 类型的两个数据成员pair对象.first和pair对象.second来访问元素 reference: [1]. https://zhuanlan.zhihu.com/p/542115773 ","date":"2023-07-16","objectID":"/posts/datastructrue/:1:17","tags":["draft"],"title":"C++ STL Containers","uri":"/posts/datastructrue/"},{"categories":["Algorithm"],"content":"Runebook www.doc4dev.com ","date":"2023-07-16","objectID":"/posts/treenode/:0:0","tags":["draft"],"title":"TreeNode 二叉树","uri":"/posts/treenode/"},{"categories":["Algorithm"],"content":"深度优先遍历 前序遍历：中左右 5 4 1 2 6 7 8 中序遍历：左中右 1 4 2 5 7 6 8 后序遍历：左右中 1 2 4 7 8 6 5 二叉树的定义 struct TreeNode { int val; TreeNode *left; TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) {} }; ","date":"2023-07-16","objectID":"/posts/treenode/:1:0","tags":["draft"],"title":"TreeNode 二叉树","uri":"/posts/treenode/"},{"categories":["Algorithm"],"content":"前序遍历 递归法 class Solution { public: void traversal(TreeNode* cur, vector\u003cint\u003e\u0026 vec) { if (cur == nullptr) return; vec.push_back(cur-\u003eval); traversal(root-\u003eleft, vec); traversal(root-\u003eright, vec); } vector\u003cint\u003e preorderTraversal(TreeNode* root) { vector\u003cint\u003e res; traversal(root, vec); return res; } }; 迭代法 class Solution { public: vector\u003cint\u003e preorderTraversal(TreeNode* root) { stack\u003cTreeNode*\u003e st; vector\u003cint\u003e res; if (root == nullptr) return res; st.push(root); while (!st.empty()) { TreeNode* node = st.top(); st.pop(); res.push_back(node-\u003eval); if (node-\u003eright) st.push(node-\u003eright); if (node-\u003eleft) st.push(node-\u003eleft); } return res; } }; ","date":"2023-07-16","objectID":"/posts/treenode/:1:1","tags":["draft"],"title":"TreeNode 二叉树","uri":"/posts/treenode/"},{"categories":["Algorithm"],"content":"中序遍历 递归法 class Solution { public: void traversal(TreeNode* cur, vector\u003cint\u003e\u0026 vec) { if (cur == nullptr) return; traversal(root-\u003eleft, vec); vec.push_back(cur-\u003eval); traversal(root-\u003eright, vec); } vector\u003cint\u003e inorderTraversal(TreeNode* root) { vector\u003cint\u003e res; traversal(root, vec); return res; } }; 迭代法 // 中序遍历 class Solution { public: vector\u003cint\u003e inorderTraversal(TreeNode* root) { stack\u003cTreeNode*\u003e st; vector\u003cint\u003e res; if (root == nullptr) return; TreeNode* cur = root; while (!cur || !st.empty()) { if (cur != nullptr) { st.push(cur); cur = cur-\u003eleft; // 左 } else { cur = st.top(); st.pop(); res.push_back(cur-\u003eval); cur = cur-\u003eright; } } return res; } }; ","date":"2023-07-16","objectID":"/posts/treenode/:1:2","tags":["draft"],"title":"TreeNode 二叉树","uri":"/posts/treenode/"},{"categories":["Algorithm"],"content":"后序遍历 递归法 class Solution { public: void traversal(TreeNode* cur, vector\u003cint\u003e\u0026 vec) { if (cur == nullptr) return; traversal(root-\u003eleft, vec); traversal(root-\u003eright, vec); vec.push_back(cur-\u003eval); } vector\u003cint\u003e postorderTraversal(TreeNode* root) { vector\u003cint\u003e res; traversal(root, vec); return res; } }; 迭代法 class Solution { public: vector\u003cint\u003e postorderTraversal(TreeNode* root) { vector\u003cint\u003e res; if (!root) return res; stack\u003cTreeNode*\u003e st; st.push(root); while (!st.empty()) { TreeNode* node = st.top(); st.pop(); res.push(node-\u003eval); if (node-\u003eleft) st.push(node-\u003eleft); if (node-\u003eright) st.push(node-\u003eright); } reverse(res.begin(), res.end()); return res; } }; ","date":"2023-07-16","objectID":"/posts/treenode/:1:3","tags":["draft"],"title":"TreeNode 二叉树","uri":"/posts/treenode/"},{"categories":["Algorithm"],"content":"二叉树的统一迭代法 迭代法前序遍历 // 中左右 class Solution { public: vector\u003cint\u003e preorderTraversal(TreeNode* root) { vector\u003cint\u003e res; stack\u003cTreeNode*\u003e st; if (root) st.push(root); while (!st.empty()) { TreeNode* node = st.top(); if (node) { st.pop(); if (node-\u003eright) st.push(node-\u003eright); if (node-\u003eleft) st.push(node-\u003eleft); st.push(node); st.push(nullptr); } else { st.pop(); node = st.top(); st.pop(); res.push_back(node-\u003eval); } } return res; } }; 迭代法中序遍历 //左中右 class Solution { public: vector\u003cint\u003e inorderTraversal(TreeNode* root) { vector\u003cint\u003e res; stack\u003cTreeNode*\u003e st; if (root != nullptr) st.push(root); while(!st.empty()) { TreeNode* node = st.top(); if (node != nullptr) { st.pop(); //将该节点弹出，避免重复操作 if (node-\u003eright) st.push(node-\u003eright); st.push(node); st.push(nullptr); if (node-\u003eleft) st.push(node-\u003eleft); } else { st.pop(); node = st.top(); st.pop(); res.push_back(node-\u003eval); } } return res; } }; 迭代法后序遍历 // 左右中 class Solution { public: vector\u003cint\u003e postorderTraversal(TreeNode* root) { vector\u003cint\u003e res; stack\u003cTreeNode*\u003e st; if (root) st.push(root); while (!st.empty()) { TreeNode* node = st.top(); if (node) { st.pop(); st.push(node); st.push(nullptr); if (node-\u003eright) st.push(node-\u003eright); if (node-\u003eleft) st.push(node-\u003eleft); } else { st.pop(); node = st.top(); st.pop(); res.push_back(node-\u003eval); } } return res; } }; ","date":"2023-07-16","objectID":"/posts/treenode/:2:0","tags":["draft"],"title":"TreeNode 二叉树","uri":"/posts/treenode/"},{"categories":["Algorithm"],"content":"广度优先遍历 (层序遍历) 递归法 class Solution { public: vector\u003cvector\u003cint\u003e\u003e levelOrder(TreeNode* root) { queue\u003cTreeNode*\u003e que; if (root) que.push(root); vector\u003cvector\u003cint\u003e\u003e ans; while (!que.empty()) { int size = que.size(); vector\u003cint\u003e vec; for (int i = 0; i \u003c size; ++i) { TreeNode* node = que.front(); que.pop(); vec.push_back(node-\u003eval); if (node-\u003eleft) que.push(node-\u003eleft); if (node-\u003eright) que.push(node-\u003eright); } ans.push_back(vec); } return ans; } }; 迭代法 class Solution { public: void order(TreeNode* cur, vector\u003cvector\u003cint\u003e\u003e\u0026 res, int depth) { if (cur == nullptr) return; if (res.size() == depth) res.push_back(vector\u003cint\u003e()); res[depth].push_back(cur-\u003eval); order(cur-\u003eleft, res, depth + 1); order(cur-\u003eright, res, depth + 1); } vector\u003cvector\u003cint\u003e\u003e levelOrder(TreeNode* root) { vector\u003cvector\u003cint\u003e\u003e res; int depth = 0; order(root, res, depth); return res; } }; ","date":"2023-07-16","objectID":"/posts/treenode/:3:0","tags":["draft"],"title":"TreeNode 二叉树","uri":"/posts/treenode/"},{"categories":["Algorithm"],"content":"Sorting Algotithms Collection 排序算法合集 ","date":"2023-07-16","objectID":"/posts/sortingalgo/:1:0","tags":["算法"],"title":"排序算法","uri":"/posts/sortingalgo/"},{"categories":["Algorithm"],"content":"0. 排序算法 排序算法在所有计算机算法，乃至整个计算机领域中，都占据着非常重要的地位。基础算法是软件的核心，而查找算法和排序算法则是计算机基础算法的核心。 排序算法是计算机科学中用于对元素序列进行排序的一系列算法。排序算法在实际应用中非常广泛，比如数据库索引、文件排序、数据检索等。 0.1 定义： 排序算法是一种将一组数据元素重新排列成有序序列的算法。这个“有序”可以是升序或降序。 0.2 作用： 排序算法在许多领域都有广泛的应用，包括但不限于： •数据分析：对数据进行排序可以更容易地识别数据中的模式和趋势。 •数据库管理：数据库查询经常需要对结果进行排序。 •搜索算法：排序算法可以用于优化搜索过程，如二分搜索依赖于排序好的列表。 •算法实现：许多算法的实现依赖于排序，如归并排序是归并算法的基础。 0.3 分类： 按算法的时间复杂度进行分类： O(n^2) 算法：冒泡排序、选择排序、插入排序 O(n log n) 算法：快速排序、归并排序、堆排序 O(n) 算法：计数排序、桶排序、基数排序 按照空间复杂度（内存使用量）进行分类： 原地排序算法（空间复杂度为 O(1)）：冒泡排序、选择排序、插入排序、堆排序 非原地排序算法（空间复杂度大于 O(1)）：归并排序、计数排序 按照实现排序的方法进行分类： 插入类排序：直接插入排序、二分插入排序、Shell排序（希尔排序） 交换类排序：冒泡排序、快速排序、随机快速排序 选择类排序：简单选择排序、堆排序 归并类排序：归并排序 分配类排序：计数排序、桶排序、基数排序 混合类排序：鸡尾酒排序（冒泡排序的变体，双向冒泡） 其他排序：拓扑排序、循环排序 ","date":"2023-07-16","objectID":"/posts/sortingalgo/:1:1","tags":["算法"],"title":"排序算法","uri":"/posts/sortingalgo/"},{"categories":["Algorithm"],"content":"1. Quick Sort 快速排序 快速排序（Quick Sort）是一种高效的排序算法，由C. A. R. Hoare在1960年提出。它采用分治法的策略，通过选择一个“基准”元素，将数组分为两部分：一部分包含所有小于基准的元素，另一部分包含所有大于基准的元素。然后递归地对这两部分进行快速排序。 1.1 算法步骤 •选择基准：从数组中选择一个元素作为基准。 •分区操作：重新排列数组，所有比基准小的元素放在基准的左边，所有比基准大的元素放在基准的右边。 •递归排序：递归地对基准左边和右边的子数组进行快速排序。 •完成：递归到基情况（数组只有一个或零个元素）时，排序完成。 1.2 算法图解 快速排序通过选择一个基准值，将数组分为两部分，然后递归地对这两部分进行排序。 BP Network 1.3 算法特点 •效率：在大多数情况下，快速排序的平均时间复杂度为O(n log n)。 •不稳定性：快速排序是不稳定的排序算法，因为在分区过程中可能会改变相同元素的相对顺序。 •时间复杂度：平均情况下为O(n log n)，但在最坏情况下（例如，数组已经排序或完全逆序）为O(n^2)。 •空间复杂度：O(log n)，快速排序是原地排序算法，但递归性质导致它需要O(log n)的额外栈空间。 1.4 代码实现 void quick_sort(vector\u003cint\u003e\u0026 nums, int l, int r) { if (l \u003e= r) { return; } int first = l, last = r; while (l \u003c r) { while (l \u003c r \u0026\u0026 nums[l] \u003c nums[first]) { l++; } while (l \u003c r \u0026\u0026 nums[r] \u003e nums[first]) { r--; } swap(nums[l], nums[r]); } swap(nums[first], nums[r]); quick_sort(nums, first, r - 1); quick_sort(nums, r + 1, last); } def quick_sort(arr, low, high): if low \u003c high: # 分区操作 pivot_index = partition(arr, low, high) # 递归地对基准左边和右边的子数组进行快速排序 quick_sort(arr, low, pivot_index - 1) quick_sort(arr, pivot_index + 1, high) def partition(arr, low, high): # 选择基准（这里以最右侧的元素作为基准） pivot = arr[high] i = low - 1 for j in range(low, high): if arr[j] \u003c pivot: i += 1 arr[i], arr[j] = arr[j], arr[i] # 将基准放到正确的位置 arr[i + 1], arr[high] = arr[high], arr[i + 1] return i + 1 # 示例 arr = [10, 7, 8, 9, 1, 5] quick_sort(arr, 0, len(arr) - 1) print(\"Sorted array is:\", arr) ","date":"2023-07-16","objectID":"/posts/sortingalgo/:1:2","tags":["算法"],"title":"排序算法","uri":"/posts/sortingalgo/"},{"categories":["Algorithm"],"content":"2. Merge Sort 归并排序 归并排序（Merge Sort）是一种分治算法，由约翰·冯·诺伊曼在1945年发明。它通过递归地将数组分成两半，然后对每一半进行排序，最后将排序好的两半合并在一起，从而完成整个数组的排序。 2.1 算法步骤 •分割：将待排序的数组分成两半，直到每个子数组只包含一个元素。 •递归排序：递归地对每个子数组进行归并排序。 •合并：将排序好的两个子数组合并成一个有序数组。 2.2 算法图解 归并排序通过递归地将数组分成更小的部分，然后合并这些部分，直到整个数组被排序。 BP Network BP Network 2.3 算法特点 •稳定性：归并排序是一种稳定的排序算法，因为它不会改变相同元素的相对顺序。 •时间复杂度：无论最好、最坏还是平均情况下，时间复杂度都是O(n log n)。 •空间复杂度：O(n)，归并排序需要使用到额外的空间来存储临时的合并结果。 2.4 代码实现 void print_arr(vector\u003cint\u003e\u0026 nums) { for (auto num:nums) { std::cout \u003c\u003c num \u003c\u003c \" \"; } std::cout \u003c\u003c std::endl; } void merge(vector\u003cint\u003e\u0026 nums, int low, int mid, int high) { vector\u003cint\u003e tmp (high - low + 1); int i = low; int j = mid + 1; int k = 0; while (i \u003c= mid \u0026\u0026 j \u003c= high) { if (nums[i] \u003c nums[j]) { tmp[k++] = nums[i++]; } else { tmp[k++] = nums[j++]; } } while (i \u003c= mid) { tmp[k++] = nums[i++]; } while (j \u003c= high) { tmp[k++] = nums[j++]; } for (int i = 0; i \u003c tmp.size(); ++i) { nums[low+i] = tmp[i]; } } void merge_sort(vector\u003cint\u003e\u0026 nums, int l, int r) { if (l == r) return; int mid = l + (r - l) / 2; merge_sort(nums, l, mid); merge_sort(nums, mid + 1, r); merge(nums, l, mid, r); } int main() { vector\u003cint\u003e arr = {64, 34, 25, 12, 22, 11, 90}; print_arr(arr); merge_sort(arr, 0, arr.size() - 1); print_arr(arr); return 0; } Python def merge_sort(arr): if len(arr) \u003e 1: mid = len(arr) // 2 # 找到中间位置 L = arr[:mid] # 左侧序列 R = arr[mid:] # 右侧序列 merge_sort(L) # 递归对左侧序列进行排序 merge_sort(R) # 递归对右侧序列进行排序 # 合并两个排序好的序列 i = j = k = 0 # 按顺序合并元素直到一个子数组为空 while i \u003c len(L) and j \u003c len(R): if L[i] \u003c R[j]: arr[k] = L[i] i += 1 else: arr[k] = R[j] j += 1 k += 1 # 将剩余的元素移到数组的末尾 while i \u003c len(L): arr[k] = L[i] i += 1 k += 1 while j \u003c len(R): arr[k] = R[j] j += 1 k += 1 return arr # 示例 arr = [38, 27, 43, 3, 9, 82, 10] sorted_arr = merge_sort(arr) print(\"Sorted array is:\", sorted_arr) 2.5 适用场景 归并排序由于其稳定性和时间复杂度，适用于以下情况： •大数据集：归并排序适合处理大型数据集，因为它的性能不会受到数据规模的影响。 •稳定性需求：当排序过程中保持元素的相对顺序很重要时，归并排序是一个合适的选择。 •外存排序：归并排序适合于磁盘等外存上的排序，因为它可以有效地减少读取和写入的次数。 •内存限制：尽管归并排序需要额外的内存空间，但通过优化可以实现为原地排序，从而减少内存使用。 ","date":"2023-07-16","objectID":"/posts/sortingalgo/:1:3","tags":["算法"],"title":"排序算法","uri":"/posts/sortingalgo/"},{"categories":["Algorithm"],"content":"3. Insertion Sort 插入排序 插入排序（Insertion Sort）是一种简单直观的排序算法，它通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。 3.1 算法步骤 •开始：假设序列中第一个元素已经排序； •插入：取下一个未排序的元素，与已排序序列中的元素从后向前比较； •移动：如果已排序序列中的元素比当前元素大，则将该元素移到下一位； •插入：将当前元素放到合适的位置； •重复：对序列中剩余的每个元素重复步骤2-4。 3.2 算法图解 插入排序通过将每个元素插入到前面已排序序列中的适当位置，从而逐步构建完整的有序序列。 BP Network 动态示意图: 插入排序示意图 3.3 算法特点 •简单：插入排序的原理和实现都很简单，容易理解和编程实现。 •稳定：插入排序是一种稳定的排序算法，因为它不会改变相同元素的相对顺序。 •时间复杂度：在最好的情况下（即数列已经是排序状态），时间复杂度为O(n)；在最坏和平均情况下，时间复杂度为O(n^2)。 •空间复杂度：O(1)，插入排序是原地排序，不需要额外的存储空间。 3.4 代码实现 def insertion_sort(arr): # 从第二个元素开始遍历，因为第一个元素可以认为已经排序 for i in range(1, len(arr)): key = arr[i] # 从当前元素的前一个元素开始，向前遍历已排序的元素 j = i - 1 # 将大于key的元素向后移动 while j \u003e= 0 and key \u003c arr[j]: arr[j + 1] = arr[j] j -= 1 # 将key放到正确的位置 arr[j + 1] = key return arr # 示例 arr = [12, 11, 13, 5, 6] sorted_arr = insertion_sort(arr) print(\"Sorted array is:\", sorted_arr) void insertion_sort(vector\u003cint\u003e\u0026 nums) { int n = nums.size(); for (int i = 1; i \u003c n; ++i) { int key = nums[i]; int j = i - 1; while (j \u003e= 0 \u0026\u0026 nums[j] \u003e key) { nums[j+1] = nums[j]; j--; } nums[j+1] = key; } } 3.5 适用场景 插入排序虽然在最坏情况下效率不高，但在以下情况下可能很有用： •数据规模较小：对于小型数据集，插入排序的性能是可接受的。 •初始数据部分有序：如果数据集已经部分有序，插入排序的性能会接近线性。 •教学目的：由于其简单性，插入排序常被用作教学示例，帮助初学者理解算法和排序的基本概念。 •在线排序：插入排序适合在线排序，即数据逐个到来时进行排序。 ","date":"2023-07-16","objectID":"/posts/sortingalgo/:1:4","tags":["算法"],"title":"排序算法","uri":"/posts/sortingalgo/"},{"categories":["Algorithm"],"content":"4. 希尔排序(Shell Sorting) 希尔排序是插入排序的一种更高效的改进版本，也称为缩小增量排序。它通过引入一个“增量”的概念来优化插入排序，允许进行较远距离的元素交换，从而减少比较和移动的次数。 4.1 算法步骤 •开始：选择一个增量序列，它可以是固定的，也可以是动态生成的。 •排序：使用插入排序对增量序列定义的子序列进行排序。 •缩小：减小增量序列的值，重复上一步，直到增量为1。 •完成：当增量为1时，整个数组将被排序。 4.2 算法图解 希尔排序通过将原始数据分成多个子序列，每个子序列的元素之间相隔特定的增量。然后对每个子序列进行插入排序，随着增量的减小，子序列的间隔也逐渐减小，直到增量为1，此时整个数组已经接近有序，最终进行一次普通的插入排序即可完成排序。 BP Network 4.3 算法特点 •效率：希尔排序的效率依赖于增量序列的选择，通常比普通插入排序要快。 •稳定性：希尔排序是不稳定的排序算法，因为它在插入排序过程中可能会改变相同元素的相对顺序。 •时间复杂度：希尔排序的平均时间复杂度为O(n^1.5)到O(n^2)，这取决于增量序列的选择。在最好的情况下，时间复杂度可以接近O(n log n)。 •空间复杂度：O(1)，希尔排序是原地排序，不需要额外的存储空间。 4.4 代码实现 void print_arr(vector\u003cint\u003e\u0026 nums) { for (auto num:nums) { std::cout \u003c\u003c num \u003c\u003c \" \"; } std::cout \u003c\u003c std::endl; } void shell_sort(vector\u003cint\u003e\u0026 nums) { int n = nums.size(); int len = n / 2; while (len \u003e 0) { for (int i = len; i \u003c n; i++) { int j = i; int temp = nums[i]; while (j - len \u003e= 0 \u0026\u0026 temp \u003c nums[j - len]) { nums[j] = nums[j - len]; j -= len; } nums[j] = temp; } len = len / 2; } return; } int main() { vector\u003cint\u003e arr = {64, 34, 25, 12, 22, 11, 90}; print_arr(arr); shell_sort(arr); print_arr(arr); return 0; } def shell_sort(arr): n = len(arr) gap = n // 2 # 初始增量 while gap \u003e 0: for i in range(gap, n): temp = arr[i] j = i # 对子序列进行插入排序 while j \u003e= gap and arr[j - gap] \u003e temp: arr[j] = arr[j - gap] j -= gap arr[j] = temp gap //= 2 # 减小增量 return arr # 示例 arr = [12, 11, 13, 5, 6, 7, 10, 9] sorted_arr = shell_sort(arr) print(\"Sorted array is:\", sorted_arr) 4.5 适用场景 希尔排序由于其较好的性能，适用于以下情况： •中等数据规模：对于数据规模不是非常大的情况，希尔排序可以提供比普通插入排序更好的性能。 •初始数据部分有序：如果数据部分有序，希尔排序的性能会有所提升。 •增量序列选择：通过精心选择增量序列，希尔排序可以接近于O(n log n)的时间复杂度，从而在某些情况下比快速排序等算法更高效。 ","date":"2023-07-16","objectID":"/posts/sortingalgo/:1:5","tags":["算法"],"title":"排序算法","uri":"/posts/sortingalgo/"},{"categories":["Algorithm"],"content":"5. Bubble Sort 冒泡排序 冒泡排序（Bubble Sort）是一种简单的排序算法，它重复地遍历要排序的数列，一次比较两个元素，如果它们的顺序错误就把它们交换过来。遍历数列的工作是重复进行直到没有再需要交换，也就是说该数列已经排序完成。 5.1 算法步骤 •开始：从数列的第一个元素开始，比较相邻的两个元素。 •比较与交换：如果左边的元素大于右边的元素，就交换它们两个。 •移动：移动到下一个元素对，重复步骤2。 •重复：继续这个过程，直到最后一次交换发生，此时数列的最后一个元素是最大的，已经被“冒泡”到它应该在的位置。 •减少比较次数：由于最大的元素已经在它应在的位置，所以下一次遍历可以减少一个比较（即从第一个元素开始，不需要再和它比较）。 5.2 算法图解 冒泡排序从头开始，依次比较数组中相邻的2个元素，如果后面的数比前面的数大，则交换2个数，否则不交换。每进行一轮比较，都会把数组中最大的元素放到最后面。 BP Network 5.3 算法特点 简单：冒泡排序的原理简单，容易实现。 稳定：冒泡排序是一种稳定的排序算法，因为它不会改变相同元素之间的顺序。 时间复杂度：平均和最坏时间复杂度均为O(n^2)，其中n是数列的长度。在最好的情况下（即数列已经是排序状态），时间复杂度为O(n)。 空间复杂度：O(1)，因为冒泡排序是原地排序，不需要额外的存储空间。 5.4 代码实现 def bubble_sort(arr): n = len(arr) swapped = False for i in range(n): # 由于每次最大的元素都会被放到它应在的位置，所以可以减少比较次数 swapped = False for j in range(0, n-i-1): # 相邻元素两两比较 if arr[j] \u003e arr[j+1]: # 发现元素顺序错误，交换它们 arr[j], arr[j+1] = arr[j+1], arr[j] swapped = True if not flag: break return arr # 示例 arr = [64, 34, 25, 12, 22, 11, 90] sorted_arr = bubble_sort(arr) print(\"Sorted array is:\", sorted_arr) void print_arr(vector\u003cint\u003e\u0026 nums) { for (auto num:nums) { std::cout \u003c\u003c num \u003c\u003c \" \"; } std::cout \u003c\u003c std::endl; } void bubble_sort(vector\u003cint\u003e\u0026 nums) { int n = nums.size(); bool swapped = false; for (int i = 0; i \u003c n; ++i) { swapped = false; for (int j = 0; j \u003c n - i - 1; ++j) { if (nums[j] \u003e nums[j+1]) { swap(nums[j], nums[j+1]); swapped = true; } } if (!swapped) { // 一旦没有交换操作，说明已经完成排序，可以跳出循环 break; } } } int main() { vector\u003cint\u003e arr = {64, 34, 25, 12, 22, 11, 90}; print_arr(arr); bubble_sort(arr); print_arr(arr); // 11 12 22 25 34 64 90 return 0; } 5.5 使用场景 冒泡排序由于其性能原因，通常不适用于大型数据集的排序。然而，它在以下情况下可能很有用： 数据规模较小：当数据集很小或者几乎已经排序时，冒泡排序的性能是可接受的。 教学目的：由于其简单性，冒泡排序常被用作教学示例，帮助初学者理解算法和排序的基本概念。 需要稳定性：在某些特定情况下，保持元素的相对顺序很重要，冒泡排序可以满足这种稳定性需求。 ","date":"2023-07-16","objectID":"/posts/sortingalgo/:1:6","tags":["算法"],"title":"排序算法","uri":"/posts/sortingalgo/"},{"categories":["Algorithm"],"content":"6. 选择排序 选择排序是一种简单直观的排序算法，它的工作原理是每一次从待排序的数据元素中选出最小（或最大）的一个元素，存放在序列的起始位置，直到全部待排序的数据元素排完。 6.1 算法步骤 •开始：在未排序序列中找到最小（大）元素； •交换：将找到的最小（大）元素与序列的第0个元素交换； •移动：从序列的第1个元素开始，继续寻找最小（大）元素，然后与序列的第1个元素交换； •重复：重复步骤2和3，直到序列的第n-1个元素（其中n是序列的长度）。 6.2 算法图解 选择排序通过重复扫描数组，找到最小的元素，然后将其与当前位置的元素交换。这个过程会一直进行，直到整个数组被排序。 BP Network 6.3 算法特点 •简单：选择排序的实现相对简单，容易理解和编程实现。 •不稳定：选择排序在交换过程中可能会改变相同元素的顺序，因此它不是稳定的排序算法。 •时间复杂度：无论最好、最差还是平均情况下，时间复杂度都是O(n^2)，其中n是数列的长度。 •空间复杂度：O(1)，选择排序是原地排序，不需要额外的存储空间。 6.4 代码实现 def selection_sort(arr): n = len(arr) for i in range(n-1): # 找到最小元素的索引 min_idx = i for j in range(i+1, n): if arr[j] \u003c arr[min_idx]: min_idx = j # 将找到的最小元素交换到序列的前面 arr[i], arr[min_idx] = arr[min_idx], arr[i] return arr # 示例 arr = [64, 34, 25, 12, 22, 11, 90] sorted_arr = selection_sort(arr) print(\"Sorted array is:\", sorted_arr) void print_arr(vector\u003cint\u003e\u0026 nums) { for (auto num:nums) { std::cout \u003c\u003c num \u003c\u003c \" \"; } std::cout \u003c\u003c std::endl; } void selection_sort(vector\u003cint\u003e\u0026 nums) { int mid_idx; int n = nums.size(); for (int i = 0; i \u003c n - 1; ++i) { mid_idx = i; for (int j = i + 1; j \u003c n; ++j) { if (nums[j] \u003c nums[mid_idx]) { mid_idx = j; } } swap(nums[mid_idx], nums[i]); } } int main() { vector\u003cint\u003e arr = {64, 34, 25, 12, 22, 11, 90}; print_arr(arr); selection_sort(arr); print_arr(arr); return 0; } 6.5 适用场景 选择排序的性能相对较差，因此它不适用于大型数据集的排序。然而，在以下情况下，选择排序可能比较适用： •数据规模较小：当数据集较小时，选择排序的简单性可能使其成为一个合适的选择。 •教学目的：由于其实现简单，选择排序常被用作教学示例，帮助初学者理解算法和排序的基本概念。 •排序过程中的特定操作：在某些特定的应用场景中，如果排序过程中需要频繁地访问未排序部分的元素，选择排序可能比其他算法更合适。。 ","date":"2023-07-16","objectID":"/posts/sortingalgo/:1:7","tags":["算法"],"title":"排序算法","uri":"/posts/sortingalgo/"},{"categories":["Algorithm"],"content":"6. 堆排序 ","date":"2023-07-16","objectID":"/posts/sortingalgo/:1:8","tags":["算法"],"title":"排序算法","uri":"/posts/sortingalgo/"},{"categories":["Algorithm"],"content":"7. 计数排序 ","date":"2023-07-16","objectID":"/posts/sortingalgo/:1:9","tags":["算法"],"title":"排序算法","uri":"/posts/sortingalgo/"},{"categories":["Algorithm"],"content":"8. 桶排序 ","date":"2023-07-16","objectID":"/posts/sortingalgo/:1:10","tags":["算法"],"title":"排序算法","uri":"/posts/sortingalgo/"},{"categories":["Algorithm"],"content":"Reference: [1]. https://mp.weixin.qq.com/s/P8MmmMc4vB_I9tnK3towLQ ","date":"2023-07-16","objectID":"/posts/sortingalgo/:2:0","tags":["算法"],"title":"排序算法","uri":"/posts/sortingalgo/"},{"categories":["Algorithm"],"content":"KnapSack 背包问题 Definiton 定义 背包问题是一种组合优化的NP完全问题:有N个物品和容量为W的背包，每个物品都有自己的体积w和价值v，求拿哪些物品可以使得背包所装下的物品的总价值最大。如果限定每种物品只能选择0个或者1个，则称问题为0-1背包问题;如果不限定每种物品的数量，则问题称为无界背包问题和或者完全背包问题。 0-1 背包问题 以 0-1 背包问题为例。我们可以定义一个二维数组 dp 存储最大价值，其中 dp[i][j] 表示前 i 件物品体积不超过 j 的情况下能达到的最大价值。在我们遍历到第 i 件物品时，在当前背包总容量为 j 的情况下，如果我们不将物品 i 放入背包，那么 dp[i][j] = dp[i-1][j]，即前 i 个物品的最大价值等于只取前 i-1 个物品时的最大价值；如果我们将物品 i 放入背包，假设第 i 件物品体积为 w，价值为 v，那么我们得到 dp[i][j] = dp[i-1][j-w] + v。我们只需在遍历过程中对这两种情况取最大值即可，总时间复杂度和空间复杂度都为 O(NW)。 int knapsack(vector\u003cint\u003e\u0026 weights, vector\u003cint\u003e\u0026 values, int N, int W) { vector\u003cvector\u003cint\u003e\u003e dp(N+1, vector\u003cint\u003e (W+1, 0)); for (int i = 1; i \u003c=N; ++i) { int w = weight[i-1], v = values[i-1]; for (int j = 1; j \u003c= W; ++j) { if (j \u003e= w) { dp[i][j] = max(dp[i-1][j], dp[i-1][j-w] + v); } else { dp[i][j] = dp[i-1][j]; } } } return dp[N][W]; } 空间压缩: int knapsack(vector\u003cint\u003e\u0026 weights, vector\u003cint\u003e\u0026 values, int N, int W) { vector\u003cint\u003e dp(W+1, 0); for (int i = 1; i \u003c= N; ++i) { int w = weights[i-1], v = values[i-1]; for (j = W; j \u003e= w; ++j) { dp[j] = max(dp[j], dp[j-w] + v); } } return dp[W]; } 完全背包问题 完全背包问题中，一个物品可以拿多次。对于拿多个物品的情况，我们只需考虑 dp[2][3] 即可，即 dp[2][5] = max(dp[1][5], dp[2][3] + 3)。这样，我们 就得到了完全背包问题的状态转移方程：dp[i][j] = max(dp[i-1][j], dp[i][j-w] + v)，其与 0-1背包问题的差别仅仅是把状态转移方程中的第二个 i-1 变成了 i。 int knapsack(vector\u003cint\u003e\u0026 weights, vector\u003cint\u003e\u0026 values, int N, int W) { vector\u003cvector\u003cint\u003e\u003e dp(N+1, vector\u003cint\u003e(W+1, 0)); for (int i = 1; i \u003c= N; ++i) { int w = weights[i-1], v = values[i-1]; for (int j = 1; j \u003c= W; ++j) { if (j \u003e= w) { dp[i][j] = max(dp[i-1][j], dp[i][j-w] + v); } else { dp[i][j] = dp[i-1][j]; } } } return dp[N][W]; } 空间压缩: int knapsack(vector\u003cint\u003e\u0026 weights, vector\u003cint\u003e\u0026 values, int N, int W) { vector\u003cint\u003e dp(W+1, 0); for (int i = 1; i \u003c= N; ++i) { int w = weights[i-1], v = values[i-1]; for (int j = w; j \u003c= W; ++j) { dp[j] = max(dp[j], dp[j-w] + v); } } return dp[W]; } ref: dp: https://juejin.cn/post/6844903993429196813 knapsack problem: https://blog.csdn.net/qq_38410730/article/details/81667885 完全背包问题: https://www.cnblogs.com/darkerg/p/15464987.html ","date":"2023-07-16","objectID":"/posts/knapsack/:0:1","tags":["draft"],"title":"KnapSack Problem 背包问题","uri":"/posts/knapsack/"},{"categories":["ML"],"content":"最大似然估计（Maximum likelihood estimation, 简称MLE）和最大后验概率估计（Maximum a posteriori estimation, 简称MAP）是很常用的两种参数估计方法，如果不理解这两种方法的思路，很容易弄混它们。下文将详细说明MLE和MAP的思路与区别。 但别急，我们先从概率和统计的区别讲起。 概率和统计是一个东西吗？ 概率(probabilty)和统计(statistics)看似两个相近的概念，其实研究的问题刚好相反。 概率研究的问题是，已知一个模型和参数，怎么去预测这个模型产生的结果的特性(例如均值，方差，协方差等等)。 举个例子，我想研究怎么养猪(模型是猪)，我选好了想养的品种、喂养方式、猪棚的设计等等(选择参数)，我想知道我养出来的猪大概能有多肥，肉质怎么样(预测结果)。 统计研究的问题则相反。统计是，有一堆数据，要利用这堆数据去预测模型和参数。仍以猪为例。现在我买到了一堆肉，通过观察和判断，我确定这是猪肉(这就确定了模型。在实际研究中，也是通过观察数据推测模型是／像高斯分布的、指数分布的、拉普拉斯分布的等等)，然后，可以进一步研究，判定这猪的品种、这是圈养猪还是跑山猪还是网易猪，等等(推测模型参数)。 一句话总结：概率是已知模型和参数，推数据。统计是已知数据，推模型和参数。 显然，本文解释的MLE和MAP都是统计领域的问题。它们都是用来推测参数的方法。为什么会存在着两种不同方法呢？ 这需要理解贝叶斯思想。我们来看看贝叶斯公式。 贝叶斯公式到底在说什么？ 学习机器学习和模式识别的人一定都听过贝叶斯公式(Bayes’ Theorem)： 式[1] $P(A|B)=\\frac{P(B|A)P(A)}{P(B)}$ 贝叶斯公式看起来很简单，无非是倒了倒条件概率和联合概率的公式。 把B展开，可以写成: 式[2] $P(A|B)=\\frac{P(B|A)P(A)}{P(B|A)P(A) + P(B|\\sim A)P(\\sim A)}$ 这个式子就很有意思了。 想想这个情况。一辆汽车(或者电瓶车)的警报响了，你通常是什么反应？有小偷？撞车了？ 不。。 你通常什么反应都没有。因为汽车警报响一响实在是太正常了！每天都要发生好多次。本来，汽车警报设置的功能是，出现了异常情况，需要人关注。然而，由于虚警实在是太多，人们渐渐不相信警报的功能了。 贝叶斯公式就是在描述，你有多大把握能相信一件证据？（how much you can trust the evidence） 我们假设响警报的目的就是想说汽车被砸了。把$A$计作“汽车被砸了”，$B$计作“警报响了”，带进贝叶斯公式里看。我们想求等式左边发生$A∣B$的概率，这是在说警报响了，汽车也确实被砸了。汽车被砸**引起(trigger)**警报响，即B∣A。但是，也有可能是汽车被小孩子皮球踢了一下、被行人碰了一下等其他原因(统统计作$\\sim A$)，其他原因引起汽车警报响了，即 $B|\\sim A$。那么，现在突然听见警报响了，这时汽车已经被砸了的概率是多少呢(这即是说，警报响这个证据有了，多大把握能相信它确实是在报警说汽车被砸了)想一想，应当这样来计算。用警报响起、汽车也被砸了这事件的数量，除以响警报事件的数量(这即[式1])。进一步展开，即警报响起、汽车也被砸了的事件的数量，除以警报响起、汽车被砸了的事件数量加上警报响起、汽车没被砸的事件数量(这即[式2])。 再思考[式2]。想让$P(A∣B)=1$，即警报响了，汽车一定被砸了，该怎么做呢？让$P(B|\\sim A)P(\\sim A) = 0$即 可 。很容易想清楚，假若让$P(\\sim A)=0$,即杜绝了汽车被球踢、被行人碰到等等其他所有情况，那自然，警报响了，只剩下一种可能——汽车被砸了。这即是提高了响警报这个证据的说服力。 **从这个角度总结贝叶斯公式：做判断的时候，要考虑所有的因素。**老板骂你，不一定是你把什么工作搞砸了，可能只是他今天出门前和太太吵了一架。 再思考[式2]。观察【式2】右边的分子，$P(B∣A)$为汽车被砸后响警报的概率。姑且认为这是1吧。但是，若$P(A)$很小，即汽车被砸的概率本身就很小，则$P(B∣A)P(A)$仍然很小，即【式2】右边分子仍然很小，$P(A|B)$还是大不起来。 这里，$​P(A)$ 即是常说的先验概率，如果A的先验概率很小，就算$P(B∣A)$较大，可能A的后验概率$P(A∣B)$还是不会大(假设$P(B∣\\sim A)P(\\sim A)$不变的情况下)。 从这个角度思考贝叶斯公式：一个本来就难以发生的事情，就算出现某个证据和他强烈相关，也要谨慎。证据很可能来自别的虽然不是很相关，但发生概率较高的事情。 似然函数 似然(likelihood)这个词其实和概率(probability)是差不多的意思，Colins字典这么解释:The likelihood of something happening is how likely it is to happen. 你把likelihood换成probability，这解释也读得通。但是在统计里面，似然函数和概率函数却是两个不同的概念(其实也很相近就是了)。 对于这个函数: $$P(x|\\theta)$$ 输入有两个: $x$表示某一个具体的数据；$\\theta$表示模型的参数。 如果$\\theta$是已知确定的，$x$是变量，这个函数叫做概率函数(probability function)，它描述对于不同的样本点x，其出现概率是多少。 如果$x$是已知确定的，$\\theta$是变量，这个函数叫做似然函数(likelihood function), 它描述对于不同的模型参数，出现$x$这个样本点的概率是多少。 最大似然估计(MLE) 假设有一个造币厂生产某种硬币，现在我们拿到了一枚这种硬币，想试试这硬币是不是均匀的。即想知道抛这枚硬币，正反面出现的概率（记为$\\theta$）各是多少？ 这是一个统计问题，回想一下，解决统计问题需要什么？ 数据！ 于是我们拿这枚硬币抛了10次，得到的数据($x_0$)是：反正正正正反正正正反。我们想求的正面概率$\\theta$是模型参数，而抛硬币模型我们可以假设是二项分布。 那么，出现实验结果$x_0$(即反正正正正反正正正反)的似然函数是多少呢？ $$f(x_0 ,\\theta) = (1-\\theta)\\times\\theta\\times\\theta\\times\\theta\\times\\theta\\times(1-\\theta)\\times\\theta\\times\\theta\\times\\theta\\times(1-\\theta) = \\theta ^ 7(1 - \\theta)^3 = f(\\theta)$$ ​ 注意，这是个只关于$\\theta$的函数。而最大似然估计，顾名思义，就是要最大化这个函数。我们可以画出$f(\\theta)$的图像： 可以看出，在$\\theta = 0.7$时，似然函数取得最大值。 这样，我们已经完成了对$\\theta$的最大似然估计。即，抛10次硬币，发现7次硬币正面向上，最大似然估计认为正面向上的概率是0.7。（ummm…这非常直观合理，对吧？） 且慢，一些人可能会说，硬币一般都是均匀的啊！ 就算你做实验发现结果是“反正正正正反正正正反”，我也不信$\\theta = 0.7$。 这里就包含了贝叶斯学派的思想了——要考虑先验概率。 为此，引入了最大后验概率估计。 最大后验概率估计(MAP) 最大似然估计是求参数$\\theta$, 使似然函数$P(x_0 | \\theta)$最 大 。 最大后验概率估计则是想求$\\theta$使$P(x_0|\\theta)$ 最大。求得的$\\theta$不单单让似然函数大，不单单让似然函数大，$\\theta$自己出现的先验概率也得大。(这有点像正则化里加惩罚项的思想，不过正则化里是利用加法，而MAP里是利用乘法). MAP其实是在最大化$P(\\theta|x_0) = \\frac{P(x_0|\\theta)P(\\theta)}{P(x_0)}$，不过因为$x_0$是确定的(即投出的“反正正正正反正正正反”)，$P(x_0)$是一个已知值，所以去掉了分母$P(x_0)$(假设“投10次硬币”是一次实验，实验做了1000次，“反正正正正反正正正反”出现了n次，则$P(x_0) = n/1000$)。总之，这是一个可以由数据集得到的值）。最大化$P(\\theta | x_0)$的意义也很明确，$x_0$已经出现了，要求$\\theta$取什么值使$P(\\theta | x_0)$最大。顺带一提，$P(\\theta | x_0)$, ​即后验概率，这就是“最大后验概率估计”名字的由来。 对于投硬币的例子来看，我们认为（”先验地知道“$\\theta$取0.5的概率很大，取其他值的概率小一些。我们用一个高斯分布来具体描述我们掌握的这个先验知识，例如假设$P(\\theta)$为均值0.5，方差0.1的高斯函数，如下图： 则$P(x_0 | \\theta)$的函数图像为： 注意，此时函数取最大值时，θ \\thetaθ取值已向左偏移，不再是0.7。实际上，在$\\theta = 0.558$时函数取得了最大值。即，用最大后验概率估计，得到$\\theta = 0.558$ 最后，那要怎样才能说服一个贝叶斯派相信$\\theta = 0.7$呢？你得多做点实验。。 如果做了1000次实验，其中700次都是正面向上，这时似然函数为: 如果仍然假","date":"2023-07-16","objectID":"/posts/mleandmap/:0:0","tags":["MLE"],"title":"详解最大似然估计(MLE)、最大后验概率估计(MAP)，以及贝叶斯公式的理解","uri":"/posts/mleandmap/"},{"categories":["Memo"],"content":"Linux系统各系统文件夹下的区别 首先，usr 指 Unix System Resource，而不是User。 通常， /usr/bin下面的都是系统预装的可执行程序，会随着系统升级而改变。 /usr/local/bin目录是给用户放置自己的可执行程序的地方，推荐放在这里，不会被系统升级而覆盖同名文件。 如果两个目录下有相同的可执行程序，谁优先执行受到PATH环境变量的影响，比如我的一台服务器的PATH变量为。 echo $PATH 这里/usr/local/bin优先于/usr/bin, 一般都是如此。 /lib是内核级的, /usr/lib是系统级的, /usr/local/lib是用户级的. / - 对你的电脑来说, 有且只有一个根目录。所有的东西都是从这里开始。举个例子: 当你在终端里输入\"/home\"，你其实是在告诉电脑，先从/(根目录)开始，再进入到home目录。 /lib/ — 包含许多被/bin/和/sbin/中的程序使用的库文件。目录/usr/lib/中含有更多用于用户程序的库文件。/lib目录下放置的是/bin和/sbin目录下程序所需的库文件。/lib目录下的文件的名称遵循下面的格式： libc.so.* ld* 仅仅被/usr目录下的程序所使用的共享库不必放到/lib目录下。只有/bin和/sbin下的程序所需要的库有必要放到/lib目录下。实际上，libm.so.*类型的库文件如果被是/bin和/sbin所需要的，也可以放到/usr/lib下。 /bin/ — 用来贮存用户命令。目录 /usr/bin 也被用来贮存用户命令。 /sbin/ — 许多系统命令(例如 shutdown)的贮存位置。目录/usr/sbin中也包括了许多系统命令。 /root/ — 根用户(超级用户)的主目录。 /mnt/ — 该目录中通常包括系统引导后被挂载的文件系统的挂载点。譬如，默认的光盘挂载点是/mnt/cdrom/. /boot/ — 包括内核和其它系统启动期间使用的文件。 /lost+found/ — 被fsck用来放置零散文件(没有名称的文件)。 /lib/ — 包含许多被/bin/和/sbin/中的程序使用的库文件。目录/usr/lib/中含有更多用于用户程序的库文件。 /dev/ — 贮存设备文件。 /etc/ — 包含许多配置文件和目录。系统主要的设定档几乎都放置在这个目录内，例如人员的帐号密码档、各种服务的启始档等等。 一般来说，这个目录下的各档案属性是可以让一般使用者查阅的，但是只有root有权力修改。 /var/ — 用于贮存variable(或不断改变的)文件，例如日志文件和打印机假脱机文件。 /usr/ — 包括与系统用户直接有关的文件和目录，例如应用程序及支持它们的库文件。在这个目录下，你可以找到那些不适合放在/bin或/etc目录下的额外的工具。比如像游戏阿，一些打印工具拉等等。/usr目录包含了许多子目录： /usr/bin目录用于存放程序; /usr/share用于存放一些共享的数据，比如音乐文件或者图标等等;/usr/lib目录用于存放那些不能直接运行的，但却是许多程序运行所必需的一些函数库文件。 /proc/ — 一个虚拟的文件系统(不是实际贮存在磁盘上的)，它包括被某些程序使用的系统信息。 /initrd/ — 用来在计算机启动时挂载 initrd.img 映像文件的目录以及载入所需设备模块的目录。 警告: 不要删除/initrd/目录。如果你删除了该目录后再重新引导Red Hat Linux时，你将无法引导你的计算机。 /tmp/ — 用户和程序的临时目录。/tmp给予所有系统用户读写权。**这是让一般使用者或者是正在执行的程序暂时放置档案的地方。**这个目录是任何人都能够存取的，所以你需要定期的清理一下。当然，重要资料不可放置在此目录啊。 因为FHS甚至建议在开机时，应该要将/tmp下的资料都删除。 /home/ — 用户主目录的默认位置。 /opt/ — 可选文件和程序的贮存目录。该目录主要被第三方开发者用来简易地安装和卸装他们的软件包。这里主要存放那些可选的程序。你想尝试最新的firefox测试版吗?那就装到/opt目录下吧，这样，当你尝试完，想删掉firefox的时候，你就可 以直接删除它，而不影响系统其他任何设置。安装到/opt目录下的程序，它所有的数据、库文件等等都是放在同个目录下面。 /usr/local/ - 这里主要存放那些手动安装的软件，即apt或者apt-get安装的软件。它和/usr目录具有相类似的目录结构。让软件包管理器来管理/usr目录，而把自定义的脚本(scripts)放到/usr/local目录下面，我想这应该是个不错的主意。 /media/ - 有些linux的发行版使用这个目录来挂载那些usb接口的移动硬盘(包括U盘)、CD/DVD驱动器等等。 ","date":"2023-07-16","objectID":"/posts/filesystem/:0:0","tags":["Linux"],"title":"Linux Filesystem","uri":"/posts/filesystem/"},{"categories":["Memo"],"content":"/usr/local/ 和 /usr/share/ 区别 /usr/local - 这个目录一般是用来存放用户自编译安装软件的存放目录; 一般是通过源码包安装的软件，如果没有特别指定安装目录的话，一般是安装在这个目录中。这个目录下面有子目录。 /usr/share - 系统共用的东西存放地，比如/usr/share/fonts是字体目录，/usr/share/doc和/usr/share/man帮助文件。 /var/log - 系统日志存放，分析日志要看这个目录的东西; /var/spool - 打印机、邮件、代理服务器等脱机目录。 Linux Command Notes ","date":"2023-07-16","objectID":"/posts/filesystem/:1:0","tags":["Linux"],"title":"Linux Filesystem","uri":"/posts/filesystem/"},{"categories":["Memo"],"content":"查找文件的命令:find/locate/whereis/which/type/grep ","date":"2023-07-16","objectID":"/posts/filesystem/:2:0","tags":["Linux"],"title":"Linux Filesystem","uri":"/posts/filesystem/"},{"categories":["Memo"],"content":"find find命令准确，但速度非常慢，它可以查找任何类型的文件 使用格式 find [指定目录] [指定条件] [指定动作] 参数说明: [指定目录]： 所要搜索的目录及其所有子目录。默认为当前目录 [指定条件]： 所要搜索的文件的特征 -name：按文件名来查找文件 -user：按照文件的属主来查找文件 -group：按照文件所属的组来查找文件 -perm：按照文件权限来查找文件 -prune：不在当前指定目录中查找 [指定动作]： 对搜索结果进行特定的处理 -print：将匹配的文件输出到标准输出 -exec：对匹配的文件执行该参数所给出的shell命令 -ok：和-exec的作用相同，在执行每一个命令之前，让用户来确定是否执行 find命令不加任何参数时，表示搜索路径为当前目录及其子目录，默认的动作为-print，即不过滤任何结果，也就是说输出所有的文件 使用示例: - 递归搜索当前目录中，所有以file开头的文件 shell find . -name 'file*' - 递归搜索当前目录中，所有以file开头的文件，并显示它们的详细信息 shell find . -name 'file*' -ls ","date":"2023-07-16","objectID":"/posts/filesystem/:2:1","tags":["Linux"],"title":"Linux Filesystem","uri":"/posts/filesystem/"},{"categories":["Memo"],"content":"locate locate命令可以说是find -name的另一种写法，但是要比后者快得多，原因在于它不搜索具体目录，而是搜索一个数据库/var/lib/locatedb，这个数据库中含有本地所有文件信息. Linux自动创建这个数据库，并且每天自动更新一次，所以使用locate命令查不到最新变动过的文件。为了避免这种情况，可以在使用locate之前，先使用updatedb命令，手动更新数据库. 使用格式: locate [参数] \u003c文件名\u003e 使用示例: 搜索etc目录下所有以file开头的文件 locate /etc/file 搜索用户主目录下，所有以f开头的文件，并且忽略大小写 locate -i ~/f ","date":"2023-07-16","objectID":"/posts/filesystem/:2:2","tags":["Linux"],"title":"Linux Filesystem","uri":"/posts/filesystem/"},{"categories":["Memo"],"content":"whereis whereis命令只能搜索特定格式的文件 使用格式 whereis [参数] \u003c文件名\u003e 可搜索文集类型 二进制文件(-b) 源代码文件(-s) 说明文件(-m) 如果省略参数，则返回所有信息 使用示例: 找出名为find的文件位置 whereis find ","date":"2023-07-16","objectID":"/posts/filesystem/:2:3","tags":["Linux"],"title":"Linux Filesystem","uri":"/posts/filesystem/"},{"categories":["Memo"],"content":"which which命令的作用是，在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果, 也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。 使用格式 which \u003c命令\u003e 使用实例: 查找find命令的位置 which find ","date":"2023-07-16","objectID":"/posts/filesystem/:2:4","tags":["Linux"],"title":"Linux Filesystem","uri":"/posts/filesystem/"},{"categories":["Memo"],"content":"type type命令其实不能算查找命令，它是用来区分某个命令到底是由shell自带的，还是由shell外部的独立二进制文件提供的; 如果一个命令是外部命令，那么使用-p参数，会显示该命令的路径，相当于which命令。 使用格式 type \u003c命令\u003e 使用实例: 查看cd命令是否为shell自带的命令 type cd 查看grep是否为外部命令 type grep ","date":"2023-07-16","objectID":"/posts/filesystem/:2:5","tags":["Linux"],"title":"Linux Filesystem","uri":"/posts/filesystem/"},{"categories":["Memo"],"content":"grep grep命令用于查找拥有特殊字段的文件。 语法 grep [-abcEFGhHilLnqrsvVwxy][-A\u003c显示行数\u003e][-B\u003c显示列数\u003e][-C\u003c显示列数\u003e][-d\u003c进行动作\u003e][-e\u003c范本样式\u003e][-f\u003c范本文件\u003e][--help][范本样式][文件或目录...] 参数: -a 或 –text : 不要忽略二进制的数据。 -A\u003c显示行数\u003e 或 –after-context=\u003c显示行数\u003e : 除了显示符合范本样式的那一列之外，并显示该行之后的内容。 -b 或 –byte-offset : 在显示符合样式的那一行之前，标示出该行第一个字符的编号。 -B\u003c显示行数\u003e 或 –before-context=\u003c显示行数\u003e : 除了显示符合样式的那一行之外，并显示该行之前的内容。 -c 或 –count : 计算符合样式的列数。 -C\u003c显示行数\u003e 或 –context=\u003c显示行数\u003e或-\u003c显示行数\u003e : 除了显示符合样式的那一行之外，并显示该行之前后的内容。 -d \u003c动作\u003e 或 –directories=\u003c动作\u003e : 当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。 -e\u003c范本样式\u003e 或 –regexp=\u003c范本样式\u003e : 指定字符串做为查找文件内容的样式。 -E 或 –extended-regexp : 将样式为延伸的正则表达式来使用。 -f\u003c规则文件\u003e 或 –file=\u003c规则文件\u003e : 指定规则文件，其内容含有一个或多个规则样式，让grep查找符合规则条件的文件内容，格式为每行一个规则样式。 -F 或 –fixed-regexp : 将样式视为固定字符串的列表。 -G 或 –basic-regexp : 将样式视为普通的表示法来使用。 -h 或 –no-filename : 在显示符合样式的那一行之前，不标示该行所属的文件名称。 -H 或 –with-filename : 在显示符合样式的那一行之前，表示该行所属的文件名称。 -i 或 –ignore-case : 忽略字符大小写的差别。 -l 或 –file-with-matches : 列出文件内容符合指定的样式的文件名称。 -L 或 –files-without-match : 列出文件内容不符合指定的样式的文件名称。 -n 或 –line-number : 在显示符合样式的那一行之前，标示出该行的列数编号。 -o 或 –only-matching : 只显示匹配PATTERN 部分。 -q 或 –quiet或–silent : 不显示任何信息。 -r 或 –recursive : 此参数的效果和指定\"-d recurse\"参数相同。 -s 或 –no-messages : 不显示错误信息。 -v 或 –invert-match : 显示不包含匹配文本的所有行。 -V 或 –version : 显示版本信息。 -w 或 –word-regexp : 只显示全字符合的列。 -x –line-regexp : 只显示全列符合的列。 -y : 此参数的效果和指定\"-i\"参数相同。 示例: # 查找指定目录/etc/acpi 及其子目录（如果存在子目录的话）下所有文件中包含字符串\"update\"的文件，并打印出该字符串所在行的内容 grep -r update /etc/acpi # 查看符合条件的日志条目。 grep -n '2019-10-24 00:01:11' *.log # 只匹配文本文件，不匹配二进制文件的命令 grep -srn \"parameter\" . --binary-files=without-match ","date":"2023-07-16","objectID":"/posts/filesystem/:2:6","tags":["Linux"],"title":"Linux Filesystem","uri":"/posts/filesystem/"},{"categories":["Memo"],"content":"VIM 8.2 安装 ","date":"2023-07-16","objectID":"/posts/vim_installation/:0:0","tags":["vim"],"title":"Vim Installation","uri":"/posts/vim_installation/"},{"categories":["Memo"],"content":"1. Install Python3.9 from source Update the packages list and install the packages necessary to build Python sudo apt update \u0026\u0026 sudo apt install build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev libsqlite3-dev wget libbz2-dev Download the latest release’s source code from the Python download page using wget wegt https://www.python.org/ftp/python/3.9.0/Python-3.9.1.tgz Switch to the Python source directory and execute the configure script which performs a number of checks to make sure all of the dependencies on your system are present cd Python-3.9.1 ./configure --enable-optimizations --with-lto --enable-shared --prefix=/usr/local/python39 make -j8 When the build process is complete, install the Python binaries by typing sudo make altinstall Do not use the standard make install as it will overwrite the default system python3 binary. copy the dynamic library to usr/lib/x86_64-linux-gnu/libpython3.9.so.1.0 sudo cp /usr/local/python39/lib/libpython3.9.so.1.0 /usr/lib/x86_64-linux-gnu/ the command can slove the error: error while loading shared libraries: libpython3.9.so.1.0: cannot open shared object file: No such file or directory make the soft link to set python39 as default python3 sudo ln -sf /usr/local/python39/bin/python3.9 /usr/bin/python3 sudo ln -s /usr/local/python39/bin/python3.9 /usr/bin/python3.9 using update-alternatives to switch different python version list all the python versions sudo update-alternatives --list python3 display python3 sudo update-alternatives --display python3 set different number for different version sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1 sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 2 show different mode and select number to switch another mode sudo update-alternatives --config python3 ","date":"2023-07-16","objectID":"/posts/vim_installation/:1:0","tags":["vim"],"title":"Vim Installation","uri":"/posts/vim_installation/"},{"categories":["Memo"],"content":"2. 源码安装cmake ","date":"2023-07-16","objectID":"/posts/vim_installation/:2:0","tags":["vim"],"title":"Vim Installation","uri":"/posts/vim_installation/"},{"categories":["Memo"],"content":"2.1 download the cmake source code download source code wget https://github.com/Kitware/CMake/releases/download/v3.23.1/cmake-3.23.1.tar.gz ","date":"2023-07-16","objectID":"/posts/vim_installation/:2:1","tags":["vim"],"title":"Vim Installation","uri":"/posts/vim_installation/"},{"categories":["Memo"],"content":"2.2 extract the source code directory and run the command to install extraction and configuration cd cmake-2.23.0 ./bootstrap //需要的话也可以指定安装目录，例如--prefix=/usr/local/cmake make \u0026\u0026 sudo make install ","date":"2023-07-16","objectID":"/posts/vim_installation/:2:2","tags":["vim"],"title":"Vim Installation","uri":"/posts/vim_installation/"},{"categories":["Memo"],"content":"2.3 create soft link and set cmake as default set cmake as default sudo ln -s /usr/local/bin/cmake /usr/bin/cmake ","date":"2023-07-16","objectID":"/posts/vim_installation/:2:3","tags":["vim"],"title":"Vim Installation","uri":"/posts/vim_installation/"},{"categories":["Memo"],"content":"3. 首先从github下载源码vim 8.2 ","date":"2023-07-16","objectID":"/posts/vim_installation/:3:0","tags":["vim"],"title":"Vim Installation","uri":"/posts/vim_installation/"},{"categories":["Memo"],"content":"3.1 源码安装vim8.2 run the following command to downlaod source code of VIM from github git clone git clone https://github.com/vim/vim.git cd vim git pull cd src/ sudo make distclean # 如果您以前构建国vim cofigure the installation file ./configure --with-features=huge --enable-multibyte --enable-python3interp=dynamic --with-python3-config-dir=/usr/lib/python3.10/config-3.10-x86_64-linux-gnu/ --enable-cscope --enable-gui=auto --enable-gtk2-check --enable-fontset --enable-largefile --disable-netbeans --with-compiledby=\"18817571704@163.com\" --enable-fail-if-missing --prefix=/usr/local/vim82 sudo make sudo make install enable clipboard then you can copy the content from system clipboard to vim sudo apt-get install vim-gtk3 卸载vim 使用以下命令重置编译操作 sudo make distclean 使用以下命令，可以卸载命令 sudo make uninstall ","date":"2023-07-16","objectID":"/posts/vim_installation/:3:1","tags":["vim"],"title":"Vim Installation","uri":"/posts/vim_installation/"},{"categories":["Memo"],"content":"3.2 安装vim-plug以及插件 安装vim-plug: curl -fLo ~/.vim/autoload/plug.vim --create-dirs \\ https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim 安装主题gruvbox to fix error: Cannot find color scheme ‘gruvbox’ mkdir ~/.vim/colors/ cp ~/.vim/plugged/gruvbox/gruvbox.vim ~/.vim/colors/ 安装YCM(YouCompleteMe) 根据~/.vimrc按装YCM cd ~/.vim/plugged/YouCompleteMe/ ./install.py --clang-completer 安装ctags sudo apt-get install exuberant-ctags 其他主题直接编辑:PlugInstall进行安装 ","date":"2023-07-16","objectID":"/posts/vim_installation/:3:2","tags":["vim"],"title":"Vim Installation","uri":"/posts/vim_installation/"},{"categories":["Memo"],"content":"3.2 reference 参考链接: [1] https://github.com/ycm-core/YouCompleteMe/wiki/Building-Vim-from-source [2] https://wizardforcel.gitbooks.io/use-vim-as-ide/content/0.html ","date":"2023-07-16","objectID":"/posts/vim_installation/:3:3","tags":["vim"],"title":"Vim Installation","uri":"/posts/vim_installation/"},{"categories":["Memo"],"content":"zsh说明 zsh是一个Linux下强大的shell, 由于大多数Linux产品安装以及默认使用bash shell, 但是丝毫不影响极客们对zsh的热衷, 几乎每一款Linux产品都包含有zsh，通常可以用apt-get、urpmi或yum等包管理器进行安装. zsh是bash的增强版，其实zsh和bash是两个不同的概念，zsh更加强大。 通常zsh配置起来非常麻烦，且相当的复杂，所以oh-my-zsh是为了简化zsh的配置而开发的，因此oh-my-zsh算是zsh的配置. ","date":"2023-07-16","objectID":"/posts/zsh_installation/:1:0","tags":["Zsh"],"title":"Zsh Installation","uri":"/posts/zsh_installation/"},{"categories":["Memo"],"content":"准备 查看当前系统用shell版本 echo $SHELL 查看系统自带哪些shell cat /etc/shells ","date":"2023-07-16","objectID":"/posts/zsh_installation/:2:0","tags":["Zsh"],"title":"Zsh Installation","uri":"/posts/zsh_installation/"},{"categories":["Memo"],"content":"安装zsh 通过命令行安装zsh sudo apt install zsh ","date":"2023-07-16","objectID":"/posts/zsh_installation/:3:0","tags":["Zsh"],"title":"Zsh Installation","uri":"/posts/zsh_installation/"},{"categories":["Memo"],"content":"zsh配置 将zsh设置为默认的shell chsh -s /bin/zsh 然后重启电脑 reboot ","date":"2023-07-16","objectID":"/posts/zsh_installation/:4:0","tags":["Zsh"],"title":"Zsh Installation","uri":"/posts/zsh_installation/"},{"categories":["Memo"],"content":"安装oh-my-zsh及其个性化配置 ","date":"2023-07-16","objectID":"/posts/zsh_installation/:5:0","tags":["Zsh"],"title":"Zsh Installation","uri":"/posts/zsh_installation/"},{"categories":["Memo"],"content":"安装oh-my-zsh 执行以下命令安装oh-my-zsh sh -c \"$(wget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)\" 或者 sh -c \"$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\" ","date":"2023-07-16","objectID":"/posts/zsh_installation/:5:1","tags":["Zsh"],"title":"Zsh Installation","uri":"/posts/zsh_installation/"},{"categories":["Memo"],"content":"主题配置 打开配置文件~/.zshrc 输入: ZSH_THEME=\"xxf\" xxf.zsh-theme文件下载地址: xxf.zsh-theme文件下载 下载之后将文件拷贝到以下路径: /home/username/.oh-my-zsh/themes/ ","date":"2023-07-16","objectID":"/posts/zsh_installation/:5:2","tags":["Zsh"],"title":"Zsh Installation","uri":"/posts/zsh_installation/"},{"categories":["Memo"],"content":"插件 安装自动补全插件incr 首先，下载incr插件到本地 cd ~/.oh-my-zsh/plugins/ mkdir incr \u0026\u0026 cd incr wget http://mimosa-pudica.net/src/incr-0.2.zsh 编辑~/.zshrc文件，添加以下内容: source ~/.oh-my-zsh/plugins/incr/incr*.zsh 然后，source一下: source ~/.zshrc 直接使用默认插件 在~/.zshrc文件中添加插件: plugins=(git extract z) 安装autojump插件 通过命令行安装autojump sudo apt install autojump 在~/.zshrc文件中编辑: . /usr/share/autojump/autojump.sh 然后，source一下: source ~/.zshrc 安装zsh-syntax-highlighting语法高亮插件 从gihub下载源码并放在~/.oh-my-zsh/plugins/文件夹下: cd ~/.oh-my-zsh/plugins/ git clone https://github.com/zsh-users/zsh-syntax-highlighting.git 在~/.zshrc文件中编辑: source ~/.oh-my-zsh/plugins/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh 然后，source一下: source ~/.zshrc 安装zsh-autosuggestions语法历史记录插件 从gihub下载源码并放在~/.oh-my-zsh/plugins/文件夹下: cd ~/.oh-my-zsh/plugins/ git clone git@github.com:zsh-users/zsh-autosuggestions.git 在~/.zshrc文件中编辑: source ~/.oh-my-zsh/plugins/zsh-autosuggestions/zsh-autosuggestions.zsh 然后，source一下: source ~/.zshrc ","date":"2023-07-16","objectID":"/posts/zsh_installation/:5:3","tags":["Zsh"],"title":"Zsh Installation","uri":"/posts/zsh_installation/"},{"categories":["Memo"],"content":"其他 设置更新日期 在~/.zshrc文件中编： exprot UPDATE_ZSH_DAYS=13 禁止自动更新 DISABLE_AUTO_UPDATE=\"true\" 手动更新oh-my-zsh upgrade_oh_my_zsh 卸载oh-my-zsh uninstall_on_my_zsh zsh ","date":"2023-07-16","objectID":"/posts/zsh_installation/:5:4","tags":["Zsh"],"title":"Zsh Installation","uri":"/posts/zsh_installation/"},{"categories":["Memo"],"content":"从bash到zsh的切换 直接执行zsh和oh-my-zsh的安装以及配置，并且在~/.zshrc文件中添加: source ~/.bashrc ","date":"2023-07-16","objectID":"/posts/zsh_installation/:5:5","tags":["Zsh"],"title":"Zsh Installation","uri":"/posts/zsh_installation/"},{"categories":["Memo"],"content":"zsh 快捷键 快捷键 ⌃ + u: 清空当前行 ⌃ + a: 移动到行首 ⌃ + e: 移动到行尾 ⌃ + f: 向前移动 ⌃ + b: 向后移动 ⌃ + p: 上一条命令 ⌃ + n: 下一条命令 ⌃ + r: 搜索历史命令 ⌃ + y: 召回最近用命令删除的文字 ⌃ + h: 删除光标之前的字符 ⌃ + d: 删除光标所指的字符 ⌃ + w: 删除光标之前的单词 ⌃ + k: 删除从光标到行尾的内容 ⌃ + t: 交换光标和之前的字符 ","date":"2023-07-16","objectID":"/posts/zsh_installation/:6:0","tags":["Zsh"],"title":"Zsh Installation","uri":"/posts/zsh_installation/"},{"categories":["Git"],"content":" 工作区：就是你在电脑里能看到的目录。 暂存区：英文叫 stage, 或 index。一般存放在 “.git 目录下” 下的 index 文件（.git/index）中，所以我们把暂存区有时也叫作索引（index）。 版本库：工作区有一个隐藏目录。git，这个不算工作区，而是 Git 的版本库。 ","date":"2023-07-16","objectID":"/posts/introduction/:0:0","tags":["Git"],"title":"Git 常用指令汇总","uri":"/posts/introduction/"},{"categories":["Git"],"content":"介绍 https://git-scm.com/ 先通过几张图片来大致了解一下 Git 的工作原理吧！ 文章开头的流程图已经简单明了地说明了 Git 常用操作的工作流程，下图换种风格再展示一次： 提到 Git 就会联想到 github, 下图从 Git 的角度简单说明了一些 Github 常用操作的关系： 下面这个图则展示了工作区、版本库中的暂存区和版本库之间的关系： 图中左侧为工作区，右侧为版本库。在版本库中标记为 \"index\" 的区域是暂存区（stage, index），标记为 “master” 的是 master 分支所代表的目录树。 HEAD 指针：每个 git 仓库有且仅有一个 HEAD 指针，它通常指向當前某个活動的本地分支指针（最初本地仓库 master)。也可以是某个提交记录、某个 tag，但这会让其处于 detached HEAD（游离头）状态，此状态下的所有提交都无效。 图中我们可以看出此时 \"HEAD\" 实际是指向 master 分支的一个\"游标\"。所以图示的命令中出现 HEAD 的地方可以用 master 来替换。 图中的objects标识的区域为 Git 的对象库，实际位于 \".git/objects\" 目录下，里面包含了创建的各种对象及内容。 当对工作区修改（或新增）的文件执行 \"git add\"命令时，暂存区的目录树被更新，同时工作区修改（或新增）的文件内容被写入到对象库中的一个新的对象中，而该对象的 ID 被记录在暂存区的文件索引中。 当执行提交操作（git commit）时，暂存区的目录树写到版本库（对象库）中，master 分支会做相应的更新。即 master 指向的目录树就是提交时暂存区的目录树。 当执行 \"git reset HEAD\" 命令时，暂存区的目录树会被重写，被 master 分支指向的目录树所替换，但是工作区不受影响。 当执行 \"git rm --cached \u003cfile\u003e\" 命令时，会直接从暂存区删除文件，工作区则不做出改变。 当执行 \"git checkout .\" 或者 \"git checkout -- \u003cfile\u003e\" 命令时，会用暂存区全部或指定的文件替换工作区的文件。这个操作很危险，会清除工作区中未添加到暂存区的改动。 当执行 \"git checkout HEAD .\" 或者 \"git checkout HEAD \u003cfile\u003e\" 命令时，会用 HEAD 指向的 master 分支中的全部或者部分文件替换暂存区和以及工作区中的文件。这个命令也是极具危险性的，因为不但会清除工作区中未提交的改动，也会清除暂存区中未提交的改动。 ","date":"2023-07-16","objectID":"/posts/introduction/:1:0","tags":["Git"],"title":"Git 常用指令汇总","uri":"/posts/introduction/"},{"categories":["Git"],"content":"Git 配置 git config --global --list #查看全局配置 git config --local --list #查看本项目配置 # 第一次使用 git 的时候，需要设置用户信息和用户邮箱，用于辨识提交者身份 git config --global user.name \"用户名\" git config --global user.email \"邮箱\" git config --global alias.cm commit git config --global alias.br branch # 配置指令别名简写 git config --global credential.helper store # 输入一次账号密码后第二次就会记住账号密码 git config --global core.ignorecase false # 关闭忽略大小写 git config --system core.longpaths true # 配置长路径 git config --global http.sslVerify false # 禁用 SSL 验证 git config --global core.protectNTFS false # 关闭 NTFS 文件保护 git config --global url.\"https://\".insteadOf git:// # git:// 报错 ","date":"2023-07-16","objectID":"/posts/introduction/:2:0","tags":["Git"],"title":"Git 常用指令汇总","uri":"/posts/introduction/"},{"categories":["Git"],"content":"基本操作 git init ## 把当前的目录变成可以用 git 进行版本控制的 git 仓库，生成隐藏。git 文件。 git add XX ## 把 xx 文件添加到暂存区去。 git add –A ## git add --all 的缩写，添加全部到暂存区 git add –u ## 把文件的删除和修改添加到暂存区（不包括新增） git add . ## 监控工作区的状态树，使用它会把工作时的所有变化提交到暂存区 git commit -m \"message\" ## 从暂存区提交到本地仓库 git commit -a -m \"message\" ## 相当于省略 git add，但是无法提交新增的文件 git push origin master ## Git 会把 master 分支推送到远程库对应的远程分支上 Tips Commit Message 内容尽量规范！ 当某一次提交后，突然想起漏提交了文件，或不小心提交了不满意的代码时， 可以使用git commit --amend -m \"message\"指令。它可以在不增加一个新的 commit-id 的情况下将新修改的代码追加到前一次的 commit-id 中。提交之后 message 也将被本次的 message 覆盖，所以还需要再次添加上次的 message。 ","date":"2023-07-16","objectID":"/posts/introduction/:2:1","tags":["Git"],"title":"Git 常用指令汇总","uri":"/posts/introduction/"},{"categories":["Git"],"content":"push git push origin branch-name git push –u origin master git push origin --delete branch-name ## 删除远程分支 把当前 master 分支推送到远程库；-u表示记住分支和地址，下次使用git push即可。 ","date":"2023-07-16","objectID":"/posts/introduction/:2:2","tags":["Git"],"title":"Git 常用指令汇总","uri":"/posts/introduction/"},{"categories":["Git"],"content":"remote git remote add origin reposityUrl ## 关联一个远程库 git remote ## 查看远程库的信息 git remote –v ## 查看远程库的详细信息 ","date":"2023-07-16","objectID":"/posts/introduction/:2:3","tags":["Git"],"title":"Git 常用指令汇总","uri":"/posts/introduction/"},{"categories":["Git"],"content":"clone git clone reposityUrl ## 从远程库中克隆 git clone -b branchName reposityUrl ## 克隆指定分支 ","date":"2023-07-16","objectID":"/posts/introduction/:2:4","tags":["Git"],"title":"Git 常用指令汇总","uri":"/posts/introduction/"},{"categories":["Git"],"content":"pull git pull 从远程仓库拉下来到本地库然后合并相当于git fetch+git merge。 一般 push 前先拉去最新版本，避免代码冲突，如果有冲突需要解决了冲突才能提交。 import repositories 同步更新 git pull 原链接 git push origin master ","date":"2023-07-16","objectID":"/posts/introduction/:2:5","tags":["Git"],"title":"Git 常用指令汇总","uri":"/posts/introduction/"},{"categories":["Git"],"content":"fetch git fetch ## 从远程库抓下最新版本，但是不合并 fetch 是从远程库到本地库，但是未在工作区，需要git merge ","date":"2023-07-16","objectID":"/posts/introduction/:2:6","tags":["Git"],"title":"Git 常用指令汇总","uri":"/posts/introduction/"},{"categories":["Git"],"content":"merge git merge dev ## 在当前的分支上合并 dev 分支 分支合并也是在本地完成 (从本地库到工作区)，新的分支只有在合并后才允许被删除。 如果分支合并是出现冲突需要解决了冲突才能合并，使用git status查看冲突文件。 ","date":"2023-07-16","objectID":"/posts/introduction/:2:7","tags":["Git"],"title":"Git 常用指令汇总","uri":"/posts/introduction/"},{"categories":["Git"],"content":"branch,checkout git branch ## 查看当前所有的分支 git branch name ## 创建分支 git branch –r ## 看远程所有分支 git branch –a ## 查看本地远程分支 git branch –d name ## 删除分支 git checkout name ## 切换分支 git checkout –b name ## 创建并切换到 name 分支上 git checkout -- file git checkout -- file相当于取消对文档的修改，将最新的本地版本库的本文件复制覆盖它。（比较危险！） ","date":"2023-07-16","objectID":"/posts/introduction/:2:8","tags":["Git"],"title":"Git 常用指令汇总","uri":"/posts/introduction/"},{"categories":["Git"],"content":"reflog,log git log ## 显示所有提交过的版本信息：commit id，提交者，日期 git reflog ## 查看历史记录的 commit id Tips 想看到自己的操作记录，则可以使用 log 与 reflog，它两个的区别如下： git log命令可以显示所有提交过的版本信息； 如果感觉太繁琐，可以加上参数--pretty=oneline，只会显示版本号和提交时的备注信息。 git reflog可以查看所有分支的所有操作记录。（包括已经被删除的 commit 记录和 reset 的操作） ","date":"2023-07-16","objectID":"/posts/introduction/:2:9","tags":["Git"],"title":"Git 常用指令汇总","uri":"/posts/introduction/"},{"categories":["Git"],"content":"reset git reset --hard HEAD^ git reset --hard HEAD~ ## 回退到上一个版本 git reset --hard HEAD~100 ## 回退到 100 个版本 git reset head -- file ## 不加 file 则全部退回 git reset file ## 将本地仓库的当前版本退回至暂存区，相当于取消暂存 版本退回是从本地仓库到暂存区，如果已经提交远程库，此时的版本是低于最新的版本的会拒绝提交， 需要用git push -f origin master强制提交。 特别提醒 如果你git reset --hard HEAD^+git push -f origin master执行完，github 中的记录和本地文件都会回到退回的状态。简单来说就是一修改了一天的 bug, 完工后，你这一套操作直接打回原形。别慌（实际内心慌的一麻皮。） 通过git log -g命令来找到需要恢复的信息对应的 commitid，可以通过提交的时间和记录来辨别， 找到执行reset --hard之前的那个 commit 对应的 commit-id 通过git branch recover_branch commit-id来建立一个新的分支 这样，就把到 commitid 为止的代码、各种提交记录等信息都恢复到了 recover_branch 分支上了。 ","date":"2023-07-16","objectID":"/posts/introduction/:2:10","tags":["Git"],"title":"Git 常用指令汇总","uri":"/posts/introduction/"},{"categories":["Git"],"content":"status git status 查看你的文件在暂存区和工作目录的状态，默认是较为详细的显示，并提示你可以用何种命令完成你接下来可能要做的事情。 git status -s 较为简单的输出当前的状态，如： $ git status -s M README.md D hello.rb ?? world.java 你可以看到，在简短输出中，有两栏。第一栏是暂存区的，第二栏则是工作目录的。这里表示： README.md 在暂存区中的状态是 modify hello.rb 在工作目录中的状态是 delete world.java 还未添加到版本控制。 ","date":"2023-07-16","objectID":"/posts/introduction/:2:11","tags":["Git"],"title":"Git 常用指令汇总","uri":"/posts/introduction/"},{"categories":["Git"],"content":"diff git diff XX ## 查看 XX 文件修改了哪些内容 git diff ## 工作目录和暂存区 git diff --cached ## 暂存区和本地仓库 git diff HEAD ## 工作目录和本地仓库 git diff --stat ## 显示信息摘要 ","date":"2023-07-16","objectID":"/posts/introduction/:2:12","tags":["Git"],"title":"Git 常用指令汇总","uri":"/posts/introduction/"},{"categories":["Git"],"content":"rm, mv git rm ## 将文件从暂存区和工作目录删除，-f 为强制删除 git rm filename ## 删除文件 git rm –r dirname ## 删除文件夹 –r 表示递归所有子目录 git rm --cached \u003cpath\u003e ## 将文件从暂存区中删除 git mv \u003cold_path\u003e \u003cnew_path\u003e git rm用来删除文件、目录。git mv命令用于移动或重命名一个文件、目录。 比如删除 photos 文件，本地删除后，远程仓库还会有，所以 git rm -r photos git commit -m \"删除相册\" git push ","date":"2023-07-16","objectID":"/posts/introduction/:2:13","tags":["Git"],"title":"Git 常用指令汇总","uri":"/posts/introduction/"},{"categories":["Git"],"content":"submodule git submodule add ## 添加子模组 git submodule init ## 子模组初始化 git submodule update ## 子模组更新 git submodule -help Note 当一个远程库有子模组时，直接 clone 子模组只是一个空文件夹，需要进入子模组的空文件夹init和update才行。 或者使用递归克隆git clone --recursive 远程库 子模组更新后，父模组必须更新，因为需要更新 commit id。 ","date":"2023-07-16","objectID":"/posts/introduction/:2:14","tags":["Git"],"title":"Git 常用指令汇总","uri":"/posts/introduction/"},{"categories":["Git"],"content":"tag git tag v1.0 git tag -a v1.0 ## 给最新一次提交打标签 git tag -a \u003ctagname\u003e -m \"标签\" ## 指定标签信息命令 git show \u003ctagname\u003e ## 显示标签信息 git tag ## 查看版本打的 Tag git tag -d v1.0 ## 删除本地标签 git push origin :refs/tags/v1.0 ## 删除远程标签 $ git push [remote] [tag] ## 提交指定 tag $ git push [remote] --tags ## 提交所有 tag Note 当你执行git tag -a命令时，Git 会打开你的编辑器，让你写一句标签注解，就像你给提交写注解一样。 如果我们忘了给某个提交打标签，又将它发布了，我们可以给它追加标签。 例如，假设我们发布了提交 85fc7e7（最后一行），但是那时候忘了给它打标签。 我们现在也可以： $ git tag -a v0.9 85fc7e7 $ git log --oneline --decorate --graph * d5e9fc2 (HEAD -\u003e master) Merge branch 'change_site' |\\ | * 7774248 (change_site) changed the runoob.php * | c68142b 修改代码 |/ * c1501a2 removed test.txt、add runoob.php * 3e92c19 add test.txt * 3b58100 (tag: v0.9) 第一次版本提交 ","date":"2023-07-16","objectID":"/posts/introduction/:2:15","tags":["Git"],"title":"Git 常用指令汇总","uri":"/posts/introduction/"},{"categories":["Git"],"content":"stash git stash ## 把当前的工作隐藏起来，等以后恢复现场后继续工作 git stash list ## 查看所有被隐藏的文件列表 ","date":"2023-07-16","objectID":"/posts/introduction/:2:16","tags":["Git"],"title":"Git 常用指令汇总","uri":"/posts/introduction/"},{"categories":["Git"],"content":"gitk gitk ## git 自带 GUI gitk --all ","date":"2023-07-16","objectID":"/posts/introduction/:2:17","tags":["Git"],"title":"Git 常用指令汇总","uri":"/posts/introduction/"},{"categories":["Git"],"content":"github,gitea 等平台 issue 的常用标签 bug 描述的问题是一个 bug enhancement 功能增强，没有 feature 也可以指 New feature or request feature 新功能 duplicate 问题重复 invalid 可用的，不是 bug question 疑问，需要进一步的信息 wontfix 不会修复此问题 help-wanted 需要帮助 good first issue Good for newcomers 更多标签 ","date":"2023-07-16","objectID":"/posts/introduction/:3:0","tags":["Git"],"title":"Git 常用指令汇总","uri":"/posts/introduction/"},{"categories":["Git"],"content":"license ","date":"2023-07-16","objectID":"/posts/introduction/:4:0","tags":["Git"],"title":"Git 常用指令汇总","uri":"/posts/introduction/"},{"categories":["Git"],"content":"其他 常用 Git 命令清单 github 上 fork 了别人的项目后，再同步更新别人的提交 Gearn Git Branching ","date":"2023-07-16","objectID":"/posts/introduction/:5:0","tags":["Git"],"title":"Git 常用指令汇总","uri":"/posts/introduction/"},{"categories":["Git"],"content":"Git 命令汇总 ","date":"2023-07-16","objectID":"/posts/gitnotes1/:1:0","tags":["Git"],"title":"Git 命令记录","uri":"/posts/gitnotes1/"},{"categories":["Git"],"content":"1. git rebase ref: https://git-scm.com/docs/git-rebase 用法一:git rebase \u003cbranch-name\u003e 将topic分支的base由E改为master A---B---C topic / D---E---F---G master 运行: git rebase master git rebase master topic 结果: A'--B'--C' topic / D---E---F---G master if upstream branch already has a change like below: A---B---C topic / D---E---A'---F master then run the command git rebase master, you will get following result: B'---C' topic / D---E---A'---F master 用法二:git rebase --onto assume topic is based on next, and next is based on master o---o---o---o---o master \\ o---o---o---o---o next \\ o---o---o topic run the command below: git rebase --onto master next topic then we get the result below: o---o---o---o---o master | \\ | o'--o'--o' topic \\ o---o---o---o---o next Another example: A range of commits could also be removed with rebase. If we have the following situation: E---F---G---H---I---J topicA then the command git rebase --onto topicA~5 topicA~3 topicA would result in the removal of commits F and G: E---H'---I'---J' topicA 用法三:git rebase -i \u003ccommit_id\u003e \u003ccommit_id\u003e $\\mathbb{\\rightarrow}$ 将多个commit合并为一个。 # 执行git log，得到以下commit_ids \u003e\u003e\u003e21fd585 \u003e\u003e\u003e45j3483 \u003e\u003e\u003e9i8975d \u003e\u003e\u003e73c20ec 目标: 将21fd585、45j3483、9i8975d rebase 到 73c20ec git rebase -i 73c20ec 21fd585 得到: pick pick pick pick 改为 pick squash squash squash 最后，编辑commit内容， 得到 \u003e\u003e\u003eb8bec33 # 此处为新的commit \u003e\u003e\u003e73c20ec 推送到remote: git push -f origin master ref: https://www.bilibili.com/video/BV15h411f74h/ https://blog.csdn.net/weixin_45953517/article/details/114362752 https://blog.csdn.net/weixin_44691608/article/details/118740059#t7 遇到detached HEAD的解决办法 git branch b1 git checkout master git merge b1 git push origin master git branch -d b1 ","date":"2023-07-16","objectID":"/posts/gitnotes1/:1:1","tags":["Git"],"title":"Git 命令记录","uri":"/posts/gitnotes1/"},{"categories":["Git"],"content":"2. git cherrypick 将指定的提交用于其他分支 例如: a - b - c - d Master \\ e - f - g Feature run the command below and apply commit(f) to master git checkout master git cherry-pick f get the result a - b - c - d - f Master \\ e - f - g Feature 转移多个提交 # 将 A 和 B 两个提交应用到当前分支 git cherry-pick \u003cHashA\u003e \u003cHashB\u003e 或者 # 该命令可以转移从 A 到 B 的所有提交,它们必须按照正确的顺序放置：提交 A 必须早于提交 B，否则命令将失败，但不会报错。 git cherry-pick A..B # 使用上面的命令，提交 A 将不会包含在 Cherry pick 中， 如果要包含提交 A，可以使用下面的语法。 git cherry-pick A^..B ref:https://www.ruanyifeng.com/blog/2020/04/git-cherry-pick.html ","date":"2023-07-16","objectID":"/posts/gitnotes1/:1:2","tags":["Git"],"title":"Git 命令记录","uri":"/posts/gitnotes1/"},{"categories":["Git"],"content":"3. git submodule 将一个repo添加为submodule git submodule add https://github.com/chaconinc/DbConnector 克隆含有子模块的项目 git clone https://github.com/chaconinc/MainProject #此时包含子模块目录，但是其中没有任何文件 cd MainProject cd DbConnector/ # 此时有DbConnector目录，但是文件夹是空的 git submodule init # 用来初始化本地配置文件 git submodule update # 从该项目中抓取并检出父项目中列出的合适的提交 或者 git clone --recurse-submodules https://github.com/chaconinc/MainProject 或者已经克隆了项目，但是忘记--recurse-submodule, 则使用 git submodule update --init --recursive ","date":"2023-07-16","objectID":"/posts/gitnotes1/:1:3","tags":["Git"],"title":"Git 命令记录","uri":"/posts/gitnotes1/"},{"categories":["Git"],"content":"4. 拉取远程分支到本地 拉取某一个远程的分支，并在创建相应的本地分支名称 git fetch origin remote-branch-name git checkout -b local-branch-name origin/remote-branch-name ","date":"2023-07-16","objectID":"/posts/gitnotes1/:1:4","tags":["Git"],"title":"Git 命令记录","uri":"/posts/gitnotes1/"},{"categories":["Git"],"content":"5. git tag 用git tag打标签 git tag -a v1.0 git tag -a v0 85fc7e7 #追加标签 git clone 按照tag拉取代码 # git clone --branch [tags标签] [git地址] git clone -b v5.2.0 --depth=1 http://gitlab地址 ","date":"2023-07-16","objectID":"/posts/gitnotes1/:1:5","tags":["Git"],"title":"Git 命令记录","uri":"/posts/gitnotes1/"},{"categories":["Git"],"content":"6. git stash git stash:隐藏修改 git stash # 隐藏修改 git stash save \"stash-name\" #给每一个stash取名字 git stash pop # 恢复隐藏的修改 git stash list # 列出所有的隐藏 git stash apply [number] # 指定恢复使用哪一个隐藏修改 git stash drop # 移除某一项修改 git stash clear # 删除所有隐藏的修改 git stash show # 查看隐藏的修改 git stash show -p git stash show --patch # 查看特定的stash的diff ","date":"2023-07-16","objectID":"/posts/gitnotes1/:1:6","tags":["Git"],"title":"Git 命令记录","uri":"/posts/gitnotes1/"},{"categories":["Git"],"content":"7. 代码回退: git reset/git revert ref:https://blog.csdn.net/weixin_35082950/article/details/113629326 本地分支版本回退的方法 git reflog # 找回要回退的版本的commit_id git reset --hard \u003ccommit_id\u003e 自己的远程分支版本回退的方法 # 如果你的错误提交已经推送到自己的远程分支了，那么就需要回滚远程分支了。 # 1. 首先要回退本地分支： git reflog git reset --hard \u003ccommit_id\u003e # 2. 强制推送到远程分支 git push -f 公共远程分支版本回退的问题 一个显而易见的问题：如果你回退公共远程分支，把别人的提交给丢掉了怎么办？ 假设你的远程master分支情况是这样的: A1–A2–B1 # 其中A、B分别代表两个人，A1、A2、B1代表各自的提交。并且所有人的本地分支都已经更新到最新版本，和远程分支一致。 这个时候你发现A2这次提交有错误，你用reset回滚远程分支master到A1，那么理想状态是你的队友一拉代码git pull，他们的master分支也回滚了，然而现实却是，你的队友会看到下面的提示： $ git status On branch master Your branch is ahead of 'origin/master' by 2 commits. (use \"git push\" to publish your local commits) nothing to commit, working directory clean 也就是说，你的队友的分支并没有主动回退，而是比远程分支超前了两次提交，因为远程分支回退了嘛。 git revert HEAD #撤销最近一次提交 git revert HEAD~1 #撤销上上次的提交，注意：数字从0开始 git revert 0ffaacc #撤销0ffaacc这次提交 git revert 命令意思是撤销某次提交。它会产生一个新的提交，虽然代码回退了，但是版本依然是向前的，所以，当你用revert回退之后，所有人pull之后，他们的代码也自动的回退了。 但是，要注意以下几点： 1、revert 是撤销一次提交，所以后面的commit id是你需要回滚到的版本的前一次提交。 2、使用revert HEAD是撤销最近的一次提交，如果你最近一次提交是用revert命令产生的，那么你再执行一次，就相当于撤销了上次的撤销操作，换句话说，你连续执行两次revert HEAD命令，就跟没执行是一样的。 3、使用revert HEAD~1 表示撤销最近2次提交，这个数字是从0开始的，如果你之前撤销过产生了commi id，那么也会计算在内的。 4、如果使用 revert 撤销的不是最近一次提交，那么一定会有代码冲突，需要你合并代码，合并代码只需要把当前的代码全部去掉，保留之前版本的代码就可以了。 git revert 命令的好处就是不会丢掉别人的提交，即使你撤销后覆盖了别人的提交，他更新代码后，可以在本地用 reset 向前回滚，找到自己的代码，然后拉一下分支，再回来合并上去就可以找回被你覆盖的提交了。 revert 合并代码，解决冲突 使用revert命令，如果不是撤销的最近一次提交，那么一定会有冲突，如下所示： 全部清空 第一次提交 解决冲突很简单，因为我们只想回到某次提交，因此需要把当前最新的代码去掉即可，也就是HEAD标记的代码: \u003c\u003c\u003c\u003c\u003c\u003c\u003c HEAD 全部清空 第一次提交 ======= 把上面部分代码去掉就可以了，然后再提交一次代码就可以解决冲突了。 ","date":"2023-07-16","objectID":"/posts/gitnotes1/:1:7","tags":["Git"],"title":"Git 命令记录","uri":"/posts/gitnotes1/"},{"categories":["Git"],"content":"8. git branch 将本地分支与远程分支关联: git branch --set-upstream=origin/remote_branch your_branch ","date":"2023-07-16","objectID":"/posts/gitnotes1/:1:8","tags":["Git"],"title":"Git 命令记录","uri":"/posts/gitnotes1/"},{"categories":["Git"],"content":"9. git commit git commit --amend: 提交小修改但是不增加commit_id: git add . git commmit --amend # 此除可以修改commit message git push origin master ","date":"2023-07-16","objectID":"/posts/gitnotes1/:1:9","tags":["Git"],"title":"Git 命令记录","uri":"/posts/gitnotes1/"},{"categories":["Git"],"content":"10. git pull 示例: git pull \u003c远程主机名\u003e \u003c远程分支名\u003e:\u003c本地分支名\u003e Examples： 取回origin主机的next分支，与本地的master分支合并 git pull origin next:master 远程分支(next)要与当前分支合并，则冒号后面的部分可以省略。 git pull origin next 如果当前分支与远程分支存在追踪关系，git pull就可以省略远程分支名 git pull origin 如果当前分支只有一个追踪分支，连远程主机名都可以省略 ","date":"2023-07-16","objectID":"/posts/gitnotes1/:1:10","tags":["Git"],"title":"Git 命令记录","uri":"/posts/gitnotes1/"},{"categories":["Git"],"content":"11. git clone https://mp.weixin.qq.com/s?__biz=MzA4NjkwOTQ2OA==\u0026mid=2459742421\u0026idx=1\u0026sn=48b3849c03a8e99aa4a557e9643a68d1\u0026chksm=89af6fd53c65887bd2c4a8ada2d5afabbffabf2b390477bc298e7ed11e7a563f3ba83fff9e13\u0026scene=132\u0026exptype=timeline_recommend_article_extendread_extendread_for_notrec#wechat_redirect git flow git pull ","date":"2023-07-16","objectID":"/posts/gitnotes1/:1:11","tags":["Git"],"title":"Git 命令记录","uri":"/posts/gitnotes1/"},{"categories":["Pandas"],"content":"Pandas Notes ","date":"2023-07-15","objectID":"/posts/pandasnotes1/:0:0","tags":["draft"],"title":"Pandas Notes 1","uri":"/posts/pandasnotes1/"},{"categories":["Pandas"],"content":"Input/Output pd.read_csv(filepath): 读取csv文件 ref: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html?highlight=read_csv pd.read_pickle():读取pickle数据 import pandas pandas.read_pickle(filepath_or_buffer, compression='infer', storage_options=None) ref: https://pandas.pydata.org/docs/reference/api/pandas.read_pickle.html Parameters: filepath_or_buffer: 文件名或者文件路径 字符串、路径对象(实现 os.PathLike[str] )或 file-like 对象实现二进制 readlines() 函数。 compression: str or dict, default ‘infer’ 用于on-disk 数据的即时解压缩。如果 ‘infer’ 和 ‘filepath_or_buffer’ 是 path-like，则从以下扩展名检测压缩：“.gz”、“.bz2”、“.zip”、“.xz”或“.zst”(否则不压缩)。如果使用‘zip’，ZIP 文件必须只包含一个要读入的数据文件。设置为None 不解压缩。也可以是键 ‘method’ 设置为 {'zip' , 'gzip' , 'bz2' , 'zstd' } 之一的字典，其他键值对分别转发到 zipfile.ZipFile , gzip.GzipFile , bz2.BZ2File 或 zstandard.ZstdDecompressor 。例如，可以使用自定义压缩字典为 Zstandard 解压缩传递以下内容：compression={‘method’: ‘zstd’, ‘dict_data’: my_compression_dict}。 storage_options: dict, optional 对特定存储连接有意义的额外选项，例如主机、端口、用户名、密码等。对于 HTTP(S) URL，键值对作为标头选项转发到 urllib。对于其他 URL(例如以 “s3://” 和 “gcs://” 开头)，键值对被转发到fsspec 。有关详细信息，请参阅fsspec和urllib。 ","date":"2023-07-15","objectID":"/posts/pandasnotes1/:1:0","tags":["draft"],"title":"Pandas Notes 1","uri":"/posts/pandasnotes1/"},{"categories":["Pandas"],"content":"General functions 通用函数 ","date":"2023-07-15","objectID":"/posts/pandasnotes1/:2:0","tags":["draft"],"title":"Pandas Notes 1","uri":"/posts/pandasnotes1/"},{"categories":["Pandas"],"content":"Series ","date":"2023-07-15","objectID":"/posts/pandasnotes1/:3:0","tags":["draft"],"title":"Pandas Notes 1","uri":"/posts/pandasnotes1/"},{"categories":["Pandas"],"content":"DataFrame DataFrame是一个【表格型】的数据结构，可以看做是【由Series组成的字典】（共用同一个索引）。DataFrame由按一定顺序排列的多列数据组成。设计初衷是将Series的使用场景从一维拓展到多维。 ","date":"2023-07-15","objectID":"/posts/pandasnotes1/:4:0","tags":["draft"],"title":"Pandas Notes 1","uri":"/posts/pandasnotes1/"},{"categories":["Pandas"],"content":"Constructor DataFrame[data, index, columns, dtype, copy]: 构造一个DataFrame对象 ","date":"2023-07-15","objectID":"/posts/pandasnotes1/:4:1","tags":["draft"],"title":"Pandas Notes 1","uri":"/posts/pandasnotes1/"},{"categories":["Pandas"],"content":"Attributes and underlying data DataFrame.index: 行标签(行信息)-\u003e第0列的信息 DataFrame.columns: 列标签(列信息)-\u003e 第0行的信息 DataFrame.dtypes: 返回DataFrame的数据类型 DataFrame.info([verbose, buf, max_cols, ...]): 返回df的信息 DataFrame.select_dtypes([include, exclude]): 返回DataFrame中根据columns筛选的部分数据 DataFrame.values: 以numpy数组的形式返回数据 DataFrame.axes: 返回一个list，其中是df的axes DataFrame.ndim: 返回int，代表axes/array的数量 DataFrame.shape: 返回tuple, 代表df维度 DataFrame.memory_usage([index, deep]): 返回数据内存使用情况 DataFrame.empty: 判断df是否为空 DataFrame.set_flags(*[, copy, ...]): 返回带有更新标记的df DataFrame.set_flags(*, copy=False, allows_duplicate_labels=None) 参数：allows_duplicate_labels：布尔型，可选。返回的对象是否允许重复标签。 返回：Series或DataFrame, 与调用者相同的类型。 注意：此方法返回一个新对象，该对象是与输入数据相同的视图。改变输入或输出值将反映在另一个中。此方法旨在用于方法链中。“Flags” 与 “metadata” 不同。标志反映了 pandas 对象(Series 或 DataFrame)的属性。元数据是 index 据集的属性，应存储在 DataFrame.attrs 中。 demo: \u003e\u003e\u003e df = pd.DataFrame({\"A\":[1, 2]}) \u003e\u003e\u003e df.flags.allows_duplicate_labels True \u003e\u003e\u003e df2 = df.set_flags(allows_duplicate_labels=False) \u003e\u003e\u003e df2.flags.allows_duplicate_labels False DataFrame.groupby(): ","date":"2023-07-15","objectID":"/posts/pandasnotes1/:4:2","tags":["draft"],"title":"Pandas Notes 1","uri":"/posts/pandasnotes1/"},{"categories":["Pandas"],"content":"Conversion DataFrame.astype(dtype[,copy, errors]):数据类型转换 DataFrame.convert_dtypes([infer_objects, ...]):根据现存数据推断pd.NA数据类型 DataFrame.infer_objects():根据现有数据大部分数据推断类型 DataFrame.copy([deep]):深度拷贝 demo s = pd.Series([1,2], index=[\"a\",\"b\"]) deep = s.copy()# 深拷贝 shallow = s.copy(deep=False) # 浅拷贝 DataFrame.bool():判断数据是ture还是false，只针对单个元素对象 ","date":"2023-07-15","objectID":"/posts/pandasnotes1/:4:3","tags":["draft"],"title":"Pandas Notes 1","uri":"/posts/pandasnotes1/"},{"categories":["Pandas"],"content":"Indexing，iteration DataFrame.head([n]): return the first n rows DataFrame.at[4,'B']: 用标签取值(行名为4，列名为B的值) DataFrame.iat[1,2]: 用行列的整数取值(第1行,第二列的值) DataFrame.loc['cobra':'viper', 'max_speed']: 取行名为’cobra’至’viper’, 列名为’max_speed’的值 DataFrame.iloc: 通过行列的值取值 df.iloc[0]:取第0行，所有列的值，返回series类型 df.iloc[[0]]:取得第0行，所有列的值，返回df类型 df.iloc[[0,1]]:取得第0行和第1行的所有列的值 df.iloc[:3]:取得第0，1，2行的值 df.iloc[[True, False, True]]: 用True/False标记要取的行 df.iloc[lambda x:x.index % 2 == 0]: 用lambda标记要取的行 df.iloc[0,1]:取得第0行，第1列的值 df.iloc[[0,2],[1,3]]: 取得第0行，第2行，第1列，第3列的值 df.iloc[1:3, 0:3]: 取得第1行，第2行，第0列，第1列，第2列的值 df.iloc[:, [True,False,True,False]]:取所有的行，用True/False取相应的列 df.iloc[:,lambda df:[0,2]]: 取所有的行，取第0列，第2列 df.insert(loc, column, value, allow_duplicates=False):插入相应的列 loc:(int), 列的位置 column: 列的名字，一般类型为string value: 列数据的值 df.drop():删除固定的行或者列 df.drop_duplicates(subset, keep, inplace=False,ignore_index=False):删除重复的行或者列 subset: 根据某一列的值，删除行数据 keep: 设置保留第一次出现的数据或者最后一次出现的数据 ","date":"2023-07-15","objectID":"/posts/pandasnotes1/:4:4","tags":["draft"],"title":"Pandas Notes 1","uri":"/posts/pandasnotes1/"},{"categories":["Python"],"content":"python文件相关 ","date":"2023-07-15","objectID":"/posts/pythonnotes1/:1:0","tags":["draft"],"title":"Python Notes 1","uri":"/posts/pythonnotes1/"},{"categories":["Python"],"content":"os.path模块 os.path.exists(): 判断当前目录以及文件是否存在 os.path.mkdir(): 若目录或文件不存在，则创建 import os # 目录 dirs = '/Users/joseph/work/python/' if not os.path.exists(dirs): os.makedirs(dirs) # 文件 filename = '/Users/joseph/work/python/poem.txt' if not os.path.exists(filename): os.system(r\"touch {}\".format(path))#调用系统命令行来创建文件 os.listdir()： 用于返回指定的文件夹包含的文件或文件夹的名字的列表 # 打开文件 path = \"/var/www/html/\" # 如果目录名字为中文 需要转码处理 path = unicode(path,'utf-8') dirs = os.listdir(path) # 输出所有文件和文件夹 for file in dirs: print(file) os.path.join(): 路径拼接 import os path = \"/home\" # Join various path components print(os.path.join(path, \"User/Desktop\", \"file.txt\")) # /home/User/Desktop/file.txt path = \"User/Documents\" # Join various path components print(os.path.join(path, \"/home\", \"file.txt\")) # /home/file.txt # In above example '/home' # represents an absolute path # so all previous components i.e User / Documents # are thrown away and joining continues # from the absolute path component i.e / home. print(os.path.join(path, \"Downloads\", \"file.txt\", \"/home\")) # /home # In above example '/User' and '/home' # both represents an absolute path # but '/home' is the last value # so all previous components before '/home' # will be discarded and joining will # continue from '/home' os.path.abspath(path): 返回绝对路径 os.path.basename(path): 返回文件名 os.path.commonprefix(list): 返回list(多个路径)中，所有path共有的最长的路径 os.path.dirname(path): 返回文件路径 os.path.expanduser(path): 把path中包含的\"~“和”~user\"转换成用户目录 os.path.expandvars(path): 根据环境变量的值替换path中包含的 “$name” 和 “${name}” os.path.getatime(path): 返回最近访问时间(浮点型秒数) os.path.getmtime(path): 返回最近文件修改时间 os.path.getctime(path): 返回文件 path 创建时间 os.path.getsize(path): 返回文件大小，如果文件不存在就返回错误 os.path.isfile(path): 判断路径是否为文件 os.path.isdir(path): 判断路径是否为目录 os.path.islink(path): 判断路径是否为链接 os.path.ismount(path): 判断路径是否为挂载点 os.path.normcase(path): 转换path的大小写和斜杠 os.path.normpath(path): 规范path字符串形式 os.path.realpath(path): 返回path的真实路径 os.path.relpath(path[, start]): 从start开始计算相对路径 os.path.samefile(path1, path2): 判断目录或文件是否相同 os.path.sameopenfile(fp1, fp2): 判断fp1和fp2是否指向同一文件 os.path.samestat(stat1, stat2): 判断stat tuple stat1和stat2是否指向同一个文件 os.path.split(path): 把路径分割成 dirname 和 basename，返回一个元组 os.path.splitdrive(path): 一般用在 windows 下，返回驱动器名和路径组成的元组 os.path.splitext(path): 分割路径，返回路径名和文件扩展名的元组 os.path.splitunc(path): 把路径分割为加载点与文件 os.path.walk(path, visit, arg): 遍历path，进入每个目录都调用visit函数，visit函数必须有3个参数(arg, dirname, names)，dirname表示当前目录的目录名，names代表当前目录下的所有文件名，args则为walk的第三个参数 os.walk(path,topdown=True,onerror=None): 函数返回一个元组，含有三个元素。这三个元素分别是：每次遍历的路径名、路径下子目录列表、目录下文件列表。 path = 'xxx/xxx' for root, dirs, files in os.walk(path): print(root) # path以及path下的目录 print(dirs) # path下的文件夹 print(files) # path下每个文件夹中的文件 区别：os.path.walk()与os.walk()产生的文件名列表并不相同.os.walk()产生目录树下的目录路径和文件路径，而os.path.walk()只产生文件路径（是子目录与文件的混合列表）。 ref: https://www.cnblogs.com/zmlctt/p/4222621.html os.path.supports_unicode_filenames: 设置是否支持unicode路径名 ","date":"2023-07-15","objectID":"/posts/pythonnotes1/:1:1","tags":["draft"],"title":"Python Notes 1","uri":"/posts/pythonnotes1/"},{"categories":["draft"],"content":"ref: [1] https://chenllliang.github.io/2020/02/04/dataloader/ [2] https://blog.csdn.net/zyq12345678/article/details/90268668 [3] https://cloud.tencent.com/developer/article/1877393 ","date":"2023-07-15","objectID":"/posts/datasetanddataloader/:0:0","tags":["draft"],"title":"PyTorch Dataset And DataLoader","uri":"/posts/datasetanddataloader/"},{"categories":["draft"],"content":"Dataset PyTorch为我们提供的两个Dataset和DataLoader类分别负责可被Pytorch使用的数据集的创建以及向训练传递数据的任务。如果想个性化自己的数据集或者数据传递方式，也可以自己重写子类。 Dataset是DataLoader实例化的一个参数，所以这篇文章会先从Dataset的源代码讲起，然后讲到DataLoader，关注主要函数，少细枝末节，目的是使大家学会自定义自己的数据集。 ","date":"2023-07-15","objectID":"/posts/datasetanddataloader/:1:0","tags":["draft"],"title":"PyTorch Dataset And DataLoader","uri":"/posts/datasetanddataloader/"},{"categories":["draft"],"content":"什么时候使用Dataset CIFAR10是CV训练中经常使用到的一个数据集，在PyTorch中CIFAR10是一个写好的Dataset，我们使用时只需以下代码： data = datasets.CIFAR10(\"./data/\", transform=transform, train=True, download=True) datasets.CIFAR10就是一个Datasets子类，data是这个类的一个实例。 我们有的时候需要用自己在一个文件夹中的数据作为数据集，这个时候，我们可以使用ImageFolder这个方便的API。 FaceDataset = datasets.ImageFolder('./data', transform=img_transform) ","date":"2023-07-15","objectID":"/posts/datasetanddataloader/:1:1","tags":["draft"],"title":"PyTorch Dataset And DataLoader","uri":"/posts/datasetanddataloader/"},{"categories":["draft"],"content":"如何定义一个自己的数据集合 torch.utils.data.dataset 是一个表示数据集的抽象类。任何自定义的数据集都需要继承这个类并覆写相关方法。 所谓数据集，其实就是一个负责处理索引(index)到样本(sample)映射的一个类(class)。 Pytorch提供两种数据集： Map式数据集 Iterable式数据集 Map式数据集 一个Map式的数据集必须要重写__getitem__(self, index), len(self) 两个内建方法，用来表示从索引到样本的映射(Map). 这样一个数据集dataset，举个例子，当使用dataset[idx]命令时，可以在你的硬盘中读取你的数据集中第idx张图片以及其标签（如果有的话）;len(dataset)则会返回这个数据集的容量。 例子-1： 自己实验中写的一个例子：这里我们的图片文件储存在“./data/faces/”文件夹下，图片的名字并不是从1开始，而是从final_train_tag_dict.txt这个文件保存的字典中读取，label信息也是用这个文件中读取。大家可以照着上面的注释阅读这段代码。 from torch.utils import data import numpy as np from PIL import Image class face_dataset(data.Dataset): def __init__(self): self.file_path = './data/faces/' f=open(\"final_train_tag_dict.txt\",\"r\") self.label_dict=eval(f.read()) f.close() def __getitem__(self,index): label = list(self.label_dict.values())[index-1] img_id = list(self.label_dict.keys())[index-1] img_path = self.file_path+str(img_id)+\".jpg\" img = np.array(Image.open(img_path)) return img,label def __len__(self): return len(self.label_dict) 下面我们看一下官方MNIST数据集的例子 class MNIST(data.Dataset): \"\"\"`MNIST \u003chttp://yann.lecun.com/exdb/mnist/\u003e`_ Dataset. Args: root (string): Root directory of dataset where ``processed/training.pt`` and ``processed/test.pt`` exist. train (bool, optional): If True, creates dataset from ``training.pt``, otherwise from ``test.pt``. download (bool, optional): If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again. transform (callable, optional): A function/transform that takes in an PIL image and returns a transformed version. E.g, ``transforms.RandomCrop`` target_transform (callable, optional): A function/transform that takes in the target and transforms it. \"\"\" urls = [ 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz', 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz', 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz', 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz', ] raw_folder = 'raw' processed_folder = 'processed' training_file = 'training.pt' test_file = 'test.pt' classes = ['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine'] class_to_idx = {_class: i for i, _class in enumerate(classes)} @property def targets(self): if self.train: return self.train_labels else: return self.test_labels def __init__(self, root, train=True, transform=None, target_transform=None, download=False): self.root = os.path.expanduser(root) self.transform = transform self.target_transform = target_transform self.train = train # training set or test set if download: self.download() if not self._check_exists(): raise RuntimeError('Dataset not found.' + ' You can use download=True to download it') if self.train: self.train_data, self.train_labels = torch.load( os.path.join(self.root, self.processed_folder, self.training_file)) else: self.test_data, self.test_labels = torch.load( os.path.join(self.root, self.processed_folder, self.test_file)) def __getitem__(self, index): \"\"\" Args: index (int): Index Returns: tuple: (image, target) where target is index of the target class. \"\"\" if self.train: img, target = self.train_data[index], self.train_labels[index] else: img, target = self.test_data[index], self.test_labels[index] # doing this so that it is consistent with all other datasets # to return a PIL Image img = Image.fromarray(img.numpy(), mode='L') if self.transform is not None: img = self.transform(img) if self.target_transform is not None: target = self.target_transform(target) return img, target def __len__(self): if self.train: return len(self.train_data) else: return len(self.test_data) def _check_exists(self): return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and \\ os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file)) def download(self): \"\"\"Download the MNIST data if it doesn't exist in processed_folder already.\"\"\" from s","date":"2023-07-15","objectID":"/posts/datasetanddataloader/:1:2","tags":["draft"],"title":"PyTorch Dataset And DataLoader","uri":"/posts/datasetanddataloader/"},{"categories":["draft"],"content":"Iterable数据集 一个Iterable（迭代）式数据集是抽象类data.IterableDataset的子类，并且覆写了__iter__方法成为一个迭代器。这种数据集主要用于数据大小未知，或者以流的形式的输入，本地文件不固定的情况，需要以迭代的方式来获取样本索引。 关于迭代器与生成器的知识可以参见博主的另一篇文章Python迭代器与生成器介绍及在Pytorch源码中应用[https://chenllliang.github.io/2020/02/06/PyIter/]。 ","date":"2023-07-15","objectID":"/posts/datasetanddataloader/:1:3","tags":["draft"],"title":"PyTorch Dataset And DataLoader","uri":"/posts/datasetanddataloader/"},{"categories":["draft"],"content":"DataLoader Data loader. Combines a dataset and a sampler, and provides an iterable over the given dataset. –PyTorch Documents 一般来说PyTorch中深度学习训练的流程是这样的： 创建Dateset Dataset传递给DataLoader DataLoader迭代产生训练数据提供给模型 对应的一般都会有这三部分代码 # 创建Dateset(可以自定义) dataset = face_dataset # Dataset部分自定义过的face_dataset # Dataset传递给DataLoader dataloader = torch.utils.data.DataLoader(dataset,batch_size=64,shuffle=False,num_workers=8) # DataLoader迭代产生训练数据提供给模型 for i in range(epoch): for index,(img,label) in enumerate(dataloader): pass 到这里应该就PyTorch的数据集和数据传递机制应该就比较清晰明了了。Dataset负责建立索引到样本的映射，DataLoader负责以特定的方式从数据集中迭代的产生 一个个batch的样本集合。在enumerate过程中实际上是dataloader按照其参数sampler规定的策略调用了其dataset的getitem方法。 ","date":"2023-07-15","objectID":"/posts/datasetanddataloader/:2:0","tags":["draft"],"title":"PyTorch Dataset And DataLoader","uri":"/posts/datasetanddataloader/"},{"categories":["draft"],"content":"参数介绍 先看一下实例化一个DataLoader所需的参数，我们只关注几个重点即可。 DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None, num_workers=0, collate_fn=None, pin_memory=False, drop_last=False, timeout=0, worker_init_fn=None) 参数介绍: dataset (Dataset) – 定义好的Map式或者Iterable式数据集。 batch_size (python:int, optional) – 一个batch含有多少样本 (default: 1)。 shuffle (bool, optional) – 每一个epoch的batch样本是相同还是随机 (default: False)。 sampler (Sampler, optional) – 决定数据集中采样的方法. 如果有，则shuffle参数必须为False。 batch_sampler (Sampler, optional) – 和 sampler 类似，但是一次返回的是一个batch内所有样本的index。和 batch_size, shuffle, sampler, and drop_last 三个参数互斥。 num_workers (python:int, optional) – 多少个子程序同时工作来获取数据，多线程。 (default: 0) collate_fn (callable, optional) – 合并样本列表以形成小批量。 pin_memory (bool, optional) – 如果为True，数据加载器在返回前将张量复制到CUDA固定内存中。 drop_last (bool, optional) – 如果数据集大小不能被batch_size整除，设置为True可删除最后一个不完整的批处理。如果设为False并且数据集的大小不能被batch_size整除，则最后一个batch将更小。(default: False) timeout (numeric, optional) – 如果是正数，表明等待从worker进程中收集一个batch等待的时间，若超出设定的时间还没有收集到，那就不收集这个内容了。这个numeric应总是大于等于0。 (default: 0) worker_init_fn (callable, optional) – 每个worker初始化函数 (default: None) dataset 没什么好说的，很重要，需要按照前面所说的两种dataset定义好，完成相关函数的重写。 batch_size 也没啥好说的，就是训练的一个批次的样本数。 shuffle 表示每一个epoch中训练样本的顺序是否相同，一般True。 ","date":"2023-07-15","objectID":"/posts/datasetanddataloader/:3:0","tags":["draft"],"title":"PyTorch Dataset And DataLoader","uri":"/posts/datasetanddataloader/"},{"categories":["draft"],"content":"采样器 sampler 重点参数，采样器，是一个迭代器。PyTorch提供了多种采样器，用户也可以自定义采样器。 所有sampler都是继承 torch.utils.data.sampler.Sampler这个抽象类。 关于迭代器的基础知识在博主这篇文章中可以找到Python迭代器与生成器介绍及在Pytorch源码中应用。[] class Sampler(object): # \"\"\"Base class for all Samplers. # Every Sampler subclass has to provide an __iter__ method, providing a way # to iterate over indices of dataset elements, and a __len__ method that # returns the length of the returned iterators. # \"\"\" # 一个 迭代器 基类 def __init__(self, data_source): pass def __iter__(self): raise NotImplementedError def __len__(self): raise NotImplementedError PyTorch自带的Sampler SequentialSampler RandomSampler SubsetRandomSampler WeightedRandomSampler SequentialSampler 很好理解就是顺序采样器。 其原理是首先在初始化的时候拿到数据集data_source，之后在__iter__方法中首先得到一个和data_source一样长度的range可迭代器。每次只会返回一个索引值。 class SequentialSampler(Sampler): # r\"\"\"Samples elements sequentially, always in the same order. # Arguments: # data_source (Dataset): dataset to sample from # \"\"\" # 产生顺序 迭代器 def __init__(self, data_source): self.data_source = data_source def __iter__(self): return iter(range(len(self.data_source))) def __len__(self): return len(self.data_source) 参数作用: data_source: 同上 num_sampler: 指定采样的数量，默认是所有。 replacement: 若为True，则表示可以重复采样，即同一个样本可以重复采样，这样可能导致有的样本采样不到。所以此时我们可以设置num_samples来增加采样数量使得每个样本都可能被采样到。 class RandomSampler(Sampler): # r\"\"\"Samples elements randomly. If without replacement, then sample from a shuffled dataset. # If with replacement, then user can specify ``num_samples`` to draw. # Arguments: # data_source (Dataset): dataset to sample from # num_samples (int): number of samples to draw, default=len(dataset) # replacement (bool): samples are drawn with replacement if ``True``, default=False # \"\"\" def __init__(self, data_source, replacement=False, num_samples=None): self.data_source = data_source self.replacement = replacement self.num_samples = num_samples if self.num_samples is not None and replacement is False: raise ValueError(\"With replacement=False, num_samples should not be specified, \" \"since a random permute will be performed.\") if self.num_samples is None: self.num_samples = len(self.data_source) if not isinstance(self.num_samples, int) or self.num_samples \u003c= 0: raise ValueError(\"num_samples should be a positive integeral \" \"value, but got num_samples={}\".format(self.num_samples)) if not isinstance(self.replacement, bool): raise ValueError(\"replacement should be a boolean value, but got \" \"replacement={}\".format(self.replacement)) def __iter__(self): n = len(self.data_source) if self.replacement: return iter(torch.randint(high=n, size=(self.num_samples,), dtype=torch.int64).tolist()) return iter(torch.randperm(n).tolist()) def __len__(self): return len(self.data_source) 这个采样器常见的使用场景是将训练集划分成训练集和验证集: class SubsetRandomSampler(Sampler): # r\"\"\"Samples elements randomly from a given list of indices, without replacement. # Arguments: # indices (sequence): a sequence of indices # \"\"\" def __init__(self, indices): self.indices = indices def __iter__(self): return (self.indices[i] for i in torch.randperm(len(self.indices))) def __len__(self): return len(self.indices) batch_sampler 前面的采样器每次都只返回一个索引，但是我们在训练时是对批量的数据进行训练，而这个工作就需要BatchSampler来做。也就是说BatchSampler的作用就是将前面的Sampler采样得到的索引值进行合并，当数量等于一个batch大小后就将这一批的索引值返回。 class BatchSampler(Sampler): # Wraps another sampler to yield a mini-batch of indices. # Args: # sampler (Sampler): Base sampler. # batch_size (int): Size of mini-batch. # drop_last (bool): If ``True``, the sampler will drop the last batch if # its size would be less than ``batch_size`` # Example: # \u003e\u003e\u003e list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=False)) # [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]] # \u003e\u003e\u003e list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=True)) # [[0, 1, 2], [3, 4, 5], [6, 7, 8]] # 批次采样 def __init__(self, sampler, batch_size, drop_last): if not isinstance(sampler, Sampler): raise ValueError(\"sampler should be an instance of \" \"torch.utils.data.Sampler, but got sampler={}\" .format(sampler)) if","date":"2023-07-15","objectID":"/posts/datasetanddataloader/:3:1","tags":["draft"],"title":"PyTorch Dataset And DataLoader","uri":"/posts/datasetanddataloader/"},{"categories":["draft"],"content":"多线程 num_workers 参数表示同时参与数据读取的线程数量，多线程技术可以加快数据读取，提供GPU/CPU利用率。 未来会出一篇文章讲一讲PyTorch多线程实现的原理。 ","date":"2023-07-15","objectID":"/posts/datasetanddataloader/:3:2","tags":["draft"],"title":"PyTorch Dataset And DataLoader","uri":"/posts/datasetanddataloader/"},{"categories":["draft"],"content":"DataLoader 和 Dataset 简单举例 # construct dataset import torch from torch.utils.data import Dataset,DataLoader class MyDataset(Dataset): def __init__(self): self.data = torch.tensor([[1,2,3],[2,3,4],[3,4,5],[4,5,6]]) self.label = torch.LongTensor([1,1,0,0]) def __getitem__(self,index): return self.data[index],self.label[index] def __len__(self): return len(self.data) # dataloader mydataloader = DataLoader(dataset=mydataset, batch_size = 2, shuffle=True) for i, (data, label) in enumerate(mydataloader): print(data, label) ","date":"2023-07-15","objectID":"/posts/datasetanddataloader/:3:3","tags":["draft"],"title":"PyTorch Dataset And DataLoader","uri":"/posts/datasetanddataloader/"},{"categories":["draft"],"content":"DEMO1 - MLP’s Dataset and DataLoader dim_output = 2 class TrainValidDataset(Dataset): ''' Args: - root_dir (string): Directory containing all folders with different dates, each folder containing .cruise.h5 data files. ''' def __init__(self, list_of_files): self.list_of_files_ = list_of_files self.data_size_until_this_file_ = [] self.dataset_size = 0 for file in self.list_of_files_: with h5py.File(file, 'r') as h5_file: data_size = h5_file[list(h5_file.keys())[0]].shape[0] self.dataset_size += data_size self.data_size_until_this_file_.append(self.dataset_size) print ('Total size of dataset: {}'.format(self.data_size_until_this_file_)) def __len__(self): return self.dataset_size def __getitem__(self, index): bin_idx = self.FindBin(index, 0, len( self.data_size_until_this_file_)-1) with h5py.File(self.list_of_files_[bin_idx], 'r') as h5_file: idx_offset = self.data_size_until_this_file_[bin_idx] - \\ h5_file[list(h5_file.keys())[0]].shape[0] data = h5_file[list(h5_file.keys())[0]][index-idx_offset] label = data[-dim_output:] label[0] = (label[0] \u003e 0.0).astype(float) return data[:-dim_output], label # Binary search to expedite the data-loading process. def FindBin(self, index, start, end): if (start == end): return start mid = int((start+end)/2.0) if (self.data_size_until_this_file_[mid] \u003c= index): return self.FindBin(index, mid+1, end) else: return self.FindBin(index, start, mid) # search all the files in the directory def getListOfFiles(dirName): listOfFiles = os.listdir(dirName) allFiles = list() for entry in listOfFiles: fullPath = os.path.join(dirName, entry) if os.path.isdir(fullPath): allFiles = allFiles + getListOfFiles(fullPath) else: allFiles.append(fullPath) return allFiles if __name__ == '__main__': list_of_training_files = getListOfFiles('data') train_dataset = TrainValidDataset(list_of_training_files) myDataLoader = DataLoader(dataset=train_dataset, batch_size=2, drop_last=True, shuffle=True) for i, (data, label) in enumerate(myDataLoader): print(data.shape) ","date":"2023-07-15","objectID":"/posts/datasetanddataloader/:4:0","tags":["draft"],"title":"PyTorch Dataset And DataLoader","uri":"/posts/datasetanddataloader/"},{"categories":["draft"],"content":"DEMO2 - LaneGCN’s Dataset and DataLoader dataset description: class ArgoDataset(Dataset): def __init__(self, split, config, train=True): self.config = config self.train = train if 'preprocess' in config and config['preprocess']: if train: self.split = np.load(self.config['preprocess_train'], allow_pickle=True) else: self.split = np.load(self.config['preprocess_val'], allow_pickle=True) else: self.avl = ArgoverseForecastingLoader(split) self.avl.seq_list = sorted(self.avl.seq_list) self.am = ArgoverseMap() if 'raster' in config and config['raster']: #TODO: DELETE self.map_query = MapQuery(config['map_scale']) def __getitem__(self, idx): if 'preprocess' in self.config and self.config['preprocess']: data = self.split[idx] if self.train and self.config['rot_aug']: new_data = dict() for key in ['city', 'orig', 'gt_preds', 'has_preds']: if key in data: new_data[key] = ref_copy(data[key]) dt = np.random.rand() * self.config['rot_size']#np.pi * 2.0 theta = data['theta'] + dt new_data['theta'] = theta new_data['rot'] = np.asarray([ [np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]], np.float32) rot = np.asarray([ [np.cos(-dt), -np.sin(-dt)], [np.sin(-dt), np.cos(-dt)]], np.float32) new_data['feats'] = data['feats'].copy() new_data['feats'][:, :, :2] = np.matmul(new_data['feats'][:, :, :2], rot) new_data['ctrs'] = np.matmul(data['ctrs'], rot) graph = dict() for key in ['num_nodes', 'turn', 'control', 'intersect', 'pre', 'suc', 'lane_idcs', 'left_pairs', 'right_pairs', 'left', 'right']: graph[key] = ref_copy(data['graph'][key]) graph['ctrs'] = np.matmul(data['graph']['ctrs'], rot) graph['feats'] = np.matmul(data['graph']['feats'], rot) new_data['graph'] = graph data = new_data else: new_data = dict() for key in ['city', 'orig', 'gt_preds', 'has_preds', 'theta', 'rot', 'feats', 'ctrs', 'graph']: if key in data: new_data[key] = ref_copy(data[key]) data = new_data if 'raster' in self.config and self.config['raster']: data.pop('graph') x_min, x_max, y_min, y_max = self.config['pred_range'] cx, cy = data['orig'] region = [cx + x_min, cx + x_max, cy + y_min, cy + y_max] raster = self.map_query.query(region, data['theta'], data['city']) data['raster'] = raster return data data = self.read_argo_data(idx) data = self.get_obj_feats(data) data['idx'] = idx if 'raster' in self.config and self.config['raster']: x_min, x_max, y_min, y_max = self.config['pred_range'] cx, cy = data['orig'] region = [cx + x_min, cx + x_max, cy + y_min, cy + y_max] raster = self.map_query.query(region, data['theta'], data['city']) data['raster'] = raster return data data['graph'] = self.get_lane_graph(data) return data def __len__(self): if 'preprocess' in self.config and self.config['preprocess']: return len(self.split) else: return len(self.avl) def read_argo_data(self, idx): city = copy.deepcopy(self.avl[idx].city) \"\"\"TIMESTAMP,TRACK_ID,OBJECT_TYPE,X,Y,CITY_NAME\"\"\" df = copy.deepcopy(self.avl[idx].seq_df) agt_ts = np.sort(np.unique(df['TIMESTAMP'].values)) mapping = dict() for i, ts in enumerate(agt_ts): mapping[ts] = i trajs = np.concatenate(( df.X.to_numpy().reshape(-1, 1), df.Y.to_numpy().reshape(-1, 1)), 1) steps = [mapping[x] for x in df['TIMESTAMP'].values] steps = np.asarray(steps, np.int64) objs = df.groupby(['TRACK_ID', 'OBJECT_TYPE']).groups keys = list(objs.keys()) obj_type = [x[1] for x in keys] agt_idx = obj_type.index('AGENT') idcs = objs[keys[agt_idx]] agt_traj = trajs[idcs] agt_step = steps[idcs] del keys[agt_idx] ctx_trajs, ctx_steps = [], [] for key in keys: idcs = objs[key] ctx_trajs.append(trajs[idcs]) ctx_steps.append(steps[idcs]) data = dict() data['city'] = city data['trajs'] = [agt_traj] + ctx_trajs data['steps'] = [agt_step] + ctx_steps return data def get_obj_feats(self, data): orig = data['trajs'][0][19].copy().astype(np.float32) if self.train and self.config['rot_aug']: theta = np.random.rand() * np.pi * 2.0 else: pre = data['trajs'][0][18] - orig theta = np.pi - np.arctan2(pre[1], pre[0]) rot = np.asarray([ [np.cos(theta), -np","date":"2023-07-15","objectID":"/posts/datasetanddataloader/:5:0","tags":["draft"],"title":"PyTorch Dataset And DataLoader","uri":"/posts/datasetanddataloader/"},{"categories":["PyTorch"],"content":"Torch 基本函数 ","date":"2023-07-15","objectID":"/posts/pytorchnotes/:1:0","tags":["draft"],"title":"PyTorch Notes","uri":"/posts/pytorchnotes/"},{"categories":["PyTorch"],"content":"1. torch.einsum() torch.einsum(equation, *operands)-\u003eTensor:爱因斯坦求和 ref1: 算子部署: https://blog.csdn.net/HW140701/article/details/120654252 ref2: 例子: https://zhuanlan.zhihu.com/p/361209187 三条基本规则: 规则一: equation 箭头左边，在不同输入之间重复出现的索引表示，把输入张量沿着该维度做乘法操作，比如还是以上面矩阵乘法为例， “ik,kj-\u003eij”，k 在输入中重复出现，所以就是把 a 和 b 沿着 k 这个维度作相乘操作； 规则二: 只出现在 equation 箭头左边的索引，表示中间计算结果需要在这个维度上求和，也就是上面提到的求和索引； 规则三: equation 箭头右边的索引顺序可以是任意的，比如上面的 “ik,kj-\u003eij” 如果写成 “ik,kj-\u003eji”，那么就是返回输出结果的转置，用户只需要定义好索引的顺序，转置操作会在 einsum 内部完成 特殊规则: equation 可以不写包括箭头在内的右边部分，那么在这种情况下，输出张量的维度会根据默认规则推导。就是把输入中只出现一次的索引取出来，然后按字母表顺序排列，比如上面的矩阵乘法 “ik,kj-\u003eij” 也可以简化为 “ik,kj”，根据默认规则，输出就是 “ij” 与原来一样； equation 中支持 “…” 省略号，用于表示用户并不关心的索引。比如只对一个高维张量的最后两维做转置可以这么写： a = torch.randn(2,3,5,7,9) # i = 7, j = 9 b = torch.einsum('...ij-\u003e...ji', [a]) ","date":"2023-07-15","objectID":"/posts/pytorchnotes/:1:1","tags":["draft"],"title":"PyTorch Notes","uri":"/posts/pytorchnotes/"},{"categories":["PyTorch"],"content":"2. torch.permute()/torch.transpose() torch.permute(dim0, dim1, dim2):用于调换不同维度的顺序 torch.transpose(input, dim0, dim1):交换矩阵的两个维度 ","date":"2023-07-15","objectID":"/posts/pytorchnotes/:1:2","tags":["draft"],"title":"PyTorch Notes","uri":"/posts/pytorchnotes/"},{"categories":["PyTorch"],"content":"3. torch.rand() torch.rand(dim0, dim1):生成dim0 x dim1的tensor ","date":"2023-07-15","objectID":"/posts/pytorchnotes/:1:3","tags":["draft"],"title":"PyTorch Notes","uri":"/posts/pytorchnotes/"},{"categories":["PyTorch"],"content":"4. torch.size()/torch.shape torch.size():返回tensor的size torch.shape:返回tensor的size ","date":"2023-07-15","objectID":"/posts/pytorchnotes/:1:4","tags":["draft"],"title":"PyTorch Notes","uri":"/posts/pytorchnotes/"},{"categories":["PyTorch"],"content":"5. torch.tensordot() ref: tensordot()和einsum()的区别: https://blog.csdn.net/Eric_1993/article/details/105670381 torch.tensordot(tensor1， tensor2， axes=([dim1,dim2],[dim0, dim1])): 将axes指定的子数组进行点乘, axes 指定具体的维度. ","date":"2023-07-15","objectID":"/posts/pytorchnotes/:1:5","tags":["draft"],"title":"PyTorch Notes","uri":"/posts/pytorchnotes/"},{"categories":["PyTorch"],"content":"6. torch.transpose() torch.transpose(tensor, dim0, dim2) —\u003e Tensor:在dim0和dim1方向上转置 ###7. torch.index_add_() Tensor.index_add_(dim, index, source, *, alpha=1) → Tensor demo: \u003e\u003e\u003e x = torch.ones(5, 3) \u003e\u003e\u003e t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float) \u003e\u003e\u003e index = torch.tensor([0, 4, 2]) \u003e\u003e\u003e x.index_add_(0, index, t) tensor([[ 2., 3., 4.], [ 1., 1., 1.], [ 8., 9., 10.], [ 1., 1., 1.], [ 5., 6., 7.]]) \u003e\u003e\u003e x.index_add_(0, index, t, alpha=-1) tensor([[ 1., 1., 1.], [ 1., 1., 1.], [ 1., 1., 1.], [ 1., 1., 1.], [ 1., 1., 1.]]) ","date":"2023-07-15","objectID":"/posts/pytorchnotes/:1:6","tags":["draft"],"title":"PyTorch Notes","uri":"/posts/pytorchnotes/"},{"categories":["PyTorch"],"content":"Torch NN Module import torch from torch import nn from torch import functional as F ","date":"2023-07-15","objectID":"/posts/pytorchnotes/:2:0","tags":["draft"],"title":"PyTorch Notes","uri":"/posts/pytorchnotes/"},{"categories":["PyTorch"],"content":"1. nn.Conv1d() torch.nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None) Shape: - Input: $(N, C_{in}, L_{in})$ or $(C_{in}, L_{in})$ - Output: $(N, C_{in}, L_{in})$ or $(C_{in}, L_{in})$, where $$L_{out} = \\frac{L_{in} + 2 \\cdot \\text{padding} - \\text{dilation} \\cdot (\\text{kernel_size} - 1) - 1}{stride}$$ Demo: m = nn.Conv1d(16, 33, 3, stride=2) input = torch.randn(20, 16, 50) # B x C x H or N x C x L output = m(input) print(output.shape) # torch.Size([20, 33, 24]) ","date":"2023-07-15","objectID":"/posts/pytorchnotes/:2:1","tags":["draft"],"title":"PyTorch Notes","uri":"/posts/pytorchnotes/"},{"categories":["PyTorch"],"content":"2. nn.Conv2d() torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None) Shape: Input: $(N, C_{\\text in}, H_{\\text in}, W_{\\text in})$ or $(C_{\\text in}, H_{\\text in}, W_{\\text in})$ - Output: $(N, C_{\\text out}, H_{\\text out}, W_{\\text out})$ or $(C_{\\text out}, H_{\\text out}, W_{\\text out})$, where $$ H_{out} = \\frac{H_{in} + 2 \\cdot \\text{padding[0]} - \\text{dilation[0]} \\cdot (\\text{kernel_size[0]} - 1) - 1}{stride[0]} + 1 $$ $$ W_{out} = \\frac{W_{in} + 2 \\cdot \\text{padding[1]} - \\text{dilation[1]} \\cdot (\\text{kernel_size[1]} - 1) - 1}{stride[1]} + 1 $$ Demo: # With square kernels and equal stride m = nn.Conv2d(16, 33, 3, stride=2) # non-square kernels and unequal stride and with padding m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2)) # output.shape: 20 x 33 x 28 x 100 # non-square kernels and unequal stride and with padding and dilation m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1)) # output.shape: 20 x 33 x 26 x 100 input = torch.randn(20, 16, 50, 100) output = m(input) # ","date":"2023-07-15","objectID":"/posts/pytorchnotes/:2:2","tags":["draft"],"title":"PyTorch Notes","uri":"/posts/pytorchnotes/"},{"categories":["PyTorch"],"content":"3. nn.functional.interpolate() torch.nn.functional.interpolate(input, size=None, scale_factor=None, mode='nearest', align_corners=None, recompute_scale_factor=None, antialias=False) ","date":"2023-07-15","objectID":"/posts/pytorchnotes/:2:3","tags":["draft"],"title":"PyTorch Notes","uri":"/posts/pytorchnotes/"},{"categories":["PyTorch"],"content":"4. nn.functional.ReLU() $$ \\text{ReLU} = (x)^+ = \\max {(0,x)}$$ torch.nn.ReLU(inplace=False) 作用: Sigmoid的导数只有在0附近的时候有比较好的激活性，在正负饱和区的梯度都接近于0，所以这会造成梯度弥散，而ReLU函数在大于0的部分梯度为常数，所以不会产生梯度弥散现象。 ReLU函数在负半区的导数为0 ，所以一旦神经元激活值进入负半区，那么梯度就会为0，而正值不变，这种操作被成为单侧抑制。（也就是说：在输入是负值的情况下，它会输出0，那么神经元就不会被激活。这意味着同一时间只有部分神经元会被激活，从而使得网络很稀疏，进而对计算来说是非常有效率的。）正因为有了这单侧抑制，才使得神经网络中的神经元也具有了稀疏激活性。尤其体现在深度神经网络模型(如CNN)中，当模型增加N层之后，理论上ReLU神经元的激活率将降低2的N次方倍。 relu函数的导数计算更快，程序实现就是一个if-else语句，而sigmoid函数要进行浮点四则运算。 Shape: Input: $(∗)$, where $*$ means any number of dimensions. Output: $(∗)$, same shape as the input. Demo: m = nn.ReLU() input = torch.randn(2) output = m(input) # An implementation of CReLU - https://arxiv.org/abs/1603.05201 m = nn.ReLU() input = torch.randn(2).unsqueeze(0) output = torch.cat((m(input),m(-input))) ","date":"2023-07-15","objectID":"/posts/pytorchnotes/:2:4","tags":["draft"],"title":"PyTorch Notes","uri":"/posts/pytorchnotes/"},{"categories":["PyTorch"],"content":"5. nn.MaxPool2d() torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False) Shape: Input: $(N, C, H_{in}, W_{in})$ or $(C, H_{in}, W_{in})$ Output: $(N, C, H_{out}, W_{out})$ or $(C, H_{out}, W_{out})$ where, $$ H_{out} = \\frac{H_{in} + 2 * \\text{padding}[0] - \\text{dilation}[0] * (\\text{kernel_size}[0]-1) - 1}{\\text{stride}[0]} + 1$$ $$ W_{out} = \\frac{W_{in} + 2 * \\text{padding}[1] - \\text{dilation}[1] * (\\text{kernel_size}[1]-1) - 1}{\\text{stride}[1]} + 1$$ demo: # pool of square window of size=3, stride=2 m = nn.MaxPool2d(3, stride=2) # pool of non-square window m = nn.MaxPool2d((3, 2), stride=(2, 1)) input = torch.randn(20, 16, 50, 32) output = m(input) # 20 16 24 31 ","date":"2023-07-15","objectID":"/posts/pytorchnotes/:2:5","tags":["draft"],"title":"PyTorch Notes","uri":"/posts/pytorchnotes/"},{"categories":["PyTorch"],"content":"6. nn.AvgPool2d() torch.nn.AvgPool2d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None) Shape: Input: $(N, C, H_{in}, W_{in})$ or $(C, H_{in}, W_{in})$ Output: $(N, C, H_{out}, W_{out})$ or $(C, H_{out}, W_{out})$ where, $$ H_{out} = \\frac{H_{in} + 2 * \\text{padding}[0] - (\\text{kernel_size}[0])}{\\text{stride}[0]} + 1$$ $$ W_{out} = \\frac{W_{in} + 2 * \\text{padding}[1] - (\\text{kernel_size}[1])}{\\text{stride}[1]} + 1$$ demo: # pool of square window of size=3, stride=2 m = nn.AvgPool2d(3, stride=2) # pool of non-square window m = nn.AvgPool2d((3, 2), stride=(2, 1)) input = torch.randn(20, 16, 50, 32) output = m(input) # 20 16, 24 31 ","date":"2023-07-15","objectID":"/posts/pytorchnotes/:2:6","tags":["draft"],"title":"PyTorch Notes","uri":"/posts/pytorchnotes/"},{"categories":["PyTorch"],"content":"torch.cuda ref link: https://zhuanlan.zhihu.com/p/76908135 torch.cuda.current_device(): 返回当前选择的设备的索引 torch.cuda.current_stream(): 返回参数设备的当前的Stream torch.cuda.default_stream(): 返回当前参数设备的Stream CLASS torch.cuda.device: 可以改变选择的设备的上下文管理器 Parameters：device (torch.device or int) – device index to select. It’s a no-op if this argument is a negative integer or None. torch.cuda.device_count(): 返回可使用GPU的数量 CLASS torch.cuda.device_of(obj) Context-manager 将参数对象的设备改成当前的设备。你可以使用张量或者存储作为参数。如果传入的对象没有分配在GPU上，这个操作是无效的。 torch.cuda.empty_cache() 释放caching allocator当前持有的所有未占用的cached memory，使其可以用在其他GPU应用且可以在 nvidia-smi可视化。 注意：empty_cache() 并不会增加PyTorch可以使用的GPU显存的大小。 查看 Memory management 来获取更多的GPU显存管理的信息。 torch.cuda.get_device_capability(device=None) Gets the cuda capability of a device. Parameters：device (torch.device or int, optional) – device for which to return the device capability. This function is a no-op if this argument is a negative integer. It uses the current device, given bycurrent_device(), if device is None (default). Returns：the major and minor cuda capability of the device Return type ： tuple(int, int) torch.cuda.get_device_name(device=None) torch.cuda.init() 初始化PyTorch的CUDA状态。如果你通过C API与PyTorch进行交互，你可能需要显式调用这个方法。只有CUDA的初始化完成，CUDA的功能才会绑定到Python。用户一般不应该需要这个，因为所有PyTorch的CUDA方法都会自动在需要的时候初始化CUDA。如果CUDA的状态已经初始化了，将不起任何作用。 [torch.cuda.is_available()] torch.cuda.max_memory_allocated(device=None) Returns the maximum GPU memory occupied by tensors in bytes for a given device. torch.cuda.max_memory_cached(device=None) torch.cuda.memory_allocated(device=None) Parameters：device (torch.device or int, optional) – selected device. Returns statistic for the current device, given by current_device(), if device is None (default). torch.cuda.memory_cached(devide=None) [``] ","date":"2023-07-15","objectID":"/posts/pytorchnotes/:3:0","tags":["draft"],"title":"PyTorch Notes","uri":"/posts/pytorchnotes/"},{"categories":["ML"],"content":"ref: [1] https://www.cnblogs.com/rushup0930/p/13359513.html [2] https://blog.csdn.net/u013250861/article/details/123029585#t12 [3] https://blog.csdn.net/wf592523813/article/details/95202448 [4] https://zhuanlan.zhihu.com/p/69101372 classification 分类 主要涉及的知识点： 混淆矩阵、Precision(精准率)、Recall(召回率)、Accuracy(准确率)、F1-score （包括二分类和多分类问题） ROC、AUC 最常见的指标Accuracy到底有哪些不足？ 解: Accuracy是分类问题中最常用的指标，它计算了分类正确的预测数与总预测数的比值。但是，对于不平衡数据集而言，Accuracy并不是一个好指标。 假设我们有100张图片，其中91张图片是「狗」，5张是「猫」，4张是「猪」，我们希望训练一个三分类器，能正确识别图片里动物的类别。其中，狗这个类别就是大多数类 (majority class)。当大多数类中样本（狗）的数量远超过其他类别（猫、猪）时，如果采用Accuracy来评估分类器的好坏，那么即便模型性能很差 (如无论输入什么图片，都预测为「狗」)，也可以得到较高的Accuracy Score (如91%)。此时，虽然Accuracy Score很高，但是意义不大。当数据异常不平衡时，Accuracy评估方法的缺陷尤为显著。 ","date":"2023-07-15","objectID":"/posts/metrics/:0:0","tags":["draft"],"title":"Classification and Regression Metrics","uri":"/posts/metrics/"},{"categories":["ML"],"content":"二分类模型的常见指标 在二分类问题中，假设该样本一共有两种类别：Positive和Negative。当分类器预测结束，我们可以绘制出混淆矩阵（confusion matrix）。其中分类结果分为如下几种： True Positive (TP): 把正样本成功预测为正。 True Negative (TN)：把负样本成功预测为负。 False Positive (FP)：把负样本错误地预测为正。 False Negative (FN)：把正样本错误的预测为负。 一个小技巧， 第一个字母表示划分正确与否， T 表示判定正确（判定正确）， F表示判定错误(False)； 第二个字母表示分类器判定结果， P表示判定为正例， N表示判定为负例。 在二分类模型中，Accuracy，Precision，Recall和F1 score的定义如下： $$\\text{Accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}$$ Accuracy 能够清晰的判断我们模型的表现，但有一个严重的缺陷： 在正负样本不均衡的情况下，占比大的类别往往会成为影响 Accuracy 的最主要因素，此时的 Accuracy 并不能很好的反映模型的整体情况。 $$\\text{Precision} = \\frac{TP}{TP + FP}$$ Precision着重评估在预测为Positive的所有数据中，真实Positve的数据到底占多少？ 精确率高，意味着分类器要尽量在 “更有把握” 的情况下才将样本预测为正样本， 这意味着精确率能够很好的体现模型对于负样本的区分能力，精确率越高，则模型对负样本区分能力越强。 $$\\text{Recall} = \\frac{TP}{TP + FN}$$ Recall着重评估：在所有的Positive数据中，到底有多少数据被成功预测为Positive 召回率高，意味着分类器尽可能将有可能为正样本的样本预测为正样本，这意味着召回率能够很好的体现模型对于正样本的区分能力，召回率越高，则模型对正样本的区分能力越强。 举例: 一个医院新开发了一套癌症AI诊断系统，想评估其性能好坏。我们把病人得了癌症定义为Positive，没得癌症定义为Negative。那么， 到底该用什么指标进行评估呢？ 如用Precision对系统进行评估，那么其回答的问题就是： 在诊断为癌症的一堆人中，到底有多少人真得了癌症？ 如用Recall对系统进行评估，那么其回答的问题就是： 在一堆得了癌症的病人中，到底有多少人能被成功检测出癌症？ 如用Accuracy对系统进行评估，那么其回答的问题就是： 在一堆癌症病人和正常人中，有多少人被系统给出了正确诊断结果（患癌或没患癌）？ 那啥时候应该更注重Recall而不是Precision呢？ 当False Negative (FN)的成本代价很高 (后果很严重)，希望尽量避免产生FN时，应该着重考虑提高Recall指标。 那啥时候应该更注重Precision而不是Recall呢？ 当False Positive (FP)的成本代价很高 (后果很严重)时，即期望尽量避免产生FP时，应该着重考虑提高Precision指标。 $$\\text{F1-score} = \\frac{2 \\times Precision \\times Recall}{Precision + Recall}$$ 而F1-score是Precision和Recall两者的综合。 举个更有意思的例子（我拍脑袋想出来的，绝对原创哈），假设检察机关想将罪犯捉拿归案，需要对所有人群进行分析，以判断某人犯了罪（Positive），还是没犯罪（Negative）。显然，检察机关希望不漏掉一个罪人（提高recall），也不错怪一个好人（提高precision），所以就需要同时权衡recall和precision两个指标。 尤其在上个世纪，中国司法体制会更偏向Recall，即「天网恢恢，疏而不漏，任何罪犯都插翅难飞」。而西方司法系统会更偏向Precision，即「绝不冤枉一个好人，但是难免有罪犯成为漏网之鱼，逍遥法外」。到底是哪种更好呢？显然，极端并不可取。Precision和Recall都应该越高越好，也就是F1应该越高越好。 如何通俗的解释召回率与精确率？ 例：公园里有50只皮卡丘和10只臭臭泥。有正常审美的人都会想要用精灵球把尽可能多的皮卡丘抓回来，同时尽可能少地抓住臭臭泥。 最终我们的精灵球成功抓回来了45只皮卡丘和10只臭臭泥。 我们就可以说50只皮卡丘中有45只被召唤 (call) 回来 (re) 了，所以 recall = 45 / 50。 但同时，这台机器还误把5只臭臭泥识别为皮卡丘，在它抓回来的所有55只神奇宝贝中，精灵球对皮卡丘判断的精准性 (precision) = 45 / 55。 在上面的例子中，精灵球=预测模型，皮卡丘=正样本，臭臭泥=负样本。 总结这两个概念的用处：描述模型对正样本的预测性能 1、recall描述模型“把正样本叫 (call) 回来(re)”的能力。 2、precision描述模型“叫回来的正样本”有多少是精确的。 ","date":"2023-07-15","objectID":"/posts/metrics/:1:0","tags":["draft"],"title":"Classification and Regression Metrics","uri":"/posts/metrics/"},{"categories":["ML"],"content":"AOC / AUC 混淆矩阵中有着Positive、Negative、True、False的概念，其意义如下： 称预测类别为1的为Positive（阳性），预测类别为0的为Negative（阴性）。 预测正确的为True（真），预测错误的为False（伪）。 对上述概念进行组合，就产生了如下的混淆矩阵: 然后，由此引出True Positive Rate（真阳率）、False Positive（伪阳率）两个概念： $$TP Rate = \\frac{TP}{TP + FN}$$ $$FP Rate = \\frac{FP}{FP + TN}$$ 仔细看这两个公式，发现其实TPRate就是TP除以TP所在的列，FPRate就是FP除以FP所在的列，二者意义如下： TPRate的意义是所有真实类别为1的样本中，预测类别为1的比例。 FPRate的意义是所有真实类别为0的样本中，预测类别为1的比例。 如果上述概念都弄懂了，那么ROC曲线和AUC就so easy了： 按照定义，AUC即ROC曲线下的面积，而ROC曲线的横轴是FPRate，纵轴是TPRate，当二者相等时，即y=x，如下图: 表示的意义是：对于不论真实类别是1还是0的样本，分类器预测为1的概率是相等的。 换句话说，分类器对于正例和负例毫无区分能力，和抛硬币没什么区别，一个抛硬币的分类器是我们能想象的最差的情况，因此一般来说我们认为AUC的最小值为0.5（当然也存在预测相反这种极端的情况，AUC小于0.5，这种情况相当于分类器总是把对的说成错的，错的认为是对的，那么只要把预测类别取反，便得到了一个AUC大于0.5的分类器）。 而我们希望分类器达到的效果是：对于真实类别为1的样本，分类器预测为1的概率（即TPRate），要大于真实类别为0而预测类别为1的概率（即FPRate），即y＞x，因此大部分的ROC曲线长成下面这个样子： 说了这么多还是不够直观，不妨举个简单的例子。 首先对于硬分类器（例如SVM，NB），预测类别为离散标签，对于8个样本的预测情况如下： 得到混淆矩阵如下： 进而算得TPRate=3/4，FPRate=2/4，得到ROC曲线： 最终得到AUC为0.625。 对于LR等预测类别为概率的分类器，依然用上述例子，假设预测结果如下： 这时，需要设置阈值来得到混淆矩阵，不同的阈值会影响得到的TPRate，FPRate，如果阈值取0.5，小于0.5的为0，否则为1，那么我们就得到了与之前一样的混淆矩阵。其他的阈值就不再啰嗦了。依次使用所有预测值作为阈值，得到一系列TPRate，FPRate，描点，求面积，即可得到AUC。 最后说说AUC的优势，AUC的计算方法同时考虑了分类器对于正例和负例的分类能力，在样本不平衡的情况下，依然能够对分类器作出合理的评价。 例如在反欺诈场景，设欺诈类样本为正例，正例占比很少（假设0.1%），如果使用准确率评估，把所有的样本预测为负例，便可以获得99.9%的准确率。 但是如果使用AUC，把所有样本预测为负例，TPRate和FPRate同时为0（没有Positive），与(0,0) (1,1)连接，得出AUC仅为0.5，成功规避了样本不均匀带来的问题。 ","date":"2023-07-15","objectID":"/posts/metrics/:2:0","tags":["draft"],"title":"Classification and Regression Metrics","uri":"/posts/metrics/"},{"categories":["ML"],"content":"多分类模型的常见指标详细解析 在多分类（大于两个类）问题中，假设我们要开发一个动物识别系统，来区分输入图片是猫，狗还是猪。给定分类器一堆动物图片，产生了如下结果混淆矩阵。 在混淆矩阵中，正确的分类样本（Actual label = Predicted label）分布在左上到右下的对角线上。其中，Accuracy的定义为分类正确（对角线上）的样本数与总样本数的比值。Accuracy度量的是全局样本预测情况。而对于Precision和Recall而言，每个类都需要单独计算其Precision和Recall。 classify_multiclass_prediction 比如，对类别「猪」而言，其Precision和Recall分别为: $$\\text{Precision} = \\frac{TP}{TP + FP} = \\frac{20}{20 + 50} = \\frac{2}{7}$$ $$\\text{Recall} = \\frac{TP}{TP + FN} = \\frac{20}{10} = \\frac{2}{3}$$ 也就是: $$P_{cat} = \\frac{8}{15}, P_{dog} = \\frac{17}{23}, P_{pig} = \\frac{2}{7}, (P代表Precision) $$ $$R_{cat} = \\frac{4}{7}, R_{dog} = \\frac{17}{32}, R_{pig} = \\frac{2}{3}, (R代表Recall) $$ 如果想评估该识别系统的总体功能，必须考虑猫、狗、猪三个类别的综合预测性能。那么，到底要怎么综合这三个类别的Precision呢？是简单加起来做平均吗？通常来说， 我们有如下几种解决方案（也可参考scikit-learn官网）： 1. Macro-average方法 该方法最简单，直接将不同类别的评估指标（Precision/ Recall/ F1-score）加起来求平均，给所有类别相同的权重。该方法能够平等看待每个类别，但是它的值会受稀有类别影响。 $$\\text{Macro-Precision} = \\frac{P_{cat} + P_{dog} + P_{pig}}{3} = 0.5194$$ $$\\text{Macro-Recall} = \\frac{R_{cat} + R_{dog} + R_{pig}}{3} = 0.5898$$ 2. Weighted-average方法 该方法给不同类别不同权重（权重根据该类别的真实分布比例确定），每个类别乘权重后再进行相加。该方法考虑了类别不平衡情况，它的值更容易受到常见类（majority class）的影响。 $$W_{cat} : W_{dog} : W_{pig} = N_{cat} : N_{dog} : N_{pig} = \\frac{7}{26} : \\frac{16}{26} : \\frac{3}{26} (W代表权重，N代表样本在该类别下的真实数目)$$ $$\\text{Weighted-Precision} = P_{cat} \\times W_{cat} + P_{dog} \\times W_{dog} + P_{pig} \\times W_{pig} = 0.6314$$ $$\\text{Weighted-Recall} = {R_{cat} \\times W_{cat} + R_{dog} \\times W_{dog} + R_{pig} \\times W_{pig}}= 0.5577$$ 3. Micro-average方法 该方法把每个类别的TP, FP, FN先相加之后，在根据二分类的公式进行计算。 $$\\text{Micro-Precision} = \\frac{TP_{cat} + TP_{dog} + TP_{pig}}{TP_{cat} + TP_{dog} + TP_{pig} + FP_{cat} + FP_{dog} + FP_{pig}} = 0.5577$$ $$\\text{Micro-Recall} = \\frac{TP_{cat} + TP_{dog} + TP_{pig}}{TP_{cat} + TP_{dog} + TP_{pig} + FN_{cat} + FN_{dog} + FN_{pig}} = 0.5577$$ 其中，特别有意思的是，Micro-precision 和 Micro-recall竟然始终相同！这是为啥呢？ 这是因为在某一类中的False Positive样本，一定是其他某类别的False Negative样本。听起来有点抽象？举个例子，比如说系统错把「狗」预测成「猫」，那么对于狗而言，其错误类型就是False Negative，对于猫而言，其错误类型就是False Positive。于此同时，Micro-precision和Micro-recall的数值都等于Accuracy，因为它们计算了对角线样本数和总样本数的比值，总结就是 $$\\text{Micro-Precision} = \\text{Micro-Recall} = \\text{Micro-F1 score} = \\text{Accuracy}$$ demo示例: import numpy as np import seaborn as sns from sklearn.metrics import confusion_matrix import pandas as pd import matplotlib.pyplot as plt from sklearn.metrics import accuracy_score, average_precision_score,precision_score,f1_score,recall_score # create confusion matrix y_true = np.array([-1]*70 + [0]*160 + [1]*30) y_pred = np.array([-1]*40 + [0]*20 + [1]*20 + [-1]*30 + [0]*80 + [1]*30 + [-1]*5 + [0]*15 + [1]*20) cm = confusion_matrix(y_true, y_pred) conf_matrix = pd.DataFrame(cm, index=['Cat','Dog','Pig'], columns=['Cat','Dog','Pig']) # plot size setting fig, ax = plt.subplots(figsize = (4.5,3.5)) sns.heatmap(conf_matrix, annot=True, annot_kws={\"size\": 19}, cmap=\"Blues\") plt.ylabel('True label', fontsize=18) plt.xlabel('Predicted label', fontsize=18) plt.xticks(fontsize=18) plt.yticks(fontsize=18) plt.savefig('confusion.pdf', bbox_inches='tight') plt.show() print('------Weighted------') print('Weighted precision', precision_score(y_true, y_pred, average='weighted')) print('Weighted recall', recall_score(y_true, y_pred, average='weighted')) print('Weighted f1-score', f1_score(y_true, y_pred, average='weighted')) print('------Macro------') print('Macro precision', precision_score(y_true, y_pred, average='macro')) print('Macro recall', recall_score(y_true, y_pred, average='macro')) print('Macro f1-score', f1_score(y_true, y_pred, average='macro')) print('------Micro------') print('Micro precision', precision_score(y_true, y_pred, average='micro')) print('Micro recall', recall_score(y_true, y_pred, average='micro')) print('Micro f1-score', f1_score(y_true, y_pred, average='micro')) Regression 回归 回归算法的评价指标就是MSE，RMSE，MAE、R-Squared。 MSE和MAE适用于误差相对明显的时候，大的误差也有比较高的权重，RMSE则是针对误差不是很明显的时候；MAE是一个线性的指标，所有个体差异在平均值上均等加权，所以它更加凸显出异常值，相比MSE； RMSLE: 主要针对数据集中有一个特别大的异常值，这种情况下，data会被s","date":"2023-07-15","objectID":"/posts/metrics/:3:0","tags":["draft"],"title":"Classification and Regression Metrics","uri":"/posts/metrics/"},{"categories":["ML"],"content":"用pickle保存和加载模型 保存模型 import pickle from sklearn.svm import SVC model_dir = './model.pkl' model = SVC() with open(model_dir, 'wb') as f: pickle.dump(model, f) f.close() # 注意:保存完模型之后要关闭文件 加载模型 import pickle model_dir = './model.pkl' with open(model_dir, 'rb') as f: model = pickel.load(f) print(mode.predict(x)) ","date":"2023-07-15","objectID":"/posts/notes_1/:1:0","tags":["ML"],"title":"Maching Learning Notes 1","uri":"/posts/notes_1/"},{"categories":["ML"],"content":"逻辑回归 Logistic Regression LR Implementation code snippets from sklearn.linear_model import LogisticRegression from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score import numpy as np import matplotlib.pyplot as plt import pickle from tqdm import tqdm data_path = './data/merged_data/data.npy' data = np.load(data_path, allow_pickle=True) model_l1_path='./model/logistic_reg_l1.pickle' model_l2_path='./model/logictic_reg_l2.pickle' X = data[:,0:35] y = data[:, -1] X_train, x_test, Y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) # lr_l1 = LogisticRegression(penalty=\"l1\", C=0.5, solver='sag', multi_class=\"auto\") # lr_l2 = LogisticRegression(penalty=\"l2\", C=0.5, solver='sag', multi_class=\"auto\") # # train model # lr_l1.fit(X_train, Y_train) # lr_l2.fit(X_train, Y_train) # model performence on train set l1_train_predict = [] l2_train_predict = [] # model performence on test set l1_test_predict = [] l2_test_predict = [] for c in tqdm(np.linspace(0.01, 2, 50)): # lr_l1 = LogisticRegression(penalty=\"l1\", C=c, solver='liblinear', max_iter=1000) # lr_l2 = LogisticRegression(penalty='l2', C=c, solver='liblinear', max_iter=1000) lr_l1 = LogisticRegression(penalty=\"l1\", C=c, solver='liblinear', max_iter=1000, multi_class='auto') lr_l2 = LogisticRegression(penalty='l2', C=c, solver='liblinear', max_iter=1000, multi_class='auto') # 训练模型，记录L1正则化模型在训练集测试集上的表现 lr_l1.fit(X_train, Y_train) l1_train_predict.append(accuracy_score(lr_l1.predict(X_train), Y_train)) l1_test_predict.append(accuracy_score(lr_l1.predict(x_test), y_test)) # 记录L2正则化模型的表现 lr_l2.fit(X_train, Y_train) l2_train_predict.append(accuracy_score(lr_l2.predict(X_train), Y_train)) l2_test_predict.append(accuracy_score(lr_l2.predict(x_test), y_test)) if c == 2: pred_y_test = lr_l2.predict(x_test) mask = abs(pred_y_test-y_test) \u003c 5 neg_test = pred_y_test[mask] res = (len(neg_test)/len(pred_y_test)) print(res) with open(model_l1_path, 'wb') as f1: pickle.dump(lr_l1, f1) with open(model_l2_path, 'wb') as f2: pickle.dump(lr_l2, f2) data = [l1_train_predict, l2_train_predict, l1_test_predict, l2_test_predict] label = ['l1_train', 'l2_train', 'l1_test', \"l2_test\"] color = ['red', 'green', 'orange', 'blue'] plt.figure(figsize=(12, 6)) for i in range(4) : plt.plot(np.linspace(0.01, 2, 50), data[i], label=label[i], color=color[i]) plt.legend(loc=\"best\") plt.show() ","date":"2023-07-15","objectID":"/posts/notes_1/:2:0","tags":["ML"],"title":"Maching Learning Notes 1","uri":"/posts/notes_1/"},{"categories":["ML"],"content":"支持向量机 Support Vector Machine Using GridSearch to find the best parameters [code snippets] import numpy as np import matplotlib.pyplot as plt from sklearn.linear_model import Perceptron, LogisticRegression from sklearn.svm import SVC from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn import datasets from sklearn import metrics import pickle merged_data_dir = '../data/merged_data/merged_data.npy' model_dir='./svm.pkl' data = np.load(merged_data_dir, allow_pickle=True) #labeling for ele in data: if ele[-1] \u003c 20: ele[-1] = 0 elif ele[-1] \u003e=20 and ele[-1] \u003c 40: ele[-1] = 1 else: ele[-1] = 2 X = data[:,0:34] y = data[:,-1] print(y) # Create training and test split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y) # feature scaling # sc = StandardScaler() # sc.fit(X_train) # X_train_std = sc.transform(X_train) # X_test_std = sc.transform(X_test) ################################## # # Instantiate the Support Vector Classifier (SVC) # svc = SVC(C=10, random_state=1, kernel='rbf', gamma=0.3) # # Fit the model # svc.fit(X_train, y_train) # # Make the predictions # y_predict = svc.predict(X_test) # # Measure the performance # print(\"Accuracy score %.3f\" %metrics.accuracy_score(y_test, y_predict)) ############################################# def svm_cross_validation(train_x, train_y): from sklearn.model_selection import GridSearchCV from sklearn.svm import SVC model = SVC(kernel='rbf', probability=True) param_grid = {'C': [1e-3, 1e-2, 1e-1, 1, 10, 100, 1000], 'gamma': [0.001, 0.0001]} grid_search = GridSearchCV(model, param_grid, n_jobs = 8, verbose=1, scoring='accuracy') grid_search.fit(train_x, train_y) best_parameters = grid_search.best_estimator_.get_params() for para, val in list(best_parameters.items()): print(para, val) model = SVC(kernel='rbf', C=best_parameters['C'], gamma=best_parameters['gamma'], probability=True) model.fit(train_x, train_y) return model svm_model = svm_cross_validation(X_train, y_train) with open(model_dir, 'wb') as f1: pickle.dump(svm_model, f1) f1.close() print(svm_model.score(X_test, y_test)) y_predict = svm_model.predict(X_test) print(y_predict) ","date":"2023-07-15","objectID":"/posts/notes_1/:3:0","tags":["ML"],"title":"Maching Learning Notes 1","uri":"/posts/notes_1/"},{"categories":["Memo"],"content":"docker 入门教程 Ref Link: [1] https://ruanyifeng.com/blog/2018/02/docker-tutorial.html [2] https://cloud.tencent.com/developer/article/1885678 [3] 「Docker」 - 保存镜像 [4] 如何制作Docker镜像(image)? ","date":"2023-07-15","objectID":"/posts/dockerintroduction/:1:0","tags":["docker"],"title":"Docker安装及学习","uri":"/posts/dockerintroduction/"},{"categories":["Memo"],"content":"一、Docker 是什么？ \u0026\u0026 Docker 的用途 Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。它是目前最流行的 Linux 容器解决方案。 Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。 总体来说，Docker 的接口相当简单，用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。 ","date":"2023-07-15","objectID":"/posts/dockerintroduction/:1:1","tags":["docker"],"title":"Docker安装及学习","uri":"/posts/dockerintroduction/"},{"categories":["Memo"],"content":"二、docker 安装 参考连接:ubuntu下docker的安装 安装完成后，运行下面的命令，验证是否安装成功。 docker version # or docker info Docker 需要用户具有 sudo 权限，为了避免每次命令都输入sudo，可以把用户加入 Docker 用户组。 # 创建docker用户组 sudo groupadd docker # 应用用户加入docker用户组 sudo usermod -aG docker $USER # 重启docker服务 sudo systemctl restart docker su root su ${USER} Docker是服务器–客户端(server–client)架构。命令行运行docker命令的时候，需要本机有 Docker 服务。如果这项服务没有启动，可以用下面的命令启动: # service 命令的用法 sudo service docker start # systemctl 命令的用法 sudo systemctl start docker ","date":"2023-07-15","objectID":"/posts/dockerintroduction/:1:2","tags":["docker"],"title":"Docker安装及学习","uri":"/posts/dockerintroduction/"},{"categories":["Memo"],"content":"三、image 文件 Docker 把应用程序及其依赖，打包在 image 文件里面。只有通过这个文件，才能生成 Docker 容器。image 文件可以看作是容器的模板。Docker 根据 image 文件生成容器的实例。同一个 image 文件，可以生成多个同时运行的容器实例。 image 是二进制文件。实际开发中，一个 image 文件往往通过继承另一个 image 文件，加上一些个性化设置而生成。举例来说，你可以在 Ubuntu 的 image 基础上，往里面加入 Apache 服务器，形成你的 image。 # 列出本机的所有 image 文件。 $ docker image ls # 删除 image 文件 $ docker image rm [imageName] image 文件是通用的，一台机器的 image 文件拷贝到另一台机器，照样可以使用。一般来说，为了节省时间，我们应该尽量使用别人制作好的 image 文件，而不是自己制作。即使要定制，也应该基于别人的 image 文件进行加工，而不是从零开始制作。 为了方便共享，image 文件制作完成后，可以上传到网上的仓库。Docker 的官方仓库 Docker Hub 是最重要、最常用的 image 仓库。此外，出售自己制作的 image 文件也是可以的。 ","date":"2023-07-15","objectID":"/posts/dockerintroduction/:1:3","tags":["docker"],"title":"Docker安装及学习","uri":"/posts/dockerintroduction/"},{"categories":["Memo"],"content":"四、实例：hello world 首先，运行下面的命令，将 image 文件从仓库抓取到本地。 docker image pull library/hello-world 上面代码中，docker image pull是抓取 image 文件的命令。library/hello-world是 image 文件在仓库里面的位置，其中library是 image 文件所在的组，hello-world是 image 文件的名字。 由于 Docker 官方提供的 image 文件，都放在library组里面，所以它的是默认组，可以省略。因此，上面的命令可以写成下面这样。 docker image pull hello-world 抓取成功以后，就可以在本机看到这个 image 文件了。 docker image ls 运行image: docker container run hello-world docker container run命令会从 image 文件，生成一个正在运行的容器实例。 注意，docker container run命令具有自动抓取 image 文件的功能。如果发现本地没有指定的 image 文件，就会从仓库自动抓取。因此，前面的docker image pull命令并不是必需的步骤。 如果运行成功，你会在屏幕上读到下面的输出。 $ docker container run hello-world Hello from Docker! This message shows that your installation appears to be working correctly. ... ... 输出这段提示以后，hello world就会停止运行，容器自动终止。 有些容器不会自动终止，因为提供的是服务。比如，安装运行 Ubuntu 的 image，就可以在命令行体验 Ubuntu 系统。 $ docker container run -it ubuntu bash 对于那些不会自动终止的容器，必须使用docker container kill命令手动终止。 $ docker container kill [containID] ","date":"2023-07-15","objectID":"/posts/dockerintroduction/:1:4","tags":["docker"],"title":"Docker安装及学习","uri":"/posts/dockerintroduction/"},{"categories":["Memo"],"content":"五、容器文件 image文件生成的容器实例，本身也是一个文件，称为容器文件。也就是说，一旦容器生成，就会同时存在两个文件： image文件和容器文件。而且关闭容器并不会删除容器文件，只是容器停止运行而已。 上面命令的输出结果之中，包括容器的 ID。很多地方都需要提供这个 ID，比如上一节终止容器运行的docker container kill命令。 终止运行的容器文件，依然会占据硬盘空间，可以使用docker container rm命令删除。 $ docker container rm [containerID] 运行上面的命令之后，再使用docker container ls --all命令，就会发现被删除的容器文件已经消失了。 ","date":"2023-07-15","objectID":"/posts/dockerintroduction/:1:5","tags":["docker"],"title":"Docker安装及学习","uri":"/posts/dockerintroduction/"},{"categories":["Memo"],"content":"六、 Dockerfile 文件 学会使用 image 文件以后，接下来的问题就是，如何可以生成 image 文件？如果你要推广自己的软件，势必要自己制作 image 文件。 这就需要用到 Dockerfile 文件。它是一个文本文件，用来配置 image。Docker 根据 该文件生成二进制的 image 文件。 下面通过一个实例，演示如何编写 Dockerfile 文件。 ","date":"2023-07-15","objectID":"/posts/dockerintroduction/:1:6","tags":["docker"],"title":"Docker安装及学习","uri":"/posts/dockerintroduction/"},{"categories":["Memo"],"content":"七、实例: 下面我以 koa-demos 项目为例，介绍怎么写 Dockerfile 文件，实现让用户在 Docker 容器里面运行 Koa 框架。 作为准备工作，请先下载源码[]。 $ git clone https://github.com/ruanyf/koa-demos.git $ cd koa-demos 7.1 编写 Dockerfile 文件 首先，在项目的根目录下，新建一个文本文件.dockerignore，写入下面的内容。 .git node_modules npm-debug.log 上面代码表示，这三个路径要排除，不要打包进入 image 文件。如果你没有路径要排除，这个文件可以不新建。 然后，在项目的根目录下，新建一个文本文件 Dockerfile，写入下面的内容。 FROM node:8.4 COPY . /app WORKDIR /app RUN npm install --registry=https://registry.npm.taobao.org EXPOSE 3000 上面代码一共五行，含义如下。 FROM node:8.4：该 image 文件继承官方的 node image，冒号表示标签，这里标签是8.4，即8.4版本的 node。 COPY . /app：将当前目录下的所有文件（除了.dockerignore排除的路径），都拷贝进入 image 文件的/app目录。 WORKDIR /app：指定接下来的工作路径为/app。 RUN npm install：在/app目录下，运行npm install命令安装依赖。注意，安装后所有的依赖，都将打包进入 image 文件。 EXPOSE 3000：将容器 3000 端口暴露出来， 允许外部连接这个端口。 7.2 创建image文件 有了 Dockerfile 文件以后，就可以使用docker image build命令创建 image 文件了。 $ docker image build -t koa-demo . # 或者 $ docker image build -t koa-demo:0.0.1 . 上面代码中，-t参数用来指定 image 文件的名字，后面还可以用冒号指定标签。如果不指定，默认的标签就是latest。最后的那个点表示 Dockerfile 文件所在的路径，上例是当前路径，所以是一个点。 如果运行成功，就可以看到新生成的 image 文件koa-demo了。 docker image ls 7.3 生成容器 docker container run命令会从 image 文件生成容器。 $ docker container run -p 8000:3000 -it koa-demo /bin/bash # 或者 $ docker container run -p 8000:3000 -it koa-demo:0.0.1 /bin/bash 上面命令的各个参数含义如下： p参数：容器的 3000 端口映射到本机的 8000 端口。 it参数：容器的 Shell 映射到当前的 Shell，然后你在本机窗口输入的命令，就会传入容器。 koa-demo:0.0.1：image 文件的名字（如果有标签，还需要提供标签，默认是 latest 标签）。 /bin/bash：容器启动以后，内部第一个执行的命令。这里是启动 Bash，保证用户可以使用 Shell。 如果一切正常，运行上面的命令以后，就会返回一个命令行提示符。 root@66d80f4aaf1e:/app# 这表示你已经在容器里面了，返回的提示符就是容器内部的 Shell 提示符。执行下面的命令。 root@66d80f4aaf1e:/app# node demos/01.js 这时，Koa 框架已经运行起来了。打开本机的浏览器，访问 http://127.0.0.1:8000，网页显示\"Not Found\"，这是因为这个 demo 没有写路由。 这个例子中，Node 进程运行在 Docker 容器的虚拟环境里面，进程接触到的文件系统和网络接口都是虚拟的，与本机的文件系统和网络接口是隔离的，因此需要定义容器与物理机的端口映射（map）。 现在，在容器的命令行，按下 Ctrl + c 停止 Node 进程，然后按下 Ctrl + d （或者输入 exit）退出容器。此外，也可以用docker container kill终止容器运行。 # 在本机的另一个终端窗口，查出容器的 ID $ docker container ls # 停止指定的容器运行 $ docker container kill [containerID] 容器停止运行之后，并不会消失，用下面的命令删除容器文件。 # 查出容器的 ID $ docker container ls --all # 删除指定的容器文件 $ docker container rm [containerID] 也可以使用docker container run命令的–rm参数，在容器终止运行后自动删除容器文件。 $ docker container run --rm -p 8000:3000 -it koa-demo /bin/bash 7.4 CMD命令 上一节的例子里面，容器启动以后，需要手动输入命令node demos/01.js。我们可以把这个命令写在 Dockerfile 里面，这样容器启动以后，这个命令就已经执行了，不用再手动输入了。 FROM node:8.4 COPY . /app WORKDIR /app RUN npm install --registry=https://registry.npm.taobao.org EXPOSE 3000 CMD node demos/01.js 上面的 Dockerfile 里面，多了最后一行CMD node demos/01.js，它表示容器启动后自动执行node demos/01.js。 你可能会问，RUN命令与CMD命令的区别在哪里？简单说，RUN命令在 image 文件的构建阶段执行，执行结果都会打包进入 image 文件；CMD命令则是在容器启动后执行。另外，一个 Dockerfile 可以包含多个RUN命令，但是只能有一个CMD命令。 注意，指定了CMD命令以后，docker container run命令就不能附加命令了（比如前面的/bin/bash），否则它会覆盖CMD命令。现在，启动容器可以使用下面的命令。 $ docker container run --rm -p 8000:3000 -it koa-demo:0.0.1 7.5 发布 image 文件 容器运行成功后，就确认了 image 文件的有效性。这时，我们就可以考虑把 image 文件分享到网上，让其他人使用。 首先，去 hub.docker.com 或 cloud.docker.com 注册一个账户。然后，用下面的命令登录。 $ docker login 接着，为本地的 image 标注用户名和版本。 $ docker image tag [imageName] [username]/[repository]:[tag] # 实例 $ docker image tag koa-demos:0.0.1 ruanyf/koa-demos:0.0.1 也可以不标注用户名，重新构建一下 image 文件。 $ docker image build -t [username]/[repository]:[tag] . 最后，发布 image 文件。 $ docker image push [username]/[repository]:[tag] 发布成功以后，登录 hub.docker.com，就可以看到已经发布的 image 文件。 ","date":"2023-07-15","objectID":"/posts/dockerintroduction/:1:7","tags":["docker"],"title":"Docker安装及学习","uri":"/posts/dockerintroduction/"},{"categories":["Memo"],"content":"八、其他有用的命令 (1) docker container start 前面的docker container run命令是新建容器，每运行一次，就会新建一个容器。同样的命令运行两次，就会生成两个一模一样的容器文件。如果希望重复使用容器，就要使用docker container start命令，它用来启动已经生成、已经停止运行的容器文件。 $ docker container start [containerID] (2) docker container stop 前面的docker container kill命令终止容器运行，相当于向容器里面的主进程发出 SIGKILL 信号。而docker container stop命令也是用来终止容器运行，相当于向容器里面的主进程发出 SIGTERM 信号，然后过一段时间再发出 SIGKILL 信号。 docker container stop [containerID] 这两个信号的差别是，应用程序收到 SIGTERM 信号以后，可以自行进行收尾清理工作，但也可以不理会这个信号。如果收到 SIGKILL 信号，就会强行立即终止，那些正在进行中的操作会全部丢失。 (3) docker container logs docker container logs命令用来查看 docker 容器的输出，即容器里面 Shell 的标准输出。如果docker run命令运行容器的时候，没有使用-it参数，就要用这个命令查看输出。 docker container logs [containerID] (4) docker container exec docker container exec命令用于进入一个正在运行的 docker 容器。如果docker run命令运行容器的时候，没有使用-it参数，就要用这个命令进入容器。一旦进入了容器，就可以在容器的 Shell 执行命令了。 $ docker container exec -it [containerID] /bin/bash (5) docker container cp 和 docker cp docker container cp命令用于从正在运行的 Docker 容器里面，将文件拷贝到本机。下面是拷贝到当前目录的写法。 docker container cp [containID]:[/path/to/file] . docker cp命令用于从将宿主机内的文件拷贝文件到container中: docker cp [OPTIONS] [src path] [container id]:[dest path] 非常感谢你一直读到了这里，这个系列还有下一篇，介绍如何使用 Docker 搭建真正的网站，欢迎继续阅读。 (6) docker commit docker commit命令用于保存container的修改。 docker commit -m \"commit message\" [containr ID] [new REPOSITORY:TAG] (7) docker save and docker load docker save 和 docker load 将image文件保存为压缩文件或者加载本地的压缩文件为image。 docker save -o [outputname path] [REPOSITORY:TAG] docker load -i [outputname.tar] ","date":"2023-07-15","objectID":"/posts/dockerintroduction/:1:8","tags":["docker"],"title":"Docker安装及学习","uri":"/posts/dockerintroduction/"},{"categories":["Memo"],"content":"一、 apt-get source update apt-get source change the /etc/apt/sources.list file to aliyun source add sudo user in rootlink adduser [name] apt-get install sudo 赋予用户sudo权限: sudo usermod -a -G adm username sudo usermod -a -G sudo username su [name] 在文件/etc/sudoers中更改用户的sudo权限: # sudoers file. # # This file MUST be edited with the 'vi sudo' command as root. # # See the sudoers man page for the details on how to write a sudoers file. # # Host alias specification # User alias specification # Cmnd alias specification # Defaults specification # User privilege specification root ALL=(ALL) ALL [username] ALL=(ALL) ALL # Uncomment to allow people in group wheel to run all commands # %wheel ALL=(ALL) ALL # Same thing without a password # %wheel ALL=(ALL) NOPASSWD: ALL # Samples # %users ALL=/sbin/mount /cdrom,/sbin/umount /cdrom # %users localhost=/sbin/shutdown -h now ","date":"2023-07-15","objectID":"/posts/softwareinstallation/:1:0","tags":["Linux"],"title":"程序安装教程","uri":"/posts/softwareinstallation/"},{"categories":["Memo"],"content":"二、 Anaconda or Miniconda Installation download anaconda or miniconda from tsinghua source website download command: wget https://mirrors.tuna.tsinghua.edu.cn/anaconda/miniconda/Miniconda3-latest-Linux-x86_64.sh run the command to install: bash Miniconda3-latest-linux-x86_64.sh change the conda channels to tsinghua source nano ~/.condarc paste the following channels into your ~/.condarc file:ref link conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ #Conda Forge conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge/ #msys2（可略） conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/ #bioconda（可略） conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/ #menpo（可略） conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/menpo/ #pytorch conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/ # for legacy win-64（可略） conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/peterjc123/ conda config --set show_channel_urls yes anaconda 环境文件environment.yml使用参考 创建环境: conda env create -f environment.yml -n myenv 导出当前环境配置: conda env export \u003e environment.yml 更新环境: conda env update -f environment.yml ","date":"2023-07-15","objectID":"/posts/softwareinstallation/:2:0","tags":["Linux"],"title":"程序安装教程","uri":"/posts/softwareinstallation/"},{"categories":["Memo"],"content":"三、 Cmake Installation Ref Link Download cmake source file: wget https://cmake.org/files/v3.20/cmake-3.20.0-linux-x86_64.tar.gz extract the file and move the file to /opt/cmake-3.20.0 tar zxvf cmake-3.20.0-linux-x86_64.tar.gz mv cmake-3.20.0-linux-x86_64 /opt/cmake-3.20.0 link the cmake as system cmake ln -sf /opt/cmake-3.20.0/bin/* /usr/bin/ check if successfully installed cmake --version ","date":"2023-07-15","objectID":"/posts/softwareinstallation/:3:0","tags":["Linux"],"title":"程序安装教程","uri":"/posts/softwareinstallation/"},{"categories":["Memo"],"content":"四、 Openmpi Installation Ref Link Install openmpi with command line: sudo apt-get install openmpi-bin openmpi-doc libopenmpi-dev 在conda下安装openmapi: conda install openmpi ","date":"2023-07-15","objectID":"/posts/softwareinstallation/:4:0","tags":["Linux"],"title":"程序安装教程","uri":"/posts/softwareinstallation/"},{"categories":["Memo"],"content":"五、 Anaconda下安装jupyter notebook 安装jupyter notebook pip install jupyter notebook==6.1.0 安装nbextensions pip install jupyter_contrib_nbextensions jupyter contrib nbextension install --user 如果遇到如下报错信息: ModuleNotFoundError: No module named 'notebook.base' 注意: 一般由于notebook版本\u003e=7.0.0导致 原因: Notebook的版本太高了，将notebook的版本降到6.1.0 pip install jupyter notebook==6.1.0 # 或者 pip install --upgrade notebook==6.1.0 然后再重新安装插件。 安装nbextensions_configurator pip install jupyter_nbextensions_configurator jupyter nbextensions_configurator enable --user 启动jupyter Notebook jupyter notebook 若如下报错: ModuleNotFoundError: No module named 'jupyter_server.contents' TypeError: warn() missing 1 required keyword-only argument: 'stacklevel' 则执行以下命令安装traitlets库: pip install traitlets==5.9.0 在codemirror.css文件中更改字体 文件路径: /home/{$USERNAME}/miniconda3/envs/pytorch/lib/python3.8/site-packages/notebook/static/components/codemirror/lib/codemirror.css 推荐安装的几个jupyter插件: zenmode table of content(2) Autopep8 variable inspector ExecuteTime Hide input all 隐藏代码输入 jupyter notebook v7.0 extension installation support: https://github.com/jupyter/notebook/discussions/6881 ","date":"2023-07-15","objectID":"/posts/softwareinstallation/:5:0","tags":["Linux"],"title":"程序安装教程","uri":"/posts/softwareinstallation/"},{"categories":["Transformer"],"content":"reference: [1]. The Transformer Family [2]. Attention [3]. 细节考究 ","date":"2023-07-15","objectID":"/posts/transformerintroduction/:0:0","tags":["draft"],"title":"Transformer Introduction","uri":"/posts/transformerintroduction/"},{"categories":["Transformer"],"content":"Transformer Family ","date":"2023-07-15","objectID":"/posts/transformerintroduction/:1:0","tags":["draft"],"title":"Transformer Introduction","uri":"/posts/transformerintroduction/"},{"categories":["Transformer"],"content":"Notations Symbol Meaning $d$ The model size / hidden state dimension / positional encoding size. $h$ The number of heads in multi-head attention layer. $L$ The segment length of input sequence. $X \\in \\mathbb R ^ {L \\times d}$ The input sequence where each element has been mapped into an embedding vector of shape , same as the model size. $W^k \\in \\mathbb R ^ {d \\times d^k}$ The key weight matrix. $W^q \\in \\mathbb R ^ {d \\times d^k}$ The query weight matrix. $W^v \\in \\mathbb R ^ {d \\times d^k}$ The value weight matrix.Often we have $d_k = d_v = d$. $W^K_i, W^q_i \\in \\mathbb R ^ {d \\times d^k / h}; W^v_i \\in \\mathbb R^{d x d_v / h}$ The weight matrices per head. $W^o \\in \\mathbb d_v \\times d$ The output weight matrix. $Q = XW^q \\in \\mathbb R^{L \\times d_q}$ The query embedding inputs. $K = XW^k \\in \\mathbb R^{L \\times d_k}$ The key embedding inputs. $V = XW^v \\in \\mathbb R^{L \\times d_v}$ The value embedding inputs. $S_i$ A collection of key positions for the -th query to attend to. $A \\in \\mathbb R ^ {L \\times L}$ The self-attention matrix between a input sequence of lenght $L$ and itself. $A = softmax (Q K^T/\\sqrt{(d_k)} )$ $a_ij \\ in A $ The scalar attention score between query $q_i$ and key $k_j$. $P \\in \\mathbb R ^ {L \\times d}$ position encoding matrix, where the $i-th$ row is the positional encoding for input $x_i$. ","date":"2023-07-15","objectID":"/posts/transformerintroduction/:1:1","tags":["draft"],"title":"Transformer Introduction","uri":"/posts/transformerintroduction/"},{"categories":["Transformer"],"content":"Attention and Self-Attention Attention is a mechanism in the neural network that a model can learn to make predictions by selectively attending to a given set of data. The amount of attention is quantified by learned weights and thus the output is usually formed as a weighted average. Self-attention is a type of attention mechanism where the model makes prediction for one part of a data sample using other parts of the observation about the same sample. Conceptually, it feels quite similar to non-local means. Also note that self-attention is permutation-invariant; in other words, it is an operation on sets. There are various forms of attention / self-attention, Transformer (Vaswani et al., 2017) relies on the scaled dot-product attention: given a query matrix $Q$, a key matrix $K$ and a value matrix $V$, the output is a weighted sum of the value vectors, where the weight assigned to each value slot is determined by the dot-product of the query with the corresponding key: $$\\text{Attention}(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V$$ And for a query and a key vector $q_i, k_j \\in \\mathbb R ^ d$ (row vectors in query and key matrices), we have a scalar score: $$a_{ij} = softmax(\\frac{q_i k_j^T}{\\sqrt{d_k}}) = \\frac{\\exp(q_i k_j^T)}{\\sqrt{d_k}\\sum_{r \\in S_i}(q_i k_j^T)}$$ where $S_i$ is a collection of key positions for the $i$-th query to attend to. See my old post for other types of attention if interested. ","date":"2023-07-15","objectID":"/posts/transformerintroduction/:1:2","tags":["draft"],"title":"Transformer Introduction","uri":"/posts/transformerintroduction/"},{"categories":["Transformer"],"content":"Multi-Head Self-Attention The multi-head self-attention module is a key component in Transformer. Rather than only computing the attention once, the multi-head mechanism splits the inputs into smaller chunks and then computes the scaled dot-product attention over each subspace in parallel. The independent attention outputs are simply concatenated and linearly transformed into expected dimensions. $$\\text{MulitHeadAttention}(X_q, X_k, X_v) = [\\text{head}_1,;…; \\text{head}_h] W^o, where \\text{head}_i = \\text{Attention}(X_qW_i^q, X_kW_i^k, X_vW_i^v)$$ where $[.;.]$ is a concatenation operation. $W_i^q, W_i^k \\in \\mathbb R^{d \\times d_{k} / h}$, $W_i^v \\in \\mathbb R^{d \\times d_{v} / h}$ are weight matrices to map input embeddings of size $L \\times d$ into query, key and value matrices. And $W^o \\in \\mathbb R ^ {d_v \\times d}$ is the output linear transformation. All the weights should be learned during training. ","date":"2023-07-15","objectID":"/posts/transformerintroduction/:1:3","tags":["draft"],"title":"Transformer Introduction","uri":"/posts/transformerintroduction/"},{"categories":["Transformer"],"content":"Transformer The Transformer (which will be referred to as “vanilla Transformer” to distinguish it from other enhanced versions; Vaswani, et al., 2017) model has an encoder-decoder architecture, as commonly used in many NMT models. Later decoder-only Transformer was shown to achieve great performance in language modeling tasks, like in GPT and BERT. Encoder-Decoder Architecture The encoder generates an attention-based representation with capability to locate a specific piece of information from a large context. It consists of a stack of 6 identity modules, each containing two submodules, a multi-head self-attention layer and a point-wise fully connected feed-forward network. By point-wise, it means that it applies the same linear transformation (with same weights) to each element in the sequence. This can also be viewed as a convolutional layer with filter size 1. Each submodule has a residual connection and layer normalization. All the submodules output data of the same dimension $d$. The function of Transformer decoder is to retrieve information from the encoded representation. The architecture is quite similar to the encoder, except that the decoder contains two multi-head attention submodules instead of one in each identical repeating module. The first multi-head attention submodule is masked to prevent positions from attending to the future. Positional Encoding Because self-attention operation is permutation invariant, it is important to use proper positional encoding to provide order information to the model. The positional encoding $P \\in \\mathbb R ^ {L \\times d}$ has the same dimension as the input embedding, so it can be added on the input directly. The vanilla Transformer considered two types of encodings: (1). Sinusoidal positional encoding is defined as follows, given the token $i = 1, …, L$ position and the dimension $\\delta = 1, …, d$: $$ \\text{PE}(i, \\delta) = \\left{ \\begin{aligned} \\sin\\big(\\frac{i}{10000^{2\\delta’/d}}\\big) , if \\delta\u0026=2\\delta’\\ \\cos\\big(\\frac{i}{10000^{2\\delta’/d}}\\big) , if \\delta\u0026=2\\delta’+1 \\ \\end{aligned} \\right.$$ In this way each dimension of the positional encoding corresponds to a sinusoid of different wavelengths in different dimensions, from $2\\pi$ to 10000 * $2\\pi$. (2). Learned positional encoding, as its name suggested, assigns each element with a learned column vector which encodes its absolute position (Gehring, et al. 2017). ","date":"2023-07-15","objectID":"/posts/transformerintroduction/:1:4","tags":["draft"],"title":"Transformer Introduction","uri":"/posts/transformerintroduction/"},{"categories":["Planning"],"content":"[new ref 1] (https://zhuanlan.zhihu.com/p/619039492) [old ref 1] (https://zhuanlan.zhihu.com/p/399545248) ","date":"2023-07-15","objectID":"/posts/latticeplanner/:0:0","tags":["draft"],"title":"Lattice Planner","uri":"/posts/latticeplanner/"},{"categories":["Planning"],"content":"一、Lattice Planner简介 LatticePlanner算法属于一种局部轨迹规划器，输出轨迹将直接输入到控制器，由控制器完成对局部轨迹的跟踪控制。因此，Lattice Planner输出的轨迹是一条光滑无碰撞满足车辆运动学约束和速度约束的平稳安全的局部轨迹。Lattice Planner的输入端主要由三部分组成，感知及障碍物信息、参考线信息及定位信息。 [pic] 局部规划模块的输出是带有速度信息的一系列轨迹点组成的轨迹，其保证了车辆控制器在车辆跟踪控制过程中的平稳性和安全性。 ","date":"2023-07-15","objectID":"/posts/latticeplanner/:1:0","tags":["draft"],"title":"Lattice Planner","uri":"/posts/latticeplanner/"},{"categories":["Planning"],"content":"二、Lattice规划算法实现过程 Lattice规划算法是一种基于采样的运动规划算法，通过将车辆坐标系转换到参考线坐标系，也就是frenet坐标系下，然后在frenet坐标系下分别对frenet的d轴和s轴进行规划，形成frenet坐标系下的规划轨迹，然后将frenet坐标系下的轨迹合成到世界坐标系下还原为世界坐标系下的轨迹。算法实现过程大概可以分为以下几步： 将车辆当前位姿信息转换到frenet坐标系下，获得车辆在frenet坐标系的初始状态；根据当前速度计算前瞻距离，获得前瞻点，获得车辆在前瞻点位置frenet坐标系下的目标状态。 对轨迹状态进行采样，分别是轨迹运行时间t，目标速度v，及到参考线的横向位移d，通过这三个规划参数可以获得采样状态。 构建横向位移和纵向位移的多项式规划函数s(t)，d(s)，获得横向位移和纵向位移的规划函数后，进行时间插值就可以获得参考线frenet坐标系下的轨迹点，最后将轨迹点从frenet坐标系转换到cartesian坐标系，就可以获得物理世界采样轨迹，由于横向和纵向都是通过高次多项式插值获得，以此cartesian坐标系下的轨迹也是光滑的。 采样轨迹的碰撞检测、曲率约束及最优轨迹打分。采样轨迹是一系列满足速度约束的光滑轨迹，但其还需要满足无碰撞和车辆运动学曲率约束的强制约束，及远离障碍物和靠近参考线等组成的代价约束。采样轨迹的打分就是为了获得一条最优的满足约束条件的无碰撞光滑轨迹。该轨迹也是lattice输出到controller用于车辆跟随的轨迹。 Frenet坐标系和Cartesian坐标系的相互转换 Frenet坐标系是参考线上的坐标系，是一个动坐标系。Frenet坐标系的建立，以车辆位置到参考线的最近点R作为frenet坐标系的原点，以参考线切线方向作为T轴，垂直于T轴向外为N轴。如下图所示，是frenet坐标系和cartesian坐标系的相互转换关系，黑色虚线是车辆当前运行的轨迹方向，黑色实线是车辆运行的参考线。 [pic] 如上图所示，参考线（Reference line）是一条光滑的车道线，按上图所示将汽车的坐标点P（图中红色点）投影到参考线上，得到一个参考线上的投影点R（图中绿色点）。从参考线起点到投影点的路径长度就是汽车在Frenet坐标系下的纵向偏移量，用s表示。而投影点到汽车位置的距离 $l(s)$ 则是汽车在Frenet坐标系下的横向偏移量。因为参考线是足够光滑的，我们也可通过汽车的朝向、速度、加速度来计算出Frenet坐标系下，横向和纵向偏移量的一阶导和二阶导。这里将横向偏移量 $l(s)$ 设计成纵向偏移量s的函数。这是因为对于carlike模型的汽车而言，横向运动是由纵向运动诱发的。而\u003c/font color=red\u003e将坐标点转换到frenet坐标系的目的则是为了方便规划曲线的生成和车道线横向和纵向方向上的轨迹采样，从而获得覆盖整个车道的光滑采样轨迹。 frenet坐标系和cartesian坐标系的转换关系可以可以参考如下论文[https://link.zhihu.com/?target=https%3A//www.researchgate.net/profile/Moritz-Werling/publication/224156269_Optimal_Trajectory_Generation_for_Dynamic_Street_Scenarios_in_a_Frenet_Frame/links/54f749df0cf210398e9277af/Optimal-Trajectory-Generation-for-Dynamic-Street-Scenarios-in-a-Frenet-Frame.pdf] 如下所示是两个坐标系之间的变换公式。 ref:https://blog.csdn.net/u013468614/article/details/108748016 cartesian坐标系到frenet坐标系的变换公式： frenet坐标系到cartesian坐标系的变换公式： 上式中，各变量的含义如下： 如下图所示绿色线代表了参考线reference_line，红色和蓝色线代表经过横向偏移位移均匀变化之后形成的路线。 ","date":"2023-07-15","objectID":"/posts/latticeplanner/:2:0","tags":["draft"],"title":"Lattice Planner","uri":"/posts/latticeplanner/"},{"categories":["Planning"],"content":"三、Lattice Planner轨迹采样 Lattice规划器的轨迹采样，主要分为横向采样、纵向采样以及轨迹时间周期采样。 横向轨迹的采样需要涵盖多种横向运动状态，需要根据车道宽度设置横向采样的采样区间，通过横向采样间隔，形成不同的横向采样偏移量。 纵向采样的采样区间可以通过前瞻点的位移长度s，作为基准采样长度，然后通过对轨迹速度ds进行采样。 时间周期采样，就是对轨迹的运行周期时间进行采样。而百度Apollo的轨迹采样，只对横向位移和纵向位移进行了采样，并设计了采样状态横向偏移量，-0.5，0.0和0.5，以及四个到达这些横向偏移量的纵向位移，分别为10，20，40，80来得到采样状态。所以Lattice规划器的轨迹采样主要是对轨迹横纵向状态进行采样，但采样方式可以根据环境情况进行调整。 ","date":"2023-07-15","objectID":"/posts/latticeplanner/:3:0","tags":["draft"],"title":"Lattice Planner","uri":"/posts/latticeplanner/"},{"categories":["Planning"],"content":"四、Lattice Planner速度规划 有了前面的采样状态，现在需要做的是根据采样状态生成横向 $l(s)$ 和纵向 $s(t)$ 和规划函数，两种规划函数都是通过多项式进行拟合求解生成。主要使用了4次和5次多項式拟合，从而满足了车辆运行过程中的一阶导，二阶导连续，也就是速度和加速度连续，保证了轨迹的平滑性要求。 对于纵向轨迹 $s(t)$ ，在停车和跟车状态，都是五次多项式，但对于巡航状态，由于我们不需要确定状态的S值，所以只有五个变量，因此用四次多项式就可以了。对于横向轨迹$l(s)$也使用了五次多项式拟合。 这里规划器的采样方式没有使用Apollo中Lattice的横纵向采样方式，而是采用了上文中提到的采样方式，因此约束变量有： 巡航模式下的纵向拟合函数的求解 ","date":"2023-07-15","objectID":"/posts/latticeplanner/:4:0","tags":["draft"],"title":"Lattice Planner","uri":"/posts/latticeplanner/"},{"categories":["Planning"],"content":"五、轨迹生成及轨迹评价函数 轨迹的生成成就是将frenet坐标系下的轨迹转换到cartesian坐标系中，前面我们知道了位姿点在frenet坐标系和cartesian坐标系的相互转换关系，因此现在我们需要做的就是对横纵向轨迹函数 $s(t)$ 和 $l(s(t))$ 进行轨迹的时间细分形成规划函数的横纵向轨迹规划点 $s(t_i)$ 和 $l(s(t_i))$，该规划点是在frenet坐标系中，因此需要进行frenet坐标系到cartesian坐标系的坐标转换，从而形成控制器可用的采样轨迹。 获得采用轨迹之后，接着需要进行目标轨迹的曲率检查和碰撞检测，目的是为了使目标采样轨迹满足车辆的运动学控制要求和无碰撞要求，这样就形成了安全可靠的轨迹簇。这些轨迹簇都可以满足车辆的控制要求，但并不是最优的，因此需要从轨迹簇中选出一组最优的运行轨迹。这时就需要引入轨迹评价函数，用来对候选轨迹进行打分。 轨迹评价函数主要为了使得目标轨迹尽量靠近静态参考线轨迹运行，同时，速度尽量不发生大突变，满足舒适性要求，且尽量远离障碍物。因此最后轨迹评价函数可以通过如下伪代码描述： $$traj_{cost} = k_{lat} * cost_{lat} + k_{lon} * cost_{lon} + k_{obs} * obs_{cost};$$ 上式中， - k_lat : 表示纵向误差代价权重 - cost_lat： 表示纵向误差，综合考虑纵向速度误差，时间误差及加加速度的影响。 - k_lon : 表示横向误差代价权重 - cost_lon： 表示横向向误差，综合考虑了横向加速度误差及横向偏移误差的影响。 - k_obs : 表示障碍物代价权重 - obs_cost： 表示障碍物距离损失。 最后选择出代价值最好的一条轨迹输入到控制器，用于控制器的跟踪控制。 ","date":"2023-07-15","objectID":"/posts/latticeplanner/:5:0","tags":["draft"],"title":"Lattice Planner","uri":"/posts/latticeplanner/"},{"categories":["Planning"],"content":"ref: [1]. https://blog.csdn.net/qq_41667348/category_11789612.html [2]. https://zhuanlan.zhihu.com/p/492988036 [3]. https://www.zhihu.com/column/c_1020971709242818560 [4]. https://blog.csdn.net/qq_35503971/article/details/106337900 简介 EM Planner是Apollo面向L4的实时运动规划算法，该算法首先通过顶层多车道策略，选择出一条参考路径，再根据这条参考线，在Frenet坐标系下，进行车道级的路径和速度规划，规划主要通过Dynamic Programming和基于样条的Quadratic Programming实现。EM Planner充分考虑了无人车安全性、舒适性、可扩展性的需求，通过考虑交通规则、障碍物决策、轨迹光滑性等要求，可适应高速公路、低速城区场景的规划需求。通过Apollo仿真和在环测试，EM Planner算法体现了高度的可靠性，和低耗时性。 ","date":"2023-07-15","objectID":"/posts/emplanner/:0:0","tags":["draft"],"title":"EM Planner","uri":"/posts/emplanner/"},{"categories":["Planning"],"content":"多车道EM Planner框架 ","date":"2023-07-15","objectID":"/posts/emplanner/:1:0","tags":["draft"],"title":"EM Planner","uri":"/posts/emplanner/"},{"categories":["Planning"],"content":"整体框架 所有规划需要的信息在EM Planner的顶层汇集，然后参考线生成器会生成一些基于障碍物和交通规则的候选车道级参考线，这个过程主要是依赖于高精度地图和Routing模块给出的全局规划结果。以下是车道级的规划过程： 首先会基于给定参考线生成Frenet坐标系，通过给定参考线将所有的自车信息和环境信息转换到参考线下的Frenet坐标系。 接下来所有的车道级信息将会传递给车道级最优求解器，该求解器会求解最优路径和最优速度。在求解最优路径时，周围环境信息将会被投影到Frenet坐标系（E-step），然后基于投影的信息生成一条光滑路径（M-step）。 同样的，在求解最优速度时，一旦生成了一条最优路径，障碍物就会被投影到ST图中（E-step），然后最优速度求解器会生成一条光滑的速度规划（M-step）。结合路径和速度规划结果，就生成了一条给定车道的光滑轨迹。 最后一步会将所有的车道级轨迹传递给参考线轨迹决策器，基于当前车辆状态、相关约束和每条轨迹的代价，轨迹决策器会决定一条最优的轨迹。 ","date":"2023-07-15","objectID":"/posts/emplanner/:1:1","tags":["draft"],"title":"EM Planner","uri":"/posts/emplanner/"},{"categories":["Planning"],"content":"多车道策略 利用搜索算法【2】【3】结合代价估算形成变道策略是一种比较常见的处理变道问题的方法，但是这种方法存在计算量大、难以适用交规以及前后决策可能缺少连贯性等特点。Apollo的解决办法是将多车道策略划分为两种类型：无法通行的被动变道，和能够通行的主动变道。 被动变道一般由道路阻挡造成的，通过全局规划模块重新生成全局路径解决； 主动变道是考虑动态障碍物而做出的决策。Apollo通过同步生成多条候选车道的方法解决主动变道问题，在Frenet坐标系下，投影障碍物、考虑交规后生成多条车道级的候选路径，最后传递到变道决策器中选择出一条最优的车道决策。 ","date":"2023-07-15","objectID":"/posts/emplanner/:1:2","tags":["draft"],"title":"EM Planner","uri":"/posts/emplanner/"},{"categories":["Planning"],"content":"路径-速度迭代算法 在Frenet坐标下的轨迹规划实际上是带约束的3D最优求解问题。该问题一般有两种求解方法：直接3D最优化求解和路径-速度解耦求解。 直接方法【4】【5】试图在SLT坐标系下使用轨迹采样或Lattice搜索,这些方法都受到搜索复杂度的限制，因此搜索结果是次优的。 而路径-速度解耦规划会分别求解路径和速度的最优解。速度的生成将会在生产的路径上进行【6】。虽然结果可能也不是最优的，但会在速度和路径分别求解时更加灵活。 EM Planner迭代地进行路径和速度最优求解，通过估计和来向、低速障碍物的交互，上一帧的速度规划将有助于下一帧的路径规划。然后将路径规划结果再交给速度最优求解器来推算出一个最优的速度结果。 ","date":"2023-07-15","objectID":"/posts/emplanner/:1:3","tags":["draft"],"title":"EM Planner","uri":"/posts/emplanner/"},{"categories":["Planning"],"content":"决策和交通规则约束 交通规则是硬约束，而与障碍物的交互是软约束。一些决策方法直接考虑的是数值上的最优解【7】，也有像【5】一样同时进行规划和决策。而Apollo EM Planner的决策是优先于规划的，决策模块将会为规划带来更明确的意图，减少最优求解的搜索空间。决策部分的第一步是将车辆的运动意图用一根粗略、灵活的轨迹来描述。这条轨迹也可以用来估计与障碍物之间的交互，并且当情景更加复杂时，这种基于轨迹的决策方法也是灵活的。第二步是基于决策生成的轨迹来构造一个凸空间，用来做基于样条光滑的轨迹生成，主要是通过二次规划来达到迭代生产路径、速度解的目的。 ","date":"2023-07-15","objectID":"/posts/emplanner/:1:4","tags":["draft"],"title":"EM Planner","uri":"/posts/emplanner/"},{"categories":["Planning"],"content":"车道级EM PLanner框架 ","date":"2023-07-15","objectID":"/posts/emplanner/:2:0","tags":["draft"],"title":"EM Planner","uri":"/posts/emplanner/"},{"categories":["Planning"],"content":"整体框架 框架包括了一帧规划中的两个E-step和两个M-step，轨迹信息将会在前后两帧中传递，以下是整个车道级规划的流程： 在第一个E-step中，障碍物会被投影到车道Frenet坐标系，障碍物包括了静态障碍物和动态障碍物。静态障碍物会直接从笛卡尔坐标系转换到Frenet坐标系，而动态的信息则以其运动轨迹来描述。通过上一帧的预测信息，和自车的运动信息，可以估算自车和动态障碍物在每个时间点的交互情况，轨迹重叠的部分会被映射到Frenet坐标系中。初次之外，在最优路径求解过程中，动态障碍物的出现会最终导致自车做出避让的决策。因此，出于安全的考虑，SL投影只考虑低速和来向障碍物，而对于高速的动态障碍物，EM Planner的平行变道策略会考虑这种情景。 在第二个E-step，所有的障碍物都会在ST中与生成的速度信息进行估计，如果对应的ST中重叠部分，那么对应区域将会在ST中进行重新生成。 在两次M-step过程中，通过Dynamic Programming和Quadratic Programming生成路径和速度规划。然而在进行投影的SL和ST坐标内求解时非凸的，因此，为了解决这个问题，首先使用Dynamic Programming获得一个粗略的解，同时这个解也能够提供诸如避让、减速、超车的决策。通过这个粗略的解，可以构建一个凸的通道，然后使用基于Quadratic Programming的样条最优求解。 接下来的部分将会详细介绍框架中的步骤。 ","date":"2023-07-15","objectID":"/posts/emplanner/:2:1","tags":["draft"],"title":"EM Planner","uri":"/posts/emplanner/"},{"categories":["Planning"],"content":"SL和ST投影（E-step） SL投影 SL投影是基于类似于【3】中的G2光滑参考线（曲率导数连续）。给定一个时刻，如果自车与预测的障碍物轨迹有重叠区域，那么这个重叠区域将会在SL坐标系被标注为与动态障碍物的估计交互区域。这个区域可以理解为自车和动态障碍物的包围盒的重叠区域。图4展示了这一种案例，红色代表动态障碍物的预测轨迹，用离散点来表示；蓝色表示自车的状态。 ST投影 ST投影用于帮助我们估计自车的速度规划。当生成了一条光滑的路径以后，与自车有交互的动态障碍物和静态障碍物都会被投影到路径上，同理，这种交互也定义为包围盒的重叠。如图5，这是一个ST图投影案例。 红色区域表示在2s处距离自车40m远切入规划路径的动态障碍物ST信息，绿色表示在自车后的动态障碍物ST信息，M-step将会在剩下的区域找到可行光滑最优解。 ","date":"2023-07-15","objectID":"/posts/emplanner/:2:2","tags":["draft"],"title":"EM Planner","uri":"/posts/emplanner/"},{"categories":["Planning"],"content":"DP路径（M-step） M-step求解Frenet坐标系下的最优路径规划，实际上在一个非凸的区间（从左和从右避让是两个局部最优情景）就是找到一个最优的 $l=f(s)$ 方程。主要包括两步：基于Dynamic Programming的路径决策和基于样条的路径规划。 基于Dynamic Programming的路径步骤提供一条粗略的路径信息，其可以带来可行通道和绕障决策，如图6所示，这一步包括Lattice采样、代价函数、Dynamic Programming搜索。 Lattice采样基于Frenet坐标系，多行的点在撒在自车前。如图7所示，行与行之间的点使用五次方多项式连接，而行与行之间的间隔取决于自车速度、道路结构、是否换道等等。出于安全考虑，路径总长可以达到200m或者覆盖8s的行驶长度。 每段Lattice路径的代价通过光滑程度、障碍物避让、车道代价来评价： 而光滑程度又通过以下方程来衡量，一阶导表示朝向偏差，二阶导表示曲率，三阶导表示曲率导数： 障碍物的代价由以下方程给出，方程中的d由自车bounding box到障碍物bounding box的距离表示。迹规划 车道代价由以下方程给出，主要是考虑在道路上与否以及与参考线之间的差异，一般是与车道中心线的差异： ","date":"2023-07-15","objectID":"/posts/emplanner/:2:3","tags":["draft"],"title":"EM Planner","uri":"/posts/emplanner/"},{"categories":["Planning"],"content":"样条QP路径（M-step） 基于样条的路径可以理解为是Dynamic Programming更精细的版本。通过DP采样出的路径生成一条可通行通道，然后在通道中利用基于Quadratic Programming的样条曲线生产光滑路径。具体实例如图8所示，步骤流程可由图9所示： QP的目标函数为： 其中 $ g(s) $ 为DP规划的路径，$ f(s) $ 的一阶导表示朝向、二阶导表示曲率、三阶导表示曲率的导数。该函数描述了避让障碍物和曲线光滑性之间的权衡。 QP的约束包括边界约束和动力学可行性。这些约束都会施加在每个s处，通过限制l来将车辆限制在车道内。由于EM Planner使用的是自行车模型，因此这样对l的限制也是不够的。如图10所示，为了使得边界约束变凸并且线性，在自车的前后两端各增加了一个半圆。前轮到后轮中心的距离用 l_f ​表示，车宽用w表示，因此车的左前角的横向位置可以用以下方程给出： 通过线性化可以变为： 同理，其余三个角的位置都可以被线性化，显然因为 $ \\theta $ 足够小，小于 $ pi/12 $，因此可以这样线性化。 $ f(s) $ 的二阶导和三阶导与动力学可行性相关，除了边界条件以外，生成的路径还应该和自车的初始条件相匹配。因为所有的约束都是线性的，所以使用Quadratic Programming求解非常迅速。 具体的光滑样条曲线和QP问题可以在附录中查阅。 ","date":"2023-07-15","objectID":"/posts/emplanner/:2:4","tags":["draft"],"title":"EM Planner","uri":"/posts/emplanner/"},{"categories":["Planning"],"content":"DP速度求解（M-step） M-step的速度规划是在ST图中求解最优速度规划，即求解出最优函数 S(t)。与求解最优路径相似，在ST图中求解最优速度规划也是非凸的最优化问题。同样也采用Dynamic Programming配合样条曲线Quadratic Programming来找到光滑速度规划。图12是速度求解的pipeline： DP速度求解包括代价函数、ST栅格图以及Dynamic Programming搜索。生成的结果包括分段线性的速度规划、可通行通道以及障碍物速度决策。如图11所示，该结果在QP中用来作为参考速度规划，通过该参考速度生成凸的区域。 在栅格图中，使用有限差分法来估计速度、加速度和jerk： 从DP生成的速度中选择出最优的一条的方法是最小化以下的代价函数： 第一项是速度误差，g用来惩罚与 $ V_ref $ 的不同的误差。第二项、第三项用来描述曲线的光滑程度。最后一项用来描述障碍物代价，以到障碍物的距离来衡量。 DP搜索空间也收到车辆动力学约束，并且也有单调性约束，因为不希望车辆倒退。一些对于动力学约束的必要简化也用来加速算法。 ","date":"2023-07-15","objectID":"/posts/emplanner/:2:5","tags":["draft"],"title":"EM Planner","uri":"/posts/emplanner/"},{"categories":["Planning"],"content":"QP速度求解（M-step） 因为分段线性的速度规划不能满足动力学的要求，所以需要使用Quadratic Programming来填补动力学空缺。图13是样条曲线QP速度求解的pipeline： QP速度求解包括三部分：代价函数、线性约束以及样条曲线QP求解器。 除了初始条件约束以外，主要有以下的边界约束： 第一个约束是单调性约束；第二、第三、第四约束主要是交通规则和车辆动力学约束。通过约束、cost函数计算以后，spline QP speed会生成一条如图14中的光滑可行的速度规划。 结合路径规划，EM Planner最终会生成一条光滑轨迹。 ","date":"2023-07-15","objectID":"/posts/emplanner/:2:6","tags":["draft"],"title":"EM Planner","uri":"/posts/emplanner/"},{"categories":["Planning"],"content":"解QP问题的说明 为了安全考虑，路径和速度大概在100个不同的位置或时间点，那么约束就有超过600个。对于速度、路径求解，分段五次多项式已经足够，因此样条曲线大概有3-5个多项式，大概就有30个参数。因此Quadratic Programming就变成了相对小的目标函数，和相对大的约束。QP能比较好的解决这个问题，并且使用了上一帧的解作为热启动，加速求解过程。实践中，QP问题解的平均时间3ms。 ","date":"2023-07-15","objectID":"/posts/emplanner/:2:7","tags":["draft"],"title":"EM Planner","uri":"/posts/emplanner/"},{"categories":["Planning"],"content":"DP和QP非凸问题的说明 在非凸问题上，DP和QP都有他们单独的限制。DP和QP的组合，能够很好吸收两者优点，并求得一个理性解。 DP:DP的优劣受到撒点分辨率和时间分辨率的影响，通常在运行时间限制的情况下，一般只会得出一个粗糙解而非最优解，比如会从障碍物左侧绕开，但并不是按照最完美的路径绕开。 QP:QP需要在凸空间求解，因此必须借助DP的解来形成凸空间。随机的或者基于规则的决策，通常会给QP带来非凸的空间，因此解QP问题会失败或者陷入局部最优。 DP+QP:（1）通过DP寻求粗糙解；（2）DP解能够生成凸空间；（3）QP在DP解形成的凸空间内，很大可能能够获得全局最优解。 ","date":"2023-07-15","objectID":"/posts/emplanner/:2:8","tags":["draft"],"title":"EM Planner","uri":"/posts/emplanner/"},{"categories":["Planning"],"content":"案例分析 图15展示了EM Planner在规划周期内，帧与帧之间完成最优轨迹规划的过程。 假设自车以10m/s的速度行进，一动态障碍物沿着相反方向朝着我们以同样10m/s的速度驶来，EM Planner按以下步骤迭代生成速度和路径规划： 历史规划（图15-a）：在动态障碍物出现之前，自车以恒定速度10m/s向前行驶。 路径规划迭代1（图15-b）：基于当前车速和动态障碍物的车速，两者将会在S=40m处相遇，因此，最好的方法是在S=40m处绕开障碍物。 速度规划迭代1（图15-c）：基于路径规划结果，即从右侧避开障碍物，自车将调整其速度规划，在避开障碍物之前减速到5m/s。 路径规划迭代2（图15-d）：由于产生了新的速度规划，自车将不再会与动态障碍物在S=40m处避开，而会在一个新的位置S=30m处避开障碍物。因此，路径规划结果也将会随速度规划改变而重新更新。 速度规划迭代2（图15-e）：由于路径规划已经更新，新的绕障位置在S=30m处，因此在S=40处减速也就没有必要了，新的速度规划使得自车可以在S=40m处加速而在S=30m处形成一个光滑的绕障。 经过迭代之后，最终车辆将在S=30m处减速绕障，并且绕障结束之后会加速，这样一个过程和人类驾驶员的表现很相似。 但值得注意的是，并不是每次规划都必须采取如上四步骤，根据场景不同可能会产生更多或更少的步骤。一般而言，场景越复杂，所需要的步骤就越多。 ","date":"2023-07-15","objectID":"/posts/emplanner/:3:0","tags":["draft"],"title":"EM Planner","uri":"/posts/emplanner/"},{"categories":["Planning"],"content":"总结 EM Planner是一种基于弱决策的算法，相比于强决策算法，EM Planner在复杂场景、多障碍物情况下表现更好。强决策依赖于提前制定出的决策行为，并且有难以理解和预测与障碍物交互的缺陷、难以满足大量障碍物阻挡生成基于规则的最佳轨迹的缺陷。 EM Planner通过将三维规划问题转化为两个二维规划问题，显著地降低了运算复杂度，因此会带来运行时间的压缩和整个系统的可交互性。 ","date":"2023-07-15","objectID":"/posts/emplanner/:4:0","tags":["draft"],"title":"EM Planner","uri":"/posts/emplanner/"},{"categories":["Planning"],"content":"决策规划（一）自动驾驶安全、舒适、高效的“守护神” ","date":"2023-07-15","objectID":"/posts/decisionandplanning_1/:1:0","tags":["draft"],"title":"Decision and Planning [1]","uri":"/posts/decisionandplanning_1/"},{"categories":["Planning"],"content":"决策规划分层架构 决策规划的任务，就是在对感知到的周边物体的预测轨迹的基础上，结合自动驾驶车辆的和当前位置，对车辆做出最合理的决策和控制。 正如人的大脑又分为左脑和右脑、并负责不同的任务一样，模块化自动驾驶系统中决策规划层也可以继续细分为执行不同任务的子层。而这一分层设计最早其实是源自2007年举办的DAPRA城市挑战赛，比赛中多数参赛队伍都将自动驾驶系统的决策规划方式包括三层：全局路径规划层（Route Planning）、行为决策层（Behavioral Layer）和运动规划层（Motion Planning），如图5所示。 全局路径规划层聚焦在相对顶层的路径规划，聚焦在分钟到小时级别的规划。该层在接收到输入的目的地信息后，基于存储的地图信息搜素出一条自起始点至目标点的一条可通过的路径。如图6所示，在蓝色起点和黄色终点之间，黑色就是搜索出来的一条可通行的路径，当然路径不止一条，如何搜索出最优是下文将要介绍的内容。 行为决策层在收到全局路径后，结合感知环境信息、交通规则信息、车辆状态信息、驾驶场景信息等，推导判断下一分钟或下一秒时刻的情况，作出车道保持、车辆跟随、车道变换和制动避撞等的适合当前交通环境的驾驶行为。如图8所示，自车在检测到前方存在低速行驶车辆，且右侧车道满足变道条件后，作出向右变道的驾驶行为决策。 运动规划层也被成为局部路径规划层，与全局路径规划聚焦在分钟到小时级别的规划不同，运动规划聚焦在毫秒级到秒级的规划。规划的时候，根据输入的行为决策信息、结合车辆实时位姿信息、局部环境信息、全局路径参考信息等，在“安全、舒适、效率”的精神引领下，规划生成一条满足特定约束条件的平滑轨迹轨迹（包括行驶轨迹、速度、方向等），并输入给控制执行层。 ","date":"2023-07-15","objectID":"/posts/decisionandplanning_1/:1:1","tags":["draft"],"title":"Decision and Planning [1]","uri":"/posts/decisionandplanning_1/"},{"categories":["planning"],"content":"ref: [1]. https://mp.weixin.qq.com/s?__biz=MzI2NDY3OTExNw==\u0026mid=2247487486\u0026idx=1\u0026sn=830e7989f285214903c377b35e4b26d1\u0026chksm=eaa9b45cddde3d4a800aaf20fe318f491db75dda42e195cf14bf40084764c29464e7ccb4aad7\u0026mpshare=1\u0026scene=24\u0026srcid=0304BpDN7zLg79RhCijHZ2vJ\u0026sharer_sharetime=1677894823237\u0026sharer_shareid=56cef55fe29db276ae71bc9f586487a1\u0026key=2feb26e6a61e3d07649dfd6a51be6bb25154bc6376a7efb1822eb9800c6762bdec0839b31eac2d53e7f3a38b41696a04763e2640b202142a465d103b5d979e98f8f58c6e6605e2a76edf1c546c4d4d5f42dfe55935123958e7d001d2f802261f3473e6a62ac38fbb731fa7b486d65f38fe75c7121cb46fbab1e7b14f414379f9\u0026ascene=14\u0026uin=MjUyNzM0ODk1\u0026devicetype=Windows+10+x64\u0026version=6309001c\u0026lang=zh_CN\u0026countrycode=DE\u0026exportkey=n_ChQIAhIQpLbne6sMPw4l4V2IEPhLPxLZAQIE97dBBAEAAAAAAD%2FvOcyN4xcAAAAOpnltbLcz9gKNyK89dVj0cCpL6X4%2F9D%2BOuEd517ZezCwL3LfXM5G32y6FBL094wgcVWCTvgW%2Bz4fcrxht5Et9%2FUDDn2cw7Ay9T9fyCNiz21sZHDrEOhZlmmdWpjj2WKQ1flB1hocdJwzrYu0PN7DoVSQ4LEsw3yErLBUhYBSwGAArxC5y%2FzMbMZ8hFAQhKnpd9GPPRQCQmIeWvMl2Zb6nmhgch5icU5Ro%2F%2BmZx%2BV7tbmT0VIVBN7amHSXzs8eAiXSq0I%3D\u0026acctmode=0\u0026pass_ticket=xjMi8aZX3Oq63c%2B7lWkTHtjTObwzDeknqt%2FUl2bVeVY8VC%2F1bfFzwKgz6ydTfuv150JdS2QIagqoczC%2FeNOvBg%3D%3D\u0026wx_header=1\u0026fontgear=2 ","date":"2023-07-15","objectID":"/posts/decisionandplanning_4/:0:0","tags":["draft"],"title":"Decision and Planning [4]","uri":"/posts/decisionandplanning_4/"},{"categories":["planning"],"content":"决策规划（四）行为决策常用算法 满足两个要求: 安全性和舒适性 运动规划生成的轨迹是一种由二维空间和一维时间组成的三维空间中的曲线，是一种偏实时的路径规划。 ","date":"2023-07-15","objectID":"/posts/decisionandplanning_4/:1:0","tags":["draft"],"title":"Decision and Planning [4]","uri":"/posts/decisionandplanning_4/"},{"categories":["planning"],"content":"PRM 概率路标法 (Probabilistic Road Maps, PRM），是一种经典的采样方法，由Lydia E.等人在1996年提出。PRM主要包含三个阶段，一是采样阶段，二是碰撞检测阶段，三是搜索阶段。 采样阶段: 在采样阶段中，PRM首先在地图空间进行均匀的随机采样，也就是对地图进行稀疏采样，目的是将大地图简化为较少的采样点。 碰撞检测阶段: 剔除落在障碍物上的采样点，并将剩下的点与其一定距离范围内的点相连，同时删除穿越障碍物的连线，从而构成一张无向图。 搜索阶段: 利用全局路径规划算法章节介绍的搜索算法（Dijkstra、A*等）在无向图中进行搜索，从而找出一条起点A到终点B之间的可行路径。 算法步骤可以总结为： （1）构造无向图G =（V，E），其中V代表随机采样的点集，E代表两采样点之间所有可能的无碰撞路径，G初始状态为空。 （2）随机撒点，并选取一个无碰撞的点c(i)加入到V中。 （3）定义距离r，如果c(i)与V中某些点的距离小于r，则将V中这些点定义为c(i)的邻域点。 （4）将c(i)与其邻域点相连，生成连线t，并检测连线t是否与障碍物发生碰撞，如果无碰撞，则将t加入E中。 （5）重复步骤2-4，直到所有采样点（满足采样数量要求）均已完成上述步骤。 （5）采用图搜索算法对无向图G进行搜索，如果能找到起始点A到终点B的路线，说明存在可行的行驶轨迹。 PRM算法相比基于搜索的算法，简化了环境、提高了效率。但是在有狭窄通道场景中，很难采样出可行路径，效率会大幅降低。 ","date":"2023-07-15","objectID":"/posts/decisionandplanning_4/:1:1","tags":["draft"],"title":"Decision and Planning [4]","uri":"/posts/decisionandplanning_4/"},{"categories":["planning"],"content":"RRT 快速探索随机树（Rapidly Exploring Random Trees，RRT），是Steven M. LaValle和James J. Kuffner Jr.在1998年提出的一种基于随机生长树思想实现对非凸高维空间快速搜索的算法。 与PRM相同的是两者都是基于随机采样的算法，不同的是PRM最终生成的是一个无向图，而RRT生成的是一个随机树。RRT的最显著特征就是具备空间探索的能力，即从一点向外探索拓展的特征。 RRT分单树和双树两种类型，单树RRT将起点作为随机树的根节点，通过随机采样、碰撞检测的方式为随机树增加叶子节点，最终生成一颗随机树。而双树RRT则拥有两颗随机树，分别以起点和终点为根节点，以同样的方式进行向外的探索，直到两颗随机树相遇，从而达到提高规划效率的目的。 对于单树RRT算法，我们将起点A设置为随机树的根，并生成一个随机采样点，如图27所示，随机采样点有下面这几种情况。 （1）随机采样点1落在自由区域中，但是根节点A和随机采样点1之间的连线存在障碍物，无法通过碰撞检测，采样点1会被舍弃，重新再生成随机采样点。 （2）随机采样点2落在障碍物的位置，采样点2也会被舍弃，重新再生成随机采样点。 （3）随机采样点3落在自由区域，且与根节点A之间的连线不存在障碍物，但是超过根节点的步长限制。但此时这个节点不会被简单的舍弃掉，而是会沿着根节点和随机采样点3的连线，找出符合步长限制的中间点，将这个中间点作为新的采样点，也就是图29中的4。 接着我们继续生成新的随机采样点，如果新的随机采样点位于自由区域，那么我们就可以遍历随机树中已有的全部节点，找出距离新的随机采样点最近的节点，同时求出两者之间的距离，如果满足步长限制的话，我们将接着对这两个节点进行碰撞检测，如果不满足步长限制的话，我们需要沿着新的随机采样点和最近的节点的连线方向，找出一个符合步长限制的中间点，用来替代新的随机采样点。最后如果新的随机采样点和最近的节点通过了碰撞检测，就意味着二者之间存在边，我们便可以将新的随机采样点添加进随机树中，并将最近的点设置为新的随机采样点的父节点。 重复上述过程，直到新的随机采样点在终点的步长限制范围内，且满足碰撞检测。则将新的随机采样点设为终点B的父节点，并将终点加入随机树，从而完成迭代，生成如图30所示的完整随机树。 相比PRM，RRT无需搜索步骤、效率更高。通过增量式扩展的方式，找到路径后就立即结束，搜索终点的目的性更强。但是RRT作为一种纯粹的随机搜索算法，对环境类型不敏感，当地图空间中存在狭窄通道时，因被采样的概率低，导致算法的收敛速度慢，效率会大幅下降，有时候甚至难以在有狭窄通道的环境找到路径。 图31展示了 RRT应对存在狭窄通道地图空间时的两种表现，一种是RRT很快就找到了出路，一种是一直被困在障碍物里面。 围绕如何更好的“进行随机采样”、“定义最近的点”以及“进行树的扩展”等方面，诞生了多种改进型的算法，包括双树RRT-Connect（双树）、lazy-RRT, RRT-Extend等。 PRM和RRT都是一个概率完备但非最优的路径规划算法，也就是只要起点和终点之间存在有效的路径，那么只要规划的时间足够长，采样点足够多，必然可以找到有效的路径。但是这个解无法保证是最优的。 采用PRM和RRT等随机采样算法生成的行驶轨迹，大多是一条条线段，线段之间的曲率也不不连续，这样的行驶轨迹是不能保证舒适性的，所以还需要进一步进行曲线平滑、角度平滑处理。代表算法是基于曲线插值的方法：RS曲线、Dubins曲线、多项式曲线、贝塞尔曲线和样条曲线等。 所有基于曲线插值方法要解决的问题就是：在图32上的若干点中，求出一条光滑曲线尽可能逼近所有点。下文以多项式曲线和贝塞尔曲线为例，介绍曲线插值算法的示例。 ","date":"2023-07-15","objectID":"/posts/decisionandplanning_4/:1:2","tags":["draft"],"title":"Decision and Planning [4]","uri":"/posts/decisionandplanning_4/"},{"categories":["planning"],"content":"多项式曲线 ","date":"2023-07-15","objectID":"/posts/decisionandplanning_4/:1:3","tags":["draft"],"title":"Decision and Planning [4]","uri":"/posts/decisionandplanning_4/"},{"categories":["Planning"],"content":"ref: [1] https://mp.weixin.qq.com/s/hgT-a3Ug9578k1DmioRgUg [2] http://www.gamedev.net/reference/articles/article2003.asp A*算法详解 ","date":"2023-07-15","objectID":"/posts/a_star/:0:0","tags":["Planning"],"title":"A star (A*) 算法","uri":"/posts/a_star/"},{"categories":["Planning"],"content":"0. 概述 虽然掌握了 A* 算法的人认为它容易，但是对于初学者来说， A* 算法还是很复杂的。 ","date":"2023-07-15","objectID":"/posts/a_star/:1:0","tags":["Planning"],"title":"A star (A*) 算法","uri":"/posts/a_star/"},{"categories":["Planning"],"content":"1. 搜索区域(The Search Area) 我们假设某人要从 A 点移动到 B 点，但是这两点之间被一堵墙隔开。如图 1 ，绿色是 A ，红色是 B ，中间蓝色是墙。 图 1 你应该注意到了，我们把要搜寻的区域划分成了正方形的格子。这是寻路的第一步，简化搜索区域，就像我们这里做的一样。这个特殊的方法把我们的搜索区域简化为了 2 维数组。数组的每一项代表一个格子，它的状态就是可走 (walkalbe) 和不可走 (unwalkable) 。通过计算出从 A 到 B需要走过哪些方格，就找到了路径。一旦路径找到了，人物便从一个方格的中心移动到另一个方格的中心，直至到达目的地。 方格的中心点我们称为“节点 (nodes) ”。如果你读过其他关于 A* 寻路算法的文章，你会发现人们常常都在讨论节点。为什么不直接描述为方格呢？因为我们有可能把搜索区域划为为其他多变形而不是正方形，例如可以是六边形，矩形，甚至可以是任意多边形。而节点可以放在任意多边形里面，可以放在多边形的中心，也可以放在多边形的边上。我们使用这个系统，因为它最简单。 ","date":"2023-07-15","objectID":"/posts/a_star/:2:0","tags":["Planning"],"title":"A star (A*) 算法","uri":"/posts/a_star/"},{"categories":["Planning"],"content":"2. 开始搜索(Starting the Search) 一旦我们把搜寻区域简化为一组可以量化的节点后，就像上面做的一样，我们下一步要做的便是查找最短路径。在 A* 中，我们从起点开始，检查其相邻的方格，然后向四周扩展，直至找到目标。 我们这样开始我们的寻路旅途： 从起点 A 开始，并把它就加入到一个由方格组成的 open list( 开放列表 ) 中。这个 open list 有点像是一个购物单。当然现在 open list 里只有一项，它就是起点 A ，后面会慢慢加入更多的项。 Open list 里的格子是路径可能会是沿途经过的，也有可能不经过。基本上 open list 是一个待检查的方格列表。 查看与起点 A 相邻的方格 ( 忽略其中墙壁所占领的方格，河流所占领的方格及其他非法地形占领的方格 ) ，把其中可走的 (walkable) 或可到达的 (reachable) 方格也加入到 open list 中。把起点 A 设置为这些方格的父亲 (parent node 或 parent square) 。当我们在追踪路径时，这些父节点的内容是很重要的。稍后解释。 把 A 从 open list 中移除，加入到 close list( 封闭列表 ) 中， close list 中的每个方格都是现在不需要再关注的。 如下图所示，深绿色的方格为起点，它的外框是亮蓝色，表示该方格被加入到了 close list 。与它相邻的黑色方格是需要被检查的，他们的外框是亮绿色。每个黑方格都有一个灰色的指针指向他们的父节点，这里是起点 A 。 图 2 下一步，我们需要从 open list 中选一个与起点 A 相邻的方格，按下面描述的一样或多或少的重复前面的步骤。但是到底选择哪个方格好呢？具有最小 F 值的那个。 ","date":"2023-07-15","objectID":"/posts/a_star/:3:0","tags":["Planning"],"title":"A star (A*) 算法","uri":"/posts/a_star/"},{"categories":["Planning"],"content":"3. 路径排序(Path Sorting) 计算出组成路径的方格的关键是下面这个等式： $$F = G + H \\tag{1}$$ 这里， G = 从起点 A 移动到指定方格的移动代价，沿着到达该方格而生成的路径。 H = 从指定的方格移动到终点 B 的估算成本。这个通常被称为试探法，有点让人混淆。为什么这么叫呢，因为这是个猜测。直到我们找到了路径我们才会知道真正的距离，因为途中有各种各样的东西 ( 比如墙壁，水等 ) 。本教程将教你一种计算 H 的方法，你也可以在网上找到其他方法。 我们的路径是这么产生的：反复遍历 open list ，选择 F 值最小的方格。这个过程稍后详细描述。我们还是先看看怎么去计算上面的等式。 如上所述， G 是从起点Ａ移动到指定方格的移动代价。在本例中，横向和纵向的移动代价为 10 ，对角线的移动代价为 14 。之所以使用这些数据，是因为实际的对角移动距离是 2 的平方根，或者是近似的 1.414 倍的横向或纵向移动代价。使用 10 和 14 就是为了简单起见。比例是对的，我们避免了开放和小数的计算。这并不是我们没有这个能力或是不喜欢数学。使用这些数字也可以使计算机更快。稍后你便会发现，如果不使用这些技巧，寻路算法将很慢。 既然我们是沿着到达指定方格的路径来计算 G 值，那么计算出该方格的 G 值的方法就是找出其父亲的 G 值，然后按父亲是直线方向还是斜线方向加上 10 或 14 。随着我们离开起点而得到更多的方格，这个方法会变得更加明朗。 有很多方法可以估算 H 值。这里我们使用 Manhattan 方法，计算从当前方格横向或纵向移动到达目标所经过的方格数，忽略对角移动，然后把总数乘以 10 。之所以叫做 Manhattan 方法，是因为这很像统计从一个地点到另一个地点所穿过的街区数，而你不能斜向穿过街区。重要的是，计算 H 时，要忽略路径中的障碍物。这是对剩余距离的估算值，而不是实际值，因此才称为试探法。 把 G 和 H 相加便得到 F 。我们第一步的结果如下图所示。每个方格都标上了 F ， G ， H 的值，就像起点右边的方格那样，左上角是 F ，左下角是 G ，右下角是 H 。 图 3 好，现在让我们看看其中的一些方格。在标有字母的方格， G = 10 。这是因为水平方向从起点到那里只有一个方格的距离。与起点直接相邻的上方，下方，左方的方格的 G 值都是 10 ，对角线的方格 G 值都是 14 。 H 值通过估算起点于终点 ( 红色方格 ) 的 Manhattan 距离得到，仅作横向和纵向移动，并且忽略沿途的墙壁。使用这种方式，起点右边的方格到终点有 3 个方格的距离，因此 H = 30 。这个方格上方的方格到终点有 4 个方格的距离 ( 注意只计算横向和纵向距离 ) ，因此 H = 40 。对于其他的方格，你可以用同样的方法知道 H 值是如何得来的。 每个方格的 F 值，再说一次，直接把 G 值和 H 值相加就可以了。 ","date":"2023-07-15","objectID":"/posts/a_star/:4:0","tags":["Planning"],"title":"A star (A*) 算法","uri":"/posts/a_star/"},{"categories":["Planning"],"content":"4. 继续搜索(Continuing the Search) 为了继续搜索，我们从 open list 中选择 F 值最小的 ( 方格 ) 节点，然后对所选择的方格作如下操作： 把它从 open list 里取出，放到 close list 中。 检查所有与它相邻的方格，忽略其中在 close list 中或是不可走 (unwalkable) 的方格 ( 比如墙，水，或是其他非法地形 ) ，如果方格不在open lsit 中，则把它们加入到 open list 中。 把我们选定的方格设置为这些新加入的方格的父亲。 如果某个相邻的方格已经在 open list 中，则检查这条路径是否更优，也就是说，经由当前方格 ( 我们选中的方格 ) 到达那个方格是否具有更小的 G 值。如果没有，不做任何操作。 相反，如果 G 值更小，则把那个方格的父亲设为当前方格 ( 我们选中的方格 ) ，然后重新计算那个方格的 F 值和 G 值。如果你还是很混淆，请参考下图。 图 4 Ok ，让我们看看它是怎么工作的。在我们最初的 9 个方格中，还有 8 个在 open list 中，起点被放入了 close list 中。在这些方格中，起点右边的格子的 F 值 40 最小，因此我们选择这个方格作为下一个要处理的方格。它的外框用蓝线打亮。 首先，我们把它从 open list 移到 close list 中 ( 这就是为什么用蓝线打亮的原因了 ) 。然后我们检查与它相邻的方格。它右边的方格是墙壁，我们忽略。它左边的方格是起点，在 close list 中，我们也忽略。其他 4 个相邻的方格均在 open list 中，我们需要检查经由这个方格到达那里的路径是否更好，使用 G 值来判定。让我们看看上面的方格。它现在的 G 值为 14 。如果我们经由当前方格到达那里， G 值将会为 20(其中 10 为到达当前方格的 G 值，此外还要加上从当前方格纵向移动到上面方格的 G 值 10) 。显然 20 比 14 大，因此这不是最优的路径。如果你看图你就会明白。直接从起点沿对角线移动到那个方格比先横向移动再纵向移动要好。 当把 4 个已经在 open list 中的相邻方格都检查后，没有发现经由当前方格的更好路径，因此我们不做任何改变。现在我们已经检查了当前方格的所有相邻的方格，并也对他们作了处理，是时候选择下一个待处理的方格了。 因此再次遍历我们的 open list ，现在它只有 7 个方格了，我们需要选择 F 值最小的那个。有趣的是，这次有两个方格的 F 值都 54 ，选哪个呢？没什么关系。从速度上考虑，选择最后加入 open list 的方格更快。这导致了在寻路过程中，当靠近目标时，优先使用新找到的方格的偏好。但是这并不重要。 ( 对相同数据的不同对待，导致两中版本的 A* 找到等长的不同路径 ) 。 我们选择起点右下方的方格，如下图所示。 图 5 这次，当我们检查相邻的方格时，我们发现它右边的方格是墙，忽略之。上面的也一样。 我们把墙下面的一格也忽略掉。为什么？因为如果不穿越墙角的话，你不能直接从当前方格移动到那个方格。你需要先往下走，然后再移动到那个方格，这样来绕过墙角。 ( 注意：穿越墙角的规则是可选的，依赖于你的节点是怎么放置的 ) 这样还剩下 5 个相邻的方格。当前方格下面的 2 个方格还没有加入 open list ，所以把它们加入，同时把当前方格设为他们的父亲。在剩下的3 个方格中，有 2 个已经在 close list 中 ( 一个是起点，一个是当前方格上面的方格，外框被加亮的 ) ，我们忽略它们。最后一个方格，也就是当前方格左边的方格，我们检查经由当前方格到达那里是否具有更小的 G 值。没有。因此我们准备从 open list 中选择下一个待处理的方格。 不断重复这个过程，直到把终点也加入到了 open list 中，此时如下图所示。 图 6 注意，在起点下面 2 格的方格的父亲已经与前面不同了。之前它的 G 值是 28 并且指向它右上方的方格。现在它的 G 值为 20 ，并且指向它正上方的方格。这在寻路过程中的某处发生，使用新路径时 G 值经过检查并且变得更低，因此父节点被重新设置， G 和 F 值被重新计算。尽管这一变化在本例中并不重要，但是在很多场合中，这种变化会导致寻路结果的巨大变化。 那么我们怎么样去确定实际路径呢？很简单，从终点开始，按着箭头向父节点移动，这样你就被带回到了起点，这就是你的路径。如下图所示。从起点 A 移动到终点 B 就是简单从路径上的一个方格的中心移动到另一个方格的中心，直至目标。就是这么简单！ 图 7 ","date":"2023-07-15","objectID":"/posts/a_star/:5:0","tags":["Planning"],"title":"A star (A*) 算法","uri":"/posts/a_star/"},{"categories":["Planning"],"content":"5. A*算法总结(Summary of the A* Method) Ok ，现在你已经看完了整个的介绍，现在我们把所有步骤放在一起： 把起点加入 open list 。 重复如下过程： a. 遍历 open list ，查找 F 值最小的节点，把它作为当前要处理的节点。 b. 把这个节点移到 close list 。 c. 对当前方格的 8 个相邻方格的每一个方格执行如下操作: 如果它是不可抵达的或者它在 close list 中，忽略它。否则，做如下操作。 如果它不在 open list 中，把它加入 open list ，并且把当前方格设置为它的父亲，记录该方格的 F ， G 和 H 值。 如果它已经在 open list 中，检查这条路径 ( 即经由当前方格到达它那里 ) 是否更好，用 G 值作参考。更小的 G 值表示这是更好的路径。如果是这样，把它的父亲设置为当前方格，并重新计算它的 G 和 F 值。如果你的 open list 是按 F 值排序的话，改变后你可能需要重新排序。 d. 停止，当你 把终点加入到了 open list 中，此时路径已经找到了，或者 查找终点失败，并且 open list 是空的，此时没有路径。 保存路径。从终点开始，每个方格沿着父节点移动直至起点，这就是你的路径。 ","date":"2023-07-15","objectID":"/posts/a_star/:6:0","tags":["Planning"],"title":"A star (A*) 算法","uri":"/posts/a_star/"},{"categories":["Planning"],"content":"6. 题外话(Small Rant) 请原谅我的离题，当你在网上或论坛上看到各种关于 A* 算法的讨论时，你偶尔会发现一些 A* 的代码，实际上他们不是。要使用 A* ，你必须包含上面讨论的所有元素 —- 尤其是 open list ， close list 和路径代价 G ， H 和 F 。也有很多其他的寻路算法，这些算法并不是 A* 算法， A* 被认为是最好的。在本文末尾引用的一些文章中 Bryan Stout 讨论了他们的一部分，包括他们的优缺点。在某些时候你可以二中择一，但你必须明白自己在做什么。 Ok ，不废话了。回到文章。 ","date":"2023-07-15","objectID":"/posts/a_star/:7:0","tags":["Planning"],"title":"A star (A*) 算法","uri":"/posts/a_star/"},{"categories":["Planning"],"content":"7. 实现的注解(Notes on Implemetation) 现在你已经明白了基本方法，这里是你在写自己的程序是需要考虑的一些额外的东西。下面的材料引用了一些我用 C++ 和 Basic 写的程序，但是对其他语言同样有效。 维护 Open List ：这是 A* 中最重要的部分。每次你访问 Open list ，你都要找出具有最小 F 值的方格。有几种做法可以做到这个。你可以随意保存路径元素，当你需要找到具有最小 F 值的方格时，遍历整个 open list 。这个很简单，但对于很长的路径会很慢。这个方法可以通过维护一个排好序的表来改进，每次当你需要找到具有最小 F 值的方格时，仅取出表的第一项即可。我写程序时，这是我用的第一个方法。 对于小地图，这可以很好的工作，但这不是最快的方案。追求速度的 A* 程序员使用了叫做二叉堆的东西，我的程序里也用了这个。以我的经验，这种方法在多数场合下会快 2—3 倍，对于更长的路径速度成几何级数增长 (10 倍甚至更快 ) 。如果你想更多的了解二叉堆，请阅读Using Binary Heaps in A* Pathfinding 。 其他单位：如果你碰巧很仔细的看了我的程序，你会注意到我完全忽略了其他单位。我的寻路者实际上可以互相穿越。这取决于游戏，也许可以，也许不可以。如果你想考虑其他单位，并想使他们移动时绕过彼此，我建议你的寻路程序忽略它们，再写一些新的程序来判断两个单位是否会发生碰撞。如果发生碰撞，你可以产生一个新的路径，或者是使用一些标准的运动法则（比如永远向右移动，等等）直至障碍物不在途中，然后产生一个新的路径。为什么在计算初始路径是不包括其他单位呢？因为其他单位是可以动的，当你到达的时候它们可能不在自己的位置上。这可以产生一些怪异的结果，一个单位突然转向来避免和一个已不存在的单位碰撞，在它的路径计算出来后和穿越它路径的那些单位碰撞了。 在寻路代码中忽略其他单位，意味着你必须写另一份代码来处理碰撞。这是游戏的细节，所以我把解决方案留给你。本文末尾引用的 Bryan Stout’s 的文章中的几种解决方案非常值得了解。 一些速度方面的提示：如果你在开发自己的 A* 程序或者是改编我写的程序，最后你会发现寻路占用了大量的 CPU 时间，尤其是当你有相当多的寻路者和一块很大的地图时。如果你阅读过网上的资料，你会发现就算是开发星际争霸，帝国时代的专家也是这样。如果你发现事情由于寻路而变慢了，这里有些主意很不错： ◆ 使用小地图或者更少的寻路者。 ◆ 千万不要同时给多个寻路者寻路。取而代之的是把它们放入队列中，分散到几个游戏周期中。如果你的游戏以每秒 40 周期的速度运行，没人能察觉到。但是如果同时有大量的寻路者在寻路的话，他们会马上就发现游戏慢下来了。 ◆ 考虑在地图中使用更大的方格。这减少了寻路时需要搜索的方格数量。如果你是有雄心的话，你可以设计多套寻路方案，根据路径的长度而使用在不同场合。这也是专业人士的做法，对长路径使用大方格，当你接近目标时使用小方格。如果你对这个有兴趣，请看 Two-Tiered A* Pathfinding 。 ◆ 对于很长的路径，考虑使用路径点系统，或者可以预先计算路径并加入游戏中。 ◆ 预先处理你的地图，指出哪些区域是不可到达的。这些区域称为“孤岛”。实际上，他们可以是岛屿，或者是被墙壁等包围而不可到达的任意区域。 A* 的下限是，你告诉他搜寻通往哪些区域的路径时，他会搜索整个地图，直到所有可以抵达的方格都通过 open list 或 close list 得到了处理。这会浪费大量的 CPU 时间。这可以通过预先设定不可到达的区域来解决。在某种数组中记录这些信息，在寻路前检查它。在我的 Blitz 版程序中，我写了个地图预处理程序来完成这个。它可以提前识别寻路算法会忽略的死路径，这又进一步提高了速度。 不同的地形损耗：在这个教程和我的程序中，地形只有 2 种：可抵达的和不可抵达的。但是如果你有些可抵达的地形，移动代价会更高些，沼泽，山丘，地牢的楼梯等都是可抵达的地形，但是移动代价比平地就要高。类似的，道路的移动代价就比它周围的地形低。 在你计算给定方格的 G 值时加上地形的代价就很容易解决了这个问题。简单的给这些方格加上一些额外的代价就可以了。 A* 算法用来查找代价最低的路径，应该很容易处理这些。在我的简单例子中，地形只有可达和不可达两种， A* 会搜寻最短和最直接的路径。但是在有地形代价的环境中，代价最低的的路径可能会很长。 就像沿着公路绕过沼泽而不是直接穿越它。 另一个需要考虑的是专家所谓的“ influence Mapping ”，就像上面描述的可变成本地形一样，你可以创建一个额外的计分系统，把它应用到寻路的 AI 中。假设你有这样一张地图，地图上有个通道穿过山丘，有大批的寻路者要通过这个通道，电脑每次产生一个通过那个通道的路径都会变得很拥挤。如果需要，你可以产生一个 influence map ，它惩罚那些会发生大屠杀的方格。这会让电脑选择更安全的路径，也可以帮助它避免因为路径短（当然也更危险）而持续把队伍或寻路者送往某一特定路径。 维护未探测的区域：你玩 PC 游戏的时候是否发现电脑总是能精确的选择路径，甚至地图都未被探测。对于游戏来说，寻路过于精确反而不真实。幸运的是，这个问题很容易修正。答案就是为每个玩家和电脑（每个玩家，不是每个单位 — 那会浪费很多内存）创建一个独立的 knownWalkability 数组。每个数组包含了玩家已经探测的区域的信息，和假设是可到达的其他区域，直到被证实。使用这种方法，单位会在路的死端徘徊，并会做出错误的选择，直到在它周围找到了路径。地图一旦被探测了，寻路又向平常一样工作。 平滑路径： A* 自动给你花费最小的，最短的路径，但它不会自动给你最平滑的路径。看看我们的例子所找到的路径（图 7 ）。在这条路径上，第一步在起点的右下方，如果第一步在起点的正下方是不是路径会更平滑呢？ 有几个方法解决这个问题。在你计算路径时，你可以惩罚那些改变方向的方格，把它的 G 值增加一个额外的开销。另一种选择是，你可以遍历你生成的路径，查找那些用相邻的方格替代会使路径更平滑的地方。要了解更多，请看 Toward More Realistic Pathfinding 。 非方形搜索区域：在我们的例子中，我们使用都是 2D 的方形的区域。你可以使用不规则的区域。想想冒险游戏中的那些国家，你可以设计一个像那样的寻路关卡。你需要建立一张表格来保存国家相邻关系，以及从一个国家移动到另一个国家的 G 值。你还需要一个方法了估算 H 值。其他的都可以向上面的例子一样处理。当你向 open list 添加新项时，不是使用相邻的方格，而是查看表里相邻的国家。 类似的，你可以为一张固定地形的地图的路径建立路径点系统。路径点通常是道路或地牢通道的转折点。作为游戏设计者，你可以预先设定路径点。如果两个路径点的连线没有障碍物的话它们被视为相邻的。在冒险游戏的例子中，你可以保存这些相邻信息在某种表中，当 open list 增加新项时使用。然后记录 G 值（可能用两个结点间的直线距离）和 H 值（可能使用从节点到目标的直线距离）。其它的都想往常一样处理。 ","date":"2023-07-15","objectID":"/posts/a_star/:8:0","tags":["Planning"],"title":"A star (A*) 算法","uri":"/posts/a_star/"},{"categories":["Planning"],"content":"8. 进一步阅读(Further Reading) Ok ，现在你已经对 A* 有了个基本的了解，同时也认识了一些高级的主题。我强烈建议你看看我的代码，压缩包里包含了 2 个版本的实现，一个是 C++ ，另一个是 Blitz Basic 。 2 个版本都有注释，你以该可以很容易就看懂。下面是链接： Sample Code: A* Pathfinder (2D) Version 1.71 。 如果你不会使用 C++ 或是 BlitzBasic ，在 C++ 版本下你可以找到两个 exe 文件。 BlitzBasic 版本必须去网站 Blitz Basic 下载 BlitzBasic 3D 的免费 Demo 才能运行。 在这里 here 你可以看到一个 Ben O’Neill 的 A* 在线验证实例。 你应该阅读下面这几个站点的文章。在你读完本教程后你可以更容易理解他们。 Amit’s A* Pages ： Amit Patel 的这篇文章被广泛引用，但是如果你没有阅读本教程的话，你可能会感到很迷惑。尤其是你可以看到 Amit Patel自己的一些想法。 Smart Moves: Intelligent Path Finding ： Bryan Stout 的这篇需要去 Gamasutra.com 注册才能阅读。 Bryan 用 Delphi 写的程序帮助我学习了A* ，同时给了我一些我的程序中的一些灵感。他也阐述了 A* 的其他选择。 Terrain Analysis ： Dave Pottinger 一篇非常高阶的，有吸引力的文章。他是 Ensemble Studios 的一名专家。这个家伙调整了游戏帝国时代和王者时代。不要期望能够读懂这里的每一样东西，但是这是一篇能给你一些不错的主意的很有吸引力的文章。它讨论了包 mip-mapping ， influence mapping ，和其他高阶 AI 寻路主题。他的 flood filling 给了我在处理死路径 ”dead ends” 和孤岛 ”island” 时的灵感。这包含在我的 Blitz版本的程序里。 ","date":"2023-07-15","objectID":"/posts/a_star/:9:0","tags":["Planning"],"title":"A star (A*) 算法","uri":"/posts/a_star/"},{"categories":["Distributed Computing"],"content":"TensorRT 介绍 TensorRT是一个高性能的深度学习推理（Inference）优化器，可以为深度学习应用提供低延迟、高吞吐率的部署推理。TensorRT可用于对超大规模数据中心、嵌入式平台或自动驾驶平台进行推理加速。TensorRT现已能支持TensorFlow、Caffe、Mxnet、Pytorch等几乎所有的深度学习框架，将TensorRT和NVIDIA的GPU结合起来，能在几乎所有的框架中进行快速和高效的部署推理。 TensorRT 是一个C++库，从 TensorRT 3 开始提供C++ API和Python API，主要用来针对 NVIDIA GPU进行 高性能推理（Inference）加速。 由以上图可以很清楚的看出，训练(training)和 推理(inference)的区别： **训练(training)**包含了前向传播和后向传播两个阶段，针对的是训练集。训练时通过误差反向传播来不断修改网络权值(weights)。 **推理(inference)**只包含前向传播一个阶段，针对的是除了训练集之外的新数据。可以是测试集，但不完全是，更多的是整个数据集之外的数据。其实就是针对新数据进行预测，预测时，速度是一个很重要的因素。 一般的深度学习项目，训练时为了加快速度，会使用多GPU分布式训练。但在部署推理时，为了降低成本，往往使用单个GPU机器甚至嵌入式平台（比如 NVIDIA Jetson）进行部署，部署端也要有与训练时相同的深度学习环境，如caffe，TensorFlow等。 由于训练的网络模型可能会很大（比如，inception，resnet等），参数很多，而且部署端的机器性能存在差异，就会导致推理速度慢，延迟高。这对于那些高实时性的应用场合是致命的，比如自动驾驶要求实时目标检测，目标追踪等。所以为了提高部署推理的速度，出现了很多轻量级神经网络，比如squeezenet，mobilenet，shufflenet等。基本做法都是基于现有的经典模型提出一种新的模型结构，然后用这些改造过的模型重新训练，再重新部署。 而tensorRT 则是对训练好的模型进行优化。 tensorRT就只是 推理优化器。当你的网络训练完之后，可以将训练模型文件直接丢进tensorRT中，而不再需要依赖深度学习框架（Caffe，TensorFlow等），如下: 可以认为tensorRT是一个只有前向传播的深度学习框架，这个框架可以将 Caffe，TensorFlow的网络模型解析，然后与tensorRT中对应的层进行一一映射，把其他框架的模型统一全部 转换到tensorRT中，然后在tensorRT中可以针对NVIDIA自家GPU实施优化策略，并进行部署加速。 目前TensorRT8.0 几乎可以支持所有常用的深度学习框架，对于caffe和TensorFlow来说，tensorRT可以直接解析他们的网络模型；对于caffe2，pytorch，mxnet，chainer，CNTK等框架则是首先要将模型转为 ONNX 的通用深度学习模型，然后对ONNX模型做解析。而tensorflow和MATLAB已经将TensorRT集成到框架中去了。 **ONNX(Open Neural Network Exchange)**是微软和Facebook携手开发的开放式神经网络交换工具，也就是说不管用什么框架训练，只要转换为ONNX模型，就可以放在其他框架上面去inference。这是一种统一的神经网络模型定义和保存方式，上面提到的除了tensorflow之外的其他框架官方应该都对onnx做了支持，而ONNX自己开发了对tensorflow的支持。从深度学习框架方面来说，这是各大厂商对抗谷歌tensorflow垄断地位的一种有效方式；从研究人员和开发者方面来说，这可以使开发者轻易地在不同机器学习工具之间进行转换，并为项目选择最好的组合方式，加快从研究到生产的速度。 ONNX / TensorFlow / Custom deep-learning frame模型的工作方式： tensorRT中有一个 Plugin 层，这个层提供了 API 可以由用户自己定义tensorRT不支持的层。 TensorRT-plugin 目前TensorRT支持的层有:https://github.com/onnx/onnx-tensorrt/blob/main/docs/operators.md 目前ONNX支持的算子:https://github.com/onnx/onnx/blob/main/docs/Operators.md ","date":"2023-07-14","objectID":"/posts/tensorrt_introduction/:0:1","tags":["TensorRT"],"title":"TensorRT Introduction","uri":"/posts/tensorrt_introduction/"},{"categories":["Distributed Computing"],"content":"TensorRT 优化方式 TensorRT优化方法主要有以下几种方式，最主要的是前面两种。 层间融合或张量融合(Layer \u0026 Tensor Fusion) 如下图左侧是GoogLeNetInception模块的计算图。这个结构中有很多层，在部署模型推理时，这每一层的运算操作都是由GPU完成的，但实际上是GPU通过启动不同的CUDA（Compute unified device architecture）核心来完成计算的，CUDA核心计算张量的速度是很快的，但是往往大量的时间是浪费在CUDA核心的启动和对每一层输入/输出张量的读写操作上面，这造成了内存带宽的瓶颈和GPU资源的浪费。TensorRT通过对层间的横向或纵向合并（合并后的结构称为CBR，意指 convolution, bias, and ReLU layers are fused to form a single layer），使得层的数量大大减少。横向合并可以把卷积、偏置和激活层合并成一个CBR结构，只占用一个CUDA核心。纵向合并可以把结构相同，但是权值不同的层合并成一个更宽的层，也只占用一个CUDA核心。合并之后的计算图（图4右侧）的层次更少了，占用的CUDA核心数也少了，因此整个模型结构会更小，更快，更高效。 数据精度校准(Weight \u0026Activation Precision Calibration) 大部分深度学习框架在训练神经网络时网络中的张量（Tensor）都是32位浮点数的精度（Full 32-bit precision，FP32），一旦网络训练完成，在部署推理的过程中由于不需要反向传播，完全可以适当降低数据精度，比如降为FP16或INT8的精度。更低的数据精度将会使得内存占用和延迟更低，模型体积更小。 Precision Dynamic Range FP32 −3.4×1038 ~ 3.4×1038 FP16 −65504 ~ 65504 INT8 −128 ~ 127 UINT8 0 ~ 256 INT8只有256个不同的数值，使用INT8来表示 FP32精度的数值，肯定会丢失信息，造成性能下降。不过TensorRT会提供完全自动化的校准（Calibration ）过程，会以最好的匹配性能将FP32精度的数据降低为INT8精度，最小化性能损失。 Kernel Auto-Tuning 网络模型在推理计算时，是调用GPU的CUDA核进行计算的。TensorRT可以针对不同的算法，不同的网络模型，不同的GPU平台，进行 CUDA核的调整（怎么调整的还不清楚），以保证当前模型在特定平台上以最优性能计算。 TensorRT will pick the implementation from a library of kernels that delivers the best performance for the target GPU, input data size, filter size, tensor layout, batch size and other parameters. Dynamic Tensor Memory 在每个tensor的使用期间，TensorRT会为其指定显存，避免显存重复申请，减少内存占用和提高重复使用效率。 Multi-Stream Execution Scalable design to process multiple input streams in parallel，这个应该就是GPU底层的优化了。 ","date":"2023-07-14","objectID":"/posts/tensorrt_introduction/:0:2","tags":["TensorRT"],"title":"TensorRT Introduction","uri":"/posts/tensorrt_introduction/"},{"categories":["Distributed Computing"],"content":"TensorRT 安装 CUDA的安装 安装显卡驱动 安装cuda 2.1 进入nvidia开发者网站的CUDA下载页面选择runfile格式的文件下载。 2.2 下载完成后，解压，并运行上图中的命令，会有条款，接受即可，注意安装CUDA的时候不要安装驱动 2.3 路径设置 $ export PATH=/usr/local/cuda-10.2/bin:/usr/local/cuda-10.2/nsight-compute-2019.5.0${PATH:+:${PATH}} $ export LD_LIBRARY_PATH=/usr/local/cuda-10.2/lib64/${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}} 并使设置生效: source ~/.bashrc 2.4 验证安装是否成功 进入/usr/local/cuda-10.1/samples/1_Utilities/目录， cd deviceQuery sudo make ./deviceQuery 出现如下输出，则CUDA安装成功。 安装cuDNN 3.1进入cudnn下载页面，下载版本合适的版 3.2 解压，并进入到相应目录，运行以下命令： sudo cp cuda/include/cudnn*.h /usr/local/cuda-10.2/include sudo cp cuda/lib64/libcudnn* /usr/local/cuda-10.2/lib64 sudo chmod a+r /usr/local/cuda-10.2/include/cudnn*.h sudo chmod a+r /usr/local/cuda-10.2/lib64/libcudnn* 3.3 查看cudnn版本 cat /usr/local/cuda-10.2/include/cudnn.h | grep CUDNN_MAJOR -A 2 新版本: cat /usr/local/cuda-10.2/include/cudnn_version.h | grep CUDNN_MAJOR -A 2 ref: https://blog.csdn.net/weixin_43592742/article/details/115689886?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-0\u0026spm=1001.2101.3001.4242 TensorRT的安装 英伟达提供的安装指导 tensorRT 要匹配cuda和cudnn版本。在安装之前请匹配。 OSS 和 GA 两个版本: TensorRT OSS: git clone -b master https://github.com/nvidia/TensorRT TensorRT cd TensorRT git submodule update --init --recursive GA 版本(下载地址) 对GA版本和OSS版本在~/.bashrc文件中声明路径: (GA: General Availability Stable Version) (OSS: OPEN SOURCE) [oss版本路径]export TRT_SOURCE=/home/yejian/TensorRT/TensorRT_7.2.1 [GA Release 版本路径]export TRT_RELEASE=/home/yejian/TensorRT/TensorRT_7.2.1/TensorRT-7.2.1.6/TensorRT-7.2.1.6 测试确保安装成功 cd /home/yejian/TensorRT/TensorRT-8.6.1.6/samples/sampleOnnxMNIST make ../../bin ./sample_onnx_mnist Build TensorRT RSS (这一步需要在编写自定义算子的时候编译通过，才能调用自定义算子) cd $TRT_OSSPATH mkdir -p build \u0026\u0026 cd build cmake .. -DTRT_LIB_DIR=$TRT_LIBPATH -DTRT_OUT_DIR=`pwd`/out make -j$(nproc) ref: https://blog.csdn.net/Msjiangmei/article/details/132585145 ","date":"2023-07-14","objectID":"/posts/tensorrt_introduction/:0:3","tags":["TensorRT"],"title":"TensorRT Introduction","uri":"/posts/tensorrt_introduction/"},{"categories":["Distributed Computing"],"content":"自定义算子开发 – ScatterElements 在自定义算子开发过程中，需要撰写一下4个文件，并且把文件放在scatterElementsPlugin文件夹中: CmakeLists.txt scatterElements.cu scatterElementsPlugin.cpp scatterElementsPlugin.h 如图所示: 自定义算子的生成与注册 将以上四个文件报括文件夹复制到TensorRT(OOS)下的plugin文件夹下; 然后修改注册信息文件:(这些文件也在plugin文件夹下) ${TRT_SOURCE}/plugin: CMakeLists.txt ${TRT_SOURCE}/InferPlugin.cpp ${TRT_SOURCE}/common/kernels/kernel.h ${TRT_SOURCE}/parsers/onnx/builtin_op_importers.cpp 执行完以上步骤以后，重新编译OOS版本，然后就可以调用自定义算子: cd $TRT_OSSPATH mkdir -p build \u0026\u0026 cd build cmake .. -DTRT_LIB_DIR=$TRT_LIBPATH -DTRT_OUT_DIR=`pwd`/out make -j$(nproc) ","date":"2023-07-14","objectID":"/posts/tensorrt_introduction/:1:0","tags":["TensorRT"],"title":"TensorRT Introduction","uri":"/posts/tensorrt_introduction/"},{"categories":["RL"],"content":" quote note abstract info tip success question warning failure danger bug example quote https://zhuanlan.zhihu.com/p/337976595 DRL:DQN, PG, AC, DDPG, SAC概述 ","date":"2023-07-14","objectID":"/posts/dpg/:0:0","tags":["draft"],"title":"DPG","uri":"/posts/dpg/"},{"categories":["RL"],"content":"1. 引言 ​ 首先在论文的引言部分给出了经典的强化学习算法的不足之处:许多的经典强化学习算法在大型的模型、数据采样效率、鲁棒性(无需手动超参调整)上都有很大的提升空间。Q-Learning算法(包括函数逼近类算法)在许多简单问题上应用存在局限性,例如要满足状态空间与动作空间的离散型要求，并且其理解起来也是一件很困难的事情、而vanilla policy gradient算法的数据效率与鲁棒性较差、置信域优化算法(TRPO)相对来说比较复杂，而且对于包含噪声或参数共享(在策略函数与价值函数之间有其他的辅助任务需求)的网络结构不兼容(比如dropout)。 ​ 该论文的主要目的是为了解决上述问题，在TRPO的基础上运用一阶优化提高其数据的使用效率与良好的表现。创新的使用了一种对目标函数使用限幅概率比(clipped probabilty ratios)的方法，对原有策略的表现做出悲观主义的估计(个人理解这里是对原有策略目标函数 $J(\\theta)$ 的下界做出估计)。为了优化策略 $\\pi_{\\theta}$,我们交替从策略中采样数据，并对采样数据执行几个优化阶段。 ​实验比较了好几个代理者算法，发现其中采用限幅概率比(clipped probabilty ratios)的方法表现效果最佳。相比于之前的一些强化学习算法，PPO在连续控制问题上比之前的算法效果都要好。在Atari游戏中，其表现要显著强于A2C和ACER算法，因为其是更加简单的(从策略的采样复杂度的角度上来说)。 ","date":"2023-07-14","objectID":"/posts/ppo/:1:0","tags":["PPO"],"title":"强化学习 | PPO 论文解读","uri":"/posts/ppo/"},{"categories":["RL"],"content":"2. 背景 ","date":"2023-07-14","objectID":"/posts/ppo/:2:0","tags":["PPO"],"title":"强化学习 | PPO 论文解读","uri":"/posts/ppo/"},{"categories":["RL"],"content":"2.1 策略梯度方法(Policy Gradient Methods) 策略梯度方法主要通过计算一个 $estimator s(\\hat{g})$, 并且将其用于随机梯度下降算法中实现策略的梯度上升功能 $(\\theta\\leftarrow\\theta+\\alpha\\hat{g})$。比较常用的一种estimator如下所示: $$\\hat{g}=\\hat{E}t\\left[\\nabla\\theta\\log\\pi_\\theta\\left(a_t\\left|s_t\\right.\\right)\\hat{A}_t\\right]$$ 其中 $\\pi_{\\theta}$ ​是随机策略函数，$\\hat{A_t}$ 是在第 $t$个步长时的优势函数 $A(s_t,a_t)$ 的估计值。 由之前的知识我们可以知道，这里的 $\\hat{ A_t}$ 如果是用MonteCarlo方法来估计即: $\\hat{A_t} = G_t-v_{\\omega}(s_t)$ ，便是Reinforce with baseline 方法。如果采用 $\\hat{A_t} = Q_{\\pi_{\\theta}}(s_t,a_t)-v_{\\omega}(s_t)$ 来估计，便是A2C方法。 其中: $\\hat E_t[…]$表明采用在一群采样的样本之间采用经验平均值来估计，即: $\\hat{E_t[…]}=\\frac{1}{n}\\sum_{t=1}^n[…]$。由于可以用带用自动梯度计算的软件对 $\\hat{g}$ 进行计算，因此 $\\hat{g}$ 可以视为对以下目标进行梯度计算 $\\nabla_{\\theta}$: $$L^{PG}(\\theta)=\\hat{E}t\\left[\\log\\pi\\theta\\left(a_t\\left|s_t\\right.\\right)\\hat{A}_t\\right]$$ ​ 尽管上式在用多个轨迹(trajectory)对误差 $L^{PG}(\\theta)$ 进行多步的参数更新优化时有一定的优势。但是这么做理由并不充分(原话是doing so is not well-justified我不知道怎么翻译比较合适)，并且这常常会导致一个毁灭性的极大范围的策略参数 $\\theta$ 的更新问题(个人认为这里想强调的是学习率$\\alpha$ 不好调，容易造成参数的估计出现问题)。 ","date":"2023-07-14","objectID":"/posts/ppo/:2:1","tags":["PPO"],"title":"强化学习 | PPO 论文解读","uri":"/posts/ppo/"},{"categories":["RL"],"content":"2.2 置信域方法 在TRPO算法中，目标函数(或者称为代理函数)是一个被要求最大化的目标函数，其被约束在一系列的策略更新的约束下。具体而言该优化问题可以描述如下: $$\\max_\\theta\\hat{E}t\\left[\\frac{\\pi\\theta\\left(a_t\\left|s_t\\right.\\right)}{\\pi_{\\theta_{old}}\\left(a_t\\left|s_t\\right.\\right)}\\hat{A}t\\right]\\s.t.\\hat{E}t\\left[KL[\\pi{\\theta{old}}\\left(.|s_t\\right),\\pi_\\theta\\left(.|s_t\\right)]\\right]\\leq\\delta $$ ​ 其中，$\\theta_{old}$ 是在策略函数 $\\pi$ 更新之前的 $\\theta$，是个向量。该约束问题可以在对目标在 $\\theta_{old}$ ​进行一阶近似(泰勒一阶展开)，在约束处对 $\\theta_{old}$ ​进行二阶近似(泰勒二阶展开)如下后，利用共轭梯度法求解。 $$\\max_\\theta g(\\theta_{old})(\\theta-\\theta_{old})\\s.t.\\frac12(\\theta-\\theta_{old})^TF(\\theta_{old})(\\theta-\\theta_{old})\\leq\\delta $$ 其中， $F(\\theta)=E_{s_{t} ,a_{t}\\sim\\pi_{\\theta}} [\\nabla_{\\theta} \\operatorname{log}\\pi(a_{t} |s_{t} ;\\theta)[\\nabla_{\\theta} \\operatorname{log}\\pi(a_{t} |s_{t} ;\\theta)]^{T}]$，而 $g\\left(\\theta\\right)=\\nabla_{\\theta}E_{\\pi(\\theta_{old})}[\\frac{\\pi_\\theta\\left(a_t\\mid s_t\\right)}{\\pi_{\\theta_{old}\\left(a_t\\mid s_t\\right)}}\\hat{A}_{t}]$ 事实上，上述的置信域优化问题的求解一般建议采用罚函数法求解，而并不是利用带约束优化问题的常规套路求解。将上述带约束的优化问题转化为如下的无约束优化问题： $$\\max_\\theta\\hat{E}t\\left[\\frac{\\pi\\theta\\left(a_t\\left|s_t\\right.\\right)}{\\pi_{\\theta_{old}\\left(a_t\\left|s_t\\right.\\right)}}\\hat{A}t-\\beta KL[\\pi{\\theta_{old}}\\left(.|s_t\\right),\\pi_\\theta\\left(.|s_t\\right)]\\right]$$ ​对于其中的 $\\beta$ 为罚系数。事实上上式中对于 $KL$ 散度实际使用时，用最大散度替代平均散度实现约束效果。而TRPO算法使用时一般用硬约束而非罚函数，这是因为选择 $\\beta$ 时，不同的 $\\beta$ 的选择会产生许多不同的问题。因此为了实现我们一阶优化算法的目标，选择一个固定的惩罚系数 $\\beta$ 用SGD优化上面的罚方程是不现实的(这里主要强调的是调超参 $\\beta$ 的问题)。 3.剪裁代理目标(Clipped Surrogate Objective) 设$r_t\\left(\\theta\\right)=\\frac{\\pi_\\theta\\left(a_t\\left|s_t\\right.\\right)}{\\pi_{\\theta_{old}}\\left(a_t\\left|s_t\\right.\\right)}$。TRPO算法最大化一个代理目标函数如下: $$L^{CPI}(\\theta)=\\hat{E}t\\left[\\frac{\\pi\\theta\\left(a_t\\left|s_t\\right.\\right)}{\\pi_{\\theta_{old}}\\left(a_t\\left|s_t\\right.\\right)}\\hat{A}_t\\right]=\\hat{E}_t\\left[r_t\\left(\\theta\\right)\\hat{A}_t\\right]$$ ​其中CPI指的是保守策略迭代(conservative policy iteration)。如果没有KL散度的约束，最大化 $L^{CPI}(\\theta)$ 将导致一个大的策略参数的过估计。因此我们考虑修正这个目标，去惩罚比率$r_t(\\theta)$远离1时的情况。 我们主要考虑如下所示的最大化目标函数: $$L^{CLIP}(\\theta)=\\hat{E}_t\\left[\\min(r_t\\left(\\theta\\right)\\hat{A}_t,\\mathbf{clip}(r_t\\left(\\theta\\right),1-\\varepsilon,1+\\varepsilon)\\hat{A}_t)\\right]$$ ​而其中 $\\varepsilon$ 是一个待调的超参，一般可以设为 \\varepsilon = 0.2$，上式的第一个最小项是 $L^{CPI}(\\theta)$。第二个最小项是 $\\mathbf{clip}(r_t(\\theta),1-\\varepsilon,1+\\varepsilon)\\hat{A_t})$，通过切片比率修正了代理函数: $$\\left.\\mathbf{clip}(r_t\\left(\\theta\\right),1-\\varepsilon,1+\\varepsilon)=\\left{\\begin{array}{l}1-\\varepsilon,r_t\\left(\\theta\\right)\\leq1-\\varepsilon\\r_t\\left(\\theta\\right)\\quad,1-\\varepsilon\\leq r_t\\left(\\theta\\right)\\leq1+\\varepsilon\\1+\\varepsilon,r_t\\left(\\theta\\right)\\geq1+\\varepsilon\\end{array}\\right.\\right.$$ 当 $\\hat {A_t}$ ​取不同的符号时，其 $L^{CLIP}(\\theta)$ 和 $r$ 的关系如下图所示: BP Network 个人理解:当 $\\hat A_t\\geq 0$时，为了达到目标 $\\max L^{CLIP}(\\theta)$，限制 $r_t(\\theta)$ 只在小于 $1+\\varepsilon$ 时有增大趋势。而当 $r_t(\\theta)$ 过大即 $r_t(\\theta)\\geq 1+\\varepsilon$ 时，限制其 $L^{CLIP}(\\theta)$ 的继续增大。这样对于那些使得 $r_t(\\theta)$过大的 $\\theta$ , 其目标函数 $L^{CLIP}(\\theta)$ 不会更大，也就不在$ \\theta$ 的搜索的考虑范围之内。因此采用搜索算法搜索 $\\theta$ 时不容易搜索到使得 $r_t(\\theta)$ 过大的 $\\theta$。达到在尽可能置信域内搜索$\\theta$的效果。当$\\hat{A_t}\\leq0$时，同理依然如此。 对比不同方法在连续控制问题中的调整参数 $\\theta$ 对散度 $KL(\\theta,\\theta_{old})$ 的影响效果如下图所示: BP Network 该图可以看出在初始参数 $\\theta_{old}$ 的一次PPO算法迭代之后，$KL(\\pi_{\\theta},\\pi_{\\theta_{old}})$ 几乎最大值才是0.02。这充分保住了$\\theta$ 在 $\\theta_{old}$ 的置信域之内。该图来自于 Hopper-v1问题，超参数如下: BP Network ","date":"2023-07-14","objectID":"/posts/ppo/:2:2","tags":["PPO"],"title":"强化学习 | PPO 论文解读","uri":"/posts/ppo/"},{"categories":["RL"],"content":"4.自适应罚函数系数方法 前面讲到采用罚函数法进行参数更新时，主要是罚函数系数 $\\beta$ 的选取比较困难。而现在一种克服方法是自适应调整系数 $\\beta$。 其优化目标如下: $$\\max L^{KLPEN}(\\theta)=\\hat{E_t}\\left[\\frac{\\pi_\\theta\\left(a_t\\left|s_t\\right.\\right)}{\\pi_{\\theta_{old}\\left(a_t\\left|s_t\\right.\\right)}}\\hat{A}t-\\beta KL[\\pi{\\theta_{old}}\\left(.|s_t\\right),\\pi_\\theta\\left(.|s_t\\right)]\\right]$$ ​计算 $d=\\hat{E}{t}\\left[KL[\\pi{\\theta_{old}}\\left(.|s_{t}\\right),\\pi_{\\theta}\\left(.|s_{t}\\right)]\\right]$, 当$d\\leq\\frac{d_{targ}}{1.5},\\beta\\leftarrow\\frac\\beta2$​; 当 $d\\geq1.5d_{targ} ,\\beta\\leftarrow2\\beta$。值得一提的是 $\\beta$的初值以及参数1.5和2对算法本身并不敏感。这是因为算法会在使用中自动判断并且调整参数。 ","date":"2023-07-14","objectID":"/posts/ppo/:2:3","tags":["PPO"],"title":"强化学习 | PPO 论文解读","uri":"/posts/ppo/"},{"categories":["RL"],"content":"5.算法部分 BP Network 在网上找了一个比较详细的伪代码图: BP Network 算法中优势函数的计算如下(具体算法过程不过多描述请参考原论文)： BP Network ","date":"2023-07-14","objectID":"/posts/ppo/:2:4","tags":["PPO"],"title":"强化学习 | PPO 论文解读","uri":"/posts/ppo/"},{"categories":["RL"],"content":"6.实验部分 不过多描述，就给张图： BP Network ","date":"2023-07-14","objectID":"/posts/ppo/:2:5","tags":["PPO"],"title":"强化学习 | PPO 论文解读","uri":"/posts/ppo/"},{"categories":["RL"],"content":"Ref: [1] PPO算法经典论文阅读 [2] PPO(Proximal Policy Optimization Algorithms)论文解读及实现 [3] 影响PPO算法性能的10个关键技巧（附PPO算法简洁Pytorch实现） ","date":"2023-07-14","objectID":"/posts/ppo/:3:0","tags":["PPO"],"title":"强化学习 | PPO 论文解读","uri":"/posts/ppo/"},{"categories":["RL"],"content":"[DQN]paper link: https://arxiv.org/pdf/1312.5602v1.pdf ","date":"2023-07-14","objectID":"/posts/dqn/:0:0","tags":null,"title":"DQN","uri":"/posts/dqn/"},{"categories":["RL"],"content":"DQN: Playing Atari with Deep Reinforcement Learning ","date":"2023-07-14","objectID":"/posts/dqn/:1:0","tags":null,"title":"DQN","uri":"/posts/dqn/"},{"categories":["RL"],"content":"General Architecture Here is Network listed: play Atari games using RL and perform better than human CNN + Q Learning: CNN for frame-skiped images features extraction; and Q Learning for policy generation Network Channel Kernel Size Stride Activation Output Size Input NA NA NA NA $84\\times84\\times4$ First Conv 16 8x8 4 Relu $20 \\times 20 \\times 6$ Second Conv 32 4x4 2 Relu $9 \\times 9 \\times 32$ Hidden NA NA NA Relu 256 Output NA NA NA None 4 to 18 在当时，普遍的做法是为每一个action学习一个函数，而不是一个网络结构直接输出所有q的value. ","date":"2023-07-14","objectID":"/posts/dqn/:1:1","tags":null,"title":"DQN","uri":"/posts/dqn/"},{"categories":["RL"],"content":"Key 1: Input Info Process 图像处理部分 Grayscale, Downsampling and Cropping RGB channels to gray scale channel (将RGB取均值为灰度图): 216 x 163 x 3 =\u003e(grayscale) 216 x 163 x 1 =\u003e(downsampling) 110 x 84 x 1 =\u003e(cropping) 84 x 84 x 1 游戏部分 Key Frame and Action Repeat select skipped frames (每个4帧选取关键帧)，假设智能体看不见中间过程; 而且agent在每k帧选择一个action，可以加速训练 作用: 加速游戏进行: 计算Q-Value是最耗时的步骤; 减少噪声: 过分紧密的frame重复信息过多，之前的action容易被否决; 缩短reward signal到具体aciton之间的时间间隔。 History as Input continuous history key frames as input (连续四个关键帧作为输入) 作用: 可以帮助智能体获得更多有效信息进行训练 Reward Clipping 将多有的reward简化为+1, -1和0 缺点: 有可能对训练效果有影响 作用: 损失了部分信息，但是可以保证不同游戏的reward scale相同，可以用相同的参数进行训练(因为在论文中，作者在多个游戏上对DQN进行了验证)。 ","date":"2023-07-14","objectID":"/posts/dqn/:1:2","tags":null,"title":"DQN","uri":"/posts/dqn/"},{"categories":["RL"],"content":"Key 2: Replay Buffer 原理: DQN中对神经网络的训练本质依然是SGD，SGD要求多次利用样本，并且样本独立，但相邻的transition都是高度相关的，所以要记住过去的transition一起抽样; Replay Buffer通过记忆一段时间内的trainsition，可以让训练数据分布更平稳; Replay Buffer通过忘记很久之前的trainsition，可以保证记住的分布大致模拟当前policy的分布，从而进行policy update; 可以多次重复采样，提升data efficiency. Replay Buffer生效的一个重要条件: 存储transition数量合适 太多: 可能使reward signal太过稀疏，影响训练 太少: 可能会导致训练数据的分布迅速变化 ","date":"2023-07-14","objectID":"/posts/dqn/:1:3","tags":null,"title":"DQN","uri":"/posts/dqn/"},{"categories":["RL"],"content":"Key 3: Semi-Gradient Method 在Eauation3中， $$y_i = r + \\gamma \\max_{a’}Q(s’, a’; \\theta_{t-1})$$ 不和之后的Q函数共享参数; 但是在实际的训练过程中，采用 $$ y_i = r + \\gamma \\max_{a’}Q(s’, a’; \\theta_{t})$$ 和之后的Q函数共享参数，但是实际上不参与导数计算，这种方法称为Semi-Gradient Method。 作用: 使训练更新更稳定。 ","date":"2023-07-14","objectID":"/posts/dqn/:1:4","tags":null,"title":"DQN","uri":"/posts/dqn/"},{"categories":["RL"],"content":"1. 强化学习 Reinforcement Learning (RL): 强化学习 强化学习是人工智能（AI）和机器学习（ML）领域的一个重要子领域，不同于监督学习和无监督学习，强化学习通过智能体与环境的不断交互(即采取动作)，进而获得奖励，从而不断优化自身动作策略，以期待最大化其长期收益(奖励之和)。强化学习特别适合序贯决策问题(涉及一系列有序的决策问题)。 ML Categories 在实际应用中，针对某些任务，我们往往无法给每个数据或者状态贴上准确的标签，但是能够知道或评估当前情况或数据是好还是坏，可以采用强化学习来处理。例如，下围棋(Go)，星际争霸II(Starcraft II)等游戏。 1.1 强化学习的定义 Agent interacts with its surroundings known as the environment. Agent will get a reward from the environemnt once it takes an action in the current enrivonment. Meanwhile, the environment evolves to the next state. The goal of the agent is to maximize its total reward (the Return) in the long run. 智能体与环境的不断交互(即在给定状态采取动作)，进而获得奖励，此时环境从一个状态转移到下一个状态。智能体通过不断优化自身动作策略，以期待最大化其长期回报或收益(奖励之和)。 强化学习流程图 ","date":"2023-07-14","objectID":"/posts/rl_introduction/:1:0","tags":["RL"],"title":"RL | 强化学习 -- 简介","uri":"/posts/rl_introduction/"},{"categories":["RL"],"content":"1.2 强化学习的相关概念 (1) 状态 State ($S$): agent’s observation of its environment; (2) 动作 Action ($A$): the approaches that agent interacts with the environment; (3) 奖励 Reward ($R_t$): the bonus that agent get once it takes an action in the environment at the given time step t.回报(Return)为Agent所获得的奖励之和。 (4) 转移概率 Transistion Probability ($P$): the transition possibility that environment evolves from one state to another. 环境从一个状态转移到另一个状态，可以是确定性转移过程，例如，$S_{t+1} = f(S_t, A_t)$, 也可以是随机性转移过程，例如 $S_{t+1} \\sim p\\left( S_{t+1}|S_t, A_t \\right)$ (5) 折扣因子 Discount factor ( $\\gamma$ ): to measure the importance of future reward to agent at the current state. (6) 轨迹(Trajectory):是一系列的状态、动作、和奖励，可以表述为： $$\\tau = (S_0, A_0, R_0, S_1, A_1, R_1, … )$$ 用轨迹$\\tau$来记录Agent如何和环境交互。轨迹的初始状态是从起始状态分布中随机采样得到的。一条轨迹有时候也称为片段(Episode)或者回合，是一个从初始状态(Initial State，例如游戏的开局)到最终状态(Terminal State，如游戏中死亡或者胜利)的序列。 (7) 探索-利用的折中(Exploration-Exploitation Tradeoff): 这里，探索是指Agent通过与环境的交互来获取更多的信息，而利用是指使用当前已知信息来使得Agent的表现达到最佳，例如，贪心(greedy)策略。同一时间，只能二者选一。因此，如何平衡探索和利用二者，以实现长期回报(Long-term Return)最大，是强化学习中非常重要的问题。 因此，可以用$ (S，A，P，R，\\gamma) $来描述强化学习过程。 ","date":"2023-07-14","objectID":"/posts/rl_introduction/:1:1","tags":["RL"],"title":"RL | 强化学习 -- 简介","uri":"/posts/rl_introduction/"},{"categories":["RL"],"content":"1.3 强化学习的数学建模 (1) 马尔可夫过程 (Markov Process，MP) 是一个具备马尔可夫性质的离散随机过程。 马尔可夫性质是指下一状态 $ S_{t+1} $ 只取决于当前状态 $S_t$. $$p(S_{t+1}|S_{t}) = p(S_{t+1} | S_0, S_1, S_2, …, S_t)$$ 可以用有限状态集合 $\\mathcal{S}$ 和状态转移矩阵 $\\mathbf{P}$ 表示MP过程为 $\u003c\\mathcal{S}, \\mathbf{P}\u003e$。 为了能够刻画环境对Agent的反馈奖励，马尔可夫奖励过程将上述MP从 $\u003c\\mathcal{S}, \\mathbf{P}\u003e$ 扩展到了$ \u003c\\mathcal{S}, \\mathbf{P}, R, \\gamma\u003e$。这里，$R$表示奖励函数，而 $\\gamma$ 表示奖励折扣因子。 $$R_t = R(S_t)$$ 回报(Return)是Agent在一个轨迹上的累计奖励。折扣化回报定义如下： $$G_{t=0:T} = R(\\tau) = \\sum_{t=0}^{T}\\gamma^{t}R_t$$ 价值函数(Value Function) $V(s)$是Agent在状态$s$的期望回报(Expected Return)。 $$V^{\\pi} (s) = \\mathbb{E}[R(\\tau) | S_0 = s]$$ (3) 马尔可夫决策过程 (Markov Decision Process，MDP) MDP被广泛应用于经济、控制论、排队论、机器人、网络分析等诸多领域。 马尔可夫决策过程的立即奖励(Reward，$R$)与状态和动作有关。MDP可以用$\u003c\\mathcal{S},\\mathcal{A}, \\mathbf{P}, R, \\gamma\u003e$来刻画。 $\\mathcal{A}$表示有限的动作集合，此时，立即奖励变为 $$R_t = R(S_t, A_t)$$ 策略(Policy)用来刻画Agent根据环境观测采取动作的方式。Policy是从一个状态 $s \\in \\mathcal{S}$ 到动作 $a \\in \\mathcal{A}$的概率分布$\\pi(a|s)$ 的映射，$\\pi(a|s)$ 表示在状态$s$下，采取动作 $a$ 的概率。 $$\\pi (a|s) = p (A_t = a | S_t = s), \\exist{t} $$ 期望回报(Expected Return)是指在一个给定策略下所有可能轨迹的回报的期望值，可以表示为： $$J(\\pi) = \\int_{\\tau} p(\\tau | \\pi) R(\\tau) = \\mathbb{E}_{\\tau \\sim \\pi}[R(\\tau)]$$ 这里, $p(\\tau|\\pi)$表示给定初始状态分布 $\\rho_0$ 和策略 $\\pi$，马尔可夫决策过程中一个 $T$ 步长的轨迹 $\\tau$ 的发生概率，如下： $$p(\\tau | \\pi) = \\rho_0(s_0)\\prod \\limits_{t=0}^{T-1} p(S_{t+1} | S_t, A_t) \\pi (A_t | S_t)$$ 强化学习优化问题通过优化方法来提升策略，以最大化期望回报。最优策略$\\pi^*$ 可以表示为: $$\\pi ^ * = \\argmax_{\\pi} J(\\pi)$$ 给定一个策略 $\\pi$，价值函数$V(s)$，即给定状态下的期望回报，可以表示为: $$V^{\\pi}(s) = \\mathbb{E}_{\\tau \\sim \\pi} [R(\\tau) | S_0 = s] = \\mathbb{E}_{A_t \\sim \\pi(\\cdot | S_t)} [\\sum_{t=0}^{\\infin}\\gamma^t R(S_t, A_t) | S_0 = s]$$ 在MDP中，给定一个动作，就有动作价值函数(Action-Value Function)，是基于状态和动作的期望回报。其定义如下： $$Q^{\\pi}(s, a) = \\mathbb{E}_{\\tau \\sim \\pi}[R(\\tau) | S_0 = s, A_0 = a] = \\mathbb{E}_{A_t \\sim \\pi(\\cdot | S_t)}[\\sum_{t=0}^{\\infin}\\gamma^t R(S_t, A_t)|S_0 = s, A_0 = a]$$ 根据上述定义，可以得到： $$V^{\\pi}(s) = \\mathbb{E}_{a \\sim \\pi}[Q^{\\pi}(s,a)]$$ ","date":"2023-07-14","objectID":"/posts/rl_introduction/:1:2","tags":["RL"],"title":"RL | 强化学习 -- 简介","uri":"/posts/rl_introduction/"},{"categories":["RL"],"content":"2. 深度强化学习 Deep Learning + Reinforcement Learning = Deep Reinforcement Learning (DRL) 深度学习DL有很强的抽象和表示能力，特别适合建模RL中的值函数，例如: 动作价值函数 $Q^\\pi \\left(s, a \\right)$。 二者结合，极大地拓展了RL的应用范围。 ","date":"2023-07-14","objectID":"/posts/rl_introduction/:2:0","tags":["RL"],"title":"RL | 强化学习 -- 简介","uri":"/posts/rl_introduction/"},{"categories":["RL"],"content":"3. 常见深度强化学习算法 深度强化学习的算法比较多，常见的有：DQN，DDPG，PPO，TRPO，A3C，SAC 等等。 常见深度强化学习算法 ","date":"2023-07-14","objectID":"/posts/rl_introduction/:3:0","tags":["RL"],"title":"RL | 强化学习 -- 简介","uri":"/posts/rl_introduction/"},{"categories":["RL"],"content":"3.1 Deep Q-Networks （DQN） DQN网路将Q-Learning和深度学习结合起来，并引入了两种新颖的技术来解决以往采用神经网络等非线性函数逼近器表示动作价值函数 Q(s,a) 所产生的不稳定性问题： 技术1: 经验回放缓存（Replay Buffer）：将Agent获得的经验存入缓存中，然后从该缓存中均匀采用（也可考虑基于优先级采样）小批量样本用于Q-Learning的更新； 技术2: 目标网络（Target Network）：引入独立的网络，用来代替所需的Q网络来生成Q-Learning的目标，进一步提高神经网络稳定性。 其中, 技术1 能够提高样本使用效率，降低样本间相关性，平滑学习过程；技术2 能够是目标值不受最新参数的影响，大大较少发散和震荡。 DQN算法具体描述如下： DQN 伪代码 注意：这里随机动作选择概率$\\epsilon$一般是随着迭代Episode和Time Step的增加，而逐渐降低，目的是降低随机策略的影响，逐步提高Q网络对Agent动作选择的影响。 该算法中，Line 14 具体更新方式如下： $$\\theta^Q\\leftarrow\\theta^Q+\\beta\\sum_{i\\in\\mathcal{N}}\\frac{\\partial Q(s,a|\\theta^Q)}{\\partial\\theta^Q}\\left[y_i-Q(s,a|\\theta^Q)\\right]$$ 其中，集合$N$中为minibatch的$N$个$(S_t,A_t,R_t,S_{t+1})$经验样本集合，$\\beta$表示一次梯度迭代中的迭代步长。 参考文献 [1] V. Mnih et al., “Human-level control through deep reinforcement learning,” Nature, vol. 518, no. 7540, pp. 529–533, Feb. 2015. ","date":"2023-07-14","objectID":"/posts/rl_introduction/:3:1","tags":["RL"],"title":"RL | 强化学习 -- 简介","uri":"/posts/rl_introduction/"},{"categories":["RL"],"content":"3.2 Deep Deterministic Policy Gradient（DDPG） DDPG算法可以看作Deterministic Policy Gradient（DPG）算法和深度神经网络的结合，是对上述深度Q网络（DQN）在连续动作空间的扩展。 DDPG同时建立Q值函数（Critic）和策略函数（Actor）。这里，Critic与DQN相同，采用TD方法进行更新；而Actor利用Critic的估计，通过策略梯度方法进行更新。 DDPG算法具体描述如下： DDPG 伪代码 原论文中采用Ornstein-Uhlenbeck过程（O-U过程）作为添加噪声项N \\mathcal{N}N，也可以采用时间不相关的零均值高斯噪声（相关实践表明，其效果也很好）。 参考文献 [1] Lillicrap, Timothy P., et al. “Continuous control with deep reinforcement learning”，arXiv preprint, 2015, online: https://arxiv.org/pdf/1509.02971.pdf ","date":"2023-07-14","objectID":"/posts/rl_introduction/:3:2","tags":["RL"],"title":"RL | 强化学习 -- 简介","uri":"/posts/rl_introduction/"},{"categories":["RL"],"content":"3.3 Proximal Policy Optimization（PPO） PPO算法是对信赖域策略优化算法(Trust Region Policy Optimization, TRPO) 的一个改进，用一个更简单有效的方法来强制策略$\\pi_\\theta$与$\\pi_{\\theta}^{\\prime}$相似。 具体来说，TRPO中的优化问题如下： $$\\begin{gathered}\\max_{\\pi_{\\theta}^{\\prime}}\\mathcal{L}_{\\pi_{\\theta}}(\\pi_{\\theta}^{\\prime})\\\\s.t.\\mathbb{E}_{s\\sim\\rho_{\\pi_\\theta}}[D_{KL}\\left(\\pi_\\theta\\left|\\left|\\pi_\\theta^{\\prime}\\right.\\right)\\right]\\leq\\delta \\end{gathered}$$ 而PPO算法直接优化上述问题的正则版本，即： $$\\max_{\\pi_{\\theta}^{\\prime}}\\mathcal{L}_{\\pi_{\\theta}}\\left(\\pi_{\\theta}^{\\prime}\\right)-\\lambda\\mathbb{E}_{s\\sim\\rho_{\\pi_{\\theta}}}\\quad[D_{KL}\\left(\\pi_{\\theta}||\\pi_{\\theta}^{\\prime}\\right)]$$ 这里，入为正则化系数，对应TRPO优化问题中的每一个$\\delta$,都存在一个相应的$\\lambda$,使得上述两个优化问题有相同的解。然而，入的值依赖于$\\pi_\\theta$,因此，在PPO中，需要使用一个可动态调整的$\\lambda$。具体来说有两种方法： (1) 通过检验KL散度值来决定$\\lambda$是增大还是减小，该版本的PPO算法称为PPO-Penalty; (2) 直接截断用于策略梯度的目标函数，从而得到更保守的更新，该方法称为PPO-Clip。 PPO-Clip算法具体描述如下： PPO 伪代码 $$f(\\theta’)=\\min\\left(\\ell_t\\left(\\theta’\\right)A^{\\pi_{\\theta_{dd}}}(S_t,A_t),clip(\\ell_t\\left(\\theta’\\right),1-\\epsilon,1+\\epsilon)A^{\\pi_{\\theta_{dd}}}(S_t,A_t)\\right)$$ 这里，$clip(x,1-\\epsilon,1+\\epsilon)$表示将$x$截断在$[1-\\epsilon,1+\\epsilon]$中。 参考文献 [1] Schulman, J. , et al. “Proximal Policy Optimization Algorithms”，arXiv preprint, 2017, online: https://arxiv.org/pdf/1707.06347.pdf [2] Schulman J, Levine S, Abbeel P, et al. “Trust region policy optimization”, International conference on machine learning. PMLR, 2015: 1889-1897, online: http://proceedings.mlr.press/v37/schulman15.pdf ","date":"2023-07-14","objectID":"/posts/rl_introduction/:3:3","tags":["RL"],"title":"RL | 强化学习 -- 简介","uri":"/posts/rl_introduction/"},{"categories":["RL"],"content":"4. 深度强化学习算法分类 ","date":"2023-07-14","objectID":"/posts/rl_introduction/:4:0","tags":["RL"],"title":"RL | 强化学习 -- 简介","uri":"/posts/rl_introduction/"},{"categories":["RL"],"content":"4.1 根据Agent训练与测试所采用的策略是否一致 4.1.1 off-policy (离轨策略、离线策略) Agent在训练(产生数据)时所使用的策略 $\\pi_1$与 agent测试(方法评估与实际使用–目标策略)时所用的策略 $\\pi_2$ 不一致。 例如，在DQN算法中，训练时，通常采用 $\\epsilon-greedy$ 策略；而在测试性能或者实际使用时，采用 $ a^* = arg \\max\\limits_{a} Q^{\\pi}\\left( s, a \\right) $ 策略。 常见算法有：DDPG，TD3，Q-learning，DQN等。 4.1.2 on-policy (同轨策略、在线策略) Agent在训练时(产生数据)所使用的策略与其测试(方法评估与提升)时使用的策略为同一个策略 $\\pi$。 常见算法有：Sarsa，Policy Gradient，TRPO，PPO，A3C等。 ","date":"2023-07-14","objectID":"/posts/rl_introduction/:4:1","tags":["RL"],"title":"RL | 强化学习 -- 简介","uri":"/posts/rl_introduction/"},{"categories":["RL"],"content":"4.2 策略优化的方式不同 4.2.1 Value-based algorithms(基于价值的算法) 基于价值的方法通常意味着对动作价值函数 $Q^{\\pi}(s,a)$的优化，最优策略通过选取该函数 $Q^{\\pi}(s,a)$ 最大值所对应的动作，即 $\\pi^* \\approx \\arg \\max\\limits_{\\pi}Q^{\\pi}(s,a)$，这里，$\\approx$ 由函数近似误差导致。 基于价值的算法具有采样效率相对较高，值函数估计方差小，不易陷入局部最优等优点，缺点是通常不能处理连续动作空间问题，最终策略通常为确定性策略。 常见算法有 Q-learning，DQN，Double DQN，等，适用于 Discrete action space。其中，DQN算法是基于state-action function $Q(s,a)$ 来进行选择最优action的。 4.2.2 Policy-based algorithms(基于策略的算法) 基于策略的方法直接对策略进行优化，通过对策略迭代更新，实现累计奖励(回报)最大化。其具有策略参数化简单、收敛速度快的优点，而且适用于连续或者高维动作空间。 **策略梯度方法(Policy Gradient Method，PGM)**是一类直接针对期望回报通过梯度下降(Gradient Descent，针对最小化问题)进行策略优化的强化学习方法。其不需要在动作空间中求解价值最大化的优化问题，从而比较适用于 continuous and high-Dimension action space，也可以自然地对随机策略进行建模。 PGM方法通过梯度上升的方法直接在神经网络的参数上优化Agent的策略。 根据相关理论，期望回报 $J(\\pi_{\\theta})$ 关于参数 $\\theta$ 的梯度可以表示为： $$\\nabla_\\theta J(\\pi_\\theta)=\\mathbb{E}_{\\tau\\sim\\pi_\\theta}\\left[\\sum_{t=0}^TR_t\\nabla_\\theta\\sum_{t^{\\prime}=0}^T\\log\\pi_\\theta(A_{t^{\\prime}}|S_{t^{\\prime}})\\right]=\\mathbb{E}_{\\tau\\sim\\pi_\\theta}\\left[\\sum_{t^{\\prime}=0}^T\\nabla_\\theta\\log\\pi_\\theta\\left(A_{t^{\\prime}}|S_{t^{\\prime}}\\right)\\sum_{t=0}^TR_t\\right]$$ 当$T \\rightarrow \\infin$ 时，上式可以表示为： $$\\nabla_{\\theta}J(\\pi_{\\theta}) = \\mathbb{E}_{\\tau \\sim \\pi_{\\theta}}[\\sum_{t’=0}^{\\infin}\\nabla_{\\theta} \\log \\pi_{\\theta}(A_{t’} | S_{t’}) \\gamma^{t’}\\sum_{t=t’}^{\\infin} \\gamma^{t-t’}R_t]$$ 在实际中，经常去掉 $ \\gamma^{t^{\\prime}} $，从而避免过分强调轨迹早期状态的问题。 上述方法往往对梯度的估计有较大的方法(奖励 $R_t$ 的随机性可能对轨迹长度L呈指数级增长)。为此，常用的方法是引进一个基准函数 $b(S_i)$，仅是状态 $S_i$ 的函数。可将上述梯度修改为： $$\\nabla_{\\theta}J(\\pi_{\\theta}) = \\mathbb{E}_{\\tau \\sim \\pi_{\\theta}}[\\sum_{t’=0}^{\\infin}\\nabla_{\\theta} \\log \\pi_{\\theta}(A_{t’} | S_{t’}) (\\sum_{t=t’}^{\\infin} \\gamma^{t-t’}R_t - b(S_{t’}))]$$ 常见的PGM算法有REINFORCE，PG，PPO，TRPO 等。 4.2.3 Actor-Critic algorithms (演员-评论家方法) Actor-Critic方法结合了上述 基于价值 的方法和 基于策略 的方法，利用基于价值的方法学习Q值函数或状态价值函数V来提高采样效率(Critic)，并利用基于策略的方法学习策略函数(Actor)，从而适用于连续或高维动作空间。其缺点也继承了二者的缺点，例如，Critic存在过估计问题，而Actor存在探索不足的问题等。 常见算法有 DDPG, A3C，TD3，SAC等，适用于 continuous and high-Dimension action space ","date":"2023-07-14","objectID":"/posts/rl_introduction/:4:2","tags":["RL"],"title":"RL | 强化学习 -- 简介","uri":"/posts/rl_introduction/"},{"categories":["RL"],"content":"4.3 参数更新的方式不同 Parameters updating methods 4.3.1 Monte Carlo method(蒙特卡罗方法) 蒙特卡罗方法：必须等待一条轨迹 $\\tau_k$ 生成(真实值)后才能更新。 常见算法有：Policy Gradient，TRPO，PPO等。 4.3.2 Temporal Difference method(时间差分方法) 时间差分方法：在每一步动作执行都可以通过自举法(Bootstrapping)(估计值)及时更新。 常见算法有：DDPG，Q-learning，DQN等。 ","date":"2023-07-14","objectID":"/posts/rl_introduction/:4:3","tags":["RL"],"title":"RL | 强化学习 -- 简介","uri":"/posts/rl_introduction/"},{"categories":["RL"],"content":"参考 [1]. https://blog.csdn.net/b_b1949/article/details/128997146 [2]. https://blog.csdn.net/magicyangjay111/article/details/132645347 ","date":"2023-07-14","objectID":"/posts/rl_introduction/:5:0","tags":["RL"],"title":"RL | 强化学习 -- 简介","uri":"/posts/rl_introduction/"},{"categories":["Distributed Computing"],"content":"1. 概述 分布式训练服务框架与集合通信库的组合构成了分布式训练的整体服务软件栈，在第3篇、第4篇文章里已经剖析完集合通信的相关内容，而本文会以Horovod为例介绍数据并行下分布式训练服务框架的基本原理以及进行架构解析。当前，在分布式训练里分布式训练服务框架需要解决以下几个核心问题 ： 计算与通信同步耦合问题：如果反向传播一产生一份梯度，就马上对其调用全局AllReduce，计算与通信同步耦合，容易造成死锁同时性能也会很不如意； 计算时间与通信时间串行问题：神经网络是分层的，梯度计算的过程是数据加载，然后前向传播算出损失值，再反向传播算出梯度，而反向计算时梯度是从输出层往输入层方向一层一层产生的，在有些模型里，如果需要等所有的梯度都计算完毕才能触发全局AllReduce，那么对性能的影响也会很大； 梯度生成的落后者问题：集群内每个计算节点的同一份梯度的产生不一定都是同一时刻的，如果梯度没有全部生成就发起对这个梯度的全局规约，否则容易造成训练出来的模型精度不达标或者不收敛的问题； 梯度融合问题：如果每一份梯度都触发一次全局AllReduce，在梯度Tensor较多的神经网络训练里，整体的训练系统性能会变得极低； 易用性问题：从TensorFlow，PyTorch迁移过来需要改的代码需要极少，从单卡训练迁移到多卡训练需要改动的代码也需要极少； 可移植问题：支持多种多样的深度学习训练框架，比如 TensorFlow、PyTorch、MxNet等，也能支持多种多样的通信库，比如openMPI、NCCL、Gloo、CCL、RCCL等； 可靠性问题：在集群训练的过程中网络时不可靠的、计算卡是会出故障的、服务器是会出故障的、系统软件也是会出Bug的，这些因素造成了分布式训练过程中还存在可靠性问题，如何解决这个问题也是一个难题。 软件是由人实现的，解析一个软件系统最难的地方在于从庞杂的代码里倒推出背后实现它的人的设计意图，为了更好的理解Horovod，本文会基于以上这几个分布式训练的核心问题，以Horovod为例介绍分布式训练服务框架的基本原理以及进行架构解析。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_5/:1:0","tags":["Distributed Training"],"title":"分布式训练 - 第5篇 - 分布式训练服务框架基本原理与架构解析","uri":"/posts/distributedtraining_5/"},{"categories":["Distributed Computing"],"content":"2. 基础知识 ","date":"2023-07-13","objectID":"/posts/distributedtraining_5/:2:0","tags":["Distributed Training"],"title":"分布式训练 - 第5篇 - 分布式训练服务框架基本原理与架构解析","uri":"/posts/distributedtraining_5/"},{"categories":["Distributed Computing"],"content":"2.1 单卡训练 神经网络的训练，本质上就是Y=F(x)的迭代，通过反复输入X、输出Y，使得神经网络的参数变化与输入输出间的复杂关系拟合。在神经网络训练的过程中，通过输入数据利用梯度下降的方法进行迭代从而优化神经网络参数，并最终输出神经网络模型。而神经网络可以看作一种运算模型，其由大量的神经元（节点）相互联接构成，其由输入层、隐藏层以及输出层组合而成（如下图左侧所示）。神经元(neuron)是神经网络的基本计算单元，也被称作节点(node)，它可以接受来自其他神经元或外部数据的输入，然后计算出一个输出（如下图右上角所示）。 如上图右下角所示，在单卡训练迭代中，基于并行梯度下降法，会有以下操作： 第一步，读取部分数据，并且将数据加载进训练卡的存储空间； 第二步，对模型进行前向传播计算，从输入层往输出层一层一层的进行计算，得到损失差LOSS； 第三步，对模型进行反向传播计算，从输出层往输入层一层一层的进行计算，得到梯度值，注意这一步会把每一层都计算出一个梯度张量（Gradient Tensor）出来； 第四步，将新的到的梯度与部分数据 作为新的输入，重新开始以上步骤的迭代。 在这一步里有一个很重要的与性能优化相关的信息是反向传播是每一层输出一个梯度张量，以及反向传播是从输出层往输入层一层一层的进行计算的，这一点信息可以用通信隐藏性能优化与梯度融合优化。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_5/:2:1","tags":["Distributed Training"],"title":"分布式训练 - 第5篇 - 分布式训练服务框架基本原理与架构解析","uri":"/posts/distributedtraining_5/"},{"categories":["Distributed Computing"],"content":"2.2 多卡训练 以数据并行随机梯度下降法( SGD )为例，多卡神经网络的训练过程如下图，与单卡训练相比，多卡训练多了梯度全局规约的过程： 第一步，通过Broadcast操作将第一个节点参数同步到集群内的所有的训练卡上，保证每个计算节点的初始参数是一致的，同时训练脚本在多个计算节点上运行，每个计算节点包含了整体的模型参数； 第二步，将数据样本切片分发到整个集群内的个计算节点（训练卡）上并且通过数据流水技术将数据样本加载进训练卡的高速内存空间内，作为输入X; 第三步，每个训练卡在其数据样本上运行前向传播，计算出损失差LOSSi； 第四步，对计算出的LOSSi进行反向传播，得到梯度GRADi，这一步也需要注意得是每一层都会计算出一个梯度，同时梯度是以输出的Tensor来表示的； 第五步，所有的训练卡计算出来的部分梯度，在主机内及主机之间通过集合通信进行全局归约(AllReduce)得到全局梯度； 第六步，最后再将这个全局梯度作为参数进行更新，再进行以上2-5步骤的迭代从而获得新的梯度。 以上2-6步骤就是多卡并行梯度下降的基本思想，即多个计算节点通过分片的数据样本进行梯度计算，得到分区梯度后，再通过全局梯度规约以及将这个聚合好的梯度作为新的参数进行更新，从而实现并行梯度下降。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_5/:2:2","tags":["Distributed Training"],"title":"分布式训练 - 第5篇 - 分布式训练服务框架基本原理与架构解析","uri":"/posts/distributedtraining_5/"},{"categories":["Distributed Computing"],"content":"3. 几个核心问题 在本章节里会解读本文概述里提到的分布式服务框架需要解决的几个与性能、易用性等相关的几个核心问题，并且以Horovod为例讲述Horovod是如何解决这个几个难题的。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_5/:3:0","tags":["Distributed Training"],"title":"分布式训练 - 第5篇 - 分布式训练服务框架基本原理与架构解析","uri":"/posts/distributedtraining_5/"},{"categories":["Distributed Computing"],"content":"3.1 计算与通信解耦 在神经网络的训练过程中，每一神经网络层都会计算出一个梯度，同时梯度是以输出Tensor来表示的，如果反向传播一计算出一个梯度就马上调用通信去做梯度规约，将计算与通信同步耦合，那么整体的性能的表现就会很差。比如一个ResNet-50 v3的梯度张量个数是153个，如果一计算出一个梯度就马上进行通信，假设计算梯度花了1ms，通信这个梯度花了 500ms，那么这个过程就是 501ms，总体上就需要501x153 = 76653ms，即近76.6s才能完成一次梯度迭代。而将计算与通信解耦，计算的归计算，通信的归通信，通过性能优化策略减少通信的次数，既能提升整体训练性能也能避免某些死锁问题，比如计算梯度grad i的时候花了很长时间，而通信线程一直在等待这个梯度，表现出来就是死锁现象。 Horovod采用计算与通信分离的设计思想，解耦了计算过程与通信过程，从而提升了整体训练的性能与可靠性。如下图的Horovod逻辑架构图所示，从图中可以看出Horovod解耦了计算与通信，其将框架层计算出来的梯度request信息push 到一个消息队列message_queue里，同时将梯度信息push到一个Tensor_table里，再通过控制层在后台起一个loop线程，周期性的从消息队列里读取梯度消息，在控制层集群的节点之间协商达成一致后，再进行消息分发触发训练行为。 如上图可看出，Horovod从下到上分为7层：物理层、链路层、数据传输层、控制层、消息层、框架层以及用户层。框架层，控制层以及数据传输层体现了Horovod的核心设计理念，即：框架层，用户可以自定义Op，以插件的形式hack进框架；在控制层，worker节点与master节点之间协商达成触发训练行为的约定；在数据传输层，服务器内以及服务器之间采用集合通信库传输数据。 本质上Horovod的整体设计理念之一遵循的是生产者消费者模式，如下图所示： 在Horovod里每个计算节点都会有有两个核心线程：Execution thread 和 Background thread ： 生产者Execution Thread 是用来做梯度计算的，在TensorFlow、PyTorch之类的之类的训练框架计算出梯度Tensor后，将Tensor 信息push进tenor_table队列，同时将Tensor的request信息push进message_queue队列; 消费者Background thread 是做集合通讯以及全局Allreduce的，后台线程会每隔一段时间轮询消息队列，拿到一批Tensor信息之后，会进行相应的操作。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_5/:3:1","tags":["Distributed Training"],"title":"分布式训练 - 第5篇 - 分布式训练服务框架基本原理与架构解析","uri":"/posts/distributedtraining_5/"},{"categories":["Distributed Computing"],"content":"3.2 通信隐藏 神经网络是分层的，在训练的过程中，先是数据加载，然后前向传播算出LOSS，再反向传播算出梯度，而反向计算时梯度是从输出层往输入层方向一层一层产生的，如果需要等所有的梯度都计算完毕才能触发全局AllReduce，对性能不是很友好。如下图所示，计算时间与通信时间是串行的，如果能将全局梯度规约的通信时间与计算时间想办法并行起来，将通信时间隐藏在计算时间之内，那么就能节约梯度的训练时间从而提升分布式训练系统整体的训练性能。 如下图所示，将计算出来的梯度进行分桶触发异步Allreduce，一边反向传播计算梯度，一边做部分梯度的全局规约通信，从而达到将通信时间隐藏在计算时间内的效果。而Horovod为达成这一效果，Background thread 会每隔一段时间轮询梯度消息队列里的梯度信息，获取了可以过全局规约的梯度后，就进行全局规约操作，而这个时间其他的梯度还在计算过程中，通过调整轮询的时间间隔从而达到调整梯度分桶的效果。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_5/:3:2","tags":["Distributed Training"],"title":"分布式训练 - 第5篇 - 分布式训练服务框架基本原理与架构解析","uri":"/posts/distributedtraining_5/"},{"categories":["Distributed Computing"],"content":"3.3 梯度协商 神经网络的每一层对应一个梯度Tensor，在分布式训练集群里每张训练卡对同一份梯度计算产生的时间是有差异的，当集群内每个计算节点的同一神经网络层的同一梯度都产生时，才能发起对这个梯度的全局AllReduce规约，否则容易造成丢梯度，训练出来模型精度不达标或者模型不收敛。比如在一个128卡的训练集群里，同一份梯度是对应同一个神经网络模型里的同一层神经网络的，只有每张训练卡上都计算出了同一层神经网络的梯度 才能对这一层神经网络的梯度进行全局规约，如下图所示： Horovod设计了一种梯度状态协商机制，它将 计算节点Rank0 作为coordinator（master），其余的rank1-N节点进程为worker，由coordinator来协商确定同一份梯度是否在每个计算节点上都已经计算出来，只有在每个计算节点上都计算出来的同一梯度才可以进行全局规约操作。在Horovod里每个计算节点上都有一个message_queue以及tensor_table，而在coordinator节点上除此之外，还有一个message_table用于保存可以进行全局Allreduce的梯度请求次数信息。Horovod 控制面的ComputeResponseList 函数里实现了这一梯度的协商过程，在从message_queue获取了本节点生成的梯度信息后，coordinator会与其他节点协商这个梯度是否都计算出来，这一过程是阻塞进行的，这个协商过程如下图： 一个梯度是否能满足全局规约AllReduce的协商过程如下： 首先，集群内的每个计算节点进程都会往coordinator Rank0发送一个 tensor的请求request，表示说本节点这一层神经网络的梯度已经生成，比如tensor1，每个rank都会往rank0 发送一个本梯度tensor1已经计算出来的请求信息； 第二步，coordinator接收到节点的梯度协商请求后（包括本节点），会把收到的tensor请求次数进行累加，并将这个信息记录在message_table里，当这个梯度的请求信息达到集群内节点的个数时，比如在N个节点的集群，一个神经网络层的梯度tensor的通信请求出现了N次，那就表示在本集群里所有的计算节点都已经发出了对该梯度tensor的通信request，这就表明这个梯度tensor是符合全局规约要求的，就能进行集合通信全局规约，不符合要求的梯度tensor将继续留在message_table中，直到条件符合为止； 第三步，再接着coordinator会将满足全局allreduce规约条件的梯度Tensor通过response返回给其他节点，告诉其他节点这个梯度可以启动全局规约AllReduce。 经过这几步的协商达成梯度全局状态一致的目的，从而避免梯度丢失造成的模型精度不达标、不收敛或者进程死锁问题。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_5/:3:3","tags":["Distributed Training"],"title":"分布式训练 - 第5篇 - 分布式训练服务框架基本原理与架构解析","uri":"/posts/distributedtraining_5/"},{"categories":["Distributed Computing"],"content":"3.4 梯度融合 神经网络的每一层都能对应一个梯度，假设每生成一个梯度就进行一次全局规约时，100个梯度就需要进行100次全局通信100次全局规约，而通信对训练的性能有巨大的影响，这种情况表现出来的效果就是分布式训练集群的整体性能极差。通过梯度融合计算将多个梯度合成一个，从而减少全局规约的次数能大幅提高分布式训练的训练性能，如下图所示，将N个小梯度Tensor合成两个，能将全局通信的次数减少到2次，从而大幅提升训练性能，在Horovod里这个功能对TensorFusion特性。但这个特性也会与3.2通信隐藏特性相冲突，需要根据具体情况进行合理的调试优化。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_5/:3:4","tags":["Distributed Training"],"title":"分布式训练 - 第5篇 - 分布式训练服务框架基本原理与架构解析","uri":"/posts/distributedtraining_5/"},{"categories":["Distributed Computing"],"content":"3.5 易用性 从TensorFlow，PyTorch等框架迁移到Horovod需要改的的代码极少，horovod接入方式比较简单，与原生训练框架对比，主要的区别在于： 1，初始化 Horovod，包括机器资源的分配： horovod.init() 2，向每个进程分配XPU资源， 典型的设置是 1 个 XPU 一个进程，即设置 local rank： config.gpu_options.visible_device_list = str(hvd.local_rank()) 3，对原优化器进行包装，分布式优化器将梯度计算委托给原始优化器，使用allreduce或allgather对梯度求平均，然后应用这些平均梯度： opt=hvd.DistributedOptimizer(opt) 4， 将初始化参数从rank 0广播给其他进程(rank表示进程序号)，实现参数的初始化，确保所有节点的初始化参数保持一致： hvd.BroadcastGlobalVariablesHook(0)： ","date":"2023-07-13","objectID":"/posts/distributedtraining_5/:3:5","tags":["Distributed Training"],"title":"分布式训练 - 第5篇 - 分布式训练服务框架基本原理与架构解析","uri":"/posts/distributedtraining_5/"},{"categories":["Distributed Computing"],"content":"3.6 可移植 可移植问题，Horovod通过 OP和OpKernels的插件化机制支持多种多样的深度学习训练框架，比如 TensorFlow、PyTorch、MxNet等。基于的opKernels的可定制化机制，Horovod自定义了Op然后hack了数据链路层的通信协议，从而达到在多个深度学习框架之间可移植。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_5/:3:6","tags":["Distributed Training"],"title":"分布式训练 - 第5篇 - 分布式训练服务框架基本原理与架构解析","uri":"/posts/distributedtraining_5/"},{"categories":["Distributed Computing"],"content":"3.7 可靠性问题 在集群训练的过程中网络时不可靠的、计算卡是会出故障的、服务器是会出故障的的，这些因素造成了分布式训练过程中需要考虑训练集群的可靠性，Horovod结合集合通信库Gloo对外提供了弹性训练的特性，但可靠性不只是弹性训练就能完全解决的，它还有更多的系统级的问题需要解决，因此可靠性问题留着一个后续研究问题，不在本文阐述。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_5/:3:7","tags":["Distributed Training"],"title":"分布式训练 - 第5篇 - 分布式训练服务框架基本原理与架构解析","uri":"/posts/distributedtraining_5/"},{"categories":["Distributed Computing"],"content":"4. 优点缺点、改进点 简单易用、可移植，并且支持弹性训练提升了可靠性； 不依赖于某个框架，其通过MPI机制独立建立了一套分布式训练服务系统； 将计算与通信分离，完成了allreduce、allgather等集合通信工作，实现了规模可扩展； 巧妙的通过间隔轮询的机制支持通信时间隐藏，并且完成了梯度协商从而保证训练出来的模型是可收敛、精度达标的； 支持梯度融合，支持将小的tensor合并成一个大的tensor再进行通信传递，从而减小通信操作的额外开销； 自带压缩算法，可以减少集合通信的数据量； ","date":"2023-07-13","objectID":"/posts/distributedtraining_5/:4:0","tags":["Distributed Training"],"title":"分布式训练 - 第5篇 - 分布式训练服务框架基本原理与架构解析","uri":"/posts/distributedtraining_5/"},{"categories":["Distributed Computing"],"content":"5. 思考题 问题1，将通信时间隐藏在计算时间内能有助于提升训练系统的整体性能，但这一特性是针对SIMT芯片的架构的进行性能优化的，如果DSA芯片不能支持这一特性，那应该如何优化Horovod从而大幅提升整体的训练性能？（可以确定这一定是能做到的） 问题2，梯度协商的过程中，每个梯度都需要协商一次，在梯度较多，网络规模较大的集群里，这一特性也会影响性能，如何进行优化才能有效提升Horovod性能？\\ 问题3，不同的模型对梯度融合有不同的要求，那么梯度融合需要融合到什么程度才能有效提升性能？ 可以说明的是，这三个问题解决后还能继续提升Horovod在DSA架构芯片上的整体的分布式训练系统级性能。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_5/:5:0","tags":["Distributed Training"],"title":"分布式训练 - 第5篇 - 分布式训练服务框架基本原理与架构解析","uri":"/posts/distributedtraining_5/"},{"categories":["Distributed Computing"],"content":"6. 小结 本文介绍了分布式训练的基础知识以及剖析了分布式训练服务框架所面临的几个核心问题，以Horovod为例从计算与通信解耦、通信隐藏、梯度协商、梯度融合、易用性以及可移植这几个角度倒推了分布式训练服务框架背后的设计意图，从而帮助大家能更好的理解分布式训练服务框架。 ref: [1] https://www.changping.me [2] https://horovod.ai [3] https://www.cnblogs.com/rossiXYZ/p/14910959.html [4] https://zhuanlan.zhihu.com/p/374575049 ","date":"2023-07-13","objectID":"/posts/distributedtraining_5/:6:0","tags":["Distributed Training"],"title":"分布式训练 - 第5篇 - 分布式训练服务框架基本原理与架构解析","uri":"/posts/distributedtraining_5/"},{"categories":["Distributed Computing"],"content":"ref: [1]. https://www.changping.me/2022/04/10/ai-distributed-training-coll-topo/ ","date":"2023-07-13","objectID":"/posts/distributedtraining_4/:0:0","tags":["Distributed Training"],"title":"分布式训练 – 第4篇 - 分布式训练常用的网络结构及集合通信拓扑算法","uri":"/posts/distributedtraining_4/"},{"categories":["Distributed Computing"],"content":"1. 概述 在深度学习的分布式训练里，Ring AllReduce拓扑算法奠定了数据并行训练的集合通信基础，但集合通信拓扑不只是仅有Ring Allreduce，经典的集合通信拓扑算法还有2D-Ring/Hierarchical Ring AllReduce，halving and doubling AllReduce，Butterfly AllReduce，2D-Torus AllReduce，2D-Mesh AllReduce，double binary tree等。拓扑算法很多，但也不是所有的拓扑算法都能满足实际的生产需求的，这需要具体问题具体分析、具体场景具体设计。 集合通信的难点在于需要在固定的网络互联结构的约束下进行高效的通信，集合通信拓扑算法与物理网络互联结构强相关，为了发挥网络通信的效率，也不是说就能随意发挥通信拓扑算法，更多的是在效率与成本、带宽与时延、客户要求与质量、创新与产品化等之间进行合理取舍。 充分发挥训练加速卡与网络的效率是通信拓扑算法的初衷，但除了设计高效的集合通信拓扑算法外，分布式训练中需要解决的通信难题还有：网络是异构的，网络带宽是有限的，主机内PCIE SWITCH是有亲和性的，网络是会出故障的，节点是有落后者效应的，设备成本是需要考虑的，数据中心是有部署约束的，用户是有多租户要求的等，这些属于产品化的范畴不在本文阐述。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_4/:1:0","tags":["Distributed Training"],"title":"分布式训练 – 第4篇 - 分布式训练常用的网络结构及集合通信拓扑算法","uri":"/posts/distributedtraining_4/"},{"categories":["Distributed Computing"],"content":"2. 网络互联结构 分布式训练的集合通信拓扑算法与物理的网络互联结构强相关，而网络互联结构又多种多样，因此，本文需要先对网络互联结构进行约束，依据生产中常用的、既定的互联结构设计集合通信算法，网络互联结构描述如下： ","date":"2023-07-13","objectID":"/posts/distributedtraining_4/:2:0","tags":["Distributed Training"],"title":"分布式训练 – 第4篇 - 分布式训练常用的网络结构及集合通信拓扑算法","uri":"/posts/distributedtraining_4/"},{"categories":["Distributed Computing"],"content":"2.1 服务内网络互联结构 以一台集成了8张训练加速卡的服务器为例，如下图: 这台服务器内的网络互联情况如下： 1）在这台服务器内，8张训练加速卡通过私有协议连接组成多个主机内的物理ring环，且可双工； 2）服务期内网络带宽 NVLINK\u003ePCIE switch \u003e QPI； 3）加速卡1、2、3、4之间两两全互联，加速卡5,、6、7、8之间两两全互联，2、5、3、8之间非全互联； 4）加速卡1、4与网卡NIC1 挂在同一个PCIE Switch上，具有亲和性，加速卡2、3与网卡NIC2挂在同一个PCIE Switch上，具有亲和性，而PCIE Switch之间也互联，因此 加速卡 1、2、3、4 与网卡NIC 1、NIC2具备亲和性，它们无需通过CPU的QPI线进行通信； 5）加速卡5、8与网卡NIC3 挂在同一个PCIE Switch上，具有亲和性，加速卡6、7与网卡NIC4挂在同一个PCIE Switch上，具有亲和性，而PCIE Switch之间也互联的，因此 加速卡 5、6、7、8 与网卡NIC 3、NIC4具备亲和性，它们也无需通过CPU的QPI线进行通信； 6）网卡可根据需要 选择 1张、2张、4张或8张，最多可以采用8张RDMA物理网卡； ","date":"2023-07-13","objectID":"/posts/distributedtraining_4/:2:1","tags":["Distributed Training"],"title":"分布式训练 – 第4篇 - 分布式训练常用的网络结构及集合通信拓扑算法","uri":"/posts/distributedtraining_4/"},{"categories":["Distributed Computing"],"content":"2.2 服务器间网络互联结构 以一个训练加速卡集群为例，如下图是一个常用的CLOS互联架构方案: 在这个集群内，其网络互联情况如下： 1）集群内每台服务器自带高速RDMA网卡，通过RDMA 交换机在主机间两两全互联； 2）交换机组成CLOS架构，分为Spine与Leaf交换机，当然也可以是更为高端的Spine、Leaf合一的高端交换机； 3）RDMA网卡与Leaf交换机互联，每台服务器的RDMA网卡数量根据成本与性能考虑，可以是1张、2张+每卡虚拟化4卡、4张+每卡虚拟化2卡或8张； ","date":"2023-07-13","objectID":"/posts/distributedtraining_4/:2:2","tags":["Distributed Training"],"title":"分布式训练 – 第4篇 - 分布式训练常用的网络结构及集合通信拓扑算法","uri":"/posts/distributedtraining_4/"},{"categories":["Distributed Computing"],"content":"2.3 高速网卡及其虚拟化使用 RDMA网卡是双工的且可虚拟化，在这里每台服务器可根据成本、性能的考虑选用1张、2张、4张或8张，且在服务器内左右对称，如下图： 从成本与效率的角度考虑，每台服务器内的网卡可以是以下配置： 1张物理RDMA网卡，不进行虚拟化，直接用双工通道，适合选用2D/Hierarchical Ring拓扑算法； 2张物理RDMA网卡，可以每张虚拟化出4个虚拟网卡，2X4共8卡，适合选用2D-MESH、2D-Torus拓扑算法； 4张物理RDMA网卡，可每张虚拟化出2个虚拟网卡，4X2共8卡，适合选用2D-MESH、2D-Torus拓扑算法； 8张物理RDMA网卡，不需要虚拟化，直接采用双工通道，适合选用2D-MESH、2D-Torus拓扑算法； 在实际的分布式训练生产集群中，集合通信算法也可以结合RDMA网卡端口（包括虚拟化的）的具体个数进行设计，而拓扑算法的选择也是需要根据成本与效率的进行合理取舍的。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_4/:2:3","tags":["Distributed Training"],"title":"分布式训练 – 第4篇 - 分布式训练常用的网络结构及集合通信拓扑算法","uri":"/posts/distributedtraining_4/"},{"categories":["Distributed Computing"],"content":"2.4 网络结构抽象 网络根据连接情况可分为ring结构、mesh结构、 torus 结构以及tree结构，基于以上的服务器内网络互联结构、服务器间网络互联结构以及网卡的具体情况，可以抽象出一个网络结构，即二维环面网络：Torus 网络，而Torus网络横向与纵向都可以看成ring结构，因此相应的拓扑算法基本上就是Ring-Based 集合通信拓扑算法。如下图： TORUS网络是常见的大规模并行计算机的互连网络，在上图这个Torus网络里： 1）横向：主机内8卡通过私有连接协议，比如CXL/CCIX/NVLINK等组成一个或多个ring，如上图的黄色连接线，横向8卡组成二维Torus的横向维度； 2）纵向：主机间通过RDMA（RoCE/IB）网卡、交换机互联组成1到8个ring，如上图的红色连接线，纵向采用RDMA网卡组成二维Torus的纵向维度； 3）根据物理网卡数量、网卡虚拟化以及PCIe Switch亲和性的实际情况： 每台服务器1张网卡可组成主机间一个ring，网卡与XPU0 挂载同一个PCIE switch上，依据最佳实践原则（比如性能、成本、客户要求等），适合选用2D/Hierarchical Ring拓扑算法； 两张网卡可组成主机间两个ring或者经过虚拟化组成8个ring，根据PCIE SWITCH亲和性原则，一张网卡与XPU0挂在同一个pcie switch，另一张网卡与XPU4挂在同一个pcie switch，依据最佳实践原则（比如性能、成本、客户要求等），适合选用2D-MESH、2D-Torus拓扑算法； 4张网卡、8张网卡以此类推，也是根据PCIE SWITCH亲和性原则进行连接，主机间RDMA物理网卡不够就虚拟化网口来凑，并且要服务器内的RDMA出口端口数左右平衡，依据最佳实践原则（比如性能、成本、客户要求等），也是适合选用2D-MESH、2D-Torus拓扑算法，这样才能发挥多张网卡以及XPU的算力优势。 4）更复杂的Torus网络组合关系还可以如下图，从横向只有 主机内的8卡纵向只有主机间的RDMA互联，扩展到 横向与纵向 主机内互联与主机间互联混合，但本文仅限于在横向8卡的二维Torus网络下进行拓扑算法选择与设计，因此不展开讲述。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_4/:2:4","tags":["Distributed Training"],"title":"分布式训练 – 第4篇 - 分布式训练常用的网络结构及集合通信拓扑算法","uri":"/posts/distributedtraining_4/"},{"categories":["Distributed Computing"],"content":"3. 常用的通信拓扑算法 Torus 网络结构可以解读本文中的物理网络互联结构的一切，而Torus网络的横向与纵向都可以看成ring结构，因此，相应的集合通信拓扑算法都可以看成是Ring-Based 集合通信拓扑算法。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_4/:3:0","tags":["Distributed Training"],"title":"分布式训练 – 第4篇 - 分布式训练常用的网络结构及集合通信拓扑算法","uri":"/posts/distributedtraining_4/"},{"categories":["Distributed Computing"],"content":"3.1 Ring AllReduce 在分布式训练中，Ring 是最基础的互联结构，在本文中Ring AllReduce的应用场景是在服务器内将8张加速卡组环通信进行分布式训练。每个XPU都是这个主机内互联环上的一个计算节点，每个节点都有一个前向和一个后向，它只会向它的前向接收数据，并向它的右向发送数据，如下图所示，8张XPU 通过主机内的私有互联网络组成一个环，当然因为这些通信网络是双工的，这8张XPU训练加速卡也可以看成是通过多个逻辑环互联起来的，同时缺点是，如果这个ring太大，Ring Allreduce的效率也会变得很低。 Ring Allreduce 有两种组合实现策略： 1）先Reduce后broadcast； 2）先ScatterReduce后AllGather，这两个策略执行后都会让每个XPU节点得到一样的平均梯度，如下图所示： 3.1.1 Reduce +broadcast 在Reduce + broadcast里，reduce先将8张卡的梯度reduce sum到master节点 XPU0 上，再通过broadcast将这个总的平均梯度复制给其他XPU，如下图： Reduce + broadcast这种策略有几个比较大的缺点： 1）8张卡的数据都reduce sum到一张卡，假设每张卡的梯度是100MB，8张卡就是800MB，这可能存在XPU 0计算很久，而其他7张卡空闲的情况存在，整体效率不高； 2）XPU0 的网络带宽可能会成为瓶颈，8张卡的数据都只能通过XPU0的互联网络进行reduce和broadcast，在数据量比较大的场景 XPU0的带宽成为瓶颈； 3）8张XPU不都是两两全互联的，因此，要把8张卡的数据一次Reduce或broadcast，这一点受限于网络互联条件做不到，那么就需要采用 ring或tree的策略进行reduce或broadcast，这样效率也不高。 3.1.2 ScatterReduce + AllGather Ring AllReduce 的Ring ScatterReduce + Ring AllGather策略组合里，每个 XPU只会从前向接受数据，并发送数据给后向，其算法主要分为： ScatterReduce：这一步会先scatter拆分数据块再进行reduce，并且在执行完毕后，每张XPU都会包括一个完整的经过融合的同维梯度； AllGather：这一步会进行全局Gather同步，最后所有 XPU都会得到完整的大的整个梯度； Ring ScatterReduce + Ring AllGather是效率比较高的 Ring AllReduce 组合策略，这个策略考虑到了XPU上的梯度可能很大的情况，比如一个梯度有400MB，在scatterreduce阶段就会先被拆分成 ring上XPU个数份，比如主机内XPU个数等于8，那么 这400MB 就会被 拆分成8份，每份50MB，从而减少了加速卡的计算量以及节约带宽。此外，scatterReduce通过将数据拆分成小块，同时并发进行scatterReduce，从而将通信时间隐藏在计算时间内进而提高Ring AllReduce的效率。 3.1.2.1 ScatterReduce 首先， ScatterReduce先将梯度拆分为N个更小的块，N等于ring里XPU个数，8张卡就拆分成8份，然后进行N-1次scatterreduce迭代。在第一轮迭代中XPU 0上的A0传递给XPU1上A1并相加，XPU1上的B1传递给XPU2上的B2并相加，XPU 2上的C2传递给XPU3上C3并相加，XPU3上的D3传递给XPU4上的D4并相加，以此类推，过程如下图左侧： 接下来，XPU还会进行N-2次 ScatterReduce 迭代，在每次迭代过程中，XPU都会从前向接收一个小梯度块并累加到自己的梯度块中，并且也会向其后向发送一个小梯度块，每个XPU接收和发送的小梯度块在每次迭代中都是不同的，这样经过迭代，到最后，每个XPU将有一个完整的同维梯度，该块梯度中包含所有XPU中该块对应的所有梯度的总和，如上图右侧的累加和部分。 3.1.2.2 Allgather 在scatterReduce迭代完成之后，每个XPU都会得到一个同维度的完整的梯度累加值，将这些完整的累加值复制到其他的加速卡后，才算完成allReduce。Allgather的迭代次数与scatterReduce是相同的，也都需要进行N-1次（N是ring上的XPU卡数）迭代，但是不同于ScatterReduce的是allGather没有reduce的过程，只有数值的复制。这样迭代到最后，每个XPU都得到大的拆分前的梯度的完整累加值，如下图演示了这一过程，从第一次迭代开始，到最后AllGather拿到整体的结果。这里头的具体过程就不在这里描述了，可以查相关资料。 Ring AllReduce 实现简单，在ring较少时，效率也较高，但是在ring比较大时需要的网络节点跳数变得比较大，通信时延增加，因此效率也会降低。比如，一个1000张XPU的 ring，这里头网络的跳数 是N-1= 1000-1 =999， 同时传输的过程中，传输效率还受效率最低、带宽最低的XPU的限制，这时网络上的时延会变得巨高，这个时候ring allreduce拓扑算法就变得不大适用这个场景，同时如果在异构网络里涉及网络的不同连接方式，Ring AllReduce也不大适合使用，因此就需要采用另外的更适合网络结构的更高效的集合通信拓扑算法来进行优化。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_4/:3:1","tags":["Distributed Training"],"title":"分布式训练 – 第4篇 - 分布式训练常用的网络结构及集合通信拓扑算法","uri":"/posts/distributedtraining_4/"},{"categories":["Distributed Computing"],"content":"3.2 2D-Ring AllReduce 如果一台2.1里的服务器只配置了一张RDMA网卡，每台服务器通过RDMA交换机互联，这个集群的网络是异构的（如下图），那么Ring AllReduce拓扑算法就不适用了，这个时候，对于这个网络拓扑结构比较适合的是2D-Ring AllReduce也叫Hierarchical Ring AllReduce。 经过抽象，可以将这个网络结构表达成如下的Torus结构： 横向：每台服务器8个XPU节点，每个XPU节点通过私有协议网络互联； 纵向：每台服务器通过一张RDMA网卡NIC 0 通过交换机互联，这个网卡NIC0 与XPU0 挂在同一个PCIE switch上，满足具备亲和性条件，XPU0上的梯度可以通过NIC 0 与其他服务器上的XPU进行全局规约。 2D-Ring AllReduce的过程如下图所示： 第1步，先进行主机内Ring AllReduce，也可以是 Ring Reduce或者根据主机内的互联情况选用的分层reduce方式，将8张卡上的梯度累加到Master节点 XPU0 上； 第2步，进行主机间XPU 0的 Ring AllReduce，将每台服务器的XPU0上的数据进行全局规约； 第3步，进行主机内Broadcast，将XPU0上的梯度复制到服务器内的其他XPU上 2D-Ring AllReduce能充分发挥异构网络的优势，将主机内、主机间的网络带宽充分利用起来。但是XPU的利用率也不是很高，比如在做主机间的Ring AllReduce，每台服务器内的其他7张XPU是处于空闲状态的。 再假设，如果每台服务器配置了 2张/4张/8张RDMA网卡，这个时候 2D-RING AllReduce又难以将网络的优势发挥出来，那么就需要选用 2D-Torus/2D-Mesh AllReduce拓扑算法。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_4/:3:2","tags":["Distributed Training"],"title":"分布式训练 – 第4篇 - 分布式训练常用的网络结构及集合通信拓扑算法","uri":"/posts/distributedtraining_4/"},{"categories":["Distributed Computing"],"content":"3.3 2D-Torus AllReduce 考虑到服务器内PCIE SWITCH 的亲和性问题，2D-Torus至少需要配备2张 左右对称的RDMA网卡才能发挥这个拓扑算法的优势。在这个集群里主机内每张卡都通过私有的通信协议组成Ring，而主机间，可以通过RDMA网卡（包括虚拟化出来的）与RDMA交换机将XPU两两互联，这个网络也是异构的，如下图所示： 经过抽象，可以将这个网络结构表达成如下的Torus结构： 横向：每台服务器8个XPU节点，每个XPU节点通过私有协议网络互联； 纵向：每台服务器通过至少2张RDMA网卡NIC 0 /NIC 1通过交换机互联，这个网卡NIC0 与XPU0、1、2、3 挂在同一个PCIE switch上，具备亲和性条件，XPU0、1、2、3上的梯度数据可以通过NIC 0 与其他服务器上的XPU进行交换。网卡NIC1 与XPU4、5、6、7 挂在同一个PCIE switch上，具备亲和性条件，XPU4、5、6、7上的梯度数据可以通过NIC 1 与其他服务器上的XPU进行交换； 当然如果网卡是4个或者8个，也可以根据PCIE SWITCH的亲和性情况合理安排XPU与NIC的对应关系。 2D-Torus AllReduce的过程如下图所示： 第1步，横向，先进行主机内Ring ScatterReduce，将主机内8张卡上的梯度进行拆分与规约，这样经过迭代，到最后每个XPU将有一个完整的同维梯度，该块梯度包含所有XPU中该块所对应的所有梯度的总和（参考3.1.2.1 scatterReduce) 第2步，纵向，进行主机间N个（N等于服务器内XPU个数，这里是8个）纵向的 Ring AllReduce，将每台服务器的XPU0-XPU7上的数据进行集群内纵向全局规约； 第3步，横向，进行主机内AllGather，将XPUi(i=0-7)上的梯度复制到服务器内的其他XPU上； 2D-Torus AllReduce能充分挖掘XPU的效率以及发挥异构网络里多网卡的优势，将XPU以及主机内、主机间的网络带宽优势充分利用起来。此外，除了 2D-Torus AllReduce外，2D-Mesh AllReduce也能发挥类似效率。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_4/:3:3","tags":["Distributed Training"],"title":"分布式训练 – 第4篇 - 分布式训练常用的网络结构及集合通信拓扑算法","uri":"/posts/distributedtraining_4/"},{"categories":["Distributed Computing"],"content":"3.4 2D-Mesh AllReduce 2D-Mesh AllReduce的主要思想也是分层，与2D-Torus AllReduce类似，都是水平和垂直两个方向，但是有点差异，如下图所示： 不同于2D-Torus AllReduce的拓扑算法，2D-Mesh AllReduce 过程是： 第1步，横向，先进行主机内Ring AllReduce 将主机内的8张XPU的梯度都进行规约； 第2步，纵向，进行主机间N个（N等于主机内XPU个数，这里是8个）纵向的 Ring AllReduce； 经过这两步，完成了整体的梯度累加，2D-Mesh AllReduce 也能充分发挥XPU与多网卡异构网络的优势，将XPU与主机内、主机间的网络带宽优势充分利用起来。这里的2D-Mesh与Google论文上的有点差异，主要是吸取了其分层的思想而不是复制其一样的设计。理论上2D-Mesh AllReduce对比 2D-Torus AllReduce，主机间AllReduce用的是 主机内8卡的全局梯度，数据量会比ScatterReduce部分来的大点，因此效率也会相应降低一点。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_4/:3:4","tags":["Distributed Training"],"title":"分布式训练 – 第4篇 - 分布式训练常用的网络结构及集合通信拓扑算法","uri":"/posts/distributedtraining_4/"},{"categories":["Distributed Computing"],"content":"4. 问题探讨 如下图所示，基于Torus网络的结构，组合Ring AllReduce，2D-Ring AllReduce, 2D-Mesh AllReduce，2D-Torus AllReduce还能构建 3D-Ring/Mesh/Torus AllReduce拓扑算法，但是这些拓扑算法的效率需要进行实践才能证实，也许在规模较大的集群里才能发挥出3D 拓扑算法的优势。 关于 3D-Ring/Mesh/Torus AllReduce的拓扑算法，这里就不在阐述，可作为研究使用。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_4/:4:0","tags":["Distributed Training"],"title":"分布式训练 – 第4篇 - 分布式训练常用的网络结构及集合通信拓扑算法","uri":"/posts/distributedtraining_4/"},{"categories":["Distributed Computing"],"content":"5. 小结 本文讲述了分布式训练里最常用的几个网络结构以及通信拓扑算法： Ring AllReduce 的最佳组合是 ScatterReduce + AllGather； 2D-Ring AllReduce = 主机内 ringAllReduce/Ring Reduce +主机间 RingAllReduce + 主机内Broadcast； 2D-Torus AllReduce = 主机内 Ring ReduceScatter + 主机间N个Ring AllReduce + 主机内Ring AllGather； 2D-Mesh AllReduce = 主机内Ring AllReduce + 主机间N个Ring AllReduce; Ring AllReduce适合主机内互联Ring的情况使用，2D-Ring AllReduce适合一台服务器配置了一张网卡的异构网络场景，2D-Torus AllReduce与2D-Mesh AllReduce适合一台服务器配置了2/4/8张网卡的异构网络场景。 集合通信拓扑算法多种多样，但基于成本以及效率的取舍考虑，可生产适用的其实也不多，除了理论上的理解之外更重要的是自己编写代码去实践落地。除此之外，还需要解决网络带宽有限、网络容易出故障、落后者效应、部署约束、多租户等产品化的质量要求。 REF: [1] https://www.changping.me [2] 《volta-architecture-whitepaper》 [3] 2D-HRA: Two-Dimensional Hierarchical Ring-based All-reduce Algorithm in Large-Scale Distributed Machine Learning [4] Massively Distributed SGD: ImageNet/ResNet-50 Training in a Flash [5] https://zhuanlan.zhihu.com/p/79030485 , 腾讯机智团队分享–AllReduce算法的前世今生 [6] https://zhuanlan.zhihu.com/p/370548366, ring allreduce和tree allreduce的具体区别是什么？ [7] https://zhuanlan.zhihu.com/p/184942777 , 分布式深度学习初探 [8] https://arxiv.org/abs/1811.06992 ， Image Classification at Supercomputer Scale ","date":"2023-07-13","objectID":"/posts/distributedtraining_4/:5:0","tags":["Distributed Training"],"title":"分布式训练 – 第4篇 - 分布式训练常用的网络结构及集合通信拓扑算法","uri":"/posts/distributedtraining_4/"},{"categories":["Distributed Computing"],"content":"ref: [1]. https://zhuanlan.zhihu.com/p/493092647 ","date":"2023-07-13","objectID":"/posts/distributedtraining_3/:0:0","tags":["Distributed Training"],"title":"分布式训练 – 第3篇 - 集合通信及其通信原语","uri":"/posts/distributedtraining_3/"},{"categories":["Distributed Computing"],"content":"概述 集合通信（Collective Communications）是一个进程组的所有进程都参与的全局通信操作，其最为基础的操作有 发送send、接收receive、复制copy、组内进程栅障同步Barrier以及节点间进程同步(signal+wait)，这几个最基本的操作经过组合构成了一组通信模板也叫通信原语，比如：1对多的广播broadcast、多对1的收集gather、多对多的收集all-gather、1对多的发散scatter、多对1的规约reduce、多对多的规约all-reduce、组合的规约与发散reduce-scatter、多对多的all-to-all等，集合通信的难点在于通信效率以及网络硬件连接拓扑结构的最佳适用。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_3/:1:0","tags":["Distributed Training"],"title":"分布式训练 – 第3篇 - 集合通信及其通信原语","uri":"/posts/distributedtraining_3/"},{"categories":["Distributed Computing"],"content":"通信原语 以一台集成了4张训练加速卡的服务器为例，如下图，服务器内四张训练加速卡是全连接的，物理连接方式可以是私有物理互联协议，比如CXL、NVLINK，也可以是PCIe、InfiniBand、Ethernet等，本文将以此物理拓扑结构描述集合通信中常用的几组通信原语。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_3/:2:0","tags":["Distributed Training"],"title":"分布式训练 – 第3篇 - 集合通信及其通信原语","uri":"/posts/distributedtraining_3/"},{"categories":["Distributed Computing"],"content":"Broadcast Broadcast属于1对多的通信原语，一个数据发送者，多个数据接收者，可以在集群内把一个节点自身的数据广播到其他节点上。如下图所示，圈圈表示集群中的训练加速卡节点，相同的颜色的小方块则代表相同的数据。当主节点 0 执行Broadcast时，数据即从主节点0被广播至其他节点。 Broadcast是数据的1对多的同步，它将一张XPU卡上的数据同步到其他所有的XPU卡上，其应用场景有： 1）数据并行的参数初始化，确保每张卡上的初始参数是一致的； 2）allReduce里的 broadcast + reduce组合里的broadcast操作； 3）分布式训练parameter server 参数服务器结构里的 master节点 broadcast 数据到worker节点，再从worker节点reduce数据回master节点里的broadcast操作； ","date":"2023-07-13","objectID":"/posts/distributedtraining_3/:2:1","tags":["Distributed Training"],"title":"分布式训练 – 第3篇 - 集合通信及其通信原语","uri":"/posts/distributedtraining_3/"},{"categories":["Distributed Computing"],"content":"Scatter 同Broadcast一样，Scatter也是一个1对多的通信原语，也是一个数据发送者，多个数据接收者，可以在集群内把一个节点自身的数据发散到其他节点上。与Broadcast不同的是Broadcast把主节点0的数据发送给所有节点，而Scatter则是将数据的进行切片再分发给集群内所有的节点，如下图所示，不相同的颜色的小方块代表不相同的数据，主节点 0 将数据分为四份分发到了节点0-3。 Scatter是数据的1对多的分发，它将一张XPU卡上的数据进行分片再分发到其他所有的XPU卡上，他的反向操作对应Gather，其应用场景有: 1）ReduceScatter组合里的 Scatter操作； 2）模型并行里初始化时将模型scatter到不同的XPU上； ","date":"2023-07-13","objectID":"/posts/distributedtraining_3/:2:2","tags":["Distributed Training"],"title":"分布式训练 – 第3篇 - 集合通信及其通信原语","uri":"/posts/distributedtraining_3/"},{"categories":["Distributed Computing"],"content":"Gather Gather操作属于多对1的通信原语，具有多个数据发送者，一个数据接收者，可以在集群内把多个节点的数据收集到一个节点上，如下图所示，不相同的颜色的小方块代表不相同的数据。 Gather是数据的多对1的收集，它将多张XPU卡上的数据收集到1张XPU卡上，他的反向操作对应Scatter，其应用场景有： 1）ReduceScatter组合里的 Scatter操作； ","date":"2023-07-13","objectID":"/posts/distributedtraining_3/:2:3","tags":["Distributed Training"],"title":"分布式训练 – 第3篇 - 集合通信及其通信原语","uri":"/posts/distributedtraining_3/"},{"categories":["Distributed Computing"],"content":"AllGather AllGather属于多对多的通信原语，具有多个数据发送者，多个数据接收者，可以在集群内把多个节点的数据收集到一个主节点上（Gather），再把这个收集到的数据分发到其他节点上（broadcast），即收集集群内所有的数据到所有的节点上。 AllGather是数据的多对多的同步全收集，它将多张XPU卡上的数据收集到多张XPU卡上，可以看做Gather + Broadcast的操作组合，它的反向操作对应ReduceScatter，其最应用场景有： 1） AllGather可应用于模型并行； 2）模型并行里前向计算里的参数全同步，需要用allgather把模型并行里将切分到不同的XPU上的参数全同步到一张XPU上才能进行前向计算。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_3/:2:4","tags":["Distributed Training"],"title":"分布式训练 – 第3篇 - 集合通信及其通信原语","uri":"/posts/distributedtraining_3/"},{"categories":["Distributed Computing"],"content":"Reduce Reduce属于多对1的通信原语，具有多个数据发送者，一个数据接收者，可以在集群内把多个节点的数据规约运算到一个主节点上，常用的规约操作符有：求累加和SUM、求累乘积PROD、求最大值MAX、求最小值MIN、逻辑与 LAND、按位与BAND、逻辑或LOR、按位或BOR、逻辑异或LXOR、按位异或BOXR、求最大值和最小大的位置MAXLOC、求最小值和最小值的位置MINLOC等，这些规约运算也需要加速卡支持对应的算子才能生效。 Reuduce操作从集群内每个节点上获取一个输入数据，通过规约运算操作后，得到精简数据，如下图的SUM求累加和：节点0数值 5、节点1数值6、节点2数值7、节点3数值8，经过SUM运算后 累积和为 26，即得到更为精简的数值，在reduce原语里回会去调用 reduce SUM算子来完成这个求和累加。 Reduce是数据的多对1的规约运算，它将所有张XPU卡上的数据规约（比如SUM求和）到1张XPU卡上，其应用场景有： 1）AllReduce里的 broadcast + reduce组合里的reduce操作； 2）ReduceScatter组合里的 reduce操作； 3）分布式训练parameter server 参数服务器结构里的 master节点 broadcast 数据到worker节点，再从worker节点reduce数据回master节点里的reduce操作； ","date":"2023-07-13","objectID":"/posts/distributedtraining_3/:2:5","tags":["Distributed Training"],"title":"分布式训练 – 第3篇 - 集合通信及其通信原语","uri":"/posts/distributedtraining_3/"},{"categories":["Distributed Computing"],"content":"ReduceScatter ReduceScatter属于多对多的通信原语，具有多个数据发送者，多个数据接收者，其在集群内的所有节点上都按维度执行相同的Reduce规约运算，再将结果发散到集群内所有的节点上，Reduce-scatter等价于节点个数次的reduce规约运算操作，再后面执行节点个数的scatter次操作，其反向操作是AllGather。 如下图所示，先reduce操作 XPU 0-3的数据reduce为 A(A0+A1+A2+A3) + B(B0 + B1 +B2 + B3) + C(C0 + C1 + C2 + C3) + D(D0 + D1 + D2 + D3 ) 到一张XPU上，再进行分片scatter到集群内所有的XPU卡上。 ReduceScatter是数据的多对多的reduce + scatter运算，它将所有的XPU卡上的数据先规约（比如SUM求和）到1张XPU卡上，再进行scatter，其应用场景有： 1）ReduceScatter即可应用于数据并行也可应用于模型并行； 2）数据并行allReduce里的 ReduceScatter+ Allgather组合里的ReduceScatter操作； 3）模型并行里在前向allgather后的反向计算里的ReduceScatter； ","date":"2023-07-13","objectID":"/posts/distributedtraining_3/:2:6","tags":["Distributed Training"],"title":"分布式训练 – 第3篇 - 集合通信及其通信原语","uri":"/posts/distributedtraining_3/"},{"categories":["Distributed Computing"],"content":"AllReduce AllReduce属于多对多的通信原语，具有多个数据发送者，多个数据接收者，其在集群内的所有节点上都执行相同的Reduce操作，可以将集群内所有节点的数据规约运算得到的结果发送到所有的节点上。AllReduce操作可通过在主节点上执行Reduce + Broadcast或ReduceScatter + AllGather实现，如下图所示：先在主节点上执行reduce得到规约累加和26，再把这个累加和26 broadcast到其他的节点，这样整个集群内，每个节点的数值就都保持一致。 AllReduce是数据的多对多的规约运算，它将所有的XPU卡上的数据规约（比如SUM求和）到集群内每张XPU卡上，其应用场景有： 1） AllReduce应用于数据并行； 2）数据并行各种通信拓扑结构比如Ring allReduce、Tree allReduce里的 allReduce操作； ","date":"2023-07-13","objectID":"/posts/distributedtraining_3/:2:7","tags":["Distributed Training"],"title":"分布式训练 – 第3篇 - 集合通信及其通信原语","uri":"/posts/distributedtraining_3/"},{"categories":["Distributed Computing"],"content":"All-To-All All-To-All操作每一个节点的数据会scatter到集群内所有节点上，同时每一个节点也会Gather集群内所有节点的数据。ALLTOALL是对ALLGATHER的扩展，区别是ALLGATHER 操作中，不同节点向某一节点收集到的数据是相同的，而在ALLTOALL中，不同的节点向某一节点收集到的数据是不同的，如下图所示: AllToAll是数据的多对多的转置，它将所有张XPU卡上的数据转置到所有的XPU卡上，其主要应用场景有： 1） AllToAll应用于模型并行； 2）模型并行里的矩阵转置； 3）数据并行到模型并行的矩阵转置； ","date":"2023-07-13","objectID":"/posts/distributedtraining_3/:2:8","tags":["Distributed Training"],"title":"分布式训练 – 第3篇 - 集合通信及其通信原语","uri":"/posts/distributedtraining_3/"},{"categories":["Distributed Computing"],"content":"Send 与 Receive 数据或参数在不同XPU之间的发送与接收。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_3/:2:9","tags":["Distributed Training"],"title":"分布式训练 – 第3篇 - 集合通信及其通信原语","uri":"/posts/distributedtraining_3/"},{"categories":["Distributed Computing"],"content":"Barrier BARRIER同步操作会阻塞所有的调用者直到所有的组内成员都调用了它， 用于一个集合通信子中所有进程的同步，调用函数时进程将处于等待状态，直到通信子中所有进程 都调用了该函数后才继续执行。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_3/:2:10","tags":["Distributed Training"],"title":"分布式训练 – 第3篇 - 集合通信及其通信原语","uri":"/posts/distributedtraining_3/"},{"categories":["Distributed Computing"],"content":"Signal与Wait Signal与Wait属于记录型信号量机制： wait(s)，signal(s)可用于解决进程间的同步问题，在通信原语里从一个节点发送一个数据到另外一个节点时，会同时signal一个event值到对端，对端的wait操作接收到这个event时会返回一个确认给signal，这样保证在节点的进程间进行数据的同步操作。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_3/:2:11","tags":["Distributed Training"],"title":"分布式训练 – 第3篇 - 集合通信及其通信原语","uri":"/posts/distributedtraining_3/"},{"categories":["Distributed Computing"],"content":"小结 在分布式训练过程中，深度学习训练框架不会去直接操作底层的通信网络，而是通过使用网络通信库来完成数据的集合通信，各家AI芯片加速卡厂家都会提供私有的网络通信库比如：xxx-AWARE OpenMPI或xCCL来完成这个底层通信硬件的屏蔽与抽象。在分布式训练集群里网络通信硬件连接样式多种多样，可以是Ethernet、InfiniBand 、RoCE v2/v1 等也可以是CXL、NVLINK等私有协议，这就要求在通信的后端层根据各个厂家的自己的SDK开发库接口，根据实际情况实现 各自的网络通信库，比如cuda-aware MPI、NCCL、NVSHMEM，以及根据实际的网络拓扑组合完成对应的最有效的网络拓扑算法。 本文讲述了分布式训练里的集合通信原语，这些原语是集合通信拓扑算法的基本组成单元，后续的文章里会讲述如何组合这些通信原语以完成合适的通信拓扑算法。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_3/:3:0","tags":["Distributed Training"],"title":"分布式训练 – 第3篇 - 集合通信及其通信原语","uri":"/posts/distributedtraining_3/"},{"categories":["Distributed Computing"],"content":"ref: [1]. https://zhuanlan.zhihu.com/p/492667659 ","date":"2023-07-13","objectID":"/posts/distributedtraining_2/:0:0","tags":["Distributed Training"],"title":"分布式训练 – 第2章 - 训练与系统评价指标","uri":"/posts/distributedtraining_2/"},{"categories":["Distributed Computing"],"content":"前言 不同于教科书里讲的深度学习的评价指标，这里主要讲述生产训练中常用的评价指标。通常在分布式训练中对训练的过程与结果会进行评价，比如选择一个评价指标：准确率，即表明模型求解给定问题的准确度。而本文提到的评价指标主要分为两大类，即训练结果评价与训练系统评价。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_2/:1:0","tags":["Distributed Training"],"title":"分布式训练 – 第2章 - 训练与系统评价指标","uri":"/posts/distributedtraining_2/"},{"categories":["Distributed Computing"],"content":"训练指标 教科书里经常提到的深度学习的评价指标有准确率、精确率、召回率、F1值等，如下： 准确率（Accuracy），所有的预测正确（正类负类）的占总的比重； 精确率（Precision），查准率，即正确预测为正的占全部预测为正的比例； 召回率（Recall），查全率，即正确预测为正的占全部实际为正的比例； F1值（H-mean值），F1值为算数平均数除以几何平均数，且越大越好； 实际上这些指标在真正的生产过程中用的不多，在实际的分布式训练过程中，比较关心的训练评价指标有： 加速比（speedup），即多卡训练下的单卡吞吐量平均指标除以单卡训练下的吞吐量平均指标，比如，大规模训练下的 ResNet-50 v1.5的单卡FPS指标是600，而单卡训练的FPS指标是800，那么加速比即 600/800 = 0.75，加速比体现的是训练集群的效率与可扩展性，越高的加速比表明训练集群的资源利用率越高，但是越高的加速比要求对训练集群的技术要求也越高。比如 一个 1000张卡的训练集群，要求 加速比 0.9以上，那么对于主机间的网络、主机内的网络、全栈软件、训练卡内部的硬件架构、集合通信拓扑算法、训练算法的优化等的要求都极高，这就涉及到整个分布式训练系统的问题，而不是单个点能彻底解决的； 吞吐量，sequence/sec 或 FPS, 即每秒能处理的图片数或数据量； 收敛时间（Time）与训练次数（epoch），生产过程中对训练所有的时间是有要求的，假设给定一个模型的训练次数(epoch)为100，如果要把这个100次都训练完需要 好几天，甚至好几个星期，那么可以认为生产不适用，基本上可以定义 训练一个模型到收敛需要 24小时以上，都可以看做是生产不适用，需要扩大训练集群的规模，使之训练时间控制在24小时之内； 平均准确率(eval Accuracy)，平均准确率是训练是否收敛的重要评判标准之一，比如定义一个 Resnet50 v1.5 的训练模型的准确率为 76%，如果训练结束的平均准确率能达到这个值就认为训练是收敛的； 可收敛，训练的最终结果可以达到 平均准确率的要求，即认为可收敛，否者即任务训练失败； 学习率(Learning rate)与损失率(Loss)，学习率大模型训练学习速度快，但是易导致损失率爆炸, 学习率小模型训练学习速度慢，而且容易过拟合，收敛速度慢； 曲线拟合(Curve Fitting)，这是一个非常重要的评价手段，在XPU训练的场景下，通常先用一个已有的之前训练好模型为基础或先用GPU训练出一个基础模型，然后把XPU训练的结果指标跟GPU训练模型的指标进行比较，曲线拟合即认为XPU的训练结果达标，这也是调试XPU训练结果的一个重要手段。这里埋一个问题，按照曲线拟合的说法，假设有一个2000张XPU卡的集群，怎样评价这个集群训练的结果是正确的？以GPU训练的结果做比较，那么找一个这么大规模的GPU集群进行训练然后得到想要的模型做基础匹配也是不大现实的，那么需要采用什么技术方案才能解决这个问题？ 以TensorBoard为例，说明模型的评价指标，在下面的命令行列输入一个baseline:/log_path_2： tensorboard --logdir=training_model:/log_path_1, baseline:/log_path_2 这个baseline 的模型已经确定是精度达标，生产可用的。然后 XPU训练的模型的 training_model:/log_path_1 与这个GPU训练处的baseline进行比，在tensorboard里可以表现如下图： 在上图里，新的模型的eval_accuracy值与baseline的值最终是一样的，这说明训练结果是收敛且精度达标，eval_accuracy中间的线有点差异是由于按不同的训练次数进行tensorboard指标保存所造成。新模型的Loss线与Learning_rate 线也与基础线吻合，这说明XPU训练的模型质量可生产适用。eval_accuracy、Loss、Learning_rate是三个最重要的度量指标，只要这样三个指标达标，那么大概率即可判断这个在XPU下新训练的模型具备生产可用能力。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_2/:2:0","tags":["Distributed Training"],"title":"分布式训练 – 第2章 - 训练与系统评价指标","uri":"/posts/distributedtraining_2/"},{"categories":["Distributed Computing"],"content":"系统指标 分布式训练系统其本身也是一个分布式系统，因此除了训练领域相关的度量指标，也有与分布式系统质量有关的一套度量指标，其中比较重要的几项内容如下： 可用性(Availability)，可用性指的是分布式训练系统长时间可对外提供服务的能力，通常采用小数点后的9的个数作为度量指标，按照这种约定“五个九”等于0.99999（或99.999％）的可用性，默认企业级达标的可用性为6个9。但是当前从时间维度来度量可用性已经没有太大的意义，因为设计得好的系统可以在系统出现故障得情况下也能保证对外提供得服务不中断，因此，当前更合适得可用性度量指标 是请求失败率; 可靠性(Reliability)，可靠性一般指系统在一定时间内、在一定条件下可以无故障地执行指定功能的能力或可能性， 也是采用小数点后的9的个数作为度量指标，通常5个9的可靠性就可以满足企业级达标； 可伸缩性(Scalability)，是指通过向系统添加资源来处理越来越多的工作并且维持高质量服务的能力，其受可用性以及可靠性的制约，集群规模越大出故障的概率越高从而降低可用性、可靠性，为了保证可用性以及可靠性达标，需要适配合理的可伸缩性指标； 韧性(resilience)，通常也叫容错性（fault-tolerant），也就是健壮和强壮的意思，指的是系统的对故障与异常的处理能力，比如在软件故障、硬件故障、认为故障这样的场景下，系统还能保持正常工作的能力，分布式训练系统的容错能力是一个非常重要的指标。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_2/:3:0","tags":["Distributed Training"],"title":"分布式训练 – 第2章 - 训练与系统评价指标","uri":"/posts/distributedtraining_2/"},{"categories":["Distributed Computing"],"content":"小结 本文从实践的角度讲述了分布式训练的训练结果评价指标与系统评价指标，这些指标是度量一个分布式训练系统与训练的模型是否生产可用的重要参考。日拱一卒，功不唐捐，分享是最好的学习，与其跟随不如创新，希望这个知识点对大家有用。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_2/:4:0","tags":["Distributed Training"],"title":"分布式训练 – 第2章 - 训练与系统评价指标","uri":"/posts/distributedtraining_2/"},{"categories":["Distributed Computing"],"content":"ref: [1]. https://zhuanlan.zhihu.com/p/487945343 ","date":"2023-07-13","objectID":"/posts/distributedtraining_1/:0:0","tags":["Distributed Training"],"title":"分布式训练 – 第1章 - 什么是分布式训练","uri":"/posts/distributedtraining_1/"},{"categories":["Distributed Computing"],"content":"前言 深度学习软件工程具有一体两面性：单卡的功能完备性、质量、用户体验以及多卡大规模。多卡大规模的出现是为了解决这样一个主要矛盾，即：“日益增长的数据、模型训练的需求与当前单卡计算能力无法满足这个需求之间的矛盾”，而分布式训练可以通过扩展卡子的规模解决这个矛盾，因此，这就是分布式训练的价值。 然而，正如懂得很多道理，仍旧过不好这一生一样，懂得很多分布式训练的理论与知识，也不一定就能做好一个分布式训练系统。把这么多机器连接跑起来、跟跑好也是两回事，分布式训练是一门实践的软件工程，只有你PK过设计方案，调试过一个个Bug，手把手的敲过一行行的代码，为了性能指标能达标无所不用其极的去验证各种性能优化方案，才能知道细节在哪里，难点在哪里，痛点、挑战点在哪里。因此，宏观处着眼，微观处着手，才能完全理解分布式训练的道理。 一个知识领域里的 “道 法 术 器” 这四个境界需要从 微观、中观以及宏观 三个角度来把握，微观是实践，中观讲方法论，宏观靠领悟。本系列文章我把它命名为《分布式训练》，从工程实战的角度拆解分布式训练里最重要的套路，也是从“微观实践、中观方法论、宏观领悟”这三个维度系统性的探讨分布式训练技术，本文讲述第一篇，也是最难讲清楚的一篇（后续保持迭代更新），即本质的一问：“什么是分布式训练\"。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_1/:1:0","tags":["Distributed Training"],"title":"分布式训练 – 第1章 - 什么是分布式训练","uri":"/posts/distributedtraining_1/"},{"categories":["Distributed Computing"],"content":"什么是分布式训练 简单来说，分布式训练 = 分布式训练系统 = 分布式系统 + 训练系统，因此，要解答什么是分布式训练就需要解答什么是分布式系统以及什么是训练系统，而“系统 = 要素x连接 + 目的 + 边界”，因此进一步的就是需要分析分布式系统的要素、连接、目的与边界以及训练系统的要素、连接、目的与边界。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_1/:2:0","tags":["Distributed Training"],"title":"分布式训练 – 第1章 - 什么是分布式训练","uri":"/posts/distributedtraining_1/"},{"categories":["Distributed Computing"],"content":"分布式系统 在AI训练过程中采用单卡总会遇到一些问题，比如原始的数据样本太大无法加载进训练卡，或者模型太大无法训练，那么这就需要用到分布式技术把大量的数据分割成小块由多个训练卡分别进行计算，在更新运算结果后，再将结果统一合并得出最终的可用模型。百科上对分布式系统的定义有： A distributed system is a system whose components are located on different networked computers, which communicate and coordinate their actions by passing messages to one another. The components interact with one another in order to achieve a common goal. 即： 分布式系统是指其组件位于不同的网络计算机上的系统，这些组件通过相互传递消息来进行通信和协调其动作，且彼此相互交互以完成一个共同的任务目标。 从这句话可以得出三个结论： 分布式系统的组件是位于不同的网络计算机上的； 分布式系统的组件通过传递消息进行通信与协调的； 分布式系统的组件是通过相互交互以完成一个共同的任务目标，同时是有边界的； 因此基于此定义，拆解分布式系统的概念，从中可以看到分布式系统里的要素即为组件，连接即网络，目的是共同的任务目标。其中的位于不同的网络计算机上的“组件”是分布式系统的要素，即各种计算单元，比如Ai训练加速卡，“网络”是分布式系统的连接，即神经网与数据网，“共同的任务目标”是分布式系统的目的，即训练，至此，再进一步抽象，可以推导出分布式系统的公理化定义，也是分布式系统的本质理论定义： 分布式系统 = 计算 x 网络 + 功能 + 边界 在这个公式里，计算即计算单元，是各种AI训练加速卡，比如GPU, TPU, DPU, DTU。网络即网络连接单元，在单个训练卡内为计算用的神经网，主机内的多个卡子之间是PCIE 以及PCIE Switch，以及各种高带宽通信网，比如GenZ,CXL,NVLINK,OpenCAPI,CCIX等，在主机之间是各种通信网络，比如RDMA网络、InfiniBand网络、普通的TCP网络以及对应的各种交换机，另外从磁盘 + 主机内存 + 训练卡的HBM这个IO路径我们认为属于IO网络，而这里的目的即训练，同时这个系统是有边界的，其专注于解决Ai训练过程中的难题，不是什么功能都能往里塞都能解决的。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_1/:2:1","tags":["Distributed Training"],"title":"分布式训练 – 第1章 - 什么是分布式训练","uri":"/posts/distributedtraining_1/"},{"categories":["Distributed Computing"],"content":"训练系统 以数据并行随机梯度下降( SGD )技术为例，神经网络训练的过程如下: 1，首先需要通过在第一个step进行Broadcast操作将参数同步到集群内的所有的训练卡上; 2，将数据样本切片分发到整个集群的每张训练卡上并且通过data Loader技术将数据样本加载进训练卡的高速内存空间内，作为输入X; 3，每个训练卡在其数据样本上运行前向传播，计算出误差LOSSi； 4，对计算出的LOSSi进行反向传播，得到梯度GRADi； 5，所有的训练卡在主机内及主机之间进行集合通信并进行梯度归约(AllReduce)； 6，最后再进行参数更新以获得新的梯度参数。 本质上分布式训练是数据加载、前向传播、反向传播、集合通信以及参数更新这5个步骤的逻辑组合，因此，基于以上步骤，这里可以推导出训练系统的公式定义如下： 训练系统 = 数据加载 + （前向传播 + 反向传播） + 集合通信 + 参数更新 从上面的步骤可知分布式训练是在固定的步骤迭代中进行的，并且需要系统内的所有的训练卡都完成它们的迭代步骤，才能进行最后的参数更新，这相当于在单个训练卡上执行梯度下降技术，但是通过在系统内所有的训练卡之间分发数据样本并同时执行计算来获得训练的加速。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_1/:2:2","tags":["Distributed Training"],"title":"分布式训练 – 第1章 - 什么是分布式训练","uri":"/posts/distributedtraining_1/"},{"categories":["Distributed Computing"],"content":"举例说明 以TensorFlow为例说明模型的训练过程，TensorFlow 是用数据流图做计算的，如下图所示: 图中显示了 TensorFlow 的训练过程，其包含输入（input）、塑形（reshape）、Relu 层（Relu layer）、Logit 层（Logit layer）、Softmax、交叉熵（cross entropy）、梯度（gradient）、SGD 训练（SGD Trainer）等部分。 它的训练过程是，首先从数据分片输入开始，经过Reshape数据清洗后，进行前向传播运算，通过Relu 层后得到LOSS值，然后进入 Logit 层，再进行反向传播并且用 Cross Entropy、softmax等 来计算梯度，接着进行梯度归约(Allreduce)，这一步在分布式场景就涉及集合通信的过程，最后进行参数更新SGD Trainer，如此迭代循环直到获得收敛指标达标的结果为止。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_1/:2:3","tags":["Distributed Training"],"title":"分布式训练 – 第1章 - 什么是分布式训练","uri":"/posts/distributedtraining_1/"},{"categories":["Distributed Computing"],"content":"小结 采用分布式训练的目的往往也是因为数据量或模型太大，一个加速卡的高速内存放不下，因此对数据或者模型进行切分，分发到多卡上进行计算与归约。本文很概况性的讲述了什么是分布式训练，简单来说分布式训练就是分布式计算的一种，通过对数据样本的计算，得出最后可用的模型再用于数据推理。本系列文章的后续内将展开讲述分布式训练的基础理论、训练过程、质量保证、集合通信、系统工程、产品化等，同样分布式训练系统除了解决训练所带来的各种故障也还需要解决分布式所带来的各种故障。 ","date":"2023-07-13","objectID":"/posts/distributedtraining_1/:3:0","tags":["Distributed Training"],"title":"分布式训练 – 第1章 - 什么是分布式训练","uri":"/posts/distributedtraining_1/"},{"categories":["Distributed Computing"],"content":"Horovod 介绍 Horovod 是 Uber 开源的深度学习工具，它的发展吸取了Facebook “Training ImageNet In 1 Hour” 与百度 “Ring Allreduce” 的优点，在保证分布式训练性能的同时，兼顾了前端的简洁和对不同深度学习框架的支持，使用起来对开发人员比较的友好，算是分布式训练方向的标杆项目了。 ","date":"2023-07-13","objectID":"/posts/horovod_and_openmpi/:1:0","tags":["Horovod"],"title":"Horovod and Openmpi","uri":"/posts/horovod_and_openmpi/"},{"categories":["Distributed Computing"],"content":"集合通信库 集合通信库，这个词可能听起来会比较的陌生，不过如果我再提几个关键字，可能大家多少都会有所耳闻。资历比较老的是 MPI (Message Passing Interface 及其实现 OpenMPI 和 MPICH，年轻一点的会是 Nvidia 针对其显卡开源的 NCCL，或者是 facebook 开源的 gloo，或者是像华为针对其高性能硬件提供的HCCL，大体上都可以归入到集合通信库的类别。他们相同的地方是大体上会遵照 MPI 提供的接口规定，实现了包括点对点通信（SEND,RECV等），集合通信（ REDUCE，BROADCAST，ALLREDUCE等）等相关接口，然后根据自己硬件或者是系统的需要，在底层实现上进行了相应的改动，保证接口的稳定和性能。 ","date":"2023-07-13","objectID":"/posts/horovod_and_openmpi/:2:0","tags":["Horovod"],"title":"Horovod and Openmpi","uri":"/posts/horovod_and_openmpi/"},{"categories":["Distributed Computing"],"content":"点对点通信: Point-to-Point Communication Send/Recv: ","date":"2023-07-13","objectID":"/posts/horovod_and_openmpi/:2:1","tags":["Horovod"],"title":"Horovod and Openmpi","uri":"/posts/horovod_and_openmpi/"},{"categories":["Distributed Computing"],"content":"集合通信 Scatter/Gather reduce/allreduce boradcast/all-gather 这里在机器学习训练中使用比较多的是 all-reduce，场景类似在不同的 node 上跑不同 batch 的数据，然后更新梯度需要从各个汇总之后平均再回传到各自的 node 中。而这部分，有很多种实现的方式，比较直观和简单的是把所有的梯度都汇总到的某一个 node 上（如下图 node d 所示），然后再把汇总的信息重新分发到不同的 node 上 ，这样可以计算通信量，如下：对于 P 个节点，每个节点消息大小为 M，node d 节点的通信量为 2*(P-1)M，这里假设节点之间互联互通，带宽为B。 不过这种情况下，很容易导致 node d 会成为性能瓶颈，因为 node d 需要跟其他所有 node 通信所以它的通信量是其他节点的 P 倍。假设节点间的带宽还是一样，node d 完成所有通信所需要的时间是 2(P-1)M/B*。所以现在很多的集合通信框架不会使用这种方式，更多的是通过树状或者是环状(ring) 去实现 all-reduce。 如果只是做成树状的可以做成如下图所示，虽然传递的步数增多了，不过消除了node d 的通信瓶颈，完成所有的通信的时间大概是 2log_2N(M/B)*，随着节点数目 P 的增加，树形结构的效果会越来越明显。 业界用得最多一种优化的方式是，每次只传一部分，这部分是百度提出的 ring-allreduce 的方案，具体的介绍可以参考这篇博客Bringing HPC Techniques to Deep Learning，这边就不赘述了。整体上就是每次不会像上面这样整份数据传递，而是一部分一部分传，优化后，所有节点需要传输的数据量的传输 2(N−1)M/N 比较平均，所需要的时间可以大概是 2(N−1)M/(NB)，horovod 也是基于这种 all-reduce 的形式实现的。 ","date":"2023-07-13","objectID":"/posts/horovod_and_openmpi/:2:2","tags":["Horovod"],"title":"Horovod and Openmpi","uri":"/posts/horovod_and_openmpi/"},{"categories":["Distributed Computing"],"content":"实践: pytorch.distributed 尝试使用 pytorch 自带的分布式工具包 torch.distributed，进行一些概念性的尝试。 为了方便尝试，我这里提供了一个简单的 demo，大家如果安装了 gpu 版本的 pytorch \u003e= 1.3，应该都可以尝试下面的例子尝试使用多进程模拟分布式（单机上可以跑）。 import os import torch import torch.distributed as dist import time import argparse from torch.multiprocessing import Process parser = argparse.ArgumentParser(description='PyTorch MNIST Example') parser.add_argument('-m', '--mode', type=str, default='one_device', metavar='N', help='distribute mode, distributed/one_device') parser.add_argument('-f', '--function', type=str, default='p2p', metavar='N', help='function to run (p2p/all_reduce/gpu_all_reduce)') parser.add_argument('-b', '--backend', type=str, default=\"nccl\", metavar='N', help='distribute backend (gloo/nccl)') def init_process(rank, size, fn, backend='nccl'): \"\"\" Initialize the distributed environment. \"\"\" os.environ['MASTER_ADDR'] = '127.0.0.1' os.environ['MASTER_PORT'] = '29500' dist.init_process_group(backend, rank=rank, world_size=size) fn(rank, size) def run(rank, size): tensor = torch.zeros(1) print('Rank ', rank, ' has data before send/recv', tensor) if rank == 0: tensor += 1 # Send the tensor to process 1 dist.send(tensor=tensor, dst=1) else: # Receive tensor from process 0 dist.recv(tensor=tensor, src=0) print('Rank ', rank, ' has data after send/recv', tensor) def run_allreduce(rank, size): \"\"\" Simple reduce communication. \"\"\" group = dist.new_group([0, 1]) device = torch.device('cuda:%d' % rank) tensor = torch.ones(1).to(device) dist.all_reduce(tensor, op=dist.ReduceOp.SUM, group=group) print('Rank ', rank, ' has data ', tensor[0]) def run_multigpu_allreduce(rank, size): group = dist.new_group([0, 1]) tensor_list = [] for dev_idx in range(2): device = torch.device('cuda:%d' % (2 * rank + dev_idx)) tensor = torch.ones(1).to(device) tensor_list.append(tensor) dist.all_reduce_multigpu(tensor_list) print('all_reduce_multigpu', tensor_list) dist.all_reduce(tensor_list[0], op=dist.ReduceOp.SUM, group=group) print('Rank ', rank, ' has data tensor[0]:', tensor_list[0], \", tensor[1]:\", tensor_list[1]) if __name__ == \"__main__\": args = parser.parse_args() backend = args.backend if args.mode == \"distributed\" or os.environ.get('RANK',None): print(\"in distribute mode\") if args.function == \"all_reduce\": function, size = run_allreduce, 2 elif args.function == \"gpu_all_reduce\": function, size = run_multigpu_allreduce, 2 else: function, size, backend = run, 2, \"gloo\" rank = int(os.environ['RANK']) p = Process(target=init_process, args=(rank, size, function, backend)) p.start() p.join() else: print(\"in one device mode\") if args.function == \"all_reduce\": function, size = run_allreduce, 2 elif args.function == \"gpu_all_reduce\": function, size = run_multigpu_allreduce, 2 else: function, size, backend = run, 2, \"gloo\" processes = [] for rank in range(size): p = Process(target=init_process, args=(rank, size, function, backend)) p.start() processes.append(p) for p in processes: p.join() 可以简单地运行上面的例子： send/recv: $ python3 distribute_test.py # 输出如下： in one device mode Rank 0 has data before send/recv tensor([0.]) Rank 1 has data before send/recv tensor([0.]) Rank 0 has data after send/recv tensor([1.]) Rank 1 has data after send/recv tensor([1.]) 上面是演示的是通过 pytorch 的 multiprocessing 包，模拟一次分布式的 send/recv 过程，这里是 rank0 的进程往 rank1 的进程发送一个 tensor，可以看到 rank 1 tensor 初始化为 0，是接收到 rank 0 的tensor 后变为 1 的。（注意：这里特别设置了 backend 为 gloo 是因为 nccl 不支持 point2point 的传输，具体不同 backend 支持什么形式的原语，参考文档backend部分 ） all_reduce $ python3 distribute_test.py -f all_reduce # 输出如下： in one device mode Rank 0 has data tensor(2., device='cuda:0') Rank 1 has data tensor(2., device='cuda:1') # 对应函数 def run_allreduce(rank, size): \"\"\" Simple reduce communication. \"\"\" group = dist.new_group([0, 1]) # use rank 0 and rank 1 device = torch.device('cuda:%d' % rank) tensor = torch.ones(1).to(device) dist.all_reduce(tensor, op=dist.ReduceOp.SUM, group=group) print('Rank ', rank, ' has data ', tensor[0]) 这里也很浅白，主要就是对两个进程上的 tensor 进行一次 allreduce，可以看到两个 rank 上的结果都为 2了。 g","date":"2023-07-13","objectID":"/posts/horovod_and_openmpi/:2:3","tags":["Horovod"],"title":"Horovod and Openmpi","uri":"/posts/horovod_and_openmpi/"},{"categories":["Distributed Computing"],"content":"MPI 更深入的尝试，可以尝试了解一下 mpi 的知识，这个mpi教程 算是写得比较系统的，大家可以参考一下来练习，特别是对底层不是很了解的同学，可以多看看 Running an MPI cluster within a LAN 的部分，实操一下通过 ssh 跑起一个分布式的 demo。集合通信库的基础大概先到这里，如果要深入的可以再去看看 openMPI，和 nccl 的实现。 ","date":"2023-07-13","objectID":"/posts/horovod_and_openmpi/:2:4","tags":["Horovod"],"title":"Horovod and Openmpi","uri":"/posts/horovod_and_openmpi/"},{"categories":["Distributed Computing"],"content":"Horovod流程分析 下面我会以一个简单的 pytorch horovod 的 demo 尝试去理解一下 horovod 的工作机理，demo 如下（省略了一些不关键的代码段）。为了准确起见，我们是根据 horovod v0.20.3 的版本进行阅读的，如果是其他版本，可能会跟这里的内容有一些出入。 ","date":"2023-07-13","objectID":"/posts/horovod_and_openmpi/:3:0","tags":["Horovod"],"title":"Horovod and Openmpi","uri":"/posts/horovod_and_openmpi/"},{"categories":["Distributed Computing"],"content":"pytorch demo 一般的 horovod 训练程序都会包含以下几个关键步骤： 1. hvd.init: 对 horovod 2. 初始化。初始化模型，数据集，优化器，初始化不同 node 的模型权重。 3. 使用 hvd.DistributedOptimizer 包装优化器。 4. 进入训练流程，进行优化迭代。 我们会着重介绍第 1 和 4 步，因为主要也是1，4步会跟 c++ 后端进行信息交换。 import torch.backends.cudnn as cudnn import torch.nn.functional as F import torch.optim as optim import torch.utils.data.distributed from torchvision import models import horovod.torch as hvd import timeit import numpy as np ... # some argparse hvd.init() # Set up standard model. model = getattr(models, args.model)() optimizer = optim.SGD(model.parameters(), lr=0.01 * lr_scaler) # Horovod: (optional) compression algorithm. compression = hvd.Compression.fp16 if args.fp16_allreduce else hvd.Compression.none # Horovod: wrap optimizer with DistributedOptimizer. optimizer = hvd.DistributedOptimizer(optimizer, named_parameters=model.named_parameters(), compression=compression, op=hvd.Adasum if args.use_adasum else hvd.Average) # Horovod: broadcast parameters \u0026 optimizer state. hvd.broadcast_parameters(model.state_dict(), root_rank=0) hvd.broadcast_optimizer_state(optimizer, root_rank=0) # Set up fixed fake data data = torch.randn(args.batch_size, 3, 224, 224) target = torch.LongTensor(args.batch_size).random_() % 1000 if args.cuda: data, target = data.cuda(), target.cuda() def benchmark_step(): optimizer.zero_grad() output = model(data) loss = F.cross_entropy(output, target) loss.backward() optimizer.step() #... some log configuration img_secs = [] for x in range(args.num_iters): time = timeit.timeit(benchmark_step, number=args.num_batches_per_iter) img_sec = args.batch_size * args.num_batches_per_iter / time img_secs.append(img_sec) # Results ... 然后下图是我对 horovod 整体流程的梳理，把一些不是很关键的部分隐藏了，可能有一些细节的地方和实现有出入，不过我待会会有详细的说明。这里先解释一下，下面几个大的部分: main.py： 表示训练脚本，一般是 使用 horovod 提供的函数跟特定的训练框架相互合作完成分布式训练（下文称前端） C++ interface：是指 horovod python 函数调用 C++ 的接口 GlobalState：在 horovod 中是一个全局变量，其中的元素可以供不同的线程访问，在加载 C++ 的代码时候就已经创建了，同时创建的还有各种 context（mpi_context, nccl_context, gpu_context）后面会提到，主要会在下图 backgroundThreadLoop 中完成 globalstate 不同元素初始化，比较重要的有 controller 管理总体通信控制流，tensor_queue 会处理从前端过来的通信需求（allreduce，broadcast 等）。 BackgroundThreadLoop：是训练过程中的后台线程，主要负责跟其他节点的通信，和处理前端过来的通信需求（request），会轮询调用 RunLoopOnce，不断查看 tensor_queue 中有没有需要通信的tensor，如果有跟其他节点同步更新，然后执行通信操作。 ","date":"2023-07-13","objectID":"/posts/horovod_and_openmpi/:3:1","tags":["Horovod"],"title":"Horovod and Openmpi","uri":"/posts/horovod_and_openmpi/"},{"categories":["Distributed Computing"],"content":"流程分析 下面使用 mpi_controller 进行 allreduce 操作进行分析。 1.hvd.init()-\u003eInitializeHorovodOnce 首先，hvd.init() 会通过一系列的调用和配置最终调用 horovod/common/http://operations.cc 下的 InitializeHorovodOnce 函数，这个函数会根据加载的集合通讯库（mpi 或者 gloo）为 globalstate 创建对应的 controller，然后使用 BackgroundThreadLoop 启动一个后台线程。 horovod/common/http://operations.cc #628 void InitializeHorovodOnce(const int* ranks, int nranks) { // ... some envParse #if HAVE_MPI // Enable mpi is it's used either i[n cpu data transfer or controller if (horovod_global.cpu_operation == LibType::MPI || horovod_global.control_operation == LibType::MPI) { mpi_context.Enable(); } // 创建一个 MPIController 对象 if (horovod_global.control_operation == LibType::MPI){ horovod_global.controller.reset(new MPIController( horovod_global.response_cache, horovod_global.tensor_queue, horovod_global.timeline, horovod_global.parameter_manager, mpi_context)); horovod_global.controller-\u003eSetRanks(ranks, nranks); } #endif #if HAVE_GLOO //... #endif // Reset initialization flag horovod_global.initialization_done = false; // 启动后台线程 horovod_global.background_thread = std::thread( BackgroundThreadLoop, std::ref(horovod_global)); } while (!horovod_global.initialization_done) { std::this_thread::sleep_for(std::chrono::milliseconds(1)); } } 2.BackgroundThreadLoop BackgroundThreadLoop 会为 GlobalState 初始化一系列包括初始化 mpi_context， controller的元素，然后轮询调用 RunLoopOnce，还有一些对 RunLoopOnce 结束后的后处理。 void BackgroundThreadLoop(HorovodGlobalState\u0026 state) { #if HAVE_MPI // Initialize mpi context auto mpi_ctx_manager = MPIContextManager(); #endif // mpi_context 会根据前端和环境变量传过来的信息，创建 mpi 线程，和一些 mpiOps mpi_context.Initialize(state.controller-\u003eGetRanks(), mpi_ctx_manager); #endif // Initialize controller // 会同步不同 node 的 global_size, local_size, rank, is_coordinator 等信息 state.controller-\u003eInitialize(); // Set background thread affinity parse_and_set_affinity(std::getenv(HOROVOD_THREAD_AFFINITY), local_size, local_rank); #if HAVE_GPU ... // 设置 gpu_context 的 stream 数目等初始化动作 #endif // 下面是设置 parameter_manager 这里为了节省篇幅直接给出，设置的语句， // 原来这里会读取对应的环境变量的，去设置 parameter_manager。 // 后面也会有篇幅介绍 parameter_manager，这里先不展开。 state.parameter_manager.SetTensorFusionThresholdBytes(64 * 1024 * 1024); state.parameter_manager.SetCycleTimeMs(5); state.parameter_manager.SetCacheEnabled(true); state.response_cache.set_capacity( (int)state.parameter_manager.CacheEnabled() * state.cache_capacity); state.parameter_manager.SetHierarchicalAllgather(value, true); state.parameter_manager.SetAutoTuning(true); ... // 其他一些初始化设置 // 设置op_manager，这里主要是注册不同的集合通信库的 ops //（ 如：NCCLAllreduce, MPI_GPUAllgather 等） op_manager.reset(CreateOperationManager(state)); // 初始化完成 state.initialization_done = true; // Iterate until shutdown. try { while (RunLoopOnce(state)); } catch (const std::exception\u0026 ex) { LOG(ERROR) \u003c\u003c \"Horovod background loop uncaught exception: \" \u003c\u003c ex.what(); } ... // 其他一些后处理函数 } 3.Optimizer.step()-\u003eDoAllReduce 这里我们先不急着看 RunLoopOnce 函数，先回到 InitializeHorovodOnce ，因为上面的 initialization_done = True，所以 InitializeHorovodOnce 可以退出了，就是前端的 hvd.init() 可以进行下一步了。这里 main.py 走完前向 loss = model(data,target)，后向逻辑 loss.backward()，调用 optimizer.step() 进行梯度同步。optimizer.step() 会通过一系列的调用和处理（如：compression 等操作）最终会调用 C++ interface 的 DoAllReduce 函数。 DoAllReduce 函数会调用 EnqueueTensorAllreduce 函数会把需要 reduce 的 tensor 组装成一个Request 往 GlobalState 的 tensor_queue 里面塞。这里注意每个 tensor 会创建对应 TensorTableEntry，用于保存tensor 的权重，message 主要是一些 元信息 metadata。然后就等后台线程去读取这些allreduce 的请求了。 Status EnqueueTensorAllreduce(std::shared_ptr\u003cOpContext\u003e context, std::shared_ptr\u003cTensor\u003e tensor, std::shared_ptr\u003cTensor\u003e output, std::shared_ptr\u003cReadyEvent\u003e ready_event, const std::string name, const int device, StatusCallback callback, ReduceOp reduce_op, double prescale_factor, double postscale_factor) { Status status; ... // some config Request message; message.set_request_rank(horovod_global.controller-\u003eGetRank()); message.set_tensor_name(name); message.set_tensor_type(tensor-\u003edtype()); message.set_device(device); message.set_prescale_factor(prescale_factor); messag","date":"2023-07-13","objectID":"/posts/horovod_and_openmpi/:3:2","tags":["Horovod"],"title":"Horovod and Openmpi","uri":"/posts/horovod_and_openmpi/"},{"categories":["Distributed Computing"],"content":"其他关键模块 上面只是介绍了 horovod 主流程工作原理，不过 horovod 还有其他一些模块协同主流程工作的，下面会对其中的一些我认为可以值得一说的模块说一下。 Parameter_manager: Parameter_manager 主要是 GlobalState 的一个用于管理一些调节 horovod 性能的参数的管理器，在 BackgroundThreadLoop 中跟其他的 GlobalState 的元素一同初始化，然后会读取下面这些对应的环境变量，然后进行设置。 HOROVOD_FUSION_THRESHOLD：指传输数据切片的大小，默认是64M，如果切片太大，传输的时候就不能很好地 pipeline 传输，如果太小，一个 tensor 需要传输多次，增加 IO 的 overhead。 HOROVOD_CYCLE_TIME：指 RunLoopOnce 的睡眠时长，默认是 5ms，我自己的猜测（还没进行验证）比较理想的睡眠时间应该是 RunLoopOnce 其余逻辑处理的时间 + HOROVOD_CYCLE_TIME 刚好等于一次前向传播和后向传播所用的时间，因为睡太久前端会在等 RunLoopOnce 睡醒；如果睡太短，不断地跑一次 RunLoopOnce，tensor_queue 也不会有新的元素，只是白跑。 HOROVOD_CACHE_CAPACITY：指 cache 的大小，这个可能跟 model 层数参数量相关了。 HOROVOD_HIERARCHICAL_ALLGATHER：是否使用分层的allgather的方式等 Parameter_manager也提供了对这些参数自动调节的功能。通过Parameter_manager.SetAutoTuning进行设置，设置后会在初始的几个batch尝试不同的参数组合进行通信，后面会收敛到一组最优的参数值。 ","date":"2023-07-13","objectID":"/posts/horovod_and_openmpi/:3:3","tags":["Horovod"],"title":"Horovod and Openmpi","uri":"/posts/horovod_and_openmpi/"},{"categories":["Distributed Computing"],"content":"MPIContext mpi_context 是在加载 C++ 的代码时候就已经创建了，同时创建的还有其他 context（ nccl_context, gpu_context），主要是维护一些节点上 mpi 通信的必要环境信息和设置，如： 3 个 MPI communicator，mpi_comm，local_comm，cross_comm 分别负责 horovod mpi 传输，节点内传输，和节点间分层传输（主要用于 hierarchical allreduce）。 mpi_float16_t: horovod 主要以 float16 传输。 mpi_float16_sum: float16 对应的sum 操作。 在 horovod 使用 mpi 的时候，都会使用上面的 communicator 进行数据传输。 ","date":"2023-07-13","objectID":"/posts/horovod_and_openmpi/:3:4","tags":["Horovod"],"title":"Horovod and Openmpi","uri":"/posts/horovod_and_openmpi/"},{"categories":["Distributed Computing"],"content":"Tensorflow2 TensorFlow2 前端对 horovod 的调用跟 pytorch 类似，只是因为 tensorflow 2 是通过 tape 等级制记录梯度的, 所以会有一些不同。 hvd.init() # Set up standard model. model = getattr(applications, args.model)(weights=None) opt = tf.optimizers.SGD(0.01) data = tf.random.uniform([args.batch_size, 224, 224, 3]) target = tf.random.uniform([args.batch_size, 1], minval=0, maxval=999, dtype=tf.int64) @tf.function def benchmark_step(first_batch): # Horovod: (optional) compression algorithm. compression = hvd.Compression.fp16 if args.fp16_allreduce else hvd.Compression.none # Horovod: use DistributedGradientTape with tf.GradientTape() as tape: probs = model(data, training=True) loss = tf.losses.sparse_categorical_crossentropy(target, probs) # Horovod: add Horovod Distributed GradientTape. tape = hvd.DistributedGradientTape(tape, compression=compression) gradients = tape.gradient(loss, model.trainable_variables) opt.apply_gradients(zip(gradients, model.trainable_variables)) if first_batch: hvd.broadcast_variables(model.variables, root_rank=0) hvd.broadcast_variables(opt.variables(), root_rank=0) for x in range(args.num_iters): benchmark_step(first_batch=False) with tf.GradientTape() as tape这一句会调用 horovod/tensorflow/__init__.py 中_DistributedGradientTape 下 init 函数注册 allreduce 的句柄（handle） 然后调用 gradients = tape.gradient(loss, model.trainable_variables) 会调用一系列的跳转最后会调用 tensorflow/mpi_ops.py 下的 _allreduce ，进而调用 `MPI_LIB.horovod_allreduce MPI_LIB.horovod_allreduce 在 horovod/tensorflow/http://mpi_ops.cc 中被 HorovodAllreduceOp 所注册，根据 TensorFlow 的 ops流程，会调用 ops.ComputeAsync，到这里会跟 pytorch 类似会调用 EnqueueTensorAllreduce 把对应的 tensor 和 ops 送到 GlobalState 的 tensor_queue 中。 class HorovodAllreduceOp : public AsyncOpKernel { public: explicit HorovodAllreduceOp(OpKernelConstruction* context) : AsyncOpKernel(context) { OP_REQUIRES_OK(context, context-\u003eGetAttr(\"reduce_op\", \u0026reduce_op_)); OP_REQUIRES_OK(context, context-\u003eGetAttr(\"prescale_factor\", \u0026prescale_factor_)); OP_REQUIRES_OK(context, context-\u003eGetAttr(\"postscale_factor\", \u0026postscale_factor_)); OP_REQUIRES_OK(context, context-\u003eGetAttr(\"ignore_name_scope\", \u0026ignore_name_scope_)); } void ComputeAsync(OpKernelContext* context, DoneCallback done) override { OP_REQUIRES_OK_ASYNC(context, ConvertStatus(common::CheckInitialized()), done); ... // 一些变量验证，初始化 auto enqueue_result = EnqueueTensorAllreduce( hvd_context, hvd_tensor, hvd_output, ready_event, node_name, device, [context, done](const common::Status\u0026 status) { context-\u003eSetStatus(ConvertStatus(status)); done(); }, reduce_op, (double) prescale_factor_, (double) postscale_factor_); OP_REQUIRES_OK_ASYNC(context, ConvertStatus(enqueue_result), done); } private: int reduce_op_; // Using float since TF does not support double OP attributes float prescale_factor_; float postscale_factor_; bool ignore_name_scope_; }; ","date":"2023-07-13","objectID":"/posts/horovod_and_openmpi/:3:5","tags":["Horovod"],"title":"Horovod and Openmpi","uri":"/posts/horovod_and_openmpi/"},{"categories":["Distributed Computing"],"content":"总结 horovod 的流程分析大概就是这样，没有特别复杂，代码的阅读体验也是比较好的，在主流程的关键函数都有比较清晰的注释。对于第三方开发者来说，horovod 本身已经用了很多提高性能的 tricks，可以 custom 优化的地方不多，一些可以动的参数，也已经提供了autotuning，直接使用就可以得到很好的性能。如果尝试优化，可能要从传输上着手，如 BytePS 会尝试使用不同的网络拓扑引入一些 PS 节点提高带宽等，如果有时间我也会聊一下这个。另外上面的分析也有很多是我自己阅读代码时候的一些思考可能不一定准确，如果有不准确或者模糊的地方，也希望大家可以多多斧正。 References: [1]. https://zhuanlan.zhihu.com/p/332825987 [2]. https://zhuanlan.zhihu.com/p/158584571 [3]. https://zhuanlan.zhihu.com/p/79030485 [4]. https://github.com/zjykzj/pytorch-distributed [5]. MPI教程 https://blog.csdn.net/qq_47058489/article/details/125980505 https://blog.csdn.net/weixin_45385568/article/details/121208161?spm=1001.2101.3001.6650.1\u0026utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1-121208161-blog-87971642.pc_relevant_multi_platform_featuressortv2removedup\u0026depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7Edefault-1-121208161-blog-87971642.pc_relevant_multi_platform_featuressortv2removedup\u0026utm_relevant_index=1 [5.] ubuntu20.04 + docker + horovod Horovod and Distributed Training ","date":"2023-07-13","objectID":"/posts/horovod_and_openmpi/:4:0","tags":["Horovod"],"title":"Horovod and Openmpi","uri":"/posts/horovod_and_openmpi/"},{"categories":["OS"],"content":"进程和线程的区别 ","date":"2023-07-13","objectID":"/posts/os_2/:1:0","tags":["OS"],"title":"Process and Coroutine","uri":"/posts/os_2/"},{"categories":["OS"],"content":"进程、线程、协程的概念 进程： 是并发执行的程序在执行过程中分配和管理资源的基本单位，是一个动态概念，竞争计算机系统资源的基本单位。 线程： 是进程的一个执行单元，是进程内科调度实体。比进程更小的独立运行的基本单位。线程也被称为轻量级进程。 协程： 是一种比线程更加轻量级的存在。一个线程也可以拥有多个协程。其执行过程更类似于子例程，或者说不带返回值的函数调用。 ","date":"2023-07-13","objectID":"/posts/os_2/:1:1","tags":["OS"],"title":"Process and Coroutine","uri":"/posts/os_2/"},{"categories":["OS"],"content":"进程和线程的区别 地址空间： 线程共享本进程的地址空间，而进程之间是独立的地址空间。 资源： 线程共享本进程的资源如内存、I/O、cpu等，不利于资源的管理和保护，而进程之间的资源是独立的，能很好的进行资源管理和保护。 健壮性： 多进程要比多线程健壮，一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都死掉。 执行过程： 每个独立的进程有一个程序运行的入口、顺序执行序列和程序入口，执行开销大。 但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制，执行开销小。 可并发性： 两者均可并发执行。 切换时： 进程切换时，消耗的资源大，效率高。所以涉及到频繁的切换时，使用线程要好于进程。同样如果要求同时进行并且又要共享某些变量的并发操作，只能用线程不能用进程。 其他： 线程是处理器调度的基本单位，但是进程不是。 ","date":"2023-07-13","objectID":"/posts/os_2/:1:2","tags":["OS"],"title":"Process and Coroutine","uri":"/posts/os_2/"},{"categories":["OS"],"content":"协程和线程的区别 协程避免了无意义的调度，由此可以提高性能，但程序员必须自己承担调度的责任。同时，协程也失去了标准线程使用多CPU的能力。 线程（thread） 相对独立 有自己的上下文 切换受系统控制； 协程（coroutine） 相对独立 有自己的上下文 切换由自己控制，由当前协程切换到其他协程由当前协程来控制。 ","date":"2023-07-13","objectID":"/posts/os_2/:1:3","tags":["OS"],"title":"Process and Coroutine","uri":"/posts/os_2/"},{"categories":["OS"],"content":"何时使用多进程，何时使用多线程？ 对资源的管理和保护要求高，不限制开销和效率时，使用多进程。 要求效率高，频繁切换时，资源的保护管理要求不是很高时，使用多线程。 ","date":"2023-07-13","objectID":"/posts/os_2/:1:4","tags":["OS"],"title":"Process and Coroutine","uri":"/posts/os_2/"},{"categories":["OS"],"content":"为什么会有线程？ 每个进程都有自己的地址空间，即进程空间，在网络或多用户换机下，一个服务器通常需要接收大量不确定数量用户的并发请求，为每一个请求都创建一个进程显然行不通（系统开销大响应用户请求效率低），因此操作系统中线程概念被引进。 ","date":"2023-07-13","objectID":"/posts/os_2/:1:5","tags":["OS"],"title":"Process and Coroutine","uri":"/posts/os_2/"},{"categories":["OS"],"content":"*python多线程存在的问题 存在问题： python由于历史遗留的问题，严格说多个线程并不会同时执行（没法有效利用多核处理器，python的并发只是在交替执行不同的代码）。 多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核。所以python的多线程并发并不能充分利用多核，并发没有java的并发严格。 原因： 原因就在于GIL ，在Cpython 解释器（Python语言的主流解释器）中，有一把全局解释锁（GIL, Global Interpreter Lock），在解释器解释执行Python 代码时，任何Python线程执行前，都先要得到这把GIL锁。 这个GIL全局锁实际上把所有线程的执行代码都给上了锁。 这意味着，python在任何时候，只可能有一个线程在执行代码。 其它线程要想获得CPU执行代码指令，就必须先获得这把锁，如果锁被其它线程占用了，那么该线程就只能等待，直到占有该锁的线程释放锁才有执行代码指令的可能。 多个线程一起执行反而更加慢的原因： 同一时刻，只有一个线程在运行，其它线程只能等待，即使是多核CPU，也没办法让多个线程「并行」地同时执行代码，只能是交替执行，因为多线程涉及到上线文切换、锁机制处理（获取锁，释放锁等），所以，多线程执行不快反慢。 什么时候GIL被释放？ 当一个线程遇到I/O 任务时，将释放GIL。 计算密集型（CPU-bound）线程执行100次解释器的计步（ticks）时（计步可粗略看作Python 虚拟机的指令），也会释放GIL。 即，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行。 Python虽然不能利用多线程实现多核任务，但可以通过多进程实现多核任务。多个Python进程有各自独立的GIL锁，互不影响。 参考博客 ","date":"2023-07-13","objectID":"/posts/os_2/:1:6","tags":["OS"],"title":"Process and Coroutine","uri":"/posts/os_2/"},{"categories":["OS"],"content":"*进程的几种通信方式 管道： 速度慢，容量有限，只有父子进程能通讯 FIFO： 任何进程间都能通讯，但速度慢 消息队列： 容量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题 信号量： 不能传递复杂消息，只能用来同步 共享内存区： 能够很容易控制容量，速度快，但要保持同步，比如一个进程在写的时候，另一个进程要注意读写的问题，相当于线程中的线程安全，当然，共享内存区同样可以用作线程间通讯，不过没这个必要，线程间本来就已经共享了同一进程内的一块内存 ","date":"2023-07-13","objectID":"/posts/os_2/:1:7","tags":["OS"],"title":"Process and Coroutine","uri":"/posts/os_2/"},{"categories":["OS"],"content":"*举例说明进程、线程、协程 程序： 例如main.py这是程序，是一个静态的程序。 python进程： 一个程序运行起来后，代码+用到的资源 称之为进程，它是操作系统分配资源的基本单元。 multiprocessing.Process实现多进程 进程池： 如果要启动大量的子进程，可以用进程池的方式批量创建子进程。 multiprocessing.Pool 进程间通信： 各自在独立的地址空间，并不能直接进行全局的数据共享，在创建子进程的时候会将父进程的数据复制到子进程中一份。 进程间通信 Python的multiprocessing模块包装了底层的机制，提供了Queue、Pipes等多种方式来交换数据。 python线程： thread是比较低级,底层的模块，threading是高级模块，对thread进行了封装,可以更加方便的被使用。 python协程： 线程和进程的操作是由程序触发系统接口，最后的执行者是系统；协程的操作则是程序员,当程序中存在大量不需要CPU的操作时（例如 I/O），适用于协程。 例如yield 其中 yield 是python当中的语法。 当协程执行到yield关键字时，会暂停在那一行，等到主线程调用send方法发送了数据，协程才会接到数据继续执行。 但是，yield让协程暂停，和线程的阻塞是有本质区别的。 \u003c/font color=red\u003e协程的暂停完全由程序控制，线程的阻塞状态是由操作系统内核来进行切换。 因此，协程的开销远远小于线程的开销。 最重要的是，协程不是被操作系统内核所管理，而完全是由程序所控制(也就是在用户态执行)。 这样带来的好处就是性能得到了很大的提升，不会像线程切换那样消耗资源。 python可以通过 yield/send 的方式实现协程。在python 3.5以后，async/await 成为了更好的替代方案。 ","date":"2023-07-13","objectID":"/posts/os_2/:1:8","tags":["OS"],"title":"Process and Coroutine","uri":"/posts/os_2/"},{"categories":["OS"],"content":"操作系统(一) ","date":"2023-07-13","objectID":"/posts/os_1/:1:0","tags":["OS"],"title":"计算机操作系统","uri":"/posts/os_1/"},{"categories":["OS"],"content":"1.1 进程和线程的区别？ 进程和线程都是操作系统中进行任务调度的基本单位，二者之间的主要区别如下： 资源占用：进程是操作系统资源分配的基本单位，一个进程可以拥有多个线程，而线程是进程中的执行单元，是CPU调度的基本单位。每个线程共享所属进程的资源，如代码段、数据段、打开的文件等。而进程之间互相独立，互不干扰，每个进程有自己独立的资源空间，不同进程之间需要通过IPC（进程间通信）来进行通信和数据共享。 调度和切换：操作系统在调度和分配CPU时，将进程作为基本的调度和分配单位，即进程拥有自己的调度队列。而线程是依附于进程而存在的，一个进程中的多个线程共享进程的时间片和资源，因此在调度和切换时，线程切换比进程切换更快，也更加轻量级。 创建和销毁：进程的创建和销毁比线程更加复杂，创建一个进程需要为其分配资源、建立PCB（进程控制块）、建立内核对象等，而销毁进程需要回收资源、关闭打开的文件等。而线程的创建和销毁相对简单，只需要为其分配线程栈、建立TCB（线程控制块）等即可。 通信和同步：进程之间通过IPC（管道、套接字、消息队列等）进行通信和数据共享，而线程之间可以直接访问同一进程的共享数据区，也可以通过锁机制实现同步。 综上所述，进程和线程在资源占用、调度和切换、创建和销毁、通信和同步等方面有着不同的特点，开发者在实际编程时需要根据具体的情况选择使用进程还是线程来完成任务。 ","date":"2023-07-13","objectID":"/posts/os_1/:1:1","tags":["OS"],"title":"计算机操作系统","uri":"/posts/os_1/"},{"categories":["OS"],"content":"1.2 协程与线程的区别？ 协程和线程都是用于实现多任务的技术，但是它们的实现方式有所不同，具体区别如下： 调度方式不同：线程由操作系统内核进行调度，而协程则是在用户空间中进行调度，不需要切换到内核态。 并发性不同：线程是操作系统调度的最小单位，多个线程可以并行执行；协程则是在单线程内部通过协作式调度实现并发。 内存使用不同：线程是由操作系统内核创建的，需要占用一定的系统资源，而协程则是由用户程序创建，不需要占用额外的系统资源。 上下文切换开销不同：线程在切换时需要保存和恢复所有的寄存器状态和内核堆栈，而协程只需要保存和恢复少量的寄存器状态，开销较小。 编程难度不同：线程的编程难度相对较大，因为多线程之间需要共享资源并进行同步，而协程则是在单线程内部调度，因此编程难度相对较小。 总之，线程是操作系统内核的调度对象，具有独立的系统资源，可以并行执行多个任务；而协程是用户程序的调度对象，不需要占用额外的系统资源，通过协作式调度实现任务之间的切换。 ","date":"2023-07-13","objectID":"/posts/os_1/:1:2","tags":["OS"],"title":"计算机操作系统","uri":"/posts/os_1/"},{"categories":["OS"],"content":"1.3、并发和并行的区别？ 并发和并行都是指同时处理多个任务的方式，但是它们有不同的含义。 并发是指一个处理器同时处理多个任务，这些任务通常是通过在不同的时间间隔内交替进行的，这样在同一时刻可以看到有多个任务在运行。这些任务可以是在同一个程序内的不同线程，也可以是在不同程序之间的交互，例如客户端与服务器之间的通信。 并行是指使用多个处理器同时处理多个任务，这些任务在同一时刻可以看到有多个任务在同时运行。与并发不同的是，并行需要多个处理器或多个计算核心，而并发则可以在单个处理器上执行多个任务。 简单来说，并发是在一个处理器上同时执行多个任务，而并行是在多个处理器或计算核心上同时执行多个任务。 ","date":"2023-07-13","objectID":"/posts/os_1/:1:3","tags":["OS"],"title":"计算机操作系统","uri":"/posts/os_1/"},{"categories":["OS"],"content":"1.4 进程与线程的切换流程？ 进程与线程的切换流程如下： 当前进程或线程执行到阻塞状态（如等待I/O完成）时，触发切换操作。 操作系统内核保存当前进程或线程的上下文（即当前的寄存器值和程序计数器等信息），并将处理器分配给另一个进程或线程。 内核从调度队列中选择另一个进程或线程，并恢复其保存的上下文信息。 处理器开始执行新的进程或线程，从之前保存的状态恢复执行。 在进程切换时，需要将整个进程的上下文信息保存下来，包括进程的虚拟内存、全局变量等，切换时还需要进行内存映射，开销比较大。 在线程切换时，只需要保存当前线程的上下文信息即可，线程共享进程的虚拟内存，切换时不需要进行内存映射，开销较小。 ","date":"2023-07-13","objectID":"/posts/os_1/:1:4","tags":["OS"],"title":"计算机操作系统","uri":"/posts/os_1/"},{"categories":["OS"],"content":"1.5 为什么虚拟地址空间切换比较耗时？ 虚拟地址空间切换的耗时是因为它涉及到了硬件和操作系统的复杂操作。当进程或线程切换时，需要保存当前的程序状态（寄存器值、堆栈指针等）和上下文信息（当前指令位置、程序计数器等）。然后，内核必须选择另一个进程或线程，并将它的状态和上下文信息装入内存，这样才能保证程序能够继续运行。这个过程涉及到多个操作系统的内核和硬件机制，例如上下文切换、内存管理和硬件中断等。 在这个过程中，为了切换到另一个进程或线程，需要保存和恢复大量的状态信息，包括内核上下文和硬件寄存器等。这些操作需要耗费大量的CPU时间和内存带宽，因此切换过程通常是相对比较耗时的。 ref: [1].https://zhuanlan.zhihu.com/p/616080301 ","date":"2023-07-13","objectID":"/posts/os_1/:1:5","tags":["OS"],"title":"计算机操作系统","uri":"/posts/os_1/"},{"categories":["GPU"],"content":"[1] https://blog.csdn.net/Augusdi/article/details/12187291 ","date":"2023-07-12","objectID":"/posts/cuda/:0:0","tags":["CUDA"],"title":"CUDA Introduction","uri":"/posts/cuda/"},{"categories":["GPU"],"content":"CUDA编程 ","date":"2023-07-12","objectID":"/posts/cuda/:1:0","tags":["CUDA"],"title":"CUDA Introduction","uri":"/posts/cuda/"},{"categories":["GPU"],"content":"1.什么是CUDA CUDA(Compute Unified Device Architecture)，统一计算架构，是NVidia推出的并行计算平台。NVidia官方对其的解释是：一个并行计算平台和简单（简洁）地使用图像处理单元（GPU）进行通用计算的编程模型。利用GPU的能力在计算性能上有惊人的提升。 简单地说CUDA是便于程序员利用NVidia GPU进行通用计算的开发环境及工具，目前支持C/C++语言，将来还会支持Fortran语言。 ","date":"2023-07-12","objectID":"/posts/cuda/:1:1","tags":["CUDA"],"title":"CUDA Introduction","uri":"/posts/cuda/"},{"categories":["GPU"],"content":"2.为什么要用到CUDA CPU主频要比GPU高2-3倍左右，但是通常情况下GPU核心的数量要比CPU多2-3个数量级以上。因此GPU的计算能力要远大于CPU，充分发挥GPU的计算能力，可以有成倍的性能提升。 早期利用GPU的计算能力是使用着色器和着色语言（GLSL等）。目前广泛使用的是CUDA和OpenCL。CUDA是针对NVidia GPU硬件设备设计的，而 OpenCL是针对跨平台设计的。因此CUDA可充分发挥NVidia GPU的计算性能。 CUDA可以直接使用C/C++语言来开发GPU程序，省去了程序员重新学一种新语言的麻烦。 ","date":"2023-07-12","objectID":"/posts/cuda/:1:2","tags":["CUDA"],"title":"CUDA Introduction","uri":"/posts/cuda/"},{"categories":["GPU"],"content":"3.CUDA环境搭建 CUDA环境主要分为四点：硬件（GPU设备）、操作系统、C/C++编译器和CUDA工具包。 硬件（GPU设备），必须是支持CUDA的GPU。可到NVidia官网查询支持CUDA的GPU设备，具体地址为：http://www.nvidia.com/object/cuda_home_new.html 。 操作系统，支持Microsoft Windows、Mac OS X和Linux。 C/C++编译器，对不同的操作系统有不同的要求。 CUDA工具包，NVidia提供了不同操作系统对应的CUDA Toolkit，可从https://developer.nvidia.com/cuda-downloads 下载对应的版本。 本文只以Microsoft Windows为例介绍如何搭建CUDA环境。 准备材料： ·一台装有支持CUDA GPU的电脑。 ·Microsoft Windows操作系统（Microsoft Windows XP,Vista,7,or 8 or Windows Server 2003 or 2008）。 ·CUDA工具包（相应操作系统）。下载地址：https://developer.nvidia.com/cuda-downloads ·C/C++编译器：Microsoft Visual Studio 2008 或 2010，或者对应版本的Microsoft Visual C++ Express产品。 安装步骤： ·在装有支持CUDA GPU的电脑上安装Microsoft Windows操作系统（一般情况下都已经完成这步骤）。 ·安装C/C++编译器，可只安装其中的C++编译器部分。 ·安装CUDA工具包。（CUDA工具包中有NVidia GPU的驱动程序，尚未安装的请选择安装。） 安装验证： Windows XP系统：进入 C:\\Documents and Settings\\All Users\\Application Data\\NVIDIA Corporation\\CUDA Samples\\v5.0\\bin\\win32\\Release 目录运行deviceQuery.exe文件。 Windows Vista, Windows 7, Windows 8, Windows Server 2003, and Windows Server 2008系统：进入 C:\\ProgramData\\NVIDIA Corporation\\CUDA Samples\\v5.0\\bin\\win32\\Release 目录运行deviceQuery.exe文件。 如果安装正确，执行deviceQuery.exe文件会得到GPU设备的相应信息。如果没有安装支持CUDA的GPU也会得出GPU的信息，其中CUDA Capability Major/Minor version number信息为9999.9999。 Microsoft Windows上更详细的安装信息请查看：http://docs.nvidia.com/cuda/cuda-getting-started-guide-for-microsoft-windows/index.html 。 Mac OS X的安装：http://docs.nvidia.com/cuda/cuda-getting-started-guide-for-mac-os-x/index.html 。 Linux的安装：http://docs.nvidia.com/cuda/cuda-getting-started-guide-for-linux/index.html 。 ","date":"2023-07-12","objectID":"/posts/cuda/:1:3","tags":["CUDA"],"title":"CUDA Introduction","uri":"/posts/cuda/"},{"categories":["GPU"],"content":"4.第一个CUDA程序 在Microsoft Windows系统上，如果成功搭建了CUDA环境，则在Microsoft Visual Studio中已经集成了CUDA的开发组件。 以下以Windows 7 + Microsoft Visual Studio 2008为例，创建第一个CUDA程序。 打开Microsoft Visual Studio 2008，依次：File-\u003eNew-\u003eProject-\u003eNVIDIA-\u003eCUDA-\u003eCUDA 5.0 Runtime，输入相应的项目名称确定即可。 默认会生成一个kernel.cu文件，内容如下： #include \"cuda_runtime.h\" #include \"device_launch_parameters.h\" #include \u003cstdio.h\u003e void addWithCuda(int *c, const int *a, const int *b, size_t size); __global__ void addKernel(int *c, const int *a, const int *b) { int i = threadIdx.x; c[i] = a[i] + b[i]; } int main() { const int arraySize = 5; const int a[arraySize] = { 1, 2, 3, 4, 5 }; const int b[arraySize] = { 10, 20, 30, 40, 50 }; int c[arraySize] = { 0 }; // Add vectors in parallel. addWithCuda(c, a, b, arraySize); printf(\"{1,2,3,4,5} + {10,20,30,40,50} = {%d,%d,%d,%d,%d}\\n\", c[0], c[1], c[2], c[3], c[4]); // cudaThreadExit must be called before exiting in order for profiling and // tracing tools such as Nsight and Visual Profiler to show complete traces. cudaThreadExit(); return 0; } // Helper function for using CUDA to add vectors in parallel. void addWithCuda(int *c, const int *a, const int *b, size_t size) { int *dev_a = 0; int *dev_b = 0; int *dev_c = 0; // Choose which GPU to run on, change this on a multi-GPU system. cudaSetDevice(0); // Allocate GPU buffers for three vectors (two input, one output) . cudaMalloc((void**)\u0026dev_c, size * sizeof(int)); cudaMalloc((void**)\u0026dev_a, size * sizeof(int)); cudaMalloc((void**)\u0026dev_b, size * sizeof(int)); // Copy input vectors from host memory to GPU buffers. cudaMemcpy(dev_a, a, size * sizeof(int), cudaMemcpyHostToDevice); cudaMemcpy(dev_b, b, size * sizeof(int), cudaMemcpyHostToDevice); // Launch a kernel on the GPU with one thread for each element. addKernel\u003c\u003c\u003c1, size\u003e\u003e\u003e(dev_c, dev_a, dev_b); // cudaThreadSynchronize waits for the kernel to finish, and returns // any errors encountered during the launch. cudaThreadSynchronize(); // Copy output vector from GPU buffer to host memory. cudaMemcpy(c, dev_c, size * sizeof(int), cudaMemcpyDeviceToHost); cudaFree(dev_c); cudaFree(dev_a); cudaFree(dev_b); } 代码1 这是一个将两个一维数组相加的例子。 其中addKernel是内核函数，它的计算过程是在GPU上实现的，用函数类型限定符__global__限制，且函数类型为void型。 cuda_runtime.h头文件包括了运行时API和其参数的定义。（如果使用驱动API则使用cuda.h头文件）。 device_launch_parameters.h头文件包含了内核函数的5个变量threadIdx、blockDim、blockIdx、gridDim和wrapSize。 对其中CUDA运行时API函数的解释： cudaSetDevice()：选择设备（GPU）。（可以不使用，不使用的情况下，默认选择设备0） cudaMalloc()：动态分配显存。 cudaMemcpy()：设备与主机之内的数据拷贝。 cudaThreadSynchronize()：同步所有设备上的线程，等待所有线程结束。 cudaFree():释放由cudaMalloc分配的显存。 cudaThreadExit():结束CUDA上下文环境，释放其中的资源。 这些函数的具体介绍在 http://docs.nvidia.com/cuda/cuda-runtime-api/index.html 中。 ","date":"2023-07-12","objectID":"/posts/cuda/:1:4","tags":["CUDA"],"title":"CUDA Introduction","uri":"/posts/cuda/"},{"categories":["GPU"],"content":"5. CUDA编程 5.1. 基本概念 CUDA编程中需要注意一些基本概念，分别为：主机(host)、设备(device)、运行时API、驱动API、warp、bank、函数类型限定符、变量类型限定符、thread、block、grid、计算能力、SIMT、内置变量、纹理、CUDA数组等。 主机(host)：可理解为CPU与内存的组合。 设备(device)：可理解为GPU与显存的组合。 运行时API：是指CUDA运行时API是在驱动API的基础上封装而成的，简化了CUDA的开发。 驱动API：是指CUDA驱动API，相比运行时API更接近于设备，可灵活运用设备的特性开发CUDA，可实现运行时API无法实现的功能。 warp：多处理器激活、管理、调度和执行并行任务的单位。计算能力2.x的设备warp为32个线程。未来的设备可能不同，可以通过内置变量warpSize查询。 bank：为了获得较高的存储器带宽，共享存储器被划分为多个大小相等的存储器模块，称为存储体，这些存储体就叫bank，可同步访问。 函数类型限定符：是CUDA C中特有的，用来修饰是主机函数，设备调用的设备函数，还是主机调用的设备函数。有__device__、global、host。 变量类型限定符：是用来修饰设备变量的。有__device__、constant、shared。 thread：设备中的线程，与主机中的线程是同一个概念。 block：线程块，由一组线程组成。一个线程块中的所以线程会在同一个多处理器上执行，一个多处理器上可同时执行多个线程块。 grid：有所有线程块组成的网格。 计算能力：是NVidia GPU不同架构的计算能力。 SIMT：单指令多线程，与单指令多数据（SIMD）类似。一条指令多个线程一同执行，实现程序的并行化。 内置变量：有threadIdx、blockDim、blockIdx、gridDim、warpSize。其中threadIdx指此线程在线程块中的位置；blockDim指线程块维度；blockIdx指该线程块在网格中的位置；gridDim指线程块网格维度；warpSize指一个warp多少个线程。 纹理：本文主要涉及到的是纹理参考、纹理绑定、纹理获取。 CUDA数组：区别于线性存储器，对数据进行了对齐等的处理，包括一维、二维和三维。其中的数据为：一元、二元或四元组。 CUDA编程模型基础 在给出CUDA的编程实例之前，这里先对CUDA编程模型中的一些概念及基础知识做个简单介绍。CUDA编程模型是一个异构模型，需要CPU和GPU协同工作。在CUDA中，host和device是两个重要的概念，我们用host指代CPU及其内存，而用device指代GPU及其内存。CUDA程序中既包含host程序，又包含device程序，它们分别在CPU和GPU上运行。同时，host与device之间可以进行通信，这样它们之间可以进行数据拷贝。典型的CUDA程序的执行流程如下： 分配host内存，并进行数据初始化；分配device内存，并从host将数据拷贝到device上；调用CUDA的核函数在device上完成指定的运算；将device上的运算结果拷贝到host上；释放device和host上分配的内存。 上面流程中最重要的一个过程是调用CUDA的核函数来执行并行计算，kernel是CUDA中一个重要的概念，kernel是在device上线程中并行执行的函数，核函数用__global__符号声明，在调用时需要用«\u003cgrid, block»\u003e来指定kernel要执行的线程数量，在CUDA中，每一个线程都要执行核函数，并且每个线程会分配一个唯一的线程号thread ID，这个ID值可以通过核函数的内置变量threadIdx来获得。 由于GPU实际上是异构模型，所以需要区分host和device上的代码，在CUDA中是通过函数类型限定词开区别host和device上的函数，主要的三个函数类型限定词如下： __global__：在device上执行，从host中调用（一些特定的GPU也可以从device上调用），返回类型必须是void，不支持可变参数参数，不能成为类成员函数。注意用__global__定义的kernel是异步的，这意味着host不会等待kernel执行完就执行下一步。__device__：在device上执行，单仅可以从device中调用，不可以和__global__同时用。__host__：在host上执行，仅可以从host上调用，一般省略不写，不可以和__global__同时用，但可和__device__，此时函数会在device和host都编译。 要深刻理解kernel，必须要对kernel的线程层次结构有一个清晰的认识。首先GPU上很多并行化的轻量级线程。kernel在device上执行时实际上是启动很多线程，一个kernel所启动的所有线程称为一个网格（grid），同一个网格上的线程共享相同的全局内存空间，grid是线程结构的第一层次，而网格又可以分为很多线程块（block），一个线程块里面包含很多线程，这是第二个层次。线程两层组织结构如下图所示，这是一个gird和block均为2-dim的线程组织。grid和block都是定义为dim3类型的变量，dim3可以看成是包含三个无符号整数（x，y，z）成员的结构体变量，在定义时，缺省值初始化为1。因此grid和block可以灵活地定义为1-dim，2-dim以及3-dim结构，对于图中结构（主要水平方向为x轴），定义的grid和block如下所示，kernel在调用时也必须通过执行配置«\u003cgrid, block»\u003e来指定kernel所使用的线程数及结构。 所以，一个线程需要两个内置的坐标变量（blockIdx，threadIdx）来唯一标识，它们都是dim3类型变量，其中blockIdx指明线程所在grid中的位置，而threaIdx指明线程所在block中的位置，如图中的Thread (1,1)满足： threadIdx.x = 1 threadIdx.y = 1 blockIdx.x = 1 blockIdx.y = 1 一个线程块上的线程是放在同一个流式多处理器（SM)上的，但是单个SM的资源有限，这导致线程块中的线程数是有限制的，现代GPUs的线程块可支持的线程数可达1024个。有时候，我们要知道一个线程在blcok中的全局ID，此时就必须还要知道block的组织结构，这是通过线程的内置变量blockDim来获得。它获取线程块各个维度的大小。对于一个2-dim的block ，线程 的ID值为 ，如果是3-dim的block ，线程 的ID值为 。另外线程还有内置变量gridDim，用于获得网格块各个维度的大小。 kernel的这种线程组织结构天然适合vector,matrix等运算，如我们将利用上图2-dim结构实现两个矩阵的加法，每个线程负责处理每个位置的两个元素相加，代码如下所示。线程块大小为(16, 16)，然后将N*N大小的矩阵均分为不同的线程块来执行加法运算。 此外这里简单介绍一下CUDA的内存模型，如下图所示。可以看到，每个线程有自己的私有本地内存（Local Memory），而每个线程块有包含共享内存（Shared Memory）,可以被线程块中所有线程共享，其生命周期与线程块一致。此外，所有的线程都可以访问全局内存（Global Memory）。还可以访问一些只读内存块：常量内存（Constant Memory）和纹理内存（Texture Memory）。内存结构涉及到程序优化，这里不深入探讨它们。 还有重要一点，你需要对GPU的硬件实现有一个基本的认识。上面说到了kernel的线程组织层次，那么一个kernel实际上会启动很多线程，这些线程是逻辑上并行的，但是在物理层却并不一定。这其实和CPU的多线程有类似之处，多线程如果没有多核支持，在物理层也是无法实现并行的。但是好在GPU存在很多CUDA核心，充分利用CUDA核心可以充分发挥GPU的并行计算能力。GPU硬件的一个核心组件是SM，前面已经说过，SM是英文名是 Streaming Multiprocessor，翻译过来就是流式多处理器。SM的核心组件包括CUDA核心，共享内存，寄存器等，SM可以并发地执行数百个线程，并发能力就取决于SM所拥有的资源数。当一个kernel被执行时，它的gird中的线程块被分配到SM上，一个线程块只能在一个SM上被调度。SM一般可以调度多个线程块，这要看SM本身的能力。那么有可能一个kernel的各个线程块被分配多个SM，所以grid只是逻辑层，而SM才是执行的物理层。SM采用的是SIMT (Single-Instruction, Multiple-Thread，单指令多线程)架构，基本的执行单元是线程束（warps)，线程束包含32个线程，这些线程同时执行相同的指令，但是每个线程都包含自己的指令地址计数器和寄存器状态，也有自己独立的执行路径。所以尽管线程束中的线程同时从同一程序地址执行，但是可能具有不同的行为，比如遇到了分支结构，一些线程可能进入这个分支，但是另外一些有可能不执行，它们只能死等，因为GPU规定线程束中所有线程在同一周期执行相同的指令，线程束分化会导致性能下降。当线程块被划分到某个SM上时，它将进一步划分为多个线程束，因为这才是SM的基本执行单元，但是一个SM同时并发的线程束数是有限的。这是因为资源限制，SM要为每个线程块分配共享内存，而也要为每个线程束中的线程分配独立的寄存器。","date":"2023-07-12","objectID":"/posts/cuda/:1:5","tags":["CUDA"],"title":"CUDA Introduction","uri":"/posts/cuda/"},{"categories":["GPU"],"content":"5.3. 存储器层次结构 CUDA存储器有：寄存器(register)、共享存储器(shared memory)、常量存储器(constant memory)、本地存储器(local memory)、全局存储器(global memory)、纹理存储器等。其中寄存器和本地存储器是线程(thread)私有的，共享存储器是对线程块(block)中的所有线程可见，常量存储器、全局存储器和纹理存储器是对网格(grid)中所有线程可见。 下图解释了存储器的层次结构： 5.4. 运行时API 运用运行时API开发CUDA程序需要了解：初始化、设备管理、存储器管理、流管理、事件管理、纹理参考管理、OpenGL互操作和Direct3D互操作。 运行时API文档地址为：http://docs.nvidia.com/cuda/cuda-runtime-api/index.html 。 5.4.1. 初始化 运行时API不存在显示初始化函数，初始化会在首次调用运行时函数时完成。虽然不需要调用初始化函数进行初始化，但是退出时需要调用退出函数cudaThreadExit()释放资源。 5.4.2. 设备管理 有些电脑上可能有多块设备，因此对于不同的要求选择合适的设备。设备管理主要是获取设备信息和选择执行设备。 主要有三个函数： ·cudaGetDeviceCount()：得到电脑上设备的个数。 ·cudaGetDeviceProperties()：获得对应设备的信息。 ·cudaSetDevice()：设置CUDA上下文对应的设备。 运行__global__函数前需要提前选择设备，如果不调用cudaSetDevice()函数，则默认使用0号设备。 上面三个函数的具体用法请查看CUDA运行时API文档。 5.4.3. 存储器管理 共享存储器、常量存储器、线性存储器和CUDA数组的使用是存储器管理的主要部分。 5.4.3.1 共享存储器 共享存储器，使用__shared__变量限定符修饰，可静态或动态分配共享存储器。 代码一： 静态分配共享存储器，是在设备代码中直接分配共享存储器的大小，如下代码： #define SHARED_MEM 16 __global__ void kernel(…) { __shared__ int shared[SHARED_MEM]; } void main() { kernel\u003c\u003c\u003cnBlock, nThread\u003e\u003e\u003e(…); } 代码2 动态分配共享存储器，是在主机代码中使用内核函数的第三个特定参数传入分配共享存储器的大小，如下代码： #define SHARED_MEM 16 __global__ void kernel(…) { extern __shared__ int shared[]; } void main() { int nSharedMem = (int)SHARED_MEM; kernel\u003c\u003c\u003cnBlock, nThread, nSharedMem*sizeof(int)\u003e\u003e\u003e(…); } 5.4.3.2. 常量存储器 常量存储器，使用__constant__变量限定符修饰。使用常量存储器，是由于其在设备上有片上缓存，比全局存储器读取效率高很多。 使用常量存储器时会涉及的运行时API函数主要有： ·cudaMemcpyToSymbol() ·cudaMemcpyFromSymbol() ·cudaGetSymbolAddress() ·cudaGetSymbolSize() 主机代码中使用cudaGetSymbolAddress()获取__constant__或__device__定义的变量地址。设备代码中可通过提取__device__、__shared__或__constant__变量的指针获取变量地址。 5.4.3.3. 线性存储器 线性存储器是使用cudaMalloc()、cudaMallocPitch()或cudaMalloc3D()分配的，使用cudaFree()释放。二维的时候建议使用cudaMallocPitch()分配，cudaMallocPitch()函数对对齐进行了调整。这三个分配函数对应cudaMemset()、cudaMemset2D()、cudaMemset3D()三个memset函数和cudaMemcpy()、cudaMemcpy2D()、cudaMemcpy3D()三个memcpy函数。 5.4.3.4. CUDA数组 CUDA数组是使用cudaMallocArray()、cudaMalloc3DArray()分配的，使用cudaFreeArray()释放。 相关memcpy函数请查阅CUDA运行时API文档。 具体使用可查阅CUDA编程指南：http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html 。 5.4.4. 流管理 主机设备之间的内存拷贝与内核在设备上执行是异步的。在不使用流的情况下，是这样执行的：设备先从主机上拷贝内存，拷贝完成之后，再在设备上执行内核代码计算，最后当内核执行完毕，再把设备上的内存拷贝到主机上。当使用两个流的情况下，0号流执行内核代码的同时1号流拷贝主机内存到设备，1号流执行的同时0号流拷贝设备内存到主机（具体的实现并不一定如此，这里是为了说明流的作用简单做了假设）。两个流的情况下，部分内存拷贝和内置执行是同时进行的（异步的），比同步的内存拷贝和内核执行节省了时间。 与流有关的函数有： ·cudaStreamCreate()：流的创建； ·cudaStreamDestroy()：流的销毁； ·cudaStreamSynchronize()：流同步； ·*Async：与流相关的其他函数。 内核\u003c\u003c\u003c…\u003e\u003e\u003e的第四个参数为哪个流。 CUDA编程指南中有对流具体实现的讲解。 https://blog.csdn.net/a925907195/article/details/39500915 ","date":"2023-07-12","objectID":"/posts/cuda/:1:6","tags":["CUDA"],"title":"CUDA Introduction","uri":"/posts/cuda/"},{"categories":["GPU"],"content":"第5章 共享内存和常量内存 了解数据在共享内存中是如何被安排的 掌握从二维共享内存到线性全局内存的索引转换 解决不同访问模式中存储体中的冲突 在共享内存中缓存数据以减少对全局内存的访问 使用共享内存避免非合并全局内存的访问 理解常量缓存和只读缓存之间的差异 使用线程束洗牌指令编程 ","date":"2023-07-12","objectID":"/posts/cuda_05/:1:0","tags":["CUDA"],"title":"CUDA_C_NOTES [5]","uri":"/posts/cuda_05/"},{"categories":["GPU"],"content":"5.1 CUDA共享内存概述 GPU中有两种类型的内存: 板载内存: 全局内存是较大的板载内存，具有相对较高的延迟。 片上内存: 共享内存是较小的片上内存，具有相对较低的延迟，并且共享内存可以提供比全局内存高得多的带宽 共享内存通常的用途有: 块内线程通信的通道 用于全局内存数据的可编程管理的缓存 高速暂存存储器，用于转换数据以优化全局内存访问模式 5.1.1 共享内存 共享内存（shared memory，SMEM）是GPU的一个关键部件。物理上，每个SM都有一个小的低延迟内存池，这个内存池被当前正在该SM上执行的线程块中的所有线程所共享。(共享内存就是SM上的一块低延迟内存池) 共享内存使同一个线程块中的线程能够互相协作，便于重用片上数据，并可以大大降低核函数所需的全局内存带宽。由于共享内存中的内容是由应用程序显式管理的，所以它通常被描述为可编程管理的缓存。 当每个线程块开始执行时，会分配给它一定数量的共享内存。这个共享内存的地址空间被线程块中所有的线程共享。它的内容和创建时所在的线程块具有相同生命周期。每个线程束发出共享内存访问请求。在理想的情况下，每个被线程束共享内存访问的请求在一个事务中完成。最坏的情况下，每个共享内存的请求在32个不同的事务中顺序执行。如果多个线程访问共享内存中的同一个字，一个线程读取该字后，通过多播把它发送给其他线程。 共享内存被SM中的所有常驻线程块划分，因此，共享内存是限制设备并行性的关键资源。一个核函数使用的共享内存越多，处于并发活跃状态的线程块就越少。 可编程管理的缓存 共享内存是一个可编程管理的缓存。当数据移动到共享内存中以及数据被释放时,我们对它有充分的控制权。由于在CUDA中允许手动管理共享内存,所以通过在数据布局上提供更多的细粒度控制和改善片上数据的移动,使得对应用程序代码进行优化变得更简单了 5.1.2 共享内存分配 有多种方法可以用来分配或声明由应用程序请求所决定的共享内存变量。可以静态或动态地分配共享内存变量。在CUDA的源代码文件中,共享内存可以被声明为一个本地的CUDA核函数或是一个全局的CUDA核函数。CUDA支持一维、二维和三维共享内存数组的声明。 共享内存变量用下列修饰符进行声明: __shared__ 如果在核函数中进行声明,那么这个变量的作用域就局限在该内核中。如果在文件的任何核函数外进行声明,那么这个变量的作用域对所有核函数来说都是全局的。 ","date":"2023-07-12","objectID":"/posts/cuda_05/:1:1","tags":["CUDA"],"title":"CUDA_C_NOTES [5]","uri":"/posts/cuda_05/"},{"categories":["GPU"],"content":"CH04 全局内存 ","date":"2023-07-12","objectID":"/posts/cuda_04/:1:0","tags":["CUDA"],"title":"CUDA_C_NOTES [4]","uri":"/posts/cuda_04/"},{"categories":["GPU"],"content":"4.1 CUDA内存模型概述 在现有的硬件存储子系统下， 必须依靠内存模型获得最佳的延迟和带宽。 CUDA内存模结合了主机和设备的内存系统， 展现了完整的内存层次结构， 使你能显式地控制数据布以优化性能.s 4.1.1 内存层次结构的优点 两种不同类型的局部性: 时间局部性：时间局部性认为如果一个数据位置被引用， 那么该数据在较短的间周期内很可能会再次被引用， 随着时间流逝， 该数据被引用的可能性逐渐降低 空间局部性：空间局部性认为如果一个内存位置被引用， 则附近的位置也可能会被引用 现代计算机使用不断改进的低延迟低容量的内存层次结构来优化性能。 这种内存层次结构仅在支持局部性原则的情况下有效。 一个内存层次结构由具有不同延迟、 带宽容量的多级内存组成。 通常， 随着从处理器到内存延迟的增加， 内存的容量也在增加。 CPU和GPU的主存都采用的是DRAM（动态随机存取存储器），而低延迟内存（如CPU一级缓存）使用的则是SRAM（静态随机存取存储器）。内存层次结构中最大且最慢的级别通常使用磁盘或闪存驱动来实现。在这种内存层次结构中，当数据被处理器频繁使用时，该数据保存在低延迟、低容量的存储器中；而当该数据被存储起来以备后用时，数据就存储在高延迟、大容量的存储器中。这种内存层次结构符合大内存低延迟的设想。 GPU和CPU内存模型的主要区别是， CUDA编程模型能将内存层次结构更好地呈现给用户， 能让我们显式地控制它的行为. 4.1.2 CUDA内存模型 对于程序员来说， 一般有两种类型的存储器： 可编程的： 你需要显式地控制哪些数据存放在可编程内存中 不可编程的： 你不能决定数据的存放位置， 程序将自动生成存放位置以获得好的性能 在CPU内存层次结构中， 一级缓存和二级缓存都是不可编程的存储器。 CUDA内存模型提出了多种可编程内存的类型: 寄存器 (register) 共享内存 (shared memory) 本地内存 (local memory) 常量内存（constant memory） 纹理内存 () 全局内存(global memory) 一个核函数中的线程都有自己私有的本地内存。 一个线程块有自己的共享内存， 对同一线程块中所有线程都可见， 其内容持续线程块的整个生命周期。 所有线程都可以访问全局内存。 所有线程都能访问的只读内存空间有： 常量内存空间和纹理内存空间。 \u003e 全局内存、 常量内存和纹理内存空间有不同的用途。 纹理内存为各种数据布局提供了不同的寻址模式和滤波模式。 对于一个应用程序来说， 全局内存、 常量内存和纹理内存中的内容具有相同的生命周期. 4.1.2.1 寄存器 寄存器是GPU上运行速度最快的内存空间。 核函数中声明的一个没有其他修饰符的自变量， 通常存储在寄存器中。 在核函数声明的数组中， 如果用于引用该数组的索引是常量且能在编译时确定， 那么该数组也存储在寄存器中。 寄存器变量对于每个线程来说都是私有的， 一个核函数通常使用寄存器来保存需要频 繁访问的线程私有变量。 寄存器变量与核函数的生命周期相同。 一旦核函数执行完毕， 就不能对寄存器变量进行访问了。 寄存器是一个在SM中由活跃线程束划分出的较少资源: 在Fermi架构中，每个线程最多有63个寄存器； 在Kepler架构中，每个线程最多有255个寄存器； 在核函数中使用较少的寄存器将使在SM上有更多的常驻线程块。 每个SM上并发线程块越多，使用率和性能就越高 如果一个核函数使用了超过硬件限制数量的寄存器， 则会用本地内存替代多占用的寄 存器。 4.1.2.2 本地内存（local memory） 编译器可能存放到本地内存中的变量有： 在编译时使用未知索引引用的本地数组 可能会占用大量寄存器空间的较大本地结构体或数组 任何不满足核函数寄存器限定条件的变量 “本地内存”这一名词是有歧义的： 溢出到本地内存中的变量本质上与全局内存在同一 块存储区域， 因此本地内存访问的特点是高延迟和低带宽， 并且如在本章后面的4.3节中所描述的那样， 本地内存访问符合高效内存访问要求. 4.1.2.3 共享内存 在核函数中使用如下修饰符修饰的变量存放在共享内存中： __shared__ 因为共享内存是片上内存， 所以与本地内存或全局内存相比， 它具有更高的带宽和更 低的延迟。 它的使用类似于CPU一级缓存， 但它是可编程的。 每一个SM都有一定数量的由线程块分配的共享内存。 因此， 必须非常小心不要过度使用共享内存， 否则将在不经意间限制活跃线程束的数量。 共享内存在核函数的范围内声明， 其生命周期伴随着整个线程块。 当一个线程块执行结束后， 其分配的共享内存将被释放并重新分配给其他线程块。 共享内存是线程之间相互通信的基本方式。 一个块内的线程通过使用共享内存中的数 据可以相互合作。 访问共享内存必须同步使用如下调用， 该命令是在之前章节中介绍过的CUDA运行时调用： void __syncthreads(); 该函数设立了一个执行障碍点， 即同一个线程块中的所有线程必须在其他线程被允许 执行前达到该处。 为线程块里所有线程设立障碍点， 这样可以避免潜在的数据冲突。 SM中的一级缓存和共享内存都使用64KB的片上内存， 它通过静态划分， 但在运行时 可以通过如下指令进行动态配置： cudaError_t cudaFuncSetCacheConfig(const void* func, enum cadaFuncCache cacheConfig) 4.1.2.4 常量内存 常量内存驻留在设备内存中， 并在每个SM专用的常量缓存中缓存。 常量变量用如下 修饰符来修饰: __constant__ 常量变量必须在全局空间内和所有核函数之外进行声明。 对于所有计算能力的设备， 都只可以声明64KB的常量内存。 常量内存是静态声明的， 并对同一编译单元中的所有核函数可见。 核函数只能从常量内存中读取数据。（不能往常量内存中写数据） 因此， 常量内存必须在主机端使用下面的函数来 初始化： cudaError_t cudaMemoryToSymbol(const void* symbol, const void* src, size_t count) 这个函数将count个字节从src指向的内存复制到symbol指向的内存中， 这个变量存放在设备的全局内存或常量内存中。 线程束中的所有线程从相同的内存地址中读取数据时， 常量内存表现最好。 举个例子， 数学公式中的系数就是一个很好的使用常量内存的例子， 因为一个线程束中所有的线程使用相同的系数来对不同数据进行相同的计算。 如果线程束里每个线程都从不同的地址空间读取数据， 并且只读一次， 那么常量内存中就不是最佳选择， 因为每从一个常量内存中读取一次数据， 都会广播给线程束里的所有线程。 4.1.2.5 纹理内存 纹理内存是一种通过指定的只读缓存访问的全局内存。 只读缓存包括硬件滤波的支持， 它可以将浮点插入作为读过程的一部分来执行。 纹理内存是对二维空间局部性的优化， 所以线程束里使用纹理内存访问二维数据的线程可以达到最优性能。 4.1.2.6 全局内存 全局内存是GPU中最大、 延迟最高并且最常使用的内存。 global指的是其作用域和生命周期。 它的声明可以在任何SM设备上被访问到， 并且贯穿应用程序的整个生命周期。 一个全局内存变量可以被静态声明或动态声明。 你可以使用如下修饰符在设备代码中 静态地声明一个变量： __device__ 在第2章的2.1节中， 你已经学习了如何动态分配全局内存。 在主机端使用cuda-Malloc 函数分配全局内存， 使用cudaFree函数释放全局内存。 然后指向全局内存的指针就会作为 参数传递给核函数。 全局内存分配空间存在于应用程序的整个生命周期中， 并且可以访问 所有核函数中的所有线程。 从多个线程访问全局内存时必须注意。 因为线程的执行不能跨 线程块同步， 不同线程块内的多个线程并发地修改全局内存的同一位置可能会出现问题， 这将导致一个未定义的程序行为。 优化内存事务对于获得最优性能来说是至关重要的。 当一个线程束执行内存加载/ 存储时， 需要满足的传输数量通常取决于以下两个因素： 跨线程的内存地址分布 每个事务内存地址的对齐方式 对于一个给定的线程束内存请求， 事务数量和数据吞吐率是由设备的计算能力来确定 的。 对于计算能力为1.0和1.1的设备， 全局内存访问的要求是非常严格的。 对于计算能力高于1.1的设备， 由于内存事务被缓存， 所以要求较为宽松。 缓存的内存事务利用数据局部性来提高数据吞吐率。 4.1.2.7 GPU缓存 跟CPU缓存一样， GPU缓存是不可编程的内存。 在GPU上有4种缓存： 一级缓存 二级缓存 只读常量缓存 只读纹理缓存 每个SM都有一个一级缓存， 所有的SM共享一个二级缓存。 一级和二级缓存都被用来在存储本地内存和全局内存中的数据， 也包括寄存器溢出的部分。对Fermi GPU和Kepler K40或其后发布的GPU来说， CUDA允许我们配置读操作的数据是使用一级和二级缓存，还是只使用二级缓存。 在GPU上只有内存加载操作可以被缓存，内存存储操作不能被缓存。 每个SM也有一个只读常量缓存和只读纹理缓存， 它们用于在设备内存中提高来自于各自内存空间内的读取性能。 4.1.2.8 CUDA变量声明总结 4.1.2.9 静态全局内存 ","date":"2023-07-12","objectID":"/posts/cuda_04/:1:1","tags":["CUDA"],"title":"CUDA_C_NOTES [4]","uri":"/posts/cuda_04/"},{"categories":["GPU"],"content":"4.2 内存管理 CUDA编程的内存管理与C语言的类似， 需要程序员显式地管理主机和设备之间的数 据移动。 随着CUDA版本的升级， NVIDIA正系统地实现主机和设备内存空间的统一， 但对于大多数应用程序来说， 仍需要手动移动数据。 分配和释放设备内存 在主机和设备之间传输数据 4.2.1 内存分配和释放 CUDA编程模型假设了一个包含一个主机和一个设备的异构系统， 每一个异构系统都 有自己独立的内存空间。 核函数在设备内存空间中运行， CUDA运行时提供函数以分配和释放设备内存。 你可以在主机上使用下列函数分配全局内存： cudaError_t cudaMalloc(void **devPrt, size_t count); 这个函数在设备上分配了count字节的全局内存， 并用devptr指针返回该内存的地址。 你需要用从主机上传输的数据来填充所分配的全局内存， 或用下列函数将其初始 化: cudaError_t cudaMemset(void *devPtr, int value, size_t count); 这个函数用存储在变量value中的值来填充从设备内存地址devPtr处开始的count字节。 一旦一个应用程序不再使用已分配的全局内存， 那么可以以下代码释放该内存空间： cudaError_t cudaFree(void *devPtr); 这个函数释放了devPtr指向的全局内存， 该内存必须在此前使用了一个设备分配函数 （如cudaMalloc） 来进行分配。 否则， 它将返回一个错误cudaErrorInvalidDevicePointer。 如果地址空间已经被释放， 那么cudaFree也返回一个错误。 4.2.2 内存传输 一旦分配好了全局内存， 你就可以使用下列函数从主机向设备传输数据： cudaError_t cudaMemory(void *dst, const void *src, size_t count, enum cudaMemcpyKind kind) 这个函数从内存位置src复制了count字节到内存位置dst。 变量kind指定了复制的方向， 可以有下列取值： cudaMemcpyHostToHost cudaMemcpyHostToDevice cudaMemcpyDeviceToHost cudaMemcpyDeviceToDevice CUDA编程的一个基本原则应是尽可能地减少主机与设备之间的传输. 4.2.3 固定内存 分配的主机内存默认是pageable（可分页） ， 它的意思也就是因页面错误导致的操 作， 该操作按照操作系统的要求将主机虚拟内存上的数据移动到不同的物理位置。 虚拟内存给人一种比实际可用内存大得多的假象， 就如同一级缓存好像比实际可用的片上内存大得多一样。 GPU不能在可分页主机内存上安全地访问数据， 因为当主机操作系统在物理位置上移 动该数据时， 它无法控制。 当从可分页主机内存传输数据到设备内存时， CUDA驱动程序首先分配临时页面锁定的或固定的主机内存， 将主机源数据复制到固定内存中， 然后从固定内存传输数据给设备内存， 如图4-4左边部分所示 CUDA运行时允许你使用如下指令直接分配固定主机内存： cudaError_t cudaMallocHost(void **devPtr, size_t count); 这个函数分配了count字节的主机内存， 这些内存是页面锁定的并且对设备来说是可 访问的。 由于固定内存能被设备直接访问， 所以它能用比可分页内存高得多的带宽进行读写。 然而， 分配过多的固定内存可能会降低主机系统的性能， 因为它减少了用于存储虚拟内存数据的可分页内存的数量， 其中分页内存对主机系统是可用的。 主机与设备间的内存传输 与可分页内存相比， 固定内存的分配和释放成本更高， 但是它为大规模数据传输提供 了更高的传输吞吐量 4.2.4 零拷贝内存 通常来说， 主机不能直接访问设备变量， 同时设备也不能直接访问主机变量。 但有一个例外： 零拷贝内存。 主机和设备都可以访问零拷贝内存。 GPU线程可以直接访问零拷贝内存。 在CUDA核函数中使用零拷贝内存有以下几个优 势。 当设备内存不足时可利用主机内存 避免主机和设备间的显式数据传输 提高PCIe传输率 当使用零拷贝内存来共享主机和设备间的数据时， 你必须同步主机和设备间的内存访 问， 同时更改主机和设备的零拷贝内存中的数据将导致不可预知的后果。 零拷贝内存是固定（不可分页） 内存， 该内存映射到设备地址空间中。 你可以通过下列函数创建一个到固定内存的映射： cudaError_t cudaHostAlloc(void **pHost, size_t count, unsigned int flags); 这个函数分配了count字节的主机内存， 该内存是页面锁定的且设备可访问的。 用这 个函数分配的内存必须用cudaFreeHost函数释放。 flags参数可以对已分配内存的特殊属性 进一步进行配置： - cudaHostAllocDefault - cudaHostAllocPortable - cudaHostAllocWriteCombined - cudaHostAllocMapped cudaHostAllocDefault函数使cudaHostAlloc函数的行为与cudaMallocHost函数一致。 设置cudaHostAllocPortable函数可以返回能被所有CUDA上下文使用的固定内存， 而不仅是执 行内存分配的那一个。 标志cudaHostAllocWriteCombined返回写结合内存， 该内存可以在某些系统配置上通过PCIe总线上更快地传输， 但是它在大多数主机上不能被有效地读取。因此， 写结合内存对缓冲区来说是一个很好的选择， 该内存通过设备使用映射的固定内存或主机到设备的传输。 零拷贝内存的最明显的标志是cudaHostAllocMapped， 该标志返回， 可以实现主机写入和设备读取被映射到设备地址空间中的主机内存。 你可以使用下列函数获取映射到固定内存的设备指针： cudaError_t cudaHostGetDevicePointer(void **pDevice, void *pHost, unsigned int flags); 该函数返回了一个在pDevice中的设备指针， 该指针可以在设备上被引用以访问映射得到的固定主机内存。 如果设备不支持映射得到的固定内存， 该函数将失效。 flag将留作以后使用。 现在， 它必须被置为0。 在进行频繁的读写操作时， 使用零拷贝内存作为设备内存的补充将显著降低性能。 因为每一次映射到内存的传输必须经过PCIe总线。 与全局内存相比， 延迟也显著增加。 零拷贝内存 有两种常见的异构计算系统架构： 集成架构和离散架构。 在集成架构中， CPU和GPU集成在一个芯片上， 并且在物理地址上共享主存。 在这种架构中， 由于无须在PCIe总线上备份， 所以零拷贝内存在性能和可编程性方面可能更佳。 对于通过PCIe总线将设备连接到主机的离散系统而言， 零拷贝内存只在特殊情况下有优势。 因为映射的固定内存在主机和设备之间是共享的， 你必须同步内存访问来避免任何潜在的数据冲突， 这种数据冲突一般是由多线程异步访问相同的内存而引起的。 注意不要过度使用零拷贝内存。 由于其延迟较高， 从零拷贝内存中读取设备核函数可能很慢。 4.2.5 统一虚拟寻址 ","date":"2023-07-12","objectID":"/posts/cuda_04/:1:2","tags":["CUDA"],"title":"CUDA_C_NOTES [4]","uri":"/posts/cuda_04/"},{"categories":["GPU"],"content":"CH03 CUDA执行模型 ","date":"2023-07-12","objectID":"/posts/cuda_03/:1:0","tags":["CUDA"],"title":"CUDA_C_NOTES [3]","uri":"/posts/cuda_03/"},{"categories":["GPU"],"content":"3.1 CUDA执行模型概述 CUDA执行模型能够提供有助于在指令吞吐量和内存访问方面编写高效代码的见解 3.1.1 GPU架构概述 GPU架构是围绕一个流式多处理器（SM） (Stream Multiprocessor)的可扩展阵列搭建的,可以通过复制这种架构的构建块来实现GPU的硬件并行 Fermi SM的关键组件： CUDA核心 共享内存/一级缓存 寄存器文件 加载/存储单元 特殊功能单元 线程束调度器 GPU中的每一个SM都能支持数百个线程并发执行， 每个GPU通常有多个SM， 所以在一个GPU上并发执行数千个线程是有可能的。 当启动一个内核网格时， 它的线程块被分布在了可用的SM上来执行。 线程块一旦被调度到一个SM上， 其中的线程只会在那个指定的SM上并发执行。 多个线程块可能会被分配到同一个SM上， 而且是根据SM资源的可用性进行调度的。同一线程中的指令利用指令级并行性进行流水线化， 另外， 在CUDA中已经介绍了线程级并行。 CUDA采用单指令多线程（SIMT）（single instruciton multi thread） 架构来管理和执行线程， 每32个线程为一组， 被称为线程束（warp） 。 线程束中的所有线程同时执行相同的指令。 每个线程都有自己的指令地址计数器和寄存器状态， 利用自身的数据执行当前的指令。 每个SM都将分配给它的线程块划分到包含32个线程的线程束中， 然后在可用的硬件资源上调度执行。 SIMT架构与SIMD（单指令多数据） 架构相似。 两者都是将相同的指令广播给多个执行单元来实现并行。 一个关键的区别是SIMD要求同一个向量中的所有元素要在一个统一的同步组中一起执行， 而SIMT允许属于同一线程束的多个线程独立执行. SIMT确保可以编写独立的线程级并行代码、 标量线程以及用于协调线程的数据并行代码。 SIMT模型包含3个SIMD所不具备的关键特征。 每个线程都有自己的指令地址计数器 每个线程都有自己的寄存器状态 每个线程可以有一个独立的执行路径 一个神奇的数字： 32 从概念上讲， 它是SM用SIMD方式所同时处理的工作粒度。 优化工作负载以适应线程束（一组有32个线程） 的边界， 一般这样会更有效地利用GPU计算资源。 一个线程块只能在一个SM上被调度。 一旦线程块在一个SM上被调度， 就会保存在该SM上直到执行完成。 在同一时间， 一个SM可以容纳多个线程块. 在SM中， 共享内存和寄存器是非常重要的资源。 共享内存被分配在SM上的常驻线程块中， 寄存器在线程中被分配。 尽管线程块里的所有线程都可以逻辑地并行运行， 但是并不是所有线程都可以同时在物理层面执行。 因此， 线程块里的不同线程可能会以不同的速度前进。 在并行线程中共享数据可能会引起竞争： 多个线程使用未定义的顺序访问同一个数据， 从而导致不可预测的程序行为。 CUDA提供了一种用来同步线程块里的线程的方法，从而保证所有线程在进一步动作之前都达到执行过程中的一个特定点。 然而， 没有提供块间同步的原语。 当线程束由于任何理由闲置的时候（如等待从设备内存中读取数值） ， SM可以从同一SM上的常驻线程块中调度其他可用的线程束。 在并发的线程束间切换并没有开销， 因为硬件资源已经被分配到了SM上的所有线程和块中， 所以最新被调度的线程束的状态已经存储在SM上 SM： GPU架构的核心* SM是GPU架构的核心。 寄存器和共享内存是SM中的稀缺资源。 CUDA将这些资源分配到SM中的所有常驻线程里。 这些有限的资源限制了在SM上活跃的线程束数量，活跃的线程束数量对应于SM上的并行量。 了解一些SM硬件组成的基本知识， 有助于组织线程和配置内核执行以获得最佳的性能 3.1.2 Fermi架构 Fermi的特征是多达512个加速器核心， 这被称为CUDA核心。 每个CUDA核心都有一个全流水线的整数算术逻辑单元（ALU） 和一个浮点运算单元（FPU） ， 在这里每个时钟周期执行一个整数或是浮点数指令。 CUDA核心被组织到16个SM中， 每一个SM含有32个CUDA核心。 Fermi架构有6个384位的GDDR5 DRAM存储器接口， 支持多达6GB的全局机载内存， 这是许多应用程序关键的计算资源。 主机接口通过PCIe总线将GPU与CPU相连。 GigaThread引擎（图示左侧第三部分） 是一个全局调度器， 用来分配线程块到SM线程束调度器上。 一个SM(Stream Multiprocessor)包含以下内容： 执行单元（CUDA核心） 调度线程束的调度器和调度单元 共享内存、 寄存器文件和一级缓存 每一个多处理器有16个加载/存储单元（如图3-1所示） ， 允许每个时钟周期内有16个线程（线程束的一半） 计算源地址和目的地址。 特殊功能单元（SFU） 执行固有指令， 如正弦、 余弦、 平方根和插值。 每个SFU每个时钟周期内的每个线程上执行一个固有指令 每个SM有两个线程束调度器和两个指令调度单元。 当一个线程块被指定给一个SM时， 线程块中的所有线程被分成了线程束。 两个线程束调度器选择两个线程束， 再把一个 指令从线程束中发送到一个组上， 组里有16个CUDA核心、 16个加载/存储单元或4个特殊功能单元（如图3-4所示） 。 Fermi架构， 计算性能2.x， 可以在每个SM上同时处理48个线程束， 即可在一个SM上同时常驻1536个线程。 3.1.3 Kepler架构 发布于2012年秋季的Kepler GPU架构是一种快速、 高效、 高性能的计算架构。 Kepler 的特点使得混合计算更容易理解。 图3-6表示了Kepler K20X芯片框图， 它包含了15个SM 和6个64位的内存控制器。 以下是Kepler架构的3个重要的创新。 强化的SM 动态并行 Hyper-Q技术 Kepler K20X的关键部分是有一个新的SM单元， 其包括一些结构的创新， 以提高编程效率和功率效率。 每个Kepler SM单元包含192个单精度CUDA核心， 64个双精度单元， 32个特殊功能单元（SFU） 以及32个加载/存储单元（LD/ST） 3.1.4 配置文件驱动优化 配置文件驱动的发展对于CUDA编程尤为重要， 原因主要有以下几个方面。 一个单纯的内核应用一般不会产生最佳的性能。 性能分析工具能帮助你找到代码中影响性能的关键部分， 也就是性能瓶颈。 CUDA将SM中的计算资源当前SM中的多个常驻线程块之间进行分配。 这种分配形式导致一些资源成为了性能限制者。 性能分析工具能帮助我们理解计算资源是如何被利用的。 CUDA提供了一个硬件架构的抽象， 它能够让用户控制线程并发。 性能分析工具可以检测和优化， 并将优化可视化。 ","date":"2023-07-12","objectID":"/posts/cuda_03/:1:1","tags":["CUDA"],"title":"CUDA_C_NOTES [3]","uri":"/posts/cuda_03/"},{"categories":["GPU"],"content":"3.2 理解线程束执行的本质 本章已经提到了把32个线程划分到一个执行单元中的概念： 线程束（warp）。 现在从硬件的角度来介绍线程束执行， 并能够获得指导内核设计的方法。 3.2.1 线程束和线程块 线程束是SM中基本的执行单元。 当一个线程块的网格被启动后， 网格中的线程块分布在SM中。 一旦线程块被调度到一个SM上， 线程块中的线程会被进一步划分为线程束。 一个线程束由32个连续的线程组成， 在一个线程束中， 所有的线程按照单指令多线程（SIMT） 方式执行； 也就是说， 所有线程都执行相同的指令， 每个线程在私有数据上进 行操作。 一个给定的二维线程块， 在一个块中每个线程的独特标识符都可以用内置变量threadIdx和blockDim来计算： threadIdx.y * blockDim.x + threadIdx.x 对于一个三维线程块， 计算如下： threadIdx.x * blockDim.y * block.Dim.x + threadIdx.y * blockDim.x * threadIdx.x 一个线程块的线程束的数量可以根据下式确定： $$一个线程块中线程束的数量 = 向正无穷取整（\\frac{一个线程块中线程的数量}{线程束大小}）$$ 因此， 硬件总是给一个线程块分配一定数量的线程束。 线程束不会在不同的线程块之间分离。 如果线程块的大小不是线程束大小的偶数倍， 那么在最后的线程束里有些线程就不会活跃。 从逻辑角度来看， 线程块是线程的集合， 它们可以被组织为一维、 二维或三维布局。 从硬件角度来看， 线程块是一维线程束的集合。 在线程块中线程被组织成一维布局，每32个连续线程组成一个线程束。 3.2.2 线程束分化 GPU是相对简单的设备， 它没有复杂的分支预测机制。 一个线程束中的所有线程在同一周期中必须执行相同的指令， 如果一个线程执行一条指令， 那么线程束中的所有线程都必须执行该指令。 如果在同一线程束中的线程使用不同的路径通过同一个应用程序， 这可能会产生问题。 如果一个线程束中的线程产生分化， 线程束将连续执行每一个分支路径， 而禁用不执行这一路径的线程。 线程束分化会导致性能明显地下降。 重要提示: 当一个分化的线程采取不同的代码路径时， 会产生线程束分化 不同的if-then-else分支会连续执行 尝试调整分支粒度以适应线程束大小的倍数， 避免线程束分化 不同的分化可以执行不同的代码且无须以牺牲性能为代价 3.2.3 资源分配 线程束的本地执行上下文主要由以下资源组成： 程序计数器 寄存器 共享内存 由SM处理的每个线程束的执行上下文， 在整个线程束的生存期中是保存在芯片内的。 因此， 从一个执行上下文切换到另一个执行上下文没有损失。 每个SM都有32位的寄存器组， 它存储在寄存器文件中， 并且可以在线程中进行分配， 同时固定数量的共享内存用来在线程块中进行分配。 对于一个给定的内核， 同时存在于同一个SM中的线程块和线程束的数量取决于在SM中可用的且内核所需的寄存器和共享内存的数量。 若每个线程消耗的寄存器越多， 则可以放在一个SM中的线程束就越少。 如果可以减少内核消耗寄存器的数量， 那么就可以同时处理更多的线程束。 若一个线程块消耗的共享内存越多， 则在一个SM中可以被同时处理的线程块就会变少。 如果每个线程块使用的共享内存数量变少， 那么可以同时处理更多的线程块。 当计算资源（如寄存器和共享内存） 已分配给线程块时， 线程块被称为活跃的块。 它所包含的线程束被称为活跃的线程束。 活跃的线程束可以进一步被分为以下3种类型： 选定的线程束 阻塞的线程束 符合条件的线程束 一个SM上的线程束调度器在每个周期都选择活跃的线程束， 然后把它们调度到执行 单元。 活跃执行的线程束被称为选定的线程束。 如果一个活跃的线程束准备执行但尚未执 行， 它是一个符合条件的线程束。 如果一个线程束没有做好执行的准备， 它是一个阻塞的 线程束。 如果同时满足以下两个条件则线程束符合执行条件。 32个CUDA核心可用于执行 当前指令中所有的参数都已就绪 3.2.4 延迟隐藏 SM依赖线程级并行， 以最大化功能单元的利用率， 因此， 利用率与常驻线程束的数量直接相关。 在指令发出和完成之间的时钟周期被定义为指令延迟。 当每个时钟周期中所有的线程调度器都有一个符合条件的线程束时， 可以达到计算资源的完全利用。 这就可以保证， 通过在其他常驻线程束中发布其他指令， 可以隐藏每个指令的延迟。 考虑到指令延迟， 指令可以被分为两种基本类型： 算术指令: 一个算术操作从开始到它产生输出之间的时间； 内存指令: 指发送出的加载或存储操作和数据到达目的地之间的时间。 你可能想知道如何估算隐藏延迟所需要的活跃线程束的数量。 利特尔法则（Little’s Law） 可以提供一个合理的近似值。 它起源于队列理论中的一个定理， 它也可以应用于 GPU中： $$所需线程束数量 = 延迟 \\times 吞吐量$$ 吞吐量和带宽 吞吐量和带宽都是用来度量性能的速度指标。 带宽通常是指理论峰值， 而吞吐量是指已达到的值 带宽通常是用来描述单位时间内最大可能的数据传输量， 而吞吐量是用来描述单位时 间内任何形式的信息或操作的执行速度， 例如， 每个周期完成多少个指令。 吞吐量由SM中每个周期内的操作数量确定， 而执行一条指令的一个线程束对应32个 操作。 这个简单的单位转换表明， 有两种方法可以提高并行： 指令级并行（ILP） ： 一个线程中有很多独立的指令 线程级并行（TLP） ： 很多并发地符合条件的线程 延迟隐藏取决于每个SM中活跃线程束的数量， 这一数量由执行配置和资源约束隐式 决定（一个内核中寄存器和共享内存的使用情况） 。 选择一个最优执行配置的关键是在延 迟隐藏和资源利用之间找到一种平衡。 显示充足的并行 因为GPU在线程间分配计算资源并在并发线程束之间切换的消耗（在一个或两个周期 命令上） 很小， 所以所需的状态可以在芯片内获得。 如果有足够的并发活跃线程， 那么可 以让GPU在每个周期内的每一个流水线阶段中忙碌。 在这种情况下， 一个线程束的延迟可 以被其他线程束的执行隐藏。 因此， 向SM显示足够的并行对性能是有利的 3.2.5 占用率 在每个CUDA核心里指令是顺序执行的。 当一个线程束阻塞时， SM切换执行其他符 合条件的线程束。 理想情况下， 我们想要有足够的线程束占用设备的核心。 占用率是每个 SM中活跃的线程束占最大线程束数量的比值。 $$占用率 = \\frac{活跃线程束数量}{最大线程束数量}$$ 极端地操纵线程块会限制资源的利用： 小线程块： 每个块中线程太少， 会在所有资源被充分利用之前导致硬件达到每个SM的线程束数量的限制 大线程块： 每个块中有太多的线程， 会导致在每个SM中每个线程可用的硬件资源较少 网格和线程块大小的准则 使用这些准则可以使应用程序适用于当前和将来的设备： 保持每个块中线程数量是线程束大小（32） 的倍数 避免块太小： 每个块至少要有128或256个线程 根据内核资源的需求调整块大小 块的数量要远远多于SM的数量， 从而在设备中可以显示有足够的并行 通过实验得到最佳执行配置和资源使用情况 占用率唯一注重的是在每个SM中并发线程或线 程束的数量。 然而， 充分的占用率不是性能优化的唯一目标。 内核一旦达到一定级别的占 用率， 进一步增加占用率可能不会改进性能。 为了提高性能， 可以调整很多其他因素。 3.2.6 同步 在CUDA中， 同步可以在两个级别执行： 系统级： 等待主机和设备完成所有的工作 块级： 在设备执行过程中等待一个线程块中所有线程到达同一点 对于主机来说： cudaError_t cudaDeviceSynchronize(void):cudaDeviceSyn-chronize函数可以用来阻塞主机应用程序， 直到所有的CUDA操作（复制、核函数等） 完成; __device__ void __syncthreads(void);:CUDA提供了一个使用块局部栅栏来同步它们的执行的功能。 当__syncthreads被调用时， 在同一个线程块中每个线程都必须等待直至该线程块中所有其他线程都已经达到这个同步点。 线程块中的线程可以通过共享内存和寄存器来共享数据。 在不同的块之间没有线程同步。 块间同步， 唯一安全的方法是在每个内核执行结束端使用全局同步点； 也就是说， 在全局同步之后， 终止当前的核函数， 开始执行新的核函数。 不同块中的线程不允许相互同步， 因此GPU可以以任意顺序执行块。 这使得CUDA程序在大规模并行GPU上是可扩展的。 3.2.7 可扩展性 对于任何并行应用程序而言， 可扩展性是一个理想的特性。 可扩展性意味着为并行应用程序提供了额外的硬件资源， 相对于增加的资源， 并行应用程序会产生加速。 例如， 若一个CUDA程序在两个SM中是可扩展的， 则与在一个SM中运行相比， 在两个SM中运行会使运行时间减半。 一个可扩展的并行程序可以高效地使用所有的计算资源以提高性能。 可扩展性意味着增加的计算核心可以提高性能。 串行代码本身是不可扩展的， 因为在成千上万的内核上运行一个串行单线程应用程序， 对性能是没有影响的。 并行代码有可扩展的潜能， 但真正的可扩展性取决于算法设计和硬件特性。 ","date":"2023-07-12","objectID":"/posts/cuda_03/:1:2","tags":["CUDA"],"title":"CUDA_C_NOTES [3]","uri":"/posts/cuda_03/"},{"categories":["GPU"],"content":"3.3 并行性的表现 ","date":"2023-07-12","objectID":"/posts/cuda_03/:1:3","tags":["CUDA"],"title":"CUDA_C_NOTES [3]","uri":"/posts/cuda_03/"},{"categories":["GPU"],"content":"3.6 动态并行 在本书中， 到目前为止， 所有核函数都是从主机线程中被调用的。 GPU的工作负载完 全在CPU的控制下。 CUDA的动态并行允许在GPU端直接创建和同步新的GPU内核。 在一 个核函数中在任意点动态增加GPU应用程序的并行性， 是一个令人兴奋的新功能。 ","date":"2023-07-12","objectID":"/posts/cuda_03/:1:4","tags":["CUDA"],"title":"CUDA_C_NOTES [3]","uri":"/posts/cuda_03/"},{"categories":["GPU"],"content":"CH02 CUDA编程模型 ","date":"2023-07-12","objectID":"/posts/cuda_02/:1:0","tags":["CUDA"],"title":"CUDA_C_NOTES [2]","uri":"/posts/cuda_02/"},{"categories":["GPU"],"content":"2.1 CUDA编程模型概述 CUDA编程模型提供了一个计算机架构抽象作为应用程序和其可用硬件之间的桥梁。 CUDA编程模型还利用GPU架构的计算能力提供了以下几个特有功能: 一种通过层次结构在GPU中组织线程的方法(2.3) 一种通过层次结构在GPU中访问内存的方法(4.5) 程序员可以通过以下几个不同层面来看待并行计算: 领域层：如何解析数据和函数，以便在并行环境中正确高效的解决问题（在并行编程中高效的使用pthreads或者OpemMP技术显式地管理线程） 逻辑层：如何组织并发线程 硬件层：理解线程如何映射到核心以帮助提高其性能 ","date":"2023-07-12","objectID":"/posts/cuda_02/:1:1","tags":["CUDA"],"title":"CUDA_C_NOTES [2]","uri":"/posts/cuda_02/"},{"categories":["GPU"],"content":"2.1.1 CUDA编程 在一个异构环境中包含多个CPU和GPU， 每个GPU和CPU的内存都由一条PCI-Express总线分隔开。 主机： CPU及其内存（主机内存） 设备： GPU及其内存（设备内存） “统一寻址”（Unified Memory） 的编程模型的改进， 它连接了主机内存和设备内存空间， 可使用单个指针访问CPU和GPU内存， 无须彼此之间手动拷贝数据。 什么是“统一寻址”（Unified Memory)? CUDA 6.0提出了统一寻址， 使用一个指针来访问CPU和GPU的内存。(详见第4章) 内核（kernel） 是CUDA编程模型的一个重要组成部分， 其代码在GPU上运行。 CUDA编程模型主要是异步的， 因此在GPU上进行的运算可以与主机-设备通信重叠。 一个典型的CUDA程序包 括由并行代码互补的串行代码。 串行代码在cpu上执行，并行代码在GPU上执行。 一个典型的CUDA程序实现流程遵循以下模式： 把数据从CPU内存拷贝到GPU内存； 调用核函数对存储在GPU内存中的数据进行操作； 将数据从GPU内存传送回到CPU内存。 2.1.2 内存管理 CUDA运行时负责分配与释放设备内存， 并且在主机内存和设备内存之间传输数据。 表2-1 主机和设备内存函数 标准c函数 CUDA C函数 标准c函数 CUDA C函数 malloc cudaMalloc memset cudaMemset memcpy cudaMemcpy free cudaFree cudaMalloc函数负责在GPU的内存里分配内存； cudaMemcpy函数负责主机和设备之间的数据传输； cudaError_t cudaMemcpy(void* dst, const void* src, size_t count, cudaMemcpyKind kind) 从src指向的源存储区复制一定数量的字节到dst指向的目标存储区 kind有以下几种: cudaMemcpyHostToHost cudaMemcpyHostToDevice cudaMemcpyDeviceToHost cudaMemcpyDeviceToDevice CUDA编程模型从GPU架构中抽象出一个内存层次结构：全局内存和共享内存。 内存层次结构 全局内存 共享内存 为什么CPU和GPU是异步的？ 当数据被转移到GPU的全局内存后， 主机端调用核函数在GPU上进行数组求和。 一旦内核被调用， 控制权立刻被传回主机， 这样的话， 当核函数在GPU上运行时， 主机可以执行其他函数。 因此， 内核与主机是异步的。 不同的存储空间 2.1.3 线程管理 当核函数在主机端启动时， 它的执行会移动到设备上， 此时设备中会产生大量的线程并且每个线程都执行由核函数指定的语句。 由一个内核启动所产生的所有线程统称为一个网格。 同一网格中的所有线程共享相同的全局内存空间。 一个网格由多个线程块构成， 一个线程块包含一组线程， 同一线程块内的线程协作可以通过以下方式来实现： 同步 共享内存 不同线程块内的线程不能协作。 线程依靠以下两个坐标变量来区分彼此 blockIdx(线程块在线程格内的索引) threadIdx(块内的线程索引) 些变量是核函数中需要预初始化的内置变量。 当执行一个核函数时， CUDA运行时为每个线程分配坐标变量blockIdx和threadIdx。 基于这些坐标， 你可以将部分数据分配给不同的线程。 该坐标变量是基于uint3定义的CUDA内置的向量类型， 是一个包含3个无符号整数的结构， 可以通过x、 y、 z三个字段来指定： blockIdx.x blockIdx.y blockIdx.z threadIdx.x threadIdx.y threadIdx.z CUDA可以组织三维的网格和块. 网格和块的维度由下列两个内置变量指定: blockDim(线程块的维度， 用每个线程块中的线程数来表示) gridDim(线程格的维度， 用每个线程格中的线程数来表示) 它们是dim3类型的变量， 是基于uint3定义的整数型向量， 用来表示维度。 当定义一个dim3类型的变量时， 所有未指定的元素都被初始化为1。 dim3类型变量中的每个组件可以通过它的x、 y、 z字段获得。 如下所示: blockDim.x blockDim.y blockDim.z 网格和线程块的维度 一个线程格会被组织成线程块的二维数组形式， 一个线程块会被组织成线程的三维数组形式 在CUDA程序中有两组不同的网格和块变量： 手动定义的dim3数据类型和预定义的uint3数据类型。 手动定义的dim3类型的网格和块变量仅在主机端可见， 而unit3类型的内置预初始化的网格和块变量仅在设备端可见。 从主机端和设备端访问网格/块变量 区分主机端和设备端的网格和块变量的访问是很重要的。 例如， 声明一个主机端的块变量， 你按如下定义它的坐标并对其进行访问： block.x, block.y, block.z 在设备端， 你已经预定义了内置块变量的大小： blockDim.x, blockDim.y, and blockDim.z 在启动内核之前就定义了主机端的网格和块变量， 并从主机端通过由x、 y、 z三个字段决定的矢量结构来访问它们。 当内核启动时， 可以使用内核中预初始化的内置变量。 总之， 在启动内核之前就定义了主机端的网格和块变量， 并从主机端通过由x、 y、 z三个字段决定的矢量结构来访问它们。 当内核启动时， 可以使用内核中预初始化的内置变量. 对于一个给定的数据大小， 确定网格和块尺寸的一般步骤为： 确定块的大小 在已知数据大小和块大小的基础上计算网格维度 要确定块尺寸， 通常需要考虑： 内核的性能特性 GPU资源的限制 线程层次结构 CUDA的特点之一就是通过编程模型揭示了一个两层的线程层次结构（grid-\u003eblock-\u003ethread）。 由于一个内核 启动的网格和块的维数会影响性能， 这一结构为程序员优化程序提供了一个额外的途径。 2.1.4 启动一个CUDA核函数 CUDA内核调用是对C语言函数调用语句的延伸， «\u003c»\u003e运算符内是核函数的执行配置。 kernel_name \u003c\u003c\u003cgrid, block\u003e\u003e\u003e(argument list) 利用执行配置可以指定线程在GPU上调度运行的方式。 执行配置的第一个值是网格维度， 也就是启动块的数目。 第二个值是块维度， 也就是每个块中线程的数目。 通过指定网格和块的维度， 你可以进行以下 配置： 内核中线程的数目 内核中使用的线程布局 同一个块(block)中的线程之间可以相互协作， 不同块内的线程不能协作。 假设你有32个数据元素用于计算， 每8个元素一个块， 需要启动4个块： kernel_name\u003c\u003c\u003c4, 8\u003e\u003e\u003e(argument list) 由于数据在全局内存中是线性存储的， 因此可以用变量blockIdx.x和threadId.x来进行以下操作。 在网格中标识一个唯一的线程 建立线程和数据元素之间的映射关系 如果把所有32个元素放到一个块里， 那么只会得到一个块: kernel_name\u003c\u003c\u003c1, 32\u003e\u003e\u003e(argument list) 如果每个块只含有一个元素， 那么会有32个块： kernel_name\u003c\u003c\u003c32, 1\u003e\u003e\u003e(argument list) 核函数的调用与主机线程是异步的。 核函数调用结束后， 控制权立刻返回给主机端. 你可以调用以下函数来强制主机端程序等待所有的核函数执行结束： cudaError_t cudaDeivceSynchronize(void); 一些CUDA运行时API在主机和设备之间是隐式同步的。 当使用cudaMemcpy函数在主 机和设备之间拷贝数据时， 主机端隐式同步， 即主机端程序必须等待数据拷贝完成后才能 继续执行程序。 异步行为 不同于C语言的函数调用， 所有的CUDA核函数的启动都是异步的。 CUDA内核调用完成后， 控制权立刻返回给CPU。 2.1.5 编写核函数 核函数是在设备端执行的代码。 用__global__声明定义核函数: __global__ void kernel_name(argument list); 核函数必须有一个void返回类型。 表2-2总结了CUDA C程序中的函数类型限定符 限定符 执行 调用 备注 global device host CUDA核函数的限制 以下限制适用于所有核函数: 只能访问设备内存 必须具有void返回类型 不支持可变数量的参数 不支持静态变量 显示异步行为 ","date":"2023-07-12","objectID":"/posts/cuda_02/:1:2","tags":["CUDA"],"title":"CUDA_C_NOTES [2]","uri":"/posts/cuda_02/"},{"categories":["GPU"],"content":"2.3 组织并行线程 (以阅读为主) 从前面的例子可以看出， 如果使用了合适的网格和块大小来正确地组织线程， 那么可以对内核性能产生很大的影响。 2.3.1 使用块和线程建立矩阵索引 在一个矩阵加法核函数中，一个线程通常被分配一个数据元素来处理。首先要完成的任务是使用块和线程索引从全局内存中访问指定的数据。 ","date":"2023-07-12","objectID":"/posts/cuda_02/:1:3","tags":["CUDA"],"title":"CUDA_C_NOTES [2]","uri":"/posts/cuda_02/"},{"categories":["GPU"],"content":"Ch01 基于CUDA的异构并行计算 ","date":"2023-07-12","objectID":"/posts/cuda_01/:1:0","tags":["CUDA"],"title":"CUDA_C_NOTES [1]","uri":"/posts/cuda_01/"},{"categories":["GPU"],"content":"1.1 并行计算 并行计算通常设计两个不同的计算机领域 计算机架构(硬件)：在结构级别上支持并行性 并行程序设计(软件)：充分使用计算机架构的计算能力来并发地解决问题 1.1.1 串行编程和并行编程 1.1.2 并行性 并行性方式 任务并行： 当许多任务或函数可以独立地、大规模地并行执行时，这就是任务并行。任务并行的核心是在于利用多核系统对任务进行分配。 数据并行： 当可以处理许多数据的时候，就是数据并行。数据并行的重点是利用多核系统对数据进行分配。 CUDA编程非常适合解决数据并行问题。 数据划分方式： 块划分： 每个线程作用于一部分数据， 通常这些数据具有相同大小。 一组连续数据被分到一个块内，每个数据块以任意次序被安排给一个线程，线程通常在同一时间只处理一个数据块。 周期划分： 每个线程作用于数据的多部分。 在周期划分中，更少的数据被分到一个块内。相邻的线程处理相邻的数据块，每个线程可以处理多个数据块。为一个待处理的线程选择一个新的块，就意味着要跳过和现有线程一样多的数据块。 1.1.3 计算机架构 计算机机构分类(弗林分类(Flynn’s Taxonomy))：根据指令和数据进入CPU的方式进行分类 单指令单数据（SISD） 一种串行架构。 在这种计算机上只有一个核心。在任何时间点上只有一个指令流在处理一个数据流。 单指令多数据（SIMD） 一种并行架构类型。在这种计算机上有多个核心。 在任何时间点上所有的核心只有一个指令流处理不同的数据流，例如向量机。 优势: 在CPU上编写代码时， 程序员可以继续按串行逻辑思考但对并行数据操作实现并行加速，而其他细节则由编译器来负责。 多指令单数据（MISD） 比较少见, 每个核心通过使用多个指令流处理同一个数据流 多指令多数据（MIMD） 一种并行架构， 在这种架构中，多个核心使用多个指令流来异步处理多个数据流，从而实现空间上的并行性。 许多MIMD架构还包括SIMD执行的子组件。 计算机架构优劣的评价指标： 降低延迟 延迟是一个操作从开始到完成所需要的时间， 常用微秒来表示 提高带宽 带宽是单位时间内可处理的数据量， 通常表示为MB/s或GB/s。 提高吞吐量 吞吐量是单位时间内成功处理的运算数量， 通常表示为gflops（即每秒十亿次的浮点运算数量） ， 特别是在重点使用浮点计算的科学计算领域经常用到 延迟用来衡量完成一次操作的时间， 而吞吐量用来衡量在给定的单位时间内处理的操作量 根据内存组织方式进一步划分计算机架构: 分布式内存的多节点系统 大型计算引擎是由许多网络连接的处理器构成的。 每个处理器有自己的本地内存， 而且处理器之间可以通过网络进行通信(类似于多机多卡) 共享内存的多处理器系统 GPU代表了一种众核架构，几乎包括了前文描述的所有并行结构： 多线程、MIMD（多指令多数据）、 SIMD（单指令多数据）， 以及指令级并行。 NVIDIA公司称这 种架构为SIMT（单指令多线程）。 GPU核心和CPU核心 尽管可以使用多核和众核来区分CPU和GPU的架构， 但这两种核心是完全不同的。 CPU核心比较重， 用来处理非常复杂的控制逻辑， 以优化串行程序执行。 GPU核心较轻， 用于优化具有简单控制逻辑的数据并行任务， 注重并行程序的吞吐量。 ","date":"2023-07-12","objectID":"/posts/cuda_01/:1:1","tags":["CUDA"],"title":"CUDA_C_NOTES [1]","uri":"/posts/cuda_01/"},{"categories":["GPU"],"content":"1.2 异构计算 CPU和GPU是两个独立的处理器， 它们通过单个计算节点中的PCI-Express总线相连。 在这种典型的架构中， GPU指的是离散的设备，从同构系统到异构系统的转变是高性能计算 史上的一个里程碑。 同构计算使用的是同一架构下的一个或多个处理器来执行一个应用。 而异构计算则使用一个处理器架构来执行一个应用，为任务选择适合它的架构，使其最终 对性能有所改进. 1.2.1 异构架构 一个典型的异构计算节点包括两个多核CPU插槽和两个或更多个的众核GPU。 GPU不 是一个独立运行的平台而是CPU的协处理器。 因此， GPU必须通过PCIe总线与基于CPU的 主机相连来进行操作， 如图1-9所示。 这就是为什么CPU所在的位置被称作主机端(host)而GPU 所在的位置被称作设备端(device)。 一个异构应用包括两部分： 主机代码：在CPU上运行 设备代码：在GPU上运行. 描述GPU容量的两个重要特征 CUDA核心数量 内存大小 相应的， 有两种不同的指标来评估GPU的性能: 峰值计算性能：用来评估计算容量的一个指标， 通常定义为每秒能处理的单精度或双精度浮点运算的数量，通常用GFlops（每秒十亿次浮点运算） 或TFlops（每秒万 亿次浮点运算） 来表示 内存带宽：从内存中读取或写入数据的比率。 内存带宽通常用GB/s表示 计算能力 1.2.2 异构计算范例 GPU与CPU结合后， 能有效提高大规模计算问题的处理速度与性能。 CPU针对动态工作负载进行了优化， 这些动态工作负载是由短序列的计算操作和不可预测的控制流程标 记的； 而GPU在其他领域内的目的是： 处理由计算任务主导的且带有简单控制流的工作负载。 CPU线程与GPU线程 CPU上的线程通常是重量级的实体。 操作系统必须交替线程使用启用或关闭CPU执行通道以提供多线程处理功能。 上下文的切换缓慢且开销大。 GPU上的线程是高度轻量级的。 在一个典型的系统中会有成千上万的线程排队等待工作。 如果GPU必须等待一组线程执行结束， 那么它只要调用另一组线程执行其他任务即可 1.2.3 CUDA： 一种异构计算平台 CUDA是一种通用的并行计算平台和编程模型，它利用NVIDIA GPU中的并行计算引擎能更有效地解决复杂的计算问题。通过使用CUDA，你可以像在CPU上那样，通过GPU来进行计算。 CUDA提供了两层API来管理GPU设备和组织线程， 如图1-13所示。 CUDA驱动API：驱动API是一种低级API， 它相对来说较难编程， 但是它对于在GPU设备使用上提供了更多的控制。 CUDA运行时API：运行时API是一个高级API， 它在驱动API的上层实现。 每个运行时API函数都被分解为更多传给驱动API的基本运算。 一个CUDA程序包含了以下两个部分: 在CPU上运行的主机代码 在GPU上运行的设备代码 NVIDIA的CUDA nvcc编译器在编译过程中将设备代码从主机代码中分离出来. 主机代码是标准的C代码，使用C编译器进行编译。 设备代码，也就是核函数， 是用扩展的带有标记数据并行函数关键字的CUDA C语言编写的. 设备代码通过nvcc进行编译。 在链接阶段，在内核程序调用和显示GPU设备操作中添加CUDA运行时库。 ","date":"2023-07-12","objectID":"/posts/cuda_01/:1:2","tags":["CUDA"],"title":"CUDA_C_NOTES [1]","uri":"/posts/cuda_01/"},{"categories":["GPU"],"content":"1.3 用GPU输出Hello World 用专用扩展名.cu来创建一个源文件 使用CUDA nvcc编译器来编译程序 从命令行运行可执行文件， 这个文件有可在GPU上运行的内核代码。 首先， 我们编写一个C语言程序来输出“Hello World”， 如下所示 #include\u003cstdio.h\u003e int main(void) { printf(\"Hello World from CPU!\\n\")； } 把代码保存到hello.cu中， 然后使用nvcc编译器来编译。 CUDA nvcc编译器和gcc编译器及其他编译器有相似的语义 nvcc hello.cu -o hello 如果你运行可执行文件hello， 将会输出： Hello World from CPU! 接下来， 编写一个内核函数， 命名为helloFromGPU， 用它来输出字符串“Hello World from GPU！ ”。 __global__ void helloFromGPU(void) { printf(\"Hello World from GPU!\\n\"); } 修饰符__global__告诉编译器这个函数将会从CPU中调用， 然后在GPU上执行。用下面的代码启动内核函数. helloFromGPU \u003c\u003c\u003c1, 10\u003e\u003e\u003e() 三重尖括号意味着从主线程到设备端代码的调用。 一个内核函数通过一组线程来执行， 所有线程执行相同的代码。 三重尖括号里面的参数是执行配置， 用来说明使用多少线程来执行内核函数。 在这个例子中，有10个GPU线程被调用。 cudaDeviceReset()用来显式地释放和清空当前进程中与当前设备有关的所有资源。 一个典型的CUDA编程结构包括5个主要步骤: 1. 分配GPU内存 2. 从CPU内存中拷贝数据到GPU内存 3. 调用CUDA内核函数来完成程序指定的运算 4. 将数据从GPU拷回CPU内存 5. 释放GPU内存空间 ","date":"2023-07-12","objectID":"/posts/cuda_01/:1:3","tags":["CUDA"],"title":"CUDA_C_NOTES [1]","uri":"/posts/cuda_01/"},{"categories":["GPU"],"content":"1.4 使用CUDA C编程难吗 数据局部性: 指的是数据重用， 以降低内存访问的延迟 时间局部性：指在相对较短的时间段内数据或资源的重用 空间局部性：指在相对较接近的存储空间内数据元素的重用。 CUDA中有内存层次和线程层次的概念 内存层次结构 线程层次结构 CUDA核中有3个关键抽象 线程组的层次结构 内存的层次结构 障碍同步 ","date":"2023-07-12","objectID":"/posts/cuda_01/:1:4","tags":["CUDA"],"title":"CUDA_C_NOTES [1]","uri":"/posts/cuda_01/"},{"categories":["GPU"],"content":"1.5 总结 CPU + GPU的异构系统成为高性能计算的主流架构: 在GPU上执行数据并行工作， 在CPU上执行串行和任务并行的工作。 ","date":"2023-07-12","objectID":"/posts/cuda_01/:1:5","tags":["CUDA"],"title":"CUDA_C_NOTES [1]","uri":"/posts/cuda_01/"},{"categories":["C++"],"content":" quote note abstract info tip success question warning failure danger bug example quote ref: https://zhuanlan.zhihu.com/p/650986900 ","date":"2023-07-12","objectID":"/posts/newfeature/:0:0","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"C++ 11 新特性总结 ","date":"2023-07-12","objectID":"/posts/newfeature/:1:0","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] C++ 11 是什么，C++ 11标准的由来 C++ 这门编程语言的历史可以追溯至 1979 年，当时的 Bjarne Stroustrup（C++ 之父，后续简称 Stroustrup）还在使用 Simula 语言进行开发工作。 Simula 语言被认为是第一个面向对象的编程语言。Stroustrup 也非常赞赏 Simula 语言的这种特性，但由于实例开发中 Simula 语言的执行效率太低，所以此后不久，Stroustrup 开始从事“带类的C”编程语言的开发工作。 注意在开发初期，并没有 C++ 这个称谓。所谓“带类的C”，顾名思义就是在 C 语言的基础上，为其加入面向对象的思想（扩增一些写好的类和对象）。初期的 C++ 除了具备 C 语言的所有功能外，还具有类、基本继承、内联函数、默认函数参数以及强类型检查等简单功能。 不仅如此，Stroustrup 还在 CPre（C语言编译器）的基础上，专门为“带类的C”开发了一个编译器，称为 Cfront，它可以将带有类的 C 代码自动转换为普通 C 语言程序。值得一提的是在 1993 年，Cfront 因难以支持 C++ 异常机制被弃用。 1983 年，“带类的C”正式被称为“C++”，其中“++”就取自 C 语言中的“++”运算符，这也从侧面表明了 Stroustrup 对于 C++ 这门编程语言的定位。 与此同时，C++还增添了很多功能，比如虚函数、函数重载、引用、const 关键字以及 // 注释符号等。 在随后的几年时间里，C++ 得到了快速地发展。比如说， C++ 不断地被更新，类中增加了受保护成员（protected）和私有成员（private），并允许使用多继承等；Stroustrup 出版了 《带注释的C++参考手册》一书，其一度被当做 C++ 开发的重要参考；Borland 发布了 Turbo C ++编译器，该编译器包含有大量的第三方 C++ 库，极大便利了 C ++ 的开发，等等。 直到 1998 年，C++ 标准委员会发布了第一版 C++ 标准，并将其命名为 C++98 标准。据不知名人士透露，《带注释的C++参考手册》这本书对 C++98 标准的制定产生了很大的影响。 经过作者的不断迭代，一本书往往会先后发布很多个版本，其中每个新版本都是对前一个版本的修正和更新。C++ 编程语言的发展也是如此。截止到目前（2020年），C++的发展历经了以下 3 个个标准： 2011 年，新的 C++ 11 标准诞生，用于取代 C++ 98 标准。此标准还有一个别名，为“C++ 0x”； 2014 年，C++ 14 标准发布，该标准库对 C++ 11 标准库做了更优的修改和更新； 2017 年底，C++ 17 标准正式颁布。 所谓标准，即明确 C++ 代码的编写规范，所有的 C++ 程序员都应遵守此标准。 值得一提的是在 C++ 11 标准之前，C++ 标准委员会还在 2003 年对 C++ 98 标准做了一次修改（称为 C++ 03 标准），但由于其仅仅修复了一些 C++ 98 标准中存在的漏洞，并未修改核心语法，因此人们习惯将这次修订和 C++ 98 合称为 C++98/03 标准。 以上 3 个标准中，相比对前一个版本的修改和更新程度，C++ 11 标准无疑是颠覆性的，该标准在 C++ 98 的基础上修正了约 600 个 C++ 语言中存在的缺陷，同时添加了约 140 个新特性，这些更新使得 C++ 语言焕然一新。读者可以这样理解 C++ 11 标准，它在 C++ 98/03 标准的基础上孕育出了全新的 C++ 编程语言，造就了 C++ 新的开始。 那么，C++ 11 标准到底包含哪些新特性呢？别急，接下来会分篇给大家做详细地讲解。 ","date":"2023-07-12","objectID":"/posts/newfeature/:1:1","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] auto类型推导完全攻略 在 C++11 之前的版本（C++98 和 C++ 03）中，定义变量或者声明变量之前都必须指明它的类型，比如 int、char 等；但是在一些比较灵活的语言中，比如 C#、JavaScript、PHP、Python 等，程序员在定义变量时可以不指明具体的类型，而是让编译器（或者解释器）自己去推导，这就让代码的编写更加方便。 C++11 为了顺应这种趋势也开始支持自动类型推导了！C++11 使用 auto 关键字来支持自动类型推导。 auto 类型推导的语法和规则 在之前的 C++ 版本中，auto 关键字用来指明变量的存储类型，它和 static 关键字是相对的。auto 表示变量是自动存储的，这也是编译器的默认规则，所以写不写都一样，一般我们也不写，这使得 auto 关键字的存在变得非常鸡肋。 C++11 赋予 auto 关键字新的含义，使用它来做自动类型推导。也就是说，使用了 auto 关键字以后，编译器会在编译期间自动推导出变量的类型，这样我们就不用手动指明变量的数据类型了。 auto 关键字基本的使用语法如下： auto name = value; name 是变量的名字，value 是变量的初始值。 注意：auto 仅仅是一个占位符，在编译器期间它会被真正的类型所替代。或者说，C++ 中的变量必须是有明确类型的，只是这个类型是由编译器自己推导出来的 auto 类型推导的简单例子： auto n = 10; auto f = 12.8; auto p = \u0026n; auto url = “http://c.biancheng.net/cplus/”; 下面我们来解释一下： 第 1 行中，10 是一个整数，默认是 int 类型，所以推导出变量 n 的类型是 int。 第 2 行中，12.8 是一个小数，默认是 double 类型，所以推导出变量 f 的类型是 double。 第 3 行中，\u0026n 的结果是一个 int* 类型的指针，所以推导出变量 p 的类型是 int*。 第 4 行中，由双引号\"“包围起来的字符串是 const char* 类型，所以推导出变量 url 的类型是 const char*，也即一个常量指针。 我们也可以连续定义多个变量： int n = 20; auto *p = \u0026n, m = 99; 先看前面的第一个子表达式，\u0026n 的类型是 int*，编译器会根据 auto *p 推导出 auto 为 int。后面的 m 变量自然也为 int 类型，所以把 99 赋值给它也是正确的。 这里我们要注意，推导的时候不能有二义性。在本例中，编译器根据第一个子表达式已经推导出 auto 为 int 类型，那么后面的 m 也只能是 int 类型，如果写作m=12.5就是错误的，因为 12.5 是double 类型，这和 int 是冲突的。 还有一个值得注意的地方是：使用 auto 类型推导的变量必须马上初始化，这个很容易理解，因为 auto 在 C++11 中只是“占位符”，并非如 int 一样的真正的类型声明。 auto 的高级用法 auto 除了可以独立使用，还可以和某些具体类型混合使用，这样 auto 表示的就是“半个”类型，而不是完整的类型。请看下面的代码： int x = 0; auto *p1 = \u0026x; //p1 为 int *，auto 推导为 int auto p2 = \u0026x; //p2 为 int*，auto 推导为 int* auto \u0026r1 = x; //r1 为 int\u0026，auto 推导为 int auto r2 = r1; //r2 为 int，auto 推导为 int 下面我们来解释一下： 第 2 行代码中，p1 为 int* 类型，也即 auto * 为 int *，所以 auto 被推导成了 int 类型。 第 3 行代码中，auto 被推导为 int* 类型，前边的例子也已经演示过了。 第 4 行代码中，r1 为 int \u0026 类型，auto 被推导为 int 类型。 第 5 行代码是需要重点说明的，r1 本来是 int\u0026 类型，但是 auto 却被推导为 int 类型，这表明当=右边的表达式是一个引用类型时，auto 会把引用抛弃，直接推导出它的原始类型。 接下来，我们再来看一下 auto 和 const 的结合： int x = 0; const auto n = x; //n 为 const int ，auto 被推导为 int auto f = n; //f 为 const int，auto 被推导为 int（const 属性被抛弃） const auto \u0026r1 = x; //r1 为 const int\u0026 类型，auto 被推导为 int auto \u0026r2 = r1; //r1 为 const int\u0026 类型，auto 被推导为 const int 类型`在这里插入代码片` 下面我们来解释一下： 第 2 行代码中，n 为 const int，auto 被推导为 int。 第 3 行代码中，n 为 const int 类型，但是 auto 却被推导为 int 类型，这说明当=右边的表达式带有 const 属性时， auto 不会使用 const 属性，而是直接推导出 non-const 类型。 第 4 行代码中，auto 被推导为 int 类型，这个很容易理解，不再赘述。 第 5 行代码中，r1 是 const int \u0026 类型，auto 也被推导为 const int 类型，这说明当 const 和引用结合时，auto 的推导将保留表达式的 const 类型。 最后我们来简单总结一下 auto 与 const 结合的用法： 当类型不为引用时，auto 的推导结果将不保留表达式的 const 属性； 当类型为引用时，auto 的推导结果将保留表达式的 const 属性。 auto 的限制 前面介绍推导规则的时候我们说过，使用 auto 的时候必须对变量进行初始化，这是 auto 的限制之一。那么，除此以外，auto 还有哪些其它的限制呢？ auto 不能在函数的参数中使用。 这个应该很容易理解，我们在定义函数的时候只是对参数进行了声明，指明了参数的类型，但并没有给它赋值，只有在实际调用函数的时候才会给参数赋值；而 auto 要求必须对变量进行初始化，所以这是矛盾的。 auto 不能作用于类的非静态成员变量（也就是没有 static 关键字修饰的成员变量）中。 auto 关键字不能定义数组，比如下面的例子就是错误的： char url[] = “http://c.biancheng.net/”; auto str[] = url; //arr 为数组，所以不能使用 auto auto 不能作用于模板参数，请看下面的例子： template \u003ctypename T\u003e class A{ //TODO: }; int main(){ A\u003cint\u003e C1; A\u003cauto\u003e C2 = C1; //错误 return 0; } auto 的应用 使用 auto 定义迭代器 auto 的一个典型应用场景是用来定义 stl 的迭代器。 我们在使用 stl 容器的时候，需要使用迭代器来遍历容器里面的元素；不同容器的迭代器有不同的类型，在定义迭代器时必须指明。而迭代器的类型有时候比较复杂，书写起来很麻烦，请看下面的例子： #include \u003cvector\u003e using namespace std; int main(){ vector\u003c vector\u003cint\u003e \u003e v; vector\u003c vector\u003cint\u003e \u003e::iterator i = v.begin(); return 0; } 可以看出来，定义迭代器 i 的时候，类型书写比较冗长，容易出错。然而有了 auto 类型推导，我们大可不必这样，只写一个 auto 即可。 修改上面的代码，使之变得更加简洁： #include \u003cvector\u003e using namespace std; int main(){ vector\u003c vector\u003cint\u003e \u003e v; auto i = v.begin(); //使用 auto 代替具体的类型 return 0; } auto 可以根据表达式 v.begin() 的类型（begin() 函数的返回值类型）来推导出变量 i 的类型。 auto 用于泛型编程 auto 的另一个应用就是当我们不知道变量是什么类型，或者不希望指明具体类型的时候，比如泛型编程中。我们接着看例子： #include \u003ciostream\u003e using namespace std; class A{ public: static int get(void){ return 100; } }; class B{ public: static const char* get(void){ return \"http://c.biancheng.net/cplus/\"; } }; template \u003ctypename T\u003e void func(void){ auto val = T::get(); cout \u003c\u003c val \u003c\u003c endl; } int main(void){ func\u003cA\u003e(); func\u003cB\u003e(); return 0; } 运行结果： 100 本例中的模板函数 func() 会调用所有类的静态函数 get()，并对它的返回值做统一处理，但是 get() 的返回值类型并不一样，而且不能自动转换。这种要求在以","date":"2023-07-12","objectID":"/posts/newfeature/:1:2","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] decltype类型推导完全攻略 decltype 是 C++11 新增的一个关键字，它和 auto 的功能一样，都用来在编译时期进行自动类型推导。不了解 auto 用法的读者请转到(《C++ auto》)[http://c.biancheng.net/view/6984.html]。 decltype 是“declare type”的缩写，译为“声明类型”。 既然已经有了 auto 关键字，为什么还需要 decltype 关键字呢？因为 auto 并不适用于所有的自动类型推导场景，在某些特殊情况下 auto 用起来非常不方便，甚至压根无法使用，所以 decltype 关键字也被引入到 C++11 中。 auto 和 decltype 关键字都可以自动推导出变量的类型，但它们的用法是有区别的： auto varname = value; decltype(exp) varname = value; 其中，varname 表示变量名，value 表示赋给变量的值，exp 表示一个表达式。 auto 根据=右边的初始值 value 推导出变量的类型，而 decltype 根据 exp 表达式推导出变量的类型，跟=右边的 value 没有关系。 另外，auto 要求变量必须初始化，而 decltype 不要求。这很容易理解，auto 是根据变量的初始值来推导出变量类型的，如果不初始化，变量的类型也就无法推导了。decltype 可以写成下面的形式： decltype(exp) varname; exp 注意事项 原则上讲，exp 就是一个普通的表达式，它可以是任意复杂的形式，但是我们必须要保证 exp 的结果是有类型的，不能是 void；例如，当 exp 调用一个返回值类型为 void 的函数时，exp 的结果也是 void 类型，此时就会导致编译错误。 C++ decltype 用法举例： int a = 0; decltype(a) b = 1; //b 被推导成了 int decltype(10.8) x = 5.5; //x 被推导成了 double decltype(x + 100) y; //y 被推导成了 double 可以看到，decltype 能够根据变量、字面量、带有运算符的表达式推导出变量的类型。读者请留意第 4 行，y 没有被初始化。 decltype 推导规则 上面的例子让我们初步感受了一下 decltype 的用法，但你不要认为 decltype 就这么简单，它的玩法实际上可以非常复杂。当程序员使用 decltype(exp) 获取类型时，编译器将根据以下三条规则得出结果： 如果 exp 是一个不被括号( )包围的表达式，或者是一个类成员访问表达式，或者是一个单独的变量，那么 decltype(exp) 的类型就和 exp 一致，这是最普遍最常见的情况。 如果 exp 是函数调用，那么 decltype(exp) 的类型就和函数返回值的类型一致。 如果 exp 是一个左值，或者被括号( )包围，那么 decltype(exp) 的类型就是 exp 的引用；假设 exp 的类型为 T，那么 decltype(exp) 的类型就是 T\u0026。 为了更好地理解 decltype 的推导规则，下面来看几个实际的例子。 【实例1】exp 是一个普通表达式： #include \u003cstring\u003e using namespace std; class Student{ public: static int total; string name; int age; float scores; }; int Student::total = 0; int main(){ int n = 0; const int \u0026r = n; Student stu; decltype(n) a = n; //n 为 int 类型，a 被推导为 int 类型 decltype(r) b = n; //r 为 const int\u0026 类型, b 被推导为 const int\u0026 类型 decltype(Student::total) c = 0; //total 为类 Student 的一个 int 类型的成员变量，c 被推导为 int 类型 decltype(stu.name) url = \"http://c.biancheng.net/cplus/\"; //total 为类 Student 的一个 string 类型的成员变量， url 被推导为 string 类型 return 0; } 这段代码很简单，按照推导规则 1，对于一般的表达式，decltype 的推导结果就和这个表达式的类型一致。 【实例2】exp 为函数调用： /函数声明 int\u0026 func_int_r(int, char); //返回值为 int\u0026 int\u0026\u0026 func_int_rr(void); //返回值为 int\u0026\u0026 int func_int(double); //返回值为 int const int\u0026 fun_cint_r(int, int, int); //返回值为 const int\u0026 const int\u0026\u0026 func_cint_rr(void); //返回值为 const int\u0026\u0026 //decltype类型推导 int n = 100; decltype(func_int_r(100, 'A')) a = n; //a 的类型为 int\u0026 decltype(func_int_rr()) b = 0; //b 的类型为 int\u0026\u0026 decltype(func_int(10.5)) c = 0; //c 的类型为 int decltype(fun_cint_r(1,2,3)) x = n; //x 的类型为 const int \u0026 decltype(func_cint_rr()) y = 0; // y 的类型为 const int\u0026\u0026 需要注意的是，exp 中调用函数时需要带上括号和参数，但这仅仅是形式，并不会真的去执行函数代码。 【实例3】exp 是左值，或者被( )包围： using namespace std; class Base{ public: int x; }; int main(){ const Base obj; //带有括号的表达式 decltype(obj.x) a = 0; //obj.x 为类的成员访问表达式，符合推导规则一，a 的类型为 int decltype((obj.x)) b = a; //obj.x 带有括号，符合推导规则三，b 的类型为 int\u0026。 //加法表达式 int n = 0, m = 0; decltype(n + m) c = 0; //n+m 得到一个右值，符合推导规则一，所以推导结果为 int decltype(n = n + m) d = c; //n=n+m 得到一个左值，符号推导规则三，所以推导结果为 int\u0026 return 0; } 这里我们需要重点说一下左值和右值：左值是指那些在表达式执行结束后依然存在的数据，也就是持久性的数据；右值是指那些在表达式执行结束后不再存在的数据，也就是临时性的数据。有一种很简单的方法来区分左值和右值，对表达式取地址，如果编译器不报错就为左值，否则为右值。 decltype 的实际应用 auto 的语法格式比 decltype 简单，所以在一般的类型推导中，使用 auto 比使用 decltype 更加方便，你可以转到《C++ auto》查看很多类似的例子，本节仅演示只能使用 decltype 的情形。 我们知道，auto 只能用于类的静态成员，不能用于类的非静态成员（普通成员），如果我们想推导非静态成员的类型，这个时候就必须使用 decltype 了。下面是一个模板的定义： #include \u003cvector\u003e using namespace std; template \u003ctypename T\u003e class Base { public: void func(T\u0026 container) { m_it = container.begin(); } private: typename T::iterator m_it; //注意这里 }; int main() { const vector\u003cint\u003e v; Base\u003cconst vector\u003cint\u003e\u003e obj; obj.func(v); return 0; } 单独看 Base 类中 m_it 成员的定义，很难看出会有什么错误，但在使用 Base 类的时候，如果传入一个 const 类型的容器，编译器马上就会弹出一大堆错误信息。原因就在于，T::iterator并不能包括所有的迭代器类型，当 T 是一个 const 容器时，应当使用 const_iterator。 要想解决这个问题，在之前的 C++98/03 版本下只能想办法把 const 类型的容器用模板特化单独处理，增加了不少工作量，看起来也非常晦涩。但是有了 C++11 的 decltype 关键字，就可以直接这样写： template \u003ctypename T\u003e class Base { public: void func(T\u0026 container) { m_it = container.begin(); } private: decltype(T().begin()) m_it; //注意这里 }; 看起来是不是很清爽？ 注意，有些低版本的编译器不支持T().begin()","date":"2023-07-12","objectID":"/posts/newfeature/:1:3","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] 汇总auto和decltype的区别 通过(《C++ auto》)[http://c.biancheng.net/view/6984.html]和(《C++ decltype》)[http://c.biancheng.net/view/7151.html]两节的学习，相信大家已经掌握了 auto 和 decltype 的语法规则以及使用场景，这节我们将 auto 和 decltype 放在一起，综合对比一下它们的区别，并告诉大家该如何选择。 语法格式的区别 auto 和 decltype 都是 C++11 新增的关键字，都用于自动类型推导，但是它们的语法格式是有区别的，如下所示： auto varname = value; //auto的语法格式 decltype(exp) varname [= value]; //decltype的语法格式 其中，varname 表示变量名，value 表示赋给变量的值，exp 表示一个表达式，方括号[ ]表示可有可无。 auto 和 decltype 都会自动推导出变量 varname 的类型： auto 根据=右边的初始值 value 推导出变量的类型； decltype 根据 exp 表达式推导出变量的类型，跟=右边的 value 没有关系。 另外，auto 要求变量必须初始化，也就是在定义变量的同时必须给它赋值；而 decltype 不要求，初始化与否都不影响变量的类型。这很容易理解，因为 auto 是根据变量的初始值来推导出变量类型的，如果不初始化，变量的类型也就无法推导了。 auto 将变量的类型和初始值绑定在一起，而 decltype 将变量的类型和初始值分开；虽然 auto 的书写更加简洁，但 decltype 的使用更加灵活。 请看下面的例子： auto n1 = 10; decltype(10) n2 = 99; auto url1 = \"http://c.biancheng.net/cplus/\"; decltype(url1) url2 = \"http://c.biancheng.net/java/\"; auto f1 = 2.5; decltype(n1*6.7) f2; 这些用法在前面的两节中已经进行了分析，此处就不再赘述了。 对 cv 限定符的处理 「cv 限定符」是 const 和 volatile 关键字的统称： const 关键字用来表示数据是只读的，也就是不能被修改； volatile 和 const 是相反的，它用来表示数据是可变的、易变的，目的是不让 CPU 将数据缓存到寄存器，而是从原始的内存中读取。 在推导变量类型时，auto 和 decltype 对 cv 限制符的处理是不一样的。decltype 会保留 cv 限定符，而 auto 有可能会去掉 cv 限定符。 以下是 auto 关键字对 cv 限定符的推导规则： 如果表达式的类型不是指针或者引用，auto 会把 cv 限定符直接抛弃，推导成 non-const 或者 non-volatile 类型。 如果表达式的类型是指针或者引用，auto 将保留 cv 限定符。 下面的例子演示了对 const 限定符的推导： //非指针非引用类型 const int n1 = 0; auto n2 = 10; n2 = 99; //赋值不报错 decltype(n1) n3 = 20; n3 = 5; //赋值报错 //指针类型 const int *p1 = \u0026n1; auto p2 = p1; *p2 = 66; //赋值报错 decltype(p1) p3 = p1; *p3 = 19; //赋值报错 在 C++ 中无法将一个变量的完整类型输出，我们通过对变量赋值来判断它是否被 const 修饰；如果被 const 修饰那么赋值失败，如果不被 const 修饰那么赋值成功。虽然这种方案不太直观，但也是能达到目的的。 n2 赋值成功，说明不带 const，也就是 const 被 auto 抛弃了，这验证了 auto 的第一条推导规则。p2 赋值失败，说明是带 const 的，也就是 const 没有被 auto 抛弃，这验证了 auto 的第二条推导规则。 n3 和 p3 都赋值失败，说明 decltype 不会去掉表达式的 const 属性。 对引用的处理 当表达式的类型为引用时，auto 和 decltype 的推导规则也不一样；decltype 会保留引用类型，而 auto 会抛弃引用类型，直接推导出它的原始类型。请看下面的例子： #include \u003ciostream\u003e using namespace std; int main() { int n = 10; int \u0026r1 = n; //auto推导 auto r2 = r1; r2 = 20; cout \u003c\u003c n \u003c\u003c \", \" \u003c\u003c r1 \u003c\u003c \", \" \u003c\u003c r2 \u003c\u003c endl; //decltype推导 decltype(r1) r3 = n; r3 = 99; cout \u003c\u003c n \u003c\u003c \", \" \u003c\u003c r1 \u003c\u003c \", \" \u003c\u003c r3 \u003c\u003c endl; return 0; } 运行结果： 10, 10, 20 99, 99, 99 总结 从运行结果可以发现，给 r2 赋值并没有改变 n 的值，这说明 r2 没有指向 n，而是自立门户，单独拥有了一块内存，这就证明 r 不再是引用类型，它的引用类型被 auto 抛弃了。 给 r3 赋值，n 的值也跟着改变了，这说明 r3 仍然指向 n，它的引用类型被 decltype 保留了。 auto 虽然在书写格式上比 decltype 简单，但是它的推导规则复杂，有时候会改变表达式的原始类型；而 decltype 比较纯粹，它一般会坚持保留原始表达式的任何类型，让推导的结果更加原汁原味。 从代码是否健壮的角度考虑，我推荐使用 decltype，它没有那么多是非；但是 decltype 总是显得比较麻烦，尤其是当表达式比较复杂时，例如： vector nums; decltype(nums.begin()) it = nums.begin(); 而如果使用 auto 就会清爽很多： vector nums; auto it = nums.begin(); 在实际开发中人们仍然喜欢使用 auto 关键字（我也这么干），因为它用起来简单直观，更符合人们的审美。如果你的表达式类型不复杂，我还是推荐使用 auto 关键字，优雅的代码总是叫人赏心悦目，沉浸其中。 ","date":"2023-07-12","objectID":"/posts/newfeature/:1:4","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] 返回值类型后置（跟踪返回值类型） 在泛型编程中，可能需要通过参数的运算来得到返回值的类型。考虑下面这个场景： template \u003ctypename R, typename T, typename U\u003e R add(T t, U u) { return t+u; } int a = 1; float b = 2.0; auto c = add\u003cdecltype(a + b)\u003e(a, b); 我们并不关心 a+b 的类型是什么，因此，只需要通过 decltype(a+b) 直接得到返回值类型即可。但是像上面这样使用十分不方便，因为外部其实并不知道参数之间应该如何运算，只有 add 函数才知道返回值应当如何推导。 那么，在 add 函数的定义上能不能直接通过 decltype 拿到返回值呢？ template \u003ctypename T, typename U\u003e decltype(t + u) add(T t, U u) // error: t、u尚未定义 { return t + u; } 当然，直接像上面这样写是编译不过的。因为 t、u 在参数列表中，而 C++ 的返回值是前置语法，在返回值定义的时候参数变量还不存在。 可行的写法如下： template \u003ctypename T, typename U\u003e decltype(T() + U()) add(T t, U u) { return t + u; } 考虑到 T、U 可能是没有无参构造函数的类，正确的写法应该是这样： template \u003ctypename T, typename U\u003e decltype((*(T*)0) + (*(U*)0)) add(T t, U u) { return t + u; } 虽然成功地使用 decltype 完成了返回值的推导，但写法过于晦涩，会大大增加 decltype 在返回值类型推导上的使用难度并降低代码的可读性。 因此，在 C++11 中增加了返回类型后置(trailing-return-type，又称跟踪返回类型)语法，将 decltype 和 auto 结合起来完成返回值类型的推导。 返回类型后置语法是通过 auto 和 decltype 结合起来使用的。上面的 add 函数，使用新的语法可以写成： template \u003ctypename T, typename U\u003e auto add(T t, U u) -\u003e decltype(t + u) { return t + u; } 为了进一步说明这个语法，再看另一个例子： int\u0026 foo(int\u0026 i); float foo(float\u0026 f); template \u003ctypename T\u003e auto func(T\u0026 val) -\u003e decltype(foo(val)) { return foo(val); } 如果说前一个例子中的 add 使用 C++98/03 的返回值写法还勉强可以完成，那么这个例子对于 C++ 而言就是不可能完成的任务了。 在这个例子中，使用 decltype 结合返回值后置语法很容易推导出了 foo(val) 可能出现的返回值类型，并将其用到了 func 上。 返回值类型后置语法，是为了解决函数返回值类型依赖于参数而导致难以确定返回值类型的问题。有了这种语法以后，对返回值类型的推导就可以用清晰的方式（直接通过参数做运算）描述出来，而不需要像 C++98/03 那样使用晦涩难懂的写法。 ","date":"2023-07-12","objectID":"/posts/newfeature/:1:5","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] 对模板实例化中连续右尖括号»的改进 在 C++98/03 的泛型编程中，模板实例化有一个很烦琐的地方，那就是连续两个右尖括号（»）会被编译器解释成右移操作符，而不是模板参数表的结束。 【实例】C++98/03 中不支持连续两个右尖括号的示例。 template \u003ctypename T\u003e struct Foo { typedef T type; }; template \u003ctypename T\u003e class A { // ... }; int main(void) { Foo\u003cA\u003cint\u003e\u003e::type xx; //编译出错 return 0; } 使用 gcc 编译时，会得到如下错误提示： error: ‘\u003e\u003e’ should be ‘\u003e\u003e’ within a nested template argument list Foo\u003cA\u003e::type xx; 意思就是，Foo\u003cA\u003cint\u003e\u003e这种写法是不被支持的，要写成这样Foo\u003cA\u003cint\u003e \u003e（注意两个右尖括号之间的空格）。 这种限制无疑是很没有必要的。在 C++ 的各种成对括号中，目前只有右尖括号连续写两个会出现这种二义性。static_cast、reinterpret_cast 等 C++ 标准转换运算符，都是使用\u003c\u003e来获得待转换类型（type-id）的。若这个 type-id 本身是一个模板，用起来会很不方便。 现在在 C++11 中，这种限制终于被取消了。在 C++11 标准中，要求编译器对模板的右尖括号做单独处理，使编译器能够正确判断出»是一个右移操作符还是模板参数表的结束标记（delimiter，界定符）。 不过这种自动化的处理在某些时候会与老标准不兼容，比如下面这个例子： template \u003cint N\u003e struct Foo { // ... }; int main(void) { Foo\u003c100 \u003e\u003e 2\u003e xx; return 0; } 在 C++98/03 的编译器中编译是没问题的，但 C++11 的编译器会显示： error: expected unqualif?ied-id before ‘\u003e’ token Foo\u003c100 » 2\u003e xx; 解决的方法是这样写： Foo\u003c(100 » 2)\u003e xx; // 注意括号 这种加括号的写法其实也是一个良好的编程习惯，使得在书写时倾向于写出无二义性的代码。 扩展阅读 各种 C++98/03 编译器除了支持标准（ISO/IEC 14882：2003 及其之前的标准）之外，还自行做了不少的拓展。这些拓展中的一部分，后来经过了 C++ 委员会的斟酌和完善，进入了 C++11。 所以有一部分 C++11 的新特征，在一些 C++98/03 的老编译器下也是可以支持的，只是由于没有标准化，无法保证各种平台/编译器下的兼容性。比如像 Microsoft Visual C++2005 这种不支持 C++11 的编译器，在对模板右尖括号的处理上和现在的 C++11 是一致的。 ","date":"2023-07-12","objectID":"/posts/newfeature/:1:6","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] 使用using定义别名（替代typedef） 大家都知道，在 C++ 中可以通过 typedef 重定义一个类型： typedef unsigned int uint_t; 被重定义的类型并不是一个新的类型，仅仅只是原有的类型取了一个新的名字。因此，下面这样将不是合法的函数重载： void func(unsigned int); void func(uint_t); // error: redefinition 使用 typedef 重定义类型是很方便的，但它也有一些限制，比如，无法重定义一个模板。 想象下面这个场景： typedef std::map\u003cstd::string, int\u003e map_int_t; // … typedef std::map\u003cstd::string, std::string\u003e map_str_t; // … 我们需要的其实是一个固定以 std::string 为 key 的 map，它可以映射到 int 或另一个 std::string。然而这个简单的需求仅通过 typedef 却很难办到。 因此，在 C++98/03 中往往不得不这样写： template \u003ctypename Val\u003e struct str_map { typedef std::map\u003cstd::string, Val\u003e type; }; // ... str_map\u003cint\u003e::type map1; // ... 一个虽然简单但却略显烦琐的 str_map 外敷类是必要的。这明显让我们在复用某些泛型代码时非常难受。 现在，在 C++11 中终于出现了可以重定义一个模板的语法。请看下面的示例： template \u003ctypename Val\u003e using str_map_t = std::map\u003cstd::string, Val\u003e; // ... str_map_t\u003cint\u003e map1; 这里使用新的 using 别名语法定义了 std::map 的模板别名 str_map_t。比起前面使用外敷模板加 typedef 构建的 str_map，它完全就像是一个新的 map 类模板，因此，简洁了很多。 实际上，using 的别名语法覆盖了 typedef 的全部功能。先来看看对普通类型的重定义示例，将这两种语法对比一下： // 重定义unsigned int typedef unsigned int uint_t; using uint_t = unsigned int; // 重定义std::map typedef std::map\u003cstd::string, int\u003e map_int_t; using map_int_t = std::map\u003cstd::string, int\u003e; 可以看到，在重定义普通类型上，两种使用方法的效果是等价的，唯一不同的是定义语法。 typedef 的定义方法和变量的声明类似：像声明一个变量一样，声明一个重定义类型，之后在声明之前加上 typedef 即可。这种写法凸显了 C/C++ 中的语法一致性，但有时却会增加代码的阅读难度。比如重定义一个函数指针时： typedef void (*func_t)(int, int); 与之相比，using 后面总是立即跟随新标识符（Identifier），之后使用类似赋值的语法，把现有的类型（type-id）赋给新类型： using func_t = void (*)(int, int); 从上面的对比中可以发现，C++11 的 using 别名语法比 typedef 更加清晰。因为 typedef 的别名语法本质上类似一种解方程的思路。而 using 语法通过赋值来定义别名，和我们平时的思考方式一致。 下面再通过一个对比示例，看看新的 using 语法是如何定义模板别名的。 /* C++98/03 */ template \u003ctypename T\u003e struct func_t { typedef void (*type)(T, T); }; // 使用 func_t 模板 func_t\u003cint\u003e::type xx_1; /* C++11 */ template \u003ctypename T\u003e using func_t = void (*)(T, T); // 使用 func_t 模板 func_t\u003cint\u003e xx_2; 从示例中可以看出，通过 using 定义模板别名的语法，只是在普通类型别名语法的基础上增加 template 的参数列表。使用 using 可以轻松地创建一个新的模板别名，而不需要像 C++98/03 那样使用烦琐的外敷模板。 需要注意的是，using 语法和 typedef 一样，并不会创造新的类型。也就是说，上面示例中 C++11 的 using 写法只是 typedef 的等价物。虽然 using 重定义的 func_t 是一个模板，但 func_t 定义的 xx_2 并不是一个由类模板实例化后的类，而是 void(*)(int, int) 的别名。 因此，下面这样写： void foo(void (*func_call)(int, int)); void foo(func_t func_call); // error: redefinition 同样是无法实现重载的，func_t 只是 void(*)(int, int) 类型的等价物。 细心的读者可以发现，using 重定义的 func_t 是一个模板，但它既不是类模板也不是函数模板（函数模板实例化后是一个函数），而是一种新的模板形式：模板别名(alias template)。 其实，通过 using 可以轻松定义任意类型的模板表达方式。比如下面这样： template using type_t = T; // … type_t i; type_t 实例化后的类型和它的模板参数类型等价。这里，type_t 将等价于 int。 ","date":"2023-07-12","objectID":"/posts/newfeature/:1:7","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] 支持函数模板的默认模板参数 在 C++98/03 标准中，类模板可以有默认的模板参数，如下： template \u003ctypename T, typename U = int, U N = 0\u003e struct Foo { // ... }; 但是却不支持函数的默认模板参数： template \u003ctypename T = int\u003e // error in C++98/03: default template arguments void func() { // ... } 现在这一限制在 C++11 中被解除了。上面的 func 函数在 C++11 中可以直接使用，代码如下： int main(void) { func(); //T = int return 0; } 此时模板参数 T 的类型就为默认值 int。从上面的例子中可以看出，当所有模板参数都有默认参数时，函数模板的调用如同一个普通函数。但对于类模板而言，哪怕所有参数都有默认参数，在使用时也必须在模板名后跟随\u003c\u003e来实例化。 除了上面提到的部分之外，函数模板的默认模板参数在使用规则上和其他的默认参数也有一些不同，它没有必须写在参数表最后的限制。甚至于，根据实际场景中函数模板被调用的情形，编译器还可以自行推导出部分模板参数的类型。 这意味着，当默认模板参数和编译器自行推导出模板参数类型的能力一起结合使用时，代码的书写将变得异常灵活。我们可以指定函数中的一部分模板参数采用默认参数，而另一部分使用自动推导，比如下面的例子： template \u003ctypename R = int, typename U\u003e R func(U val) { return val; } int main() { func(97); // R=int, U=int func\u003cchar\u003e(97); // R=char, U=int func\u003cdouble, int\u003e(97); // R=double, U=int return 0; } C++11 标准中，我们可以像 func(97) 这样调用模板函数，因为编译器可以根据实参 97 自行推导出模板参数 U 的类型为 int，并且根据返回值 val=97 推导出 R 的类型也为 int；而 func(97) 手动指定了模板参数 R 的类型为 char（默认模板参数将无效），并通过实参 97 推导出了 U = int；最后 func\u003cdouble,int\u003e(97) 手动指定的 R 和 U 的类型值，因此无需编译器自行推导。 再次强调，当默认模板参数和自行推导的模板参数同时使用时，若无法推导出函数模板参数的类型，编译器会选择使用默认模板参数；如果模板参数即无法推导出来，又未设置其默认值，则编译器直接报错。例如： template \u003ctypename T, typename U = double\u003e void func(T val1 = 0, U val2 = 0) { //... } int main() { func('c'); //T=char, U=double func(); //编译报错 return 0; } 其中，func(‘c’) 的这种调用方式，编译器通过实参 ‘c’ 可以推导出 T=char，但由于未传递第 2 个实参，因此模板参数 U 使用的是默认参数 double；但 func() 的调用方式是不行的，虽然 val1 设置有默认值，但编译器无法通过该默认值推导出模板参数 T 的类型。由此不难看出，编译器的自动推导能力并没有想象的那么强大。 总的来说，C++11 支持为函数模板中的参数设置默认值，在实际使用过程中，我们可以选择使用默认值，也可以尝试由编译器自行推导得到，还可以亲自指定各个模板参数的类型。 ","date":"2023-07-12","objectID":"/posts/newfeature/:1:8","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] 在函数模板和类模板中使用可变参数 所谓可变参数，指的是参数的个数和类型都可以是任意的。提到参数，大家会第一时间想到函数参数，除此之外 C++ 的模板(包括函数模板和类模板)也会用到参数。 对于函数参数而言，C++ 一直都支持为函数设置可变参数，最典型的代表就是 printf() 函数，它的语法格式为： int printf ( const char * format, ... ); ...就表示的是可变参数，即 printf() 函数可以接收任意个参数，且各个参数的类型可以不同，例如： printf(\"%d\", 10);printf(\"%d %c\",10, 'A');printf(\"%d %c %f\",10, 'A', 1.23); 我们通常将容纳多个参数的可变参数称为参数包。借助 format 字符串，printf() 函数可以轻松判断出参数包中的参数个数和类型。 下面的程序中，自定义了一个简单的可变参数函数： #include \u003ciostream\u003e #include \u003ccstdarg\u003e //可变参数的函数 void vair_fun(int count, ...){ va_list args; va_start(args, count); for (int i = 0; i \u003c count; ++i) { int arg = va_arg(args, int); std::cout \u003c\u003c arg \u003c\u003c \" \"; } va_end(args); } int main(){ //可变参数有 4 个，分别为 10、20、30、40 vair_fun(4, 10, 20, 30,40); return 0; } 程序中的 vair_fun() 函数有 2 个参数，一个是 count，另一个就是 … 可变参数。我们可以很容易在函数内部使用 count 参数，但要想使用参数包中的参数，需要借助头文件中的 va_start、va_arg 以及 va_end 这 3 个带参数的宏： va_start(args, count)：args 是 va_list 类型的变量，我们可以简单的将其视为 char * 类型。借助 count 参数，找到可变参数的起始位置并赋值给 args； va_arg(args, int)：调用 va_start 找到可变参数起始位置的前提下，通过指明参数类型为 int，va_arg 就可以将可变参数中的第一个参数返回； va_end(args)：不再使用 args 变量后，应及时调用 va_end 宏清理 args 变量。 注意，借助 va_arg 获取参数包中的参数时，va_arg 不具备自行终止的能力，所以程序中借助 count 参数控制 va_arg 的执行次数，继而将所有的参数读取出来。控制 va_arg 执行次数还有其他方法，比如读取到指定数据时终止。 使用 … 可变参数的过程中，需注意以下几点： … 可变参数必须作为函数的最后一个参数，且一个函数最多只能拥有 1 个可变参数。 可变参数的前面至少要有 1 个有名参数（例如上面例子中的 count 参数）； 当可变参数中包含 char 类型的参数时，va_arg 宏要以 int 类型的方式读取；当可变参数中包含 short 类型的参数时，va_arg 宏要以 double 类型的方式读取。 需要注意的是，…可变参数的方法仅适用于函数参数，并不适用于模板参数。C++11 标准中，提供了一种实现\u003c/font color=red\u003e可变模板参数的方法。 可变参数模板 C++ 11 标准发布之前，函数模板和类模板只能设定固定数量的模板参数。C++11 标准对模板的功能进行了扩展，允许模板中包含任意数量的模板参数，这样的模板又称可变参数模板。 （1）可变参数函数模板 先讲解函数模板，如下定义了一个可变参数的函数模板： template\u003ctypename... T\u003e void vair_fun(T...args) { //函数体 } 模板参数中， typename（或者 class）后跟 … 就表明 T 是一个可变模板参数，它可以接收多种数据类型，又称模板参数包。vair_fun() 函数中，args 参数的类型用 T… 表示，表示 args 参数可以接收任意个参数，又称函数参数包。 这也就意味着，此函数模板最终实例化出的 vair_fun() 函数可以指定任意类型、任意数量的参数。例如，我们可以这样使用这个函数模板： vair_fun(); vair_fun(1, \"abc\"); vair_fun(1, \"abc\", 1.23); 使用可变参数模板的难点在于，如何在模板函数内部“解开”参数包（使用包内的数据），这里给大家介绍两种简单的方法。 [递归方式解包] 先看一个实例： #include \u003ciostream\u003e using namespace std; //模板函数递归的出口 void vir_fun() { } template \u003ctypename T, typename... args\u003e void vir_fun(T argc, args... argv) { cout \u003c\u003c argc \u003c\u003c endl; //开始递归，将第一个参数外的 argv 参数包重新传递给 vir_fun vir_fun(argv...); } int main() { vir_fun(1, \"http://www.biancheng.net\", 2.34); return 0; } 执行结果为： 1 http://www.biancheng.net 2.34 分析一个程序的执行流程： 首先，main() 函数调用 vir_fun() 模板函数时，根据所传实参的值，可以很轻易地判断出模板参数 T 的类型为 int，函数参数 argc 的值为 1，剩余的模板参数和函数参数都分别位于 args 和 argv 中； vir_fun() 函数中，首先输出了 argc 的值（为 1），然后重复调用自身，同时将函数参数包 argv 中的数据作为实参传递给形参 argc 和 argv； 再次执行 vir_fun() 函数，此时模板参数 T 的类型为 char*，输出 argc 的值为 “http:www.biancheng.net”。再次调用自身，继续将 argv 包中的数据作为实参； 再次执行 vir_fun() 函数，此时模板参数 T 的类型为 double，输出 argc 的值为 2.34。再次调用自身，将空的 argv 包作为实参； 由于 argv 包没有数据，此时会调用无任何形参、函数体为空的 vir_fun() 函数，最终执行结束。 以递归方式解包，一定要设置递归结束的出口。例如本例中，无形参、函数体为空的 vir_fun() 函数就是递归结束的出口。 [非递归方法解包] 借助逗号表达式和初始化列表，也可以解开参数包。 以 vir_fun() 函数为例，下面程序演示了非递归方法解包的过程： #include \u003ciostream\u003e using namespace std; template \u003ctypename T\u003e void dispaly(T t) { cout \u003c\u003c t \u003c\u003c endl; } template \u003ctypename... args\u003e void vir_fun(args... argv) { //逗号表达式+初始化列表 int arr[] = { (dispaly(argv),0)... }; } int main() { vir_fun(1, \"http://www.biancheng.net\", 2.34); return 0; } 这里重点分析一下第 13 行代码，我们以{ }初始化列表的方式对数组 arr 进行了初始化， (display(argv),0)… 会依次展开为 (display(1),0)、(display(“http://www.biancheng.net”),0) 和 (display(2.34),0)。也就是说，第 13 行代码和如下代码是等价的： int arr[] = { (dispaly(1),0), (dispaly(\"http://www.biancheng.net\"),0), (dispaly(2.34),0) }; 可以看到，每个元素都是一个逗号表达式，以 (display(1), 0) 为例，它会先计算 display(1)，然后将 0 作为整个表达式的值返回给数组，因此 arr 数组最终存储的都是 0。arr 数组纯粹是为了将参数包展开，没有发挥其它作用。 (2) 可变参数类模板 C++11 标准中，类模板中的模板参数也可以是一个可变参数。C++ 11 标准提供的 typle 元组类就是一个典型的可变参数模板类，它的定义如下： template \u003ctypename... Types\u003e class tuple; 和固定模板参数的类不同，typle 模板类实例化时，可以接收任意数量、任意类型的模板参数，例如： std:tuple\u003c\u003e tp0; std::tuple\u003cint\u003e tp1 = std::make_tuple(1); std::tuple\u003cint, double\u003e tp2 = std::make_tuple(1, 2.34); std::tuple\u003cint, double, string\u003e tp3 = std::make_tuple(1, 2.34, \"http://www.biancheng.net\"); 如下代码展示了一个支持可变参","date":"2023-07-12","objectID":"/posts/newfeature/:1:9","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] tuple元组详解 C++11 标准新引入了一种类模板，命名为 tuple（中文可直译为元组）。tuple 最大的特点是：实例化的对象可以存储任意数量、任意类型的数据。 tuple 的应用场景很广泛，例如当需要存储多个不同类型的元素时，可以使用 tuple；当函数需要返回多个数据时，可以将这些数据存储在 tuple 中，函数只需返回一个 tuple 对象即可。 本节，我们将给大家详细地讲解 tuple 的用法。 tuple对象的创建 tuple 本质是一个以可变模板参数定义的类模板，它定义在 头文件并位于 std 命名空间中。因此要想使用 tuple 类模板，程序中需要首先引入以下代码： #include \u003ctuple\u003e using std::tuple; 实例化 tuple 模板类对象常用的方法有两种，一种是借助该类的构造函数，另一种是借助 make_tuple() 函数。 (1) 类的构造函数 tuple 模板类提供有很多构造函数，包括: 1) 默认构造函数 constexpr tuple(); 2) 拷贝构造函数 tuple (const tuple\u0026 tpl); 3) 移动构造函数 tuple (tuple\u0026\u0026 tpl); 4) 隐式类型转换构造函数 template \u003cclass... UTypes\u003e tuple (const tuple\u003cUTypes...\u003e\u0026 tpl); //左值方式 template \u003cclass... UTypes\u003e tuple (tuple\u003cUTypes...\u003e\u0026\u0026 tpl); //右值方式 5) 支持初始化列表的构造函数 explicit tuple (const Types\u0026... elems); //左值方式 template \u003cclass... UTypes\u003e explicit tuple (UTypes\u0026\u0026... elems); //右值方式 6) 将pair对象转换为tuple对象 template \u003cclass U1, class U2\u003e tuple (const pair\u003cU1,U2\u003e\u0026 pr); //左值方式 template \u003cclass U1, class U2\u003e tuple (pair\u003cU1,U2\u003e\u0026\u0026 pr); //右值方式 举个例子： #include \u003ciostream\u003e // std::cout #include \u003ctuple\u003e // std::tuple using std::tuple; int main() { std::tuple\u003cint, char\u003e first; // 1) first{} std::tuple\u003cint, char\u003e second(first); // 2) second{} std::tuple\u003cint, char\u003e third(std::make_tuple(20, 'b')); // 3) third{20,'b'} std::tuple\u003clong, char\u003e fourth(third); // 4)的左值方式, fourth{20,'b'} std::tuple\u003cint, char\u003e fifth(10, 'a'); // 5)的右值方式, fifth{10.'a'} std::tuple\u003cint, char\u003e sixth(std::make_pair(30, 'c')); // 6)的右值方式, sixth{30,''c} return 0; } (2) make_tuple()函数 上面程序中，我们已经用到了 make_tuple() 函数，它以模板的形式定义在 头文件中，功能是创建一个 tuple 右值对象（或者临时对象）。 对于 make_tuple() 函数创建了 tuple 对象，我们可以上面程序中那样作为移动构造函数的参数，也可以这样用： auto first = std::make_tuple (10,'a'); // tuple \u003c int, char \u003e const int a = 0; int b[3]; auto second = std::make_tuple (a,b); // tuple \u003c int, int* \u003e 程序中分别创建了 first 和 second 两个 tuple 对象，它们的类型可以直接用 auto 表示。 tuple常用函数 为了方便您在实际开发中使用 tuple 对象，tupe 模板类提供了一个功能实用的成员函数， 头文件中也提供了一些和操作 tuple 对象相关的函数模板和类模板，如表 1 所示。 函数或类模板 描 述 tup1.swap(tup2) swap(tup1, tup2) tup1 和 tup2 表示类型相同的两个 tuple 对象，tuple 模板类中定义有一个 swap() 成员函数， 头文件还提供了一个同名的 swap() 全局函数。 swap() 函数的功能是交换两个 tuple 对象存储的内容。 get(tup) tup 表示某个 tuple 对象，num 是一个整数，get() 是 头文件提供的全局函数，功能是返回 tup 对象中第 num+1 个元素。 tuple_size::value tuple_size 是定义在 头文件的类模板，它只有一个成员变量 value，功能是获取某个 tuple 对象中元素的个数，type 为该tuple 对象的类型。 tuple_element\u003cI, type\u003e::type tuple_element 是定义在 头文件的类模板，它只有一个成员变量 type，功能是获取某个 tuple 对象第 I+1 个元素的类型。 forward_as_tuple\u003cargs…\u003e args… 表示 tuple 对象存储的多个元素，该函数的功能是创建一个 tuple 对象，内部存储的 args… 元素都是右值引用形式的。 tie(args…) = tup tup 表示某个 tuple 对象，tie() 是 头文件提供的，功能是将 tup 内存储的元素逐一赋值给 args… 指定的左值变量。 tuple_cat(args…) args… 表示多个 tuple 对象，该函数是 头文件提供的，功能是创建一个 tuple 对象，此对象包含 args… 指定的所有 tuple 对象内的元素。 tuple 模板类对赋值运算符 = 进行了重载，使得同类型的 tuple 对象可以直接赋值。此外，tuple 模板类还重载了 ==、!=、\u003c、\u003e、\u003e=、\u003c= 这几个比较运算符，同类型的 tuple 对象可以相互比较（逐个比较各个元素）。 下面的程序给您演示了表 1 中一部分函数模板和类模板的功能： #include \u003ciostream\u003e #include \u003ctuple\u003e int main() { int size; //创建一个 tuple 对象存储 10 和 'x' std::tuple\u003cint, char\u003e mytuple(10, 'x'); //计算 mytuple 存储元素的个数 size = std::tuple_size\u003cdecltype(mytuple)\u003e::value; //输出 mytuple 中存储的元素 std::cout \u003c\u003c std::get\u003c0\u003e(mytuple) \u003c\u003c \" \" \u003c\u003c std::get\u003c1\u003e(mytuple) \u003c\u003c std::endl; //修改指定的元素 std::get\u003c0\u003e(mytuple) = 100; std::cout \u003c\u003c std::get\u003c0\u003e(mytuple) \u003c\u003c std::endl; //使用 makde_tuple() 创建一个 tuple 对象 auto bar = std::make_tuple(\"test\", 3.1, 14); //拆解 bar 对象，分别赋值给 mystr、mydou、myint const char* mystr = nullptr; double mydou; int myint; //使用 tie() 时，如果不想接受某个元素的值，实参可以用 std::ignore 代替 std::tie(mystr, mydou, myint) = bar; //std::tie(std::ignore, std::ignore, myint) = bar; //只接收第 3 个整形值 //将 mytuple 和 bar 中的元素整合到 1 个 tuple 对象中 auto mycat = std::tuple_cat(mytuple, bar); size = std::tuple_size\u003cdecltype(mycat)\u003e::value; std::cout \u003c\u003c size \u003c\u003c std::endl; return 0; } 程序执行结果为： 10 x 100 5 ","date":"2023-07-12","objectID":"/posts/newfeature/:1:10","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] 列表初始化（统一了初始化方式） 我们知道，在 C++98/03 中的对象初始化方法有很多种，请看下面的代码： //初始化列表 int i_arr[3] = { 1, 2, 3 }; //普通数组 struct A { int x; struct B { int i; int j; } b; } a = { 1, { 2, 3 } }; //POD类型 //拷贝初始化（copy-initialization） int i = 0; class Foo { public: Foo(int) {} } foo = 123; //需要拷贝构造函数 //直接初始化（direct-initialization） int j(0); Foo bar(123); 这些不同的初始化方法，都有各自的适用范围和作用。最关键的是，这些种类繁多的初始化方法，没有一种可以通用所有情况。 为了统一初始化方式，并且让初始化行为具有确定的效果，C++11 中提出了列表初始化（List-initialization）的概念。 POD 类型即 plain old data 类型，简单来说，是可以直接使用 memcpy 复制的对象。 统一的初始化 在上面我们已经看到了，对于普通数组和 POD 类型，C++98/03 可以使用初始化列表（initializer list）进行初始化: int i_arr[3] = { 1, 2, 3 }; long l_arr[] = { 1, 3, 2, 4 }; struct A { int x; int y; } a = { 1, 2 }; 但是这种初始化方式的适用性非常狭窄，只有上面提到的这两种数据类型可以使用初始化列表。 在 C++11 中，初始化列表的适用性被大大增加了，它现在可以用于任何类型对象的初始化。 请看下面的代码。 【实例】通过初始化列表初始化对象。 class Foo { public: Foo(int) {} private: Foo(const Foo \u0026); }; int main(void) { Foo a1(123); Foo a2 = 123; //error: 'Foo::Foo(const Foo \u0026)' is private Foo a3 = { 123 }; Foo a4 { 123 }; int a5 = { 3 }; int a6 { 3 }; return 0; } 在上例中，a3、a4 使用了新的初始化方式来初始化对象，效果如同 a1 的直接初始化。 a5、a6 则是基本数据类型的列表初始化方式。可以看到，它们的形式都是统一的。 这里需要注意的是，a3 虽然使用了等于号，但它仍然是列表初始化，因此，私有的拷贝构造并不会影响到它。 a4 和 a6 的写法，是 C++98/03 所不具备的。在 C++11 中，可以直接在变量名后面跟上初始化列表，来进行对象的初始化。 这种变量名后面跟上初始化列表方法同样适用于普通数组和 POD 类型的初始化： int i_arr[3] { 1, 2, 3 }; //普通数组 struct A { int x; struct B { int i; int j; } b; } a { 1, { 2, 3 } }; //POD类型 在初始化时，{}前面的等于号是否书写对初始化行为没有影响。 另外，如同读者所想的那样，new 操作符等可以用圆括号进行初始化的地方，也可以使用初始化列表： int* a = new int { 123 }; double b = double { 12.12 }; int* arr = new int[3] { 1, 2, 3 }; 指针 a 指向了一个 new 操作符返回的内存，通过初始化列表方式在内存初始化时指定了值为 123。 b 则是对匿名对象使用列表初始化后，再进行拷贝初始化。 这里让人眼前一亮的是 arr 的初始化方式。堆上动态分配的数组终于也可以使用初始化列表进行初始化了。 除了上面所述的内容之外，列表初始化还可以直接使用在函数的返回值上： struct Foo { Foo(int, double) {} }; Foo func(void) { return { 123, 321.0 }; } 这里的 return 语句就如同返回了一个 Foo(123, 321.0)。 由上面的这些例子可以看到，在 C++11 中使用初始化列表是非常便利的。它不仅统一了各种对象的初始化方式，而且还使代码的书写更加简单清晰。 ","date":"2023-07-12","objectID":"/posts/newfeature/:1:11","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] lambda匿名函数用法详解 lambda 源自希腊字母表中第 11 位的 λ，在计算机科学领域，它则是被用来表示一种匿名函数。所谓匿名函数，简单地理解就是没有名称的函数，又常被称为 lambda 函数或者 lambda 表达式。 继 Python、Java、C#、PHP 等众多高级编程语言都支持 lambda 匿名函数后，C++11 标准终于引入了 lambda，本节将带领大家系统地学习 lambda 表达式的具体用法。 lambda匿名函数的定义 定义一个 lambda 匿名函数很简单，可以套用如下的语法格式： [外部变量访问方式说明符] (参数) mutable noexcept/throw() -\u003e 返回值类型 { 函数体; }; 其中各部分的含义分别为： 1. [外部变量方位方式说明符] [ ] 方括号用于向编译器表明当前是一个 lambda 表达式，其不能被省略。在方括号内部，可以注明当前 lambda 函数的函数体中可以使用哪些“外部变量”。 \u003e 所谓外部变量，指的是和当前 lambda 表达式位于同一作用域内的所有局部变量。\u003c/br\u003e 2. (参数) 和普通函数的定义一样，lambda 匿名函数也可以接收外部传递的多个参数。和普通函数不同的是，如果不需要传递参数，可以连同 () 小括号一起省略； 3. mutable 此关键字可以省略，如果使用则之前的 () 小括号将不能省略（参数个数可以为 0）。默认情况下，对于以值传递方式引入的外部变量，不允许在 lambda 表达式内部修改它们的值（可以理解为这部分变量都是 const 常量）。而如果想修改它们，就必须使用 mutable 关键字。 \u003e 对于以值传递方式引入的外部变量，lambda 表达式修改的是拷贝的那一份，并不会修改真正的外部变量； 4. noexcept/throw() 可以省略，如果使用，在之前的 () 小括号将不能省略（参数个数可以为 0）。默认情况下，lambda 函数的函数体中可以抛出任何类型的异常。而标注 noexcept 关键字，则表示函数体内不会抛出任何异常；使用 throw() 可以指定 lambda 函数内部可以抛出的异常类型。\u003c/br\u003e 值得一提的是，如果 lambda 函数标有 noexcept 而函数体内抛出了异常，又或者使用 throw() 限定了异常类型而函数体内抛出了非指定类型的异常，这些异常无法使用 try-catch 捕获，会导致程序执行失败（本节后续会给出实例）。 5. -\u003e 返回值类型 指明 lambda 匿名函数的返回值类型。值得一提的是，如果 lambda 函数体内只有一个 return 语句，或者该函数返回 void，则编译器可以自行推断出返回值类型，此情况下可以直接省略-\u003e 返回值类型。 6. 函数体 和普通函数一样，lambda 匿名函数包含的内部代码都放置在函数体中。该函数体内除了可以使用指定传递进来的参数之外，还可以使用指定的外部变量以及全局范围内的所有全局变量。 需要注意的是，外部变量会受到以值传递还是以引用传递方式引入的影响，而全局变量则不会。换句话说，在 lambda 表达式内可以使用任意一个全局变量，必要时还可以直接修改它们的值。 其中，红色标识的参数是定义 lambda 表达式时必须写的，而绿色标识的参数可以省略。 比如，如下就定义了一个最简单的 lambda 匿名函数： []{} 显然，此 lambda 匿名函数未引入任何外部变量（[] 内为空），也没有传递任何参数，没有指定 mutable、noexcept 等关键字，没有返回值和函数体。所以，这是一个没有任何功能的 lambda 匿名函数。 lambda匿名函数中的[外部变量] 对于 lambda 匿名函数的使用，令多数初学者感到困惑的就是 [外部变量] 的使用。其实很简单，无非表 1 所示的这几种编写格式。 外部变量格式 功能 [] 空方括号表示当前 lambda 匿名函数中不导入任何外部变量。 [=] 只有一个 = 等号，表示以值传递的方式导入所有外部变量； [\u0026] 只有一个 \u0026 符号，表示以引用传递的方式导入所有外部变量； [val1, val2, …] 表示以值传递的方式导入 val1、val2 等指定的外部变量，同时多个变量之间没有先后次序； [\u0026val1, \u0026val2, …] 表示以引用传递的方式导入 val1、val2等指定的外部变量，多个变量之间没有前后次序； [val, \u0026val2,…] 以上 2 种方式还可以混合使用，变量之间没有前后次序。 [=， \u0026val1,…] 表示除 val1 以引用传递的方式导入外，其它外部变量都以值传递的方式导入。 [this] 表示以值传递的方式导入当前的 this 指针。 注意，单个外部变量不允许以相同的传递方式导入多次。例如 [=，val1] 中，val1 先后被以值传递的方式导入了 2 次，这是非法的。 【例 1】lambda 匿名函数的定义和使用。 #include \u003ciostream\u003e #include \u003calgorithm\u003e using namespace std; int main() { int num[4] = {4, 2, 3, 1}; //对 a 数组中的元素进行排序 sort(num, num+4, [=](int x, int y) -\u003e bool{ return x \u003c y; } ); for(int n : num){ cout \u003c\u003c n \u003c\u003c \" \"; } return 0; } 程序执行结果为： 1 2 3 4 程序第 9 行通过调用 sort() 函数实现了对 num 数组中元素的升序排序，其中就用到了 lambda 匿名函数。而如果使用普通函数，需以如下代码实现： #include \u003ciostream\u003e #include \u003calgorithm\u003e using namespace std; //自定义的升序排序规则 bool sort_up(int x,int y){ return x \u003c y; } int main() { int num[4] = {4, 2, 3, 1}; //对 a 数组中的元素进行排序 sort(num, num+4, sort_up); for(int n : num){ cout \u003c\u003c n \u003c\u003c \" \"; } return 0; } 此程序中 sort_up() 函数的功能和上一个程序中的 lambda 匿名函数完全相同。显然在类似的场景中，使用 lambda 匿名函数更有优势。 除此之外，虽然 lambda 匿名函数没有函数名称，但我们仍可以为其手动设置一个名称，比如： #include \u003ciostream\u003e using namespace std; int main() { //display 即为 lambda 匿名函数的函数名 auto display = [](int a,int b) -\u003e void{cout \u003c\u003c a \u003c\u003c \" \" \u003c\u003c b;}; //调用 lambda 函数 display(10,20); return 0; } 程序执行结果为： 10 20 可以看到，程序中使用 auto 关键字为 lambda 匿名函数设定了一个函数名，由此我们即可在作用域内调用该函数。 【例 2】值传递和引用传递的区别 #include \u003ciostream\u003e using namespace std; //全局变量 int all_num = 0; int main() { //局部变量 int num_1 = 1; int num_2 = 2; int num_3 = 3; cout \u003c\u003c \"lambda1:\\n\"; auto lambda1 = [=]{ //全局变量可以访问甚至修改 all_num = 10; //函数体内只能使用外部变量，而无法对它们进行修改 cout \u003c\u003c num_1 \u003c\u003c \" \" \u003c\u003c num_2 \u003c\u003c \" \" \u003c\u003c num_3 \u003c\u003c endl; }; lambda1(); cout \u003c\u003c all_num \u003c\u003cendl; cout \u003c\u003c \"lambda2:\\n\"; auto lambda2 = [\u0026]{ all_num = 100; num_1 = 10; num_2 = 20; num_3 = 30; cout \u003c\u003c num_1 \u003c\u003c \" \" \u003c\u003c num_2 \u003c\u003c \" \" \u003c\u003c num_3 \u003c\u003c endl; }; lambda2(); cout \u003c\u003c all_num \u003c\u003c endl; return 0; } 程序执行结果为： lambda1: 1 2 3 10 lambda2: 10 20 30 100 可以看到，在创建 lambda1 和 lambda2 匿名函数的作用域中，有 num_1、num_2 和 num_3 这 3 个局部变量，另外还有 all_num 全局变量。 其中，lambda1 匿名函数是以 [=] 值传递的方式导入的局部变量，这意味着默认情况下，此函数内部无法修改这 3 个局部变量的值，但全局变量 all_num 除外。相对地，lambda2 匿名函数以 [\u0026] 引用传递的方式导入这 3 个局部变量，因此在该函数的内部不就可以访问这 3 个局部变量，还可以任意修改它们。同样，也可以访问甚至修改全局变量。 感兴趣的读者，可自行尝试在 lambda1 匿名函数中修改 num_1、num_2 或者 num_3 的值，观察编译器的报错信息。 当然，如果我们想在 lambda1 匿名","date":"2023-07-12","objectID":"/posts/newfeature/:1:12","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] 非受限联合体（union） 在 C/C++ 中，联合体（Union）是一种构造数据类型。在一个联合体内，我们可以定义多个不同类型的成员，这些成员将会共享同一块内存空间。老版本的 C++ 为了和C语言保持兼容，对联合体的数据成员的类型进行了很大程度的限制，这些限制在今天看来并没有必要，因此 C++11 取消了这些限制。 C++11 标准规定，任何非引用类型都可以成为联合体的数据成员，这种联合体也被称为非受限联合体。例如： class Student{ public: Student(bool g, int a): gender(g), age(a) {} private: bool gender; int age; }; union T{ Student s; // 含有非POD类型的成员，gcc-5.1.0 版本报错 char name[10]; }; int main(){ return 0; } 上面的代码中，因为 Student 类带有自定义的构造函数，所以是一个非 POD 类型的，这导致编译器报错。这种规定只是 C++ 为了兼容C语言而制定，然而在长期的编程实践中发现，这种规定是没有必要的。 关于 POD 类型稍后我们会讲解，大家先不要着急。 接下来，我们具体看一下 C++11 对 C++98 的改进。 1.C++11 允许非 POD 类型 C++98 不允许联合体的成员是非 POD 类型，但是 C++1 1 取消了这种限制。 POD 是 C++ 中一个比较重要的概念，在这里我们做一个简单介绍。POD 是英文 Plain Old Data 的缩写，用来描述一个类型的属性。 POD 类型一般具有以下几种特征（包括 class、union 和 struct等）: 1. 没有用户自定义的构造函数、析构函数、拷贝构造函数和移动构造函数。 2. 不能包含虚函数和虚基类。 3. 非静态成员必须声明为 public。 4. 类中的第一个非静态成员的类型与其基类不同，例如： c++ class B1{}; class B2 : B1 { B1 b; }; class B2 的第一个非静态成员 b 是基类类型，所以它不是 POD 类型。 5. 类或者结构体继承时，满足以下两种情况之一： - 派生类中有非静态成员，且只有一个仅包含静态成员的基类； - 基类有非静态成员，而派生类没有非静态成员。 c++ class B1 { static int n; }; class B2 : B1 { int n1; }; class B3 : B2 { static int n2; }; 对于 B2，派生类 B2 中有非静态成员，且只有一个仅包含静态成员的基类 B1，所以它是 POD 类型。对于 B3，基类 B2 有非静态成员，而派生类 B3 没有非静态成员，所以它也是 POD 类型。 6. 所有非静态数据成员均和其基类也符合上述规则（递归定义），也就是说 POD 类型不能包含非 POD 类型的数据。 7. 此外，所有兼容C语言的数据类型都是 POD 类型（struct、union 等不能违背上述规则）。 2.C++11 允许联合体有静态成员 C++11 删除了联合体不允许拥有静态成员的限制。例如： union U { static int func() { int n = 3; return n; } }; 需要注意的是，静态成员变量只能在联合体内定义，却不能在联合体外使用，这使得该规则很没用。 非受限联合体的赋值注意事项 C++11 规定，如果非受限联合体内有一个非 POD 的成员，而该成员拥有自定义的构造函数，那么这个非受限联合体的默认构造函数将被编译器删除；其他的特殊成员函数，例如默认拷贝构造函数、拷贝赋值操作符以及析构函数等，也将被删除。 这条规则可能导致对象构造失败，请看下面的例子： #include \u003cstring\u003e using namespace std; union U { string s; int n; }; int main() { U u; // 构造失败，因为 U 的构造函数被删除 return 0; } 在上面的例子中，因为 string 类拥有自定义的构造函数，所以 U 的构造函数被删除；定义 U 的类型变量 u 需要调用默认构造函数，所以 u 也就无法定义成功。 解决上面问题的一般需要用到 placement new（稍后会讲解这个概念），代码如下： #include \u003cstring\u003e using namespace std; union U { string s; int n; public: U() { new(\u0026s) string; } ~U() { s.~string(); } }; int main() { U u; return 0; } 构造时，采用 placement new 将 s 构造在其地址 \u0026s 上，这里 placement new 的唯一作用只是调用了一下 string 类的构造函数。注意，在析构时还需要调用 string 类的析构函数。 placement new 是什么？ placement new 是 new 关键字的一种进阶用法，既可以在栈（stack）上生成对象，也可以在堆（heap）上生成对象。相对应地，我们把常见的 new 的用法称为 operator new，它只能在 heap 上生成对象。 placement new 的语法格式如下： new(address) ClassConstruct(…) address 表示已有内存的地址，该内存可以在栈上，也可以在堆上；ClassConstruct(…) 表示调用类的构造函数，如果构造函数没有参数，也可以省略括号。 placement new 利用已经申请好的内存来生成对象，它不再为对象分配新的内存，而是将对象数据放在 address 指定的内存中。在本例中，placement new 使用的是 s 的内存空间。 非受限联合体的匿名声明和“枚举式类” 匿名联合体是指不具名的联合体（也即没有名字的联合体），一般定义如下： union U{ union { int x; }; //此联合体为匿名联合体 }; 可以看到，联合体 U 内定义了一个不具名的联合体，该联合体包含一个 int 类型的成员变量，我们称这个联合体为匿名联合体。 同样的，非受限联合体也可以匿名，而当非受限的匿名联合体运用于类的声明时，这样的类被称为“枚举式类”。示例如下： #include \u003ccstring\u003e using namespace std; class Student{ public: Student(bool g, int a): gender(g), age(a){} bool gender; int age; }; class Singer { public: enum Type { STUDENT, NATIVE, FOREIGENR }; Singer(bool g, int a) : s(g, a) { t = STUDENT; } Singer(int i) : id(i) { t = NATIVE; } Singer(const char* n, int s) { int size = (s \u003e 9) ? 9 : s; memcpy(name , n, size); name[s] = '\\0'; t = FOREIGENR; } ~Singer(){} private: Type t; union { Student s; int id; char name[10]; }; }; int main() { Singer(true, 13); Singer(310217); Singer(\"J Michael\", 9); return 0; } 上面的代码中使用了一个匿名非受限联合体，它作为类 Singer 的“变长成员”来使用，这样的变长成员给类的编写带来了更大的灵活性，这是 C++98 标准中无法达到的（编译器会报member ‘Student Singer::::s’ with constructor not allowed in union错误）。 ","date":"2023-07-12","objectID":"/posts/newfeature/:1:13","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] for循环（基于范围的循环）详解 C++ 11标准之前（C++ 98/03 标准），如果要用 for 循环语句遍历一个数组或者容器，只能套用如下结构： for (表达式 1; 表达式 2; 表达式 3) { //循环体 } 例如，下面程序演示了用上述结构遍历数组和容器的具体实现过程（实例一）: #include \u003ciostream\u003e #include \u003cvector\u003e #include \u003cstring.h\u003e using namespace std; int main() { char arc[] = \"http://c.biancheng.net/cplus/11/\"; int i; //for循环遍历普通数组 for (i = 0; i \u003c strlen(arc); i++) { cout \u003c\u003c arc[i]; } cout \u003c\u003c endl; vector\u003cchar\u003emyvector(arc,arc+23); vector\u003cchar\u003e::iterator iter; //for循环遍历 vector 容器 for (iter = myvector.begin(); iter != myvector.end(); ++iter) { cout \u003c\u003c *iter; } return 0; } 程序执行结果为： http://c.biancheng.net/cplus/11/ http://c.biancheng.net/ 此示例中，vector 为 STL 标准库提供的序列式容器，关于该容器的具体用法，可阅读《C++ STL vector容器详解》一节，这里不再做重复赘述。 而 C++ 11 标准中，除了可以沿用前面介绍的用法外，还为 for 循环添加了一种全新的语法格式，如下所示： for (declaration : expression){ //循环体 } 其中，两个参数各自的含义如下: declaration：表示此处要定义一个变量，该变量的类型为要遍历序列中存储元素的类型。需要注意的是，C++ 11 标准中，declaration参数处定义的变量类型可以用 auto 关键字表示，该关键字可以使编译器自行推导该变量的数据类型。 expression：表示要遍历的序列，常见的可以为事先定义好的普通数组或者容器，还可以是用 {} 大括号初始化的序列。 可以看到，同 C++ 98/03 中 for 循环的语法格式相比较，此格式并没有明确限定 for 循环的遍历范围，这是它们最大的区别，即旧格式的 for 循环可以指定循环的范围，而 C++11 标准增加的 for 循环，只会逐个遍历 expression 参数处指定序列中的每个元素。 下面程序演示了如何用 C++ 11 标准中的 for 循环遍历实例一定义的 arc 数组和 myvector 容器： #include \u003ciostream\u003e #include \u003cvector\u003e using namespace std; int main() { char arc[] = \"http://c.biancheng.net/cplus/11/\"; //for循环遍历普通数组 for (char ch : arc) { cout \u003c\u003c ch; } cout \u003c\u003c '!' \u003c\u003c endl; vector\u003cchar\u003emyvector(arc, arc + 23); //for循环遍历 vector 容器 for (auto ch : myvector) { cout \u003c\u003c ch; } cout \u003c\u003c '!'; return 0; } 程序执行结果为： http://c.biancheng.net/cplus/11/ ! http://c.biancheng.net/! 这里有以下 2 点需要说明： 1. 程序中在遍历 myvector 容器时，定义了 auto 类型的 ch 变量，当编译器编译程序时，会通过 myvector 容器中存储的元素类型自动推导出 ch 为 char 类型。注意，这里的 ch 不是迭代器类型，而表示的是 myvector 容器中存储的每个元素。 2. 仔细观察程序的输出结果，其中第一行输出的字符串和 “!” 之间还输出有一个空格，这是因为新格式的 for 循环在遍历字符串序列时，不只是遍历到最后一个字符，还会遍历位于该字符串末尾的 ‘\\0’（字符串的结束标志）。之所以第二行输出的字符串和 “!” 之间没有空格，是因为 myvector 容器中没有存储 ‘\\0’。 除此之外，新语法格式的 for 循环还支持遍历用{ }大括号初始化的列表，比如： #include \u003ciostream\u003e using namespace std; int main() { for (int num : {1, 2, 3, 4, 5}) { cout \u003c\u003c num \u003c\u003c \" \"; } return 0; } 程序执行结果为： 1 2 3 4 5 另外值得一提的是，在使用新语法格式的 for 循环遍历某个序列时，如果需要遍历的同时修改序列中元素的值，实现方案是在 declaration 参数处定义引用形式的变量。举个例子： #include \u003ciostream\u003e #include \u003cvector\u003e using namespace std; int main() { char arc[] = \"abcde\"; vector\u003cchar\u003emyvector(arc, arc + 5); //for循环遍历并修改容器中各个字符的值 for (auto \u0026ch : myvector) { ch++; } //for循环遍历输出容器中各个字符 for (auto ch : myvector) { cout \u003c\u003c ch; } return 0; } 程序执行结果为： bcdef 此程序中先后使用了 2 个新语法格式的 for 循环，其中前者用于修改 myvector 容器中各个元素的值，后者用于输出修改后的 myvector 容器中的各个元素。 有读者可能会问，declaration 参数既可以定义普通形式的变量，也可以定义引用形式的变量，应该如何选择呢？其实很简单，如果需要在遍历序列的过程中修改器内部元素的值，就必须定义引用形式的变量；反之，建议定义const \u0026（常引用）形式的变量（避免了底层复制变量的过程，效率更高），也可以定义普通变量。 ","date":"2023-07-12","objectID":"/posts/newfeature/:1:14","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] for循环使用注意事项 《C++11 for循环》一节已经详细介绍了 C++11 标准中 for 循环的基本用法。在此基础上，本节将介绍一些 for 循环的使用注意事项，帮助读者更准确高效地使用基于范围的 for 循环。 首先需要明确的一点是，当使用 for 循环遍历某个序列时，无论该序列是普通数组、容器还是用{ }大括号包裹的初始化列表，遍历序列的变量都表示的是当前序列中的各个元素。 举个例子： #include \u003ciostream\u003e #include \u003cvector\u003e using namespace std; int main() { //for循环遍历初始化列表 for (int ch : {1,2,3,4,5}) { cout \u003c\u003c ch; } cout \u003c\u003c endl; //for循环遍历普通数组 char arc[] = \"http://c.biancheng.net/cplus/11/\"; for (char ch : arc) { cout \u003c\u003c ch; } cout \u003c\u003c endl; //for循环遍历 vector 容器 vector\u003cchar\u003emyvector(arc, arc + 23); for (auto ch : myvector) { cout \u003c\u003c ch; } return 0; } 程序执行结果为： 12345 http://c.biancheng.net/cplus/11/ http://c.biancheng.net/ 上面程序演示了用 for 循环遍历 3 种序列的过程，其中前两种情况很容易理解，但对于用基于范围的 for 循环遍历容器中的元素，很多读者会将 ch 误认为指向各个元素的迭代器，其实不然，它表示的仍是容器中的各个元素。 为了加深读者对遍历容器的理解，下面程序以 map 容器为例，再举一个例子： #include \u003ciostream\u003e #include \u003cmap\u003e #include \u003cstring\u003e using namespace std; int main() { map\u003cstring, string\u003emymap{ {\"C++11\",\"http://c.biancheng.net/cplus/11/\"}, {\"Python\",\"http://c.biancheng.net/python/\"}, {\"Java\",\"http://c.biancheng.net/java/\"} }; for (pair\u003cstring,string\u003e ch : mymap) { cout \u003c\u003c ch.first \u003c\u003c \" \" \u003c\u003c ch.second \u003c\u003c endl; } return 0; } 程序执行结果为： C++11 http://c.biancheng.net/cplus/11/ Java http://c.biancheng.net/java/ Python http://c.biancheng.net/python/ 要知道，map 容器中存储的不再是普通数据类型的数据，而是 pair 类型的数据，因此程序中在使用基于范围的 for 循环遍历 map 容器时，定义的是 pair 类型的变量。 值得初学者注意的一点是，基于范围的 for 循环也可以直接遍历某个字符串，比如： for (char ch : \"http://c.biancheng.net/cplus/11/\") { cout \u003c\u003c ch; } 前面提到，普通数组可以作为被遍历的序列。拿此程序中的字符串来说，其数据类型为const char[33]，即在编译器看来字符串就是一个普通数组，因此完全可以直接作为被遍历的序列。 当然，基于范围的 for 循环也可以遍历 string 类型的字符串，这种情况下冒号前定义 char 类型的变量即可。 总的来说，基于范围的 for 循环可以遍历普通数组、string字符串、容器以及初始化列表。除此之外，for 循环冒号后还可以放置返回 string 字符串以及容器对象的函数，比如： #include \u003ciostream\u003e #include \u003cvector\u003e #include \u003cstring\u003e using namespace std; string str = \"http://c.biancheng.net/cplus/11/\"; vector\u003cint\u003e myvector = { 1,2,3,4,5 }; string retStr() { return str; } vector\u003cint\u003e retVector() { return myvector; } int main() { //遍历函数返回的 string 字符串 for (char ch : retStr()) { cout \u003c\u003c ch; } cout \u003c\u003c endl; //遍历函数返回的 vector 容器 for (int num : retVector()) { cout \u003c\u003c num \u003c\u003c \" \"; } return 0; } 程序执行结果为： http://c.biancheng.net/cplus/11/ 1 2 3 4 5 注意，基于范围的 for 循环不支持遍历函数返回的以指针形式表示的数组，比如： //错误示例 #include \u003ciostream\u003e using namespace std; char str[] = \"http://c.biancheng.net/cplus/11/\"; char* retStr() { return str; } int main() { for (char ch : retStr()) //直接报错 { cout \u003c\u003c ch; } return 0; } 原因很简单，此格式的 for 循环只能遍历有明确范围的一组数据，上面程序中 retStr() 函数返回的是指针变量，遍历范围并未明确指明，所以编译失败。 值得一提的是，当基于范围的 for 循环遍历的是某函数返回的 string 对象或者容器时，整个遍历过程中，函数只会执行一次。 举个例子: #include \u003ciostream\u003e #include \u003cstring\u003e using namespace std; string str= \"http://c.biancheng.net/cplus/11/\"; string retStr() { cout \u003c\u003c \"retStr:\" \u003c\u003c endl; return str; } int main() { //遍历函数返回的 string 字符串 for (char ch : retStr()) { cout \u003c\u003c ch; } return 0; } 程序执行结果为： retStr: http://c.biancheng.net/cplus/11/ 借助执行结果不难分析出，整个 for 循环遍历 str 字符串对象的过程中，retStr() 函数仅在遍历开始前执行了 1 次。 系统学过 STL 标准库的读者应该知道，基于关联式容器（包括哈希容器）底层存储机制的限制： 不允许修改 map、unordered_map、multimap 以及 unordered_multimap 容器存储的键的值； 不允许修改 set、unordered_set、multiset 以及 unordered_multiset 容器中存储的元素的值。 关于以上各个容器的具体用法，读者可猛击《C++ STL教程》进行系统学习。 因此，当使用基于范围的 for 循环遍历此类型容器时，切勿修改容器中不允许被修改的数据部分，否则会导致程序的执行出现各种 Bug。 另外，基于范围的 for 循环完成对容器的遍历，其底层也是借助容器的迭代器实现的。举个例子： #include \u003ciostream\u003e #include \u003cvector\u003e int main(void) { std::vector\u003cint\u003earr = { 1, 2, 3, 4, 5 }; for (auto val : arr) { std::cout \u003c\u003c val \u003c\u003c std::endl; arr.push_back(10); //向容器中添加元素 } return 0; } 程序执行结果可能为（输出结果不唯一）： 1 -572662307 -572662307 4 5 可以看到，程序的执行结果并不是我们想要的。就是因为在 for 循环遍历 arr 容器的同时向该容器尾部添加了新的元素（对 arr 容器进行了扩增），致使遍历容器所使用的迭代器失效，整个遍历过程出现错误。 如果读者想要彻底搞清楚程序执行失败的原因，读了解 vector 容器的底层存储机制，可阅读《C++ vector容器底层实现机制》一文。 因此，在使用基于范围的 for 循环遍历容器时，应避免在循环体中修改容器存储元素的个数。 ","date":"2023-07-12","objectID":"/posts/newfeature/:1:15","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] constexpr：验证是否为常量表达式（长篇神文） constexpr 是 C++ 11 标准新引入的关键字，不过在讲解其具体用法和功能之前，读者需要先搞清楚 C++ 常量表达式的含义。 所谓常量表达式，指的就是由多个（≥1）常量组成的表达式。换句话说，如果表达式中的成员都是常量，那么该表达式就是一个常量表达式。这也意味着，常量表达式一旦确定，其值将无法修改。 实际开发中，我们经常会用到常量表达式。以定义数组为例，数组的长度就必须是一个常量表达式: // 1) int url[10];//正确 // 2) int url[6 + 4];//正确 // 3) int length = 6; int url[length];//错误，length是变量 上述代码演示了 3 种定义 url 数组的方式，其中第 1、2 种定义 url 数组时，长度分别为 10 和 6+4，显然它们都是常量表达式，可以用于表示数组的长度；第 3 种 url 数组的长度为 length，它是变量而非常量，因此不是一个常量表达式，无法用于表示数组的长度。 常量表达式的应用场景还有很多，比如匿名枚举、switch-case 结构中的 case 表达式等，感兴趣的读者可自行编码测试，这里不再过多举例。 我们知道，C++ 程序的执行过程大致要经历编译、链接、运行这 3 个阶段。值得一提的是，常量表达式和非常量表达式的计算时机不同，非常量表达式只能在程序运行阶段计算出结果；而常量表达式的计算往往发生在程序的编译阶段，这可以极大提高程序的执行效率，因为表达式只需要在编译阶段计算一次，节省了每次程序运行时都需要计算一次的时间。 对于用 C++ 编写的程序，性能往往是永恒的追求。那么在实际开发中，如何才能判定一个表达式是否为常量表达式，进而获得在编译阶段即可执行的“特权”呢？除了人为判定外，C++11 标准还提供有 constexpr 关键字。 constexpr 关键字的功能是使指定的常量表达式获得在程序编译阶段计算出结果的能力，而不必等到程序运行阶段。C++ 11 标准中，constexpr 可用于修饰普通变量、函数（包括模板函数）以及类的构造函数。 注意，获得在编译阶段计算出结果的能力，并不代表 constexpr 修饰的表达式一定会在程序编译阶段被执行，具体的计算时机还是编译器说了算。 constexpr修饰普通变量 C++11 标准中，定义变量时可以用 constexpr 修饰，从而使该变量获得在编译阶段即可计算出结果的能力。 值得一提的是，使用 constexpr 修改普通变量时，变量必须经过初始化且初始值必须是一个常量表达式。举个例子： #include \u003ciostream\u003e using namespace std; int main() { constexpr int num = 1 + 2 + 3; int url[num] = {1,2,3,4,5,6}; couts\u003c\u003c url[1] \u003c\u003c endl; return 0; } 程序执行结果为： 2 读者可尝试将 constexpr 删除，此时编译器会提示“url[num] 定义中 num 不可用作常量”。 可以看到，程序第 6 行使用 constexpr 修饰 num 变量，同时将 “1+2+3” 这个常量表达式赋值给 num。由此，编译器就可以在编译时期对 num 这个表达式进行计算，因为 num 可以作为定义数组时的长度。 有读者可能发现，将此示例程序中的 constexpr 用 const 关键字替换也可以正常执行，这是因为 num 的定义同时满足“num 是 const 常量且使用常量表达式为其初始化”这 2 个条件，由此编译器会认定 num 是一个常量表达式。 注意，const 和 constexpr 并不相同，关于它们的区别，我们会在下一节做详细讲解。 另外需要重点提出的是，当常量表达式中包含浮点数时，考虑到程序编译和运行所在的系统环境可能不同，常量表达式在编译阶段和运行阶段计算出的结果精度很可能会受到影响，因此 C++11 标准规定，浮点常量表达式在编译阶段计算的精度要至少等于（或者高于）运行阶段计算出的精度。 constexpr修饰函数 constexpr 还可以用于修饰函数的返回值，这样的函数又称为“常量表达式函数”。 注意，constexpr 并非可以修改任意函数的返回值。换句话说，一个函数要想成为常量表达式函数，必须满足如下 4 个条件。 整个函数的函数体中，除了可以包含 using 指令、typedef 语句以及 static_assert 断言外，只能包含一条 return 返回语句。 举个例子： constexpr int display(int x) { int ret = 1 + 2 + x; return ret; } 注意，这个函数是无法通过编译的，因为该函数的返回值用 constexpr 修饰，但函数内部包含多条语句。 如下是正确的定义 display() 常量表达式函数的写法： constexpr int display(int x) { //可以添加 using 执行、typedef 语句以及 static_assert 断言 return 1 + 2 + x; } 可以看到，display() 函数的返回值是用 constexpr 修饰的 int 类型值，且该函数的函数体中只包含一个 return 语句。 该函数必须有返回值，即函数的返回值类型不能是 void。 举个例子： constexpr void display() { //函数体 } 像上面这样定义的返回值类型为 void 的函数，不属于常量表达式函数。原因很简单，因为通过类似的函数根本无法获得一个常量。 函数在使用之前，必须有对应的定义语句。我们知道，函数的使用分为“声明”和“定义”两部分，普通的函数调用只需要提前写好该函数的声明部分即可（函数的定义部分可以放在调用位置之后甚至其它文件中），但常量表达式函数在使用前，必须要有该函数的定义。 举个例子： #include \u003ciostream\u003e using namespace std; //普通函数的声明 int noconst_dis(int x); //常量表达式函数的声明 constexpr int display(int x); //常量表达式函数的定义 constexpr int display(int x){ return 1 + 2 + x; } int main() { //调用常量表达式函数 int a[display(3)] = { 1,2,3,4 }; cout \u003c\u003c a[2] \u003c\u003c endl; //调用普通函数 cout \u003c\u003c noconst_dis(3) \u003c\u003c endl; return 0; } //普通函数的定义 int noconst_dis(int x) { return 1 + 2 + x; } 程序执行结果为： 3 6 读者可自行将 display() 常量表达式函数的定义调整到 main() 函数之后，查看编译器的报错信息。 可以看到，普通函数在调用时，只需要保证调用位置之前有相应的声明即可；而常量表达式函数则不同，调用位置之前必须要有该函数的定义，否则会导致程序编译失败。 return 返回的表达式必须是常量表达式，举个例子： #include \u003ciostream\u003e using namespace std; int num = 3; constexpr int display(int x){ return num + x; } int main() { //调用常量表达式函数 int a[display(3)] = { 1,2,3,4 }; return 0; } 该程序无法通过编译，编译器报“display(3) 的结果不是常量”的异常。 常量表达式函数的返回值必须是常量表达式的原因很简单，如果想在程序编译阶段获得某个函数返回的常量，则该函数的 return 语句中就不能包含程序运行阶段才能确定值的变量。 注意，在常量表达式函数的 return 语句中，不能包含赋值的操作（例如 return x=1 在常量表达式函数中不允许的）。另外，用 constexpr 修改函数时，函数本身也是支持递归的，感兴趣的读者可自行尝试编码测试。 constexpr修饰类的构造函数 对于 C++ 内置类型的数据，可以直接用 constexpr 修饰，但如果是自定义的数据类型（用 struct 或者 class 实现），直接用 constexpr 修饰是不行的。 举个例子： #include \u003ciostream\u003e using namespace std; //自定义类型的定义 constexpr struct myType { const char* name; int age; //其它结构体成员 }; int main() { constexpr struct myType mt { \"zhangsan\", 10 }; cout \u003c\u003c mt.name \u003c\u003c \" \" \u003c\u003c mt.age \u003c\u003c endl; return 0; } 此程序是无法通过编译的，编译器会抛出“constexpr不能修饰自定义类型”的异常。 当我们想自定义一个可产生常量的类型时，正确的做法是在该类型的内部添加一个常量构造函数。例如，修改上面的错误示例如下： #include \u003ciostream\u003e using namespace std; //自定义类型的定义 s","date":"2023-07-12","objectID":"/posts/newfeature/:1:16","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] constexpr和const的区别 《C++11 constexpr》一节中，详细讲解了 constexpr 关键字的功能和用法。一些读者在学习过程中，经常会把 const 和 constexpr 搞混，不知道什么时候用 const，什么时候用 constexpr。本节就带领大家对 const 和 constexpr 做系统地区分。 我们知道，constexpr 是 C++ 11 标准新添加的关键字，在此之前（C++ 98/03标准）只有 const 关键字，其在实际使用中经常会表现出两种不同的语义。举个例子： #include \u003ciostream\u003e #include \u003carray\u003e using namespace std; void dis_1(const int x){ //错误，x是只读的变量 array \u003cint,x\u003e myarr{1,2,3,4,5}; cout \u003c\u003c myarr[1] \u003c\u003c endl; } void dis_2(){ const int x = 5; array \u003cint,x\u003e myarr{1,2,3,4,5}; cout \u003c\u003c myarr[1] \u003c\u003c endl; } int main() { dis_1(5); dis_2(); } 可以看到，dis_1() 和 dis_2() 函数中都包含一个 const int x，但 dis_1() 函数中的 x 无法完成初始化 array 容器的任务，而 dis_2() 函数中的 x 却可以。 这是因为，dis_1() 函数中的“const int x”只是想强调 x 是一个只读的变量，其本质仍为变量，无法用来初始化 array 容器；而 dis_2() 函数中的“const int x”，表明 x 是一个只读变量的同时，x 还是一个值为 5 的常量，所以可以用来初始化 array 容器。 C++ 11标准中，为了解决 const 关键字的双重语义问题，保留了 const 表示“只读”的语义，而将“常量”的语义划分给了新添加的 constexpr 关键字。因此 C++11 标准中，建议将 const 和 constexpr 的功能区分开，即凡是表达“只读”语义的场景都使用 const，表达“常量”语义的场景都使用 constexpr。 在上面的实例程序中，dis_2() 函数中使用 const int x 是不规范的，应使用 constexpr 关键字。 有读者可能会问，“只读”不就意味着其不能被修改吗？答案是否定的，“只读”和“不允许被修改”之间并没有必然的联系，举个例子： #include \u003ciostream\u003e using namespace std; int main() { int a = 10; const int \u0026 con_b = a; cout \u003c\u003c con_b \u003c\u003c endl; a = 20; cout \u003c\u003c con_b \u003c\u003c endl; } 程序执行结果为： 10 20 可以看到，程序中用 const 修饰了 con_b 变量，表示该变量“只读”，即无法通过变量自身去修改自己的值。但这并不意味着 con_b 的值不能借助其它变量间接改变，通过改变 a 的值就可以使 con_b 的值发生变化。 在大部分实际场景中，const 和 constexpr 是可以混用的，例如： const int a = 5 + 4; constexpr int a = 5 + 4; 它们是完全等价的，都可以在程序的编译阶段计算出结果。但在某些场景中，必须明确使用 constexpr，例如： #include \u003ciostream\u003e #include \u003carray\u003e using namespace std; constexpr int sqr1(int arg){ return arg*arg; } const int sqr2(int arg){ return arg*arg; } int main() { array\u003cint,sqr1(10)\u003e mylist1;//可以，因为sqr1时constexpr函数 array\u003cint,sqr2(10)\u003e mylist1;//不可以，因为sqr2不是constexpr函数 return 0; } 其中，因为 sqr2() 函数的返回值仅有 const 修饰，而没有用更明确的 constexpr 修饰，导致其无法用于初始化 array 容器（只有常量才能初始化 array 容器）。 总的来说在 C++ 11 标准中，const 用于为修饰的变量添加“只读”属性；而 constexpr 关键字则用于指明其后是一个常量（或者常量表达式），编译器在编译程序时可以顺带将其结果计算出来，而无需等到程序运行阶段，这样的优化极大地提高了程序的执行效率。 ","date":"2023-07-12","objectID":"/posts/newfeature/:1:17","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] long long超长整形详解 C++ 11 标准中，基于整数大小的考虑，共提供了如表 1 所示的这些数据类型。与此同时，标准中还明确限定了各个数据类型最少占用的位数。 整数类型 等价类型 C++11标准规定占用最少位数 |short|short int(有符号短整型)|至少 16 位（2 个字节）| |signed short||| |signed short int||| |unsigned short|unsigned short int（无符号短整型）|| |unsigned short int||| |int|int(有符号整形)|至少 16 位（2 个字节）| |signed||| |signed int||| |unsigned|unsigned int(无符号整形)|| |unsigned int||| |long|long int(有符号长整形)|至少 32 位（4 个字节）| |long int||| |signed long||| |signed long int||| |unsigned long|unsigned long int(无符号长整形)|| |unsigned long int||| |long long (C++11)|long long int（有符号超长整形）|至少 64 位(8 个字节)| |long long int (C++11)||| |signed long long (C++11)||| |signed long long int (C++11)||| |unsigned long long (C++11)|unsigned long long int（无符号超长整型）|| |unsigned long long int (C++11)||| C++11 标准规定，每种整数类型必须同时具备有符号（signed）和无符号（unsigned）两种类型，且每种具体的有符号整形和无符号整形所占用的存储空间（也就是位数）必须相同。注意，C++11 标准中只限定了每种类型最少占用多少存储空间，不同的平台可以占用不同的存储空间。 在表 1 罗列的这些数据类型中，long long 超长整型是 C++ 11 标准新添加的，接下来就对该整数类型做具体的介绍。 说道 C++ 标准委员会将 long long 整形写入 C++ 11 标准中，其实早在 1995 年，就有人提议将 long long 整形写入 C++ 98 标准，但被委员会拒绝了。而后 long long 整形被 C99 标准（C语言标准之一）采纳，并逐渐被很多编译器支持，于是 C++ 标准委员会重新决定将 long long 整形写入 C++ 11 标准中。 如同 long 类型整数需明确标注 “L” 或者 “l” 后缀一样，要使用 long long 类型的整数，也必须标注对应的后缀： 对于有符号 long long 整形，后缀用 “LL” 或者 “ll” 标识。例如，“10LL” 就表示有符号超长整数 10； 对于无符号 long long 整形，后缀用 “ULL”、“ull”、“Ull” 或者 “uLL” 标识。例如，“10ULL” 就表示无符号超长整数 10； 如果不添加任何标识，则所有的整数都会默认为 int 类型。 对于任意一种数据类型，读者可能更关心的是此类型的取值范围。对于 long long 类型来说，如果想了解当前平台上 long long 整形的取值范围，可以使用\u003cclimits\u003e头文件中与 long long 整形相关的 3 个宏，分别为 LLONG_MIN、LLONG_MAX 和 ULLONG_MIN： 1.LLONG_MIN：代表当前平台上最小的 long long 类型整数； 2.LLONG_MAX：代表当前平台上最大的 long long 类型整数； 3.ULLONG_MIN：代表当前平台上最大的 unsigned long long 类型整数（无符号超长整型的最小值为 0）； 举个例子： #include \u003ciostream\u003e #include \u003ciomanip\u003e #include \u003cclimits\u003e using namespace std; int main() { cout \u003c\u003c\"long long最大值：\" \u003c\u003c LLONG_MIN \u003c\u003c\" \"\u003c\u003c hex \u003c\u003c LLONG_MIN \u003c\u003c\"\\n\"; cout \u003c\u003c dec \u003c\u003c\"long long最小值：\" \u003c\u003c LLONG_MAX \u003c\u003c \" \" \u003c\u003c hex \u003c\u003c LLONG_MAX \u003c\u003c \"\\n\"; cout \u003c\u003c dec \u003c\u003c \"unsigned long long最大值：\" \u003c\u003c ULLONG_MAX \u003c\u003c \" \" \u003c\u003c hex \u003c\u003c ULLONG_MAX; return 0; } 程序执行结果为（不唯一）： long long最大值：-9223372036854775808 8000000000000000 long long最小值：9223372036854775807 7fffffffffffffff unsigned long long最大值：18446744073709551615 ffffffffffffffff 关于整形在内存中到底是如何存储的，读者可阅读《整数在内存中是如何存储的，为什么它堪称天才般的设计》一节。 此程序中，输出了各最大值和最小值对应的十六进制，显然在当前平台（Windows10 64位操作系统）上，long long 超长整型占用 64 位（也就是 16 个字节）的存储空间。读者可自行在自己的机器上运行此段代码，即可轻松得知 long long 类型在自己机器上所占用的字节数。 ","date":"2023-07-12","objectID":"/posts/newfeature/:1:18","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] C++11右值引用（一看即懂） (《C++11是什么》)[http://c.biancheng.net/view/7751.html]一节中提到，在 C++98/03 标准的基础上，C++11 标准对 C++ 语言增添了约 140 个新特性。本节要讲的右值引用就是众多新特性中的一个，同时也是最重要的特性之一。 很多初学者都感觉右值引用晦涩难懂，其实不然。右值引用只不过是一种新的 C++ 语法，真正理解起来有难度的是基于右值引用引申出的 2 种 C++ 编程技巧，分别为移动语义和完美转发。本节先给读者讲解什么是右值引用以及它的基本用法，至于移动语义和完美转发则放到后续章节讲解。 在 C++ 或者 C 语言中，一个表达式（可以是字面量、变量、对象、函数的返回值等）根据其使用场景不同，分为左值表达式和右值表达式。确切的说 C++ 中左值和右值的概念是从 C 语言继承过来的。 值得一提的是，左值的英文简写为“lvalue”，右值的英文简写为“rvalue”。很多人认为它们分别是\"left value”、“right value” 的缩写，其实不然。lvalue 是“loactor value”的缩写，可意为存储在内存中、有明确存储地址（可寻址）的数据，而 rvalue 译为 “read value”，指的是那些可以提供数据值的数据（不一定可以寻址，例如存储于寄存器中的数据）。 通常情况下，判断某个表达式是左值还是右值，最常用的有以下 2 种方法。 可位于赋值号（=）左侧的表达式就是左值；反之，只能位于赋值号右侧的表达式就是右值。举个例子: int a = 5; 5 = a; //错误，5 不能为左值 其中，变量 a 就是一个左值，而字面量 5 就是一个右值。值得一提的是，C++ 中的左值也可以当做右值使用，例如： int b = 10; // b 是一个左值 a = b; // a、b 都是左值，只不过将 b 可以当做右值使用 有名称的、可以获取到存储地址的表达式即为左值；反之则是右值。 以上面定义的变量 a、b 为例，a 和 b 是变量名，且通过 \u0026a 和 \u0026b 可以获得他们的存储地址，因此 a 和 b 都是左值；反之，字面量 5、10，它们既没有名称，也无法获取其存储地址（字面量通常存储在寄存器中，或者和代码存储在一起），因此 5、10 都是右值。 注意，以上 2 种判定方法只适用于大部分场景。由于本节主要讲解右值引用，因此这里适可而止，不再对 C++ 左值和右值做深度剖析，感兴趣的读者可自行研究。 C++右值引用 前面提到，其实 C++98/03 标准中就有引用，使用 “\u0026” 表示。但此种引用方式有一个缺陷，即正常情况下只能操作 C++ 中的左值，无法对右值添加引用。举个例子： int num = 10; int \u0026b = num; //正确 int \u0026c = 10; //错误 如上所示，编译器允许我们为 num 左值建立一个引用，但不可以为 10 这个右值建立引用。因此，C++98/03 标准中的引用又称为左值引用。 注意，虽然 C++98/03 标准不支持为右值建立非常量左值引用，但允许使用常量左值引用操作右值。也就是说，常量左值引用既可以操作左值，也可以操作右值，例如： int num = 10; const int \u0026b = num; const int \u0026c = 10; 我们知道，右值往往是没有名称的，因此要使用它只能借助引用的方式。这就产生一个问题，实际开发中我们可能需要对右值进行修改（实现移动语义时就需要），显然左值引用的方式是行不通的。 为此，C++11 标准新引入了另一种引用方式，称为右值引用，用 “\u0026\u0026” 表示。 话说，C++标准委员会在选定右值引用符号时，既希望能选用现有 C++ 内部已有的符号，还不能与 C++ 98 /03 标准产生冲突，最终选定了 2 个 ‘\u0026’ 表示右值引用。 需要注意的，和声明左值引用一样，右值引用也必须立即进行初始化操作，且只能使用右值进行初始化，比如： int num = 10; const int \u0026b = num; const int \u0026c = 10; 和常量左值引用不同的是，右值引用还可以对右值进行修改。例如： int num = 10; //int \u0026\u0026 a = num; //右值引用不能初始化为左值 int \u0026\u0026 a = 10; 程序输出结果为 100。 另外值得一提的是，C++ 语法上是支持定义常量右值引用的，例如： int \u0026\u0026 a = 10; a = 100; cout \u003c\u003c a \u003c\u003c endl; 但这种定义出来的右值引用并无实际用处。一方面，右值引用主要用于移动语义和完美转发，其中前者需要有修改右值的权限；其次，常量右值引用的作用就是引用一个不可修改的右值，这项工作完全可以交给常量左值引用完成。 学到这里，一些读者可能无法记清楚左值引用和右值引用各自可以引用左值还是右值，这里给大家一张表格，方便大家记忆： 引用类型 可以引用的值类型 使用场景 非常量左值 常量左值 非常量右值 常量右值 非常量左值引用 Y N N N 无 常量左值引用 Y Y Y Y 常用于类中构建拷贝构造函数 非常量右值引用 N N Y N 移动语义、完美转发 常量右值引用 N N Y Y 无实际用途 表中，Y 表示支持，N 表示不支持。 其实，C++11 标准中对右值做了更细致的划分，分别称为纯右值（Pure value，简称 pvalue）和将亡值（eXpiring value，简称 xvalue ）。其中纯右值就是 C++98/03 标准中的右值（本节中已经做了大篇幅的讲解），而将亡值则指的是和右值引用相关的表达式（比如某函数返回的 T \u0026\u0026 类型的表达式）。对于纯右值和将亡值，都属于右值，读者知道即可，不必深究。 ","date":"2023-07-12","objectID":"/posts/newfeature/:1:19","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] 移动构造函数的功能和用法 《C++11右值引用》一节中，给读者详细介绍了 C++ 右值引用的含义和用法，同时还提到“右值引用主要用于实现移动（move）语义和完美转发”。有关完美转发，后续章节会做详细介绍，本节主要讲解移动语义的含义以及实现它的方式。 C++11移动语义是什么 在 C++ 11 标准之前（C++ 98/03 标准中），如果想用其它对象初始化一个同类的新对象，只能借助类中的复制（拷贝）构造函数。通过《C++拷贝构造函数》一节的学习我们知道，拷贝构造函数的实现原理很简单，就是为新对象复制一份和其它对象一模一样的数据。 需要注意的是，当类中拥有指针类型的成员变量时，拷贝构造函数中需要以深拷贝（而非浅拷贝）的方式复制该指针成员。有关深拷贝和浅拷贝以及它们的区别，读者可阅读《C++深拷贝和浅拷贝》一文做详细了解。 举个例子： #include \u003ciostream\u003e using namespace std; class demo{ public: demo():num(new int(0)){ cout\u003c\u003c\"construct!\"\u003c\u003cendl; } //拷贝构造函数 demo(const demo \u0026d):num(new int(*d.num)){ cout\u003c\u003c\"copy construct!\"\u003c\u003cendl; } ~demo(){ cout\u003c\u003c\"class destruct!\"\u003c\u003cendl; } private: int *num; }; demo get_demo(){ return demo(); } int main(){ demo a = get_demo(); return 0; } 如上所示，我们为 demo 类自定义了一个拷贝构造函数。该函数在拷贝 d.num 指针成员时，必须采用深拷贝的方式，即拷贝该指针成员本身的同时，还要拷贝指针指向的内存资源。否则一旦多个对象中的指针成员指向同一块堆空间，这些对象析构时就会对该空间释放多次，这是不允许的。 可以看到，程序中定义了一个可返回 demo 对象的 get_demo() 函数，用于在 main() 主函数中初始化 a 对象，其整个初始化的流程包含以下几个阶段： 执行 get_demo() 函数内部的 demo() 语句，即调用 demo 类的默认构造函数生成一个匿名对象； 执行 return demo() 语句，会调用拷贝构造函数复制一份之前生成的匿名对象，并将其作为 get_demo() 函数的返回值（函数体执行完毕之前，匿名对象会被析构销毁）； 执行 a = get_demo() 语句，再调用一次拷贝构造函数，将之前拷贝得到的临时对象复制给 a（此行代码执行完毕，get_demo() 函数返回的对象会被析构）； 程序执行结束前，会自行调用 demo 类的析构函数销毁 a。 注意，目前多数编译器都会对程序中发生的拷贝操作进行优化，因此如果我们使用 VS 2017、codeblocks 等这些编译器运行此程序时，看到的往往是优化后的输出结果： construct! class destruct! 而同样的程序，如果在 Linux 上使用g++ demo.cpp -fno-elide-constructors命令运行（其中 demo.cpp 是程序文件的名称），就可以看到完整的输出结果： construct! \u003c-- 执行 demo() copy construct! \u003c-- 执行 return demo() class destruct! \u003c-- 销毁 demo() 产生的匿名对象 copy construct! \u003c-- 执行 a = get_demo() class destruct! \u003c-- 销毁 get_demo() 返回的临时对象 class destruct! \u003c-- 销毁 a 如上所示，利用拷贝构造函数实现对 a 对象的初始化，底层实际上进行了 2 次拷贝（而且是深拷贝）操作。当然，对于仅申请少量堆空间的临时对象来说，深拷贝的执行效率依旧可以接受，但如果临时对象中的指针成员申请了大量的堆空间，那么 2 次深拷贝操作势必会影响 a 对象初始化的执行效率。 事实上，此问题一直存留在以 C++ 98/03 标准编写的 C++ 程序中。由于临时变量的产生、销毁以及发生的拷贝操作本身就是很隐晦的（编译器对这些过程做了专门的优化），且并不会影响程序的正确性，因此很少进入程序员的视野。 那么当类中包含指针类型的成员变量，使用其它对象来初始化同类对象时，怎样才能避免深拷贝导致的效率问题呢？C++11 标准引入了解决方案，该标准中引入了右值引用的语法，借助它可以实现移动语义。 C++移动构造函数（移动语义的具体实现） 所谓移动语义，指的就是以移动而非深拷贝的方式初始化含有指针成员的类对象。简单的理解，移动语义指的就是将其他对象（通常是临时对象）拥有的内存资源“移为已用”。 以前面程序中的 demo 类为例，该类的成员都包含一个整形的指针成员，其默认指向的是容纳一个整形变量的堆空间。当使用 get_demo() 函数返回的临时对象初始化 a 时，我们只需要将临时对象的 num 指针直接浅拷贝给 a.num，然后修改该临时对象中 num 指针的指向（通常另其指向 NULL），这样就完成了 a.num 的初始化。 事实上，对于程序执行过程中产生的临时对象，往往只用于传递数据（没有其它的用处），并且会很快会被销毁。因此在使用临时对象初始化新对象时，我们可以将其包含的指针成员指向的内存资源直接移给新对象所有，无需再新拷贝一份，这大大提高了初始化的执行效率。 例如，下面程序对 demo 类进行了修改： #include \u003ciostream\u003e using namespace std; class demo{ public: demo():num(new int(0)){ cout\u003c\u003c\"construct!\"\u003c\u003cendl; } demo(const demo \u0026d):num(new int(*d.num)){ cout\u003c\u003c\"copy construct!\"\u003c\u003cendl; } //添加移动构造函数 demo(demo \u0026\u0026d):num(d.num){ d.num = NULL; cout\u003c\u003c\"move construct!\"\u003c\u003cendl; } ~demo(){ cout\u003c\u003c\"class destruct!\"\u003c\u003cendl; } private: int *num; }; demo get_demo(){ return demo(); } int main(){ demo a = get_demo(); return 0; } 可以看到，在之前 demo 类的基础上，我们又手动为其添加了一个构造函数。和其它构造函数不同，此构造函数使用右值引用形式的参数，又称为移动构造函数。并且在此构造函数中，num 指针变量采用的是浅拷贝的复制方式，同时在函数内部重置了 d.num，有效避免了“同一块对空间被释放多次”情况的发生。 在 Linux 系统中使用g++ demo.cpp -o demo.exe -std=c++0x -fno-elide-constructors命令执行此程序，输出结果为： construct! move construct! class destruct! move construct! class destruct! class destruct! 通过执行结果我们不难得知，当为 demo 类添加移动构造函数之后，使用临时对象初始化 a 对象过程中产生的 2 次拷贝操作，都转由移动构造函数完成。 我们知道，非 const 右值引用只能操作右值，程序执行结果中产生的临时对象（例如函数返回值、lambda 表达式等）既无名称也无法获取其存储地址，所以属于右值。当类中同时包含拷贝构造函数和移动构造函数时，如果使用临时对象初始化当前类的对象，编译器会优先调用移动构造函数来完成此操作。只有当类中没有合适的移动构造函数时，编译器才会退而求其次，调用拷贝构造函数。 在实际开发中，通常在类中自定义移动构造函数的同时，会再为其自定义一个适当的拷贝构造函数，由此当用户利用右值初始化类对象时，会调用移动构造函数；使用左值（非右值）初始化类对象时，会调用拷贝构造函数。 读者可能会问，如果使用左值初始化同类对象，但也想调用移动构造函数完成，有没有办法可以实现呢？ 默认情况下，左值初始化同类对象只能通过拷贝构造函数完成，如果想调用移动构造函数，则必须使用右值进行初始化。C++11 标准中为了满足用户使用左值初始化同类对象时也通过移动构造函数完成的需求，新引入了 std::move() 函数，它可以将左值强制转换成对应的右值，由此便可以使用移动构造函数。 有关 std::move() 函数的用法，后续章节会做详细讲解。 ","date":"2023-07-12","objectID":"/posts/newfeature/:1:20","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] move()函数：将左值强制转换为右值 通过学习 《C++11移动构造函数》一节我们知道，C++11 标准中借助右值引用可以为指定类添加移动构造函数，这样当使用该类的右值对象（可以理解为临时对象）初始化同类对象时，编译器会优先选择移动构造函数。 注意，移动构造函数的调用时机是：用同类的右值对象初始化新对象。那么，用当前类的左值对象（有名称，能获取其存储地址的实例对象）初始化同类对象时，是否就无法调用移动构造函数了呢？当然不是，C++11 标准中已经给出了解决方案，即调用 move() 函数。 move 本意为 “移动”，但该函数并不能移动任何数据，它的功能很简单，就是将某个左值强制转化为右值。 基于 move() 函数特殊的功能，其常用于实现移动语义。 move() 函数的用法也很简单，其语法格式如下： move(arg) 其中，arg 表示指定的左值对象。该函数会返回 arg 对象的右值形式。 【例 1】move() 函数的基础应用。 #include \u003ciostream\u003e using namespace std; class movedemo{ public: movedemo():num(new int(0)){ cout\u003c\u003c\"construct!\"\u003c\u003cendl; } //拷贝构造函数 movedemo(const movedemo \u0026d):num(new int(*d.num)){ cout\u003c\u003c\"copy construct!\"\u003c\u003cendl; } //移动构造函数 movedemo(movedemo \u0026\u0026d):num(d.num){ d.num = NULL; cout\u003c\u003c\"move construct!\"\u003c\u003cendl; } public: //这里应该是 private，使用 public 是为了更方便说明问题 int *num; }; int main(){ movedemo demo; cout \u003c\u003c \"demo2:\\n\"; movedemo demo2 = demo; //cout \u003c\u003c *demo2.num \u003c\u003c endl; //可以执行 cout \u003c\u003c \"demo3:\\n\"; movedemo demo3 = std::move(demo); //此时 demo.num = NULL，因此下面代码会报运行时错误 //cout \u003c\u003c *demo.num \u003c\u003c endl; return 0; } 程序执行结果为： construct! demo2: copy construct! demo3: move construct! 通过观察程序的输出结果，以及对比 demo2 和 demo3 初始化操作不难得知，demo 对象作为左值，直接用于初始化 demo2 对象，其底层调用的是拷贝构造函数；而通过调用 move() 函数可以得到 demo 对象的右值形式，用其初始化 demo3 对象，编译器会优先调用移动构造函数。 注意，调用拷贝构造函数，并不影响 demo 对象，但如果调用移动构造函数，由于函数内部会重置 demo.num 指针的指向为 NULL，所以程序中第 30 行代码会导致程序运行时发生错误。 【例 2】灵活使用 move() 函数。 #include \u003ciostream\u003e using namespace std; class first { public: first() :num(new int(0)) { cout \u003c\u003c \"construct!\" \u003c\u003c endl; } //移动构造函数 first(first \u0026\u0026d) :num(d.num) { d.num = NULL; cout \u003c\u003c \"first move construct!\" \u003c\u003c endl; } public: //这里应该是 private，使用 public 是为了更方便说明问题 int *num; }; class second { public: second() :fir() {} //用 first 类的移动构造函数初始化 fir second(second \u0026\u0026 sec) :fir(move(sec.fir)) { cout \u003c\u003c \"second move construct\" \u003c\u003c endl; } public: //这里也应该是 private，使用 public 是为了更方便说明问题 first fir; }; int main() { second oth; second oth2 = move(oth); //cout \u003c\u003c *oth.fir.num \u003c\u003c endl; //程序报运行时错误 return 0; } 程序执行结果为： construct! first move construct! second move construct 程序中分别构建了 first 和 second 这 2 个类，其中 second 类中包含一个 first 类对象。如果读者仔细观察不难发现，程序中使用了 2 此 move() 函数： 程序第 31 行：由于 oth 为左值，如果想调用移动构造函数为 oth2 初始化，需先利用 move() 函数生成一个 oth 的右值版本； 程序第 22 行：oth 对象内部还包含一个 first 类对象，对于 oth.fir 来说，其也是一个左值，所以在初始化 oth.fir 时，还需要再调用一次 move() 函数。 ","date":"2023-07-12","objectID":"/posts/newfeature/:1:21","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] 引用限定符的用法 在《C++右值引用》一节中，我们给您介绍了左值和右值。值得一提的是，左值和右值的区分也同样适用于类对象，本节中将左值的类对象称为左值对象，将右值的类对象称为右值对象。 默认情况下，对于类中用 public 修饰的成员函数，既可以被左值对象调用，也可以被右值对象调用。举个例子： #include \u003ciostream\u003e using namespace std; class demo { public: demo(int num):num(num){} int get_num(){ return this-\u003enum; } private: int num; }; int main() { demo a(10); cout \u003c\u003c a.get_num() \u003c\u003c endl; cout \u003c\u003c move(a).get_num() \u003c\u003c endl; return 0; } 可以看到，demo 类中的 get_num() 成员函数既可以被 a 左值对象调用，也可以被 move(a) 生成的右值 demo 对象调用，运行程序会输出两个 10。 某些场景中，我们可能需要限制调用成员函数的对象的类型（左值还是右值），为此 C++11 新添加了引用限定符。所谓引用限定符，就是在成员函数的后面添加 “\u0026” 或者 “\u0026\u0026”，从而限制调用者的类型（左值还是右值）。 修改上面程序： #include \u003ciostream\u003e using namespace std; class demo { public: demo(int num):num(num){} int get_num()\u0026{ return this-\u003enum; } private: int num; }; int main() { demo a(10); cout \u003c\u003c a.get_num() \u003c\u003c endl; // 正确 //cout \u003c\u003c move(a).get_num() \u003c\u003c endl; // 错误 return 0; } 和之前的程序相比，我们仅在 get_num() 成员函数的后面添加了 “\u0026”，它可以限定调用该函数的对象必须是左值对象。因此第 16 行代码中，move(a) 生成的右值对象是不允许调用 get_num() 函数的。 同理，我们再次修改程序： #include \u003ciostream\u003e using namespace std; class demo { public: demo(int num):num(num){} int get_num()\u0026\u0026{ return this-\u003enum; } private: int num; }; int main() { demo a(10); //cout \u003c\u003c a.get_num() \u003c\u003c endl; // 错误 cout \u003c\u003c move(a).get_num() \u003c\u003c endl; // 正确 return 0; } 和先前程序不同的是，get_num() 函数后根有 “\u0026\u0026” 限定符，它可以限定调用该函数的对象必须是一个右值对象。 注意，引用限定符不适用于静态成员函数和友元函数。 const和引用限定符 我们知道，const 也可以用于修饰类的成员函数，我们习惯称为常成员函数，例如： class demo{ public: int get_num() const; } 这里的 get_num() 就是一个常成员函数。 const 和引用限定符修饰类的成员函数时，都位于函数的末尾。C++11 标准规定，当引用限定符和 const 修饰同一个类的成员函数时，const 必须位于引用限定符前面。 需要注意的一点是，当 const \u0026\u0026 修饰类的成员函数时，调用它的对象只能是右值对象；当 const \u0026 修饰类的成员函数时，调用它的对象既可以是左值对象，也可以是右值对象。无论是 const \u0026\u0026 还是 const \u0026 限定的成员函数，内部都不允许对当前对象做修改操作。 举个例子： #include \u003ciostream\u003e using namespace std; class demo { public: demo(int num,int num2) :num(num),num2(num2) {} //左值和右值对象都可以调用 int get_num() const \u0026{ return this-\u003enum; } //仅供右值对象调用 int get_num2() const \u0026\u0026 { return this-\u003enum2; } private: int num; int num2; }; int main() { demo a(10,20); cout \u003c\u003c a.get_num() \u003c\u003c endl; // 正确 cout \u003c\u003c move(a).get_num() \u003c\u003c endl; // 正确 //cout \u003c\u003c a.get_num2() \u003c\u003c endl; // 错误 cout \u003c\u003c move(a).get_num2() \u003c\u003c endl; // 正确 return 0; } ","date":"2023-07-12","objectID":"/posts/newfeature/:1:22","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] 完美转发及其实现 C++11 标准为 C++ 引入右值引用语法的同时，还解决了一个 C++ 98/03 标准长期存在的短板，即使用简单的方式即可在函数模板中实现参数的完美转发。那么，什么是完美转发？它为什么是 C++98/03 标准存在的一个短板？C++11 标准又是如何为 C++ 弥补这一短板的？别急，本节将就这些问题给读者做一一讲解。 首先解释一下什么是完美转发，它指的是函数模板可以将自己的参数“完美”地转发给内部调用的其它函数。所谓完美，即不仅能准确地转发参数的值，还能保证被转发参数的左、右值属性不变。 在 C++ 中，一个表达式不是左值就是右值。有关如何判断一个表达式是左值还是右值，可阅读《C++右值引用》一文做详细了解。 举个例子： template\u003ctypename T\u003e void function(T t) { otherdef(t); } 如上所示，function() 函数模板中调用了 otherdef() 函数。在此基础上，完美转发指的是：如果 function() 函数接收到的参数 t 为左值，那么该函数传递给 otherdef() 的参数 t 也是左值；反之如果 function() 函数接收到的参数 t 为右值，那么传递给 otherdef() 函数的参数 t 也必须为右值。 显然，function() 函数模板并没有实现完美转发。一方面，参数 t 为非引用类型，这意味着在调用 function() 函数时，实参将值传递给形参的过程就需要额外进行一次拷贝操作；另一方面，无论调用 function() 函数模板时传递给参数 t 的是左值还是右值，对于函数内部的参数 t 来说，它有自己的名称，也可以获取它的存储地址，因此它永远都是左值，也就是说，传递给 otherdef() 函数的参数 t 永远都是左值。总之，无论从那个角度看，function() 函数的定义都不“完美”。 读者可能会问，完美转发这样严苛的参数传递机制，很常用吗？C++98/03 标准中几乎不会用到，但 C++11 标准为 C++ 引入了右值引用和移动语义，因此很多场景中是否实现完美转发，直接决定了该参数的传递过程使用的是拷贝语义（调用拷贝构造函数）还是移动语义（调用移动构造函数）。 事实上，C++98/03 标准下的 C++ 也可以实现完美转发，只是实现方式比较笨拙。通过前面的学习我们知道，C++ 98/03 标准中只有左值引用，并且可以细分为非 const 引用和 const 引用。其中，使用非 const 引用作为函数模板参数时，只能接收左值，无法接收右值；而 const 左值引用既可以接收左值，也可以接收右值，但考虑到其 const 属性，除非被调用函数的参数也是 const 属性，否则将无法直接传递。 这也就意味着，单独使用任何一种引用形式，可以实现转发，但无法保证完美。因此如果使用 C++ 98/03 标准下的 C++ 语言，我们可以采用函数模板重载的方式实现完美转发，例如： #include \u003ciostream\u003e using namespace std; //重载被调用函数，查看完美转发的效果 void otherdef(int \u0026 t) { cout \u003c\u003c \"lvalue\\n\"; } void otherdef(const int \u0026 t) { cout \u003c\u003c \"rvalue\\n\"; } //重载函数模板，分别接收左值和右值 //接收右值参数 template \u003ctypename T\u003e void function(const T\u0026 t) { otherdef(t); } //接收左值参数 template \u003ctypename T\u003e void function(T\u0026 t) { otherdef(t); } int main() { function(5);//5 是右值 int x = 1; function(x);//x 是左值 return 0; } 程序执行结果为： rvalue lvalue 从输出结果中可以看到，对于右值 5 来说，它实际调用的参数类型为 const T\u0026 的函数模板，由于 t 为 const 类型，所以 otherdef() 函数实际调用的也是参数用 const 修饰的函数，所以输出“rvalue”；对于左值 x 来说，2 个重载模板函数都适用，C++编译器会选择最适合的参数类型为 T\u0026 的函数模板，进而 therdef() 函数实际调用的是参数类型为非 const 的函数，输出“lvalue”。 显然，使用重载的模板函数实现完美转发也是有弊端的，此实现方式仅适用于模板函数仅有少量参数的情况，否则就需要编写大量的重载函数模板，造成代码的冗余。为了方便用户更快速地实现完美转发，C++ 11 标准中允许在函数模板中使用右值引用来实现完美转发。 C++11 标准中规定，通常情况下右值引用形式的参数只能接收右值，不能接收左值。但对于函数模板中使用右值引用语法定义的参数来说，它不再遵守这一规定，既可以接收右值，也可以接收左值（此时的右值引用又被称为“万能引用”）。 仍以 function() 函数为例，在 C++11 标准中实现完美转发，只需要编写如下一个模板函数即可： template \u003ctypename T\u003e void function(T\u0026\u0026 t) { otherdef(t); } 此模板函数的参数 t 既可以接收左值，也可以接收右值。但仅仅使用右值引用作为函数模板的参数是远远不够的，还有一个问题继续解决，即如果调用 function() 函数时为其传递一个左值引用或者右值引用的实参，如下所示： int n = 10; int \u0026 num = n; function(num); // T 为 int\u0026 int \u0026\u0026 num2 = 11; function(num2); // T 为 int \u0026\u0026 其中，由 function(num) 实例化的函数底层就变成了 function(int \u0026 \u0026 t)，同样由 function(num2) 实例化的函数底层则变成了 function(int \u0026\u0026 \u0026\u0026 t)。要知道，C++98/03 标准是不支持这种用法的，而 C++ 11标准为了更好地实现完美转发，特意为其指定了新的类型匹配规则，又称为引用折叠规则（假设用 A 表示实际传递参数的类型）： 当实参为左值或者左值引用（A\u0026）时，函数模板中 T\u0026\u0026 将转变为 A\u0026（A\u0026 \u0026\u0026 = A\u0026）； 当实参为右值或者右值引用（A\u0026\u0026）时，函数模板中 T\u0026\u0026 将转变为 A\u0026\u0026（A\u0026\u0026 \u0026\u0026 = A\u0026\u0026）。 读者只需要知道，在实现完美转发时，只要函数模板的参数类型为 T\u0026\u0026，则 C++ 可以自行准确地判定出实际传入的实参是左值还是右值。 通过将函数模板的形参类型设置为 T\u0026\u0026，我们可以很好地解决接收左、右值的问题。但除此之外，还需要解决一个问题，即无论传入的形参是左值还是右值，对于函数模板内部来说，形参既有名称又能寻址，因此它都是左值。那么如何才能将函数模板接收到的形参连同其左、右值属性，一起传递给被调用的函数呢？ C++11 标准的开发者已经帮我们想好的解决方案，该新标准还引入了一个模板函数 forword()，我们只需要调用该函数，就可以很方便地解决此问题。仍以 function 模板函数为例，如下演示了该函数模板的用法： #include \u003ciostream\u003e using namespace std; //重载被调用函数，查看完美转发的效果 void otherdef(int \u0026 t) { cout \u003c\u003c \"lvalue\\n\"; } void otherdef(const int \u0026 t) { cout \u003c\u003c \"rvalue\\n\"; } //实现完美转发的函数模板 template \u003ctypename T\u003e void function(T\u0026\u0026 t) { otherdef(forward\u003cT\u003e(t)); } int main() { function(5); int x = 1; function(x); return 0; } 程序执行结果为： rvalue lvalue 注意程序中第 12~16 行，此 function() 模板函数才是实现完美转发的最终版本。可以看到，forword() 函数模板用于修饰被调用函数中需要维持参数左、右值属性的参数。 总的来说，在定义模板函数时，我们采用右值引用的语法格式定义参数类型，由此该函数既可以接收外界传入的左值，也可以接收右值；其次，还需要使用 C++11 标准库提供的 forword() 模板函数修饰被调用函数中需要维持左、右值属性的参数。由此即可轻松实现函数模板中参数的完美转发。 ","date":"2023-07-12","objectID":"/posts/newfeature/:1:23","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] nullptr：初始化空指针 实际开发中，避免产生“野指针”最有效的方法，就是在定义指针的同时完成初始化操作，即便该指针的指向尚未明确，也要将其初始化为空指针。 所谓“野指针”，又称“悬挂指针”，指的是没有明确指向的指针。野指针往往指向的是那些不可用的内存区域，这就意味着像操作普通指针那样使用野指针（例如 \u0026p），极可能导致程序发生异常。 C++98/03 标准中，将一个指针初始化为空指针的方式有 2 种： int *p = 0; int *p = NULL; //推荐使用 可以看到，我们可以将指针明确指向 0（0x0000 0000）这个内存空间。一方面，明确指针的指向可以避免其成为野指针；另一方面，大多数操作系统都不允许用户对地址为 0 的内存空间执行写操作，若用户在程序中尝试修改其内容，则程序运行会直接报错。 相比第一种方式，我们更习惯将指针初始化为 NULL。值得一提的是，NULL 并不是 C++ 的关键字，它是 C++ 为我们事先定义好的一个宏，并且它的值往往就是字面量 0（#define NULL 0）。 C++ 中将 NULL 定义为字面常量 0，虽然能满足大部分场景的需要，但个别情况下，它会导致程序的运行和我们的预期不符。例如： #include \u003ciostream\u003e using namespace std; void isnull(void *c){ cout \u003c\u003c \"void*c\" \u003c\u003c endl; } void isnull(int n){ cout \u003c\u003c \"int n\" \u003c\u003c endl; } int main() { isnull(0); isnull(NULL); return 0; } 程序执行结果为： int n int n 对于 isnull(0) 来说，显然它真正调用的是参数为整形的 isnull() 函数；而对于 isnull(NULL)，我们期望它实际调用的是参数为 void*c 的 isnull() 函数，但观察程序的执行结果不难看出，并不符合我们的预期。 C++ 98/03 标准中，如果我们想令 isnull(NULL) 实际调用的是 isnull(void* c)，就需要对 NULL（或者 0）进行强制类型转换： isnull( (void*)NULL ); isnull( (void*)0 ); 如此，才会成功调用我们预期的函数（读者可自行执行此代码，观察输出结果）。 由于 C++ 98 标准使用期间，NULL 已经得到了广泛的应用，出于兼容性的考虑，C++11 标准并没有对 NULL 的宏定义做任何修改。为了修正 C++ 存在的这一 BUG，C++ 标准委员会最终决定另其炉灶，在 C++11 标准中引入一个新关键字，即 nullptr。 在使用 nullptr 之前，读者需保证自己使用的编译器支持该关键字。以 Visual Studio 和 codeblocks 为例，前者早在 2010 版本就对 C++ 11 标准中的部分特性提供了支持，其中就包括 nullptr；如果使用后者，读者需将其 G++ 编译器版本至少升级至 4.6.1（同时开启 -std=c++0x 编译选项）。 nullptr 是 nullptr_t 类型的右值常量，专用于初始化空类型指针。nullptr_t 是 C++11 新增加的数据类型，可称为“指针空值类型”。也就是说，nullpter 仅是该类型的一个实例对象（已经定义好，可以直接使用），如果需要我们完全定义出多个同 nullptr 完全一样的实例对象。 值得一提的是，nullptr 可以被隐式转换成任意的指针类型。举个例子： int * a1 = nullptr; char * a2 = nullptr; double * a3 = nullptr; 显然，不同类型的指针变量都可以使用 nullptr 来初始化，编译器分别将 nullptr 隐式转换成 int*、char* 以及 double* 指针类型。 另外，通过将指针初始化为 nullptr，可以很好地解决 NULL 遗留的问题，比如： #include \u003ciostream\u003e using namespace std; void isnull(void *c){ cout \u003c\u003c \"void*c\" \u003c\u003c endl; } void isnull(int n){ cout \u003c\u003c \"int n\" \u003c\u003c endl; } int main() { isnull(NULL); isnull(nullptr); return 0; } 程序执行结果为： int n void*c 借助执行结果不难看出，由于 nullptr 无法隐式转换为整形，而可以隐式匹配指针类型，因此执行结果和我们的预期相符。 总之在 C++11 标准下，相比 NULL 和 0，使用 nullptr 初始化空指针可以令我们编写的程序更加健壮。 ","date":"2023-07-12","objectID":"/posts/newfeature/:1:24","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] shared_ptr智能指针（超级详细） 在实际的 C++ 开发中，我们经常会遇到诸如程序运行中突然崩溃、程序运行所用内存越来越多最终不得不重启等问题，这些问题往往都是内存资源管理不当造成的。比如： 有些内存资源已经被释放，但指向它的指针并没有改变指向（成为了野指针），并且后续还在使用； 有些内存资源已经被释放，后期又试图再释放一次（重复释放同一块内存会导致程序运行崩溃）； 没有及时释放不再使用的内存资源，造成内存泄漏，程序占用的内存资源越来越多。 针对以上这些情况，很多程序员认为 C++ 语言应该提供更友好的内存管理机制，这样就可以将精力集中于开发项目的各个功能上。 事实上，显示内存管理的替代方案很早就有了，早在 1959 年前后，就有人提出了“垃圾自动回收”机制。所谓垃圾，指的是那些不再使用或者没有任何指针指向的内存空间，而“回收”则指的是将这些“垃圾”收集起来以便再次利用。 如今，垃圾回收机制已经大行其道，得到了诸多编程语言的支持，例如 Java、Python、C#、PHP 等。而 C++ 虽然从来没有公开得支持过垃圾回收机制，但 C++98/03 标准中，支持使用 auto_ptr 智能指针来实现堆内存的自动回收；C++11 新标准在废弃 auto_ptr 的同时，增添了 unique_ptr、shared_ptr 以及 weak_ptr 这 3 个智能指针来实现堆内存的自动回收。 所谓智能指针，可以从字面上理解为“智能”的指针。具体来讲，智能指针和普通指针的用法是相似的，不同之处在于，智能指针可以在适当时机自动释放分配的内存。也就是说，使用智能指针可以很好地避免“忘记释放内存而导致内存泄漏”问题出现。由此可见，C++ 也逐渐开始支持垃圾回收机制了，尽管目前支持程度还有限。 C++ 智能指针底层是采用引用计数的方式实现的。简单的理解，智能指针在申请堆内存空间的同时，会为其配备一个整形值（初始值为 1），每当有新对象使用此堆内存时，该整形值 +1；反之，每当使用此堆内存的对象被释放时，该整形值减 1。当堆空间对应的整形值为 0 时，即表明不再有对象使用它，该堆空间就会被释放掉。 接下来，我们将分别对 shared_ptr、unique_ptr 以及 weak_ptr 这 3 个智能指针的特性和用法做详细的讲解，本节先介绍 shared_ptr 智能指针。 ","date":"2023-07-12","objectID":"/posts/newfeature/:1:25","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] shared_ptr智能指针 实际上，每种智能指针都是以类模板的方式实现的，shared_ptr 也不例外。shared_ptr（其中 T 表示指针指向的具体数据类型）的定义位于头文件，并位于 std 命名空间中，因此在使用该类型指针时，程序中应包含如下 2 行代码： #include \u003cmemory\u003e using namespace std; 注意，第 2 行代码并不是必须的，也可以不添加，则后续在使用 shared_ptr 智能指针时，就需要明确指明std::。 值得一提的是，和 unique_ptr、weak_ptr 不同之处在于，多个 shared_ptr 智能指针可以共同使用同一块堆内存。并且，由于该类型智能指针在实现上采用的是引用计数机制，即便有一个 shared_ptr 指针放弃了堆内存的“使用权”（引用计数减 1），也不会影响其他指向同一堆内存的 shared_ptr 指针（只有引用计数为 0 时，堆内存才会被自动释放）。 1、shared_ptr智能指针的创建 shared_ptr 类模板中，提供了多种实用的构造函数，这里给读者列举了几个常用的构造函数（以构建指向 int 类型数据的智能指针为例）。 1.1 通过如下 2 种方式，可以构造出 shared_ptr 类型的空智能指针： std::shared_ptr\u003cint\u003e p1; //不传入任何实参std::shared_ptr\u003cint\u003e p2(nullptr); //传入空指针 nullptr 注意，空的 shared_ptr 指针，其初始引用计数为 0，而不是 1。 1.2 在构建 shared_ptr 智能指针，也可以明确其指向。例如： std::shared_ptr\u003cint\u003e p3(new int(10)); 由此，我们就成功构建了一个 shared_ptr 智能指针，其指向一块存有 10 这个 int 类型数据的堆内存空间。 同时，C++11 标准中还提供了 std::make_shared 模板函数，其可以用于初始化 shared_ptr 智能指针，例如： std::shared_ptr\u003cint\u003e p3 = std::make_shared\u003cint\u003e(10); 以上 2 种方式创建的 p3 是完全相同。 1.3 除此之外，shared_ptr 模板还提供有相应的拷贝构造函数和移动构造函数，例如： //调用拷贝构造函数 std::shared_ptr\u003cint\u003e p4(p3);//或者 std::shared_ptr\u003cint\u003e p4 = p3; //调用移动构造函数 std::shared_ptr\u003cint\u003e p5(std::move(p4)); //或者 std::shared_ptr\u003cint\u003e p5 = std::move(p4); 有关拷贝构造函数，读者可阅读《C++拷贝构造函数》一节做系统了解；有关移动构造函数，读者可阅读《C++移动构造函数》做详细了解；有关 move() 函数的功能和用法，读者可阅读《C++11 move()》一节。 如上所示，p3 和 p4 都是 shared_ptr 类型的智能指针，因此可以用 p3 来初始化 p4，由于 p3 是左值，因此会调用拷贝构造函数。需要注意的是，如果 p3 为空智能指针，则 p4 也为空智能指针，其引用计数初始值为 0；反之，则表明 p4 和 p3 指向同一块堆内存，同时该堆空间的引用计数会加 1。 而对于 std::move(p4) 来说，该函数会强制将 p4 转换成对应的右值，因此初始化 p5 调用的是移动构造函数。另外和调用拷贝构造函数不同，用 std::move(p4) 初始化 p5，会使得 p5 拥有了 p4 的堆内存，而 p4 则变成了空智能指针。 注意，同一普通指针不能同时为多个 shared_ptr 对象赋值，否则会导致程序发生异常。例如： int* ptr = new int; std::shared_ptr\u003cint\u003e p1(ptr); std::shared_ptr\u003cint\u003e p2(ptr);//错误 1.4 在初始化 shared_ptr 智能指针时，还可以自定义所指堆内存的释放规则，这样当堆内存的引用计数为 0 时，会优先调用我们自定义的释放规则。 在某些场景中，自定义释放规则是很有必要的。比如，对于申请的动态数组来说，shared_ptr 指针默认的释放规则是不支持释放数组的，只能自定义对应的释放规则，才能正确地释放申请的堆内存。 对于申请的动态数组，释放规则可以使用 C++11 标准中提供的 default_delete 模板类，我们也可以自定义释放规则： //指定 default_delete 作为释放规则 std::shared_ptr\u003cint\u003e p6(new int[10], std::default_delete\u003cint[]\u003e()); //自定义释放规则 void deleteInt(int*p) { delete []p; } //初始化智能指针，并自定义释放规则 std::shared_ptr\u003cint\u003e p7(new int[10], deleteInt); 实际上借助 lambda 表达式，我们还可以像如下这样初始化 p7，它们是完全相同的： std::shared_ptr\u003cint\u003e p7(new int[10], [](int* p) {delete[]p; }); shared_ptr 模板类还提供有其它一些初始化智能指针的方法，感兴趣的读者可前往讲解 shared_ptr 的官网做系统了解。 2、shared_ptr模板类提供的成员方法 为了方便用户使用 shared_ptr 智能指针，shared_ptr 模板类还提供有一些实用的成员方法，它们各自的功能如表 1 所示。 成员方法名 功 能 operator=() 重载赋值号，使得同一类型的 shared_ptr 智能指针可以相互赋值。 operator*() 重载 * 号，获取当前 shared_ptr 智能指针对象指向的数据。 operator-\u003e() 重载 -\u003e 号，当智能指针指向的数据类型为自定义的结构体时，通过 -\u003e 运算符可以获取其内部的指定成员。 swap() 交换 2 个相同类型 shared_ptr 智能指针的内容。 reset() 当函数没有实参时，该函数会使当前 shared_ptr 所指堆内存的引用计数减 1，同时将当前对象重置为一个空指针；当为函数传递一个新申请的堆内存时，则调用该函数的 shared_ptr 对象会获得该存储空间的所有权，并且引用计数的初始值为 1。 get() 获得 shared_ptr 对象内部包含的普通指针。 use_count() 返回同当前 shared_ptr 对象（包括它）指向相同的所有 shared_ptr 对象的数量。 unique() 判断当前 shared_ptr 对象指向的堆内存，是否不再有其它 shared_ptr 对象再指向它。 operator bool() 判断当前 shared_ptr 对象是否为空智能指针，如果是空指针，返回 false；反之，返回 true。 除此之外，C++11 标准还支持同一类型的 shared_ptr 对象，或者 shared_ptr 和 nullptr 之间，进行 ==，!=，\u003c，\u003c=，\u003e，\u003e= 运算。 下面程序给大家演示了 shared_ptr 智能指针的基本用法，以及该模板类提供了一些成员方法的用法： #include \u003ciostream\u003e #include \u003cmemory\u003e using namespace std; int main() { //构建 2 个智能指针 std::shared_ptr\u003cint\u003e p1(new int(10)); std::shared_ptr\u003cint\u003e p2(p1); //输出 p2 指向的数据 cout \u003c\u003c *p2 \u003c\u003c endl; p1.reset();//引用计数减 1,p1为空指针 if (p1) { cout \u003c\u003c \"p1 不为空\" \u003c\u003c endl; } else { cout \u003c\u003c \"p1 为空\" \u003c\u003c endl; } //以上操作，并不会影响 p2 cout \u003c\u003c *p2 \u003c\u003c endl; //判断当前和 p2 同指向的智能指针有多少个 cout \u003c\u003c p2.use_count() \u003c\u003c endl; return 0; } 程序执行结果为： 10 p1 为空 10 1 ","date":"2023-07-12","objectID":"/posts/newfeature/:1:26","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] unique_ptr智能指针 在《C++11 shared_ptr智能指针》的基础上，本节继续讲解 C++11 标准提供的另一种智能指针，即 unique_ptr 智能指针。 作为智能指针的一种，unique_ptr 指针自然也具备“在适当时机自动释放堆内存空间”的能力。和 shared_ptr 指针最大的不同之处在于，unique_ptr 指针指向的堆内存无法同其它 unique_ptr 共享，也就是说，每个 unique_ptr 指针都独自拥有对其所指堆内存空间的所有权。 这也就意味着，每个 unique_ptr 指针指向的堆内存空间的引用计数，都只能为 1，一旦该 unique_ptr 指针放弃对所指堆内存空间的所有权，则该空间会被立即释放回收。 unique_ptr 智能指针是以模板类的形式提供的，unique_ptr（T 为指针所指数据的类型）定义在头文件，并位于 std 命名空间中。因此，要想使用 unique_ptr 类型指针，程序中应首先包含如下 2 条语句： #include \u003cmemory\u003e using namespace std; 第 2 句并不是必须的，可以不添加，则后续在使用 unique_ptr 指针时，必须标注std::。 unique_ptr智能指针的创建 考虑到不同实际场景的需要，unique_ptr 模板类提供了多个实用的构造函数，这里给读者列举了几种常用的构造 unique_ptr 智能指针的方式。 通过以下 2 种方式，可以创建出空的 unique_ptr 指针： std::unique_ptr\u003cint\u003e p1(); std::unique_ptr\u003cint\u003e p2(nullptr); 创建 unique_ptr 指针的同时，也可以明确其指向。例如： std::unique_ptr\u003cint\u003e p3(new int); 由此就创建出了一个 p3 智能指针，其指向的是可容纳 1 个整数的堆存储空间。 和可以用 make_shared() 模板函数初始化 shared_ptr 指针不同，C++11 标准中并没有为 unique_ptr 类型指针添加类似的模板函数。 基于 unique_ptr 类型指针不共享各自拥有的堆内存，因此 C++11 标准中的 unique_ptr 模板类没有提供拷贝构造函数，只提供了移动构造函数。例如： std::unique_ptr\u003cint\u003e p4(new int); std::unique_ptr\u003cint\u003e p5(p4);//错误，堆内存不共享 std::unique_ptr\u003cint\u003e p5(std::move(p4));//正确，调用移动构造函数 值得一提的是，对于调用移动构造函数的 p4 和 p5 来说，p5 将获取 p4 所指堆空间的所有权，而 p4 将变成空指针（nullptr）。 默认情况下，unique_ptr 指针采用 std::default_delete 方法释放堆内存。当然，我们也可以自定义符合实际场景的释放规则。值得一提的是，和 shared_ptr 指针不同，为 unique_ptr 自定义释放规则，只能采用函数对象的方式。例如： //自定义的释放规则 struct myDel { void operator()(int *p) { delete p; } }; std::unique_ptr\u003cint, myDel\u003e p6(new int); //std::unique_ptr\u003cint, myDel\u003e p6(new int, myDel()); unique_ptr模板类提供的成员方法 为了方便用户使用 unique_ptr 智能指针，unique_ptr 模板类还提供有一些实用的成员方法，它们各自的功能如表 1 所示。 成员函数名 功能 operator*() 获取当前 unique_ptr 指针指向的数据。 operator-\u003e() 重载 -\u003e 号，当智能指针指向的数据类型为自定义的结构体时，通过 -\u003e 运算符可以获取其内部的指定成员。 operator =() 重载了 = 赋值号，从而可以将 nullptr 或者一个右值 unique_ptr 指针直接赋值给当前同类型的 unique_ptr 指针。 operator 重载了 [] 运算符，当 unique_ptr 指针指向一个数组时，可以直接通过 [] 获取指定下标位置处的数据。 get() 获取当前 unique_ptr 指针内部包含的普通指针。 get_deleter() 获取当前 unique_ptr 指针释放堆内存空间所用的规则。 operator bool() unique_ptr 指针可直接作为 if 语句的判断条件，以判断该指针是否为空，如果为空，则为 false；反之为 true。 release() 释放当前 unique_ptr 指针对所指堆内存的所有权，但该存储空间并不会被销毁。 reset() 其中 p 表示一个普通指针，如果 p 为 nullptr，则当前 unique_ptr 也变成空指针；反之，则该函数会释放当前 unique_ptr 指针指向的堆内存（如果有），然后获取 p 所指堆内存的所有权（p 为 nullptr）。 swap(x) 交换当前 unique_ptr 指针和同类型的 x 指针。 除此之外，C++11标准还支持同类型的 unique_ptr 指针之间，以及 unique_ptr 和 nullptr 之间，做 ==，!=，\u003c，\u003c=，\u003e，\u003e= 运算。 下面程序给大家演示了 unique_ptr 智能指针的基本用法，以及该模板类提供了一些成员方法的用法： #include \u003ciostream\u003e #include \u003cmemory\u003e using namespace std; int main() { std::unique_ptr\u003cint\u003e p5(new int); *p5 = 10; // p 接收 p5 释放的堆内存 int * p = p5.release(); cout \u003c\u003c *p \u003c\u003c endl; //判断 p5 是否为空指针 if (p5) { cout \u003c\u003c \"p5 is not nullptr\" \u003c\u003c endl; } else { cout \u003c\u003c \"p5 is nullptr\" \u003c\u003c endl; } std::unique_ptr\u003cint\u003e p6; //p6 获取 p 的所有权 p6.reset(p); cout \u003c\u003c *p6 \u003c\u003c endl;; return 0; } 程序执行结果为： 10 p5 is nullptr 10 ","date":"2023-07-12","objectID":"/posts/newfeature/:1:27","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++11] weak_ptr智能指针 在 C++98/03 的基础上，C++11 标准新引入了 shared_ptr、unique_ptr 以及 weak_ptr 这 3 个智能指针。其中，shared_ptr 和 unique_ptr 已经在前面章节做了详细地介绍，本节重点讲解 weak_ptr 智能指针的特性和用法。 注意学习 weak_ptr 智能指针之前，读者必须对 shared_ptr 智能指针有一定的了解，可阅读《C++11 shared_ptr智能指针》一节；关于 unique_ptr 指针，读者可阅读《C++11 unique_ptr智能指针》一节做系统学习。 C++11 weak_ptr智能指针 和 shared_ptr、unique_ptr 类型指针一样，weak_ptr 智能指针也是以模板类的方式实现的。weak_ptr（ T 为指针所指数据的类型）定义在头文件，并位于 std 命名空间中。因此，要想使用 weak_ptr 类型指针，程序中应首先包含如下 2 条语句： #include \u003cmemory\u003e using namespace std; 第 2 句并不是必须的，可以不添加，则后续在使用 unique_ptr 指针时，必须标注std::。 需要注意的是，C++11标准虽然将 weak_ptr 定位为智能指针的一种，但该类型指针通常不单独使用（没有实际用处），只能和 shared_ptr 类型指针搭配使用。甚至于，我们可以将 weak_ptr 类型指针视为 shared_ptr 指针的一种辅助工具，借助 weak_ptr 类型指针， 我们可以获取 shared_ptr 指针的一些状态信息，比如有多少指向相同的 shared_ptr 指针、shared_ptr 指针指向的堆内存是否已经被释放等等。 需要注意的是，当 weak_ptr 类型指针的指向和某一 shared_ptr 指针相同时，weak_ptr 指针并不会使所指堆内存的引用计数加 1；同样，当 weak_ptr 指针被释放时，之前所指堆内存的引用计数也不会因此而减 1。也就是说，weak_ptr 类型指针并不会影响所指堆内存空间的引用计数。 除此之外，weak_ptr 模板类中没有重载 * 和 -\u003e 运算符，这也就意味着，weak_ptr 类型指针只能访问所指的堆内存，而无法修改它。 weak_ptr指针的创建 创建一个 weak_ptr 指针，有以下 3 种方式： 1.1 可以创建一个空 weak_ptr 指针，例如： std::weak_ptr\u003cint\u003e wp1; 1.2 凭借已有的 weak_ptr 指针，可以创建一个新的 weak_ptr 指针，例如： std::weak_ptr\u003cint\u003e wp2 (wp1); 若 wp1 为空指针，则 wp2 也为空指针；反之，如果 wp1 指向某一 shared_ptr 指针拥有的堆内存，则 wp2 也指向该块存储空间（可以访问，但无所有权）。 1.3 weak_ptr 指针更常用于指向某一 shared_ptr 指针拥有的堆内存，因为在构建 weak_ptr 指针对象时，可以利用已有的 shared_ptr 指针为其初始化。例如： std::shared_ptr\u003cint\u003e sp (new int); std::weak_ptr\u003cint\u003e wp3 (sp); 由此，wp3 指针和 sp 指针有相同的指针。再次强调，weak_ptr 类型指针不会导致堆内存空间的引用计数增加或减少。 weak_ptr模板类提供的成员方法 和 shared_ptr、unique_ptr 相比，weak_ptr 模板类提供的成员方法不多，表 1 罗列了常用的成员方法及各自的功能。 成员方法 功 能 operator=() 重载 = 赋值运算符，是的 weak_ptr 指针可以直接被 weak_ptr 或者 shared_ptr 类型指针赋值。 swap(x) 其中 x 表示一个同类型的 weak_ptr 类型指针，该函数可以互换 2 个同类型 weak_ptr 指针的内容。 reset() 将当前 weak_ptr 指针置为空指针。 use_count() 查看指向和当前 weak_ptr 指针相同的 shared_ptr 指针的数量。 expired() 判断当前 weak_ptr 指针为否过期（指针为空，或者指向的堆内存已经被释放）。 lock() 如果当前 weak_ptr 已经过期，则该函数会返回一个空的 shared_ptr 指针；反之，该函数返回一个和当前 weak_ptr 指向相同的 shared_ptr 指针。 再次强调，weak_ptr 模板类没有重载 * 和 -\u003e 运算符，因此 weak_ptr 类型指针只能访问某一 shared_ptr 指针指向的堆内存空间，无法对其进行修改。 下面的样例演示了 weak_ptr 指针以及表 1 中部分成员方法的基本用法： #include \u003ciostream\u003e #include \u003cmemory\u003e using namespace std; int main() { std::shared_ptr\u003cint\u003e sp1(new int(10)); std::shared_ptr\u003cint\u003e sp2(sp1); std::weak_ptr\u003cint\u003e wp(sp2); //输出和 wp 同指向的 shared_ptr 类型指针的数量 cout \u003c\u003c wp.use_count() \u003c\u003c endl; //释放 sp2 sp2.reset(); cout \u003c\u003c wp.use_count() \u003c\u003c endl; //借助 lock() 函数，返回一个和 wp 同指向的 shared_ptr 类型指针，获取其存储的数据 cout \u003c\u003c *(wp.lock()) \u003c\u003c endl; return 0; } 程序执行结果为： 2 1 10 有关表 1 中其它成员函数的用法，感兴趣的读者可直接查看 weak_ptr 官网。 ","date":"2023-07-12","objectID":"/posts/newfeature/:1:28","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"C++ 14 新特性总结 ","date":"2023-07-12","objectID":"/posts/newfeature/:2:0","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++14] 函数返回值类型推导 C++14对函数返回类型推导规则做了优化，先看一段代码： #include \u003ciostream\u003e using namespace std; auto func(int i) { return i; } int main() { cout \u003c\u003c func(4) \u003c\u003c endl; return 0; } 使用C++11编译： ~/test$ g++ test.cc -std=c++11 test.cc:5:16: error: ‘func’ function uses ‘auto’ type specifier without trailing return type auto func(int i) { ^ test.cc:5:16: note: deduced return type only available with -std=c++14 or -std=gnu++14 上面的代码使用C++11是不能通过编译的，通过编译器输出的信息也可以看见这个特性需要到C++14才被支持。 返回值类型推导也可以用在模板中： #include \u003ciostream\u003e using namespace std; template\u003ctypename T\u003e auto func(T t) { return t; } int main() { cout \u003c\u003c func(4) \u003c\u003c endl; cout \u003c\u003c func(3.4) \u003c\u003c endl; return 0; } 注意： 函数内如果有多个return语句，它们必须返回相同的类型，否则编译失败。 auto func(bool flag) { if (flag) return 1; else return 2.3; // error } // inconsistent deduction for auto return type: ‘int’ and then ‘double’ 如果return语句返回初始化列表，返回值类型推导也会失败 auto func() { return {1, 2, 3}; // error returning initializer list } 如果函数是虚函数，不能使用返回值类型推导 struct A { // error: virtual function cannot have deduced return type virtual auto func() { return 1; } } 返回类型推导可以用在前向声明中，但是在使用它们之前，翻译单元中必须能够得到函数定义 auto f(); // declared, not yet defined auto f() { return 42; } // defined, return type is int int main() { cout \u003c\u003c f() \u003c\u003c endl; } 返回类型推导可以用在递归函数中，但是递归调用必须以至少一个返回语句作为先导，以便编译器推导出返回类型。 auto sum(int i) { if (i == 1) return i; // return int else return sum(i - 1) + i; // ok } ","date":"2023-07-12","objectID":"/posts/newfeature/:2:1","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++14] lambda参数auto 在C++11中，lambda表达式参数需要使用具体的类型声明： auto f = [] (int a) { return a; } 在C++14中，对此进行优化，lambda表达式参数可以直接是auto： auto f = [] (auto a) { return a; }; cout \u003c\u003c f(1) \u003c\u003c endl; cout \u003c\u003c f(2.3f) \u003c\u003c endl; ","date":"2023-07-12","objectID":"/posts/newfeature/:2:2","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++14] 变量模板 C++14支持变量模板： template\u003cclass T\u003e constexpr T pi = T(3.1415926535897932385L); int main() { cout \u003c\u003c pi\u003cint\u003e \u003c\u003c endl; // 3 cout \u003c\u003c pi\u003cdouble\u003e \u003c\u003c endl; // 3.14159 return 0; } ","date":"2023-07-12","objectID":"/posts/newfeature/:2:3","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++14] 别名模板 C++14也支持别名模板： template\u003ctypename T, typename U\u003e struct A { T t; U u; }; template\u003ctypename T\u003e using B = A\u003cT, int\u003e; int main() { B\u003cdouble\u003e b; b.t = 10; b.u = 20; cout \u003c\u003c b.t \u003c\u003c endl; cout \u003c\u003c b.u \u003c\u003c endl; return 0; } ","date":"2023-07-12","objectID":"/posts/newfeature/:2:4","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++14] constexpr的限制 C++14相较于C++11对constexpr减少了一些限制： C++11中constexpr函数可以使用递归，在C++14中可以使用局部变量和循环 constexpr int factorial(int n) { // C++14 和 C++11均可 return n \u003c= 1 ? 1 : (n * factorial(n - 1)); } 在C++14中可以这样做： constexpr int factorial(int n) { // C++11中不可，C++14中可以 int ret = 0; for (int i = 0; i \u003c n; ++i) { ret += i; } return ret; } C++11中constexpr函数必须必须把所有东西都放在一个单独的return语句中，而constexpr则无此限制： constexpr int func(bool flag) { // C++14 和 C++11均可 return 0; } 在C++14中可以这样： constexpr int func(bool flag) { // C++11中不可，C++14中可以 if (flag) return 1; else return 0; } ","date":"2023-07-12","objectID":"/posts/newfeature/:2:5","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++14] [[deprecated]]标记 C++14中增加了deprecated标记，修饰类、变、函数等，当程序中使用到了被其修饰的代码时，编译时被产生警告，用户提示开发者该标记修饰的内容将来可能会被丢弃，尽量不要使用。 struct [[deprecated]] A { }; int main() { A a; return 0; } 当编译时，会出现如下警告： ~/test$ g++ test.cc -std=c++14 test.cc: In function ‘int main()’: test.cc:11:7: warning: ‘A’ is deprecated [-Wdeprecated-declarations] A a; ^ test.cc:6:23: note: declared here struct [[deprecated]] A { ","date":"2023-07-12","objectID":"/posts/newfeature/:2:6","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++14] 二进制字面量与整形字面量分隔符 C++14引入了二进制字面量，也引入了分隔符，防止看起来眼花哈~ int a = 0b0001'0011'1010; double b = 3.14'1234'1234'1234; ","date":"2023-07-12","objectID":"/posts/newfeature/:2:7","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++14] std::make_unique 我们都知道C++11中有std::make_shared，却没有std::make_unique，在C++14已经改善。 struct A {}; std::unique_ptr\u003cA\u003e ptr = std::make_unique\u003cA\u003e(); ","date":"2023-07-12","objectID":"/posts/newfeature/:2:8","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++14] std::shared_timed_mutex与std::shared_lock C++14通过std::shared_timed_mutex和std::shared_lock来实现读写锁，保证多个线程可以同时读，但是写线程必须独立运行，写操作不可以同时和读操作一起进行。 实现方式如下： struct ThreadSafe { mutable std::shared_timed_mutex mutex_; int value_; ThreadSafe() { value_ = 0; } int get() const { std::shared_lock\u003cstd::shared_timed_mutex\u003e loc(mutex_); return value_; } void increase() { std::unique_lock\u003cstd::shared_timed_mutex\u003e lock(mutex_); value_ += 1; } }; 为什么是timed的锁呢，因为可以带超时时间，具体可以自行查询相关资料哈，网上有很多。 ","date":"2023-07-12","objectID":"/posts/newfeature/:2:9","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++14] std::integer_sequence template\u003ctypename T, T... ints\u003e void print_sequence(std::integer_sequence\u003cT, ints...\u003e int_seq) { std::cout \u003c\u003c \"The sequence of size \" \u003c\u003c int_seq.size() \u003c\u003c \": \"; ((std::cout \u003c\u003c ints \u003c\u003c ' '), ...); std::cout \u003c\u003c '\\n'; } int main() { print_sequence(std::integer_sequence\u003cint, 9, 2, 5, 1, 9, 1, 6\u003e{}); return 0; } 输出：7 9 2 5 1 9 1 6 std::integer_sequence和std::tuple的配合使用： template \u003cstd::size_t... Is, typename F, typename T\u003e auto map_filter_tuple(F f, T\u0026 t) { return std::make_tuple(f(std::get\u003cIs\u003e(t))...); } template \u003cstd::size_t... Is, typename F, typename T\u003e auto map_filter_tuple(std::index_sequence\u003cIs...\u003e, F f, T\u0026 t) { return std::make_tuple(f(std::get\u003cIs\u003e(t))...); } template \u003ctypename S, typename F, typename T\u003e auto map_filter_tuple(F\u0026\u0026 f, T\u0026 t) { return map_filter_tuple(S{}, std::forward\u003cF\u003e(f), t); } ","date":"2023-07-12","objectID":"/posts/newfeature/:2:10","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++14] std::exchange 直接看代码吧： int main() { std::vector\u003cint\u003e v; std::exchange(v, {1,2,3,4}); cout \u003c\u003c v.size() \u003c\u003c endl; for (int a : v) { cout \u003c\u003c a \u003c\u003c \" \"; } return 0; } 看样子貌似和std::swap作用相同，那它俩有什么区别呢？ 可以看下exchange的实现： template\u003cclass T, class U = T\u003e constexpr T exchange(T\u0026 obj, U\u0026\u0026 new_value) { T old_value = std::move(obj); obj = std::forward\u003cU\u003e(new_value); return old_value; } 可以看见new_value的值给了obj，而没有对new_value赋值，这里相信您已经知道了它和swap的区别了吧！ ","date":"2023-07-12","objectID":"/posts/newfeature/:2:11","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++14] std::quoted C++14引入std::quoted用于给字符串添加双引号，直接看代码： int main() { string str = \"hello world\"; cout \u003c\u003c str \u003c\u003c endl; cout \u003c\u003c std::quoted(str) \u003c\u003c endl; return 0; } 编译\u0026输出： ~/test$ g++ test.cc -std=c++14 ~/test$ ./a.out hello world \"hello world\" ","date":"2023-07-12","objectID":"/posts/newfeature/:2:12","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"C++ 17 新特性总结 主要新特性如下： 构造函数模板推导 结构化绑定 if-switch语句初始化 内联变量 折叠表达式 constexpr lambda表达式 namespace嵌套 __has_include预处理表达式 在lambda表达式用*this捕获对象副本 新增Attribute 字符串转换 std::variant std::optional std::any std::apply std::make_from_tuple as_const std::string_view file_system std::shared_mutex ","date":"2023-07-12","objectID":"/posts/newfeature/:3:0","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++17] 构造函数模板推导 在C++17前构造一个模板类对象需要指明类型： pair\u003cint, double\u003e p(1, 2.2); // before c++17 C++17就不需要特殊指定，直接可以推导出类型，代码如下： pair p(1, 2.2); // c++17 自动推导 vector v = {1, 2, 3}; // c++17 ","date":"2023-07-12","objectID":"/posts/newfeature/:3:1","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++17] 结构化绑定 通过结构化绑定，对于tuple、map等类型，获取相应值会方便很多，看代码： std::tuple\u003cint, double\u003e func() { return std::tuple(1, 2.2); } int main() { auto[i, d] = func(); //是C++11的tie吗？更高级 cout \u003c\u003c i \u003c\u003c endl; cout \u003c\u003c d \u003c\u003c endl; } //========================== void f() { map\u003cint, string\u003e m = { {0, \"a\"}, {1, \"b\"}, }; for (const auto \u0026[i, s] : m) { cout \u003c\u003c i \u003c\u003c \" \" \u003c\u003c s \u003c\u003c endl; } } // ==================== int main() { std::pair a(1, 2.3f); auto[i, f] = a; cout \u003c\u003c i \u003c\u003c endl; // 1 cout \u003c\u003c f \u003c\u003c endl; // 2.3f return 0; } 结构化绑定还可以改变对象的值，使用引用即可： // 进化，可以通过结构化绑定改变对象的值 int main() { std::pair a(1, 2.3f); auto\u0026 [i, f] = a; i = 2; cout \u003c\u003c a.first \u003c\u003c endl; // 2 } 注意结构化绑定不能应用于constexpr constexpr auto[x, y] = std::pair(1, 2.3f); // compile error, C++20可以 结构化绑定不止可以绑定pair和tuple，还可以绑定数组和结构体等 int array[3] = {1, 2, 3}; auto [a, b, c] = array; cout \u003c\u003c a \u003c\u003c \" \" \u003c\u003c b \u003c\u003c \" \" \u003c\u003c c \u003c\u003c endl; // 注意这里的struct的成员一定要是public的 struct Point { int x; int y; }; Point func() { return {1, 2}; } const auto [x, y] = func(); 这里其实可以实现自定义类的结构化绑定，代码如下： // 需要实现相关的tuple_size和tuple_element和get\u003cN\u003e方法。 class Entry { public: void Init() { name_ = \"name\"; age_ = 10; } std::string GetName() const { return name_; } int GetAge() const { return age_; } private: std::string name_; int age_; }; template \u003csize_t I\u003e auto get(const Entry\u0026 e) { if constexpr (I == 0) return e.GetName(); else if constexpr (I == 1) return e.GetAge(); } namespace std { template\u003c\u003e struct tuple_size\u003cEntry\u003e : integral_constant\u003csize_t, 2\u003e {}; template\u003c\u003e struct tuple_element\u003c0, Entry\u003e { using type = std::string; }; template\u003c\u003e struct tuple_element\u003c1, Entry\u003e { using type = int; }; } int main() { Entry e; e.Init(); auto [name, age] = e; cout \u003c\u003c name \u003c\u003c \" \" \u003c\u003c age \u003c\u003c endl; // name 10 return 0; } ","date":"2023-07-12","objectID":"/posts/newfeature/:3:2","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++17] if-switch语句初始化 C++17前if语句需要这样写代码： int a = GetValue(); if (a \u003c 101) { cout \u003c\u003c a; } C++17之后可以这样： // if (init; condition) if (int a = GetValue()); a \u003c 101) { cout \u003c\u003c a; } string str = \"Hi World\"; if (auto [pos, size] = pair(str.find(\"Hi\"), str.size()); pos != string::npos) { std::cout \u003c\u003c pos \u003c\u003c \" Hello, size is \" \u003c\u003c size; } 使用这种方式可以尽可能约束作用域，让代码更简洁，可读性可能略有下降，但是还好 ","date":"2023-07-12","objectID":"/posts/newfeature/:3:3","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++17] 内联变量 C++17前只有内联函数，现在有了内联变量，我们印象中C++类的静态成员变量在头文件中是不能初始化的，但是有了内联变量，就可以达到此目的： // header file struct A { static const int value; }; inline int const A::value = 10; // ==========或者======== struct A { inline static const int value = 10; } ","date":"2023-07-12","objectID":"/posts/newfeature/:3:4","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++17] 折叠表达式 C++17引入了折叠表达式使可变参数模板编程更方便： template \u003ctypename ... Ts\u003e auto sum(Ts ... ts) { return (ts + ...); } int a {sum(1, 2, 3, 4, 5)}; // 15 std::string a{\"hello \"}; std::string b{\"world\"}; cout \u003c\u003c sum(a, b) \u003c\u003c endl; // hello world ","date":"2023-07-12","objectID":"/posts/newfeature/:3:5","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++17] constexpr lambda表达式 C++17前lambda表达式只能在运行时使用，C++17引入了constexpr lambda表达式，可以用于在编译期进行计算。 int main() { // c++17可编译 constexpr auto lamb = [] (int n) { return n * n; }; static_assert(lamb(3) == 9, \"a\"); } 注意：constexpr函数有如下限制： 函数体不能包含汇编语句、goto语句、label、try块、静态变量、线程局部存储、没有初始化的普通变量，不能动态分配内存，不能有new delete等，不能虚函数。 ","date":"2023-07-12","objectID":"/posts/newfeature/:3:6","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++17] namespace嵌套 namespace A { namespace B { namespace C { void func(); } } } // c++17，更方便更舒适 namespace A::B::C { void func();) } ","date":"2023-07-12","objectID":"/posts/newfeature/:3:7","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++17] __has_include预处理表达式 可以判断是否有某个头文件，代码可能会在不同编译器下工作，不同编译器的可用头文件有可能不同，所以可以使用此来判断： #if defined __has_include #if __has_include(\u003ccharconv\u003e) #define has_charconv 1 #include \u003ccharconv\u003e #endif #endif std::optional\u003cint\u003e ConvertToInt(const std::string\u0026 str) { int value{}; #ifdef has_charconv const auto last = str.data() + str.size(); const auto res = std::from_chars(str.data(), last, value); if (res.ec == std::errc{} \u0026\u0026 res.ptr == last) return value; #else // alternative implementation... 其它方式实现 #endif return std::nullopt; } ","date":"2023-07-12","objectID":"/posts/newfeature/:3:8","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++17] 在lambda表达式用*this捕获对象副本 正常情况下，lambda表达式中访问类的对象成员变量需要捕获this，但是这里捕获的是this指针，指向的是对象的引用，正常情况下可能没问题，但是如果多线程情况下，函数的作用域超过了对象的作用域，对象已经被析构了，还访问了成员变量，就会有问题。 struct A { int a; void func() { auto f = [this] { cout \u003c\u003c a \u003c\u003c endl; }; f(); } }; int main() { A a; a.func(); return 0; } ","date":"2023-07-12","objectID":"/posts/newfeature/:3:9","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++17] 所以C++17增加了新特性，捕获*this，不持有this指针，而是持有对象的拷贝，这样生命周期就与对象的生命周期不相关啦。 struct A { int a; void func() { auto f = [*this] { // 这里 cout \u003c\u003c a \u003c\u003c endl; }; f(); } }; int main() { A a; a.func(); return 0; } ","date":"2023-07-12","objectID":"/posts/newfeature/:3:10","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++17] 新增Attribute 我们可能平时在项目中见过__declspec, attribute , #pragma指示符，使用它们来给编译器提供一些额外的信息，来产生一些优化或特定的代码，也可以给其它开发者一些提示信息。 例如: struct A { short f[3]; } __attribute__((aligned(8))); void fatal() __attribute__((noreturn)); 在C++11和C++14中有更方便的方法： [[carries_dependency]] 让编译期跳过不必要的内存栅栏指令 [[noreturn]] 函数不会返回 [[deprecated]] 函数将弃用的警告 [[noreturn]] void terminate() noexcept; [[deprecated(\"use new func instead\")]] void func() {} C++17又新增了三个： [[fallthrough]]，用在switch中提示可以直接落下去，不需要break，让编译期忽略警告 switch (i) {} case 1: xxx; // warning case 2: xxx; [[fallthrough]]; // 警告消除 case 3: xxx; break; } 使得编译器和其它开发者都可以理解开发者的意图。 [[nodiscard]] ：表示修饰的内容不能被忽略，可用于修饰函数，标明返回值一定要被处理 [[nodiscard]] int func(); void F() { func(); // warning 没有处理函数返回值 } [[maybe_unused]] ：提示编译器修饰的内容可能暂时没有使用，避免产生警告 void func1() {} [[maybe_unused]] void func2() {} // 警告消除 void func3() { int x = 1; [[maybe_unused]] int y = 2; // 警告消除 } ","date":"2023-07-12","objectID":"/posts/newfeature/:3:11","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++17] 字符串转换 新增from_chars函数和to_chars函数，直接看代码： #include \u003ccharconv\u003e int main() { const std::string str{\"123456098\"}; int value = 0; const auto res = std::from_chars(str.data(), str.data() + 4, value); if (res.ec == std::errc()) { cout \u003c\u003c value \u003c\u003c \", distance \" \u003c\u003c res.ptr - str.data() \u003c\u003c endl; } else if (res.ec == std::errc::invalid_argument) { cout \u003c\u003c \"invalid\" \u003c\u003c endl; } str = std::string(\"12.34); double val = 0; const auto format = std::chars_format::general; res = std::from_chars(str.data(), str.data() + str.size(), value, format); str = std::string(\"xxxxxxxx\"); const int v = 1234; res = std::to_chars(str.data(), str.data() + str.size(), v); cout \u003c\u003c str \u003c\u003c \", filled \" \u003c\u003c res.ptr - str.data() \u003c\u003c \" characters \\n\"; // 1234xxxx, filled 4 characters } ","date":"2023-07-12","objectID":"/posts/newfeature/:3:12","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++17] std::variant C++17增加std::variant实现类似union的功能，但却比union更高级，举个例子union里面不能有string这种类型，但std::variant却可以，还可以支持更多复杂类型，如map等，看代码： int main() { // c++17可编译 std::variant\u003cint, std::string\u003e var(\"hello\"); cout \u003c\u003c var.index() \u003c\u003c endl; var = 123; cout \u003c\u003c var.index() \u003c\u003c endl; try { var = \"world\"; std::string str = std::get\u003cstd::string\u003e(var); // 通过类型获取值 var = 3; int i = std::get\u003c0\u003e(var); // 通过index获取对应值 cout \u003c\u003c str \u003c\u003c endl; cout \u003c\u003c i \u003c\u003c endl; } catch(...) { // xxx; } return 0; } 注意：一般情况下variant的第一个类型一般要有对应的构造函数，否则编译失败： struct A { A(int i){} }; int main() { std::variant\u003cA, int\u003e var; // 编译失败 } 如何避免这种情况呢，可以使用std::monostate来打个桩，模拟一个空状态。 std::variant\u003cstd::monostate, A\u003e var; // 可以编译成功 ","date":"2023-07-12","objectID":"/posts/newfeature/:3:13","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++17] std::optional 我们有时候可能会有需求，让函数返回一个对象，如下： struct A {}; A func() { if (flag) return A(); else { // 异常情况下，怎么返回异常值呢，想返回个空呢 } } 有一种办法是返回对象指针，异常情况下就可以返回nullptr啦，但是这就涉及到了内存管理，也许你会使用智能指针，但这里其实有更方便的办法就是std::optional。 std::optional\u003cint\u003e StoI(const std::string \u0026s) { try { return std::stoi(s); } catch(...) { return std::nullopt; } } void func() { std::string s{\"123\"}; std::optional\u003cint\u003e o = StoI(s); if (o) { cout \u003c\u003c *o \u003c\u003c endl; } else { cout \u003c\u003c \"error\" \u003c\u003c endl; } } ","date":"2023-07-12","objectID":"/posts/newfeature/:3:14","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++17] std::any C++17引入了any可以存储任何类型的单个值，见代码： int main() { // c++17可编译 std::any a = 1; cout \u003c\u003c a.type().name() \u003c\u003c \" \" \u003c\u003c std::any_cast\u003cint\u003e(a) \u003c\u003c endl; a = 2.2f; cout \u003c\u003c a.type().name() \u003c\u003c \" \" \u003c\u003c std::any_cast\u003cfloat\u003e(a) \u003c\u003c endl; if (a.has_value()) { cout \u003c\u003c a.type().name(); } a.reset(); if (a.has_value()) { cout \u003c\u003c a.type().name(); } a = std::string(\"a\"); cout \u003c\u003c a.type().name() \u003c\u003c \" \" \u003c\u003c std::any_cast\u003cstd::string\u003e(a) \u003c\u003c endl; return 0; } ","date":"2023-07-12","objectID":"/posts/newfeature/:3:15","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++17] std::apply 使用std::apply可以将tuple展开作为函数的参数传入，见代码： int add(int first, int second) { return first + second; } auto add_lambda = [](auto first, auto second) { return first + second; }; int main() { std::cout \u003c\u003c std::apply(add, std::pair(1, 2)) \u003c\u003c '\\n'; std::cout \u003c\u003c add(std::pair(1, 2)) \u003c\u003c \"\\n\"; // error std::cout \u003c\u003c std::apply(add_lambda, std::tuple(2.0f, 3.0f)) \u003c\u003c '\\n'; } ","date":"2023-07-12","objectID":"/posts/newfeature/:3:16","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++17] std::make_from_tuple 使用make_from_tuple可以将tuple展开作为构造函数参数 struct Foo { Foo(int first, float second, int third) { std::cout \u003c\u003c first \u003c\u003c \", \" \u003c\u003c second \u003c\u003c \", \" \u003c\u003c third \u003c\u003c \"\\n\"; } }; int main() { auto tuple = std::make_tuple(42, 3.14f, 0); std::make_from_tuple\u003cFoo\u003e(std::move(tuple)); } ","date":"2023-07-12","objectID":"/posts/newfeature/:3:17","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++17] std::string_view 通常我们传递一个string时会触发对象的拷贝操作，大字符串的拷贝赋值操作会触发堆内存分配，很影响运行效率，有了string_view就可以避免拷贝操作，平时传递过程中传递string_view即可。 void func(std::string_view stv) { cout \u003c\u003c stv \u003c\u003c endl; } int main(void) { std::string str = \"Hello World\"; std::cout \u003c\u003c str \u003c\u003c std::endl; std::string_view stv(str.c_str(), str.size()); cout \u003c\u003c stv \u003c\u003c endl; func(stv); return 0; } ","date":"2023-07-12","objectID":"/posts/newfeature/:3:18","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++17] as_const C++17使用as_const可以将左值转成const类型 std::string str = \"str\"; const std::string\u0026 constStr = std::as_const(str); ","date":"2023-07-12","objectID":"/posts/newfeature/:3:19","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++17] file_system C++17正式将file_system纳入标准中，提供了关于文件的大多数功能，基本上应有尽有，这里简单举几个例子： namespace fs = std::filesystem; fs::create_directory(dir_path); fs::copy_file(src, dst, fs::copy_options::skip_existing); fs::exists(filename); fs::current_path(err_code); ","date":"2023-07-12","objectID":"/posts/newfeature/:3:20","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++17] std::shared_mutex C++17引入了shared_mutex，可以实现读写锁 ","date":"2023-07-12","objectID":"/posts/newfeature/:3:21","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"C++ 20 新特性总结 ","date":"2023-07-12","objectID":"/posts/newfeature/:4:0","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] 新增关键字(keywords) concept requires constinit consteval co_await co_return co_yield char8_t ","date":"2023-07-12","objectID":"/posts/newfeature/:4:1","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] 新增标识符(Identifies) import module ","date":"2023-07-12","objectID":"/posts/newfeature/:4:2","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] 模块(Modules) 优点 没有头文件 声明实现仍然可分离, 但非必要 可以显式指定那些导出(类, 函数等) 不需要头文件重复引入宏 (include guards) 模块之间名称可以相同不会冲突 模块只处理一次, 编译更快 (头文件每次引入都需要处理) 预处理宏只在模块内有效 模块引入顺序无关紧要 ","date":"2023-07-12","objectID":"/posts/newfeature/:4:3","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] 创建模块 // cppcon.cpp export module cppcon; namespace CppCon { auto GetWelcomeHelper() { return \"Welcome to CppCon 2019!\"; } export auto GetWelcome() { return GetWelcomeHelper();} } ","date":"2023-07-12","objectID":"/posts/newfeature/:4:4","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] 引用模块 // main.cpp import cppcon; int main(){ std::cout \u003c\u003c CppCon::GetWelcome(); } ","date":"2023-07-12","objectID":"/posts/newfeature/:4:5","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] import 头文件 import 隐式地将 iostream 转换为模块 加速构建, 因为 iostream 只会处理一次 和预编译头 (PCH) 具有相似的效果 ","date":"2023-07-12","objectID":"/posts/newfeature/:4:6","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] Ranges Ranges 是什么 ? Range 代表一串元素, 或者一串元素中的一段，类似 begin/end 对 好处: 简化语法和方便使用 vector\u003cint\u003e data{11, 22, 33}; sort(begin(data), end(data)); sort(data); // 使用 Ranges 防止 begin/end 不配对 使变换/过滤等串联操作成为可能 相关功能 视图(View): 延迟计算, 不持有, 不改写 Actions: 即时处理(eagerly evaluated), 改写 Algorithms: 所有接受 begin/end 对的算法都可用 Views 和 actions 使用管道符|串联 例子 串联视图 vector\u003cint\u003e data {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}; auto result = data | views::remove_if([](int i) { return i % 2 == 1;}) | views::transform([](int i) { return to_string(i);}); // result = {\"2\", \"4\", \"6\", \"8\", \"10\" }; // 注意 以上操作被延迟, 当你遍历result的时候才触发 串联actions vector\u003cint\u003e data{4, 3, 4, 1, 8, 0, 8}; vector\u003cint\u003e result = data | actions::sort | actions::unique; 排序然后去重 操作会原地对data进行更改, 然后返回 过滤和变换 int total = accumulate ( view::ints(1) | view::transform([](int i) {return i * i;}) | view::take(10), 0); view::ints(1) 产生一个无限的整型数列 平方 取前10个元素, 然后累加(accumulate) 所有的计算延迟到accumulate累加遍历的时候发生 ","date":"2023-07-12","objectID":"/posts/newfeature/:4:7","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] 协程(Coroutines) 什么是协程 它是一个函数 具备如下关键字之一: co_wait: 挂起协程, 等待其它计算完成 co_return: 从协程返回 (协程 return 禁止使用) co_yield: 同 python yield, 弹出一个值, 挂起协程, 下一次调用继续协程的运行 for co_await 循环体 for co_await (for-range-declaration: expression) statement 用处 简化如下问题的实现: generator 异步I/O 延迟计算 事件驱动的程序 例子 experimental::generator\u003cint\u003e GetSequenceGenerator( int startValue, size_t numberOfValues) { for (int i = 0 startValue; i \u003c startValue + numberOfValues; ++i){ time_t t = system_clock::to_time_t(system_clock::now()); cout \u003c\u003c std:: ctime(\u0026t); co_yield i; } } int main() { auto gen = GetSequenceGenerator(10, 5); for (const auto\u0026 value : gen) { cout \u003c\u003c value \u003c\u003c \"(Press enter for next value)\" \u003c\u003c endl; cin.ignore(); } } ","date":"2023-07-12","objectID":"/posts/newfeature/:4:8","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] Concepts 对模板类和函数的模板形参的约束 编译期断言 可声明多个 如何定义 template\u003ctypename T\u003e concept Incrementable = requires(T x) {x++; ++x;}; 使用 template\u003cIncrementable T\u003e void Foo(T t); template\u003ctypename T\u003e requires Incrementable\u003cT\u003e void Foo(T t); template\u003ctypename T\u003e void Foo(T t) requires Incrementable\u003cT\u003e; void Foo(Incrementable auto t); 例子 具备size() 方法, 且返回size_t template \u003ctypename T\u003e concept HasSize = requires (T x){ {x.size()} -\u003e std::convertible_to\u003cstd::size_t\u003e; }; 组合concept template\u003ctypename T\u003e requires Incrementable\u003cT\u003e \u0026\u0026 Decrementable\u003cT\u003e void Foo(T t); // or template\u003ctypename T\u003e concept Incr_Decrementable = Incrementable\u003cT\u003e \u0026\u0026 Decrementable\u003cT\u003e; template\u003cIncr_Decrementable T\u003e void Foo(T t); ","date":"2023-07-12","objectID":"/posts/newfeature/:4:9","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] Lambda 表达式的更新 [=, this] 需要显式捕获this变量 C++20 之前 [=] 隐式捕获this C++20 开始 需要显式捕获this: [=, this] 模板形式的 Lambda 表达式 可以在lambda表达式中使用模板语法 []template\u003cT\u003e(T x) {/* ... */}; []template\u003cT\u003e(T* p) {/* ... */}; []template\u003cT, int N\u003e(T (\u0026a)[N]) {/* ... */}; 原因1 C++20之前: 获取 vector 元素类型, 你需要这么写 auto func = [](auto vec){ using T = typename decltype(vec)::value_type; } C++20 你可以: auto func = []\u003ctypename T\u003e(vector\u003cT\u003e vec){ // ... } 原因2: 方便获取通用lambda形参类型, 访问静态函数 c++20 以前 auto func = [](auto const\u0026 x){ using T = std::decay_t\u003cdecltype(x)\u003e; T copy = x; T::static_function(); using Iterator = typename T::iterator; } C++20 开始 auto func = []\u003ctypename T\u003e(const T\u0026 x){ T copy = x; T::static_function(); using Iterator = typename T::iterator; } 原因3: 完美转发 pre c++20 auto func = [](auto\u0026\u0026 ...args) { return foo(std::forward\u003cdecltype(args)\u003e(args)...); } since c++20 auto func = []\u003ctypename …T\u003e(T\u0026\u0026 …args){ return foo(std::forward(args)...); } Lambda 表达式捕获支持打包展开(Pack Expansion) Pre C++20 template\u003cclass F, class... Args\u003e auto delay_invoke(F f, Args... args){ return [f, args...]{ return std::invoke(f, args...); } } Since c++20 template\u003cclass F, class... Args\u003e auto delay_invoke(F f, Args... args){ // Pack Expansion: args = std::move(args)... return [f = std::move(f), args = std::move(args)...](){ return std::invoke(f, args...); } } ","date":"2023-07-12","objectID":"/posts/newfeature/:4:10","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] 常量表达式(constexpr) 的更新 constexpr 虚函数 constexpr 的虚函数可以重写非 constexpr 的虚函数 非 constexpr 虚函数可以重写 constexpr 的虚函数 constexpr 函数可以: 使用 dynamic_cast() 和 typeid 动态内存分配 更改union成员的值 包含 try/catch 但是不允许****throw语句 在触发常量求值的时候 try/catch 不发生作用 需要开启 constexpr std::vector constexpr string \u0026 vector - std::string 和 std::vector 类型现在可以作为 constexpr - 未来需要支持 constexpr 反射 ","date":"2023-07-12","objectID":"/posts/newfeature/:4:11","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] 原子(Atomic)智能指针 智能指针(shared_ptr)线程安全吗? 是: 引用计数控制单元线程安全, 保证对象只被释放一次 否: 对于数据的读写没有线程安全 如何将智能指针变成线程安全? 使用 mutex 控制智能指针的访问 使用全局非成员原子操作函数访问, 诸如: std::atomic_load(), atomic_store(), … 缺点: 容易出错, 忘记使用这些操作 C++20: atomic\u003cshared_ptr\u003e, atomic\u003cweak_ptr\u003e 内部原理可能使用了mutex 全局非成员原子操作函数标记为不推荐使用(deprecated) 例子 template\u003ctypename T\u003e class concurrent_stack { struct Node { T t; shared_ptr\u003cNode\u003e next; }; atomic_shared_ptr\u003cNode\u003e head; // C++11: 去掉 \"atomic_\" 并且在访问时, 需要用 // 特殊的函数控制线程安全, 例如用std::tomic_load public: class reference { shared_ptr\u003cNode\u003e p; \u003csnip\u003e }; auto find(T t) const { auto p = head.load(); // C++11: atomic_load(\u0026head) while (p \u0026\u0026 p-\u003et != t) p = p-\u003enext; return reference(move(p)); } auto front() const { return reference(head); } void push_front(T t) { auto p = make_shared\u003cNode\u003e(); p-\u003et = t; p-\u003enext = head; while (!head.compare_exchange_weak(p-\u003enext, p)){ } // C++11: atomic_compare_exchange_weak(\u0026head, \u0026p-\u003enext, p); } void pop_front() { auto p = head.load(); while (p \u0026\u0026 !head.compare_exchange_weak(p, p-\u003enext)) { } // C++11: atomic_compare_exchange_weak(\u0026head, \u0026p, p-\u003enext); } }; ","date":"2023-07-12","objectID":"/posts/newfeature/:4:12","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] 自动合流(Joining), 可中断(Cancellable) 的线程 std::jthread 头文件 支持中断 析构函数中自动 Join 析构函数调用 stop_source.request_stop() 然后 join() 中断线程执行 头文件 \u003cstop_token\u003e std::stop_token 用来查询线程是否中断 可以和condition_variable_any配合使用 std::stop_source 用来请求线程停止运行 stop_resources 和 stop_tokens 都可以查询到停止请求 std::stop_callback 如果对应的stop_token 被要求终止, 将会触发回调函数 用法: std::stop_callback myCallback(myStopToken, []{ /* … */ }); 例子 自动合流 Join std::thread 在析构函数中如果线程 joinable() 会直接调用 std::terminate() 直接导致程序退出 void DoWorkPreCpp20() { std::thread job([] { /* ... */ }); try { // ... Do something else ... } catch (...) { job.join(); throw; // rethrow } job.join(); } void DoWork() { std::jthread job([] { /* ... */ }); // ... Do something else ... } // jthread destructor automatically calls join() 中断 std::jthread job([](std::stop_token token) { while (!token.stop_requested()) { //... } }); //... job.request_stop(); // auto source = job.get_stop_source() // auto token = job.get_stop_token() ","date":"2023-07-12","objectID":"/posts/newfeature/:4:13","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] C++20 同步(Synchronization)库 信号量(Semaphore), 维基百科请走这里 头文件 轻量级的同步原语 可用来实现任何其他同步概念, 如: mutex, latches, barriers, … 两种类型: 多元信号量(counting semaphore): 建模非负值资源计数 二元信号量(binary semaphore): 只有一个插孔, 两种状态, 最适合实现mutex std::atomic 等待和通知接口 等待/阻塞在原子对象直到其值发生改变, 通过通知函数发送通知 比轮训(polling)来的更高效 方法 wait() notify_one() notify_all() 锁存器(Latch)和屏障(Barrier) 头文件 线程的同步点 线程将阻塞在这个位置, 直到到达的线程个数达标才放行, 放行之后不再关闭 锁存器只会作用一次 屏障(Barriers) 在每个阶段中 一个参与者运行至屏障点时被阻塞，需要等待其他参与者都到达屏障点, 当到达线程数达标之后 阶段完成的回调将被执行 线程计数器被重置 开启下一阶段 线程得以继续执行 ","date":"2023-07-12","objectID":"/posts/newfeature/:4:14","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] std::atomic_ref 头文件 Atomic 引用 通过引用访问变为原子操作, 被引用对象可以为非原子类型 ","date":"2023-07-12","objectID":"/posts/newfeature/:4:15","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] 指定初始化(Designated Initializers) struct Data { int anInt = 0; std::string aString; }; Data d{ .aString = \"Hello\" }; ","date":"2023-07-12","objectID":"/posts/newfeature/:4:16","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] 航天飞机操作符 \u003c=\u003e 正规名称: 三路比较运算符 三路比较结果如下 (a \u003c=\u003e b) \u003c 0 // 如果 a \u003c b 则为 true (a \u003c=\u003e b) \u003e 0 // 如果 a \u003e b 则为 true (a \u003c=\u003e b) == 0 // 如果 a 与 b 相等或者等价 则为 true 类似于C的strcmp 函数返回-1, 0, 1 一般情况: 自动生成所有的比较操作符, 如果对象是结构体则逐个比较, 可以用下面代码代替所有的比较运算符 auto X::operator\u003c=\u003e(const Y\u0026) = default; 高级情况: 指定返回类型(支持6种所有的比较运算符) 示例: class Point { int x; int y; public: friend bool operator==(const Point\u0026 a, const Point\u0026 b){ return a.x==b.x \u0026\u0026 a.y==b.y; } friend bool operator\u003c (const Point\u0026 a, const Point\u0026 b){ return a.x \u003c b.x || (a.x == b.x \u0026\u0026 a.y \u003c b.y); } friend bool operator!=(const Point\u0026 a, const Point\u0026 b) { return !(a==b); } friend bool operator\u003c=(const Point\u0026 a, const Point\u0026 b) { return !(b\u003ca); } friend bool operator\u003e (const Point\u0026 a, const Point\u0026 b) { return b\u003ca; } friend bool operator\u003e=(const Point\u0026 a, const Point\u0026 b) { return !(a\u003cb); } // ... 其他非比较函数 ... }; #include \u003ccompare\u003e class Point { int x; int y; public: auto operator\u003c=\u003e(const Point\u0026) const = default; // 比较操作符自动生成 // ... 其他非比较函数 ... }; 标准库类型支持 \u003c=\u003e vector, string, map, set, sub_match, … ","date":"2023-07-12","objectID":"/posts/newfeature/:4:17","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] 范围 for 循环语句支持初始化语句 switch 语句初始化 (C++17): struct Foo { int value; int result; }; Foo GetData() { return Foo(); } int main() { switch (auto data = GetData(); data.value) { case 1: return data.result; } } if 语句初始化 (C++17): struct Foo { int value; int result; }; Foo* GetData() { return new Foo(); } int main() { if (auto data = GetData(); data) { // Use 'data’ } } 创建完整的日期 year_mouth_day fulldate1{2019y, September, 18d}; auto fulldate2 = 2019y / September / 18d; year_mouth_day fulldate3{Monday[3]/September/2019}; // Monday[3] 表示第三个星期一 新的事件间隔单位, 类似于秒, 分钟, … using days = duration\u003csigned interger type of at least 25bits, ratio_multiply\u003cratio\u003c24\u003e, hours::period\u003e\u003e; using weeks = ...; using mouths = ...; using years = ...; 例子 weeks w{1}; // 1 周 days d{w}; // 将 1 周 转换成天数 新的时钟类型, (之前有 system_clock, steady_clock, high_resolution_clock): utc_clock: represents Coordinated Universal Time (UTC), measures time since 00:00:00 UTC, Thursday, 1 January 1970, including leap seconds tai_clock: represents International Atomic Time (TAI), measures time since 00:00:00, 1 January 1958, and was offseted 10 seconds ahead of UTC at that date, it does not include leap seconds gps_clock: represents Global Positioning System (GPS) time, measures time since 00:00:00, 6 January 1980 UTC, it does not include leap seconds file_clock: alias for the clock used for std::filesystem::file_time_type, epoch is unspecified 新增system_clock相关的别名 template\u003cclass Duration\u003e using sys_time = std::chrono::time_point\u003cstd::chrono::system_clock, Duration\u003e; using sys_seconds = sys_time\u003cstd::chrono::seconds\u003e; using sys_days = sys_time\u003cstd::chrono::days\u003e; // 用例: system_clock::time_point t = sys_days{ 2019y / September / 18d }; // date -\u003e time_point auto yearmonthday = year_month_day{ floor\u003cdays\u003e(t) }; // time_point -\u003e date 日期 + 事件 auto t = sys_days{2019y/September/18d} + 9h + 35min + 10s; // 2019-09-18 09:35:10 UTC 时区转换 // Convert UTC to Denver time: zoned_time denver = { \"America/Denver\", t }; // Construct a local time in Denver: auto t = zoned_time{ \"America/Denver\", local_days{Wednesday[3] / September / 2019} + 9h }; // Get current local time: auto t = zoned_time{ current_zone(), system_clock::now() }; ","date":"2023-07-12","objectID":"/posts/newfeature/:4:18","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] std::span 头文件 某段连续数据的”视图” 不持有数据, 不分配和销毁数据 拷贝非常快, 推荐复制的方式传参(类似 string_view) 不支持数据跨步(stride) 可通过运行期确定长度也可编译器确定长度 int data[42]; span\u003cint, 42\u003e a {data}; // fixed-size: 42 ints span\u003cint\u003e b {data}; // dynamic-size: 42 ints span\u003cint, 50\u003e c {data}; // compilation error span\u003cint\u003e d{ ptr, len }; // dynamic-size: len ints ","date":"2023-07-12","objectID":"/posts/newfeature/:4:19","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] 特性测试宏 通过它可以判断编译器是否支持某个功能, 例如 语言特性 __has_cpp_attribute(fallthrough) __cpp_binary_literals __cpp_char8_t __cpp_coroutines 标准库特性 __cpp_lib_concepts __cpp_lib_ranges __cpp_lib_scoped_lock 包含 C++ 标准库版本, 发布日期, 版权证书, 特性宏等 ","date":"2023-07-12","objectID":"/posts/newfeature/:4:20","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] consteval函数 constexpr 函数可能编译期执行, 也可以在运行期执行, consteval 只能在编译器执行, 如果不满足要求编译不通过。 ","date":"2023-07-12","objectID":"/posts/newfeature/:4:21","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] constinit 强制指定以常量方式初始化 const char* GetStringDyn() { return \"dynamic init\"; } constexpr const char* GetString(bool constInit) { return constInit ? \"constant init\" : GetStringDyn(); } constinit const char* a = GetString(true); // ✔ constinit const char* b = GetString(false); // ❌ ","date":"2023-07-12","objectID":"/posts/newfeature/:4:22","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] 用 using 引用 enum 类型 enum class CardTypeSuit { Clubs, Diamonds, Hearts, Spades }; std::string_view GetString(const CardTypeSuit cardTypeSuit) { switch (cardTypeSuit) { case CardTypeSuit::Clubs: return \"Clubs\"; case CardTypeSuit::Diamonds: return \"Diamonds\"; case CardTypeSuit::Hearts: return \"Hearts\"; case CardTypeSuit::Spades: return \"Spades\"; } } std::string_view GetString(const CardTypeSuit cardTypeSuit) { switch (cardTypeSuit) { using enum CardTypeSuit; // 这里 case Clubs: return \"Clubs\"; case Diamonds: return \"Diamonds\"; case Hearts: return \"Hearts\"; case Spades: return \"Spades\"; } } ","date":"2023-07-12","objectID":"/posts/newfeature/:4:23","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] 格式化库(std::format) 不展开, 类似Python 的格式化, std::string s = std::format(\"Hello CppCon {}!\", 2019); ","date":"2023-07-12","objectID":"/posts/newfeature/:4:24","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] 增加数学常量 再也不用为 M_PI 发愁啦 头文件 包含 e, log2e, log10e pi, inv_pi, inv_sqrt pi ln2, ln10 sqrt2, sqrt3, inv_sqrt3 egamma ","date":"2023-07-12","objectID":"/posts/newfeature/:4:25","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] std::source_location 用于获取代码位置, 对于日志和错误信息尤其有用 ","date":"2023-07-12","objectID":"/posts/newfeature/:4:26","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] [[nodiscard(reason)]] 表明返回值不可抛弃, 加入理由的支持 [[nodiscard(\"Ignoring the return value will result in memory leaks.\")]] void* GetData() { /* ... */ } ","date":"2023-07-12","objectID":"/posts/newfeature/:4:27","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] 位运算 加入循环移位, 计数0和1位等功能 ","date":"2023-07-12","objectID":"/posts/newfeature/:4:28","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":"[C++20] 一些小更新 字符串支持 starts_with, ends_with map 支持 contains 查询是否存在某个键 list 和 forward list 的 remove, remove_if 和 unique 操作返回 size_type 表明删除个数 增加 shift_left, shift_right midpoint 计算中位数, 可避免溢出 lerp 线性插值 lerp( float a, float b, float t ) 返回 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-SIYwBQJu-1628786141278)(https://www.zhihu.com/equation?tex=a+%2B+t(b-a)]) 新的向量化策略 unsequenced_policy(execution::unseq) std::string str = \"Hello world!\"; bool b = str.starts_with(\"Hello\"); // starts_with, ends_with std::map myMap{ std::pair{1, \"one\"s}, {2, \"two\"s}, {3, \"three\"s} }; bool result = myMap.contains(2); // contains, 再也不用 .find() == .end() 了 ref: [1]. https://blog.csdn.net/qq_41854911/article/details/119657617 ","date":"2023-07-12","objectID":"/posts/newfeature/:4:29","tags":["C++"],"title":"C++ 新特性 | C++11\\C++14\\C++17","uri":"/posts/newfeature/"},{"categories":["C++"],"content":" quote c++ 八股文 第一部分 ","date":"2023-07-11","objectID":"/posts/basics_two/:0:0","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"6 基础知识(六) ","date":"2023-07-11","objectID":"/posts/basics_two/:1:0","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"6.1 构造函数为什么不能定义为虚函数？ ⽽析构函数⼀般写成虚函数的原因 ？ 构造函数不能声明为虚函数的原因是: 1 构造一个对象的时候，必须知道对象的实际类型，而虚函数行为是在运行期间确定实际类型的。而在构造一个对象时，由于对象还未构造成功。编译器无法知道对象 的实际类型，是该类本身，还是该类的一个派生类，或是更深层次的派生类。无法确定。 2 虚函数的执行依赖于虚函数表。而虚函数表在构造函数中进行初始化工作，即初始化vptr，让他指向正确的虚函数表。而在构造对象期间，虚函数表还没有被初始化，将无法进行。 虚函数的意思就是开启动态绑定，程序会根据对象的动态类型来选择要调用的方法。然而在构造函数运行的时候，这个对象的动态类型还不完整，没有办法确定它到底是什么类型，故构造函数不能动态绑定。（动态绑定是根据对象的动态类型而不是函数名，在调用构造函数之前，这个对象根本就不存在，它怎么动态绑定？） 编译器在调用基类的构造函数的时候并不知道你要构造的是一个基类的对象还是一个派生类的对象。 析构函数设为虚函数的作用: 解释：在类的继承中，如果有基类指针指向派生类，那么用基类指针delete时，如果不定义成虚函数，派生类中派生的那部分无法析构。（如果基类的析构函数不是虚函数，那么在delete 基类指针时，只调用基类的析构函数，不会调用派生类的析构函数，故派生类部分不会被析构。） ","date":"2023-07-11","objectID":"/posts/basics_two/:1:1","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"6.2 c/c++中register关键字（寄存器、缓存、内存） c/c++中register关键字（寄存器、缓存、内存） 一般情况下，变量的值是存储在内存中的，CPU 每次使用数据都要从内存中读取。如果有一些变量使用非常频繁，从内存中读取就会消耗很多时间，例如 for 循环中的增量控制。 为了解决这个问题，可以将使用频繁的变量放在CPU的通用寄存器中，这样使用该变量时就不必访问内存，直接从寄存器中读取，大大提高程序的运行效率。 寄存器、缓存、内存 为了加深对 register 变量的理解，这里有必要讲一下CPU寄存器。 按照与CPU的远近来分，离CPU最近的是寄存器，然后是缓存，最后是内存。 寄存器是最贴近CPU的，而且CPU只在寄存器中进行存取。寄存的意思是暂时存放数据，不用每次都从内存中读取，它是一个临时的存放数据的空间。 而寄存器的数据又来源于内存，于是 CPU \u003c– 寄存器 \u003c– 内存，这就是它们之间的信息交换。 那么为什么还需要缓存呢？因为如果频繁地操作内存中同一地址上的数据会影响速度，于是就在寄存器和内存之间设置一个缓存，把使用频繁的数据暂时保存到缓存，如果寄存器需要读取内存中同一地址上的数据，就不用大老远地再去访问内存，直接从缓存中读取即可。 缓存的速度远高于内存，价格也是如此。 注意：缓存的容量是有限的，寄存器只能从缓存中读取到部分数据，对于使用不是很频繁的数据，会绕过缓存，直接到内存中读取。所以不是每次都能从缓存中得到数据，这就是缓存的命中率，能够从缓存中读取就命中，否则就没命中。 关于缓存的命中率又是一门学问，哪些数据保留在缓存，哪些数据不保留，都有复杂的算法。 注意：上面所说的CPU是指CPU核心，从市场上购买的CPU已是封装好的套件，附带了寄存器和缓存，插到主板上就可以用。 从经济和速度的综合考虑，缓存又被分为一级缓存、二级缓存和三级缓存，它们的存取速度和价格依次降低，容量依次增加。购买到的CPU一般会标出三级缓存的容量。 register 变量 寄存器的数量是有限的，通常是把使用最频繁的变量定义为 register 的。 关于寄存器变量有以下事项需要注意： 为寄存器变量分配寄存器是动态完成的，因此，只有局部变量和形式参数才能定义为寄存器变量。 局部静态变量不能定义为寄存器变量，因为一个变量只能声明为一种存储类别。 寄存器的长度一般和机器的字长一致，所以，只有较短的类型如int、char、short等才适合定义为寄存器变量，诸如double等较大的类型，不推荐将其定义为寄存器类型。 CPU的寄存器数目有限，因此，即使定义了寄存器变量，编译器可能并不真正为其分配寄存器，而是将其当做普通的auto变量来对待，为其分配栈内存。当然，有些优秀的编译器，能自动识别使用频繁的变量，如循环控制变量等，在有可用的寄存器时，即使没有使用 register 关键字，也自动为其分配寄存器，无须由程序员来指定。 c++中register 在早期c语言编译器不会对代码进行优化，因此使用register关键字修饰变量是很好的补充，大大提高的速度。 register关键字请求让编译器将变量a直接放入寄存器里面，以提高读取速度，在C语言中register关键字修饰的变量不可以被取地址，但是c++中进行了优化。 c++中依然支持register关键字，但是c++编译器也有自己的优化方式，即某些变量不用register关键字进行修饰，编译器也会将多次连续使用的变量优化放入寄存器中，例如入for循环的循环变量i。 c++中也可以对register修饰的变量取地址，不过c++编译器发现程序中需要取register关键字修饰的变量的地址时，register关键字的声明将变得无效。 ","date":"2023-07-11","objectID":"/posts/basics_two/:1:2","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"6.3 c/c++中进程和线程的区别 c++多线程编程 – 进程与线程区别 c++面试-操作系统篇 面试必考 | 进程和线程的区别 何为进程(process)? 进程是一个应用程序被操作系统拉起来加载到内存之后从开始执行到执行结束的这样一个过程。简单来说，进程是程序（应用程序，可执行文件）的一次执行。进程通常由程序、数据和进程控制块（PCB）组成。比如双击打开一个桌面应用软件就是开启了一个进程。 传统的进程有两个基本属性：可拥有资源的独立单位；可独立调度和分配的基本单位。对于这句话我的理解是：进程可以获取操作系统分配的资源，如内存等；进程可以参与操作系统的调度，参与CPU的竞争，得到分配的时间片，获得处理机（CPU）运行。 进程在创建、撤销和切换中，系统必须为之付出较大的时空开销，因此在系统中开启的进程数不宜过多。比如你同时打开十几个应用软件试试，电脑肯定会卡死的。于是紧接着就引入了线程的概念。 何为线程(thread)? 线程是进程中的一个实体，是被系统独立分配和调度的基本单位。也有说，线程是CPU可执行调度的最小单位。也就是说，进程本身并不能获取CPU时间，只有它的线程才可以。 引入线程之后，将传统进程的两个基本属性分开了，线程作为调度和分配的基本单位，进程作为独立分配资源的单位。我对这句话的理解是：线程参与操作系统的调度，参与CPU的竞争，得到分配的时间片，获得处理机（CPU）运行。而进程负责获取操作系统分配的资源，如内存。 线程基本上不拥有资源，只拥有一点运行中必不可少的资源，它可与同属一个进程的其他线程共享进程所拥有的全部资源。 线程具有许多传统进程所具有的特性，故称为“轻量型进程”。同一个进程中的多个线程可以并发执行。 进程和线程的区别？ 线程分为用户级线程和内核支持线程两类，用户级线程不依赖于内核，该类线程的创建、撤销和切换都不利用系统调用来实现; 内核支持线程依赖于内核，即无论是在用户进程中的线程，还是在系统中的线程，它们的创建、撤销和切换都利用系统调用来实现。 但是，与线程不同的是，无论是系统进程还是用户进程，在进行切换时，都要依赖于内核中的进程(process)调度。因此，无论是什么进程都是与内核有关的，是在内核支持下进程切换的。尽管线程和进程表面上看起来相似，但是他们在本质上是不同的。 根据操作系统中的知识，进程至少必须有一个线程，通常将此线程称为主线程。 进程要独立地占用系统资源（如内存），而同一进程的线程之间是共享资源的。进程本身并不能获取CPU时间，只有它的线程才可以。 其他 进程在创建、撤销和切换过程中，系统的时空开销非常大。用户可以通过创建线程来完成任务，以减少程序并发执行时付出的时空开销。例如可以在一个进程中设置多个线程，当一个线程受阻时，第二个线程可以继续运行，当第二个线程受阻时，第三个线程可以继续运行……。这样，对于拥有资源的基本单位（进程），不用频繁的切换，进一步提高了系统中各种程序的并发程度。 ref: [1].https://blog.csdn.net/qq_41803340/category_10405604.html [待整理内容] ","date":"2023-07-11","objectID":"/posts/basics_two/:1:3","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"一.常考C++基础概念 ","date":"2023-07-11","objectID":"/posts/basics_two/:2:0","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"1.C++三大特性（封装、继承、多态） 封装： 隐藏类的属性和实现细节，仅仅对外提供接口， 封装性实际上是由编译器去识别关键字public、private和protected来实现的， 体现在类的成员可以有公有成员(public)，私有成员(private)，保护成员(protected)。 私有成员是在封装体内被隐藏的部分，只有类体内声明的函数(类的成员函数)才可以访问私有成员， 而在类体外的函数是不能访问的，公有成员(public)是封装体与外界的一个接口， 类体外的函数可以访问公有成员，保护成员是只有该类的成员函数和该类的派生类才可以访问的。 优点：隔离变化；便于使用；提高重用性；提高安全性 缺点：如果封装太多，影响效率；使用者不能知道代码具体实现。 继承： 被继承的是父类（基类），继承出来的是子类（派生类），子类拥有父类的所有的特性。 继承方式有公有继承、私有继承，保护继承。默认是私有继承 *公有继承中父类的公有和保护成员在子类中不变，私有的在子类中不可访问。 *私有继承中父类的公有和保护成员在子类中变为私有，但私有的在子类中不可访问。 *保护继承中父类的公有和保护成员在子类中变为保护，但私有的在子类中不可访问。 c++语言允许单继承和多继承 优点：继承减少了重复的代码、继承是多态的前提、继承增加了类的耦合性； 缺点：继承在编译时刻就定义了，无法在运行时刻改变父类继承的实现； 父类通常至少定义了子类的部分行为，父类的改变都可能影响子类的行为； 如果继承下来的子类不适合解决新问题，父类必须重写或替换，那么这种依赖关系就限制了灵活性， 最终限制了复用性。 虚继承：为了解决多重继承中的二义性问题，它维护了一张虚基类表。 (菱形继承问题) 多态: ref: 多态的四种表现形式 运行时多态(虚函数) 编译时多态(模板) 重载 类型转换 运行时多态(Subtype Polymorphism/Runtime Polymorphism) 运行时多态就是派生类重写基类的虚函数，在调用函数里，参数为基类的指针或引用，会构成多态。我之前写过一篇多态的原理，就是在讲多态(运行时多态)在底层是怎么实现的 多态的底层实现 举个例子：比如买票这个行为，成人去买就是全价，学生买就是半价票。但是不管成人还是学生都是人这个体系。所以我们需要根据谁来买票才能决定价格，这个时候就需要多态。 #include \u003ciostream\u003e class ticket { public: virtual void price() = 0; }; class adult : public ticket { public: virtual void price() override { std::cout \u003c\u003c \"成人全价！\" \u003c\u003c std::endl; } }; class student : public ticket { public: virtual void price() override { std::cout \u003c\u003c \"学生半价！\" \u003c\u003c std::endl; } }; void BuyTicket(ticket\u0026 t) { t.price(); } int main(void) { adult a; student s; BuyTicket(a); BuyTicket(s); return 0; } 编译时多态(Parametric Polymorphism/Compile-Time Polymorphism) 编译时多态就是模板。在程序编译时，编译器根据参数的类型，就将生成某种类型的函数或类。我之前关于模板的(总结)[https://blog.csdn.net/weixin_42678507/article/details/88658291] 举个简单的例子：Add() 函数是一个非常简单的函数，但是如果你写一个整型的 Add 函数，那么我想加 double 型的呢？你再写一个 double 型的 Add 函数，那么我想加 char 型的呢？ 这个时候就用到了模板，我们先定义一个逻辑，具体类型等编译时再生成该类型的函数或类。 #include \u003ciostream\u003e template\u003cclass T\u003e T Add(T lhs, T rhs) { return lhs + rhs; } int main(void) { Add(1, 2); Add(2.0, 3.0); Add('a', 'b'); return 0; } 重载(Ad-hoc Polymorphism/Overloading) 函数名相同，参数不同就构成了重载。重载主要用于函数，当某个函数的功能无法处理某些参数的情况时，我们就可以重载一个函数来单独处理。 举个例子：比如说上面的 Add 函数，当前内置类型都可以处理，但是如果我传两个字符串怎么办？就不可以像刚才那么加了。得重载一个函数单独处理。 #include \u003ciostream\u003e #include \u003cstring\u003e int Add(int lhs, int rhs) { return lhs + rhs; } std::string Add(const std::string\u0026 lhs, const std::string\u0026 rhs) { std::string ans(lhs); ans += rhs; return ans; } int main(void) { Add(1, 2); Add(\"abc\", \"def\"); return 0; } 类型转换(Coercion Polymorphism/Casting) 类型转换主要分为四种： static_cast: 相当于隐式类型转换。 const_cast: 这个可以去除一个 const 变量的 const 性质，使可以改变它的值。 reinterpret_cast: 相当于强制类型转换。 dynamic_cast: 这个可以使子类指针或引用赋值给父类指针或引用。 类型转换很简单，这里就不多赘述了。 ","date":"2023-07-11","objectID":"/posts/basics_two/:2:1","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"2.数组和链表的区别 数组和链表是两种不同的数据存储方式 数组的定义 数组是一组具有相同数据类型的变量的集合，这些变量称之为集合的元素。 每个元素都有一个编号，称之为下标，可以通过下标来区别并访问数组元素，数组元素的个数叫做数据的长度。 链表的定义 链表是一种物理存储单元上非连续、非顺序的存储结构,数据元素的逻辑顺序是通过链表中的指针链接次序实现的。 链表的特性是在中间任意位置插入和删除元素都非常快，不需要移动其它元素。 对于单向链表而言，链表中的每一个元素都要保存一个指向下一个元素的指针。 对于双向链表而言，链表中的每个元素既要保存指向下一个元素的指针，又要保存指向上一个元素的指针。 对于双向循环链表而言，链表中的最后一个元素保存一个指向第一个元素的指针。 数组和链表的区别主要表现在以下几个方面 比较 数组 链表 逻辑结构 (1) 数组在内存中连续； (2)使用数组之前，必须事先固定数组长度，不支持动态改变数组大小； (3) 数组元素增加时，有可能会数组越界； (4) 数组元素减少时，会造成内存浪费； （5）数组增删时需要移动其它元素 (1) 链表采用动态内存分配的方式，在内存中不连续 (2)支持动态增加或者删除元素 (3) 需要时可以使用malloc或者new来申请内存，不用时使用free或者delete来释放内存 内存结构 数组从栈上分配内存，使用方便，但是自由度小 链表从堆上分配内存，自由度大，但是要注意内存泄漏 访问效率 数组在内存中顺序存储，可通过下标访问，访问效率高 链表访问效率低，如果想要访问某个元素，需要从头遍历 越界问题 数组的大小是固定的，所以存在访问越界的风险 越界的风险 只要可以申请得到链表空间，链表就无越界风险 数组和链表的使用场景 比较 数组使用场景 链表使用场景 空间 数组的存储空间是栈上分配的，存储密度大，当要求存储的大小变化不大时，且可以事先确定大小，宜采用数组存储数据 链表的存储空间是堆上动态申请的，当要求存储的长度变化较大时，且事先无法估量数据规模，宜采用链表存储 时间 数组访问效率高。当线性表的操作主要是进行查找，很少插入和删除时，宜采用数组结构 链表插入、删除效率高，当线性表要求频繁插入和删除时，宜采用链表结构 ","date":"2023-07-11","objectID":"/posts/basics_two/:2:2","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"3. 智能指针 我们知道除了静态内存和栈内存外，每个程序还有一个内存池，这部分内存被称为自由空间或者堆。程序用堆来存储动态分配的对象即那些在程序运行时分配的对象，当动态对象不再使用时，我们的代码必须显式的销毁它们。 在C++中，动态内存的管理是用一对运算符完成的：new和delete，new:在动态内存中为对象分配一块空间并返回一个指向该对象的指针，delete：指向一个动态独享的指针，销毁对象，并释放与之关联的内存。 动态内存管理经常会出现两种问题：一种是忘记释放内存，会造成内存泄漏；一种是尚有指针引用内存的情况下就释放了它，就会产生引用非法内存的指针。 为了更加容易（更加安全）的使用动态内存，引入了智能指针的概念。智能指针的行为类似常规指针，重要的区别是它负责自动释放所指向的对象。标准库提供的两种智能指针的区别在于管理底层指针的方法不同，shared_ptr允许多个指针指向同一个对象，unique_ptr则“独占”所指向的对象。标准库还定义了一种名为weak_ptr的伴随类，它是一种弱引用，指向shared_ptr所管理的对象，这三种智能指针都定义在memory头文件中。 1 智能指针的作用 智能指针是一个类，用来存储指向动态分配对象的指针，负责自动释放动态分配的对象，防止堆内存泄漏。动态分配的资源，交给一个类对象去管理，当类对象生命周期结束时，自动调用析构函数释放资源 2 智能指针的种类: shared_ptr、unique_ptr、weak_ptr、auto_ptr 四种指针详情 2.1 智能指针的实现原理 智能指针的实现原理就是在一个类的内部封装了类对象的指针，然后在析构函数里对我们的类对象指针进行释放，因为类的析构是在类对象生命期结束时自动调用的，这样我们就省去了手动释放内存的操作，避免忘记手动释放导致的内存泄漏。 2.2 C++11四种智能指针总结 2.2.1 auto_ptr： auto_ptr以前是用在C98中，C++11被抛弃，头文件一般用来作为独占指针 auto_ptr被赋值或者拷贝后，失去对原指针的管理 auto_ptr不能管理数组指针，因为auto_ptr的内部实现中，析构函数中删除对象使用delete而不是delete[]，释放内存的时候仅释放了数组的第一个元素的空间，会造成内存泄漏。 auto_ptr不能作为容器对象，因为STL容器中的元素经常要支持拷贝，赋值等操作。 2.2.2 unique_ptr: C++11中用来替代auto_ptr 拷贝构造和赋值运算符被禁用，不能进行拷贝构造和赋值运算 虽然禁用了拷贝构造和赋值运算符，但unique_ptr可以作为返回值，用于从某个函数中返回动态申请内存的所有权，本质上是移动拷贝，就是使用std:move()函数，将所有权转移。 2.2.3 share_ptr: 多个指针可以指向相同的对象，调用release()计数-1，计数0时资源释放 .use_count()查计数 .reset()放弃内部所有权 share_ptr多次引用同一数据会导致内存多次释放 循环引用会导致死锁， 引用计数不是原子操作。 shared_ptr 有两个数据成员，一个是指向 对象的指针 ptr，另一个是 ref_count 指针（包含vptr、use_count、weak_count、ptr等）； 在这里插入图片描述 shared_ptr\u003cFoo\u003e x(new Foo); shared_ptr\u003cFoo\u003e y = x; 步骤一： `y=x` 涉及两个成员的复制，这两步拷贝不会同时（原子）发生，中间步骤 1，复制 ptr 指针，中间步骤 2，复制 ref_count 指针，导致引用计数加 1 步骤二: 因为是两步，如果没有 mutex 保护，那么在多线程里就有数据竞争。 多线程读写同一个 shared_ptr 必须加锁。 2.2.4 weak_ptr: 1.解决两个share_ptr互相引用产生死锁，计数永远降不到0，没办法进行资源释放，造成内存泄漏的问题。 2.使用时配合share_ptr使用，把其中一个share_ptr更换为weak_ptr。 ","date":"2023-07-11","objectID":"/posts/basics_two/:2:3","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"4. 重载、重写、重定义 (1) 重载（overload）： 指函数名相同，但是它的参数表列个数或顺序，类型不同。但是不能靠返回类型来判断。 a 相同的范围（在同一个类中） b 函数名字相同、 参数不同 c virtual关键字可有可无 d 返回值可以不同； (2) 重写（覆盖override)是指派生类函数覆盖基类函数，特征是： a 不同的范围，分别位于基类和派生类中 b 函数的名字相同、 参数相同 c 基类函数必须有virtual关键字，不能有static d 返回值相同（或者协变），否则报错； e 重写函数的访问修饰符可以不同。尽管virtual是private的，派生类中重写改写为public, protected也是可以的 (3) 重定义(隐藏redefine)是指派生类的函数屏蔽了与其同名的基类函数，特征是： a 不在同一个作用域（分别位于派生类与基类） b 函数名字相同 c 返回值可以不同 d 规则： 如果派生类的函数和基类的函数同名，但是参数不同，此时，不管有无virtual，基类的函数被隐藏； 如果派生类的函数与基类的函数同名，并且参数也相同，但是基类函数没有vitual关键字，此时，基类的函数被隐藏。 ps: 多态性可以分为静态多态性（方法的重载，一个类）和动态多态性（方法的覆盖，有继承关系的类之间的行为）。进而多态性可以由重载和覆盖来实现。 ","date":"2023-07-11","objectID":"/posts/basics_two/:2:4","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"5.static与const区别和作用 static: 1.**static局部变量**将一个变量声明为函数的局部变量，那么这个局部变量在函数执行完不会释放，而是继续保留在内存中； 2.**static全局变量**表示一个变量在当前文件的全局可以访问； 3.**static函数**表示一个函数只能在当前文件中被访问； 4.**static类成员变量**表示这个成员为全类所共有； 5.**static类成员函数**表示这个函数为全类所有，且只能访问成员变量。 6.全局变量在整个工程文件内有效；静态全局变量只在定义它的文件中有效； 7.静态局部变量只在定义它的函数内有效，且程序只分配一次内存，函数返回时不会释放，下次调用时不会重新赋值，还保留上次结果值；局部变量在函数返回时就释放掉； 8.全局变量和静态变量编译器会默认初始化为0；局部变量的默认值未知； 9.局部静态变量与全局变量共享全局数据，但是静态局部变量值在定义该变量的函数内部可见。 10.静态成员（静态成员函数）与非静态成员（成员函数）的区别在于有无this指针；静态成员是静态存储，必须进行初始化； 11.静态成员函数访问非静态成员报错: 静态成员在类加载时就已经分配内存，而此时非静态成员尚未分配内存，访问不存在的内存自然会报错； const 1.\u003cfont color=red\u003econst常量\u003c/font\u003e 定义时必须初始化，以后不能修改； 2.\u003cfont color=red\u003econst形参\u003c/font\u003e 该形参在函数里不能被修改； 3.\u003cfont color=red\u003econst修饰类成员函数\u003c/font\u003e 该函数对成员变量只能进行读操作； static关键字作用 1.函数体内static变量的作用范围为该函数体，该变量的内存只被分配一次，因此该值在下次调用时还维持上一次的值； 2.在模块内的static函数和变量可以被可以被模块内的函数访问，不能被模块外的函数访问； 3.在类内的static成员变量为整个类所有，类的所有对象只有一份拷贝； 4.在类内的static成员函数为整个类所有，这个函数不接收this指针，因此只能访问类的static成员变量； const关键字 1.阻止一个变量被改变； 2.声明常量指针和指针常量； 3.const修饰形参，表示为输入参数，在函数体内不能修改该参数的值； 4.const修饰成员函数，表明为一个常函数，不能修改成员变量的值； 5.类的成员函数，有时必须返回const类型的值，使得返回值不能为左值。 const修饰指针有三种情况 const修饰指针 — 常量指针 (const修饰的是指针,指针指向可以改,指针指向的值不可以更改) const int * p1 = \u0026a; p1 = \u0026b; //正确 //*p1 = 100; 报错 const修饰常量 — 指针常量 (const修饰的是常量,指针指向不可以改,指针指向的值可以更改) int * const p2 = \u0026a; //p2 = \u0026b; //错误 *p2 = 100; //正确 const即修饰指针,又修饰常量 (const既修饰指针又修饰常量，都不可以改) const int * const p3 = \u0026a; //p3 = \u0026b; //错误 //*p3 = 100; //错误 技巧:看const右侧紧跟着的是指针还是常量, 是指针就是常指针,是常量就是指针常量 ","date":"2023-07-11","objectID":"/posts/basics_two/:2:5","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"6. const与宏定义（#define）区别和作用 const 定义的是变量不是常量，只是这个变量的值不允许改变，是常变量，带有类型。编译运行的时候起作用，存在类型检查。 define 定义的是不带类型的常数，只进行简单的字符替换。在预编译的时候起作用，不存在类型检查。 1、两者的区别 (1) 编译器处理方式不同 #define 宏是在预处理阶段展开。 const 常量是编译运行阶段使用。 (2) 类型和安全检查不同 #define 宏没有类型，不做任何类型检查，仅仅是展开。 const 常量有具体的类型，在编译阶段会执行类型检查。 (3) 存储方式不同 #define宏仅仅是展开，有多少地方使用，就展开多少次，不会分配内存。（宏定义不分配内存，变量定义分配内存。） const常量会在内存中分配(可以是堆中也可以是栈中)。 (4) const 可以节省空间，避免不必要的内存分配。 例如： const 定义常量从汇编的角度来看，只是给出了对应的内存地址，而不是象 #define 一样给出的是立即数，所以，const 定义的常量在程序运行过程中只有一份拷贝（因为是全局的只读变量，存在静态区），而 #define 定义的常量在内存中有若干个拷贝。 (5) 提高了效率。 编译器通常不为普通const常量分配存储空间，而是将它们保存在符号表中，这使得它成为一个编译期间的常量，没有了存储与读内存的操作，使得它的效率也很高。 (6) 宏替换只作替换，不做计算，不做表达式求解;宏预编译时就替换了，程序运行时，并不分配内存。计算时注意边缘效应 ","date":"2023-07-11","objectID":"/posts/basics_two/:2:6","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"7.虚函数和纯虚函数区别 1.虚函数和纯虚函数可以定义在同一个类中，含有纯虚函数的类被称为抽象类，而只含有虚函数的类不能被称为抽象类。 2.虚函数可以被直接使用，也可以被子类重载以后，以多态的形式调用，而纯虚函数必须在子类中实现该函数才可以使用，因为纯虚函数在基类有声明而没有定义。 3.虚函数和纯虚函数都可以在子类中被重载，以多态的形式被调用。 4.虚函数和纯虚函数通常存在于抽象基类之中，被继承的子类重载，目的是提供一个统一的接口。 5.虚函数的定义形式：virtual{};纯虚函数的定义形式：virtual { } = 0;在虚函数和纯虚函数的定义中不能有static标识符，原因很简单，被static修饰的函数在编译时要求前期绑定,然而虚函数却是动态绑定，而且被两者修饰的函数生命周期也不一样。 6.虚函数充分体现了面向对象思想中的继承和多态性这两大特性，在C++语言里应用极广。比如在微软的MFC类库中，你会发现很多函数都有virtual关键字，也就是说，它们都是虚函数。难怪有人甚至称虚函数是C++语言的精髓。 7.定义纯虚函数就是为了让基类不可实例化，因为实例化这样的抽象数据结构本身并没有意义或者给出实现也没有意义。 纯虚函数只是一个接口，是个函数的声明而已，它要留到子类里去实现。 虚函数在子类里面也可以不重载的；但纯虚必须在子类去实现，这就像Java的接口一样。通常我们把很多函数加上virtual，是一个好的习惯，虽然牺牲了一些性能，但是增加了面向对象的多态性，因为你很难预料到父类里面的这个函数不在子类里面不去修改它的实现 虚函数: https://www.cnblogs.com/zkfopen/p/11061414.html ","date":"2023-07-11","objectID":"/posts/basics_two/:2:7","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"8. 指针和引用的区别 1.指针和引用的定义和性质区别： (1) 指针：指针是一个变量，只不过这个变量存储的是一个地址，指向内存的一个存储单元；而引用跟原来的变量实质上是同一个东西，只不过是原变量的一个别名而已。如： int a=1;int *p=\u0026a; int a=1;int \u0026b=a; 上面定义了一个整形变量和一个指针变量p，该指针变量指向a的存储单元，即p的值是a存储单元的地址。 而下面2句定义了一个整形变量a和这个整形a的引用b，事实上a和b是同一个东西，在内存占有同一个存储单元。 (2)引用不可以为空，当被创建的时候，必须初始化，而指针可以是空值，可以在任何时候被初始化。 (3)可以有const指针，但是没有const引用； (4)指针可以有多级，但是引用只能是一级（int **p；合法 而 int \u0026\u0026a是不合法的） (5)指针的值可以为空，但是引用的值不能为NULL，并且引用在定义的时候必须初始化； (6)指针的值在初始化后可以改变，即指向其它的存储单元，而引用在进行初始化后就不会再改变了。 (7)“sizeof引用\"得到的是所指向的变量(对象)的大小，而\"sizeof指针\"得到的是指针本身的大小； (8)指针和引用的自增(++)运算意义不一样； (9)如果返回动态内存分配的对象或者内存，必须使用指针，引用可能引起内存泄漏； ","date":"2023-07-11","objectID":"/posts/basics_two/:2:8","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"9. 结构体赋值 (结构体赋值)[https://blog.csdn.net/datase/article/details/78988320] ","date":"2023-07-11","objectID":"/posts/basics_two/:2:9","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"10. C和C++区别 (C和C++区别)[https://blog.csdn.net/czc1997/article/details/81254971] ","date":"2023-07-11","objectID":"/posts/basics_two/:2:10","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"11. C和C++传参方式区别 C语言不支持引用传参，如果想要改变传入参数的值，只能用传入指针的方式。 ","date":"2023-07-11","objectID":"/posts/basics_two/:2:11","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"12. 深拷贝和浅拷贝区别 (深拷贝和浅拷贝区别)[https://blog.csdn.net/Situo/article/details/110225143] ","date":"2023-07-11","objectID":"/posts/basics_two/:2:12","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"13. 避免头文件重复包含以及宏定义重定义 #ifndef LWIP_TCP_KEEPALIVE #define LWIP_TCP_KEEPALIVE #endif ","date":"2023-07-11","objectID":"/posts/basics_two/:2:13","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"14. 你怎么理解虚拟类？虚拟类可以实例化一个对象吗？为什么？它的作用和其他类的区别 答案：虚拟类可以派生对象，纯虚类不可以实例化对象。因为纯虚类存在未定义的函数，只是个概念，不可真实存在。虚拟类用做多态，纯虚类做接口。 ","date":"2023-07-11","objectID":"/posts/basics_two/:2:14","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"15. 内联函数怎么实现的，什么时期处理的，优缺点 答案：在程序编译时，编译器将程序中出现的内联函数的调用表达式用内联函数的函数体来进行替换。 优点：不会产生函数调用的开销 缺点：增加目标程序的代码量，即增加空间开销 ","date":"2023-07-11","objectID":"/posts/basics_two/:2:15","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"16 .位运算（按位与、按位或、异或） 按位与运算符（\u0026） 参加运算的两个数，按二进制位进行“与”运算。 运算规则：只有两个数的二进制同时为1，结果才为1，否则为0。（负数按补码形式参加按位与运算） 即 0 \u0026 0= 0 ，0 \u0026 1= 0，1 \u0026 0= 0， 1 \u0026 1= 1。 例：3 \u00265 即 00000011 \u0026 00000101 = 00000001 ，所以 3 \u0026 5的值为1。 按位或运算符（|） 参加运算的两个数，按二进制位进行“或”运算。 运算规则：参加运算的两个数只要两个数中的一个为1，结果就为1。 即 0 | 0= 0 , 1 | 0= 1 ， 0 | 1= 1 , 1 | 1= 1 。 例：2 | 4 即 00000010 | 00000100 = 00000110 ，所以2 | 4的值为 6 。 异或运算符（^） 参加运算的两个数，按二进制位进行“异或”运算。 运算规则：参加运算的两个数，如果两个相应位为“异”（值不同），则该位结果为1，否则为0。 即 0 ^ 0=0 ， 0 ^ 1= 1 ， 1 ^ 0= 1 ， 1 ^ 1= 0 。 例： 2 ^ 4 即 00000010 ^ 00000100 =00000110 ，所以 2 ^ 4 的值为6 。 ","date":"2023-07-11","objectID":"/posts/basics_two/:2:16","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"17. 原码、反码、补码 原码：是最简单的机器数表示法。用最高位表示符号位，‘1’表示负号，‘0’表示正号。其他位存放该数的二进制的绝对值。 反码：正数的反码还是等于原码 负数的反码就是他的原码除符号位外，按位取反。 补码：正数的补码等于他的原码 负数的补码等于反码+1。 ","date":"2023-07-11","objectID":"/posts/basics_two/:2:17","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"18 . 堆和栈 (堆和栈)[https://blog.csdn.net/qq_45856289/article/details/106473750] ","date":"2023-07-11","objectID":"/posts/basics_two/:2:18","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"19. 类和对象 面向对象(Object Oriented,OO)。 起初，“面向对象”是指在程序设计中采用封装、继承、多态等设计方法。现在，面向对象的思想已经涉及到软件开发的各个方面。如，面向对象的分析（OOA，ObjectOriented Analysis），面向对象的设计（OOD，Object Oriented Design）、以及面向对象的编程实现（OOP，Object Oriented Programming）。 对象和类解释： 1）对象：对象是人们要进行研究的任何事物，它不仅能表示具体的事物，还能表示抽象的规则、计划或事件。对象具有状态，一个对象用数据值来描述它的状态。对象还有操作，用于改变对象的状态，对象及其操作就是对象的行为。对象实现了数据和操作的结合，使数据和操作封装于对象的统一体中。 2）类：具有相同特性（数据元素）和行为（功能）的对象的抽象就是类。因此，对象的抽象是类，类的具体化就是对象，也可以说类的实例是对象，类实际上就是一种数据类型。类具有属性，它是对象的状态的抽象，用数据结构来描述类的属性。类具有操作，它是对象的行为的抽象，用操作名和实现该操作的方法来描述。 对象和类的关系： 类与对象的关系就如模具和铸件的关系，类的实力化的结果就是对象，而对对象的抽象就是类，类描述了一组有相同特性（属性）和相同行为的对象。 ","date":"2023-07-11","objectID":"/posts/basics_two/:2:19","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"20 . new和malloc区别 0.属性 new/delete是C++关键字，需要编译器支持。malloc/free是库函数，需要头文件支持。 1.参数 使用new操作符申请内存分配时无须指定内存块的大小，编译器会根据类型信息自行计算。而malloc则需要显式地指出所需内存的尺寸。 2.返回类型 new操作符内存分配成功时，返回的是对象类型的指针，类型严格与对象匹配，无须进行类型转换，故new是符合类型安全性的操作符。 而malloc内存分配成功则是返回void * ，需要通过强制类型转换将void*指针转换成我们需要的类型。 3.分配失败 new内存分配失败时，会抛出bac_alloc异常。malloc分配内存失败时返回NULL。 4.自定义类型 new会先调用operator new函数，申请足够的内存（通常底层使用malloc实现）。然后调用类型的构造函数，初始化成员变量，最后返回自定义类型指针。delete先调用析构函数，然后调用operator delete函数释放内存（通常底层使用free实现）。 malloc/free是库函数，只能动态的申请和释放内存，无法强制要求其做自定义类型对象构造和析构工作。 5.重载 C++允许重载new/delete操作符，特别的，布局new的就不需要为对象分配内存，而是指定了一个地址作为内存起始区域，new在这段内存上为对象调用构造函数完成初始化工作，并返回此地址。而malloc不允许重载。 6.内存区域 new操作符从自由存储区（free store）上为对象动态分配内存空间，而malloc函数从堆上动态分配内存。自由存储区是C++基于new操作符的一个抽象概念，凡是通过new操作符进行内存申请，该内存即为自由存储区。而堆是操作系统中的术语，是操作系统所维护的一块特殊内存，用于程序的内存动态分配，C语言使用malloc从堆上分配内存，使用free释放已分配的对应内存。自由存储区不等于堆，如上所述，布局new就可以不位于堆中 ","date":"2023-07-11","objectID":"/posts/basics_two/:2:20","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"21. 内核链表与双向循环链表 (内核链表与双向循环链表)[https://blog.csdn.net/liebao_han/article/details/53956609] ","date":"2023-07-11","objectID":"/posts/basics_two/:2:21","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"22. 结构体和类的区别 1.结构体是一种值类型，而类是引用类型。值类型用于存储数据的值，引用类型用于存储对实际数据的引用。 那么结构体就是当成值来使用的，类则通过引用来对实际数据操作。 结构体使用栈存储（Stack Allocation），而类使用堆存储（Heap Allocation) 栈的空间相对较小.但是存储在栈中的数据访问效率相对较高. 堆的空间相对较大.但是存储在堆中的数据的访问效率相对较低. 3.类是反映现实事物的一种抽象，而结构体的作用只是一种包含了具体不同类别数据的一种包装，结构体不具备类的继承多态特性 4.结构体赋值是 直接赋值的值. 而对象的指针 赋值的是对象的地址 5.Struct变量使用完之后就自动解除内存分配，Class实例有垃圾回收机制来保证内存的回收处理。 6.结构体的构造函数中，必须为结构体所有字段赋值，类的构造函数无此限制 首先,关于隐式构造函数.我们知道,在1个类中如果我们没有为类写任意的构造函数,那么C++编译器在编译的时候会自动的为这个类生成1个无参数的构造函数.我们将这个构造函数称之为隐式构造函数 但是一旦我们为这个类写了任意的1个构造函数的时候,这个隐式的构造函数就不会自动生成了.在结构体中,就不是这样了,在结构体中隐式的构造函数无论如何都存在。所以程序员不能手动的为结构添加1个无参数的构造函数。 7.结构体中声明的字段无法赋予初值，类可以: 如何选择结构体还是类 1． 堆栈的空间有限，对于大量的逻辑的对象，创建类要比创建结构好一些 2． 结构表示如点、矩形和颜色这样的轻量对象，例如，如果声明一个含有 1000 个点对象的数组，则将为引用每个对象分配附加的内存。在此情况下，结构的成本较低。 3． 在表现抽象和多级别的对象层次时，类是最好的选择 4． 大多数情况下该类型只是一些数据时，结构时最佳的选择 ","date":"2023-07-11","objectID":"/posts/basics_two/:2:22","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"23. 结构体和联合体区别 两者最大的区别在于内存利用 一、结构体struct 各成员各自拥有自己的内存，各自使用互不干涉，同时存在的，遵循内存对齐原则。一个struct变量的总长度等于所有成员的长度之和。 二、联合体union 各成员共用一块内存空间，并且同时只有一个成员可以得到这块内存的使用权(对该内存的读写)，各变量共用一个内存首地址。因而，联合体比结构体更节约内存。一个union变量的总长度至少能容纳最大的成员变量，而且要满足是所有成员变量类型大小的整数倍。 ","date":"2023-07-11","objectID":"/posts/basics_two/:2:23","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"24. 结构体和枚举 一、结构体 结构体:很像面向对象中的对象，但是结构体没有方法只有属性，一个结构体由不同类型的元素组成，而相较于数组来说，数组只能存储相同类型的元素。结构体占用的空间等于内部各元素占用空间的和，并且元素在内存中的地址（按照元素定义的顺序）是连续的。 注意：结构体不能像面向对象中那样递归调用，自己包含自己，但是可以包含其他类型的结构体。 二、枚举 枚举:和面向对象中一样，枚举都是用来定义一些固定取值的常量,但是C中的枚举中的值是整数，默认按照0递增,也可以在定义枚举的时候赋值，那么后面的元素的值就会以这个元素为第一个元素递增 ","date":"2023-07-11","objectID":"/posts/basics_two/:2:24","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"25 . 数组和指针的区别与联系 (数组和指针的区别与联系)[https://blog.csdn.net/cherrydreamsover/article/details/81741459] ","date":"2023-07-11","objectID":"/posts/basics_two/:2:25","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"26 . 函数指针\u0026指针函数 https://blog.csdn.net/baidu_37973494/article/details/83150266 ","date":"2023-07-11","objectID":"/posts/basics_two/:2:26","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"27 . const放在函数前后的区别 1、int GetY() const; 2、const int * GetPosition(); 对于1 该函数为只读函数，不允许修改其中的数据成员的值。 对于2 修饰的是返回值，表示返回的是指针所指向值是常量 ","date":"2023-07-11","objectID":"/posts/basics_two/:2:27","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"28 . goto语句 goto语句也称为无条件转移语句，其一般格式如下： goto 语句标号； 其中语句标号是按标识符规定书写的符号， 放在某一语句行的前面，标号后加冒号(：)。语句标号起标识语句的作用，与goto 语句配合使用。举个例子： goto label; cout \u003c\u003c \"This is the\" ","date":"2023-07-11","objectID":"/posts/basics_two/:2:28","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"29 . extern关键字 1、extern用在变量或者函数的声明前，用来说明“此变量/函数是在别处定义的，要在此处引用”。extern声明不是定义，即不分配存储空间。也就是说，在一个文件中定义了变量和函数， 在其他文件中要使用它们， 可以有两种方式：使用头文件，然后声明它们，然后其他文件去包含头文件；在其他文件中直接extern。 2、extern C作用 链接指示符extern C 如果程序员希望调用其他程序设计语言尤其是C 写的函数，那么调用函数时必须告诉编译器使用不同的要求，例如当这样的函数被调用时函数名或参数排列的顺序可能不同，无论是C++函数调用它还是用其他语言写的函数调用它，程序员用链接指示符告诉编译器该函数是用其他的程序设计语言编写的，链接指示符有两种形式既可以是单一语句形式也可以是复合语句形式。 // 单一语句形式的链接指示符 extern “C” void exit(int); // 复合语句形式的链接指示符 extern “C” { int printf( const char* … ); int scanf( const char* … ); } // 复合语句形式的链接指示符 extern “C” { #include } 链接指示符的第一种形式由关键字extern 后跟一个字符串常量以及一个普通的函数，声明构成虽然函数是用另外一种语言编写的但调用它仍然需要类型检查例如编译器会检查传递给函数exit()的实参的类型是否是int 或者能够隐式地转换成int 型，多个函数声明可以用花括号包含在链接指示符复合语句中，这是链接指示符的第二种形式花扩号被用作分割符表示链接指示符应用在哪些声明上在其他意义上该花括号被忽略，所以在花括号中声明的函数名对外是可见的就好像函数是在复合语句外声明的一样，例如在前面的例子中复合语句extern “C\"表示函数printf()和scanf()是在C 语言中写的，函数因此这个声明的意义就如同printf()和scanf()是在extern “C\"复合语句外面声明的一样，当复合语句链接指示符的括号中含有#include 时，在头文件中的函数声明都被假定是用链接指示符的程序设计语言所写的，在前面的例子中在头文件中声明的函数都是C函数链接指示符不能出现在函数体中下列代码段将会导致编译错误。 int main() { // 错误: 链接指示符不能出现在函数内 extern \"C\" double sqrt( double ); 305 第七章函数 double getValue(); //ok double result = sqrt ( getValue() ); //... return 0; } 如果把链接指示符移到函数体外程序编译将无错误 extern \"C\" double sqrt( double ); int main() { double getValue(); //ok double result = sqrt ( getValue() ); //... return 0; } 但是把链接指示符放在头文件中更合适，在那里函数声明描述了函数的接口所属，如果我们希望C++函数能够为C 程序所用又该怎么办呢我们也可以使用extern \"C\"链接指示符来使C++函数为C 程序可用例如。 // 函数calc() 可以被C 程序调用 extern \"C\" double calc( double dparm ) { /* ... */ } 如果一个函数在同一文件中不只被声明一次则链接指示符可以出现在每个声明中它，也可以只出现在函数的第一次声明中，在这种情况下第二个及以后的声明都接受第一个声明中链接指示符指定的链接规则例如 // ---- myMath.h ---- extern \"C\" double calc( double ); // ---- myMath.C ---- // 在Math.h 中的calc() 的声明 #include \"myMath.h\" // 定义了extern \"C\" calc() 函数 // calc() 可以从C 程序中被调用 double calc( double dparm ) { // ... 在本节中我们只看到为C 语言提供的链接指示extern \"C\"，extern \"C\"是惟一被保证由所有C++实现都支持的，每个编译器实现都可以为其环境下常用的语言提供其他链接指示例如extern \"Ada\"可以用来声明是用Ada 语言写的函数，extern \"FORTRAN\"用来声明是用FORTRAN 语言写的函数，等等因为其他的链接指示随着具体实现的不同而不同所以建议读者查看编译器的用户指南以获得其他链接指示符的进一步信息。 总结 extern “C” extern “C” 不但具有传统的声明外部变量的功能，还具有告知C++链接器使用C函数规范来链接的功能。 还具有告知C++编译器使用C规范来命名的功能。 ","date":"2023-07-11","objectID":"/posts/basics_two/:2:29","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"30 . 动态内存管理 (动态内存管理)[https://blog.csdn.net/zgege/article/details/82054076] ","date":"2023-07-11","objectID":"/posts/basics_two/:2:30","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"31 .数组、链表、哈希、队列、栈数据结构特点，各自优点和缺点 数组(Array)： 优点：查询快，通过索引直接查找；有序添加，添加速度快，允许重复； 缺点：在中间部位添加、删除比较复杂，大小固定，只能存储一种类型的数据； 如果应用需要快速访问数据，很少插入和删除元素，就应该用数组。 链表(LinkedList)： 优点：有序添加、增删改速度快，对于链表数据结构，增加和删除只要修改元素中的指针就可以了； 缺点：查询慢，如果要访问链表中一个元素，就需要从第一个元素开始查找； 如果应用需要经常插入和删除元素，就应该用链表。 栈(Stack)： 优点：提供后进先出的存储方式，添加速度快，允许重复； 缺点：只能在一头操作数据，存取其他项很慢； 队列(Queue)： 优点：提供先进先出的存储方式，添加速度快，允许重复； 缺点：只能在一头添加，另一头获取，存取其他项很慢； 哈希(Hash)： 特点：散列表，不允许重复； 优点：如果关键字已知则存取速度极快； 缺点：如果不知道关键字则存取很慢，对存储空间使用不充分； ","date":"2023-07-11","objectID":"/posts/basics_two/:2:31","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"32. 友元函数 引入友元函数的原因 类具有封装、继承、多态、信息隐藏的特性，只有类的成员函数才可以访问类的私有成员，非成员函数只能访问类的公有成员。为了使类的非成员函数访问类的成员，唯一的做法就是将成员定义为public，但这样做会破坏信息隐藏的特性。基于以上原因，引入友元函数解决。 (友元函数)[https://blog.csdn.net/qq_26337701/article/details/53996104] ","date":"2023-07-11","objectID":"/posts/basics_two/:2:32","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"33. 设计模式之单例模式、工厂模式、发布订阅模式以及观察者模式 (设计模式)[https://blog.csdn.net/m0_37322399/article/details/108515158] ","date":"2023-07-11","objectID":"/posts/basics_two/:2:33","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"34. 构造函数： 什么是构造函数？ 通俗的讲，在类中，函数名和类名相同的函数称为构造函数。它的作用是在建立一个对象时，做某些初始化的工作（例如对数据赋予初值）。C++允许同名函数，也就允许在一个类中有多个构造函数。如果一个都没有，编译器将为该类产生一个默认的构造函数。 构造函数上惟一的语法限制是它不能指定返回类型，甚至void 也不行。 不带参数的构造函数：一般形式为 类名 对象名(){函数体} 带参数的构造函数：不带参数的构造函数，只能以固定不变的值初始化对象。带参数构造函数的初始化要灵活的多，通过传递给构造函数的参数，可以赋予对象不同的初始值。一般形式为：构造函数名（形参表）； 创建对象使用时：类名 对象名（实参表）； 构造函数参数的初始值：构造函数的参数可以有缺省值。当定义对象时，如果不给出参数，就自动把相应的缺省参数值赋给对象。一般形式为： 构造函数名（参数=缺省值，参数=缺省值，……）; 析构函数： 当一个类的对象离开作用域时，析构函数将被调用(系统自动调用)。析构函数的名字和类名一样，不过要在前面加上 ~ 。对一个类来说，只能允许一个析构函数，析构函数不能有参数，并且也没有返回值。析构函数的作用是完成一个清理工作，如释放从堆中分配的内存。 一个类中可以有多个构造函数，但析构函数只能有一个。对象被析构的顺序，与其建立时的顺序相反，即后构造的对象先析构。 1、概念不同： 析构函数：对象所在的函数已调用完毕时，系统自动执行析构函数。 构造函数：是一种特殊的方法。特别的一个类可以有多个构造函数 ，可根据其参数个数的不同或参数类型的不同来区分它们 即构造函数的重载。 2、作用不同： 析构函数：析构函数被调用。 构造函数：为对象成员变量赋初始值 3、目的不同： 析构函数：”清理善后” 的工作 构造函数：主要用来在创建对象时初始化对象， 即为对象成员变量赋初始值，总与new运算符一起使用在创建对象的语句中。 ","date":"2023-07-11","objectID":"/posts/basics_two/:2:34","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"35. C++模板 https://blog.csdn.net/zhaizhaizhaiaaa/article/details/104091658 ","date":"2023-07-11","objectID":"/posts/basics_two/:2:35","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"36. C++ STL https://www.cnblogs.com/shiyangxt/archive/2008/09/11/1289493.html ref: https://blog.csdn.net/qq_52621551/article/details/122960158 ","date":"2023-07-11","objectID":"/posts/basics_two/:2:36","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"c++ 八股文 ","date":"2023-07-11","objectID":"/posts/basics_two/:3:0","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":"关键字与运算符 1. 指针与引⽤ 指针：存放某个对象的地址，其本⾝就是变量（命了名的对象），本⾝就有地址，所以可以有指向指针的指针；可变，包括其所指向的地址的改变和其指向的地址中所存放的数据的改变 (地址可变，地址存储的值也可变) 引⽤：就是变量的别名，从⼀⽽终，不可变，必须初始化， 不存在指向空值的引⽤，但是存在指向空值的指针 2. const 关键字 const的作⽤：被它修饰的值不能改变，是只读变量。必须在定义的时候就给它赋初值。 顶层const: 表示指针本身是个常量 底层const: 表示指针所指的对象是一个常量 2.1 常量指针（底层const）（指针指的对象不可改变） 常量指针：是指定义了⼀个指针，这个指针指向⼀个只读的对象，不能通过常量指针来改变这个对象的值。常量指针强调的是指针对其所指对象的不可改变性。 特点：靠近变量名 形式: const 数据类型 *指针变量 = 变量名 数据类型 const *指针变量 = 变量名 举例: int temp = 10; const int* a = \u0026temp; int const *a = \u0026temp; 2.2 指针常量（顶层const）(指针不能改变) 指针常量：指针常量是指定义了⼀个指针，这个指针的值只能在定义时初始化，其他地⽅不能改变。指针常量强调的是指针的不可改变性。 特点: 靠近变量类型 形式: 数据类型 * const 指针变量=变量名 实例: int* const p = \u0026temp 3. define 和 typedef的区别 ref : https://blog.csdn.net/CSSDCC/article/details/122049204 ref : https://zhuanlan.zhihu.com/p/513450251 ","date":"2023-07-11","objectID":"/posts/basics_two/:3:1","tags":["basics"],"title":"C++ 基础知识[二]","uri":"/posts/basics_two/"},{"categories":["C++"],"content":" Overview c++ 八股文 第一部分 ","date":"2023-07-11","objectID":"/posts/basics_one/:0:0","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"1. 基础知识(一) ","date":"2023-07-11","objectID":"/posts/basics_one/:1:0","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"1.1 C++语言的特点 ①C++在C的基础上引入了面向对象机制，同时也兼容C语言； ②C++三大特性：封装、继承、多态； ③C++程序结构清晰、易于扩充、程序可读性好； ④C++代码质量高，运行效率高、仅比汇编语言慢10%~20%； ⑥C++可复用性高，C++引入了模板的概念，有专门的模板库(STL)； ⑦C++是不断发展的语言，C++11中新引入了nullptr、auto变量、Lambda匿名函数、右值引用、智能指针。 C++面向对象的三大特征 封装性： 将客观事物抽象成类，每个类对自身的数据和方法实行访问控制，包括(private，protected，public)。 继承性： 广义的继承有三种实现形式：实现继承(使用基类的属性和方法而无需额外编码的能力)、可视继承(子窗体使用父窗体的外观和实现代码)、接口继承(仅使用属性和方法，实现滞后到子类实现)。 多态性： 是将父类对象设置成为和一个或更多它的子对象相等的技术。用子类对象给父类对象赋值之后，父类对象就可以根据当前赋值给它的子对象的特性以不同的方式运作。 ","date":"2023-07-11","objectID":"/posts/basics_one/:1:1","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"1.2 C++和C语言的区别 ① C语言是C++的子集，C++可以很好兼容C语言。但是C++又有很多新特性，如引用、智能指针、auto变量等； ② C++是面对对象(object-oriented)的编程语言；C语言是面对过程(process-oriented)的编程语言； ③ C语言有一些不安全的语言特性，如指针使用的潜在危险、强制转换的不确定性、内存泄露等。而C++对此增加了不少新特性来改善安全性，如const常量、引用、cast转换、智能指针、try—catch等等； ④ C++可复用性高，C++引入了模板的概念，后面在此基础上，实现了方便开发的标准模板库STL。C++的STL库相对于C语言的函数库更灵活、更通用。 ","date":"2023-07-11","objectID":"/posts/basics_one/:1:2","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"1.3 C++中 struct 和 class 的区别 ① struct 一般用于描述一个数据结构集合，而 class 是强调对一个对象数据的封装； ② struct 中默认的访问控制权限是 public 的，而 class 中默认的访问控制权限是 private 的； ③ 在继承关系中，struct 默认是公有继承，而 class 是私有继承； ④ class关键字可以用于定义模板参数，就像typename，而 struct 不能用于定义模板参数。 ","date":"2023-07-11","objectID":"/posts/basics_one/:1:3","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"1.4 include头文件的顺序以及双引号\"\"和尖括号\u003c\u003e的区别 区别： ① 尖括号\u003c \u003e的头文件是系统文件，双引号\" \"的头文件是自定义文件; ② 编译器预处理阶段查找头文件的路径不一样； 查找路径： ① 使用尖括号\u003c \u003e(系统文件)的头文件的查找路径：编译器设置的头文件路径$\\rightarrow$系统变量; ② 使用双引号\" \"(自定义文件)的头文件的查找路径：当前头文件目录$\\rightarrow$编译器设置的头文件路径$\\rightarrow$系统变量。 ","date":"2023-07-11","objectID":"/posts/basics_one/:1:4","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"1.5 C++结构体和C结构体的区别 ①C的结构体内不允许有函数存在，C++允许有内部成员函数，且允许该函数是虚函数； ②C的结构体对内部成员变量的访问权限只能是public，而C++允许 public，protected，private三种； ③C 中使用结构体需要加上 struct 关键字，或者对结构体使用 typedef 取别名，而 C++ 中可以省略 struct 关键字直接使用； ④C语言的结构体是不可以继承的，C++的结构体是可以从其他的结构体或者类继承过来的。 ","date":"2023-07-11","objectID":"/posts/basics_one/:1:5","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"1.6 导入C函数的关键字是什么，C++编译时和C有什么不同？ 关键字： 在C++中，导入C函数的关键字是extern，表达形式为extern \"C\"， extern \"C\" 的主要作用就是为了能够正确实现C++代码调用其他C语言代码。加上extern \"C\"后，会指示编译器这部分代码按C语言的进行编译，而不是C++的。 编译区别： 由于C++支持函数重载，因此编译器编译函数的过程中会将函数的参数类型也加到编译后的代码中，而不仅仅是函数名；而C语言并不支持函数重载，因此编译C语言代码的函数时不会带上函数的参数类型，一般只包括函数名。 总结: 区别在于在编译过程中是否带上函数的参数类型，C++带，C不带。 ","date":"2023-07-11","objectID":"/posts/basics_one/:1:6","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"1.7 简述C++从代码到可执行二进制文件的过程 预编译、编译、汇编、链接 ①预编译：这个过程主要的处理操作如下： (1) 将所有的#define删除，并且展开所有的宏定义 (2) 处理所有的条件预编译指令，如#if、#ifdef (3) 处理#include预编译指令，将被包含的文件插入到该预编译指令的位置。 (4) 过滤所有的注释 (5) 添加行号和文件名标识 ②编译：这个过程主要的处理操作如下： (1) 词法分析：将源代码的字符序列分割成一系列的记号。 (2) 语法分析：对记号进行语法分析，产生语法树。 (3) 语义分析：判断表达式是否有意义。 (4) 代码优化： (5) 目标代码生成：生成汇编代码。 (6) 目标代码优化 ③汇编：这个过程主要是将汇编代码转变成机器可以执行的指令(汇编代码转为机器码)。 ④链接：将不同的源文件产生的目标文件进行链接，从而形成一个可以执行的程序(链接目标文件，形成可执行程序)。 ​ 链接分为静态链接和动态链接。 (1) 静态链接，是在链接的时候就已经把要调用的函数或者过程链接到了生成的可执行文件中，就算你再去把静态库删除也不会影响可执行程序的执行；生成的静态链接库，Windows下以.lib为后缀，Linux下以.a为后缀。 (2) 动态链接，是在链接的时候没有把调用的函数代码链接进去，而是在执行的过程中，再去找要链接的函数，生成的可执行文件中没有函数代码，只包含函数的重定位信息，所以当你删除动态库时，可执行程序就不能运行。生成的动态链接库，Windows下以.dll为后缀，Linux下以.so为后缀。 ","date":"2023-07-11","objectID":"/posts/basics_one/:1:7","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"1.8 static关键字的作用 ①定义全局静态变量和局部静态变量：在变量前面加上static关键字。static的变量默认初始化为0。初始化的静态变量会在数据段分配内存，未初始化的静态变量会在BSS段分配内存。直到程序结束，静态变量始终会维持前值。只不过全局静态变量(在整个工程文件有效)和局部静态变量(在当前定义的文件内有效)的作用域不一样；(什么是数据段和BBS段内存分配?) ②定义静态函数：在函数返回类型前加上static关键字，函数即被定义为静态函数。静态函数只能在本源文件中使用；static int func() ③在变量类型前加上static关键字，变量即被定义为静态变量。静态变量只能在本源文件中使用; ④类内静态成员变量: 在c++中，static关键字可以用于定义类中的静态成员变量：使用静态数据成员，它既可以被当成全局变量那样去存储，但又被隐藏在类的内部。类中的static静态数据成员拥有一块单独的存储区，而不管创建了多少个该类的对象。所有这些对象的静态数据成员都共享这一块静态存储空间，static修饰的变量要在类外初始化。 ⑤类内静态成员函数:在c++中，static关键字可以用于定义类中的静态成员函数：与静态成员变量类似，类里面同样可以定义静态成员函数。只需要在函数前加上关键字static即可。如静态成员函数也是类的一部分，而不是对象的一部分。所有这些对象的静态数据成员都共享这一块静态存储空间，只能访问类的static成员变量，static修饰的变量要在类外初始化。 ","date":"2023-07-11","objectID":"/posts/basics_one/:1:8","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"1.9 数组和指针的区别 概念： (1)数组：数组是用于储存多个相同类型数据的集合。数组名是首元素的地址。 (2)指针：指针相当于一个变量，但是它和一般变量不一样，它存放的是其它变量在内存中的地址。指针名指向了内存的首地址。 区别： 赋值：同类型指针变量可以相互赋值；数组不行，只能一个一个元素的赋值或拷贝； 存储方式： 数组：数组在内存中是连续存放的，开辟一块连续的内存空间。数组是根据数组的下标进行访问的，数组的存储空间，不是在静态区就是在栈上。 指针：指针很灵活，它可以指向任意类型的数据。指针的类型说明了它所指向地址空间的内存。由于指针本身就是一个变量，再加上它所存放的也是变量，所以指针的存储空间不能确定。 ","date":"2023-07-11","objectID":"/posts/basics_one/:1:9","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"1.10 什么是函数指针，如何定义函数指针，有什么使用场景 概念： 函数指针就是指向函数的指针变量。每一个函数都有一个入口地址，该函数入口地址就是函数指针所指向的地址。 Note 函数指针指向函数的入口地址！ 定义形式： int func(int a); // 函数 int (*f)(int a); // 函数指针 f = \u0026func; 使用场景： 回调(callback)。我们调用别人提供的 API函数(Application Programming Interface,应用程序编程接口)，称为Call；如果别人的库里面调用我们的函数，就叫Callback。 //以库函数qsort排序函数为例，它的原型如下： void qsort(void *base,//void*类型，代表原始数组 size_t nmemb, //第二个是size_t类型，代表数据数量 size_t size, //第三个是size_t类型，代表单个数据占用空间大小 int(*compar)(const void *,const void *)//第四个参数是函数指针 ); //第四个参数告诉qsort，应该使用哪个函数来比较元素， //即只要我们告诉qsort比较大小的规则，它就可以帮我们对任意数据类型的数组进行排序。 //在库函数qsort调用我们自定义的比较函数，这就是回调的应用。 //示例 int num[100]; int cmp_int(const void* _a , const void* _b){//参数格式固定 int* a = (int*)_a; //强制类型转换 int* b = (int*)_b; return *a - *b;　} qsort(num,100,sizeof(num[0]),cmp_int); //回调cmp_int函数 ","date":"2023-07-11","objectID":"/posts/basics_one/:1:10","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"1.11 静态变量什么时候初始化 对于C语言的全局和静态变量，初始化发生在任何代码执行之前，属于编译期初始化。 而C++标准规定：全局或静态对象当且仅当对象首次用到时才进行构造。 ","date":"2023-07-11","objectID":"/posts/basics_one/:1:11","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"1.12 nullptr调用成员函数可以吗？为什么？ 可以。因为在编译时对象就绑定了函数地址，和指针空不空没关系。 //给出实例 class animal { public: void sleep() { cout \u003c\u003c \"animal sleep\" \u003c\u003c endl; } void breathe() { cout \u003c\u003c \"animal breathe haha\" \u003c\u003c endl; } }; class fish :public animal { public: void breathe(){ cout \u003c\u003c \"fish bubble\" \u003c\u003c endl; } }; int main() { animal *pAn=nullptr; //类指针 pAn-\u003ebreathe(); // 输出：animal breathe haha fish *pFish = nullptr; pFish-\u003ebreathe(); // 输出：fish bubble return 0; } // 原因：因为在编译时对象就绑定了函数地址，和指针空不空没关系。 // pAn-\u003ebreathe();编译的时候，函数的地址就和指针pAn绑定了； // 调用breath(*this), this就等于pAn。由于函数中没有需要解引用this的地方，所以函数运行不会出错， // 但是若用到this，因为this=nullptr，运行出错。 ","date":"2023-07-11","objectID":"/posts/basics_one/:1:12","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"1.13 什么是野指针，怎么产生的，如何避免？ 概念： 野指针就是指针指向的位置是不可知的(随机的、不正确的、没有明确限制的)； Note 指向位置不可知称为野指针！ 产生原因：释放内存后指针不及时置空(野指针)，依然指向了该内存，那么可能出现非法访问的错误。这些我们都要注意避免。(内存泄露) 避免办法： (1)初始化置NULL (2)申请内存后判空 (3)指针释放后置NULL (4)使用智能指针 ","date":"2023-07-11","objectID":"/posts/basics_one/:1:13","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"1.14 静态局部变量，全局变量，局部变量的特点，以及使用场景 ①首先从作用域考虑: C++里作用域可分为6种: 全局，局部，类，语句，命名空间和文件作用域。 全局变量: 全局作用域，可以通过extern作用于其他非定义的源文件。 静态全局变量: 全局作用域+文件作用域，所以无法在其他文件中使用。 局部变量: 局部作用域，比如函数的参数，函数内的局部变量等等。 静态局部变量: 局部作用域，只被初始化一次，直到程序结束。 ②从所在空间考虑：除了局部变量在栈上外，其他都在静态存储区。因为静态变量都在静态存储区，所以下次调用函数的时候还是能取到原来的值。 ③生命周期： 局部变量在栈上，出了作用域就回收内存；而全局变量、静态全局变量、静态局部变量都在静态存储区，直到程序结束才会回收内存。 ④使用场景：从它们各自特点就可以看出各自的应用场景，不再赘述。 ","date":"2023-07-11","objectID":"/posts/basics_one/:1:14","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"1.15 C++继承 ①公有继承public：基类的公有成员和保护成员作为派生类的成员时，它们都保持原有的状态，而基类的私有成员仍然是私有的，不能被这个派生类的子类所访问。 ②私有继承private：私有继承的特点是基类的公有成员和保护成员都作为派生类的私有成员，并且不能被这个派生类的子类所访问。 ③保护继承protect：保护继承的特点是基类的所有公有成员和保护成员都成为派生类的保护成员，并且只能被它的派生类成员函数或友元访问，基类的私有成员仍然是私有的 ","date":"2023-07-11","objectID":"/posts/basics_one/:1:15","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"1.16 常量指针和指针常量 常量指针和指针常量的区别 常量指针: 内存里的值不变 指针常量: 指针指向的内存地址不变 1. const int a; //指的是a是一个常量，不允许修改。 2. const int *a; //a指针所指向的内存里的值不变，即(*a)不变 常量指针 3. int const *a; //同const int *a; 4. int *const a; //a指针所指向的内存地址不变，即a不变 指针常量 5. const int *const a; //都不变，即(*a)不变，a也不变 ","date":"2023-07-11","objectID":"/posts/basics_one/:1:16","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"1.17 内联函数和函数的区别 ①内联函数比普通函数多了关键字inline； ②内联函数避免了函数调用的开销；普通函数有调用的开销； ③普通函数在被调用的时候，需要寻址(函数入口地址)；内联函数不需要寻址。 ④内联函数有一定的限制，内联函数体要求代码简单，不能包含复杂的结构控制语句(内联函数内不允许用循环语句和开关语句。普通函数没有这个要求。 ","date":"2023-07-11","objectID":"/posts/basics_one/:1:17","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"1.18 简述C++有几种传值方式，之间的区别是什么？ 值传递、引用传递、指针传递 ①值传递: 形参即使在函数体内值发生变化，也不会影响实参的值； ②引用传递: 形参在函数体内值发生变化，会影响实参的值； ③指针传递: 在指针指向没有发生改变的前提下，形参在函数体内值发生变化，会影响实参的值； ","date":"2023-07-11","objectID":"/posts/basics_one/:1:18","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"1.19 内联函数和宏函数的区别 宏常量\u0026宏函数 定义: // a. 定义一个宏常量 #define MAX 1024 // 宏常量 MAX称为符号常量 // b. 定义一个宏函数 // 宏函数:宏函数就是使用宏定义定义出来的函数,并不是真正意义上的函数。 #define GETSUM(x, y) ((x) + (y)) // 宏函数 使用宏函数的注意事项: 1.要保证运算的完整性； 2.宏函数的使用场景:频繁调用和短小的函数,封装成宏函数； 3.使用宏函数的优点:以空间换时间； 宏定义和函数的区别: 1.宏在 预处理阶段完成替换，之后被替换的文本参与编译，相当于 直接插入代码，运行时不存在函数调用，执行起来更快；函数调用在运行时需要跳转到具体调用函数; 2.宏定义属于在结构中插入代码，没有返回值; 函数调用具有返回值; 3.宏定义参数没有类型，不进行类型检查；函数参数具有类型，需要检查类型; 4.宏定义不要在最后加分号； 宏定义和typedef的区别: 1.宏主要用于 定义常量及书写复杂的内容; typedef主要用于 定义类型别名; 2.宏替换发生在预编译阶段，属于文本插入替换；typedef是编译的一部分; 3.宏不检查类型；typedef会检查数据类型; 4.宏不是语句，不需要在最后加分号; typedef是语句，要加分号标识结束; 5.注意对指针的操作，typedef char * p_char和#define p_char char *区别巨大; 宏函数和内联函数的区别: 1.在使用时，宏只做简单字符串替换(编译前或者预编译阶段)。而内联函数可以进行参数类型检查(编译时)，且具有返回值； 2.内联函数在编译时直接将函数代码嵌入到目标代码中，省去函数调用的开销来提高执行效率，并且进行参数类型检查，具有返回值，可以实现重载； 3.宏定义时要注意书写(参数要括起来)否则容易出现歧义(保证运算的完整性)，内联函数不会产生歧义； 4.内联函数有类型检查、语法判断等功能，而宏没有； define宏定义和const的区别: 处理阶段: define是在编译的预处理阶段起作用，而const是在编译、运行的时候起作用； 安全性： 1.define只做替换，不做类型检查和计算，也不求解，容易产生错误，一般最好加上一个大括号包含住全部的内容，要不然很容易出错; 2.const常量有数据类型，编译器可以对其进行类型安全检查; 内存占用： 1.define只是将宏名称进行替换，在内存中会产生多份相同的备份。const在程序运行中只有一份备份，且可以执行常量折叠，能将复杂的的表达式计算出结果放入常量表; 2.宏定义的数据没有分配内存空间，只是插入替换掉；const定义的变量只是值不能改变，但要分配内存空间; ","date":"2023-07-11","objectID":"/posts/basics_one/:1:19","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"1.20 四种cast类型转换 cast类型转换的作用 作用：克服c语言中强制类型转化带来的风险，C++引入了四种更加安全的强制类型转换运算符(明确转换的目的，便于程序的维护和分析) const_cast: 去除变量的const属性 // 1.去除const属性，将只读变为只读写 // 2.针对常量指针、常量引用和常量对象 const char *p; char *p1 = const_cast\u003cchar*\u003e(p); static_cast: 内置数据类型之间、基类-派生类之间的转换 内置数据类型之间的转换，int转double，char转int 基类指针与派生类指针之间的转换，只能转换有继承或派生关系的类。用于类层次结构之间基类和派生类指针和引用之间的转换，进行向上转型是安全的，但是进行向下转型是不安全的，但是是可以转换的; 向上转型(派生类向基类转换 -\u003e 安全)：我们知道基类的引用和指针都可以指向派生类的对象，那么将派生类的指针或者引用强转为基类的指针或者引用，那么这就是向上转型，也就是向父类转; 向下转型(基类向派生类转换 -\u003e 不安全)：向下转型就和向上转型相反，它是将父类的指针或者引用，强制转换为子类的指针或者引用 把void类型指针转换为目标类型的指针 任何类型的表达式转化为void类型 // 整形转浮点型 int a = 10; double b = static_cast\u003cdouble\u003e(a); //基类指针转派生类 class A{}; class B : public A{}; A *pA = new A; B *pB = static_cast\u003cB*\u003e(pA); // 向下转换不安全 reinterpret_cast: 可以将一个类型的指针转换为其它任意类型的指针，也可以用在指针和整形数据之间的转换。它是很危险的，如果我们没有使用它的充分理由，那么就不要使用它 为运算对象的位模式提供较低层次上的重新解释 用于底层的强制转换，依赖于机器，一般使用较少 dynamic_cast: 运行时处理; 基类向派生类转换时比static_cast更安全 dynamic_cast是运行时处理的，运行时进行类型检查，其他三种是编译时处理的 不能用于内置数据类型之间的转换 dynamic_cast在进行向上转换时和static_cast效果是一样的，但是进行向下转换时会进行类型检查，比static_cast更加安全，下行转换是否成功取决于转换对象的实际类型与目标类型是否相同 要求基类必须具有虚函数，否则编译不通过 若转换成功，返回的是指向目标的指针或引用，不成功返回NULL ","date":"2023-07-11","objectID":"/posts/basics_one/:1:20","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"2. 基础知识(二) ","date":"2023-07-11","objectID":"/posts/basics_one/:2:0","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"2.1 写出 int 、bool、 float 、指针变量与 “零值”比较的if 语句 //int与零值比较 if ( n == 0 ) if ( n != 0 ) //bool与零值比较 if (flag) // 表示flag为真 if (!flag) // 表示flag为假 //float与零值比较 const float EPSINON = 0.00001; if ((x \u003e= - EPSINON) \u0026\u0026 (x \u003c= EPSINON) //其中EPSINON是允许的误差(即精度)。 //指针变量与零值比较 if (p == nullptr) if (p != nullptr) ","date":"2023-07-11","objectID":"/posts/basics_one/:2:1","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"2.2 变量的声明和定义有什么区别 ① 变量的定义为变量分配地址和存储空间， 变量的声明不分配地址。 ② 一个变量可以在多个地方声明， 但是只在一个地方定义。声明多次，定义一次。 ③ 加入extern 修饰的是变量的声明，说明此变量将在文件外部或在文件后面部分定义。 ④ 说明：很多时候一个变量，只是声明，不分配内存空间，直到具体使用时才初始化，分配内存空间， 如外部变量。 int main() { extern int A; //这是个声明而不是定义，声明A是一个已经定义了的外部变量 //注意：声明外部变量时可以把变量类型去掉如：extern A; dosth(); //执行函数 } int A; //是定义，定义了A为整型的外部变量 ","date":"2023-07-11","objectID":"/posts/basics_one/:2:2","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"2.3 简述 #ifdef、#else、#endif和#ifndef的作用 利用 #ifdef、#endif 将某程序功能模块包括进去，以向特定用户提供该功能。在不需要时, 用户可轻易将其屏蔽。 #ifdef MATH #include “math.c” #endif //在子程序前加上标记，以便于追踪和调试。 #ifdef DEBUG printf (“Indebugging…!”); #endif 应对硬件的限制。由于一些具体应用环境的硬件不一样，限于条件，本地缺乏这种设备，只能绕过硬件，直接写出预期结果。 注意：虽然不用条件编译命令而直接用if语句也能达到要求，但那样做目标程序长(因为所有语句都编译)，运行时间长(因为在程序运行时间对if语句进行测试)。而采用条件编译，可以减少被编译的语句，从而减少目标程序的长度，减少运行时间。 ","date":"2023-07-11","objectID":"/posts/basics_one/:2:3","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"2.4 结构体可以直接赋值吗? ①结构体声明时可以直接初始化，同一结构体的不同对象之间也可以直接赋值，但是当结构体中含有指针“成员”时一定要小心。 ②注意：当有多个指针指向同一段内存时，某个指针释放这段内存可能会导致其他指针的非法操作。因此，在释放前一定要确保其他指针不再使用这段内存空间。 ","date":"2023-07-11","objectID":"/posts/basics_one/:2:4","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"2.5 sizeof 和strlen 的区别 ①sizeof是一个操作符，strlen是库函数。 ②sizeof的参数可以是数据的类型，也可以是变量，而strlen只能以结尾为’\\0’的字符串作参数。 ③编译器在编译时就计算出了sizeof的结果，而strlen函数必须在运行时才能计算出来。并且sizeof计算的是数据类型占内存的大小，而strlen计算的是字符串实际的长度。 ④数组(array)做sizeof的参数不退化，传递给strlen就退化为指针了 ","date":"2023-07-11","objectID":"/posts/basics_one/:2:5","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"2.6 sizeof求类型大小 ref: https://www.cnblogs.com/maji233/p/11439880.html ①类的大小为类的非静态成员数据的类型大小之和，也就是说静态成员数据不作考虑。 普通成员函数与sizeof无关。 ②虚函数由于要维护虚函数表，所以要占据一个指针大小，也就是4字节。 类的总大小也遵守类似class字节对齐的，调整规则。 ref: =\u003e(32 位) 指针都是 4个字节 char 1个字节 short 2个字节 int 4个字节 long 4个字节 long int 4个字节 float 4个字节 double 8个字节 long double 8个字节 =\u003e(64 位) 指针都是一个字长, 8个字节 char 1个字节 short 2个字节 int 4个字节 long 8个字节 long int 8个字节 double 8个字节 long double 也可以变长了, 16个字节 例如有如下结构体： struct Stu //自定义的数据类型，允许用户存储不同的数据类型 { int id; // 4个字节 char sex; // 1个字节 float hight; // 4个字节 }; 那么一个这样的结构体变量占多大内存呢？也就是 cout\u003c\u003csizeof(Stu)\u003c\u003cendl; 会输出什么？ 在了解字节对齐方式之前想当然的会以为：sizeof(Stu) = sizeof(int)+sizeof(char)+sizeof(float) = 9. 然而事实并非如此！ 字节对齐原则 在系统默认的对齐方式下: 每个成员相对于这个结构体变量地址的偏移量正好是该成员类型所占字节的整数倍，且最终占用字节数为成员类型中最大占用字节数的整数倍。 在这个例子中，int id的偏移量为0(0=4x0)，char sex的偏移量为4(4=1x4)，float height的偏移量为8(8=2x4)，此时占用12字节，也同时满足12=3x4.所以sizeof(Stu)=12. 总结： ①最终大小一定是最大数据类型的整数倍; ②静态变量不占空间; ③每种类型的偏移量为自身的n倍; 详细请查阅：struct/class等内存字节对齐问题详解 ref: struct地址偏移量计算 ","date":"2023-07-11","objectID":"/posts/basics_one/:2:6","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"2.7 C语言的关键字static和C++的关键字static有什么区别 ①在 C语言 中，static 用来修饰局部静态变量和外部静态变量、函数。而 C++中除了上述功能外，还用来定义类的成员变量和函数。即静态成员变量和静态成员函数。 ②注意：编程时，static 的记忆性和全局性的特点可以让在不同时期调用的函数进行通信，传递信息，而 C++的静态成员则可以在多个对象实例间进行通信，传递信息。 ","date":"2023-07-11","objectID":"/posts/basics_one/:2:7","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"2.8 Ｃ语言的malloc和Ｃ＋＋中的new有什么区别 ①new 、delete 是操作符，可以重载，只能在C++ 中使用。 ②malloc、free 是函数，可以覆盖，C、C++ 中都可以使用。 ③new 可以调用对象的构造函数，对应的delete 调用相应的析构函数。 ④malloc 仅仅分配内存，free 仅仅回收内存，并不执行构造和析构函数。 ⑤new 、delete 返回的是某种数据类型指针，malloc、free 返回的是**void指针**。 注意：malloc申请的内存空间要用free释放，而new申请的内存空间要用delete释放，不要混用。 ref: 2.11 new 和 malloc的区别 ","date":"2023-07-11","objectID":"/posts/basics_one/:2:8","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"2.9 写一个 “标准” 宏MIN #define min(a,b) ((a)\u003c=(b)?(a):(b)) ","date":"2023-07-11","objectID":"/posts/basics_one/:2:9","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"2.10 ++i和i++的区别 ++i先自增1，再返回；i++先返回i,再自增1 前置版本将对象本身作为左值返回，后置版本将对象原始值的副本作为右值返回。 ","date":"2023-07-11","objectID":"/posts/basics_one/:2:10","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"2.11 new和malloc的区别，各自底层实现原理(delete和free类似) ①new(delete)是操作符，而malloc(free)是函数。 ②new在调用的时候先分配内存，再调用构造函数，释放的时候调用析构函数；而malloc没有调用构造函数和析构函数。 ③malloc需要给定申请内存的大小，返回的指针需要强转(返回void指针)；new会调用构造函数，不用指定内存的大小，返回指针不需要强转。 ④new是操作符，可以被重载; malloc不行 ⑤new分配内存, 更直接和安全。 ⑥new发生错误抛出异常，malloc返回null ","date":"2023-07-11","objectID":"/posts/basics_one/:2:11","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"2.12 const 和 define 的区别 区别 (1)就起作用的阶段而言：#define是在编译的预处理阶段起作用，而const是在 编译、运行的时候起作用。 (2)就起作用的方式而言：#define只是简单的字符串替换，没有类型检查。而const有对应的数据类型，是要进行判断的，可以避免一些低级的错误。 (3)就存储方式而言：#define只是进行展开，有多少地方使用，就替换多少次，它定义的宏常量在内存中有若干个备份;const定义的只读变量在程序运行过程中只有一份备份。 (4)从代码调试的方便程度而言： const常量可以进行调试的，define是不能进行调试的，因为在预编译阶段就已经替换掉了。 const优点： (1)const常量有数据类型，而宏常量没有数据类型。编译器可以对前者进行类型安全检查。而对后者只进行字符替换，没有类型安全检查，并且在字符替换可能会产生意料不到的错误。 (2)有些集成化的调试工具可以对const常量进行调试，但是不能对宏常量进行调试。 (3)const可节省空间，避免不必要的内存分配，提高效率 ","date":"2023-07-11","objectID":"/posts/basics_one/:2:12","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"2.13 C++中函数指针和指针函数的区别 定义不同 指针函数: 本质是一个函数，其返回值为指针。 函数指针: 本质是一个指针，其指向一个函数。 写法不同 指针函数：int *fun(int x, int y); 函数指针：int (*fun)(int x, int y); 用法不同 //指针函数示例 typedef struct _Data{ int a; int b; }Data; //指针函数 Data* f(int a,int b){ Data * data = new Data; //... return data; } int main(){ //调用指针函数 Data * myData = f(4,5); //Data * myData = static_cast\u003cData*\u003e(f(4,5)); //... } //函数指针示例 int add(int x,int y){ return x+y; } //函数指针 int (*fun)(int x,int y); //赋值, 函数指针指向函数add fun = add; //调用 cout \u003c\u003c \"(*fun)(1,2) = \" \u003c\u003c (*fun)(1,2) ; //输出结果 //(*fun)(1,2) = 3 ","date":"2023-07-11","objectID":"/posts/basics_one/:2:13","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"2.14 使用指针需要注意什么？ ①定义指针时，先初始化为NULL空指针。 ②用malloc或new申请内存之后，应该立即检查指针值是否为NULL。防止使用指针值为NULL的内存。 ③不要忘记为数组和动态内存赋初值。防止将未被初始化的内存作为右值使用。 ④避免数字或指针的下标越界，特别要当心发生“多1”或者“少1”操作。 ⑤动态内存的申请与释放必须配对，防止内存泄漏。 ⑥用free或delete释放了内存之后，立即将指针设置为NULL，防止“野指针”。 ","date":"2023-07-11","objectID":"/posts/basics_one/:2:14","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"2.15 volatile有什么作用 ①volatile为状态寄存器一类的并行设备硬件寄存器。 ②一个中断服务子程序会访问到的非自动变量。 ③多线程间被几个任务共享的变量。 注意: 虽然volatile在嵌入式方面应用比较多，但是在PC软件的多线程中，volatile修饰的临界变量也是非常实用的。 C++中volatile的作用: 总结: 建议编译器不要对该变量进行优化，每次都从内存中读取该变量，而不是从缓存(寄存器)中读取变量。 volatile是“易变/不稳定”的意思。volatile是C的一个较为少用的关键字，解决变量在“共享”环境下容易出现读取错误的问题。 定义为volatile的变量是说这变量可能会被意想不到地改变，即在你程序运行过程中一直会变，你希望这个值被正确地处理，每次从内存中去读这个值，而不是因编译器优化从缓存的地方读取，比如读取缓存在寄存器中的数值，从而保证volatile变量被正确的读取。 在单任务的环境中，一个函数体内部，如果在两次读取变量的值之间的语句没有对变量的值进行修改，那么编译器就会设法对可执行代码进行优化。由于访问寄存器的速度要快过RAM(从RAM中读取变量的值到寄存器)，以后只要变量的值没有改变，就一直从寄存器中读取变量的值，而不对RAM进行访问。 而在多任务环境中，虽然在一个函数体内部，在两次读取变量之间没有对变量的值进行修改，但是该变量仍然有可能被其他的程序(如中断程序、另外的线程等)所修改。如果这时还是从寄存器而不是从RAM中读取，就会出现被修改了的变量值不能得到及时反应的问题。 ","date":"2023-07-11","objectID":"/posts/basics_one/:2:15","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"2.16 一个参数可以既是const又是volatile吗 可以。用const和volatile同时修饰变量，表示这个变量在程序内部是只读的，不能改变的，只在程序外部条件变化下改变，并且编译器不会优化这个变量。每次使用这个变量时，都要小心地去内存读取这个变量的值，而不是去寄存器读取它的备份。 注意：在此一定要注意const的意思，const只是不允许程序中的代码改变某一变量，其在编译期发挥作用，它并没有实际地禁止某段内存的读写特性 ","date":"2023-07-11","objectID":"/posts/basics_one/:2:16","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"2.17 *a和\u0026a有什么区别 \u0026a：其含义就是“变量a的地址”。 *a：用在不同的地方，含义也不一样。 ①在声明语句中，*a只说明a是一个指针变量，如int *a； ②在其他语句中，*a前面没有操作数且a是一个指针时，*a代表指针a指向的地址内存放的数据(解引用)，如b=*a； ③*a前面有操作数且a是一个普通变量时，a代表乘以a，如c=ba ","date":"2023-07-11","objectID":"/posts/basics_one/:2:17","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"2.18 用C 编写一个死循环程序 while(1) { } 注意：很多种途径都可实现同一种功能，但是不同的方法时间和空间占用度不同，特别是对于嵌入式软件，处理器速度比较慢，存储空间较小，所以时间和空间优势是选择各种方法的首要考虑条件。 ","date":"2023-07-11","objectID":"/posts/basics_one/:2:18","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"2.19 全局变量和局部变量有什么区别？是怎么实现的？操作系统和编译器是怎么知道的？ ①全局变量是整个程序都可访问的变量，谁都可以访问，生存期在整个程序从运行到结束(在程序结束时所占内存释放)； ②而局部变量存在于模块(子程序，函数)中，只有所在模块可以访问，其他模块不可直接访问，模块结束(函数调用完毕)，局部变量消失，所占据的内存释放。 ③操作系统和编译器，可能是通过内存分配的位置来知道的，全局变量分配在全局数据段并且在程序开始运行的时候被加载.局部变量则分配在堆栈里面。 ","date":"2023-07-11","objectID":"/posts/basics_one/:2:19","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"2.20 结构体内存对齐问题 请写出以下代码的输出结果： #include \u003cstdio.h\u003e using namespace std; /************************************************************** * 结构体内存对⻬问题 * 从偏移为0的位置开始存储； * 如果没有定义 #pragma pack(n) * sizeof 的最终结果必然是结构内部最⼤成员的整数倍，不够补⻬； * 结构内部各个成员的⾸地址必然是⾃身⼤⼩的整数倍； * ***************************************************************/ struct S1 { int i ; //起始偏移0，sizeof(i)=4; 地址0、1、2、3分配给成员i char j ; //起始偏移4，sizeof(j)=1; int a ; //sizeof(a)=4,内存对齐到8个字节，从偏移量为8处存放a; double b;//sizeof(b)=8,内存对齐到16个字节，再存放b,结构体总大小24; }; //结构体成员的首地址必须是自身大小的整数倍 struct S3 { char j;//起始偏移0，sizeof(j)=1; float i;//sizeof(i)=4，内存对齐到4，起始偏移量为4,再存放i double b;//当前地址为8，是b大小的整数倍，无需对齐，直接存放成员b 8个字节 int a;//sizeof(a)=4,内存对齐到20，再存放a,总大小24字节； }; int main() { printf(\"%d\\n\", sizeof(S1)); printf(\"%d\\n\", sizeof(S3)); return 0; } 输出: 24 24 说明： ①结构体作为一种复合数据类型，其构成元素既可以是基本数据类型的变量，也可以是一些复合型类型数据。对此，编译器会自动进行成员变量的对齐以提高运算效率。 ②默认情况下，按自然对齐条件分配空间。各个成员按照它们被声明的顺序在内存中顺序存储，第一个成员的地址和整个结构的地址相同，向结构体成员中size最大的成员对齐。 ③许多实际的计算机系统对基本类型数据在内存中存放的位置有限制，它们会要求这些数据的首地址的值是某个数k(通常它为4或8)的倍数，而这个k则被称为该数据类型的对齐模数。 ","date":"2023-07-11","objectID":"/posts/basics_one/:2:20","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"3 基础知识(三) ","date":"2023-07-11","objectID":"/posts/basics_one/:3:0","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"3.1 简述C、C++程序编译的内存分配情况 ①从静态存储区域分配： 内存在程序编译时就已经分配好，这块内存在程序的整个运行期间都存在。速度快、不容易出错， 因为有系统会善后。例如全局变量，static 变量，常量字符串等。 ②在栈上分配： 在执行函数时，函数内局部变量的存储单元都在栈上创建，函数执行结束时, 这些存储单元自动被释放。栈内存分配运算内置于处理器的指令集中，效率很高，但是分配的内存容量有限。大小为2M。 ③从堆上分配： 即动态内存分配。程序在运行的时候用 malloc 或 new 申请任意大小的内存，程序员自己负责在何时用 free 或 delete 释放内存。动态内存的生存期由程序员决定，使用非常灵活。如果在堆上分配了空间，就有责任回收它，否则运行的程序会出现内存泄漏，另外频繁地分配和释放不同大小的堆空间将会产生堆内碎块。 一个C、C++程序编译时内存分为5大存储区：堆区、栈区、全局区、文字常量区、程序代码区。 ","date":"2023-07-11","objectID":"/posts/basics_one/:3:1","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"3.2 简述strcpy、sprintf 与memcpy 的区别 ① 操作对象不同，strcpy 的两个操作对象均为字符串，sprintf 的操作源对象可以是多种数据类型， 目的操作对象是字符串，memcpy 的两个对象就是两个任意可操作的内存地址，并不限于何种数据类型。 ② 执行效率不同，memcpy 最高，strcpy 次之，sprintf 的效率最低。 ③ 实现功能不同，strcpy 主要实现字符串变量间的拷贝，sprintf 主要实现其他数据类型格式到字符串的转化，memcpy 主要是内存块间的拷贝。 注意：strcpy、sprintf 与memcpy 都可以实现拷贝的功能，但是针对的对象不同，根据实际需求，来选择合适的函数实现拷贝功能。 ","date":"2023-07-11","objectID":"/posts/basics_one/:3:2","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"3.3 请解析((void ()( ) )0)( )的含义 void (0)( ) ：是一个返回值为void，参数为空的函数指针0。 (void ()( ))0：把0转变成一个返回值为void，参数为空的函数指针。 ((void ()( ))0()：在上句的基础上加括号表示整个是一个返回值为void，无参数，并且起始地址为0的函数的名字。 ((void (*)( ))0)( )：这就是上句的函数名所对应的函数的调用。 ","date":"2023-07-11","objectID":"/posts/basics_one/:3:3","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"3.4 typedef 和define 有什么区别 ①用法不同： typedef 用来定义一种数据类型的别名，增强程序的可读性。define 主要用来定义常量，以及书写复杂使用频繁的宏。 ②执行时间不同： typedef 是编译过程的一部分，有类型检查的功能。define 是宏定义，是预编译的部分，其发生在编译之前，只是简单的进行字符串的替换，不进行类型的检查。 ③作用域不同： typedef 有作用域限定：define 不受作用域约束，只要在define 声明后的引用都是正确的。 ④对指针的操作不同： typedef 和 define 定义的指针时有很大的区别。 注意：typedef 定义是语句，因为句尾要加上分号。而define 不是语句，千万不能在句尾加分号。 ","date":"2023-07-11","objectID":"/posts/basics_one/:3:4","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"3.5 指针常量与常量指针区别 指针常量是指定义了一个指针，这个指针的值只能在定义时初始化，其他地方不能改变。(地址不可变) 常量指针是指定义了一个指针，这个指针指向一个只读的对象，不能通过常量指针来改变这个对象的值。(值不可变) 指针常量强调的是指针的不可改变性，而常量指针强调的是指针对其所指对象的不可改变性。 注意：无论是指针常量还是常量指针，其最大的用途就是作为函数的形式参数，保证实参在被调用函数中的不可改变特性。 ","date":"2023-07-11","objectID":"/posts/basics_one/:3:5","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"3.6 简述队列和栈的异同 队列和栈都是线性存储结构，但是两者的插入和删除数据的操作不同，队列是“先进先出”，栈是 “后进先出”。 注意：区别栈区和堆区。堆区的存取是“顺序随意”，而栈区是“后进先出”。栈由编译器自动分配释放 ，存放函数的参数值，局部变量的值等。其操作方式类似于数据结构中的栈。堆一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS 回收。分配方式类似于链表。 它与本题中的堆和栈是两回事。堆栈只是一种数据结构，而堆区和栈区是程序的不同内存存储区域。 ","date":"2023-07-11","objectID":"/posts/basics_one/:3:6","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"3.7 设置地址为0x67a9 的整型变量的值为0xaa66 int *ptr; ptr = (int *)0x67a9; *ptr = 0xaa66; // 对指针取地址 注意：这道题就是强制类型转换的典型例子，无论在什么平台，地址长度和整型数据的长度是一样的， 即一个整型数据可以强制转换成地址指针类型，只要有意义即可。 ","date":"2023-07-11","objectID":"/posts/basics_one/:3:7","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"3.8 编码实现字符串转化为数字 编码实现函数atoi()，设计一个程序，把一个字符串转化为一个整型数值。例如字符：“5486321 ”转化成整型：5486321。 int myAtoi(const char * str) { int num = 0; //保存转换后的数值 int isNegative = 0; //记录字符串中是否有负号 int n =0; char *p = str; if(p == NULL) //判断指针的合法性 { return -1; } while(*p++ != '\\0') //计算数字符串度 { n++; } p = str; if(p[0] == '-') //判断数组是否有负号 { isNegative = 1; } char temp = '0'; for(int i = 0 ; i \u003c n; i++) { char temp = *p++; if(temp \u003e '9' ||temp \u003c '0') //滤除非数字字符 { continue; } if(num !=0 || temp != '0') //滤除字符串开始的0 字符 { temp -= 0x30; //将数字字符转换为数值 num += temp *int( pow(10 , n - 1 -i) ); } } if(isNegative) //如果字符串中有负号，将数值取反 { return (0 - num); } else { return num; //返回转换后的数值 } } ","date":"2023-07-11","objectID":"/posts/basics_one/:3:8","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"3.9 C语言的结构体(struct)和C++的类(class)有什么区别 ①C语言的结构体是不能有成员函数的，而C++的类可以有。 ②C语言的结构体中数据成员是没有private、public和protected访问限定的。而C++的类的成员有这些访问权限限定。 ③C语言的结构体是没有继承关系的，而C++的类却有丰富的继承关系。 注意：虽然C的结构体和C++的类有很大的相似度，但是类是实现面向对象的基础。而结构体只可以简单地理解为类的前身。 ","date":"2023-07-11","objectID":"/posts/basics_one/:3:9","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"3.10 简述指针常量与常量指针的区别 ①指针常量是指定义了一个指针，这个指针的值只能在定义时初始化，其他地方不能改变。常量指针是定义了一个指针，这个指针指向一个只读的对象，不能通过常量指针来改变这个对象的值。指针常量的值只能在定义时初始化，常量指针指向一个只读的对象 ②指针常量强调的是指针的不可改变性，而常量指针强调的是指针对其所指对象的不可改变性。 注意：无论是指针常量还是常量指针，其最大的用途就是作为函数的形式参数，保证实参在被调用函数中的不可改变特性。 ","date":"2023-07-11","objectID":"/posts/basics_one/:3:10","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"3.11 哪些情况会导致“野指针”以及如何避免 ①指针变量声明时没有被初始化。解决办法：指针声明时初始化，可以是具体的地址值，也可让它指向NULL。 ②指针p被free或者delete之后，没有置为NULL。解决办法：指针指向的内存空间被释放后指针应该指向NULL。 ③指针操作超越了变量的作用范围。解决办法：在变量的作用域结束前释放掉变量的地址空间并且让指针指向NULL。 ","date":"2023-07-11","objectID":"/posts/basics_one/:3:11","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"3.12 句柄和指针的区别和联系是什么？ 句柄和指针其实是两个截然不同的概念。Windows系统用句柄标记系统资源，隐藏系统的信息。你只要知道有这个东西，然后去调用就行了，它是个32bit的uint。指针则标记某个物理内存地址，两者是不同的概念。 ","date":"2023-07-11","objectID":"/posts/basics_one/:3:12","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"3.13 new/delete与malloc/free的区别是什么 new能自动计算需要分配的内存空间，而malloc需要手工计算字节数。 int *p = new int[2]; int *q = (int )malloc(2sizeof(int)); ①new与delete直接带具体类型的指针，malloc和free返回void类型的指针。 ②new操作符能保证类型安全，而malloc不能。例如int *p = new float[2];就会报错；而int p = malloc(2sizeof(int))编译时编译器就无法指出错误来。 ③new一般分为两步：new操作和调用构造函数。new操作对应于malloc，但new操作可以重载，可以自定义内存分配策略，不做内存分配，甚至分配到非内存设备上，而malloc不行。 ④new调用构造函数，malloc不能；delete调用析构函数，而free不能。 ⑤malloc/free需要库文件stdlib.h的支持，new/delete则不需要！ ⑥new/delete是C++的关键字,申请内存失败时会抛出异常，malloc/free是库函数，申请内存失败后返回null。 ⑦new/delete是C++的内存分配和回收机制，malloc/free是C的内存分配和回收机制。 注意：delete和free被调用后，内存不会立即回收，指针也不会指向空，delete或free仅仅是告诉操作系统，这一块内存被释放了，可以用作其他用途。但是由于没有重新对这块内存进行写操作，所以内存中的变量数值并没有发生变化，出现野指针的情况。因此，释放完内存后，应该将指针指向NULL。 new delete 详解 ","date":"2023-07-11","objectID":"/posts/basics_one/:3:13","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"3.14 说一说extern“C” extern \"C\"的主要作用就是为了能够正确实现在C++代码中调用C语言代码。加上extern \"C\"后，会指示编译器这部分代码按C语言(而不是C++)的方式进行编译。由于C++支持函数重载，因此编译器编译函数的过程中会将函数的参数类型也加到编译后的代码中，而不仅仅是函数名；而C语言并不支持函数重载，因此编译C语言代码的函数时不会带上函数的参数类型，一般只包括函数名。 这个功能十分有用，因为在C++出现以前，很多代码(包括很多底层的库)都是C语言写的，为了更好地支持原来的C代码和已经写好的C语言库，需要在C++中尽可能的支持C，而extern \"C\"就是其中的一个策略。 在多个人协同开发时，可能有的人比较擅长C语言，而有的人擅长C++，这样的情况下也会出现在C++的代码中调用C语言代码的情况。 ","date":"2023-07-11","objectID":"/posts/basics_one/:3:14","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"3.15 请你来说一下C++中struct和class的区别 在C++中，class和struct做类型定义是只有两点区别： ①默认继承权限不同，class继承默认是private继承，而struct默认是public继承 ②class还可用于定义模板参数，像typename，但是关键字struct不能用于定义模板参数 ③C++保留struct关键字，原因: 保证与C语言的向下兼容性，C++必须提供一个struct ④C++中的struct定义必须百分百地保证与C语言中的struct的向下兼容性，把C++中的最基本的对象单元规定为class而不是struct，就是为了避免各种兼容性要求的限制 ⑤对struct定义的扩展使C语言的代码能够更容易的被移植到C++中 ","date":"2023-07-11","objectID":"/posts/basics_one/:3:15","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"3.16 C++类内可以定义引用数据成员吗？ 可以，必须通过成员函数初始化列表初始化。 ","date":"2023-07-11","objectID":"/posts/basics_one/:3:16","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"3.17 C++中类成员的访问权限 ①C++通过 public、protected、private 三个关键字来控制成员变量和成员函数的访问权限，它们分别表示公有的、受保护的、私有的，被称为成员访问限定符。 ②在类的内部(定义类的代码内部)，无论成员被声明为 public、protected 还是 private，都是可以互相访问的，没有访问权限的限制。 ③在类的外部(定义类的代码之外)，只能通过对象访问成员，并且通过对象只能访问 public 属性的成员，不能访问 private、protected 属性的成员 ","date":"2023-07-11","objectID":"/posts/basics_one/:3:17","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"3.18 什么是右值引用，跟左值又有什么区别？ 左值和右值的概念: ①左值: 能取地址，或者具名对象，表达式结束后依然存在的持久对象； 右值: 不能取地址，匿名对象，表达式结束后就不再存在的临时对象； ②区别: 左值能寻址，右值不能; 左值能赋值，右值不能; 左值可变，右值不能(仅对基础类型适用，用户自定义类型右值引用可以通过成员函数改变); ","date":"2023-07-11","objectID":"/posts/basics_one/:3:18","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"3.19 面向对象的三大特征 封装性: 将客观事物抽象成类，每个类对自身的数据和方法实行访问权限保护(private ， protected ， public)。 继承性: 广义的继承有三种实现形式：实现继承(使用基类的属性和方法而无需额外编码的能力)、可视继承(子窗体使用父窗体的外观和实现代码)、接口继承(仅使用属性和方法,实现滞后到子类实现)。 多态性: 是将父类对象设置成为和一个或更多它的子对象相等的技术。用子类对象给父类对象赋值之后，父类对象就可以根据当前赋值给它的子对象的特性以不同的方式运作。 ","date":"2023-07-11","objectID":"/posts/basics_one/:3:19","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"3.20 C++的空类有哪些成员函数 C++空类成员函数： 缺省构造函数。 缺省拷贝构造函数。 缺省析构函数。 缺省赋值运算符。 缺省取址运算符。 缺省取址运算符 const 。 注意：有些书上只是简单的介绍了前四个函数。没有提及后面这两个函数。但后面这两个函数也是空类的默认函数。另外需要注意的是，只有当实际使用这些空类成员函数的时候，编译器才会去定义它们。 ","date":"2023-07-11","objectID":"/posts/basics_one/:3:20","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"4. 基础知识(四) ","date":"2023-07-11","objectID":"/posts/basics_one/:4:0","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"4.1 说一说c++中四种cast转换 C++中四种类型转换是：static_cast, dynamic_cast, const_cast, reinterpret_cast 1、const_cast 用于将const变量转为非const, 去除const属性 2、static_cast 用于各种隐式转换，比如非const转const，void*转指针等, static_cast能用于多态向上转化，如果向下转能成功但是不安全，结果未知； 3、dynamic_cast 用于动态类型转换。只能用于含有虚函数的类，用于类层次间的向上和向下转化。只能转指针或引用。向下转化时，如果是非法的，对于指针返回NULL，对于引用抛异常。要深入了解内部转换的原理。 向上转换：指的是子类向基类的转换 向下转换：指的是基类向子类的转换 它通过判断在执行到该语句的时候变量的运行时类型和要转换的类型是否相同来判断是否能够进行向下转换。 4、reinterpret_cast 几乎什么都可以转，比如将int转指针，可能会出问题，尽量少用； 5、为什么不使用C的强制转换？ C的强制转换表面上看起来功能强大什么都能转，但是转化不够明确，不能进行错误检查，容易出错。 ","date":"2023-07-11","objectID":"/posts/basics_one/:4:1","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"4.2 对c++中的smart pointer四个智能指针的理解：shared_ptr,unique_ptr,weak_ptr,auto_ptr ①C++里面的四个智能指针: auto_ptr, shared_ptr, weak_ptr, unique_ptr 其中后三个是c++11支持，并且第一个已经被C++11弃用。 ②智能指针的作用是管理一个指针，因为存在以下这种情况： 申请的空间在函数结束时忘记释放，造成内存泄漏。使用智能指针可以很大程度上的避免这个问题，因为智能指针就是一个类，当超出了类的作用域时，类会自动调用析构函数，析构函数会自动释放资源。所以智能指针的作用原理就是在函数结束时自动释放内存空间，不需要手动释放内存空间。 ③auto_ptr(c++98的方案，cpp11已经抛弃) 采用所有权模式。 unique_ptr p3 (new string (“auto”)); //#4 unique_ptr p4； //#5 p4 = p3;//此时会报错！！ 编译器认为p4=p3非法，避免了p3不再指向有效数据的问题。因此，unique_ptr比auto_ptr更安全。 另外unique_ptr还有更聪明的地方：当程序试图将一个 unique_ptr 赋值给另一个时，如果源 unique_ptr 是个临时右值，编译器允许这么做；如果源 unique_ptr 将存在一段时间，编译器将禁止这么做，比如: unique_ptr pu1(new string (“hello world”)); unique_ptr pu2; pu2 = pu1; // #1 not allowed unique_ptr pu3; pu3 = unique_ptr(new string (“You”)); // #2 allowed 其中#1留下悬挂的 unique_ptr(pu1)，这可能导致危害。而#2不会留下悬挂的unique_ptr，因为它调用 unique_ptr 的构造函数，该构造函数创建的临时对象在其所有权让给 pu3 后就会被销毁。这种随情况而已的行为表明，unique_ptr 优于允许两种赋值的auto_ptr 。 注：如果确实想执行类似与#1的操作，要安全的重用这种指针，可给它赋新值。C++有一个标准库函数std::move()，让你能够将一个unique_ptr赋给另一个。例如： unique_ptr ps1, ps2; ps1 = demo(“hello”); ps2 = move(ps1); ps1 = demo(“alexia”); cout \u003c\u003c *ps2 \u003c\u003c *ps1 \u003c\u003c endl; shared_ptr实现共享式拥有概念。多个智能指针可以指向相同对象，该对象和其相关资源会在“最后一个引用被销毁”时候释放。从名字share就可以看出了资源可以被多个指针共享，它使用计数机制来表明资源被几个指针共享。可以通过成员函数use_count()来查看资源的所有者个数。除了可以通过new来构造，还可以通过传入auto_ptr, unique_ptr,weak_ptr来构造。当我们调用release()时，当前指针会释放资源所有权，计数减一。当计数等于0时，资源会被释放。 shared_ptr 是为了解决 auto_ptr 在对象所有权上的局限性(auto_ptr 是独占的), 在使用引用计数的机制上提供了可以共享所有权的智能指针。 成员函数： use_count 返回引用计数的个数 unique 返回是否是独占所有权( use_count 为 1) swap 交换两个 shared_ptr 对象(即交换所拥有的对象) reset 放弃内部对象的所有权或拥有对象的变更, 会引起原有对象的引用计数的减少 get 返回内部对象(指针), 由于已经重载了()方法, 因此和直接使用对象是一样的.如 shared_ptr sp(new int(1)); sp 与 sp.get()是等价的 weak_ptr: weak_ptr 是一种不控制对象生命周期的智能指针, 它指向一个 shared_ptr 管理的对象. 对该对象进行内存管理的是那个强引用的shared_ptr. weak_ptr只是提供了对管理对象的一个访问手段。 weak_ptr 设计的目的是为了配合 shared_ptr 而引入的一种智能指针来协助 shared_ptr 工作, 它只可以从一个 shared_ptr 或另一个 weak_ptr 对象构造, 它的构造和析构不会引起引用记数的增加或减少。 weak_ptr是用来解决shared_ptr相互引用时的死锁问题,如果说两个shared_ptr相互引用,那么这两个指针的引用计数永远不可能下降为0,资源永远不会释放。它是对对象的一种弱引用，不会增加对象的引用计数，和shared_ptr之间可以相互转化，shared_ptr可以直接赋值给它，它可以通过调用lock函数来获得shared_ptr。 class B; class A { public: shared_ptr\u003cB\u003e pb_; ~A(){ cout\u003c\u003c\"A delete\"; } }; class B { public: shared_ptr\u003cA\u003e pa_; ~B(){ cout\u003c\u003c\"B delete\"; } }; void fun() { shared_ptr\u003cB\u003e pb(new B()); shared_ptr\u003cA\u003e pa(new A()); pb-\u003epa_ = pa; pa-\u003epb_ = pb; cout \u003c\u003c pb.use_count() \u003c\u003c endl; cout \u003c\u003c pa.use_count() \u003c\u003c endl; } int main() { fun(); return 0; } 可以看到fun函数中pa ，pb之间互相引用，两个资源的引用计数为2，当要跳出函数时，智能指针pa，pb析构时两个资源引用计数会减一，但是两者引用计数还是为1，导致跳出函数时资源没有被释放(A B的析构函数没有被调用)，如果把其中一个改为weak_ptr就可以了，我们把类A里面的shared_ptr pb_; 改为weak_ptr pb_; 运行结果如下，这样的话，资源B的引用开始就只有1，当pb析构时，B的计数变为0，B得到释放，B释放的同时也会使A的计数减一，同时pa析构时使A的计数减一，那么A的计数为0，A得到释放。 注意：不能通过weak_ptr直接访问对象的方法，比如B对象中有一个方法print(),我们不能这样访问，pa-\u003epb_-\u003eprint(); 英文pb_是一个weak_ptr，应该先把它转化为shared_ptr,如：shared_ptr p = pa-\u003epb_.lock(); p-\u003eprint(); ","date":"2023-07-11","objectID":"/posts/basics_one/:4:2","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"4.3 说说强制类型转换运算符 ①static_cast 用于非多态类型的转换 用于非多态类型的转换 不执行运行时类型检查(转换安全性不如 dynamic_cast) 通常用于转换数值数据类型(如 float -\u003e int) 可以在整个类层次结构中移动指针，子类转化为父类安全(向上转换)，父类转化为子类不安全(因为子类可能有不在父类的字段或方法) ②dynamic_cast 用于多态类型的转换 用于多态类型的转换 执行运行时类型检查 只适用于指针或引用 对不明确的指针的转换将失败(返回 nullptr)，但不引发异常 可以在整个类层次结构中移动指针，包括向上转换、向下转换 ③const_cast 用于删除 const、volatile 和 __unaligned 特性(如将 const int 类型转换为 int 类型 ) ④reinterpret_cast 用于位的简单重新解释 滥用 reinterpret_cast 运算符容易带来风险。除非所需转换本身是低级别的，否则应使用其他强制转换运算符之一。 允许将任何指针转换为任何其他指针类型(如 char* 到 int* 或 One_class* 到 Unrelated_class* 之类的转换，但其本身并不安全) 也允许将任何整数类型转换为任何指针类型以及反向转换。 reinterpret_cast 运算符不能丢掉 const、volatile 或 __unaligned 特性。 reinterpret_cast 的一个实际用途是在哈希函数中，即，通过让两个不同的值几乎不以相同的索引结尾的方式将值映射到索引。 ⑤bad_cast转换失败异常 由于强制转换为引用类型失败，dynamic_cast 运算符引发 bad_cast 异常。 bad_cast 使用: try { Circle\u0026 ref_circle = dynamic_cast\u003cCircle\u0026\u003e(ref_shape); } catch (bad_cast b) { cout \u003c\u003c \"Caught: \" \u003c\u003c b.what(); } ","date":"2023-07-11","objectID":"/posts/basics_one/:4:3","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"4.4 谈谈你对拷贝构造函数和赋值运算符的认识 拷贝构造函数和赋值运算符重载有以下两个不同之处： ①拷贝构造函数生成新的类对象，而赋值运算符不能。 ②由于拷贝构造函数是直接构造一个新的类对象，所以在初始化这个对象之前不用检验原对象是否和新建对象相同，而赋值运算符则需要这个操作; ③另外，赋值运算中，如果原来的对象中有内存分配要先把内存释放掉。 注意：当有类中有指针类型的成员变量时，一定要重写拷贝构造函数和赋值运算符，不要使用默认的。 ","date":"2023-07-11","objectID":"/posts/basics_one/:4:4","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"4.5 在C++中，使用malloc申请的内存能否通过delete释放？使用new申请的内存能否用free？ 不能，malloc /free主要为了兼容C，new和delete 完全可以取代malloc /free的。 ①malloc /free的操作对象都是必须明确大小的。而且不能用在动态类上。 ②new 和delete会自动进行类型检查和大小，malloc/free不能执行构造函数与析构函数，所以动态对象它是不行的。 当然从理论上说使用malloc申请的内存是可以通过delete释放的。不过一般不这样写的。而且也不能保证每个C++的运行时都能正常。 ","date":"2023-07-11","objectID":"/posts/basics_one/:4:5","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"4.6 用C++设计一个不能被继承的类 ref: https://blog.csdn.net/wei_cheng18/article/details/81043858 template \u003ctypename T\u003e class A { friend T; private: A() {} ~A() {} }; class B : virtual public A\u003cB\u003e { public: B() {} ~B() {} }; class C : virtual public B{ public: C() {} ~C() {} }; void main( void ) { B b; //C c; return; } 注意：构造函数是实现继承的关键，每次子类对象构造时，首先调用的是父类的构造函数，然后才是自己的。实现不能被继承的类关键在于想父类的构造函数使用private控制 这里需要说明的是：我们设计的不能被继承的类B对基类A的继承必须是虚继承，这样一来C类继承B类时会去直接调用A的构造函数，而不是像普通继承那样，先调用B的构造函数再调用A的构造函数； C类直接调用A类的构造函数，由于A类的构造函数是私有的，而B是A的友元，C类不是A的友元，友元关系不会继承，因此会编译报错。 ","date":"2023-07-11","objectID":"/posts/basics_one/:4:6","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"4.8 访问基类的私有虚函数 写出以下程序的输出结果： #include \u003ciostream.h\u003e class A { virtual void g() { cout \u003c\u003c \"A::g\" \u003c\u003c endl; } private: virtual void f() { cout \u003c\u003c \"A::f\" \u003c\u003c endl; } }; class B : public A { void g() { cout \u003c\u003c \"B::g\" \u003c\u003c endl; } virtual void h() { cout \u003c\u003c \"B::h\" \u003c\u003c endl; } }; typedef void( *Fun )( void ); void main() { B b; Fun pFun; for(int i = 0 ; i \u003c 3; i++) { pFun = ( Fun )*( ( int* ) * ( int* )( \u0026b ) + i ); pFun(); } } 输出结果: B::g A::f B::h 注意：考察了面试者对虚函数的理解程度。一个对虚函数不了解的人很难正确的做出本题。 在学习面向对象的多态性时一定要深刻理解虚函数表的工作原理。 虚函数: 通过基类访问派生类定义的函数，多态时使用，使用虚函数加上virtual关键字。 虚函数就是在基类定义一个未实现的函数名，为了提高程序的可读性 虚函数详解 C++虚函数详解_疯狂的麦克斯_max的博客-CSDN博客_c++虚函数 菱形继承1 菱形继承2 ","date":"2023-07-11","objectID":"/posts/basics_one/:4:7","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"4.9 对虚函数和多态的理解 ①多态的实现主要分为静态多态和动态多态 静态多态主要是重载，在编译的时候就已经确定； 动态多态是用虚函数机制实现的，在运行期间动态绑定。 举个例子: 一个父类类型的指针指向一个子类对象时候，使用父类的指针去调用子类中重写了的父类中的虚函数的时候，会调用子类重写过后的函数，在父类中声明为加了virtual关键字的函数，在子类中重写时候不需要加virtual也是虚函数。 ②虚函数的实现: 在有虚函数的类中，类的最开始部分是一个虚函数表的指针，这个指针指向一个虚函数表，表中放了虚函数的地址，实际的虚函数在代码段(.text)中。当子类继承了父类的时候也会继承其虚函数表，当子类重写父类中虚函数时候，会将其继承到的虚函数表中的地址替换为重新写的函数地址。使用了虚函数，会增加访问内存开销，降低效率。 ","date":"2023-07-11","objectID":"/posts/basics_one/:4:8","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"4.10 简述类成员函数的重写(overwrite)、重载(overload)和隐藏的区别 (1) 重写和重载主要有以下几点不同。 ①范围的区别: 被重写的函数和重写的函数在两个类中，而重载和被重载的函数在同一个类中。 ②参数的区别: 被重写函数和重写函数的参数列表一定相同，而被重载函数和重载函数的参数列表一定不同。 ③virtual的区别：重写的基类中被重写的函数必须要有virtual修饰，而重载函数和被重载函数可以被virtual修饰，也可以没有。 (2) 隐藏和重写、重载有以下几点不同。 与重载的范围不同: 和重写一样，隐藏函数和被隐藏函数不在同一个类中。 参数的区别: 隐藏函数和被隐藏的函数的参数列表可以相同，也可不同，但是函数名肯定要相同。 当参数不相同时，无论基类中的参数是否被virtual 修饰，基类的函数都是被隐藏，而不是被重写。 注意：虽然重载和覆盖都是实现多态的基础，但是两者实现的技术完全不相同，达到的目的也是完全不同的，覆盖是动态绑定的多态，而重载是静态绑定的多态。 ","date":"2023-07-11","objectID":"/posts/basics_one/:4:9","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"4.11 链表和数组有什么区别 存储形式: 数组是一块连续的空间，声明时就要确定长度。 链表是一块可不连续的动态空间，长度可变，每个结点要保存相邻结点指针。 数据查找: 数组的线性查找速度快，查找操作直接使用偏移地址。 链表需要按顺序检索结点， 效率低。 数据插入或删除: 链表可以快速插入和删除结点，而数组则可能需要大量数据移动。 越界问题： 链表不存在越界问题，数组有越界问题。 注意： 在选择数组或链表数据结构时，一定要根据实际需要进行选择。数组便于查询，链表便于插入删除。数组节省空间但是长度固定，链表虽然变长但是占了更多的存储空间。 ","date":"2023-07-11","objectID":"/posts/basics_one/:4:10","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"4.12 用两个栈实现一个队列的功能 typedef struct node { int data; node *next; }node,*LinkStack; //创建空栈： LinkStack CreateNULLStack( LinkStack \u0026S) { S = (LinkStack)malloc( sizeof( node ) ); // 申请新结点 if( NULL == S) { printf(\"Fail to malloc a new node.\\n\"); return NULL; } S-\u003edata = 0; //初始化新结点 S-\u003enext = NULL; return S; } //栈的插入函数： LinkStack Push( LinkStack \u0026S, int data) { if( NULL == S) //检验栈 { printf(\"There no node in stack!\"); return NULL; } LinkStack p = NULL; p = (LinkStack)malloc( sizeof( node ) ); // 申请新结点 if( NULL == p) { printf(\"Fail to malloc a new node.\\n\"); return S; } if( NULL == S-\u003enext) { p-\u003enext = NULL; } else { p-\u003enext = S-\u003enext; } p-\u003edata = data; //初始化新结点 S-\u003enext = p; //插入新结点 return S; } //出栈函数： node Pop( LinkStack \u0026S) { node temp; temp.data = 0; temp.next = NULL; if( NULL == S) //检验栈 { printf(\"There no node in stack!\"); return temp; } temp = *S; if( S-\u003enext == NULL ) { printf(\"The stack is NULL,can't pop!\\n\"); return temp; } LinkStack p = S -\u003enext; //节点出栈 S-\u003enext = S-\u003enext-\u003enext; temp = *p; free( p ); p = NULL; return temp; } //双栈实现队列的入队函数： LinkStack StackToQueuPush( LinkStack \u0026S, int data) { node n; LinkStack S1 = NULL; CreateNULLStack( S1 ); //创建空栈 while( NULL != S-\u003enext ) //S 出栈入S1 { n = Pop( S ); Push( S1, n.data ); } Push( S1, data ); //新结点入栈 while( NULL != S1-\u003enext ) //S1 出栈入S { n = Pop( S1 ); Push( S, n.data ); } return S; } 注意：用两个栈能够实现一个队列的功能，那用两个队列能否实现一个栈的功能呢？结果是否定的，因为栈是先进后出，将两个栈连在一起，就是先进先出。而队列是现先进先出，无论多少个连在一起都是先进先出，而无法实现先进后出。 ","date":"2023-07-11","objectID":"/posts/basics_one/:4:11","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"4.13 共享数据的保护 ①常引用: 使所引用的形参不能被更新 void display(const double\u0026 a); ②常对象：在生存期内不能被更新，但 必须被初始化 A const a(3,4); ③常成员函数： 不能修改对象中数据成员，也不能调用类中没有被const 修饰的成员函数(常对象唯一的对外接口).如果声明了一个常对象，则该对象只能调用他的常函数！-\u003e可以用于对重载函数的区分; void print(); void print() const; ④extern int a: 使其他文件也能访问该变量 声明一个函数或定义函数时，冠以static的话，函数的作用域就被限制在了当前编译单元，当前编译单元内也必须包含函数的定义，也只在其编译单元可见，其他单元不能调用这个函数(每一个cpp文件就是一个编译单元)。 ","date":"2023-07-11","objectID":"/posts/basics_one/:4:12","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"4.14 程序内存分配方式以及它们的区别 内存分配大致上可以分成5块: 栈区(stack) 栈，就是那些由编译器在需要时分配，在不需要的时候自动清除的变量的存储区。里面的变量通常是局部变量、函数参数等。(由编译器管理) 堆区(heap) 一般由程序员分配、释放，若程序员不释放，程序结束时可能由系统回收。注意，它与数据结构中的堆是两回事，分配方式类似于链表。 全局区(静态区)(static) 全局变量和静态变量被分配到同一块内存中。程序结束后由系统释放。 常量存储区 常量字符串就是放在这里的，不允许修改，程序结束后由系统释放。 程序代码区 存放函数体的二进制代码。 C++程序在执行时，将内存大方向划分为4个区域: 程序运行前 代码区：存放函数体的二进制代码，由操作系统进行管理的 全局区：存放全局变量和静态变量以及常量 程序运行后 栈区：由编译器自动分配释放, 存放函数的参数值,局部变量等 堆区：由程序员分配和释放,若程序员不释放,程序结束时由操作系统回收 内存四区意义： 不同区域存放的数据，赋予不同的生命周期, 给我们更大的灵活编程 ","date":"2023-07-11","objectID":"/posts/basics_one/:4:13","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"4.15 explicit 函数声明时加上explicit可以阻止函数参数被隐式转换。 Class A { explicit A(int a); } Void main() { A a1=12; //不加explicit时会被隐式转换位 A a1=A(12);加了此时编译器会报错。 } 被声明为explicit的构造函数通常比non-explicit 函数更受欢迎。 ","date":"2023-07-11","objectID":"/posts/basics_one/:4:14","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"4.16 mutable关键字 mutable的中文意思是“可变的，易变的”，跟constant(既C++中的const)是反义词。在C++中，mutable也是为了突破const的限制而设置的。 被mutable修饰的变量(mutable只能用于修饰类的非静态数据成员)，将永远处于可变的状态，即使在一个const函数中。 我们知道，假如类的成员函数不会改变对象的状态，那么这个成员函数一般会声明为const。但是，有些时候，我们需要在const的函数里面修改一些跟类状态无关的数据成员，那么这个数据成员就应该被mutalbe来修饰。(使用mutable修饰的数据成员可以被const成员函数修改)。 ","date":"2023-07-11","objectID":"/posts/basics_one/:4:15","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"4.17 用const修饰函数的返回值 如果给以“指针传递”方式的函数返回值加const修饰，那么函数返回值(即指针)的内容不能被修改，该返回值只能被赋给加const修饰的同类型指针。例如函数： const char * GetString(void); // 如下语句将出现编译错误： char*str = GetString(); // 正确的用法是 const char *str =GetString(); ","date":"2023-07-11","objectID":"/posts/basics_one/:4:16","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"4.18 宏、const和enum #define不被视为语言的一部分。对于单纯常量，最好用const对象或者enum替换#define。 对于类似函数的宏，尽量使用内联函数inline替换掉#define enum枚举类型是被当做 int 或者 unsigned int 类型来处理的。 ","date":"2023-07-11","objectID":"/posts/basics_one/:4:17","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"4.19 static 对象和 non-local static对象区别 ①C++中的static对象是指存储区不属于stack和heap、“寿命\"从被构造出来直至程序结束为止的对象。 ②这些对象包括全局对象，定义于namespace作用域的对象，在class、function以及file作用域中被声明为static的对象。 ③其中，函数内的static对象称为local static对象，而其它static对象称为non-local static对象。 local static 对象和non-local static对象在何时被初始化(构造)这个问题上存在细微的差别: ①对于local static对象，在其所属的函数被调用之前，该对象并不存在，即只有在第一次调用对应函数时，local static对象才被构造出来。 ②而对于non-local static对象，在main()函数开始前就已经被构造出来，并在main()函数结束后被析构。 建议： 1.对内置对象进行手工初始化，因为C++不保证初始化它们。 2.构造函数最好使用成员初值列，而不要在构造函数本体中使用赋值操作。初值列中列出的成员变量，其排序次序应该和它们在class中的声明次序相同(初始化顺序与声明变量顺序一致)。 3.为免除“跨编译单元的初始化次序问题”，尽量以local static对象替换non-local static对象。 ","date":"2023-07-11","objectID":"/posts/basics_one/:4:18","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"4.20 全局变量和static变量的区别 ①全局变量本身就是静态存储方式， 静态全局变量当然也是静态存储方式。 这两者在存储方式上并无不同。 ②这两者的区别在于非静态全局变量的作用域是整个源程序， 当一个源程序由多个源文件组成时，非静态的全局变量在各个源文件中都是有效的。 ③而静态全局变量则限制了其作用域， 即只在定义该变量的源文件内有效， 在同一源程序的其它源文件中不能使用它。 ④由于静态全局变量的作用域局限于一个源文件内，只能为该源文件内的函数公用， 因此可以避免在其它源文件中引起错误。 ","date":"2023-07-11","objectID":"/posts/basics_one/:4:19","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"5. 基础知识(五) ","date":"2023-07-11","objectID":"/posts/basics_one/:5:0","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"5.1 为什么栈要比堆速度要快 ①首先, 栈是本着LIFO原则的存储机制, 对栈数据的定位相对比较快速, 而堆则是随机分配的空间, 处理的数据比较多, 无论如何, 至少要两次定位. ②其次, 栈是由CPU提供指令支持的, 在指令的处理速度上, 对栈数据进行处理的速度自然要优于由操作系统支持的堆数据. ③再者, 栈是在一级缓存中做缓存的, 而堆则是在二级缓存中, 两者在硬件性能上差异巨大. ④最后, 各语言对栈的优化支持要优于对堆的支持, 比如swift语言中, 三个字及以内的struct结构, 可以在栈中内联, 从而达到更快的处理速度. ","date":"2023-07-11","objectID":"/posts/basics_one/:5:1","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"5.2 c++ 析构函数调用时间 对象生命周期结束，被销毁时; delete指向对象的指针时，或delete指向对象的基类类型指针，而其基类析构函数是虚函数时; 对象i是对象o的成员，o的析构函数被调用时，对象i的析构函数也被调用 ","date":"2023-07-11","objectID":"/posts/basics_one/:5:2","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"5.3 静态绑定 动态绑定 (也叫动态连编，静态连编) 如果父类中存在有虚函数，那么编译器便会为之生成虚表(属于类)与虚指针(属于某个对象)，在程序运行时，根据虚指针的指向，来决定调用哪个虚函数，这称之与动态绑定，与之相对的是静态绑定，静态绑定在编译期就决定了。 class和template都支持接口与多态: ①对classes而言，接口是显式的，以函数签名为中心。多态则是通过virtual函数(虚函数)发生于运行期； ②对template参数而言，接口是隐式的，奠基于有效表达式。多态则是通过template具现化和函数重载解析发生于编译期。 泛型 泛型是通过参数化类型来实现在同一份代码上操作多种数据类型。利用“参数化类型”将类型抽象化，从而实现灵活的复用。 ","date":"2023-07-11","objectID":"/posts/basics_one/:5:3","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"5.4 C语言的指针和C++的引用有什么区别？ 指针有自己的一块空间，指针是一个变量，只不过这个变量存储的是一个地址，指向内存的一个存储单元，即指针是一个实体。而引用只是一个别名; 使用sizeof看一个指针的大小是4，而引用则是被引用对象的大小; 指针可以被初始化为NULL，而引用必须被初始化且必须是一个已有对象的引用; 作为参数传递时，指针需要被解引用才可以对对象进行操作，而直接对引用的修改都会改变引用所指向的对象; ","date":"2023-07-11","objectID":"/posts/basics_one/:5:4","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"5.5 请你说说C语言是怎么进行函数调用的 每一个函数调用都会分配函数栈，在栈内进行函数执行过程。调用前，先把返回地址压栈，然后把当前函数的esp指针压栈。(ESP(Extended Stack Pointer)为扩展栈指针寄存器，是指针寄存器的一种，用于存放函数栈顶指针) C语言参数压栈顺序？：从右到左 ","date":"2023-07-11","objectID":"/posts/basics_one/:5:5","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"5.6 C++中拷贝赋值函数的形参能否进行值传递？ ⭐ 不能。如果是这种情况下，调用拷贝构造函数的时候，首先要将实参传递给形参，这个传递的时候又要调用拷贝构造函数(aa = ex.aa; //此处调用拷贝构造函数)。如此循环，无法完成拷贝，栈也会满。 ","date":"2023-07-11","objectID":"/posts/basics_one/:5:6","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"5.7 include头文件的顺序以及双引号\"\"和尖括号\u003c\u003e的区别 编译器预处理阶段查找头文件的路径不一样 使用双引号\"\"包含的头文件，查找头文件路径的顺序为： ①当前头文件目录 ②编译器设置的头文件路径(编译器可使用-I显式指定搜索路径) ③系统变量CPLUS_INCLUDE_PATH/C_INCLUDE_PATH指定的头文件路径 对于使用尖括号\u003c\u003e包含的头文件，查找头文件的路径顺序为： ①编译器设置的头文件路径(编译器可使用-I显式指定搜索路径) ②系统变量CPLUS_INCLUDE_PATH/C_INCLUDE_PATH指定的头文件路径 ","date":"2023-07-11","objectID":"/posts/basics_one/:5:7","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"5.8 一个C++源文件从文本到可执行文件经历的过程 对于C/C++编写的程序，从源代码到可执行文件，一般经过下面四个步骤： 预编译，预编译的时候做一些简单的文本替换，比如宏替换，而不进行语法的检查； 编译，在编译阶段，编译器将检查一些语法错误，但是，如果使用的函数事先没有定义这种情况，不再这一阶段检查，编译后，得到.s文件 汇编，将C/C++代码变为汇编代码，得到.o或者.obj文件 链接，将所用到的外部文件链接在一起，在这一阶段，就会检查使用的函数有没有定义 链接过后，形成可执行文件.exe 详细请参阅: 一个C++源文件从文本到可执行文件经历的过程 ","date":"2023-07-11","objectID":"/posts/basics_one/:5:8","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"5.9 内存泄漏原因和判断方法 内存泄漏通常是因为调用了malloc/new等内存申请操作，但是缺少了对应的free/delete。 为了判断内存是否泄漏，我们一方面可以使用Linux环境下的内存泄漏检查工具Valgrind，另一方面我们写代码的时候，可以添加内存申请和释放的统计功能，统计当前申请和释放的内存是否一致，以此来判断内存是否有泄漏。 内存泄漏分类: 堆内存泄漏(heap leak)。堆内存是程序运行过程中根据需要通过malloc\\realloc\\new等从堆中分配的一块内存，在完成之后，必须要通过调用对应的free或者delete删除。如果程序的设计的错误导致这部分内存没有被释放，那么此后这块内存将不会被使用，就会产生Heap Leak。 系统资源泄露(Resource Leak)。主要指程序使用系统分配的资源比如 Bitmap，handle，SOCKET等没有使用相应的函数释放掉，导致系统资源的浪费，严重可导致系统效能降低，系统运行不稳定。 没有将基类的析构函数定义为虚函数。当基类指针指向子类对象时，如果基类的析构函数不是virtual，那么子类的析构函数将不会被调用，子类的资源没有正确的释放，从而造成内存泄漏。 ","date":"2023-07-11","objectID":"/posts/basics_one/:5:9","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"5.10 段错误的产生原因 段错误是什么? 一句话来说，段错误是指访问的内存超出了系统给这个程序所设定的内存空间，例如访问了不存在的内存地址、访问了系统保护的内存地址、访问了只读的内存地址等等情况。这里贴一个对于“段错误”的准确定义。 段错误产生的原因 访问不存在的内存地址 访问系统保护的内存地址 访问只读的内存地址 栈溢出 详细请参阅：Linux环境下段错误的产生原因及调试方法小结 ","date":"2023-07-11","objectID":"/posts/basics_one/:5:10","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"5.11 C++ 函数调用过程 总结起来整个过程就三步: 根据调用的函数名找到函数入口; 在栈中申请调用函数中的参数及函数体内定义的变量的内存空间; 函数执行完后，释放函数在栈中的申请的参数和变量的空间，最后返回值(如果有的话)。 详细请查阅：函数调用过程 / C/C++函数调用过程分析 ","date":"2023-07-11","objectID":"/posts/basics_one/:5:11","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"5.12 如何调试c++多线程程序？ 打印日志，日志中加上线程ID；(简单粗暴) gdb有thread相关命令，如infothread(简写infoth)显示线程消息，bxxthreadyy可以对某个thread设置断点，threadxx(简写成thrxx)切换到某个thread。再配合frame(简写f)相关的命令(比如up，down在不同frame间跳转)，基本可以处理若干个不同的线程间的debug…… 详细请查阅：C++(vs)多线程调试 (转) ","date":"2023-07-11","objectID":"/posts/basics_one/:5:12","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"5.13 面向对象和面向过程的区别 ①面向对象方法中，把数据和数据操作放在一起，组成对象; 对同类的对象抽象出其共性组成类; 类通过简单的接口与外界发生联系，对象和对象之间通过消息进行通信。 ②面向对象的三大特性是\"封装、“多态”、“继承”，五大原则是\"单一职责原则”、“开放封闭原则”、“里氏替换原则”、“依赖倒置原则”、“接口分离原则”。 ③而面向过程方法是以过程为中心的开发方法，它自顶向下顺序进行， 程序结构按照功能划分成若干个基本模块，这些模块形成树状结构。 (过程)优点： 性能比面向对象高，因为类调用时需要实例化，开销比较大，比较消耗源;比如嵌入式开发、Linux/Unix等一般采用面向过程开发，性能是最重要的因素。 缺点：没有面向对象易维护、易复用、易扩展。 (对象)优点： 易维护、易复用、易扩展，由于面向对象有封装、继承、多态性的特性，可以设计出低耦合的系统。 缺点：性能比面向过程低。 ","date":"2023-07-11","objectID":"/posts/basics_one/:5:13","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"5.14 关于引用赋值的多态： Class B; Class D : public B; B\u0026 b; D\u0026 d; B\u0026 b1 = d ; //父类可以作为子类的引用，此时b1表现和指针形式一致(会调用B的非虚函数) D\u0026 d1 = b； //错误，不能将子类作为父类的引用 ","date":"2023-07-11","objectID":"/posts/basics_one/:5:14","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"5.15 模板的声明和实现不能分开的原因 链接的时候，需要实例化模板，这时候就需要找模板的具体实现了。假设在main函数中调用了一个模板函数，这时候就需要去实例化该类型的模板。注意main函数里面只包含了.h文件，也就是只有模板的声明，没有具体实现。就会报错。 而模板的实现.cpp里面，虽然有模板的具体实现，但是没有谁在该.cpp里面使用一个模板函数，就不会生成一个具体化的实例 详细请参阅：C++ 模板类的声明与实现分离问题 / ​​​​​​C++ 模板类的声明与实现分离问题(模板实例化)​​​​​​ ","date":"2023-07-11","objectID":"/posts/basics_one/:5:15","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"5.16 C++类中引用成员和常量成员的初始化(必须用初始化列表进行初始化) 如果一个类是这样定义的： Class A { public: A(int pram1, int pram2, int pram3); private: int a; int \u0026b; // 引用成员 const int c; // 常量成员 } 假如在构造函数中对三个私有变量进行赋值则通常会这样写： A::A(int pram1, int pram2, int pram3) { a=pram1; b=pram2; c=pram3; } 但是，这样是编译不过的。因为常量和引用初始化必须赋值。所以上面的构造函数的写法只是简单的赋值，并不是初始化。 正确写法应该是： A::A(int pram1, int pram2, int pram3):b(pram2),c(pram3) { a=pram1; } 采用初始化列表实现了对常量和引用的初始化。采用括号赋值的方法，括号赋值只能用在变量的初始化而不能用在定义之后的赋值。 凡是有引用类型的成员变量或者常量类型的变量的类，不能有缺省构造函数。默认构造函数没有对引用成员提供默认的初始化机制，也因此造成引用未初始化的编译错误。并且必须使用初始化列表进行初始化const对象、引用对象。 ","date":"2023-07-11","objectID":"/posts/basics_one/:5:16","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"5.17 memset为int型数组初始化问题 头文件: #include \u003cstring.h\u003e memset() 函数用来将指定内存的前n个字节设置为特定的值，其原型为: 函数说明 void * memset(void * ptr, int value, size_t num); 参数说明： ptr 为要操作的内存的指针。 value 为要设置的值。你既可以向 value 传递 int 类型的值，也可以传递 char 类型的值，int 和 char 可以根据 ASCII 码相互转换。 num 为 ptr 的前 num 个字节，size_t 就是unsigned int。 memset() 会将 ptr 所指的内存区域的前 num 个字节的值都设置为 value，然后返回指向 ptr 的指针。 无法下面这样初始化，这样的结果是a被赋值成168430090，168430090….. int a[10]; // array memset(a, 1, sizeof(a)); 这是因为int由4个字节(说)表示，并且不能得到数组a中整数的期望值。 但我经常看到程序员使用memset将int数组元素设置为 0 或 -1。其他值不行！ int a[10]; int b[10]; memset(a, 0, sizeof(a)); memset(b, -1, sizeof(b)); //假设a为int型数组： memset(a, 0x7f, sizeof(a)); //a数组每个空间将被初始化为0x7f7f7f7f,原因是C函数传参过程中的指针降级，导致sizeof(a)，返回的是一个 something*指针类型大小的的字节数，如果是32位，就是4字节。所以memset按字节赋值。 memset(a,0xaf,sizeof(a)); //a数组每个空间将被初始化为0xafafafaf ","date":"2023-07-11","objectID":"/posts/basics_one/:5:17","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"5.18 编译器对 inline 函数的处理步骤 编译器对 inline 函数的处理: 将 inline 函数体复制到 inline 函数调用点处; 为所有 inline 函数中的局部变量分配内存空间; 将 inline 函数的输入参数和返回值映射到调用方法的局部变量空间中; 如果 inline 函数有多个返回点，将其转变为 inline 函数代码块末尾的分支(使用 GOTO); 优点: 内联函数同宏函数一样将在被调用处进行代码展开，省去了参数压栈、栈帧开辟与回收，结果返回等，从而提高程序运行速度。 内联函数相比宏函数来说，在代码展开时，会做安全检查或自动类型转换(同普通函数)，而宏定义则不会。 在类中声明同时定义的成员函数，自动转化为内联函数，因此内联函数可以访问类的成员变量，宏定义则不能。 内联函数在运行时可调试，而宏定义不可以。 缺点: 代码膨胀。内联是以代码膨胀(复制)为代价，消除函数调用带来的开销。如果执行函数体内代码的时间，相比于函数调用的开销较大，那么效率的收获会很少。另一方面，每一处内联函数的调用都要复制代码，将使程序的总代码量增大，消耗更多的内存空间。 inline 函数无法随着函数库升级而升级。inline函数的改变需要重新编译，不像 non-inline 可以直接链接。 是否内联，程序员不可控。内联函数只是对编译器的建议，是否对函数内联，决定权在于编译器。 ","date":"2023-07-11","objectID":"/posts/basics_one/:5:18","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"5.19 虚函数(virtual)可以是内联函数(inline)吗？ 虚函数可以是内联函数，内联是可以修饰虚函数的，但是当虚函数表现多态性的时候不能内联。 内联是在编译期建议编译器内联，而虚函数的多态性在运行期，编译器无法知道运行期调用哪个代码，因此虚函数表现为多态性时(运行期)不可以内联。 inline virtual 唯一可以内联的时候是：编译器知道所调用的对象是哪个类(如 Base::who())，这只有在编译期具有实际对象而不是对象的指针或引用时才会发生; ","date":"2023-07-11","objectID":"/posts/basics_one/:5:19","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"5.20 静态库和动态库比较 静态库 (.a、.lib): 将静态库的内容添加到程序中，此时程序的空间，变成了源程序空间大小 + 静态库空间大小。 动态库(共享库)(.so、.dll): 常驻内存，当程序需要调用相关函数时，会从内存调用。 区别: 静态库：对空间要求较低，而时间要求较高的核心程序中。(.a、.lib) 动态库：对时间要求较低，对空间要求较高。(.so、.dll) hash ","date":"2023-07-11","objectID":"/posts/basics_one/:5:20","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"6 基础知识(六) ","date":"2023-07-11","objectID":"/posts/basics_one/:6:0","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["C++"],"content":"6.1 构造函数为什么不能定义为虚函数？ ⽽析构函数⼀般写成虚函数的原因 ？ 构造函数不能声明为虚函数的原因是: 构造一个对象的时候，必须知道对象的实际类型，而虚函数行为是在运行期间确定实际类型的。而在构造一个对象时，由于对象还未构造成功。编译器无法知道对象的实际类型，是该类本身，还是该类的一个派生类，或是更深层次的派生类。无法确定。 虚函数的执行依赖于虚函数表。而虚函数表在构造函数中进行初始化工作，即初始化vptr，让他指向正确的虚函数表。而在构造对象期间，虚函数表还没有被初始化，将无法进行。 虚函数的意思就是开启动态绑定，程序会根据对象的动态类型来选择要调用的方法。然而在构造函数运行的时候，这个对象的动态类型还不完整，没有办法确定它到底是什么类型，故构造函数不能动态绑定。(动态绑定是根据对象的动态类型而不是函数名，在调用构造函数之前，这个对象根本就不存在，它怎么动态绑定？) 编译器在调用基类的构造函数的时候并不知道你要构造的是一个基类的对象还是一个派生类的对象。 析构函数设为虚函数的作用: 解释：在类的继承中，如果有基类指针指向派生类，那么用基类指针delete时，如果不定义成虚函数，派生类中派生的那部分无法析构。(如果基类的析构函数不是虚函数，那么在delete 基类指针时，只调用基类的析构函数，不会调用派生类的析构函数，故派生类部分不会被析构。) ref: [1]. https://blog.csdn.net/Yangy_Jiaojiao/article/details/127588598 [2]. https://blog.csdn.net/Yangy_Jiaojiao/article/details/128145609 参考(待补充): [1]. https://zhuanlan.zhihu.com/p/401341063 [2]. https://zhuanlan.zhihu.com/p/602866792 [3]. 万字长文超全 C++面经 ref: https://blog.csdn.net/m0_46245582/category_11569287.html ","date":"2023-07-11","objectID":"/posts/basics_one/:6:1","tags":["basics"],"title":"C++ 基础知识[一]","uri":"/posts/basics_one/"},{"categories":["Distributed Computing"],"content":"0 摘要 Horovod 是Uber于2017年发布的一个易于使用的高性能的分布式训练框架，在业界得到了广泛应用。 本系列将通过源码分析来带领大家了解 Horovod。本文是系列第四篇，看看如何获取 host 之间的路由等网络信息。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_4/:1:0","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[4] -- 网络基础 \u0026 Driver","uri":"/posts/2022-10-08_horovod_4/"},{"categories":["Distributed Computing"],"content":"1 引子 在 horovod/runner/launch.py 文件中，_run_static 函数中使用 driver_service.get_common_interfaces 来获取路由信息等。 def _run_static(args): nics = driver_service.get_common_interfaces(settings, all_host_names, remote_host_names, fn_cache) 因为这部分比较复杂（ Driver 的概念很类似 Spark 之中 Driver 的概念），所以本文我们单独来分析。 本文的分析问题点是： 为什么要知道路由信息？ 当有多个host时候，horovod如何处理？ 如何找到路由信息？ 怎么互相交互？ （后文会详细分析）SparkDriverService，SparkTaskService，ElasticDriver, Worker 都有什么区别和联系？ 本文重点分析 HorovodRunDriverService 和 HorovodRunTaskService 相关。 先给出一个图例，大家可以有些概念。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_4/:2:0","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[4] -- 网络基础 \u0026 Driver","uri":"/posts/2022-10-08_horovod_4/"},{"categories":["Distributed Computing"],"content":"2 总体架构 从注释可知，get_common_interfaces 完成了获得路由信息（所有host之间的共有路由接口集合）的功能，主要是调用 _driver_fn 来完成相关工作。 def get_common_interfaces(settings, all_host_names, remote_host_names=None, fn_cache=None): ''' Find the set of common and routed interfaces on all the hosts. ''' # 得到远端host地址 if remote_host_names is None: remote_host_names = network.filter_local_addresses(all_host_names) if len(remote_host_names) \u003e 0: if settings.nics: # 如果参数有设定网络接口，就使用 # If args.nics is provided, we will use those interfaces. All the workers # must have at least one of those interfaces available. nics = settings.nics else: # Find the set of common, routed interfaces on all the hosts (remote # and local) and specify it in the args to be used by NCCL. It is # expected that the following function will find at least one interface # otherwise, it will raise an exception. local_host_names = set(all_host_names) - set(remote_host_names) # 获取其他host的网络接口 nics = _driver_fn(all_host_names, local_host_names, settings, fn_cache=fn_cache) else: nics = get_local_interfaces(settings) # 获取本地的网络接口 return nics ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_4/:3:0","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[4] -- 网络基础 \u0026 Driver","uri":"/posts/2022-10-08_horovod_4/"},{"categories":["Distributed Computing"],"content":"2.1 get_local_interfaces 此函数比较简单，目的是获取本地的网络接口。 def get_local_interfaces(settings): # If all the given hosts are local, find the interfaces with address # 127.0.0.1 nics = set() for iface, addrs in net_if_addrs().items(): if settings.nics and iface not in settings.nics: continue for addr in addrs: if addr.family == AF_INET and addr.address == '127.0.0.1': nics.add(iface) break return nics ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_4/:3:1","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[4] -- 网络基础 \u0026 Driver","uri":"/posts/2022-10-08_horovod_4/"},{"categories":["Distributed Computing"],"content":"2.2 _driver_fn 这是本文重点，获取其他host 的网络接口，_driver_fn 的作用是： 启动 service 服务； 使用 driver.addresses() 获取 Driver 服务的地址（使用self._addresses = self._get_local_addresses()完成）； 使用 _launch_task_servers（利用 Driver 服务的地址）在每个 worker 之中启动 task 服务，然后 task 服务会在 service 服务中注册； 因为是一个环形，每个 worker 会探测 worker index + 1 的所有网络接口； 最后 _run_probe 返回一个所有 workers 上的所有路由接口的交集； 代码如下： 这里需要注意的一点是：@cache.use_cache() 的使用：当第一次使用过之后，会把结果放入缓存。 @cache.use_cache() def _driver_fn(all_host_names, local_host_names, settings): \"\"\" launches the service service, launches the task service on each worker and have them register with the service service. Each worker probes all the interfaces of the worker index + 1 (in a ring manner) and only keeps the routed interfaces. Function returns the intersection of the set of all the routed interfaces on all the workers. :param all_host_names: list of addresses. for example, ['worker-0','worker-1'] ['10.11.11.11', '10.11.11.12'] :type all_host_names: list(string) :param local_host_names: host names that resolve into a local addresses. :type local_host_names: set :param settings: the object that contains the setting for running horovod :type settings: horovod.runner.common.util.settings.Settings :return: example: ['eth0', 'eth1'] :rtype: list[string] \"\"\" # Launch a TCP server called service service on the host running horovod # 启动 service 服务 num_hosts = len(all_host_names) driver = HorovodRunDriverService(num_hosts, settings.key, settings.nics) # Have all the workers register themselves with the service service. #（利用 Driver 服务的地址）在每个worker之中启动 task 服务，然后task服务会在 service 服务中注册 _launch_task_servers(all_host_names, local_host_names, driver.addresses(), settings) try: # 返回一个所有 workers 上的所有路由接口的交集 return _run_probe(driver, settings, num_hosts) finally: driver.shutdown() ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_4/:3:2","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[4] -- 网络基础 \u0026 Driver","uri":"/posts/2022-10-08_horovod_4/"},{"categories":["Distributed Computing"],"content":"2.3 获取路由接口 我们对 _run_probe 函数做进一步分析。 2.3.1 probe逻辑 _run_probe 函数就是当所有 task 都启动，注册，probe 环中下一个worker 邻居完成 之后，得到 接口集合。 利用 wait_for_initial_registration 等待所有 task 完成注册； 对于所有 task，完成 task.notify_initial_registration_complete 通知； 利用 driver.wait_for_task_to_task_address_updates 等待 每一个 worker probe 完成； 利用 nics.intersection_update 得到接口集合； def _run_probe(driver, settings, num_hosts): # wait for all the hosts to register with the service service. driver.wait_for_initial_registration(settings.start_timeout) tasks = [ task_service.HorovodRunTaskClient( index, driver.task_addresses_for_driver(index), settings.key, settings.verbose) for index in range( num_hosts)] # Notify all the drivers that the initial registration is complete. for task in tasks: task.notify_initial_registration_complete() # Each worker should probe the interfaces of the next worker in a ring # manner and filter only the routed ones -- it should filter out # interfaces that are not really connected to any external networks # such as lo0 with address 127.0.0.1. driver.wait_for_task_to_task_address_updates(settings.start_timeout) # Determine a set of common interfaces for task-to-task communication. nics = set(driver.task_addresses_for_tasks(0).keys()) for index in range(1, num_hosts): nics.intersection_update( driver.task_addresses_for_tasks(index).keys()) return nics 2.3.2 等待函数 probe 利用 wait_for_initial_registration 等待所有 task 完成注册，具体等待函数如下： def wait_for_initial_registration(self, timeout): self._wait_cond.acquire() try: while len(self._all_task_addresses) \u003c self._num_proc: self._wait_cond.wait(timeout.remaining()) timeout.check_time_out_for('tasks to start') finally: self._wait_cond.release() def wait_for_task_to_task_address_updates(self, timeout): self._wait_cond.acquire() try: while len(self._task_addresses_for_tasks) \u003c self._num_proc: self._wait_cond.wait(timeout.remaining()) timeout.check_time_out_for( 'tasks to update task-to-task addresses') finally: self._wait_cond.release() ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_4/:3:3","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[4] -- 网络基础 \u0026 Driver","uri":"/posts/2022-10-08_horovod_4/"},{"categories":["Distributed Computing"],"content":"3 基础网络服务 前面提到，Horovod Driver 的概念很类似 Spark 之中 Driver 的概念。Spark应用程序运行时主要分为 Driver 和 Executor，Driver负责总体调度及UI展示，Executor负责Task运行。用户的Spark应用程序运行在Driver上（某种程度上说，用户的程序就是Spark Driver程序），经过Spark调度封装成一个个Task，再将这些Task信息发给Executor执行，Task信息包括代码逻辑以及数据信息，Executor不直接运行用户的代码。 对于 Horovod 来说： HorovodRunDriverService 就是 Driver 的实现类。 HorovodRunTaskService 提供了 Task 部分服务功能，这些 task 需要注册到 HorovodRunDriverService 之中。 这套 driver \u0026 task 机制的底层由 “基础网络服务” 支撑。 所以我们就仔细分析下基础网络服务。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_4/:4:0","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[4] -- 网络基础 \u0026 Driver","uri":"/posts/2022-10-08_horovod_4/"},{"categories":["Distributed Computing"],"content":"3.1 继承关系 首先给出继承关系，我们下面讲解的 Driver 服务由 HorovodRunDriverService 提供，Task 服务由HorovodRunTaskService 提供。 这两个类最终都继承了 network.BasicService。 network.BasicService ^ ^ | | +-------------------+ +-------------+ | | + + driver_service.BasicDriverService task_service.BasicTaskService ^ ^ | | | | | | + + HorovodRunDriverService HorovodRunTaskService ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_4/:4:1","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[4] -- 网络基础 \u0026 Driver","uri":"/posts/2022-10-08_horovod_4/"},{"categories":["Distributed Computing"],"content":"3.2 network.BasicService BasicService 提供了一个网络服务器功能。即通过find_port函数构建了一个ThreadingTCPServer对外提供服务。 class BasicService(object): def __init__(self, service_name, key, nics): self._service_name = service_name self._wire = Wire(key) self._nics = nics self._server, _ = find_port( lambda addr: socketserver.ThreadingTCPServer( addr, self._make_handler())) self._server._block_on_close = True self._port = self._server.socket.getsockname()[1] self._addresses = self._get_local_addresses() self._thread = in_thread(target=self._server.serve_forever) 3.2.1 创建Server 创建服务器代码如下，这里是搜索一个随机端口，然后设置： def find_port(server_factory): min_port = 1024 max_port = 65536 num_ports = max_port - min_port start_port = random.randrange(0, num_ports) for port_offset in range(num_ports): try: port = min_port + (start_port + port_offset) % num_ports addr = ('', port) server = server_factory(addr) return server, port except Exception as e: pass raise Exception('Unable to find a port to bind to.') 3.2.2 Server功能 服务器就是基本的功能，比如获取本server地址，处理 ping，网络交互等。 def _make_handler(self): server = self class _Handler(socketserver.StreamRequestHandler): def handle(self): try: req = server._wire.read(self.rfile) resp = server._handle(req, self.client_address) # A tuple is the usual response object followed by a utf8 text stream if type(resp) == tuple: (resp, stream) = resp server._wire.write(resp, self.wfile) server._wire.stream(stream, self.wfile) else: server._wire.write(resp, self.wfile) except (EOFError, BrokenPipeError): # Happens when client is abruptly terminated, don't want to pollute the logs. pass return _Handler def _handle(self, req, client_address): if isinstance(req, PingRequest): return PingResponse(self._service_name, client_address[0]) raise NotImplementedError(req) def _get_local_addresses(self): result = {} for intf, intf_addresses in psutil.net_if_addrs().items(): if self._nics and intf not in self._nics: continue for addr in intf_addresses: if addr.family == socket.AF_INET: if intf not in result: result[intf] = [] result[intf].append((addr.address, self._port)) return result def addresses(self): return self._addresses.copy() def shutdown(self): self._server.shutdown() self._server.server_close() self._thread.join() def get_port(self): return self._port ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_4/:4:2","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[4] -- 网络基础 \u0026 Driver","uri":"/posts/2022-10-08_horovod_4/"},{"categories":["Distributed Computing"],"content":"3.3 network.BasicClient HorovodRunDriverClient 和 HorovodRunTaskClient 这两个类都继承了network.BasicClient。 network.BasicClient 的作用就是连接 network.BasicService，与其交互。即 network.BasicClient 是一个操作接口。 network.BasicClient ^ ^ | | +------------------+ +---------------+ | | + | + driver_service.BasicDriverClient task_service.BasicTaskClient ^ ^ | | | | + + HorovodRunDriverClient HorovodRunTaskClient 两个主要 API 如下： 3.3.1 _probe _probe 获取 server 的网络接口。 def _probe(self, addresses): result_queue = queue.Queue() threads = [] for intf, intf_addresses in addresses.items(): for addr in intf_addresses: thread = in_thread(target=self._probe_one, args=(intf, addr, result_queue)) threads.append(thread) for t in threads: t.join() result = {} while not result_queue.empty(): intf, addr = result_queue.get() if intf not in result: result[intf] = [] result[intf].append(addr) return result 3.3.2 发送消息 _send 的作用是给server发送消息。 def _send(self, req, stream=None): \"\"\" Sends the request and returns the response object. Streaming data response is transferred to the optional stream parameter. \"\"\" # Since all the addresses were vetted, use the first one. addr = list(self._addresses.values())[0][0] return self._send_one(addr, req, stream) ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_4/:4:3","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[4] -- 网络基础 \u0026 Driver","uri":"/posts/2022-10-08_horovod_4/"},{"categories":["Distributed Computing"],"content":"3.4 总结 我们可以看到，network.BasicService 会提供了一个server，这个 Service 都是通过 network.BasicClient 来访问。基于此，Horovod 的HorovodRunDriverService 和 HorovodRunTaskService 这两个类就可以互相交互，进行沟通。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_4/:4:4","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[4] -- 网络基础 \u0026 Driver","uri":"/posts/2022-10-08_horovod_4/"},{"categories":["Distributed Computing"],"content":"4 Driver 服务 Driver 服务由 HorovodRunDriverService 提供，其功能主要是维护维护各种 task 地址以及相应关系。具体各种 task 地址 就是 Task 服务 来注册的。 需要注意的是：HorovodRunDriverService 和 HorovodRunTaskService 都最终继承了 network.BasicService，他们之间可以是异地运行交互。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_4/:5:0","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[4] -- 网络基础 \u0026 Driver","uri":"/posts/2022-10-08_horovod_4/"},{"categories":["Distributed Computing"],"content":"4.1 HorovodRunDriverService HorovodRunDriverService 是对 BasicDriverService 的封装。 HorovodRunDriverClient 是 其 访问接口。 class HorovodRunDriverService(driver_service.BasicDriverService): NAME = 'horovod driver service' def __init__(self, num_hosts, key, nics): super(HorovodRunDriverService, self).__init__(num_hosts, HorovodRunDriverService.NAME, key, nics) class HorovodRunDriverClient(driver_service.BasicDriverClient): def __init__(self, driver_addresses, key, verbose, match_intf=False): super(HorovodRunDriverClient, self).__init__( HorovodRunDriverService.NAME, driver_addresses, key, verbose, match_intf=match_intf) ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_4/:5:1","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[4] -- 网络基础 \u0026 Driver","uri":"/posts/2022-10-08_horovod_4/"},{"categories":["Distributed Computing"],"content":"4.2 BasicDriverService BasicDriverService基类 主要就是 维护各种 task 地址以及相应关系。 class BasicDriverService(network.BasicService): def __init__(self, num_proc, name, key, nics): super(BasicDriverService, self).__init__(name, key, nics) self._num_proc = num_proc self._all_task_addresses = {} self._task_addresses_for_driver = {} self._task_addresses_for_tasks = {} self._task_index_host_hash = {} self._task_host_hash_indices = {} self._wait_cond = threading.Condition() 这里的各种 task 地址就是 Task 服务 注册到 Driver 的数值。 可以看到里面有各种关于地址的变量，为了让大家理解这些变量的作用，对于每一个变量我们举例如下（这里有些变量是专门为 spark 设计，都放到基类里面有点奇怪）： 4.2.1 _all_task_addresses 本变量是记录了所有 task 的地址，变量举例如下： self._all_task_addresses = { 1: { 'lo' : [('1.1.1.1', 12345)], 'eth0' : [('10.10.10.01', 12345)] }, 0: { 'lo' : [('2.2.2.2', 54321)], 'eth0' : [('10.10.10.02', 54321)] } } 本变量由 task 调用 RegisterTaskRequest 来注册。 if isinstance(req, RegisterTaskRequest): self._wait_cond.acquire() try: assert 0 \u003c= req.index \u003c self._num_proc self._all_task_addresses[req.index] = req.task_addresses 4.2.2 _task_addresses_for_driver 本变量是记录了所有 task 的地址，但是网卡接口有多种，这里选择与 本 driver 地址匹配的地址。 变量举例如下： self._task_addresses_for_driver = { 1: { 'eth0' : [('10.10.10.01', 12345)] }, 0: { 'eth0' : [('10.10.10.02', 54321)] } } 本变量由 task 调用 RegisterTaskRequest 来注册。 # Just use source address for service for fast probing. self._task_addresses_for_driver[req.index] = \\ self._filter_by_ip(req.task_addresses, client_address[0]) 具体使用举例如下： def task_addresses_for_driver(self, index): self._wait_cond.acquire() try: return self._task_addresses_for_driver[index].copy() finally: self._wait_cond.release() driver用这个地址来生成 其内部 task 变量。 tasks = [ task_service.HorovodRunTaskClient( index, driver.task_addresses_for_driver(index), settings.key, settings.verbose) for index in range( num_hosts)] 4.2.3 _task_addresses_for_tasks 该变量举例如下： self._task_addresses_for_tasks = { 1: { 'eth0' : [('10.10.10.01', 12345)] }, 0: { 'eth0' : [('10.10.10.02', 54321)] } } 本变量由RegisterTaskToTaskAddressesRequest注册。 if isinstance(req, RegisterTaskToTaskAddressesRequest): self.register_task_to_task_addresses(req.index, req.task_addresses) return network.AckResponse() def register_task_to_task_addresses(self, index, task_addresses): self._wait_cond.acquire() try: assert 0 \u003c= index \u003c self._num_proc self._task_addresses_for_tasks[index] = task_addresses # 这里赋值 finally: self._wait_cond.notify_all() self._wait_cond.release() 该变量被 task 用来获取 某个 task 的一套网络接口，比如： # Determine a set of common interfaces for task-to-task communication. nics = set(driver.task_addresses_for_tasks(0).keys()) 4.2.4 _task_index_host_hash 每一个 task 有一个对应的 host hash，该数值被 MPI 作为 host name 来操作。 self._task_index_host_hash = { 1: { 'ip-10-10-10-01-dfdsfdsfdsfdsf2' }, 0: { 'ip-10-10-10-02-treterwrtqwer' } } 具体使用如下。这个函数是 spark 相关会使用，具体是逐一通知 spark task 进入下一阶段。 def task_indices(self): self._wait_cond.acquire() try: return list(self._task_index_host_hash.keys()) finally: self._wait_cond.release() 或者使用如下，是为了获取某一个 host 对应的 host hash name。 def task_index_host_hash(self, index): self._wait_cond.acquire() try: assert 0 \u003c= index \u003c self._num_proc return self._task_index_host_hash[index] finally: self._wait_cond.release() 4.2.5 _task_host_hash_indices 该变量举例如下： self._task_host_hash_indices = { { 'ip-10-10-10-01-dfdsfdsfdsfdsf2' : [1] }, { 'ip-10-10-10-02-treterwrtqwer' : [0] } } 具体是在注册 RegisterTaskRequest 时候生成。 self._task_host_hash_indices[req.host_hash].append(req.index) 使用具体代码是： def task_host_hash_indices(self): self._wait_cond.acquire() try: return self._task_host_hash_indices.copy() finally: self._wait_cond.release() 具体是被 rsh 使用。rsh 就是在某一个 host 上，让某一个 horovod rank 启动。具体逻辑是： 获取某一个 host 上所有的 task indices ； 利用 task_host_hash_indices 取出本进程 local rank 对应的 task index； 取出在 driver 中 task index 对应保持的 task address； 最后依据这个 task addresses 生成一个 SparkTaskClient，进行后续操作。 driver_client = driver_service.SparkDriverClient(driver_addresses, key, verbose=verbose) task_indices = driver_client.task_host_hash_indices(host_hash) task_index = task_indices[local_rank] tas","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_4/:5:2","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[4] -- 网络基础 \u0026 Driver","uri":"/posts/2022-10-08_horovod_4/"},{"categories":["Distributed Computing"],"content":"4.3 总体逻辑 总体逻辑如下： network.BasicService ^ ^ | | +-------------------+ +-------------+ | | + + driver_service.BasicDriverService task_service.BasicTaskService ^ ^ | | | | | | | + +----------------+------------------+ HorovodRunTaskService | HorovodRunDriverService | | | | | | _all_task_addresses | | | | _task_addresses_for_driver | | | | _task_addresses_for_tasks | | | | _task_index_host_hash | | | | _task_host_hash_indices | | | +-----------------------------------+ ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_4/:5:3","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[4] -- 网络基础 \u0026 Driver","uri":"/posts/2022-10-08_horovod_4/"},{"categories":["Distributed Computing"],"content":"5 Task 服务 HorovodRunTaskService 提供了 Task 部分服务功能。整体逻辑是由几个函数共同完成。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_4/:6:0","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[4] -- 网络基础 \u0026 Driver","uri":"/posts/2022-10-08_horovod_4/"},{"categories":["Distributed Computing"],"content":"5.1 启动具体服务 _launch_task_servers 用来启动具体服务，其主要作用是：多线程运行，在每一个线程中，远程运行 horovod.runner.task_fn。 其中： 传入参数中，all_host_names 就是程序启动时候配置的所有host，比如 [“1.1.1.1”, “2.2.2.2”]； 使用了我们之前提到的 safe_shell_exec.execute 完成了安全运行保证； 使用我们前文提到的 get_remote_command 完成了远程命令的获取，即在命令之前加上了 ssh -o PasswordAuthentication=no -o StrictHostKeyChecking=no等等配置； 最终每个启动的命令举例如下： ssh -o PasswordAuthentication=no -o StrictHostKeyChecking=no 1.1.1.1 python -m horovod.runner.task_fn xxxxxxx； 使用 execute_function_multithreaded 在每一个 host 上运行，启动 task 服务； 具体代码如下： def _launch_task_servers(all_host_names, local_host_names, driver_addresses, settings): \"\"\" Executes the task server and service client task for registration on the hosts. :param all_host_names: list of addresses. for example, ['worker-0','worker-1'] ['10.11.11.11', '10.11.11.12'] :type all_host_names: list(string) :param local_host_names: names that are resolved to one of the addresses of local hosts interfaces. For example, set(['localhost', '127.0.0.1']) :type local_host_names: set :param driver_addresses: map of interfaces and their address and port for the service. For example: { 'lo': [('127.0.0.1', 34588)], 'docker0': [('172.122.10.1', 34588)], 'eth0': [('11.111.33.73', 34588)] } :type driver_addresses: map :param settings: the object that contains the setting for running horovod :type settings: horovod.runner.common.util.settings.Settings :return: :rtype: \"\"\" def _exec_command(command): host_output = io.StringIO() try: # 完成了安全运行保证 exit_code = safe_shell_exec.execute(command, stdout=host_output, stderr=host_output) finally: host_output.close() return exit_code args_list = [] num_hosts = len(all_host_names) for index in range(num_hosts): host_name = all_host_names[index] # all_host_names 就是程序启动时候配置的所有host，比如 [\"1.1.1.1\", \"2.2.2.2\"] command = \\ '{python} -m horovod.runner.task_fn {index} {num_hosts} ' \\ '{driver_addresses} {settings}' \\ .format(python=sys.executable, index=codec.dumps_base64(index), num_hosts=codec.dumps_base64(num_hosts), driver_addresses=codec.dumps_base64(driver_addresses), settings=codec.dumps_base64(settings)) if host_name not in local_host_names: # 完成了远程命令的获取，即在命令之前加上了 `ssh -o PasswordAuthentication=no -o StrictHostKeyChecking=no`等等配置 command = get_remote_command(command, host=host_name, port=settings.ssh_port, identity_file=settings.ssh_identity_file) args_list.append([command]) # Each thread will use ssh command to launch the server on one task. If an # error occurs in one thread, entire process will be terminated. Otherwise, # threads will keep running and ssh session -- and the the task server -- # will be bound to the thread. In case, the horovod process dies, all # the ssh sessions and all the task servers will die as well. # 使用 execute_function_multithreaded 在每一个 host 上运行，启动 task 服务 threads.execute_function_multithreaded(_exec_command, args_list, block_until_all_done=False) ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_4/:6:1","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[4] -- 网络基础 \u0026 Driver","uri":"/posts/2022-10-08_horovod_4/"},{"categories":["Distributed Computing"],"content":"5.2 具体服务逻辑 上段有：{python} -m horovod.runner.task_fn {index} {num_hosts} {driver_addresses} {settings}执行具体服务逻辑，所以我们介绍下 horovod.runner.task_fn。 _task_fn 函数完成了 生成了 HorovodRunTaskService 实例，赋值给 task； 使用 HorovodRunDriverClient . register_task 来向 Driver 服务注册task（自己）的地址； 使用 HorovodRunDriverClient . register_task_to_task_addresses 来向 Driver 服务注册自己在Ring上 下一个邻居的地址； 每一个 task 都做这个操作，最后就得到了在这个 ring cluster 之中的一个路由接口； 具体代码如下： def _task_fn(index, num_hosts, driver_addresses, settings): task = task_service.HorovodRunTaskService(index, settings.key, settings.nics) try: driver = driver_service.HorovodRunDriverClient( driver_addresses, settings.key, settings.verbose) # 向 Driver 服务注册task（自己）的地址 driver.register_task(index, task.addresses(), host_hash.host_hash()) task.wait_for_initial_registration(settings.start_timeout) # Tasks ping each other in a circular fashion to determine interfaces # reachable within the cluster. next_task_index = (index + 1) % num_hosts next_task_addresses = driver.all_task_addresses(next_task_index) # We request interface matching to weed out all the NAT'ed interfaces. next_task = task_service.HorovodRunTaskClient( next_task_index, next_task_addresses, settings.key, settings.verbose, match_intf=True, attempts=10) # 向 Driver 服务注册自己在Ring上 下一个邻居的地址 driver.register_task_to_task_addresses(next_task_index, next_task.addresses()) # Notify the next task that the address checks are completed. next_task.task_to_task_address_check_completed() # Wait to get a notification from previous task that its address checks # are completed as well. task.wait_for_task_to_task_address_check_finish_signal(settings.start_timeout) finally: task.shutdown() if __name__ == '__main__': index = codec.loads_base64(sys.argv[1]) num_hosts = codec.loads_base64(sys.argv[2]) driver_addresses = codec.loads_base64(sys.argv[3]) settings = codec.loads_base64(sys.argv[4]) _task_fn(index, num_hosts, driver_addresses, settings) ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_4/:6:2","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[4] -- 网络基础 \u0026 Driver","uri":"/posts/2022-10-08_horovod_4/"},{"categories":["Distributed Computing"],"content":"5.3 HorovodRunTaskService HorovodRunTaskService 主要的作用是提供了两个等待函数。因为具体路由操作是需要彼此通知，所以需要互相等待。 class HorovodRunTaskService(task_service.BasicTaskService): NAME_FORMAT = 'horovod task service #%d' def __init__(self, index, key, nics): super(HorovodRunTaskService, self).__init__( HorovodRunTaskService.NAME_FORMAT % index, index, key, nics) self.index = index self._task_to_task_address_check_completed = False def _handle(self, req, client_address): if isinstance(req, TaskToTaskAddressCheckFinishedSignal): self._wait_cond.acquire() try: self._task_to_task_address_check_completed = True finally: self._wait_cond.notify_all() self._wait_cond.release() return TaskToTaskAddressCheckFinishedSignalResponse(self.index) return super(HorovodRunTaskService, self)._handle(req, client_address) def wait_for_task_to_task_address_check_finish_signal(self, timeout): self._wait_cond.acquire() try: while not self._task_to_task_address_check_completed: self._wait_cond.wait(timeout.remaining()) timeout.check_time_out_for('Task to task address check') finally: self._wait_cond.release() class HorovodRunTaskClient(task_service.BasicTaskClient): def __init__(self, index, task_addresses, key, verbose, match_intf=False, attempts=3): super(HorovodRunTaskClient, self).__init__( HorovodRunTaskService.NAME_FORMAT % index, task_addresses, key, verbose, match_intf=match_intf, attempts=attempts) self.index = index def task_to_task_address_check_completed(self): resp = self._send(TaskToTaskAddressCheckFinishedSignal(self.index)) return resp.index 逻辑如下： _driver_fn + | | +---------------------------------------+-------------------------------------v | | | v | _launch_task_servers v + driver = HorovodRunDriverService | + +--------------+-------------------+ | | | | | | v v v +-------------------+---------------+ horovod.runner.task_fn ...... horovod.runner.task_fn | HorovodRunDriverService | + + | | | | | | | | | _all_task_addresses | | | | | v v | _task_addresses_for_driver | register_task +-----------+---------------+ +-------+--------------------+ | | | HorovodRunTaskService | | HorovodRunTaskService | | _task_addresses_for_tasks | \u003c--------------------------------+ | | | | | | | wait | | | _task_index_host_hash | | | \u003c------\u003e | | | | \u003c--------------------------------+ | | | | _task_host_hash_indices | register_task_to_task_addresses | | | | | | +---------------------------+ +----------------------------+ +-----------------------------------+ ` 图示: ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_4/:6:3","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[4] -- 网络基础 \u0026 Driver","uri":"/posts/2022-10-08_horovod_4/"},{"categories":["Distributed Computing"],"content":"6 总结 本文总结如下： 因为 Horovod 分布式训练 涉及到多个 hosts，所以如果要彼此访问，需要知道路由信息； 当所有 task 都启动，注册，probe 环中下一个worker 邻居完成 之后，DriverService 会得到路由信息（所有host之间的共有路由接口集合），返回给 Horovod 主体部分使用； network.BasicService 提供了网络服务功能； XXXService 都是通过 XXXClient作为接口才能访问； HorovodRunDriverService 和 HorovodRunTaskService 都最终继承了 network.BasicService，他们之间可以是异地运行交互。 HorovodRunTaskService 提供了 Task 部分服务功能，这些 task 需要注册到 Driver 之中（和Spark思路类似）。 HorovodRunDriverService 是对 BasicDriverService 的封装。BasicDriverService 就是 维护各种 task 地址以及相应关系，比如： _all_task_addresses ：记录了所有 task 的地址； _task_addresses_for_driver ：记录了所有 task 的地址，但是因为网卡接口有多种，这里选择与 本driver 地址匹配的地址； _task_addresses_for_tasks ：用来给某一个 task 分配一个地址，同时获取本 task 的一套网络接口； _task_index_host_hash ：每一个 task 有一个对应的 host hash。这个函数是 spark 相关会使用，具体是逐一通知 spark task 进入下一阶段。或者是为了获取某一个 host 对应的 host hash name； _task_host_hash_indices ：具体是被 rsh 使用，由 rank 得到 在 driver 中 task index 对应保持的 task address； SparkDriverService，SparkTaskService，ElasticDriver, Worker 都有什么区别和联系？ HorovodRunDriverService 这里只是用来得到路由信息，记录各种 Task 地址； SparkDriverService 除了记录路由和地址之外，还提交执行任务（Command），因为具体在哪一个Spark Executor启动之后，SparkDriverService 就需要知道 对应 SparkTaskService 的地址，这样才能知道提交到哪里； SparkTaskService 负责执行命令（抛弃了Spark Executor的逻辑，自己搞了一套），就是从 SparkDriverService 那里获得训练函数，然后启动 python 进程来执行； ElasticDriver 做得更多，因为还有弹性，需要容错； references: [1]. https://www.cnblogs.com/rossiXYZ/p/14882053.html [2]. https://www.zhihu.com/column/c_1491039346714746880 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_4/:7:0","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[4] -- 网络基础 \u0026 Driver","uri":"/posts/2022-10-08_horovod_4/"},{"categories":["Distributed Computing"],"content":"references: [1]. https://www.cnblogs.com/rossiXYZ/p/14881812.html ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:0:0","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"0 摘要 Horovod 是Uber于2017年发布的一个易于使用的高性能的分布式训练框架，在业界得到了广泛应用。 本系列将通过源码分析来带领大家了解 Horovod。本文是系列第三篇，从 python 开始进入 Horovod 世界，看看 Horovodrun 做了什么。 前两篇链接如下： 深度学习分布式训练框架 Horovod (1) — 基础知识 深度学习分布式训练框架 horovod (2) — 从使用者角度切入 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:1:0","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"1 背景知识 首先介绍一些相关背景知识。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:2:0","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"1.1 分布式体系 在设计并行计算机时，最直接的方式就是多个计算单元共享一个内存。共享内存的编程在数据交换和访问上有较大的优势，程序编写起来更加简单。但在扩展性上有较大的瓶颈。 另一种方式为分布式内存。即每个计算单元有单独的内存，计算单元之间的数据访问通过互联网络去传输。这一架构在可移植性和扩展上会强很多，但消息的传递会成为程序设计中的难点。 将这两点结合，即是分布式共享内存并行计算机的架构，也是当今最常用的体系结构。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:2:1","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"1.2 并行任务通信 并行任务通信一般分为P2P(Point-to-point communication)和 Collective communication。 P2P通信这种模式只有一个sender和一个receiver，即点到点通信. Collective communication含多个sender多个receive Collective communication包含一些常见的原语 broadcast reduce，allreduce scatter，scatter reduce gather，allgather ring-base collectives ring-allreduce 传统Collective communication假设通信节点组成的topology是一颗fat tree，这样通信效率最高。但实际的通信topology可能比较复杂，并不是一个fat tree。因此一般用ring-based Collective communication。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:2:2","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"1.3 MPI MPI(Message Passing Interface) 是一种可以支持点对点和广播的通信协议，具体实现的库有很多，使用比较流行的包括 Open Mpi， Intel MPI 等等。 MPI 是一种消息传递编程模型。消息传递指用户必须通过显式地发送和接收消息来实现处理器间的数据交换。在这种并行编程中，每个控制流均有自己独立的地址空间，不同的控制流之间不能直接访问彼此的地址空间，必须通过显式的消息传递来实现。这种编程方式是大规模并行处理机(MPP)和机群(Cluster)采用的主要编程方式。由于消息传递程序设计要求用户很好地分解问题，组织不同控制流间的数据交换，并行计算粒度大，特别适合于大规模可扩展并行算法。 MPI 是基于进程的并行环境。进程拥有独立的虚拟地址空间和处理器调度，并且执行相互独立。MPI 设计为支持通过网络连接的机群系统，且通过消息传递来实现通信，消息传递是 MPI 的最基本特色。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:2:3","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"1.4 Open-MPI OpenMPI 是一种高性能消息传递库，最初是作为融合的技术和资源从其他几个项目（FT-MPI， LA-MPI， LAM/MPI， 以及 PACX-MPI），它是 MPI-2 标准的一个开源实现，由一些科研机构和企业一起开发和维护。因此，OpenMPI 能够从高性能社区中获得专业技术、工业技术和资源支持，来创建最好的 MPI 库。OpenMPI 提供给系统和软件供应商、程序开发者和研究人员很多便利。易于使用，并运行本身在各种各样的操作系统，网络互连，以及一批/调度系统。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:2:4","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"1.5 MPI 使用问题 因为MPI是分布式内存编程，在后面的开发中涉及节点间信息的传递。往往数据和程序是在多个节点上，所以需要保证执行命令时各节点之间信息的交换。 具体使用之中，就有两个问题: 这个多台机器Open-MPI是如何发现并建立连接的呢？ 多机多卡在训练过程中，传输环如何建立，这个也是决定了训练效率，那么Open-MPI如何去做呢？ 关于第一个问题： 设置SSH免密登录可以免去操作中密码的输入。各节点生成私钥和公钥后需要认证，此时可以保证本机免密登录。将各个子节点的公钥文件发送给主节点，然后分别加入到主节点的认证文件中，此时可以保证主节点对各个子节点的免密登录。最后将认证文件传回到每个子节点，从而保证各个子节点对其他节点之间的免密登录。 在 Open-MPI 启动的时候，可以指定--hostfile或者--host去指定要运行任务的 IP 或 Hostname，这样 Open-MPI 就会试图通过 ssh 免秘钥的方式试图去链接对方机器，并执行一系列命令，主要是为了同步环境变量、当前路径以及下发启动命令。 当然用户也可以通过其他方式给远程机器下发命令，这个可以通过环境变量OMPI_MCA_plm_rsh_agent指定。 关于第二个问题： 当所有的机器建立好连接，准备开始计算，为了能够最高效的去通信，Open-MPI中集成了组件——hwloc。该组件主要是为了单机硬件资源拓扑构建，进而构建最短路径通信。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:2:5","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"2 入口点 很多机器学习框架都会采用如下套路：shell脚本（可选），python端 和 C++端。 Shell脚本是启动运行的入口，负责解析参数，确认并且调用训练程序； Python是用户的接口，引入了C++库，封装了API，负责运行时和底层C++交互； C++实现底层训练逻辑； 以我们先看看 hordovodrun 脚本。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:3:0","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"2.1 如何运行 官方给出的 Hovorod 运行范例之一如下： horovodrun -np 2 -H localhost:4 --gloo python /horovod/examples/tensorflow2/tensorflow2_mnist.py 这里 -np 指的是进程的数量，localhost:4表示localhost节点上4个GPU。 注意，如果虚拟机只有一个核。想要强行地达到并行的效果，可以使用 -np参数，它会自动帮你把一个核心切成多份处理器，每一个分布式处理就是一个slot。 因此，我们可以从 horovodrun 这个命令入手看看。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:3:1","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"2.2 horovodrun 入口文件可以从 setup.py 看到，其就被映射成 horovod.runner.launch:run_commandline。 entry_points={ 'console_scripts': [ 'horovodrun = horovod.runner.launch:run_commandline' ] } 所以我们看看 run_commandline ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:3:2","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"2.3 run_commandline 该命令位于：horovod-master/horovod/runner/launch.py，我们摘录重要部分。 def run_commandline(): args = parse_args() _run(args) 于是进入到 _run 函数。可以看到，Horovod 会依据是否是弹性训练来选择不同的路径。我们在此系列中，会首先分析 非弹性训练 _run_static。 def _run(args): # if hosts are not specified, either parse from hostfile, or default as # localhost if not args.hosts and not args.host_discovery_script: if args.hostfile: args.hosts = hosts.parse_host_files(args.hostfile) else: # Set hosts to localhost if not specified args.hosts = 'localhost:{np}'.format(np=args.np) # Convert nics into set args.nics = set(args.nics.split(',')) if args.nics else None if _is_elastic(args): return _run_elastic(args) else: return _run_static(args) # 我们先看这里 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:3:3","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"2.4 非弹性训练 _run_static() 在 _run_static 之中做了如下操作： 首先解析各种参数，得到 settings； 会调用 driver_service.get_common_interfaces 获取网卡以及其他host的信息，依据这些信息会进行slot分配，这部分很复杂，具体我们会有专文讲解（下一篇）。 这里有一个问题：为什么要得到 host, slot, rank 之间的关系信息？由于工程上的考虑，底层 C++ 世界中对于 rank 的角色做了区分：rank 0 是 master，rank n 是 worker，所以这些信息需要决定并且传递给 C++世界； 会根据是否在参数中传递运行函数来决定采取何种路径，一般默认没有运行参数，所以会执行_launch_job 来启动训练 job； 具体代码如下： def _run_static(args): settings = hvd_settings.Settings(verbose=2 if args.verbose else 0, ssh_port=args.ssh_port, ssh_identity_file=args.ssh_identity_file, extra_mpi_args=args.mpi_args, tcp_flag=args.tcp_flag, binding_args=args.binding_args, key=secret.make_secret_key(), start_timeout=tmout, num_proc=args.np, hosts=args.hosts, output_filename=args.output_filename, run_func_mode=args.run_func is not None, nics=args.nics,...) # 首先解析各种参数，得到 settings fn_cache = None if not args.disable_cache: params = '' if args.np: params += str(args.np) + ' ' if args.hosts: params += str(args.hosts) + ' ' if args.ssh_port: params += str(args.ssh_port) if args.ssh_identity_file: params += args.ssh_identity_file parameters_hash = hashlib.md5(params.encode('utf-8')).hexdigest() fn_cache = cache.Cache(CACHE_FOLDER, CACHE_STALENESS_THRESHOLD_MINUTES, parameters_hash) # 获取网卡以及其他host的信息，依据这些信息会进行slot分配 all_host_names, _ = hosts.parse_hosts_and_slots(args.hosts) remote_host_names = network.filter_local_addresses(all_host_names) nics = driver_service.get_common_interfaces(settings, all_host_names, remote_host_names, fn_cache) if args.run_func: # get the driver IPv4 address driver_ip = network.get_driver_ip(nics) run_func_server = KVStoreServer(verbose=settings.verbose) # 启动内部KV服务器 run_func_server_port = run_func_server.start_server() put_data_into_kvstore(driver_ip, run_func_server_port, 'runfunc', 'func', args.run_func) # 把'func', args.run_func存储成KV command = [sys.executable, '-m', 'horovod.runner.run_task', str(driver_ip), str(run_func_server_port)] try: _launch_job(args, settings, nics, command) results = [None] * args.np for i in range(args.np): results[i] = read_data_from_kvstore(driver_ip, run_func_server_port,'runfunc_result', str(i)) return results finally: run_func_server.shutdown_server() else: command = args.command _launch_job(args, settings, nics, command) # 我们重点讲解这里 return None 目前逻辑如下： +-----------+ |horovodrun | +-----+-----+ | | v +--------+--------+ | run_commandline | +----+------+-----+ | | +---------+ +--------+ | | | | v v +-----+--------+ +----+--------+ | _run_elastic | | _run_static | | | | | +--------------+ +-------------+ 至此，我们已经分析完成 horovod 的入口，下面会分析具体如何启动 Job。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:3:4","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"3 运行训练 Job ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:4:0","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"3.1 _launch_job _launch_job 会根据配置或者安装情况来进行具体调用。我们看到有三种可能：gloo, mpi, js。 jsrun的资料很难找，所以我们重点看看 gloo, mpi 这两种。 def _launch_job(args, settings, nics, command): env = os.environ.copy() config_parser.set_env_from_args(env, args) def gloo_run_fn(): driver_ip = network.get_driver_ip(nics) gloo_run(settings, nics, env, driver_ip, command) def mpi_run_fn(): mpi_run(settings, nics, env, command) def js_run_fn(): js_run(settings, nics, env, command) run_controller(args.use_gloo, gloo_run_fn, args.use_mpi, mpi_run_fn, args.use_jsrun, js_run_fn, args.verbose) ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:4:1","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"3.2 run_controller run_controller 依然是一个中介函数，具体导入 gloo 或者 mpi。 def run_controller(use_gloo, gloo_run, use_mpi, mpi_run, use_jsrun, js_run, verbosity): if use_gloo: gloo_run() elif use_mpi: mpi_run() elif use_jsrun: js_run() else: if mpi_built(verbose=verbose): if lsf.LSFUtils.using_lsf() and is_jsrun_installed(): js_run() else: mpi_run() elif gloo_built(verbose=verbose): gloo_run() 目前逻辑如下： +-----------+ |horovodrun | +-----+-----+ | | v +--------+--------+ | run_commandline | +----+------+-----+ | | +---------+ +--------+ | | | | v v +-----+--------+ +----+--------+ | _run_elastic | | _run_static | | | | | +--------------+ +------+------+ | | v +------+------+ | _launch_job | | | +------+------+ | | v +---------+--------+ | run_controller | | | +----+----+-----+--+ | | | +-------------+ | +--------+ | | | | | | v v v +------+---+ +------+----+ +---+-----+ | gloo_run | | mpi_run | | js_run | | | | | | | +----------+ +-----------+ +---------+ 于是我们下面就分为两个分支介绍：gloo \u0026 mpi。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:4:2","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"4 Gloo 实现 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:5:0","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"4.1 Gloo 简介 Gloo 是 facebook出品的一个类似MPI的集合通信库（https://github.com/facebookincubator/gloo）。 集合通信库的主要特征是：大体上会遵照 MPI 提供的接口规定，实现了包括点对点通信（SEND,RECV等），集合通信（ REDUCE，BROADCAST，ALLREDUCE等）等相关接口，然后根据自己硬件或者是系统的需要，在底层实现上进行相应改动，保证接口的稳定和性能。 Gloo 为CPU和GPU提供了集合通信程序的优化实现。 它特别适用于GPU，因为它可以执行通信而无需使用GPUDirect 将数据传输到CPU的内存。 它还能够使用 NCCL 执行快速的节点内通信，并实现其自己的节点间例程计算。你不需要考虑内存数据的拷贝，只需要实现逻辑就可以。 Gloo 支持集合通信（collective Communication），并对其进行了优化。由于 GPU 之间可以直接进行数据交换，而无需经过 CPU 和内存，因此，在 GPU 上使用 gloo后端速度更快。 Horovod 为什么会选择 Gloo？个人认为除了其功能的全面性和性能之外，基于它可以二次开发是一个亮点，比如下面我们所说的 Rendezvous 功能就被 Horovod 用来实现弹性训练（我们后文有专门讲解）。 Gloo 和 MPI 都起到了同样类似作用： 一方面Horovod内集成了基于 Gloo 的AllReduce，类似于NCCL，都是用作梯度规约； 另一方面，Gloo 可以用来启动多个进程（Hovorod里用Rank表示），实现并行计算； 具体如下： +-----------------------+ +-----------------------+ +------------------------+ | gloo_run slot 1 | | gloo_run slot 2 | | gloo_run slot 3 | | | | | | | | +-------------------+ | | +------------------+ | | +------------------+ | | | python train.py | | | | python train.py | | | | python train.py | | +----+ +\u003c------+ +\u003c------+ +\u003c------+ | | | | | | | | | | | | | | | | +-------------------+ | | +------------------+ | | +------------------+ | | | | | | | | | | | +-----------------------+ +-----------------------+ +------------------------+ | | | | | | | v--------------------------------------------------------------------------------------\u003e Ring Allreduce on Gloo ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:5:1","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"4.2 Rendezvous 功能 4.2.1 Rendezvous 概念 在 Gloo 的文档中，如此说: The rendezvous process needs to happen exactly once per Gloo context. It makes participating Gloo processes exchange details for setting up their communication channels. For example, when the TCP transport is used, processes exchange IP address and port number details of listening sockets. Rendezvous can be executed by accessing a key/value store that is accessible by all participating processes. Every process is responsible for setting a number of keys and will wait until their peers have set their keys. The values stored against these keys hold the information that is passed to the transport layer. 大致意思是： Gloo 在每一个 Gloo context 之中有一个 rendezvous process，Gloo 利用它来交换通讯需要的细节。 Rendezvous 具体实现是可以依靠访问一个 KVstore 来完成。具体细节就是通过 KVstore 来进行交互。 以 Horovod 为例： Horovod 在进行容错 AllReduce 训练时，除了启动 worker 进程外，还会启动一个driver 进程。这个 driver 进程用于帮助 worker 调用 gloo 构造 AllReduce 通信环。 driver 进程中会创建一个带有 KVStore 的 RendezvousServer，driver 会将参与通信的 worker 的 ip 等信息存入 KVstore 中。 然后 worker 就可以调用 gloo 来访问 RendezvousServer 构造通信环了。 4.2.2 RendezvousServer 具体代码如下，可以看到是启动了RendezvousHTTPServer(就是继承拓展了 HTTPServer): class RendezvousServer: def __init__(self, verbose=0): self._httpd = None self._listen_thread = None self._verbose = verbose # Rendezvous function finds a available port, create http socket, # and start listening loop to handle request # self.httpd.init needs to be called after server start def start(self, handler_cls=RendezvousHandler): # 下面马上介绍 self._httpd, port = find_port( lambda addr: RendezvousHTTPServer( addr, handler_cls, self._verbose)) # start the listening loop self._listen_thread = in_thread(target=self._httpd.serve_forever) return port def init(self, host_alloc_plan): self._httpd.init(host_alloc_plan) def stop(self): self._httpd.shutdown() self._listen_thread.join() 4.2.3 KVStore KVStore 是由 KVStoreHandler 来体现，RendezvousHandler 继承了 KVStoreHandler，进而被 RendezvousServer 作为 handler 使用。 KVStoreHandler 精简版代码如下： class KVStoreHandler(SimpleHTTPRequestHandler): # Override PUT handler def do_PUT(self): paths = self.path.split('/') _, scope, key = paths # Get body length content_length = int(self.headers['Content-Length']) value = self.rfile.read(content_length) self._put_value(scope, key, value) self.send_status_code(OK) def _put_value(self, scope, key, value): with self.server.cache_lock: scope_dict = self.server.cache.setdefault(scope, {}) scope_dict[key] = value 4.2.4 底层使用 Rendezvous 具体如何使用？简要的说： Python世界构建了一个 RendezvousServer，其地址配置在环境变量（或者其他方式）中。 在 C++ 世界中，比如 horovod/common/gloo/gloo_context.h，horovod/common/gloo/gloo_context.cc 之中有使用。即得到 Python 配置的 RendezvousServer 的地址端口等，然后构建 gloo 所需的 context。 #define HOROVOD_HOSTNAME \"HOROVOD_HOSTNAME\" #define HOROVOD_RANK \"HOROVOD_RANK\" #define HOROVOD_SIZE \"HOROVOD_SIZE\" #define HOROVOD_LOCAL_RANK \"HOROVOD_LOCAL_RANK\" #define HOROVOD_LOCAL_SIZE \"HOROVOD_LOCAL_SIZE\" #define HOROVOD_CROSS_RANK \"HOROVOD_CROSS_RANK\" #define HOROVOD_CROSS_SIZE \"HOROVOD_CROSS_SIZE\" #define HOROVOD_ELASTIC \"HOROVOD_ELASTIC\" ctx = Rendezvous(HOROVOD_GLOO_GLOBAL_PREFIX, rendezvous_addr_env, rendezvous_port, rank, size, dev, timeout); local_ctx = Rendezvous(HOROVOD_GLOO_LOCAL_PREFIX + hostname, rendezvous_addr_env, rendezvous_port, local_rank, local_size, dev, timeout); cross_ctx = Rendezvous(HOROVOD_GLOO_CROSS_PREFIX + std::to_string(local_rank), rendezvous_addr_env, rendezvous_port, cross_rank, cross_size, dev, timeout); 逻辑如下，C++世界会从python世界的获取到RendezvousServer的 IP，port： +---------------------\u003e System Env +------------------+ | addr, port, ... addr, port, ... | | + | | | | | | | | | | | | | | | | | Python | C++ | | | | | | | | | | | | v +---------+---------------+ | +------------+--------+ | RendezvousServer | | |GlooContext | | | | | | | | | | | | | | | | | RendezvousHandler | | | Rendezvous | | | | | | +-------------------------+ | +---------------------+ | + ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:5:2","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"4.3 Horovd 的 gloo 入口 gloo_run 是 horovod 之中，gloo 模块的 相关入口。 注释说的很清楚：每一个 thread 将使用 ssh 命令在远程host之上启动训练job。 def gloo_run(settings, nics, env, server_ip, command): # Each thread will use ssh command to launch the job on each remote host. If an # error occurs in one thread, entire process will be terminated. Otherwise, # threads will keep running and ssh session. exec_command = _exec_command_fn(settings) launch_gloo(command, exec_command, settings, nics, env, server_ip) 就是用 launch_gloo 来运行 exec_command。 此时 command 参数类似 \"['python', 'train.py']\"。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:5:3","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"4.4 构建可执行环境 gloo_run 的第一部分是 exec_command = _exec_command_fn(settings)，就是基于各种配置来生成可以执行命令环境。如果是远程，就得生成相关远程可运行命令环境（包括切换目录，远程执行等等）。 4.4.1 _exec_command_fn 具体又可以分为两部分： 利用 get_remote_command 来生成相关远程可运行环境，比如在训练脚本前面加上 'ssh -o PasswordAuthentication=no -o StrictHostKeyChecking=no'； 调整输入输出，利用 safe_shell_exec.execute 来实现安全执行能力； 具体如下： def _exec_command_fn(settings): \"\"\" executes the jobs defined by run command on hosts. :param hosts_alloc: list of dict indicating the allocating info. For example, [{'Hostname':'worker-0', 'Rank': 0, 'Local_rank': 0, 'Cross_rank':0, 'Size':2, 'Local_size':1, 'Cross_size':2}, {'Hostname':'worker-1', 'Rank': 1, 'Local_rank': 0, 'Cross_rank':1, 'Size':2, 'Local_size':1, 'Cross_size':2} ] :type hosts_alloc: list(dict) :param remote_host_names: names that are resolved to one of the addresses of remote hosts interfaces. :param _run_command: command to execute \"\"\" def _exec_command(command, slot_info, events): index = slot_info.rank host_name = slot_info.hostname host_address = network.resolve_host_address(host_name) local_addresses = network.get_local_host_addresses() # 需要构建远程命令 if host_address not in local_addresses: local_command = quote('cd {pwd} \u003e /dev/null 2\u003e\u00261 ; {command}' .format(pwd=os.getcwd(), command=command)) command = get_remote_command(local_command, host=host_name, port=settings.ssh_port, identity_file=settings.ssh_identity_file) # Redirect output if requested # 调整输入输出，利用 safe_shell_exec.execute 来实现安全执行能力 stdout = stderr = None stdout_file = stderr_file = None if settings.output_filename: padded_rank = _pad_rank(index, settings.num_proc) output_dir_rank = os.path.join(settings.output_filename, 'rank.{rank}'.format(rank=padded_rank)) if not os.path.exists(output_dir_rank): os.mkdir(output_dir_rank) stdout_file = open(os.path.join(output_dir_rank, 'stdout'), 'w') stderr_file = open(os.path.join(output_dir_rank, 'stderr'), 'w') stdout = MultiFile([sys.stdout, stdout_file]) stderr = MultiFile([sys.stderr, stderr_file]) # 实现安全执行能力 exit_code = safe_shell_exec.execute(command, index=index, stdout=stdout, stderr=stderr, events=events,...) return exit_code, time.time() return _exec_command 4.4.2 get_remote_command 本函数是针对远程 host，获取如何在其上运行的方式。这个函数是比较新加入的，具体和 kubeflow mpi operator 也相关，以后有机会再分析。 SSH_COMMAND_PREFIX = 'ssh -o PasswordAuthentication=no -o StrictHostKeyChecking=no' def get_ssh_command(local_command, host, port=None, identity_file=None, timeout_s=None): port_arg = f'-p {port}' if port is not None else '' identity_file_arg = f'-i {identity_file}' if identity_file is not None else '' timeout_arg = f'-o ConnectTimeout={timeout_s}' if timeout_s is not None else '' return f'{SSH_COMMAND_PREFIX} {host} {port_arg} {identity_file_arg} {timeout_arg} {local_command}' def get_remote_command(local_command, host, port=None, identity_file=None, timeout_s=None): return f'{env_util.KUBEFLOW_MPI_EXEC} {host} {local_command}' if env_util.is_kubeflow_mpi() \\ else get_ssh_command(local_command, host, port, identity_file, timeout_s) 大致逻辑如下： command : python train.py + | | v +---------+-------------+ | | | get_remote_command | | | +---------+-------------+ | | v ssh -o ... python train.py + | | | v +---------+--------------+ |safe_shell_exec.execute | | | +------------------------+ ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:5:4","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"4.5 使用 gloo 执行命令 获取到了可执行环境 exec_command 与 执行命令 command 之后，就可以使用 gloo 来执行命令了。 每个 command 都是被 exec_command 来执行。 launch_gloo 来获取命令，各种配置信息，网卡信息（nics，比如 {’lo’}），host信息等，然后开始运行，就是开始运行我们的训练代码了，具体是： 建立 RendezvousServer，这个会被底层 Gloo C++ 环境使用到; host_alloc_plan = get_host_assignments 来根据host进行分配slot，就是horovod的哪个rank应该在哪个host上的哪个slot之上运行； get_run_command 获取到可执行命令； slot_info_to_command_fn 来得到在slot之上可执行的 slot command； 依据 slot_info_to_command_fn 构建 args_list，这个 list 之中，每一个arg就是一个 slot command； 多线程执行，在每一个 exec_command 之上执行每一个 arg（slot command）； 代码如下： def launch_gloo(command, exec_command, settings, nics, env, server_ip): \"\"\" Launches the given command multiple times using gloo. Each command is launched via exec_command. :param command: command to launch :param exec_command: means to execute a single command :param settings: settings for the distribution :param nics: common interfaces :param env: environment to use :param server_ip: ip to use for rendezvous server \"\"\" # Make the output directory if it does not exist if settings.output_filename: _mkdir_p(settings.output_filename) # start global rendezvous server and get port that it is listening on # 建立 RendezvousServer，这个会被底层 Gloo C++ 环境使用到 rendezvous = RendezvousServer(settings.verbose) # allocate processes into slots # 来根据host进行分配slot，就是horovod的哪个rank应该在哪个host上的哪个slot之上运行 hosts = parse_hosts(settings.hosts) host_alloc_plan = get_host_assignments(hosts, settings.num_proc) # start global rendezvous server and get port that it is listening on global_rendezv_port = rendezvous.start() rendezvous.init(host_alloc_plan) # 获取到可执行命令 run_command = get_run_command(command, server_ip, nics, global_rendezv_port) # 得到在slot之上可执行的 slot command slot_info_to_command = _slot_info_to_command_fn(run_command, env) event = register_shutdown_event() # 依据 slot_info_to_command_fn 构建 args_list，这个 list 之中，每一个arg就是一个 slot command args_list = [[slot_info_to_command(slot_info), slot_info, [event]] for slot_info in host_alloc_plan] # If an error occurs in one thread, entire process will be terminated. # Otherwise, threads will keep running. # 多线程执行，在每一个 exec_command 之上执行每一个 arg（slot command） res = threads.execute_function_multithreaded(exec_command, args_list, block_until_all_done=True) for name, value in sorted(res.items(), key=lambda item: item[1][1]): exit_code, timestamp = value 具体 HostInfo.from_string 信息如下： class HostInfo: def __init__(self, hostname, slots): self.hostname = hostname self.slots = slots @staticmethod def from_string(host_string): hostname, slots = host_string.strip().split(':') return HostInfo(hostname, int(slots)) 4.5.1.2 分配方案 get_host_assignments 会依据 host 和 process capacities (slots) 来给 Horovod 之中的进程分配，即给出一个 horovod rank 和 slot 的对应关系。设置了几个 np，就有几个 slot。 给出的分配方案类似如下，这样就知道了哪个rank对应于哪个host上的哪个slot： [ SlotInfo(hostname='h1', rank=0, local_rank=0, cross_rank=0, size=2, local_size=2, coress_size=1), SlotInfo(hostname='h2', rank=1, local_rank=0, cross_rank=0, size=2, local_size=2, coress_size=1), ] def get_host_assignments(hosts, min_np, max_np=None): \"\"\"Assign hosts with process capacities (slots) to ranks in the Horovod process. This function will try to allocate as many as possible processes on the same host to leverage local network. :param hosts: list of HostInfo objects describing host and slot capacity :type hosts: list[HostInfo] :param min_np: minimum number of processes to be allocated :param max_np: (optional) maximum number of processes to be allocated :return: a list of the allocation of process on hosts in a `SlotInfo` object. :rtype: list[SlotInfo] \"\"\" host_ranks = [] cross_ranks = collections.defaultdict(dict) rank = 0 # 依据 hosts 信息构建 rank, local rank, cross rank(hierarchical allreduce所需要) for host_info in hosts: ranks = [] for local_rank in range(host_info.slots): if rank == max_np: break ranks.append(rank) rank += 1 cross_ranks_at_local = cross_ranks[local_rank] cross_ranks_at_local[host_info.hostname] = len(cross_ranks_at_local) host_ranks.append((host_info, ranks)) world_size = rank # 给出一个 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:5:5","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"4.6 C++举例 我们给出一个底层代码，大家就进一步了解 Gloo 可以起到什么作用。 这个就是 Horovod 之中，rank 0 最终给其他 rank 发送构建好的 Tensor。 void GlooController::SendFinalTensors(ResponseList\u0026 response_list) { // Notify all nodes which tensors we'd like to reduce at this step. std::string encoded_response; ResponseList::SerializeToString(response_list, encoded_response); // Boardcast the response length int encoded_response_length = (int)encoded_response.length() + 1; { gloo::BroadcastOptions opts(gloo_context_.ctx); opts.setOutput(\u0026encoded_response_length, 1); opts.setRoot(RANK_ZERO); gloo::broadcast(opts); // 广播给其他rank } // Boardcast the response { gloo::BroadcastOptions opts(gloo_context_.ctx); opts.setOutput((uint8_t*)(encoded_response.c_str()), encoded_response_length); opts.setRoot(RANK_ZERO); gloo::broadcast(opts); // 广播给其他rank } } ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:5:6","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"5 Mpi 实现 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:6:0","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"5.1 openmpi 库 horovod 这里主要依赖 openmpi。 MPI：英文全称是Message Passing Interface，MPI是一个跨语言的通讯协议，用于编写并行计算机。支持点对点和广播。MPI是一个信息传递应用程序接口，包括协议和和语义说明，他们指明其如何在各种实现中发挥其特性。MPI的目标是高性能，大规模性，和可移植性。 openMPI：英文全称是open Message Passing Interface。openMPI是MPI的一种实现，一种库项目。 MPI在Hovorod的角色比较特殊： 一方面Horovod内集成了基于MPI的AllReduce，类似于NCCL，都是用作梯度规约； 另一方面，MPI可以用来在所有机器上启动多个进程(Hovorod里用Rank表示)，实现并行计算； ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:6:1","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"5.2 mpi_run 函数 此部分代码位于：horovod/runner/mpi_run.py。 首先摘录其关键代码如下，可以看出来其核心是运行 mpirun 命令。 # 我是下面大段代码中的关键代码！ mpirun_command = ( 'mpirun {basic_args} ' '-np {num_proc}{ppn_arg}{hosts_arg} ' '{binding_args} ' '{mpi_args} ' '{mpi_ssh_args} ' '{tcp_intf_arg} ' '{nccl_socket_intf_arg} ' '{output_filename_arg} ' '{env} {extra_mpi_args} {command}' .format(basic_args=basic_args, num_proc=settings.num_proc, ppn_arg=ppn_arg, hosts_arg=hosts_arg, binding_args=binding_args, mpi_args=' '.join(mpi_impl_flags), tcp_intf_arg=tcp_intf_arg, nccl_socket_intf_arg=nccl_socket_intf_arg, mpi_ssh_args=mpi_ssh_args, output_filename_arg=' '.join(output), env=env_list, extra_mpi_args=settings.extra_mpi_args if settings.extra_mpi_args else '', command=' '.join(quote(par) for par in command)) ) # Execute the mpirun command. if settings.run_func_mode: exit_code = safe_shell_exec.execute(mpirun_command, env=env, stdout=stdout, stderr=stderr) else: os.execve('/bin/sh', ['/bin/sh', '-c', mpirun_command], env) 就是依据各种配置以及参数来构建 mpirun 命令的所有参数，比如 ssh 的参数，mpi 参数，nccl 参数等等。 最后得到的 mpirun 命令举例如下： mpirun --allow-run-as-root --np 2 -bind-to none -map-by slot \\ -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH \\ -mca pml ob1 -mca btl ^openib \\ python train.py 具体代码如下，具体是： # 上面代码是我之中的片段 def mpi_run(settings, nics, env, command, stdout=None, stderr=None): \"\"\" Runs mpi_run. Args: settings: Settings for running MPI. Note: settings.num_proc and settings.hosts must not be None. nics: Interfaces to include by MPI. env: Environment dictionary to use for running command. command: Command and arguments to run as a list of string. stdout: Stdout of the mpi process. Only used when settings.run_func_mode is True. stderr: Stderr of the mpi process. Only used when settings.run_func_mode is True. \"\"\" # 得到各种配置 mpi_impl_flags, impl_binding_args, mpi = _get_mpi_implementation_flags(settings.tcp_flag, env=env) impi = _IMPI_IMPL == mpi # 处理ssh参数 ssh_args = [] if settings.ssh_port: ssh_args += [f'-p {settings.ssh_port}'] if settings.ssh_identity_file: ssh_args += [f'-i {settings.ssh_identity_file}'] mpi_ssh_args = '' if ssh_args: joined_ssh_args = ' '.join(ssh_args) mpi_ssh_args = f'-bootstrap=ssh -bootstrap-exec-args \\\"{joined_ssh_args}\\\"' if impi else f'-mca plm_rsh_args \\\"{joined_ssh_args}\\\"' # 处理网络配置，网卡信息等 tcp_intf_arg = '-mca btl_tcp_if_include {nics}'.format( nics=','.join(nics)) if nics and not impi else '' nccl_socket_intf_arg = '-{opt} NCCL_SOCKET_IFNAME={nics}'.format( opt='genv' if impi else 'x', nics=','.join(nics)) if nics else '' # 处理host信息 # On large cluster runs (e.g. Summit), we need extra settings to work around OpenMPI issues host_names, host_to_slots = hosts.parse_hosts_and_slots(settings.hosts) if not impi and host_names and len(host_names) \u003e= _LARGE_CLUSTER_THRESHOLD: mpi_impl_flags.append('-mca plm_rsh_no_tree_spawn true') mpi_impl_flags.append('-mca plm_rsh_num_concurrent {}'.format(len(host_names))) # if user does not specify any hosts, mpirun by default uses local host. # There is no need to specify localhost. hosts_arg = '-{opt} {hosts}'.format(opt='hosts' if impi else 'H', hosts=','.join(host_names) if host_names and impi else settings.hosts) # 处理ppn配置 ppn_arg = ' ' if host_to_slots and impi: ppn = host_to_slots[host_names[0]] for h_name in host_names[1:]: ppn_arg = ' -ppn {} '.format(ppn) # 处理超时配置 if settings.prefix_output_with_timestamp and not impi: mpi_impl_flags.append('--timestamp-output') binding_args = settings.binding_args if settings.binding_args and not impi else ' '.join(impl_binding_args) # 配置需要root身份运行 basic_args = '-l' if impi else '--allow-run-as-root --tag-output' output = [] if settings.output_filename: output.append('-outfile-pattern' if impi else '--output-filename') output.append(settings.output_filename) # 构建环境信息列表 env_list = '' if impi else ' '.join( '-x %s' % key for key in sorted(env.keys()) if env_util.is_exportable(key)) # 构建最终的 MPI 命令 # Pass all the env variables to the mpirun command. mpirun_command = ( 'mpirun {basic_args} ' '-np {num_proc}{ppn_","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:6:2","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"5.3 mpirun命令 因为 mpi_run 使用的是 mpirun 命令来运行，所以我们介绍一下。 mpirun是MPI程序的启动脚本，它简化了并行进程的启动过程，尽可能屏蔽了底层的实现细节，从而为用户提供了一个通用的MPI并行机制。 在用mpirun命令执行并行程序时，参数-np指明了需要并行运行的进程个数。mpirun首先在本地结点上启动一个进程，然后根据/usr/local/share/machines.LINUX文件中所列出的主机，为每个主机启动一个进程。若进程数比可用的并行节点数多，则多余的进程将重新按照上述规则进行。按这个机制分配好进程后，一般会给每个节点分一个固定的标号，类似于身份证了，后续在消息传递中会用到。 这里需要说明的是，实际运行的 orterun(Open MPI SPMD / MPMD启动器; mpirun / mpiexec只是它的符号链接) 命令举例如下： mpirun -np 4 \\ -bind-to none -map-by slot \\ -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH \\ -mca pml ob1 -mca btl ^openib \\ python train.py ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:6:3","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"6 总结 对比 gloo 和 mpi 的实现，我们还是能看出来区别。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:7:0","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"6.1 gloo gloo 只是一个库，需要 horovod 来完成命令分发功能。 gloo 需要 horovod 自己实现本地运行和远端运行方式，即 get_remote_command 函数 实现 'ssh -o PasswordAuthentication=no -o StrictHostKeyChecking=no'。 gloo 需要实现 RendezvousServer，底层会利用 RendezvousServer 进行通讯。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:7:1","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"6.2 mpi mpi 则功能强大很多，只要把命令配置成被 mpirun 包装，openmpi 就可以自行完成命令分发执行。说到底，horovod 是一个 mpirun 程序，即使运行了 tensor flow，也是一个mpi程序，可以互相交互。 references: [1]. https://www.cnblogs.com/rossiXYZ/p/14881812.html ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_3/:7:2","tags":["Horovod"],"title":"深度学习分布式训练框架 horovod[3] -- Horovodrun背后做了什么","uri":"/posts/2022-10-08_horovod_3/"},{"categories":["Distributed Computing"],"content":"0 摘要 Horovod 是Uber于2017年发布的一个易于使用的高性能的分布式训练框架，在业界得到了广泛应用。 本系列将通过源码分析来带领大家了解 Horovod。系列大约有15 ～ 18 篇，本文是系列第二篇，从用户角度切入 Horovod。 前一篇参见如下： 深度学习分布式训练框架 Horovod[1] – 基础知识 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_2/:1:0","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[2] -- 从使用者角度切入","uri":"/posts/2022-10-08_horovod_2/"},{"categories":["Distributed Computing"],"content":"1 Horovod 简介 Horovod 是Uber于2017年发布的一个易于使用的高性能的分布式训练框架，支持TensorFlow，Keras，PyTorch和MXNet。Horovod 的名字来自于俄国传统民间舞蹈，舞者手牵手围成一个圈跳舞，与分布式 TensorFlow 流程使用 Horovod 互相通信的场景很像。 因为各个机器学习框架对于底层集合通信库（ nccl，openmpi，gloo 等等）的利用水平可能各不相同，使得他们无法充分利用这些底层集合通信库的威力。因而，hovorod 就整合这些框架，提供一个易用高效的解决方案。 Uber的工程师就是根据FaceBook的一篇paper：“Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour”和百度的一篇“Bringing HPC Techniques to Deep Learning” 改进并发布了开源框架Horovod。 Horovod 相比于百度的工作，并无学术上的贡献。但是 Horovod 扎实的工程实现，使得它受到了更多的关注。它最大的优势在于对 RingAllReduce 进行了更高层次的抽象，使其支持多种不同的框架。同时引入了 Nvidia NCCL，对 GPU 更加友好。 Horovod依赖于Nvidia的 NCCL2 做 All Reduce，依赖于MPI做进程间通信，简化了同步多 GPU 或多节点分布式训练的开发流程。由于使用了NCCL2，Horovod也可以利用以下功能：NVLINK，RDMA，GPUDirectRDMA，自动检测通信拓扑，能够回退到 PCIe 和 TCP/IP 通信。 我们需要几个问题来引导分析： Hovorod 怎么进行数据分割？ Hovorod 怎么进行训练代码分发？ Hovorod 启动时候，python 和 C++ 都做了什么？ 如何确保 Hovorod 启动时候步骤一致； ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_2/:2:0","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[2] -- 从使用者角度切入","uri":"/posts/2022-10-08_horovod_2/"},{"categories":["Distributed Computing"],"content":"2 Hovorod 机制概述 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_2/:3:0","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[2] -- 从使用者角度切入","uri":"/posts/2022-10-08_horovod_2/"},{"categories":["Distributed Computing"],"content":"2.1 Horovod 机制 Horovod使用数据并行化策略在GPU上分配训练。 在数据并行化中，作业中的每个GPU都会接收其自己的数据批处理的独立切片，即它的“批处理切片”。 每个GPU都使用自己分配到的数据来独立计算，进行梯度更新。 假如使用两个GPU，批处理大小为32，则第一个GPU将处理前16条记录的正向传播和向后传播，以及第二个GPU处理后16条记录的正向传播和向后传播。然后，这些梯度更新将在GPU之间平均在一起，最后应用于模型。 每一个迭代的操作方法如下： 每个 worker 将维护自己的模型权重副本和自己的数据集副本。 收到执行信号后，每个工作进程都会从数据集中提取一个不相交的批次，并计算该批次的梯度。 Workers 使用ring all-reduce算法来同步彼此的梯度，从而在本地所有节点上计算同样的平均梯度。 将每个设备上的梯度 tensor 切分成长度大致相等的 num_devices 个分片，后续每一次通信都将给下一个邻居发送一个自己的分片（同时从上一个邻居接受一个新分片）。 ScatterReduce 阶段：通过 num_devices - 1 轮通信和相加，在每个 device 上都计算出一个 tensor 分片的和，即每个 device 将有一个块，其中包含所有device 中该块中所有值的总和；具体如下： AllGather 阶段：通过 num_devices - 1 轮通信和覆盖，将上个阶段计算出的每个 tensor 分片的和 广播到其他 device；最终所有节点都拥有所有tensor分片和。具体如下： 在每个设备上合并分片，得到梯度和，然后除以 num_devices，得到平均梯度； 每个 worker 将 梯度更新 应用于其模型的本地副本。 执行下一个batch。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_2/:3:1","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[2] -- 从使用者角度切入","uri":"/posts/2022-10-08_horovod_2/"},{"categories":["Distributed Computing"],"content":"3 示例代码 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_2/:4:0","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[2] -- 从使用者角度切入","uri":"/posts/2022-10-08_horovod_2/"},{"categories":["Distributed Computing"],"content":"3.1 摘要代码 我们此处给出官网示例代码部分摘要，具体分析参见下面代码中的注释。 import tensorflow as tf import horovod.tensorflow.keras as hvd # Horovod: initialize Horovod. hvd.init() # 初始化 Horovod，启动相关线程和MPI线程 # Horovod: pin GPU to be used to process local rank (one GPU per process) # 依据 local rank 为不同的进程分配不同的GPU gpus = tf.config.experimental.list_physical_devices('GPU') for gpu in gpus: tf.config.experimental.set_memory_growth(gpu, True) if gpus: tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], 'GPU') (mnist_images, mnist_labels), _ = \\ tf.keras.datasets.mnist.load_data(path='mnist-%d.npz' % hvd.rank()) # 切分数据 dataset = tf.data.Dataset.from_tensor_slices( (tf.cast(mnist_images[..., tf.newaxis] / 255.0, tf.float32), tf.cast(mnist_labels, tf.int64)) ) dataset = dataset.repeat().shuffle(10000).batch(128) mnist_model = tf.keras.Sequential([ tf.keras.layers.Conv2D(32, [3, 3], activation='relu'), ...... tf.keras.layers.Dense(10, activation='softmax') ]) # Horovod: adjust learning rate based on number of GPUs. scaled_lr = 0.001 * hvd.size() # 根据Worker的数量增加学习率的大小 opt = tf.optimizers.Adam(scaled_lr) # Horovod: add Horovod DistributedOptimizer. # 把常规TensorFlow Optimizer通过Horovod包装起来，进而使用 ring-allreduce 来得到平均梯度 opt = hvd.DistributedOptimizer( opt, backward_passes_per_step=1, average_aggregated_gradients=True) # Horovod: Specify `experimental_run_tf_function=False` to ensure TensorFlow # uses hvd.DistributedOptimizer() to compute gradients. mnist_model.compile(loss=tf.losses.SparseCategoricalCrossentropy(), optimizer=opt, metrics=['accuracy'], experimental_run_tf_function=False) callbacks = [ hvd.callbacks.BroadcastGlobalVariablesCallback(0), # 广播初始化，将模型的参数从第一个设备传向其他设备，以保证初始化模型参数的一致性 hvd.callbacks.MetricAverageCallback(), hvd.callbacks.LearningRateWarmupCallback(initial_lr=scaled_lr, warmup_epochs=3, verbose=1), ] # Horovod: save checkpoints only on worker 0 to prevent other workers from corrupting them. # 只有设备0需要保存模型参数作为checkpoint if hvd.rank() == 0: callbacks.append(tf.keras.callbacks.ModelCheckpoint('./checkpoint-{epoch}.h5')) # Horovod: write logs on worker 0. verbose = 1 if hvd.rank() == 0 else 0 # Train the model. # Horovod: adjust number of steps based on number of GPUs. mnist_model.fit(dataset, steps_per_epoch=500 // hvd.size(), callbacks=callbacks, epochs=24, verbose=verbose) ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_2/:4:1","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[2] -- 从使用者角度切入","uri":"/posts/2022-10-08_horovod_2/"},{"categories":["Distributed Computing"],"content":"3.2 horovodrun Horovod训练脚本未作为Python脚本启动。 例如，您不能使用python train.py运行此脚本。 需要采用特殊的CLI命令 horovodrun 来启动（训练代码 train.py 需要手动拷贝到各个节点上，且目录相同）： $ horovodrun -np 4 -H localhost:4 python train.py ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_2/:4:2","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[2] -- 从使用者角度切入","uri":"/posts/2022-10-08_horovod_2/"},{"categories":["Distributed Computing"],"content":"4 运行逻辑 我们按照顺序梳理，看看在程序初始化过程背后都做了什么。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_2/:5:0","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[2] -- 从使用者角度切入","uri":"/posts/2022-10-08_horovod_2/"},{"categories":["Distributed Computing"],"content":"4.1 引入python文件 如下代码会引入各种相关python文件。 import tensorflow as tf import horovod.tensorflow.keras as hvd ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_2/:5:1","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[2] -- 从使用者角度切入","uri":"/posts/2022-10-08_horovod_2/"},{"categories":["Distributed Computing"],"content":"4.2 初始化 in python python 世界的初始化位于 horovod-master/horovod/mxnet/mpi_ops.py 4.2.1 引入SO库 4.2.1.1 SO库 horovod/tensorflow/mpi_ops.py 之中会引入SO库。 比如 dist-packages/horovod/tensorflow/mpi_lib.cpython-36m-x86_64-linux-gnu.so。 SO库 就是 horovod 中 C++ 代码编译出来的结果。 def _load_library(name): \"\"\"Loads a .so file containing the specified operators. \"\"\" filename = resource_loader.get_path_to_datafile(name) library = load_library.load_op_library(filename) return library # Check possible symbol not found error from tensorflow version mismatch try: MPI_LIB = _load_library('mpi_lib' + get_ext_suffix()) except Exception as e: check_installed_version('tensorflow', tf.__version__, e) raise e else: check_installed_version('tensorflow', tf.__version__) 4.2.2.2 SO作用 引入库的作用是获取到 C++ 的函数，并且用 python 封装一下，这样就可以在 python 世界使用 C++代码了。 由下文可以看出来，python 的 _allreduce 函数就会把功能转发给 C++，由 MPI_LIB.horovod_allreduce 完成。 def _allreduce(tensor, name=None, op=Sum, prescale_factor=1.0, postscale_factor=1.0, ignore_name_scope=False): if name is None and not _executing_eagerly(): name = 'HorovodAllreduce_%s' % _normalize_name(tensor.name) return MPI_LIB.horovod_allreduce(tensor, name=name, reduce_op=op, prescale_factor=prescale_factor, postscale_factor=postscale_factor, ignore_name_scope=ignore_name_scope) 4.2.2 初始化配置 我们摘录了主要部分，就是初始化 _HorovodBasics，然后从 _HorovodBasics 内获取各种函数，变量和配置，比如是否编译了mpi，gloo等等. from horovod.common.basics import HorovodBasics as _HorovodBasics _basics = _HorovodBasics(__file__, 'mpi_lib') # import basic methods init = _basics.init size = _basics.size local_size = _basics.local_size rank = _basics.rank local_rank = _basics.local_rank mpi_built = _basics.mpi_built gloo_enabled = _basics.gloo_enabled ...... 4.2.3 hvd.init() 初始化 首先需要用 hvd.init() 来初始化，horovod 管理的所有状态都会传到 hvd 对象中。 # Horovod: initialize Horovod. hvd.init() 此处调用的是 HorovodBasics 中的函数，我们看看做了什么。 可以看到，这部分会一直深入到 C++世界，调用了大量的 MPI_LIB_CTYPES 函数，所以我们接下来就要进入到 C++的世界看看。 def init(self, comm=None): \"\"\"A function that initializes Horovod. \"\"\" atexit.register(self.shutdown) if not isinstance(comm, list): mpi_built = self.MPI_LIB_CTYPES.horovod_mpi_built() from mpi4py import MPI if MPI._sizeof(MPI.Comm) == ctypes.sizeof(ctypes.c_int): MPI_Comm = ctypes.c_int else: MPI_Comm = ctypes.c_void_p self.MPI_LIB_CTYPES.horovod_init_comm.argtypes = [MPI_Comm] comm_obj = MPI_Comm.from_address(MPI._addressof(comm)) self.MPI_LIB_CTYPES.horovod_init_comm(comm_obj) else: comm_size = len(comm) self.MPI_LIB_CTYPES.horovod_init( (ctypes.c_int * comm_size)(*comm), ctypes.c_int(comm_size)) 目前逻辑如下图： Import python files + | | v Import C++ SO files | | | v Create _HorovodBasics + | | v hvd.init() + Python | +------------------------------------------+ C++ | | v ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_2/:5:2","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[2] -- 从使用者角度切入","uri":"/posts/2022-10-08_horovod_2/"},{"categories":["Distributed Computing"],"content":"4.3 初始化 in C++ 4.3.1 horovod_init_comm 在初始化的时候，Horovod 会： 调用 MPI_Comm_dup 获取一个 Communicator，这样就有了和 MPI 协调的基础。 然后调用 InitializeHorovodOnce。 void horovod_init_comm(MPI_Comm comm) { MPI_Comm_dup(comm, \u0026mpi_context.mpi_comm); InitializeHorovodOnce(nullptr, 0); } 4.3.2 InitializeHorovodOnce InitializeHorovodOnce 是初始化的主要工作，主要是： 依据是否编译了 mpi 或者 gloo，对各自的 context 进行处理，为 globalstate 创建对应的 controller； 启动了后台线程 BackgroundThreadLoop 用来在各个worker之间协调； void horovod_init(const int* ranks, int nranks) { InitializeHorovodOnce(ranks, nranks); } void InitializeHorovodOnce(const int* ranks, int nranks) { // Ensure background thread is only started once. if (!horovod_global.initialize_flag.test_and_set()) { horovod_global.control_operation = ParseControllerOpsFromEnv(); horovod_global.cpu_operation = ParseCPUOpsFromEnv(); #if HAVE_MPI // 依据是否编译了MPI进行处理 // Enable mpi is it's used either in cpu data transfer or controller if (horovod_global.cpu_operation == LibType::MPI || horovod_global.control_operation == LibType::MPI) { mpi_context.Enable(); } if (horovod_global.control_operation == LibType::MPI){ // 创建一个 MPIController 对象 horovod_global.controller.reset(new MPIController( horovod_global.response_cache, horovod_global.tensor_queue, horovod_global.timeline, horovod_global.parameter_manager, horovod_global.group_table, mpi_context)); horovod_global.controller-\u003eSetRanks(ranks, nranks); } #endif #if HAVE_GLOO // 依据是否编译了 GLOO 进行处理 // Enable gloo is it's used either in cpu data transfer or controller if (horovod_global.cpu_operation == LibType::GLOO || horovod_global.control_operation == LibType::GLOO) { gloo_context.Enable(); } if (horovod_global.control_operation == LibType::GLOO) { horovod_global.controller.reset(new GlooController( horovod_global.response_cache, horovod_global.tensor_queue, horovod_global.timeline, horovod_global.parameter_manager, horovod_global.group_table, gloo_context)); } #endif // Reset initialization flag // 启动后台线程 horovod_global.initialization_done = false; horovod_global.background_thread = std::thread( BackgroundThreadLoop, std::ref(horovod_global)); } // Wait to ensure that the background thread has finished initializing MPI. while (!horovod_global.initialization_done) { std::this_thread::sleep_for(std::chrono::milliseconds(1)); } } 4.3.3 HorovodGlobalState 在 C++ 世界，HorovodGlobalState 起到了集中管理各种全局变量的作用。 HorovodGlobalState 在 horovod 中是一个全局变量，其中的元素可以供不同的线程访问。HorovodGlobalState 在加载 C++ 的代码时候就已经创建了，同时创建的还有各种 context（mpi_context, nccl_context, gpu_context）。 Horovod 主要会在backgroundThreadLoop 中完成 HorovodGlobalState 不同元素初始化，比较重要的有： controller 管理总体通信控制流； tensor_queue 会处理从前端过来的通信需求（allreduce，broadcast 等)； // All the Horovod state that must be stored globally per-process. HorovodGlobalState horovod_global; #if HAVE_MPI MPIContext mpi_context; #endif #if HAVE_GLOO GlooContext gloo_context; #endif .... std::unique_ptr\u003cOperationManager\u003e op_manager; HorovodGlobalState 摘要如下： struct HorovodGlobalState { // Background thread running MPI communication. std::thread background_thread; // 后台线程，用来在各个worker之间协调 ParameterManager parameter_manager; // 维护后台总体参数配置 // Encapsulates the fusion buffers, handles resizing and auto-tuning of buffer // size. FusionBufferManager fusion_buffer; // 融合tensor，以便缩减通信开销 std::shared_ptr\u003cController\u003e controller; //管理总体通信控制流 TensorQueue tensor_queue; //处理从前端过来的通信需求（allreduce，broadcast 等） // Pointer to shared buffer for allgather void* shared_buffer = nullptr; // LRU cache of Responses ResponseCache response_cache; // Information on registered groups. GroupTable group_table; ~HorovodGlobalState() { // Make sure that the destructor of the background thread is safe to // call. If a thread is still joinable (not detached or complete) its // destructor cannot be called. if (background_thread.joinable()) { shut_down = true; background_thread.join(); } } }; 目前具体逻辑如下： Import python files + | | v Import C++ SO files | | | v Create _HorovodBasics + | | v hvd.init() + Python | +--------------------------------------------------------","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_2/:5:3","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[2] -- 从使用者角度切入","uri":"/posts/2022-10-08_horovod_2/"},{"categories":["Distributed Computing"],"content":"4.3 hvd 概念 在用户代码中，接下来是rank概念。 hvd.local_rank() hvd.rank() 我们介绍下几个相关概念： Horovod为设备上的每个GPU启动了该训练脚本的一个副本。local rank就是分配给某一台计算机上每个执行训练的唯一编号（也可以认为是进程号或者GPU设备的ID号），范围是 0 到 n-1，其中 n 是该计算机上GPU设备的数量。 rank 可以认为是代表分布式任务里的一个执行训练的唯一全局编号（用于进程间通讯）。Rank 0 在Horovod中通常具有特殊的意义：它是负责此同步的设备。 在百度的实现中，不同 Rank 的角色是不一样的，Rank 0 会充当 coordinator 的角色。它会协调来自其他 Rank 的 MPI 请求，是一个工程上的考量。这一设计也被后来的 Horovod 采用。 Rank 0 也用来把参数广播到其他进程 \u0026 存储 checkpoint。 world_size：进程总数量，会等到所有world_size个进程就绪之后才会开始训练。 hvd.init 这部分的目的就是让并行进程们可以知道自己被分配的 rank / local rank 等信息，于是后续可以根据 local rank（所在节点上的第几张 GPU 卡） 来设置所需的显存分配。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_2/:5:4","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[2] -- 从使用者角度切入","uri":"/posts/2022-10-08_horovod_2/"},{"categories":["Distributed Computing"],"content":"4.5 数据处理 接下来是数据处理。 dataset = tf.data.Dataset.from_tensor_slices( (tf.cast(mnist_images[..., tf.newaxis] / 255.0, tf.float32), tf.cast(mnist_labels, tf.int64)) ) dataset = dataset.repeat().shuffle(10000).batch(128) 这里有几点需要说明： 首先，训练的数据需要放置在任何节点都能访问的地方。 其次，Horovod 需要对数据进行分片处理，需要在不同机器上按Rank进行切分，以保证每个GPU进程训练的数据集是不一样的。 数据集本体需要出于数据并行性的需求而被拆分为多个分片，Horovod的不同工作节点都将分别读取自己的数据集分片。 从 PyTorch 示例脚本看得更加清楚。 # Horovod: use DistributedSampler to partition the training data. train_sampler = torch.utils.data.distributed.DistributedSampler( train_dataset, num_replicas=hvd.size(), rank=hvd.rank()) train_loader = torch.utils.data.DataLoader( train_dataset, batch_size=args.batch_size, sampler=train_sampler, **kwargs) DataLoader的采样器组件从要绘制的数据集中返回可迭代的索引。 PyTorch中的默认采样器是顺序的，返回序列0, 1, 2, …, n 。 Horovod使用其DistributedSampler覆盖了此行为，该DistributedSampler处理跨计算机的数据集分区。 DistributedSampler本身接受两个参数作为输入： hvd.size() (GPU的总数，例如16)和hvd.rank() (从总体列表中分配给该设备的ID，例如0…15)。 Pytorch使用的是数据分布式训练，每个进程实际上是独立加载数据的，所以需要加载相同数据集后用一定的规则根据rank来顺序切割获取不同的数据子集，DistributedSampler就是用来确保dataloader只会load到整个数据集的一个特定子集的做法(实际上不用Pytorch提供的DistributedSampler工具，自己做加载数据后切分word_size个子集按rank顺序拿到子集效果也是一样)。 同时为了能够按顺序划分数据子集，拿到不同部分数据，所以数据集不能够进行随机打散，所以用了参数 'shuffle': False。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_2/:5:5","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[2] -- 从使用者角度切入","uri":"/posts/2022-10-08_horovod_2/"},{"categories":["Distributed Computing"],"content":"4.6 广播初始化变量 以下代码完成广播初始化的功能。 hvd.callbacks.BroadcastGlobalVariablesCallback(0) 这句代码保证的是 rank 0 上的所有参数只在 rank 0 初始化，然后广播给其他节点，即变量从第一个流程向其他流程传播，以实现参数一致性初始化。 下面就介绍下 Horvod 之中广播的使用。 4.6.1 广播定义 广播的具体实现是： class BroadcastGlobalVariablesCallbackImpl(object): def __init__(self, backend, root_rank, device='', *args): super(BroadcastGlobalVariablesCallbackImpl, self).__init__(*args) self.backend = backend self.root_rank = root_rank self.device = device self.broadcast_done = False def on_batch_end(self, batch, logs=None): if self.broadcast_done: return with tf.device(self.device): if hvd._executing_eagerly() and hasattr(self.model, 'variables'): # TensorFlow 2.0 or TensorFlow eager hvd.broadcast_variables(self.model.variables, root_rank=self.root_rank) hvd.broadcast_variables(self.model.optimizer.variables(), root_rank=self.root_rank) else: bcast_op = hvd.broadcast_global_variables(self.root_rank) self.backend.get_session().run(bcast_op) self.broadcast_done = True 4.6.2 broadcast_variables broadcast_variables 调用了 _make_broadcast_group_fn 完成功能，可以看到对于 执行图 的每个变量，调用了 broadcast。 def broadcast_variables(variables, root_rank): \"\"\"Broadcasts variables from root rank to all other processes. Arguments: variables: variables for broadcast root_rank: rank of the process from which global variables will be broadcasted to all other processes. \"\"\" broadcast_group = _make_broadcast_group_fn() return broadcast_group(variables, root_rank) 以及 @_cache def _make_broadcast_group_fn(): if _executing_eagerly(): # Eager mode will parallelize independent control flow def broadcast_group(variables, root_rank): for var in variables: var.assign(broadcast(var, root_rank)) return _make_subgraph(broadcast_group) else: # Graph mode requires an Op def broadcast_group(variables, root_rank): return tf.group(*[var.assign(broadcast(var, root_rank)) for var in variables]) return broadcast_group 4.6.3 调用 MPI broadcast 就是调用了 MPI 函数真正完成了功能。 def broadcast(tensor, root_rank, name=None, ignore_name_scope=False): \"\"\"An op which broadcasts the input tensor on root rank to the same input tensor on all other Horovod processes. The broadcast operation is keyed by the name of the op. The tensor type and shape must be the same on all Horovod processes for a given name. The broadcast will not start until all processes are ready to send and receive the tensor. Returns: A tensor of the same shape and type as `tensor`, with the value broadcasted from root rank. \"\"\" if name is None and not _executing_eagerly(): name = 'HorovodBroadcast_%s' % _normalize_name(tensor.name) return MPI_LIB.horovod_broadcast(tensor, name=name, root_rank=root_rank, ignore_name_scope=ignore_name_scope) 4.6.4 同步参数 在后台进程中，会根据情况定期同步参数。 bool RunLoopOnce(HorovodGlobalState\u0026 state) { // 业务逻辑功能 if (state.parameter_manager.IsAutoTuning()) { bool should_sync = state.parameter_manager.Update(tensor_names, total_tensor_size); // 看看是否需要同步，如果需要，就同步。 if (should_sync) { state.controller-\u003eSynchronizeParameters(); } } ...... } 同步参数代码也是调用了 Bcast 功能完成。 void Controller::SynchronizeParameters() { ParameterManager::Params param; if (is_coordinator_) { // rank 0 执行操作 param = parameter_manager_.GetParams(); } void* buffer = (void*)(\u0026param); size_t param_size = sizeof(param); Bcast(buffer, param_size, 0, Communicator::GLOBAL); if (!is_coordinator_) { // worker 执行操作 parameter_manager_.SetParams(param); } } ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_2/:5:6","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[2] -- 从使用者角度切入","uri":"/posts/2022-10-08_horovod_2/"},{"categories":["Distributed Computing"],"content":"4.7 DistributedOptimizer 最后需要配置DistributedOptimizer，这就是关键点之一。 # Horovod: add Horovod DistributedOptimizer. opt = hvd.DistributedOptimizer( opt, backward_passes_per_step=1, average_aggregated_gradients=True) TF Optimizer 是模型训练的关键API，可以获取到每个OP的梯度并用来更新权重。HVD 在原始 TF Optimizer的基础上包装了hvd.DistributedOptimizer。 DistributedOptimizer包装器将原始优化器作为输入，将梯度计算委托给它。 即DistributedOptimizer会调用原始优化器进行梯度计算。这样，在集群中每台机器都会用原始优化器得到自己的梯度（Local Gradient）。 Horovod DistributedOptimizer接下来会使用all-reduce或all-gather来完成全局梯度归并，然后将这些平均梯度应用于所有设备。 我们梳理下其中的调用关系： hvd.DistributedOptimizer继承 keras Optimizer，在计算时候，依然由传入的原始优化器做计算。 在得到计算的梯度之后，调用 hvd.allreduce 或者 hvd.allgather 来计算。 最后实施这些平均之后的梯度。从而实现整个集群的梯度归并操作。 具体后文会详细介绍。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_2/:5:7","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[2] -- 从使用者角度切入","uri":"/posts/2022-10-08_horovod_2/"},{"categories":["Distributed Computing"],"content":"4.8 未来可能 Horovod 目前架构的基础是：机器学习的模型参数在一张 GPU 上可以存下。 未来是否可以把模型分片结合进来，是一个很大的看点。 另外，如果模型的全连接层较多，则全连接层的强耦合性结合 allreduce 类似 bsp 的同步机制，还是会让网络通信时间成为瓶颈。因此，在 ring-allreduce 环境下，同步协议的改造，比如利用 SSP 来替换 BSP，或者利用梯度压缩来加快 allreduce 进程也是值得探索的方向。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_2/:5:8","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[2] -- 从使用者角度切入","uri":"/posts/2022-10-08_horovod_2/"},{"categories":["Distributed Computing"],"content":"5 总结 针对文初提出的几个问题，我们现在回答如下： Hovorod 怎么进行数据分割？ 答案：有的框架可以自动做数据分割。如果框架不提供，则需要用户自己进行数据分割，以保证每个GPU进程训练的数据集是不一样的。 Hovorod 怎么进行模型分发？ 用户需要手动拷贝训练代码到各个节点上。 Hovorod 启动时候，python 和 C++ 都做了什么？ 答案：python 会引入 C++库，初始化各种变量和配置。C++部分会对 MPI，GLOO上下文进行初始化，启动后台进程处理内部通信。 如何确保 Hovorod 启动时候步骤一致； 答案： rank 0 上的所有参数只在 rank 0 初始化，然后广播给其他节点，即变量从第一个流程向其他流程传播，以实现参数一致性初始化。 下一篇文章将深入到python世界看看。 reference: [1].https://www.cnblogs.com/rossiXYZ/p/14856543.html ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_2/:6:0","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[2] -- 从使用者角度切入","uri":"/posts/2022-10-08_horovod_2/"},{"categories":["Distributed Computing"],"content":"0 摘要 Horovod 是Uber于2017年发布的一个易于使用的高性能的分布式训练框架，在业界得到了广泛应用。 本系列将通过源码分析来带领大家了解 Horovod。系列大约有15 ～ 18 篇，本文是系列第一篇，介绍相关背景知识。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_1/:1:0","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[1] -- 基础知识","uri":"/posts/2022-10-08_horovod_1/"},{"categories":["Distributed Computing"],"content":"1 分布式并行训练 我们首先要介绍下分布式并行训练。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_1/:2:0","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[1] -- 基础知识","uri":"/posts/2022-10-08_horovod_1/"},{"categories":["Distributed Computing"],"content":"1.1 分布式并行训练的必要 传统的模型训练中，迭代计算只能利用当前进程所在主机上的所有硬件资源，可是单机扩展性始终有限。而目前的机器学习有如下特点： 样本数量大 目前训练数据越来越多，在大型互联网场景下，每天的样本量可以达到百亿级别。 特征维度多 因为巨大样本量导致机器学习模型参数越来越多，特征维度可以达到千亿或者万亿级别。 训练性能要求高 虽然样本量和模型参数巨大，但是业务需要我们在短期内训练出一个优秀的模型来验证。 模型实时上线 对于推荐资讯类应用，往往要求根据用户最新行为及时调整模型进行预测。 因此，单机面对海量数据和巨大模型时是无能为力的，有必要把数据或者模型分割成为多份，在多个机器上借助不同主机上的硬件资源进行训练加速。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_1/:2:1","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[1] -- 基础知识","uri":"/posts/2022-10-08_horovod_1/"},{"categories":["Distributed Computing"],"content":"1.2 分布式训练 本文所说的训练，指的是利用训练数据通过计算梯度下降的方式迭代地去优化神经网络参数，并最终输出网络模型的过程。在单次模型训练迭代中，会有如下操作： 首先利用数据对模型进行前向的计算。所谓的前向计算，就是将模型上一层的输出作为下一层的输入，并计算下一层的输出，从输入层一直算到输出层为止。 其次会根据目标函数，我们将反向计算模型中每个参数的导数，并且结合学习率来更新模型的参数。 而并行梯度下降的基本思想便是：多个处理器分别利用自己的数据来计算梯度，最后通过聚合或其他方式来实现并行计算梯度下降以加速模型训练过程。 比如两个处理器分别处理一半数据计算梯度 g_1, g_2，然后把两个梯度结果进行聚合更新，这样就实现了并行梯度下降。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_1/:2:2","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[1] -- 基础知识","uri":"/posts/2022-10-08_horovod_1/"},{"categories":["Distributed Computing"],"content":"1.3 训练并行机制 1.3.1 三种机制 由于使用小批量算法，可以把宽度$(∝W)$和深度$(∝D)$的前向传播和反向传播分发到并行的处理器上，这样深度训练的并行机制主要有三种： 第一个是模型并行机制（按照网络结构分区）。 通常是针对一个节点无法存下整个模型的情况下，去对图进行拆分。 将模型参数进行分布式存储。计算机上每个计算可以建模为一个有向无环图（DAG），顶点是计算指令，边是数据依赖（数据流）。“基于图去拆分” 会根据每一层中的神经元（即四维张量中的C、H或W维）来把一张大的图拆分成很多部分，每个部分都会在很多设备上去计算。 或者可以这么理解：深度学习的计算主要是矩阵运算，有时候矩阵非常大无法放到显存中，就只能把超大矩阵拆分了放到不同卡上计算。 模型较后部分的计算必须等前面计算完成，因此不同节点间的计算实际是串行的。但每个部分计算互不妨碍，更像是流水线结构。 第二个是数据并行机制（按照输入样本分区）。 更多场景下我们模型规模不大，在一张 GPU 可以容纳，但是训练数据量会比较大，这时候就采用数据并行机制。 具体就是在多节点上并行分割数据和训练。 第三种不常用的并行机制是 流水线机制（按层分区）。 在深度学习中，流水线可以是指重叠的计算，即在一层和下一层之间（当数据准备就绪时）连续计算；或者根据深度划分DNN，将层分配给特定处理器。 流水线可以看作是数据并行的一种形式，因为元素（样本）是通过网络并行处理的，但也可以看作是模型并行，因为流水线的长度是由DNN结构决定的。 具体可见下图: 1.3.2 如何使用 数据的并行往往意味着计算性能的可扩展，而模型的并行往往意味着内存使用的可扩展。 需要注意的是：数据并行和模型并行也并不冲突，两者可以同时存在，而流水线机制也可以和模型并行一起混用。比如，DistBelief分布式深度学习系统结合了三种并行策略。训练在同时复制的多个模型上训练，每个模型副本在不同的样本上训练（数据并行），每个副本上，依据同一层的神经元（模型并行性）和不同层（流水线）上划分任务，进行分布训练。 另外也需要根据具体问题具体分析，比如现代卷积神经网络主要由两种层构成，他们具有不一样的属性和性能。 卷积层，占据了90% ~ 95% 的计算量，5% 的参数，但是对结果具有很大的表达能力。 全连接层，占据了 5% ~ 10% 的计算量， 95% 的参数，但是对于结果具有相对较小的表达的能力。 综上：卷积层计算量大，所需参数系数 W 少，全连接层计算量小，所需参数系数 W 多。因此对于卷积层适合使用数据并行，对于全连接层适合使用模型并行。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_1/:2:3","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[1] -- 基础知识","uri":"/posts/2022-10-08_horovod_1/"},{"categories":["Distributed Computing"],"content":"1.4 数据并行训练 我们本系列主要讨论数据并行训练（其中的一种架构）. 数据并行训练只是一种逻辑架构。我们从沐神的书里面摘录： 假设机器上有k个GPU。给定要训练的模型，每个GPU将独立地维护一组完整的模型参数，尽管GPU上的参数值是相同且同步的。例如，下图演示了在k=2时使用数据并行的训练。 一般来说，训练过程如下： 在训练的任何迭代中，给定一个随机的小批量，我们将该小批量中的样本分成k个部分，并将它们均匀地分在多个GPU上。 每个GPU根据分配给它的小批量子集计算模型参数的损失和梯度。 将k个GPU中每个GPU的局部梯度聚合以获得当前的小批量随机梯度。 聚合梯度被重新分配到每个GPU。 每个GPU使用这个小批量随机梯度来更新它维护的完整的模型参数集。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_1/:2:4","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[1] -- 基础知识","uri":"/posts/2022-10-08_horovod_1/"},{"categories":["Distributed Computing"],"content":"2 通信和架构 前面提到并行梯度下降的例子：两个处理器分别处理一般数据计算梯度 $g_1$, $g_2$，然后把两个梯度结果进行聚合，最后再把最新参数发给各个分布计算单元，这种训练算法叫模型一致性方法（consistent model methods）。这就涉及到了通信问题，即如何做聚合。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_1/:3:0","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[1] -- 基础知识","uri":"/posts/2022-10-08_horovod_1/"},{"categories":["Distributed Computing"],"content":"2.1 方法和架构 一般有两种通信方法：Share memory 和 Message passing。 Share memory 就是所有处理器共享同一块内存，这样通信很容易，但是同一个节点内的处理器之间才可以共享内存，不同节点处理器之间无法共享内存。 Message passing 就是不同节点之间用消息（比如基于 TCP/IP 或者 RDMA）进行传递/通信，这样容易扩展，可以进行大规模训练。 因此我们知道，Message passing 才是解决方案，于是带来了问题：如何协调这些节点之间的通讯。 有两种架构： Client-Server架构: 一个 server 节点协调其他节点工作，其他节点是用来执行计算任务的 worker。 Peer-to-Peer架构：每个节点都有邻居，邻居之间可以互相通信。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_1/:3:1","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[1] -- 基础知识","uri":"/posts/2022-10-08_horovod_1/"},{"categories":["Distributed Computing"],"content":"2.2 异步 vs 同步 异步 vs 同步 是通信的另外一个侧面。 在数据并行训练之中，各个计算设备分别根据各自获得的batch，前向计算获得损失，进而反向传播计算梯度。计算好梯度后，就涉及到一个梯度同步的问题：每个计算设备 都有根据自己的数据计算的梯度，如何在不同GPU之间维护模型的不同副本之间的一致性？ 如果不同的模型以某种方式最终获得不同的权重，则权重更新将变得不一致，并且模型训练将有所不同。 怎么做这个同步就是设计分布式机器学习系统的一个核心问题。 分布式训练的梯度同步策略可分为异步（asynchronous）梯度更新 和 同步（synchronous）梯度更新机制。 同步指的是所有的设备都是采用相同的模型参数来训练，等待所有设备的mini-batch训练完成后，收集它们的梯度然后取均值，然后执行模型的一次参数更新。 同步训练相当于通过聚合很多设备上的mini-batch形成一个很大的batch来训练模型，Facebook就是这样做的，但是他们发现当batch大小增加时，同时线性增加学习速率会取得不错的效果。 同步训练看起来很不错，但是实际上需要各个设备的计算能力要均衡，而且要求集群的通信也要均衡。 因为每一轮结束时算得快的节点都需等待算得慢的节点算完，再进行下一轮迭代。类似于木桶效应，一个拖油瓶会严重拖慢训练进度，所以同步训练方式相对来说训练速度会慢一些。这个拖油瓶一般就叫做 straggler。(缺点) 异步训练中，各个设备完成一个mini-batch训练之后，不需要等待其它节点，直接去更新模型的参数，这样总体会训练速度会快很多 异步训练的一个很严重的问题是梯度失效问题（stale gradients），刚开始所有设备采用相同的参数来训练，但是异步情况下，某个设备完成一步训练后，可能发现模型参数其实已经被其它设备更新过了，此时这个梯度就过期了，因为现在的模型参数和训练前采用的参数是不一样的。由于梯度失效问题，异步训练虽然速度快，但是可能陷入次优解（sub-optimal training performance）。 具体如图所示: 这两种更新方式各有优缺点： 异步更新可能会更快速地完成整个梯度计算。 同步更新 可以更快地进行一个收敛。 选择哪种方式取决于实际的应用场景。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_1/:3:2","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[1] -- 基础知识","uri":"/posts/2022-10-08_horovod_1/"},{"categories":["Distributed Computing"],"content":"3 具体架构 接下来，我们看看几种具体架构实现，先给出一个总体说明： 名称 通信 架构 并行性 MapReduce 消息传递 client-server 批同步 Parameter Server 消息传递 client-server 异步 Decentralized Network 消息传递 P2P(Peer to Peer) 同步或异步 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_1/:4:0","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[1] -- 基础知识","uri":"/posts/2022-10-08_horovod_1/"},{"categories":["Distributed Computing"],"content":"3.1 MapReduce MapReduce是Client-Server架构。以 Spark 为例看看是如何进行并行化： Spark Driver 就是 Server，Spark Executor 就是 Worker 节点，每一个梯度下降过程包含一个广播、map和一个 reduce 操作。 Server 定义了 map操作（就是具体的训练），也可以把信息广播到worker节点。 Worker 会执行 map 操作进行训练，在此过程中，数据被分给 worker 进行计算。 计算结束后，worker把计算结果传回 driver 处理，这个叫做reduce。 在 reduce 过程中，Server 节点对 worker 传来的计算结果进行聚合之后，把聚合结果广播到各个worker节点，进行下一次迭代。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_1/:4:1","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[1] -- 基础知识","uri":"/posts/2022-10-08_horovod_1/"},{"categories":["Distributed Computing"],"content":"3.2 Parameter Server 参数服务器 Parameter server 也是一种client-server架构。和MapReduce不同在于 Parameter server 可以是异步的，MapReduce只有等所有map都完成了才能做reduce操作。 参数服务器架构中，计算设备被划分为参数服务器（PS）和worker。 参数服务器（server）。是中心化的组件，主要是负责模型参数的存储，平均梯度和交换更新。参数服务器可以按照不同比例的参数服务器和工作线程进行配置，每个参数服务器都有着不同的配置数据。 工作节点（worker）。每个工作节点会负责它领域内的数据分片所对应模型参数的更新计算（比如前向和反向传播这类计算密集的运算），同时它们又会向参数服务器去传递它所计算的梯度，由参数服务器来汇总所有的梯度，再进一步反馈到所有节点。 具体步骤如下： 所有的参数都存储在参数服务器中，而 工作节点（worker） 是万年打工仔。 工作节点 们只负责计算梯度，待所有计算设备完成梯度计算之后，把计算好的梯度发送给参数服务器，这样参数服务器收到梯度之后，执行一定的计算（梯度平均等）之后，就更新其维护的参数，做到了在节点之间对梯度进行平均，利用平均梯度对模型进行更新。 然后参数服务器再把更新好的新参数返回给所有的工作节点，以对每个节点中的模型副本应用一致化更新。 打工仔们会再进行下一轮的前后向计算。 逻辑如下： +----------------------------------------------+ | Parameter Server | | | | | | Compute : New P = P + Sum(Delta P ...) | | | | | | Parameter 1, Parameter 2, Parameter 3 ... | | | | | +--+----+----------+--+----------------+--+----+ ^ | ^ | ^ | | | | | | | Delta P | | Delta P| | Delta P| | +-----+ | | | | +------+ | +-----+ | | | | | | New P | | New P +------+ | | | | | | | New P | v | | | | | | v | v +-+-----------+ +-----+--+---+ +-----+--+---+ | Worker | | Worker | | Worker | | | | | | | | | | | ...... | | | Model | | Model | | Model | +------+------+ +------+-----+ +----+-------+ ^ ^ ^ | | | | | | +----+----+ +----+-----+ +--+-----+ | Data 1 | | Data 2 | | Data 3 | +---------+ +----------+ +--------+ 如图: 参数服务器既可以用在数据并行上，也可以被用到模型并行训练上。比如可以将模型切分为多个部分，存储在不同的PS Server节点上，并提供方便的访问服务，这是参数服务器的本质。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_1/:4:2","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[1] -- 基础知识","uri":"/posts/2022-10-08_horovod_1/"},{"categories":["Distributed Computing"],"content":"3.3 Decentralized Network Decentralized Network 就是去中心化网络，其特点如下： 去中心化网络没有一个中心节点，属于 Peer-to-Peer 架构。 采用 message passing 进行通信，且节点只和邻居通信。 并行方式可以采用异步或者同步。 去中心化网络的收敛情况取决于网络连接情况： 连接越紧密，收敛性越快，当强连接时候，模型可以很快收敛； 如果不是强连接，它可能不收敛； ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_1/:4:3","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[1] -- 基础知识","uri":"/posts/2022-10-08_horovod_1/"},{"categories":["Distributed Computing"],"content":"4 AllReduce 因为本系列是 Horovod，所以我们要先说说参数服务器的劣势，下一个系列我们再说参数服务器优势。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_1/:5:0","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[1] -- 基础知识","uri":"/posts/2022-10-08_horovod_1/"},{"categories":["Distributed Computing"],"content":"4.1 参数服务器劣势 尽管参数服务器可以提升表现，但仍然面临几个问题： 确定工作者与参数服务器的正确比例：如果使用一个参数服务器，它可能会成为网络或计算瓶颈。 如果使用多个参数服务器，则通信模式变为“All-to-All”，这可能使网络饱和。 处理程序复杂性：参数服务器的概念较多，这通常导致陡峭的学习曲线和大量的代码重构，压缩了实际建模的时间。 硬件成本 : 参数服务器的引入也增加了系统的硬件成本。 人们发现，MPI_AllReduce 语义也可以很好地满足数据并行训练这一需要。 需要注意的是：AllReduce 既可以是去中心化，也可以是主从式的。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_1/:5:1","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[1] -- 基础知识","uri":"/posts/2022-10-08_horovod_1/"},{"categories":["Distributed Computing"],"content":"4.2 并行任务通信分类 并行任务的通信一般可以分为 Point-to-point communication和 Collective communication。 P2P 这种模式只有一个sender和一个receiver，实现起来比较简单，比如NV GPU Direct P2P技术服务于单机多卡的单机卡间数据通信 。 Collective communication包含多个sender和多个receiver，一般的通信原理包括 broadcast，gather,all-gather，scatter，reduce，all-reduce，reduce-scatter，all-to-all等。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_1/:5:2","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[1] -- 基础知识","uri":"/posts/2022-10-08_horovod_1/"},{"categories":["Distributed Computing"],"content":"4.3 MPI_AllReduce AllReduce(对m个独立参数进行规约，并将规约结果返回给所有进程), 其实是最显然和直接的分布式机器学习抽象，因为大部分算法的结构都是分布数据。在每个子集上面算出一些局部统计量，然后整合出全局统计量，并且再分配给各个节点去进行下一轮的迭代，这样一个过程就是AllReduce。 可以把每个 Worker 看作是 MPI 概念中的一个进程，比如可以用 4 个 Worker 组成了一个组，该组由 4 个进程组成。我们在这四个进程中对梯度进行一次 MPI_AllReduce。 根据 MPI_AllReduce 的语义，所有参与计算的进程都有结果，所以梯度就完成了分发。只要在初始化的时候，我们可以保证每个 Worker 的参数是一致的，那在后续的迭代计算中，参数会一直保持一致，因为梯度信息是一致的。 AllReduce 跟 MapReduce 有类似，但后者采用的是面向通用任务处理的多阶段执行任务的方式，而AllReduce则让一个程序在必要的时候占领一台机器，并且在所有迭代的时候一直跑到底，来防止重新分配资源的开销，这更加适合于机器学习的任务处理。 所以，MPI_AllReduce 的语义可以很好地解决深度学习中梯度同步的问题。但是到底能不能使用它，还是要看下层的实现对这一场景是否足够友好。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_1/:5:3","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[1] -- 基础知识","uri":"/posts/2022-10-08_horovod_1/"},{"categories":["Distributed Computing"],"content":"5 ring-allreduce 百度提出使用新算法来平均梯度，取消 Reducer，并让这些梯度在所有节点之间交流，这被称为 ring-allreduce，他们使用 TensorFlow 也实现了这种算法（https://github.com/baidu-research/tensorflow-allreduce）。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_1/:6:0","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[1] -- 基础知识","uri":"/posts/2022-10-08_horovod_1/"},{"categories":["Distributed Computing"],"content":"5.1 特点 Ring-Allreduce特点如下： Ring Allreduce 算法使用定义良好的成对消息传递步骤序列在一组进程之间同步状态（在这种情况下为张量）。 Ring-Allreduce 的命名中 Ring 意味着设备之间的拓扑结构为一个逻辑环形，每个设备都应该有一个左邻和一个右邻居，且本设备只会向它右邻居发送数据，并且从它的左邻居接受数据。 Ring-Allreduce 的命名中的 Allreduce 则代表着没有中心节点，架构中的每个节点都是梯度的汇总计算节点。 此种算法各个节点之间只与相邻的两个节点通信，并不需要参数服务器。因此，所有节点都参与计算也参与存储，也避免产生中心化的通信瓶颈。 相比PS架构，Ring-Allreduce 架构是带宽优化的，因为集群中每个节点的带宽都被充分利用。 在 ring-allreduce 算法中，每个 N 节点与其他两个节点进行 2 * (N-1) 次通信。在这个通信过程中，一个节点发送并接收数据缓冲区传来的块。在第一个N-1迭代中，接收的值被添加到节点缓冲区中的值。在第二个N-1迭代中，接收的值代替节点缓冲区中保存的值。百度的文章证明了这种算法是带宽上最优的，这意味着如果缓冲区足够大，它将最大化地利用可用的网络。 在深度学习训练过程中，计算梯度采用BP算法，其特点是后面层的梯度先被计算，而前面层的梯度慢于后面层，Ring-allreduce架构可以充分利用这个特点，在前面层梯度计算的同时进行后面层梯度的传递，从而进一步减少训练时间。 Ring架构下的同步算法将参数在通信环中依次传递，往往需要多步才能完成一次参数同步。在大规模训练时会引入很大的通信开销，并且对小尺寸张量（tensor）不够友好。对于小尺寸张量，可以采用批量操作（batch）的方法来减小通信开销。 综上所述，Ring-based AllReduce 架构的网络通讯量如果处理适当，不会随着机器增加而增加，而仅仅和模型 \u0026 网络带宽有关，这针对参数服务器是个巨大的提升。 ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_1/:6:1","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[1] -- 基础知识","uri":"/posts/2022-10-08_horovod_1/"},{"categories":["Distributed Computing"],"content":"5.2 策略 Ring-based AllReduce 策略包括 Scatter-Reduce 和 AllGather 两个阶段。 首先是scatter-reduce，scatter-reduce 会逐步交换彼此的梯度并融合，最后每个 GPU 都会包含完整融合梯度的一部分，是最终结果的一个块。 假设环中有 N 个 worker，每个 worker 有长度相同的数组，需要将 worker 的数组进行求和。在 Scatter-Reduce 阶段，每个 worker 会将数组分成 N 份数据块，然后 worker 之间进行 N 次数据交换。在第 k 次数据交换时，第 i 个 worker 会将自己的 (i - k) % N 份数据块发送给下一个 worker。接收到上一个 worker 的数据块后，worker 会将其与自己对应的数据块求和。 然后是allgather。GPU 会逐步交换彼此不完整的融合梯度，最后所有 GPU 都会得到完整的最终融合梯度。 在执行完 Scatter-Reduce 后，每个 worker 的数组里都有某个数据块是最终求和的结果，现在需要将各数据块的最后求和结果发送到每个 worker 上。和 Scatter-Reduce 一样，也需要 N 次循环。在第 k 次循环时，第 i 个 worker 会将其第 (i+1-k)%N 个数据块发送给下一个 worker 。接收到前一个 worker 的数据块后，worker 会用接收的数据快覆盖自己对应的数据块。进行 N 次循环后，每个 worker 就拥有了数组各数据块的最终求和结果了。 以下部分来自 https://andrew.gibiansky.com/blog/machine-learning/baidu-allreduce/，这是我能找到最优秀的解读。 5.2.1 结构 环形结构如下，每个 GPU 应该有一个左邻居和一个右邻居；它只会向其右侧邻居发送数据，并从其左侧邻居接收数据。 5.2.2 scatter reduce scatter-reduce：会逐步交换彼此的梯度并融合，最后每个 GPU 都会包含完整融合梯度的一部分。 为简单起见，我们假设目标是按元素对单个大型浮点数数组的所有元素求和；系统中有 N 个 GPU，每个 GPU 都有一个相同大小的数组，在 allreduce 的最后环节，每个 GPU 都应该有一个相同大小的数组，其中包含原始数组中数字的总和。 5.2.2.1 分块 首先，GPU 将阵列划分为 N 个较小的块（其中 N 是环中的 GPU 数量）。 接下来，GPU 将进行 N-1 次 scatter-reduce 迭代。 在每次迭代中，GPU 会将其一个块发送到其右邻居，并将从其左邻居接收一个块并累积到该块中。每个 GPU 发送和接收的数据块每次迭代都不同。第 n 个 GPU 通过发送块 n 和接收块 n – 1 开始，然后逐步向后进行，每次迭代发送它在前一次迭代中接收到的块。 5.2.2.2 第一次迭代 在第一次迭代中，上图中的五个 GPU 将发送和接收以下块： GPU 发送 接收 0 块0 块4 1 块1 块0 2 块2 块1 3 块3 块2 4 块4 块3 scatter-reduce 的第一次迭代中的数据传输如下： 第一次发送和接收完成后，每个 GPU 都会有一个块，该块由两个不同 GPU 上相同块的总和组成。例如，第二个 GPU 上的第一个块将是该块中来自第二个 GPU 和第一个 GPU 的值的总和。 5.2.2.2 全部迭代 在后续迭代中，该过程继续直到最后。最终每个 GPU 将有一个块，这个块包含所有 GPU 中该块中所有值的总和。 下面系列图展示了所有数据传输和中间结果，从第一次迭代开始，一直持续到scatter-reduce完成。 iter 1： iter2： iter3： iter4： 所有 scatter-reduce 传输后的最终状态 5.2.3 Allgather 在 scatter-reduce 步骤完成后，在每个 GPU 的数组中都有某一些值（每个 GPU 有一个块）是最终值，其中包括来自所有 GPU 的贡献。为了完成 allreduce，GPU 必须接下来交换这些块，以便所有 GPU 都具有最终所需的值。 ring allgather 与 scatter-reduce 进行相同的处理（发送和接收的 N-1 次迭代），但是他们这次不是累积 GPU 接收的值，而只是简单地覆盖块。第 n 个 GPU 开始发送第 n+1 个块并接收第 n 个块，然后在以后的迭代中始终发送它刚刚接收到的块。 5.2.3.1 第一次迭代 例如，在我们的 5-GPU 设置的第一次迭代中，GPU 将发送和接收以下块： GPU 发送 接收 0 块1 块0 1 块2 块1 2 块3 块2 3 块4 块3 4 块0 块4 allgather 的第一次迭代中的数据传输如下。 第一次迭代完成后，每个 GPU 都会有最终数组的两个块。在接下来的迭代中，该过程继续一直到最后，最终每个 GPU 将拥有整个数组的完全累加值。 5.2.3.2 全部迭代 下面系列图展示了所有数据传输和中间结果，从第一次迭代开始，一直持续到全部收集完成。 Allgather 数据传输（迭代 1） Allgather 数据传输（迭代 2）如下： Allgather 数据传输（迭代 3）： Allgather 数据传输（迭代 4）： 所有全部转移后的最终状态。 5.2.4 Horovod 架构图 工作原理也可以借助Horovod的发布帖子 来看看。 5.2.5 百度思路 或者我们从百度的源码中也可以直接看到思路，现在摘录给大家。 具体代码参见 https://github.com/baidu-research/tensorflow-allreduce/commit/66d5b855e90b0949e9fa5cca5599fd729a70e874#diff-3d530d590e551619acd776cfe7eaff06R517 /* Perform a ring allreduce on the data. Allocate the necessary output tensor and * store it in the output parameter. * * Assumes that all MPI processes are doing an allreduce of the same tensor, * with the same dimensions. * * A ring allreduce is a bandwidth-optimal way to do an allreduce. To do the allreduce, * the nodes involved are arranged in a ring: * * .--0--. * / \\ * 3 1 * \\ / * *--2--* * * Each node always sends to the next clockwise node in the ring, and receives * from the previous one. * * The allreduce is done in two parts: a scatter-reduce and an allgather. In * the scatter reduce, a reduction is done, so that each node ends up with a * chunk of the final output tensor which has contributions from all other * nodes. In the allgather, those chunks are distributed among all the nodes, * so that all nodes have the entire output tensor. * * Both of these operations are done by dividing the input tensor into N * evenly sized chunks (where N is the number of nodes in the ring). * * The scatter-reduce is done in N-1 steps. In the ith step, node j will send * the (j - i)th chunk and receive the (j - i - 1)th chunk, adding it in to * its existing data for that chunk. For example, in the first iteration with * the ring depicted above, you will have the following transfers: * * Segment 0: Node 0 --\u003e Node 1 * Segment 1: Node 1 --\u003e Node 2 * Segment 2: Node 2 --\u003e Node 3 * Segment 3: Node 3 --\u003e Node 0 * * In the second iteration, you'll have ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_1/:6:2","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[1] -- 基础知识","uri":"/posts/2022-10-08_horovod_1/"},{"categories":["Distributed Computing"],"content":"5.3 区别 在中等规模模型情况下，all-reduce 更适合。当规模巨大时候则应该使用参数服务器。 参数服务器 适合的是高维稀疏模型训练，它利用的是维度稀疏的特点，每次 pull or push 只更新有效的值。但是深度学习模型是典型的dense场景，embedding做的就是把稀疏变成稠密。所以这种 pull or push 的不太适合。而 网络通信上更优化的 all-reduce 适合中等规模的深度学习。 又比如由于推荐搜索领域模型的 Embedding 层规模庞大以及训练数据样本长度不固定等原因，导致容易出现显存不足和卡间同步时间耗费等问题，所以 all-reduce 架构很少被用于搜索推荐领域。 至此，背景知识已经介绍完毕，下一篇我们开始介绍 Horovod 的使用。 reference: [1] https://www.cnblogs.com/rossiXYZ/p/14856464.html ","date":"2023-07-10","objectID":"/posts/2022-10-08_horovod_1/:6:3","tags":["Horovod"],"title":"深度学习分布式训练框架 Horovod[1] -- 基础知识","uri":"/posts/2022-10-08_horovod_1/"},{"categories":["Memo"],"content":" quote tips for hugo installation and new site creation. Commands for creating sites backend with hugo create a new markdown file hugo new posts/tech/name-of-file.md hugo new content/posts/tech/name-of-file.md create new site hugo new site name Install hugo Linux wget https://github.com/gohugoio/hugo/releases/download/v0.83.1/hugo_0.83.1_Linux-64bit.tar.gz tar -xf hugo_0.83.1_Linux-64bit.tar.gz sudo mv hugo /usr/local/bin/ hugo version ","date":"2023-07-09","objectID":"/posts/hugo_command/:0:0","tags":["hugo"],"title":"Hugo_command","uri":"/posts/hugo_command/"},{"categories":["Node.js","JavaScript"],"content":"最近在写一个 Vue 插件，需要在项目中创建一些测试页面，由于都是些静态路由，就想到之前看到过的一个项目就是用 Node.js 来自动生成路由的，于是就借鉴过来改了一下。 ","date":"2023-06-14","objectID":"/posts/gen-router/:0:0","tags":["Node.js","JavaScript","Vue"],"title":"使用 Node.js 自动创建 Vue 的路由","uri":"/posts/gen-router/"},{"categories":["Node.js","JavaScript"],"content":"源码 const fs = require('fs') const os = require('os') const vueDir = './src/views/' const routerFile = './src/router.js' fs.readdir(vueDir, function (err, files) { if (err) { console.error('❌ Could not list the directory.', err) return } const routes = [] for (const filename of files) { if (filename.indexOf('.') \u003c 0) { continue } const [name, ext] = filename.split('.') if (ext !== 'vue') { continue } const routeName = name.replace(/-([a-z])/g, (_, match) =\u003e match.toUpperCase()) let routeDescription = '' const contentFull = fs.readFileSync(`${vueDir}${filename}`, 'utf-8') // get route description from first line comment const match = /\u003c!--\\s*(.*)\\s*--\u003e/g.exec(contentFull.split(os.EOL)[0]) if (match) { routeDescription = match[1].trim() } routes.push(` { path: '/${name === 'home' ? '' : name}', name: '${routeName}',${routeDescription ? `\\n description: '${routeDescription}',` : ''} component: () =\u003e import(/* webpackChunkName: \"${routeName}\" */ '@/views/${filename}'), },`) } const result = `// This file is automatically generated by gen-router.js, please do not modify it manually！ import VueRouter from 'vue-router' import Vue from 'vue' Vue.use(VueRouter) const routes = [ ${routes.join(os.EOL)} ] const router = new VueRouter({ mode: 'hash', routes, }) export default router ` fs.writeFile(routerFile, result, 'utf-8', (err) =\u003e { if (err) throw err console.log(`✅ Router generated successfully in ${routerFile}`) }) }) 生成效果如下： // This file is automatically generated by gen-router.js, please do not modify it manually！ import VueRouter from 'vue-router' import Vue from 'vue' Vue.use(VueRouter) const routes = [ { path: '/', name: 'home', description: 'Home', component: () =\u003e import(/* webpackChunkName: \"home\" */ '@/views/home.vue'), }, ] const router = new VueRouter({ mode: 'hash', routes, }) export default router ","date":"2023-06-14","objectID":"/posts/gen-router/:1:0","tags":["Node.js","JavaScript","Vue"],"title":"使用 Node.js 自动创建 Vue 的路由","uri":"/posts/gen-router/"},{"categories":["Node.js","JavaScript"],"content":"参考 sunzsh/vue-el-demo ","date":"2023-06-14","objectID":"/posts/gen-router/:2:0","tags":["Node.js","JavaScript","Vue"],"title":"使用 Node.js 自动创建 Vue 的路由","uri":"/posts/gen-router/"},{"categories":["Git"],"content":"问题描述 在使用 SourceTree 提交代码的时候，会出现 husky 命令失败的问题（通过命令行提交代码没有问题），如下图所示： 看错误，是一个 catch 参数的问题，在新版本的 Node 中，catch 参数是可以省略的，但是在旧版本中，catch 参数是必须的。 由于使用了 nvm 管理 Node 版本，项目中的 Node 是正常的，但是 SourceTree 使用的是系统的 Node，所以会出现这个问题。 ","date":"2023-06-12","objectID":"/posts/sourcetree-husky/:1:0","tags":["Git","husky","Mac"],"title":"解决 SourceTree 提交时候 husky 命令失败问题","uri":"/posts/sourcetree-husky/"},{"categories":["Git"],"content":"解决方案 知道了问题的原因，解决起来就很简单了，只需要将 SourceTree husky hook 阶段的 Node 版本切换到项目中的 Node 版本即可。 配置 .huskyrc 文件，内容如下： echo \"export PATH=\\\"$(dirname $(which node)):\\$PATH\\\"\" \u003e ~/.huskyrc 如果你使用了 zsh 和 nvm, 建议在 $ZSH_CUSTOM 目录下添加一个自定义 zsh 脚本。 这个脚本会在你进入包含了 .nvmrc 文件目录中自动切换 node 版本，切换版本后修正 ~/.huskyrc 的 path 内容。 vim $ZSH_CUSTOM/nvm_custom.zsh # https://github.com/nvm-sh/nvm#manual-install export NVM_DIR=\"$HOME/.nvm\" [ -s \"$NVM_DIR/nvm.sh\" ] \u0026\u0026 \\. \"$NVM_DIR/nvm.sh\" # This loads nvm [ -s \"$NVM_DIR/bash_completion\" ] \u0026\u0026 \\. \"$NVM_DIR/bash_completion\" # This loads nvm bash_completion # https://github.com/nvm-sh/nvm#deeper-shell-integration autoload -U add-zsh-hook load-nvmrc() { local node_version=\"$(nvm version)\" local nvmrc_path=\"$(nvm_find_nvmrc)\" if [ -n \"$nvmrc_path\" ]; then local nvmrc_node_version=$(nvm version \"$(cat \"${nvmrc_path}\")\") if [ \"$nvmrc_node_version\" = \"N/A\" ]; then nvm install elif [ \"$nvmrc_node_version\" != \"$node_version\" ]; then nvm use fi elif [ \"$node_version\" != \"$(nvm version default)\" ]; then echo \"Reverting to nvm default version\" nvm use default fi # fix husky hook # ref: https://github.com/typicode/husky/issues/390#issuecomment-762213421 echo \"export PATH=\\\"$(dirname $(which node)):\\$PATH\\\"\" \u003e ~/.huskyrc } add-zsh-hook chpwd load-nvmrc load-nvmrc # https://github.com/nvm-sh/nvm#use-a-mirror-of-node-binaries export NVM_NODEJS_ORG_MIRROR=https://mirrors.ustc.edu.cn/node/ ","date":"2023-06-12","objectID":"/posts/sourcetree-husky/:2:0","tags":["Git","husky","Mac"],"title":"解决 SourceTree 提交时候 husky 命令失败问题","uri":"/posts/sourcetree-husky/"},{"categories":["Git"],"content":"参考 https://wxhboy.cn/2022/04/12/解决SourceTree提交时候husky命令失败问题/ https://github.com/typicode/husky/issues/390#issuecomment-762213421 https://github.com/typicode/husky/issues/904#issuecomment-862184954 https://github.com/nvm-sh/nvm#deeper-shell-integration ","date":"2023-06-12","objectID":"/posts/sourcetree-husky/:3:0","tags":["Git","husky","Mac"],"title":"解决 SourceTree 提交时候 husky 命令失败问题","uri":"/posts/sourcetree-husky/"},{"categories":["CSS","JavaScript"],"content":"新建 Vue2 项目 通过 vue-cli 创建一个叫 v2-tailwind 的项目： vue create vue2-tailwind 根据需要选择其他的功能插件，例如：Babel, Router, Vuex, CSS Pre-processors, Linter。 关于 ESLint 当在 Vue 创建项目时，你可以根据自己的需求选择不同的 ESLint 配置。以下是一些常见的选项及其优缺点和注意事项： ESLint with error prevention only: 优点：这个配置只会帮助你防止代码中的错误，它的规则相对宽松。适用于刚开始使用 ESLint 或者希望避免太多约束的开发者。 缺点：由于规则相对宽松，可能无法完全确保代码风格的一致性。 注意事项：如果你想要更严格的代码检查，可以考虑其他配置。 ESLint + Airbnb config: 优点：Airbnb 的配置非常严格，能够帮助你遵循最佳实践和编写高质量的代码。此外，它也包含了许多 ES6+ 的规则。 缺点：由于其严格性，初学者可能需要花费更多时间来解决 ESLint 报告的问题。 注意事项：在使用此配置时，请确保你理解并接受 Airbnb 的代码规范。 ESLint + Standard config: 优点：Standard 的配置旨在提供一个相对简单、一致的代码风格，适合那些喜欢“零配置”的开发者。 缺点：这个配置可能不适用于所有项目，因为它有自己的代码风格要求。 注意事项：如果你的团队或项目已经有自己的编码规范，使用 Standard 配置可能会导致不一致。 ESLint + Prettier: 优点：Prettier 是一个自动格式化工具，可以与 ESLint 结合使用，以确保代码风格的一致性。这可以提高代码可读性，并减少在代码审查过程中关注格式问题的时间。 缺点：Prettier 可能会覆盖某些 ESLint 规则，所以需要花一些时间确保配置正确。 注意事项：为了避免冲突，请确保 ESLint 和 Prettier 的规则正确配置。 总之，在选择 ESLint 配置时，需要根据你的团队、项目需求和个人偏好来权衡。选择适当的配置可以帮助你提高代码质量并保持一致的代码风格。 ","date":"2023-06-03","objectID":"/posts/v2-tailwind/:1:0","tags":["tailwindcss","Vue"],"title":"Vue2 + tailwindcss 初始化","uri":"/posts/v2-tailwind/"},{"categories":["CSS","JavaScript"],"content":"安装 tailwindcss 打开项目，安装 tailwindcss： cd vue2-tailwind # 安装 tailwindcss 低版本及相关插件 npm install tailwindcss@npm:@tailwindcss/postcss7-compat @tailwindcss/postcss7-compat postcss@^7 autoprefixer@^9 然后创建配置文件： # 创建 postcss.config.js, tailwind.config.js npx tailwindcss init -p module.exports = { plugins: { tailwindcss: {}, autoprefixer: {}, } } module.exports = { purge: [ \"./src/App.vue\", \"./src/views/**/*.{vue,js,ts,jsx,tsx}\", \"./src/components/**/*.{vue,js,ts,jsx,tsx}\", ], darkMode: 'class', // or 'media' or 'class' mode: 'jit', // 是否开启 jit 模式，开启以后编译会更快，当然，tailwindcss 版本需要在 2.1 以上 theme: { extend: {}, }, variants: { extend: {}, }, plugins: [], } 最后在 main.js 中引入 tailwindcss import \"tailwindcss/tailwind.css\" ","date":"2023-06-03","objectID":"/posts/v2-tailwind/:2:0","tags":["tailwindcss","Vue"],"title":"Vue2 + tailwindcss 初始化","uri":"/posts/v2-tailwind/"},{"categories":["CSS","JavaScript"],"content":"启动项目 启动项目，修改模板中的 class 进行测试。 npm run serve \u003ctemplate\u003e \u003cdiv id=\"app\"\u003e \u003cdiv class=\"bg-gray-100\"\u003e \u003cdiv class=\"container mx-auto\"\u003e \u003cdiv class=\"flex justify-center items-center h-screen\"\u003e \u003cdiv class=\"text-4xl text-gray-700\"\u003eHello Vue2 + tailwindcss\u003c/div\u003e \u003c/div\u003e \u003c/div\u003e \u003c/div\u003e \u003c/div\u003e \u003c/template\u003e ","date":"2023-06-03","objectID":"/posts/v2-tailwind/:3:0","tags":["tailwindcss","Vue"],"title":"Vue2 + tailwindcss 初始化","uri":"/posts/v2-tailwind/"},{"categories":["HTML"],"content":"记录使用 HTML 原生方案实现图片的懒加载。 ","date":"2023-02-12","objectID":"/posts/native-img-loading-lazy/:0:0","tags":["HTML","eager","lazy","loading"],"title":"浏览器 IMG 图片原生懒加载 loading=\"lazy\"","uri":"/posts/native-img-loading-lazy/"},{"categories":["HTML"],"content":"语法规范 HTML loading 属性适用于 img 和 iframe，语法规范见 HTML Standard - Lazy loading attributes。 关键词 状态 描述 lazy 懒惰的 用于延迟获取资源，直到满足某些条件。 eager 渴望的 用于立即获取资源；默认状态。 属性的 缺失值默认值 和 无效值默认值 都是 Eager状态。 ","date":"2023-02-12","objectID":"/posts/native-img-loading-lazy/:1:0","tags":["HTML","eager","lazy","loading"],"title":"浏览器 IMG 图片原生懒加载 loading=\"lazy\"","uri":"/posts/native-img-loading-lazy/"},{"categories":["HTML"],"content":"实际应用 基于 FixIt 主题 版本大于 v0.2.18 的博客网站使用就是原生的懒加载方案，大致如下： \u003cimg loading=\"lazy\" src=\"./example.jpg\" data-title=\"title text\" data-alt=\"alt text\" onload=\"this.title=this.dataset.title;this.alt=this.dataset.alt;for(const a of ['data-title','data-alt','onerror','onload']){this.removeAttribute(a);}this.dataset.lazyloaded='';\" onerror=\"this.title=this.dataset.title;this.alt=this.dataset.alt;for(const a of ['data-title','data-alt','onerror','onload']){this.removeAttribute(a);}\" /\u003e 为了达到 loading 的效果，以上代码中在 onload 后会给图片加上一个 data-lazyloaded 属性，所以我们可以这样来写 css 以达到显示 loading 图标的效果： img[loading='lazy']:not([data-lazyloaded]) { background: url(loading.svg) no-repeat center; } 设置 data-title 和 data-alt 是因为移动浏览器大多数只要有 title 或 alt 就会显示图片的替代字符，所以等到图片加载完或加载失败后再回填。 ","date":"2023-02-12","objectID":"/posts/native-img-loading-lazy/:2:0","tags":["HTML","eager","lazy","loading"],"title":"浏览器 IMG 图片原生懒加载 loading=\"lazy\"","uri":"/posts/native-img-loading-lazy/"},{"categories":["HTML"],"content":"懒加载特性的研究 以下结论来自 浏览器 IMG 图片原生懒加载 loading=”lazy”实践指南 « 张鑫旭-鑫空间-鑫生活 总结部分。 Lazy loading 加载数量与屏幕高度有关，高度越小加载数量越少，但并不是线性关系. Lazy loading 加载数量与网速有关，网速越慢，加载数量越多，但并不是线性关系。 Lazy loading 加载没有缓冲，滚动即会触发新的图片资源加载。 Lazy loading 加载在窗口 resize 尺寸变化时候也会触发，例如屏幕高度从小变大的时候。 Lazy loading 加载也有可能会先加载后面的图片资源，例如页面加载时滚动高度很高的时候。 ","date":"2023-02-12","objectID":"/posts/native-img-loading-lazy/:3:0","tags":["HTML","eager","lazy","loading"],"title":"浏览器 IMG 图片原生懒加载 loading=\"lazy\"","uri":"/posts/native-img-loading-lazy/"},{"categories":["HTML"],"content":"参考链接 Lazy loading - Web 性能 | MDN Lazy loading via attribute for images \u0026 iframes 兼容性 ","date":"2023-02-12","objectID":"/posts/native-img-loading-lazy/:4:0","tags":["HTML","eager","lazy","loading"],"title":"浏览器 IMG 图片原生懒加载 loading=\"lazy\"","uri":"/posts/native-img-loading-lazy/"},{"categories":["Browser"],"content":"浏览器是如何渲染页面的？ 当浏览器的网络线程收到 HTML 文档后，会产生一个渲染任务，并将其传递给渲染主线程的消息队列。 在事件循环机制的作用下，渲染主线程取出消息队列中的渲染任务，开启渲染流程。 整个渲染流程分为多个阶段，分别是： HTML 解析、样式计算、布局、分层、绘制、分块、光栅化、画 每个阶段都有明确的输入输出，上一个阶段的输出会成为下一个阶段的输入。 这样，整个渲染流程就形成了一套组织严密的生产流水线。 渲染的第一步是解析 HTML。 解析过程中遇到 CSS 解析 CSS，遇到 JS 执行 JS。为了提高解析效率，浏览器在开始解析前，会启动一个预解析的线程，率先下载 HTML 中的外部 CSS 文件和 外部的 JS 文件。 如果主线程解析到link位置，此时外部的 CSS 文件还没有下载解析好，主线程不会等待，继续解析后续的 HTML。这是因为下载和解析 CSS 的工作是在预解析线程中进行的。这就是 CSS 不会阻塞 HTML 解析的根本原因。 如果主线程解析到script位置，会停止解析 HTML，转而等待 JS 文件下载好，并将全局代码解析执行完成后，才能继续解析 HTML。这是因为 JS 代码的执行过程可能会修改当前的 DOM 树，所以 DOM 树的生成必须暂停。这就是 JS 会阻塞 HTML 解析的根本原因。 第一步完成后，会得到 DOM 树和 CSSOM 树，浏览器的默认样式、内部样式、外部样式、行内样式均会包含在 CSSOM 树中。 渲染的下一步是样式计算。 主线程会遍历得到的 DOM 树，依次为树中的每个节点计算出它最终的样式，称之为 Computed Style。 在这一过程中，很多预设值会变成绝对值，比如red会变成rgb(255,0,0)；相对单位会变成绝对单位，比如em会变成px 这一步完成后，会得到一棵带有样式的 DOM 树。 接下来是布局，布局完成后会得到布局树。 布局阶段会依次遍历 DOM 树的每一个节点，计算每个节点的几何信息。例如节点的宽高、相对包含块的位置。 大部分时候，DOM 树和布局树并非一一对应。 比如display:none的节点没有几何信息，因此不会生成到布局树；又比如使用了伪元素选择器，虽然 DOM 树中不存在这些伪元素节点，但它们拥有几何信息，所以会生成到布局树中。还有匿名行盒、匿名块盒等等都会导致 DOM 树和布局树无法一一对应。 下一步是分层 主线程会使用一套复杂的策略对整个布局树中进行分层。 分层的好处在于，将来某一个层改变后，仅会对该层进行后续处理，从而提升效率。 滚动条、堆叠上下文、transform、opacity 等样式都会或多或少的影响分层结果，也可以通过will-change属性更大程度的影响分层结果。 再下一步是绘制 主线程会为每个层单独产生绘制指令集，用于描述这一层的内容该如何画出来。 完成绘制后，主线程将每个图层的绘制信息提交给合成线程，剩余工作将由合成线程完成。 合成线程首先对每个图层进行分块，将其划分为更多的小区域。 它会从线程池中拿取多个线程来完成分块工作。 分块完成后，进入光栅化阶段。 合成线程会将块信息交给 GPU 进程，以极高的速度完成光栅化。 GPU 进程会开启多个线程来完成光栅化，并且优先处理靠近视口区域的块。 光栅化的结果，就是一块一块的位图 最后一个阶段就是画了 合成线程拿到每个层、每个块的位图后，生成一个个「指引（quad）」信息。 指引会标识出每个位图应该画到屏幕的哪个位置，以及会考虑到旋转、缩放等变形。 变形发生在合成线程，与渲染主线程无关，这就是transform效率高的本质原因。 合成线程会把 quad 提交给 GPU 进程，由 GPU 进程产生系统调用，提交给 GPU 硬件，完成最终的屏幕成像。 ","date":"2023-02-05","objectID":"/posts/browser-rendering/:1:0","tags":["Browser","JavaScript","HTML","CSS"],"title":"浏览器渲染原理","uri":"/posts/browser-rendering/"},{"categories":["Browser"],"content":"什么是 reflow？ reflow 的本质就是重新计算 layout 树。 当进行了会影响布局树的操作后，需要重新计算布局树，会引发 layout。 为了避免连续的多次操作导致布局树反复计算，浏览器会合并这些操作，当 JS 代码全部完成后再进行统一计算。所以，改动属性造成的 reflow 是异步完成的。 也同样因为如此，当 JS 获取布局属性时，就可能造成无法获取到最新的布局信息。 浏览器在反复权衡下，最终决定获取属性立即 reflow。 ","date":"2023-02-05","objectID":"/posts/browser-rendering/:2:0","tags":["Browser","JavaScript","HTML","CSS"],"title":"浏览器渲染原理","uri":"/posts/browser-rendering/"},{"categories":["Browser"],"content":"什么是 repaint？ repaint 的本质就是重新根据分层信息计算了绘制指令。 当改动了可见样式后，就需要重新计算，会引发 repaint。 由于元素的布局信息也属于可见样式，所以 reflow 一定会引起 repaint。 ","date":"2023-02-05","objectID":"/posts/browser-rendering/:3:0","tags":["Browser","JavaScript","HTML","CSS"],"title":"浏览器渲染原理","uri":"/posts/browser-rendering/"},{"categories":["Browser"],"content":"为什么 transform 的效率高？ 因为 transform 既不会影响布局也不会影响绘制指令，它影响的只是渲染流程的最后一个「draw」阶段 由于 draw 阶段在合成线程中，所以 transform 的变化几乎不会影响渲染主线程。反之，渲染主线程无论如何忙碌，也不会影响 transform 的变化。 ","date":"2023-02-05","objectID":"/posts/browser-rendering/:4:0","tags":["Browser","JavaScript","HTML","CSS"],"title":"浏览器渲染原理","uri":"/posts/browser-rendering/"},{"categories":["Spec"],"content":" 以下参考来源：阮一峰的 中文技术文档的写作规范 英语世界里，文档非常受重视，许多公司和组织都有自己的文档规范，清楚地规定写作要求，比如微软、MailChimp、Apple、Yahoo、docker、Struts 等等（维基百科有一份完整的清单）。中文的也有不少，但都不令人满意，要么太简单，要么不太适用。 对于开发者来说，在工作中也需要适当地产出一些技术文档，但是很多人都不知道怎么写文档，都是凭着感觉写。 对于开发的系统、软件而言，系统用词的准确性和统一性也显得十分重要。 参考上面的规范，于是有了下面一份中文技术文档的写作规范。 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:0:0","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"标题 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:1:0","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"层级 标题分为四级。 一级标题：文章的标题 二级标题：文章主要部分的大标题 三级标题：二级标题下面一级的小标题 四级标题：三级标题下面某一方面的小标题 下面是示例。 # 一级标题 ## 二级标题 ### 三级标题 #### 四级标题 注：最多支持六级，但是同论文写作一样，层级太深，会使得整体显得杂乱无章，当确实需要更深层级时，应另起新篇单独论述。 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:1:1","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"原则 （1）一级标题下，不能直接出现三级标题。 示例：下面的文章结构，缺少二级标题。 # 一级标题 ### 三级标题 （2）标题要避免孤立编号（即同级标题只有一个）。 示例：下面的文章结构，二级标题 A只包含一个三级标题，完全可以省略三级标题 A。 ## 二级标题 A ### 三级标题 A ## 二级标题 B （3）下级标题不重复上一级标题的名字。 示例：下面的文章结构，二级标题与下属的三级标题同名，建议避免。 ## 概述 ### 概述 （4）谨慎使用四级标题，尽量避免出现，保持层级的简单，防止出现过于复杂的章节。 如果三级标题下有并列性的内容，建议只使用项目列表（Item list）。 示例：下面的结构二要好于结构一。结构一适用的场景，主要是较长篇幅的内容。 结构一 ### 三级标题 #### 四级标题 A #### 四级标题 B #### 四级标题 C 结构二 ### 三级标题 **（1）A** **（2）B** **（3）C** ","date":"2023-02-04","objectID":"/posts/document-style-guide/:1:2","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"文本 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:2:0","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"字间距 （1）全角中文字符与半角英文字符之间，应有一个半角空格。 错误：本文介绍如何快速启动Windows系统。 正确：本文介绍如何快速启动 Windows 系统。 （2）全角中文字符与半角阿拉伯数字之间，有没有半角空格都可，但必须保证风格统一，不能两种风格混杂。 正确：2011年5月15日，我订购了5台笔记本电脑与10台平板电脑。 正确：2011 年 5 月 15 日，我订购了 5 台笔记本电脑与 10 台平板电脑。 半角的百分号，视同阿拉伯数字。 正确：今年我国经济增长率是6.5%。 正确：今年我国经济增长率是 6.5%。 （3）英文单位若不翻译，单位前的阿拉伯数字与单位符号之间，应留出适当的空隙。 例1：一部容量为 16 GB 的智能手机 例2：1 h = 60 min = 3,600 s （4）半角英文字符和半角阿拉伯数字，与全角标点符号之间不留空格。 错误：他的电脑是 MacBook Air 。 正确：他的电脑是 MacBook Air。 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:2:1","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"句子 （1）避免使用长句。 不包含任何标点符号的单个句子，或者以逗号分隔的句子构件，长度尽量保持在 20 个字以内；20 ～ 29 个字的句子，可以接受；30 ～ 39 个字的句子，语义必须明确，才能接受；多于 40 个字的句子，任何情况下都不能接受。 错误：本产品适用于从由一台服务器进行动作控制的单一节点结构到由多台服务器进行动作控制的并行处理程序结构等多种体系结构。 正确：本产品适用于多种体系结构。无论是由一台服务器（单一节点结构），还是由多台服务器（并行处理结构）进行动作控制，均可以使用本产品。 逗号分割的长句，总长度不应该超过 100 字或者正文的 3 行。 （2）尽量使用简单句和并列句，避免使用复合句。 并列句：他昨天生病了，没有参加会议。 复合句：那个昨天生病的人没有参加会议。 （3）同样一个意思，尽量使用肯定句表达，不使用否定句表达。 错误：请确认没有接通装置的电源。 正确：请确认装置的电源已关闭。 （4）避免使用双重否定句。 错误：没有删除权限的用户，不能删除此文件。 正确：用户必须拥有删除权限，才能删除此文件。 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:2:2","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"写作风格 （1）尽量不使用被动语态，改为使用主动语态。 错误：假如此软件尚未被安装， 正确：假如尚未安装这个软件， （2）不使用非正式的语言风格。 错误：Lady Gaga 的演唱会真是酷毙了，从没看过这么给力的表演！！！ 正确：无法参加本次活动，我深感遗憾。 （3）不使用冷僻、生造或者文言文的词语，而要使用现代汉语的常用表达方式。 错误：这是唯二的快速启动的方法。 正确：这是仅有的两种快速启动的方法。 （4）用对“的”、“地”、“得”。 她露出了开心的笑容。 （形容词＋的＋名词） 她开心地笑了。 （副词＋地＋动词） 她笑得很开心。 （动词＋得＋副词） （5）使用代词时（比如“其”、“该”、“此”、“这”等词），必须明确指代的内容，保证只有一个含义。 错误：从管理系统可以监视中继系统和受其直接控制的分配系统。 正确：从管理系统可以监视两个系统：中继系统和受中继系统直接控制的分配系统。 （6）名词前不要使用过多的形容词。 错误：此设备的使用必须在接受过本公司举办的正式的设备培训的技师的指导下进行。 正确：此设备必须在技师的指导下使用，且指导技师必须接受过由本公司举办的正式设备培训。 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:2:3","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"英文处理 （1）英文原文如果使用了复数形式，翻译成中文时，应该将其还原为单数形式。 英文：...information stored in random access memory (RAMs)... 中文：⋯⋯存储在随机存取存储器（RAM）里的信息⋯⋯ （2）外文缩写可以使用半角圆点(.)表示缩写。 U.S.A. Apple, Inc. （3）表示中文时，英文省略号（...）应改为中文省略号（⋯⋯）。 英文：5 minutes later... 中文：5 分钟过去了⋯⋯ （4）英文书名或电影名改用中文表达时，双引号应改为书名号。 英文：He published an article entitled \"The Future of the Aviation\". 中文：他发表了一篇名为《航空业的未来》的文章。 （5）第一次出现英文词汇时，在括号中给出中文标注。此后再次出现时，直接使用英文缩写即可。 IOC（International Olympic Committee，国际奥林匹克委员会）。这样定义后，便可以直接使用“IOC”了。 （6）专有名词中每个词第一个字母均应大写，非专有名词则不需要大写。 “American Association of Physicists in Medicine”（美国医学物理学家协会）是专有名词，需要大写。 “online transaction processing”（在线事务处理）不是专有名词，不应大写。 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:2:4","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"段落 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:3:0","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"原则 一个段落只能有一个主题，或一个中心句子。 段落的中心句子放在段首，对全段内容进行概述。后面陈述的句子为中心句子服务。 一个段落的长度不能超过七行，最佳段落长度小于等于四行。 段落的句子语气要使用陈述和肯定语气，避免使用感叹语气。 段落之间使用一个空行隔开。 段落开头不要留出空白字符。 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:3:1","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"引用 引用第三方内容时，应注明出处。 One man’s constant is another man’s variable. — Alan Perlis 如果是全篇转载，请在全文开头显著位置注明作者和出处，并链接至原文。 本文转载自 WikiQuote 使用外部图片时，必须在图片下方或文末标明来源。 本文部分图片来自 Wikipedia ","date":"2023-02-04","objectID":"/posts/document-style-guide/:3:2","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"数值 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:4:0","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"半角数字 阿拉伯数字一律使用半角形式，不得使用全角形式。 错误：这件商品的价格是１０００元。 正确：这件商品的价格是 1000 元。 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:4:1","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"千分号 数值为千位以上，应添加千分号（半角逗号）。 XXX 公司的实收资本为 ￥1,258,000 人民币。 对于 4 位的数值，千分号是选用的，比如1000和1,000都可以接受。对于 4 位以上的数值，应添加千分号。 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:4:2","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"货币 货币应为阿拉伯数字，并在数字前写出货币符号，或在数字后写出货币中文名称。 $1,000 1,000 美元 英文的货币名称，建议参考国际标准 ISO 4217。 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:4:3","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"数值范围 表示数值范围时，用波浪线（～）或一字线（—）连接。参见《标点符号》一节的“连接号”部分。 带有单位或百分号时，两个数字建议都要加上单位或百分号。 132 kg～234 kg 67%～89% ","date":"2023-02-04","objectID":"/posts/document-style-guide/:4:4","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"变化程度的表示法 数字的增加要使用“增加了”、“增加到”。“了”表示增量，“到”表示定量。 增加到过去的两倍 （过去为一，现在为二） 增加了两倍 （过去为一，现在为三） 数字的减少要使用“降低了”、“降低到”。“了”表示增量，“到”表示定量。 降低到百分之八十 （定额是一百，现在是八十） 降低了百分之八十 （原来是一百，现在是二十） 不能用“降低 N 倍”或“减少 N 倍”的表示法，要用“降低百分之几”或“减少百分之几”。因为减少（或降低）一倍表示数值原来为一百，现在等于零。 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:4:5","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"标点符号 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:5:0","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"原则 （1）中文语句的标点符号，均应该采取全角符号，这样可以与全角文字保持视觉的一致。 （2）如果整句为英文，则该句使用英文/半角标点。 （3）句号、问号、叹号、逗号、顿号、分号和冒号不得出现在一行之首。 （4）点号（句号、逗号、顿号、分号、冒号）不得出现在标题的末尾，而标号（引号、括号、破折号、省略号、书名号、着重号、间隔号、叹号、问号）可以。 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:5:1","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"句号 （1）中文语句的结尾处应该用全角句号（。）。 （2）句子末尾用括号加注时，句号应在括号之外。 错误：关于文件的输出，请参照第 1.3 节（见第 26 页。） 正确：关于文件的输出，请参照第 1.3 节（见第 26 页）。 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:5:2","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"逗号 （1）逗号（，）表示句子内部的一般性停顿。 （2）注意避免“一逗到底”，即整个段落除了结尾，全部停顿都使用逗号。 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:5:3","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"顿号 （1）句子内部的并列词，应该用全角顿号(、) 分隔，而不用逗号，即使并列词是英语也是如此。 错误：我最欣赏的科技公司有 Google, Facebook, 腾讯, 阿里和百度等。 正确：我最欣赏的科技公司有 Google、Facebook、腾讯、阿里和百度等。 （2）英文句子中，并列词语之间使用半角逗号（,）分隔。 例句：Microsoft Office includes Word, Excel, PowerPoint, Outlook and other components. （3）中文句子内部的并列词，最后一个尽量使用（和）来连接，使句子读起来更加连贯，下面两个句子都可以，第二个更优。 正确：我最欣赏的科技公司有 Google、Facebook、腾讯、阿里，以及百度等。 正确：我最欣赏的科技公司有 Google、Facebook、腾讯、阿里和百度等。 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:5:4","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"分号 （1）分号（；）表示复句内部并列分句之间的停顿。 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:5:5","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"引号 （1）引用时，应该使用全角双引号（“ ”），注意前后双引号不同。 例句：许多人都认为客户服务的核心是“友好”和“专业”。 （2）引号里面还要用引号时，外面一层用双引号，里面一层用单引号（‘ ’），注意前后单引号不同。 例句：鲍勃解释道：“我要放音乐，可萨利说，‘不行！’。” ","date":"2023-02-04","objectID":"/posts/document-style-guide/:5:6","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"括号 （1）补充说明时，使用全角圆括号（（）），括号前后不加空格。 例句：请确认所有的连接（电缆和接插件）均安装牢固。 （2）几种括号的中英文名称。 英文 中文 { } braces 或 curly brackets 大括号 [ ] square brackets 或 brackets 方括号 \u003c \u003e angled brackets 尖括号 ( ) parentheses 圆括号 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:5:7","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"冒号 （1）全角冒号（：）常用在需要解释的词语后边，引出解释和说明。 例句：请确认以下几项内容：时间、地点、活动名称和来宾数量。 （2）表示时间时，应使用半角冒号（:）。 例句：早上 8:00 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:5:8","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"省略号 （1）省略号（⋯⋯）表示语句未完、或者语气的不连续。 （2）省略号占两个汉字空间、包含六个省略点，不要使用。。。或...等非标准形式。 （3）省略号不应与“等”这个词一起使用。 错误：我们为会餐准备了香蕉、苹果、梨…等各色水果。 正确：我们为会餐准备了各色水果，有香蕉、苹果、梨⋯⋯ 正确：我们为会餐准备了香蕉、苹果、梨等各色水果。 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:5:9","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"感叹号 （1）应该使用平静的语气叙述，尽量避免使用感叹号（！）。 （2）不得多个感叹号连用，比如！！和!!!。 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:5:10","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"破折号 （1）破折号————一般用于进一步解释。 （2）破折号应占两个汉字的位置。如果破折号本身只占一个汉字的位置，那么前后应该留出一个半角空格。 例句：直觉————尽管它并不总是可靠的————告诉我，这事可能出了些问题。 例句：直觉 —— 尽管它并不总是可靠的 —— 告诉我，这事可能出了些问题。 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:5:11","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"连接号 （1）连接号用于连接两个类似的词。 （2）以下场合应该使用直线连接号（-），占一个半角字符的位置。 两个名词的复合 图表编号 例句：氧化-还原反应 例句：图 1-1 （3）数值范围（例如日期、时间或数字）应该使用波浪连接号（～）或一字号（—），占一个全角字符的位置。 例句：2009 年～2011 年 注意，波浪连接号前后两个值都建议加上单位。 （4）波浪连接号也可以用汉字“至”代替。 例句：周围温度：-20 °C 至 -10 °C ","date":"2023-02-04","objectID":"/posts/document-style-guide/:5:12","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"文档体系 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:6:0","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"结构 软件手册是一部完整的书，建议采用下面的结构。 简介（Introduction）：[必备] [文件] 提供对产品和文档本身的总体的、扼要的说明 快速上手（Getting Started）：[可选] [文件] 如何最快速地使用产品 入门篇（Basics）：[必备] [目录] 又称“使用篇”，提供初级的使用教程 环境准备（Prerequisite）：[必备] [文件] 软件使用需要满足的前置条件 安装（Installation）：[可选] [文件] 软件的安装方法 设置（Configuration）：[必备] [文件] 软件的设置 进阶篇（Advanced)：[可选] [目录] 又称“开发篇”，提供中高级的开发教程 API（Reference）：[可选] [目录|文件] 软件 API 的逐一介绍 FAQ：[可选] [文件] 常见问题解答 附录（Appendix）：[可选] [目录] 不属于教程本身、但对阅读教程有帮助的内容 Glossary：[可选] [文件] 名词解释 Recipes：[可选] [文件] 最佳实践 Troubleshooting：[可选] [文件] 故障处理 ChangeLog：[可选] [文件] 版本说明 Feedback：[可选] [文件] 反馈方式 下面是两个真实范例，可参考。 Redux 手册 Atom 手册 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:6:1","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"文件名 文档的文件名不得含有空格。 文件名必须使用半角字符，不得使用全角字符。这也意味着，中文不能用于文件名。 错误：名词解释.md 正确：glossary.md 文件名建议只使用小写字母，不使用大写字母。 错误：TroubleShooting.md 正确：troubleshooting.md 为了醒目，某些说明文件的文件名，可以使用大写字母，比如README、LICENSE。 文件名包含多个单词时，单词之间建议使用半角的连词线（-）分隔。 不佳：advanced_usage.md 正确：advanced-usage.md ","date":"2023-02-04","objectID":"/posts/document-style-guide/:6:2","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Spec"],"content":"参考链接 产品手册中文写作规范, by 华为 写作规范和格式规范, by DaoCloud 技术写作技巧在日汉翻译中的应用, by 刘方 简体中文规范指南, by lengoo 文档风格指南, by LeanCloud 豌豆荚文案风格指南, by 豌豆荚 中文文案排版指北, by sparanoid 中文排版需求, by W3C 为什么文件名要小写？, by 阮一峰 Google Developer Documentation Style Guide, by Google 出版物上数字用法的规定（国家标准 GBT15835－2011） GB 3100-1993 国际单位制及其应用 markdownlint, VSCode 插件 pangu.js, 盘古之白系列插件 ","date":"2023-02-04","objectID":"/posts/document-style-guide/:7:0","tags":null,"title":"中文技术文档的写作规范","uri":"/posts/document-style-guide/"},{"categories":["Browser"],"content":"最近在抖音上刷到很多次 袁进老师 的前端视频，然后就听了一下他的前端大师课，感觉了解一些浏览器原理后，原来工作中的一些疑问也自然解开了。 ","date":"2023-01-11","objectID":"/posts/event-loop/:0:0","tags":["Browser","JavaScript"],"title":"浏览器原理 - 事件循环","uri":"/posts/event-loop/"},{"categories":["Browser"],"content":"浏览器的进程模型 ","date":"2023-01-11","objectID":"/posts/event-loop/:1:0","tags":["Browser","JavaScript"],"title":"浏览器原理 - 事件循环","uri":"/posts/event-loop/"},{"categories":["Browser"],"content":"何为进程？ 程序运行需要有它自己专属的内存空间，可以把这块内存空间简单的理解为进程 进程 每个应用至少有一个进程，进程之间相互独立，即使要通信，也需要双方同意。 ","date":"2023-01-11","objectID":"/posts/event-loop/:1:1","tags":["Browser","JavaScript"],"title":"浏览器原理 - 事件循环","uri":"/posts/event-loop/"},{"categories":["Browser"],"content":"何为线程？ 有了进程后，就可以运行程序的代码了。 运行代码的「人」称之为「线程」。 一个进程至少有一个线程，所以在进程开启后会自动创建一个线程来运行代码，该线程称之为主线程。 如果程序需要同时执行多块代码，主线程就会启动更多的线程来执行代码，所以一个进程中可以包含多个线程。 线程 ","date":"2023-01-11","objectID":"/posts/event-loop/:1:2","tags":["Browser","JavaScript"],"title":"浏览器原理 - 事件循环","uri":"/posts/event-loop/"},{"categories":["Browser"],"content":"浏览器有哪些进程和线程？ 浏览器是一个多进程多线程的应用程序，浏览器内部工作极其复杂。 为了避免相互影响，为了减少连环崩溃的几率，当启动浏览器后，它会自动启动多个进程。 浏览器进程 可以在浏览器的任务管理器中查看当前的所有进程 其中，最主要的进程有： 浏览器进程 主要负责界面显示、用户交互、子进程管理等。浏览器进程内部会启动多个线程处理不同的任务。 网络进程 负责加载网络资源。网络进程内部会启动多个线程来处理不同的网络任务。 渲染进程（本篇重点讲解的进程） 渲染进程启动后，会开启一个渲染主线程，主线程负责执行 HTML、CSS、JS 代码。 默认情况下，浏览器会为每个标签页开启一个新的渲染进程，以保证不同的标签页之间不相互影响。 将来该默认模式可能会有所改变，有兴趣的同学可参见 chrome 官方说明文档 ","date":"2023-01-11","objectID":"/posts/event-loop/:1:3","tags":["Browser","JavaScript"],"title":"浏览器原理 - 事件循环","uri":"/posts/event-loop/"},{"categories":["Browser"],"content":"渲染主线程是如何工作的？ 渲染主线程是浏览器中最繁忙的线程，需要它处理的任务包括但不限于： 解析 HTML 解析 CSS 计算样式 布局 处理图层 每秒把页面画 60 次 执行全局 JS 代码 执行事件处理函数 执行计时器的回调函数 …… 思考题：为什么渲染进程不适用多个线程来处理这些事情？ 要处理这么多的任务，主线程遇到了一个前所未有的难题：如何调度任务？ 比如： 我正在执行一个 JS 函数，执行到一半的时候用户点击了按钮，我该立即去执行点击事件的处理函数吗？ 我正在执行一个 JS 函数，执行到一半的时候某个计时器到达了时间，我该立即去执行它的回调吗？ 浏览器进程通知我“用户点击了按钮”，与此同时，某个计时器也到达了时间，我应该处理哪一个呢？ …… 渲染主线程想出了一个绝妙的主意来处理这个问题：排队 消息队列 在最开始的时候，渲染主线程会进入一个无限循环 每一次循环会检查消息队列中是否有任务存在。如果有，就取出第一个任务执行，执行完一个后进入下一次循环；如果没有，则进入休眠状态。 其他所有线程（包括其他进程的线程）可以随时向消息队列添加任务。新任务会加到消息队列的末尾。在添加新任务时，如果主线程是休眠状态，则会将其唤醒以继续循环拿取任务 这样一来，就可以让每个任务有条不紊的、持续的进行下去了。整个过程，被称之为事件循环（消息循环）。 ","date":"2023-01-11","objectID":"/posts/event-loop/:2:0","tags":["Browser","JavaScript"],"title":"浏览器原理 - 事件循环","uri":"/posts/event-loop/"},{"categories":["Browser"],"content":"若干解释 ","date":"2023-01-11","objectID":"/posts/event-loop/:3:0","tags":["Browser","JavaScript"],"title":"浏览器原理 - 事件循环","uri":"/posts/event-loop/"},{"categories":["Browser"],"content":"何为异步？ 代码在执行过程中，会遇到一些无法立即处理的任务，比如： 计时完成后需要执行的任务 —— setTimeout、setInterval 网络通信完成后需要执行的任务 – XHR、Fetch 用户操作后需要执行的任务 – addEventListener 如果让渲染主线程等待这些任务的时机达到，就会导致主线程长期处于「阻塞」的状态，从而导致浏览器「卡死」 同步策略 渲染主线程承担着极其重要的工作，无论如何都不能阻塞！ 因此，浏览器选择异步来解决这个问题 异步策略 使用异步的方式，渲染主线程永不阻塞 面试题：如何理解 JS 的异步？ 参考答案： JS 是一门单线程的语言，这是因为它运行在浏览器的渲染主线程中，而渲染主线程只有一个。 而渲染主线程承担着诸多的工作，渲染页面、执行 JS 都在其中运行。 如果使用同步的方式，就极有可能导致主线程产生阻塞，从而导致消息队列中的很多其他任务无法得到执行。这样一来，一方面会导致繁忙的主线程白白的消耗时间，另一方面导致页面无法及时更新，给用户造成卡死现象。 所以浏览器采用异步的方式来避免。具体做法是当某些任务发生时，比如计时器、网络、事件监听，主线程将任务交给其他线程去处理，自身立即结束任务的执行，转而执行后续代码。当其他线程完成时，将事先传递的回调函数包装成任务，加入到消息队列的末尾排队，等待主线程调度执行。 在这种异步模式下，浏览器永不阻塞，从而最大限度的保证了单线程的流畅运行。 ","date":"2023-01-11","objectID":"/posts/event-loop/:3:1","tags":["Browser","JavaScript"],"title":"浏览器原理 - 事件循环","uri":"/posts/event-loop/"},{"categories":["Browser"],"content":"JS 为何会阻碍渲染？ 先看代码 \u003ch1\u003eMr.Yuan is awesome!\u003c/h1\u003e \u003cbutton\u003echange\u003c/button\u003e \u003cscript\u003e var h1 = document.querySelector('h1'); var btn = document.querySelector('button'); // 死循环指定的时间 function delay(duration) { var start = Date.now(); while (Date.now() - start \u003c duration) {} } btn.onclick = function () { h1.textContent = '袁老师很帅！'; delay(3000); }; \u003c/script\u003e 点击按钮后，会发生什么呢？ \u003c复制代码自行演示\u003e ","date":"2023-01-11","objectID":"/posts/event-loop/:3:2","tags":["Browser","JavaScript"],"title":"浏览器原理 - 事件循环","uri":"/posts/event-loop/"},{"categories":["Browser"],"content":"任务有优先级吗？ 任务没有优先级，在消息队列中先进先出 但消息队列是有优先级的 根据 W3C 的最新解释： 每个任务都有一个任务类型，同一个类型的任务必须在一个队列，不同类型的任务可以分属于不同的队列。 在一次事件循环中，浏览器可以根据实际情况从不同的队列中取出任务执行。 浏览器必须准备好一个微队列，微队列中的任务优先所有其他任务执行 https://html.spec.whatwg.org/multipage/webappapis.html#perform-a-microtask-checkpoint 随着浏览器的复杂度急剧提升，W3C 不再使用宏队列的说法 在目前 chrome 的实现中，至少包含了下面的队列： 微队列：用户存放需要最快执行的任务，优先级「最高」 延时队列：用于存放计时器到达后的回调任务，优先级「中」 交互队列：用于存放用户操作后产生的事件处理任务，优先级「高」 多队列演示图 添加任务到微队列的主要方式主要是使用 Promise、MutationObserver，例如： // 立即把一个函数添加到微队列 Promise.resolve().then(() =\u003e {}); 浏览器还有很多其他的队列，由于和我们开发关系不大，不作考虑。 面试题：阐述一下 JS 的事件循环 参考答案： 事件循环又叫做消息循环，是浏览器渲染主线程的工作方式。 在 Chrome 的源码中，它开启一个不会结束的 for 循环，每次循环从消息队列中取出第一个任务执行，而其他线程只需要在合适的时候将任务加入到队列末尾即可。 过去把消息队列简单分为宏队列和微队列，这种说法目前已无法满足复杂的浏览器环境，取而代之的是一种更加灵活多变的处理方式。 根据 W3C 官方的解释，每个任务有不同的类型，同类型的任务必须在同一个队列，不同的任务可以属于不同的队列。不同任务队列有不同的优先级，在一次事件循环中，由浏览器自行决定取哪一个队列的任务。但浏览器必须有一个微队列，微队列的任务一定具有最高的优先级，必须优先调度执行。 面试题：JS 中的计时器能做到精确计时吗？为什么？ 参考答案： 不行，因为： 计算机硬件没有原子钟，无法做到精确计时 操作系统的计时函数本身就有少量偏差，由于 JS 的计时器最终调用的是操作系统的函数，也就携带了这些偏差 按照 W3C 的标准，浏览器实现计时器时，如果嵌套层级超过 5 层，则会带有 4 毫秒的最少时间，这样在计时时间少于 4 毫秒时又带来了偏差 受事件循环的影响，计时器的回调函数只能在主线程空闲时运行，因此又带来了偏差 ","date":"2023-01-11","objectID":"/posts/event-loop/:3:3","tags":["Browser","JavaScript"],"title":"浏览器原理 - 事件循环","uri":"/posts/event-loop/"},{"categories":["Debug"],"content":"安装 Homebrew 后导致系统中原有的 npm 和 npx 失效的解决办法","date":"2022-12-15","objectID":"/posts/homebrew-npm/","tags":["Homebrew","npm","npx","Mac"],"title":"安装 Homebrew 后导致系统中原有的 npm 和 npx 失效","uri":"/posts/homebrew-npm/"},{"categories":["Debug"],"content":" 问题 前面一段时间，安装了 Homebrew, 但是今天切换 node 版本到 system version (8.10.0) 后，发现虽然 node 版本切换成功，但是 node 版本对应的 npm 和 npx 版本不相符，下面记录一下问题排查过程。 ","date":"2022-12-15","objectID":"/posts/homebrew-npm/:0:0","tags":["Homebrew","npm","npx","Mac"],"title":"安装 Homebrew 后导致系统中原有的 npm 和 npx 失效","uri":"/posts/homebrew-npm/"},{"categories":["Debug"],"content":"罪魁祸首 首先定位到这次问题的根本原因是安装 Homebrew 导致的，这点可以很快也很明确地定位到，因为以前安装 Homebrew 也遇到了这个问题，但是当时的做法是卸载 Homebrew 避免冲突。 ","date":"2022-12-15","objectID":"/posts/homebrew-npm/:1:0","tags":["Homebrew","npm","npx","Mac"],"title":"安装 Homebrew 后导致系统中原有的 npm 和 npx 失效","uri":"/posts/homebrew-npm/"},{"categories":["Debug"],"content":"Why 分析为啥会冲突，Homebrew 安装的工程中也会默认一部分依赖的二进制文件，npm 和 npx 也在其中，所以这导致了 Homebrew 的安装 npm 和 npx 覆盖了系统中 node 的 npm 和 npx 进而导致 node 和 npm 版本不一致，无法使用 npm 启动项目。 ","date":"2022-12-15","objectID":"/posts/homebrew-npm/:2:0","tags":["Homebrew","npm","npx","Mac"],"title":"安装 Homebrew 后导致系统中原有的 npm 和 npx 失效","uri":"/posts/homebrew-npm/"},{"categories":["Debug"],"content":"Where 找一下目前 npm 和 npx 的二进制文件在哪。 nvm use system node -v # 8.10.0 which npm # /opt/homebrew/bin/npm which npx # /opt/homebrew/bin/npx ","date":"2022-12-15","objectID":"/posts/homebrew-npm/:3:0","tags":["Homebrew","npm","npx","Mac"],"title":"安装 Homebrew 后导致系统中原有的 npm 和 npx 失效","uri":"/posts/homebrew-npm/"},{"categories":["Debug"],"content":"How 很明显前面的猜测是对的，那就打开这个目录看看： open /opt/homebrew/bin 找到 npm 和 npx，把他们重命名为 npm-brew 和 npx-brew, 这样通过别名也保留 Homebrew 的 npm 和 npx. 修改完后，重启终端，再看看 npm 和 npx 是否生效： nvm use system node -v # 8.10.0 which npm # /usr/local/bin/npm which npx # /usr/local/bin/npx npm -v npx -v 一切正常了，可以用 npm 继续启动原来的项目了。 ","date":"2022-12-15","objectID":"/posts/homebrew-npm/:4:0","tags":["Homebrew","npm","npx","Mac"],"title":"安装 Homebrew 后导致系统中原有的 npm 和 npx 失效","uri":"/posts/homebrew-npm/"},{"categories":["Go"],"content":"记录 GO 及 Beego 框架安装及基础配置。 ","date":"2022-08-31","objectID":"/posts/beego-install/:0:0","tags":["Beego","Go"],"title":"Beego 安装及配置","uri":"/posts/beego-install/"},{"categories":["Go"],"content":"安装 Go 官网下载安装包：https://golang.google.cn/dl/ 通过二进制文件快速安装，默认安装目录：/usr/local/go 配置环境变量 vim ~/.bash_profile # golang export GOROOT=/usr/local/go export GOBIN=$GOROOT/bin export PATH=$PATH:$GOBIN export GOPATH=$HOME/go export GOPROXY=https://goproxy.cn # Go work bin export PATH=$PATH:$GOPATH/bin ","date":"2022-08-31","objectID":"/posts/beego-install/:1:0","tags":["Beego","Go"],"title":"Beego 安装及配置","uri":"/posts/beego-install/"},{"categories":["Go"],"content":"安装 Beego Beego repository Beego docs Beego new docs Beego 的安装需要在新建项目且 go mod init \u003cmodule_name\u003e之后，在项目下执行，具体参考 beego#quick-start。 ","date":"2022-08-31","objectID":"/posts/beego-install/:2:0","tags":["Beego","Go"],"title":"Beego 安装及配置","uri":"/posts/beego-install/"},{"categories":["Go"],"content":"安装 bee bee repository 注意：arm64 架构的 mac (M1 ～系列)，下载安装 bee 时最好，使用 Rosetta 打开终端，不然无法下载 darwin_arm64 的依赖，如果已经安装了，可以使用 Rosetta 打开终端后，运行 bee update 升级，升级完后将终端复原。 bee 工具安装，go install 安裝指定版本的 bee 工具，例如： go install github.com/beego/bee/v2@latest 安装成功后，可以在 $GOPATH/bin 下看到 bee 的可执行文件。 检验 bee 工具是否安装成功： bee version 创建一个新的 Beego 项目 bee new hello cd hello go mod tidy bee run ","date":"2022-08-31","objectID":"/posts/beego-install/:3:0","tags":["Beego","Go"],"title":"Beego 安装及配置","uri":"/posts/beego-install/"},{"categories":["Spec"],"content":" 摘要 版本格式：MAJOR.MINOR.PATCH，版本号递增规则如下： MAJOR: 主版本号，当你做了不兼容的 API 修改 MINOR: 次版本号，当你做了向下兼容的功能性新增 PATCH: 修订号，当你做了向下兼容的问题修正 先行版本号及版本编译信息可以加到 MAJOR.MINOR.PATCH 的后面，作为延伸。 ","date":"2022-08-13","objectID":"/posts/semver/:0:0","tags":["SemVer"],"title":"语义版本控制（SemVer）","uri":"/posts/semver/"},{"categories":["Spec"],"content":"格式 基本的语法格式如下，更多请参考 Backus–Naur Form Grammar for Valid SemVer Versions \u003cvalid semver\u003e ::= \u003cversion core\u003e | \u003cversion core\u003e \"-\" \u003cpre-release\u003e | \u003cversion core\u003e \"+\" \u003cbuild\u003e | \u003cversion core\u003e \"-\" \u003cpre-release\u003e \"+\" \u003cbuild\u003e 范例： 代码状态 等级 规则 版本样例 首次发布 新品发布 以 1.0.0 开始 1.0.0 bug 修复，向后兼容 补丁版本发布 变更第三位数字 1.0.1 新功能，向后兼容 次版本发布 变更第二位数字，并且第三位数字重置为 0 1.1.0 重大变更，不向后兼容 主版本发布 变更第一位数字，并且第二位，第三位数字重置为 0 2.0.0 “v1.2.3” 是一个语义化版本号吗？ “v1.2.3” 并不是的一个语义化的版本号。 但是，在语义化版本号之前增加前缀 “v” 是用来表示版本号的常用做法。 在版本控制系统中，将 “version” 缩写为 “v” 是很常见的。 比如：git tag v1.2.3 -m \"Release version 1.2.3\" 中，标签是 “v1.2.3”，语义化版本号是 “1.2.3”。 ","date":"2022-08-13","objectID":"/posts/semver/:1:0","tags":["SemVer"],"title":"语义版本控制（SemVer）","uri":"/posts/semver/"},{"categories":["Spec"],"content":"规范 以下关键词 MUST、MUST NOT、REQUIRED、SHALL、SHALL NOT、SHOULD、SHOULD NOT、 RECOMMENDED、MAY、OPTIONAL 依照 RFC 2119 的叙述解读。 语义化版本控制规范（SemVer） 使用语义化版本控制的软件必须（MUST）定义公共 API。该 API 可以在代码中被定义或出现于严谨的文档内。无论何种形式都应该力求精确且完整。 标准的版本号必须（MUST）采用 X.Y.Z 的格式，其中 X、Y 和 Z 为非负的整数，且禁止（MUST NOT）在数字前方补零。X 是主版本号、Y 是次版本号、而 Z 为修订号。每个元素必须（MUST）以数值来递增。例如：1.9.1 -\u003e 1.10.0 -\u003e 1.11.0。 标记版本号的软件发行后，禁止（MUST NOT）改变该版本软件的内容。任何修改都必须（MUST）以新版本发行。 主版本号为零（0.y.z）的软件处于开发初始阶段，一切都可能随时被改变。这样的公共 API 不应该被视为稳定版。 1.0.0 的版本号用于界定公共 API 的形成。这一版本之后所有的版本号更新都基于公共 API 及其修改内容。 修订号 Z（x.y.Z | x \u003e 0）必须（MUST）在只做了向下兼容的修正时才递增。这里的修正指的是针对不正确结果而进行的内部修改。 次版本号 Y（x.Y.z | x \u003e 0）必须（MUST）在有向下兼容的新功能出现时递增。在任何公共 API 的功能被标记为弃用（deprecated）时也必须（MUST）递增。也可以（MAY）在内部程序有大量新功能或改进被加入时递增，其中可以（MAY）包括修订级别的改变。每当次版本号递增时，修订号必须（MUST）归零。 主版本号 X（X.y.z | X \u003e 0）必须（MUST）在有任何不兼容的修改被加入公共 API 时递增。其中可以（MAY）包括次版本号及修订级别的改变。每当主版本号递增时，次版本号和修订号必须（MUST）归零。 先行版本号可以（MAY）被标注在修订版之后，先加上一个连接号再加上一连串以句点分隔的标识符来修饰。标识符必须（MUST）由 ASCII 字母数字和连接号 [0-9A-Za-z-] 组成，且禁止（MUST NOT）留白。数字型的标识符禁止（MUST NOT）在前方补零。先行版的优先级低于相关联的标准版本。被标上先行版本号则表示这个版本并非稳定而且可能无法满足预期的兼容性需求。范例：1.0.0-alpha、1.0.0-alpha.1、1.0.0-0.3.7、1.0.0-x.7.z.92。 版本编译信息可以（MAY）被标注在修订版或先行版本号之后，先加上一个加号再加上一连串以句点分隔的标识符来修饰。标识符必须（MUST）由 ASCII 字母数字和连接号 [0-9A-Za-z-] 组成，且禁止（MUST NOT）留白。当判断版本的优先层级时，版本编译信息可（SHOULD）被忽略。因此当两个版本只有在版本编译信息有差别时，属于相同的优先层级。范例：1.0.0-alpha+001、1.0.0+20130313144700、1.0.0-beta+exp.sha.5114f85。 版本的优先层级指的是不同版本在排序时如何比较。 判断优先层级时，必须（MUST）把版本依序拆分为主版本号、次版本号、修订号及先行版本号后进行比较（版本编译信息不在这份比较的列表中）。 由左到右依序比较每个标识符，第一个差异值用来决定优先层级：主版本号、次版本号及修订号以数值比较。 例如：1.0.0 \u003c 2.0.0 \u003c 2.1.0 \u003c 2.1.1。 当主版本号、次版本号及修订号都相同时，改以优先层级比较低的先行版本号决定。 例如：1.0.0-alpha \u003c 1.0.0。 有相同主版本号、次版本号及修订号的两个先行版本号，其优先层级必须（MUST）透过由左到右的每个被句点分隔的标识符来比较，直到找到一个差异值后决定： 只有数字的标识符以数值高低比较。 有字母或连接号时则逐字以 ASCII 的排序来比较。 数字的标识符比非数字的标识符优先层级低。 若开头的标识符都相同时，栏位比较多的先行版本号优先层级比较高。 例如：1.0.0-alpha \u003c 1.0.0-alpha.1 \u003c 1.0.0-alpha.beta \u003c 1.0.0-beta \u003c 1.0.0-beta.2 \u003c 1.0.0-beta.11 \u003c 1.0.0-rc.1 \u003c 1.0.0 ","date":"2022-08-13","objectID":"/posts/semver/:2:0","tags":["SemVer"],"title":"语义版本控制（SemVer）","uri":"/posts/semver/"},{"categories":["Spec"],"content":"版本阶段 Base: 设计阶段，只有相应的设计没有具体的功能实现 Alpha: 软件的初级版本，基本功能已经实现，但存在较多的 bug Bate: 相对于 Alpha 已经有了很大的进步，消除了严重的 BUG，但还存在一些潜在的 BUG，还需要不断测试 RC: 该版本已经相当成熟了，基本上不存在导致错误的 Bug，与即将发行的正式版本相差无几 RELEASE: 最终发布版本，没有太大的问题 最终发布版本（RELEASE）之前的所有版本，都称为先行版本（pre-release）。 ","date":"2022-08-13","objectID":"/posts/semver/:3:0","tags":["SemVer"],"title":"语义版本控制（SemVer）","uri":"/posts/semver/"},{"categories":["Spec"],"content":"FAQ ","date":"2022-08-13","objectID":"/posts/semver/:4:0","tags":["SemVer"],"title":"语义版本控制（SemVer）","uri":"/posts/semver/"},{"categories":["Spec"],"content":"其他相关 ","date":"2022-08-13","objectID":"/posts/semver/:5:0","tags":["SemVer"],"title":"语义版本控制（SemVer）","uri":"/posts/semver/"},{"categories":["Spec"],"content":"npm SemVer 通常我们发布一个包到 npm 仓库时，我们的做法是先修改 package.json 为某个版本，然后执行 npm publish 命令。手动修改版本号的做法建立在你对 SemVer 规范特别熟悉的基础之上，否则可能会造成版本混乱。npm 和 yarn 两个包管理都提供了 SemVer 规范的版本控制命令： npm-version yarn version npm 发包基础命令： # 1. 创建一个新的包 npm init # 2. 查看是否官方源 npm config get registry # 3. 登录 npm login # 4. 发布 npm publish # 版本变化 major.minor.patch npm version patch # 升级补丁版本 npm version minor # 升级小版号 npm version major # 升级大版号 # 下架 [-force] npm unpublish 全局设置版本号前缀 # https://docs.npmjs.com/cli/v8/using-npm/config#tag-version-prefix npm config set tag-version-prefix \"\" # 全局设置版本更新 commit 提交信息 # https://docs.npmjs.com/cli/v8/using-npm/config#message npm config set message \"Chore(release): %s\" 或者设置项目的 .npmrc 或者 .yarnrc # .npmrc tag-version-prefix=\"\" message=\"Chore(release): %s\" # .yarnrc version-tag-prefix \"\" version-git-message \"Chore(release): %s\" package.json 版本控制规则使用了一些些符号： ^ ~ \u003e \u003e= \u003c \u003c= = - || 这些规则的详情如下： ^: 只会执行不更改最左边非零数字的更新。 如果写入的是 ^0.13.0，则当运行 npm update 时，可以更新到 0.13.1、0.13.2 等，但不能更新到 0.14.0 或更高版本。 如果写入的是 ^1.13.0，则当运行 npm update 时，可以更新到 1.13.1、1.14.0 等，但不能更新到 2.0.0 或更高版本。 ~: 如果写入的是 〜0.13.0，则当运行 npm update 时，会更新到补丁版本：即 0.13.1 可以，但 0.14.0 不可以。 \u003e: 接受高于指定版本的任何版本。 \u003e=: 接受等于或高于指定版本的任何版本。 \u003c=: 接受等于或低于指定版本的任何版本。 \u003c: 接受低于指定版本的任何版本。 =: 接受确切的版本。 -: 接受一定范围的版本。例如：2.1.0 - 2.6.2。 ||: 组合集合。例如 \u003c 2.1 || \u003e 2.6。 可以合并其中的一些符号，例如 1.0.0 || \u003e=1.1.0 \u003c1.2.0，即使用 1.0.0 或从 1.1.0 开始但低于 1.2.0 的版本。 还有其他的规则： 无符号：仅接受指定的特定版本（例如 1.2.1）。 latest: 使用可用的最新版本。 ","date":"2022-08-13","objectID":"/posts/semver/:5:1","tags":["SemVer"],"title":"语义版本控制（SemVer）","uri":"/posts/semver/"},{"categories":["Spec"],"content":"版本保留 对于大型软件，每个版本都有使用价值时，应保留所有历史版本 对于始终以最新版本为准的软件，则可保留至少最近的 10 个次版本 ","date":"2022-08-13","objectID":"/posts/semver/:5:2","tags":["SemVer"],"title":"语义版本控制（SemVer）","uri":"/posts/semver/"},{"categories":["Spec"],"content":"参考 Semantic Versioning 2.0.0 使用 npm 的语义版本控制 ","date":"2022-08-13","objectID":"/posts/semver/:6:0","tags":["SemVer"],"title":"语义版本控制（SemVer）","uri":"/posts/semver/"},{"categories":["Spec","Git"],"content":"Commit messages are short descriptions of changes to a repository. We should follow certain standards to effectively describe changes, such as the Conventional Commits specification based on the Angular convention that is most used on GitHub, or each development team can simplify and formulate their own commit specification. This is not only conducive to the automatic generation of Changelog in the later stage, but more importantly, when a bug occurs, the entire warehouse can be quickly checked, the problem point can be accurately located, and the version can be reverted. ","date":"2022-08-12","objectID":"/posts/commit-spec/:0:0","tags":["Git"],"title":"Commit Message Spec","uri":"/posts/commit-spec/"},{"categories":["Spec","Git"],"content":"Format [{emoji} ]{type}[({module})]: {subject within 50 words}[ (#{issue/pull request})] example: 🎉 Feat: add shortcode fixit-encryptor shortcode (#123) ⬆️ Chore(libs): update Artalk from 2.2.12 to 2.3.4 (#150) ","date":"2022-08-12","objectID":"/posts/commit-spec/:1:0","tags":["Git"],"title":"Commit Message Spec","uri":"/posts/commit-spec/"},{"categories":["Spec","Git"],"content":"Emoji https://gitmoji.dev vscode plugin utools plugin GitEmoji ","date":"2022-08-12","objectID":"/posts/commit-spec/:2:0","tags":["Git"],"title":"Commit Message Spec","uri":"/posts/commit-spec/"},{"categories":["Spec","Git"],"content":"Message Emoji Type Example Description (No Ambiguous) 🎉 ✨ Feat Feat: add {feature} new feature 🚚 Feat: adjust/migrate {feature name}, {change details} For the adjustment feature, it is necessary to describe the current situation (before) and after adjustment (after) 🔥 Feat: delete {feature name}, {deletion reason} If the feature is deleted, the reason for deletion must be explained 🐛 🚧 🚨 Fix Fix: fix {bug description} Fix known bugs 🎨 💄 ✏️ Style Style: Typesetting/CSS style {optimizing content} Changes that do not affect code operation, such as code layout and style change ♻️ Refactor Refactor: override {feature name} It is neither a new function nor a code change to fix a bug. Simply rewriting the code of a function does not affect the function result ⚡ Perf Perf: improve performance {function name}, {improve content} Optimize code performance ⏪ Revert Revert: restore version {commit message of restore version} Restore the version of one commit 📝 ✏️ Docs Docs: revise comments/update documents Adjustment of documents and notes 🔧 Chore Chore: update plugin version Changes in the construction process or auxiliary tools ","date":"2022-08-12","objectID":"/posts/commit-spec/:3:0","tags":["Git"],"title":"Commit Message Spec","uri":"/posts/commit-spec/"},{"categories":["JavaScript"],"content":"总结一下最近 electron 开发遇到的问题和一些重要知识点。 ","date":"2022-08-12","objectID":"/posts/electron-summary/:0:0","tags":["electron"],"title":"electron 踩坑总结","uri":"/posts/electron-summary/"},{"categories":["JavaScript"],"content":"简介 如果你可以建一个网站，你就可以建一个桌面应用程序。 Electron 是一个使用 JavaScript, HTML 和 CSS 等 Web 技术创建原生程序的开源框架，它负责比较难搞的部分，你只需把精力放在你的应用的核心上即可。 ","date":"2022-08-12","objectID":"/posts/electron-summary/:1:0","tags":["electron"],"title":"electron 踩坑总结","uri":"/posts/electron-summary/"},{"categories":["JavaScript"],"content":"知识点 ","date":"2022-08-12","objectID":"/posts/electron-summary/:2:0","tags":["electron"],"title":"electron 踩坑总结","uri":"/posts/electron-summary/"},{"categories":["JavaScript"],"content":"进程 electron 由两种进程组成，包括主进程和 0 个或 n 个渲染进程。 主进程：承担应用的生命周期（包括启动，退出，准备，正在切换到后台，正在切换到前台等，还负责与原生操作系统 API 通信） 渲染进程：做 web 页面的 ui，渲染进程之间独立在各自的单线程，渲染进程之间相互隔离，不能直接访问操作系统，需要通信到主线程，在通过主线程操作访问操作形态，一个 BrowserWindow 实例即为一个渲染进程 ","date":"2022-08-12","objectID":"/posts/electron-summary/:2:1","tags":["electron"],"title":"electron 踩坑总结","uri":"/posts/electron-summary/"},{"categories":["JavaScript"],"content":"技术栈 electron 整合了 Node 和浏览器的所有能力，可以随意发挥这些技术栈的特点。由于固定浏览器内核，可以无需考虑兼容性地使用 html/js/css 新特性。 ","date":"2022-08-12","objectID":"/posts/electron-summary/:2:2","tags":["electron"],"title":"electron 踩坑总结","uri":"/posts/electron-summary/"},{"categories":["JavaScript"],"content":"安装 安装 electron 时，可能因为网络问题导致下载失败，需要使用镜像仓库来下载。 # 设置 electron 镜像仓库 # https://registry.npmmirror.com/-/binary/electron # 13.1.7 版本 下载链接可能会拼错导致 404，要设置成 https://registry.npmmirror.com/-/binary/electron/v npm config set electron_mirror=https://npmmirror.com/mirrors/electron/ M1 Mac 安装较低版本 electron 时可能会报错，Failed to find Electron v xxx for darwin-arm64，因为这些版本的 electron 不支持 darwin-arm64 架构。Apple 针对未适配的 X64 应用提供了 Rosetta2 转换器，安装 darwin-x64 版本的 electron 在 Intel 模式下运行即可，参考。 ","date":"2022-08-12","objectID":"/posts/electron-summary/:2:3","tags":["electron"],"title":"electron 踩坑总结","uri":"/posts/electron-summary/"},{"categories":["JavaScript"],"content":"remote 不要频繁使用 remote, 更多应该手动进行和主进程之间的通信。 使用时需在窗口创建时设置 webPreferences.enableRemoteModule 为 true。 旧版本的 electron.remote 已经弃用，应该使用依赖 electron/remote 代替。 使用了旧版本的 remote 时会有控制台警告信息： (electron) The remote module is deprecated. Use https://github.com/electron/remote instead. 获取当前窗口：remote.getCurrentWindow() ","date":"2022-08-12","objectID":"/posts/electron-summary/:2:4","tags":["electron"],"title":"electron 踩坑总结","uri":"/posts/electron-summary/"},{"categories":["JavaScript"],"content":"问题点 ","date":"2022-08-12","objectID":"/posts/electron-summary/:3:0","tags":["electron"],"title":"electron 踩坑总结","uri":"/posts/electron-summary/"},{"categories":["JavaScript"],"content":"打开外部浏览器 electron 的 shell 模块，可以使用 shell.openExternal(url) 在默认浏览器打开链接。 ","date":"2022-08-12","objectID":"/posts/electron-summary/:3:1","tags":["electron"],"title":"electron 踩坑总结","uri":"/posts/electron-summary/"},{"categories":["JavaScript"],"content":"防抖与节流 防抖：短期内大量触发事件时，只执行最后一次。 function debounce(fn) { let timer = null; return function () { clearTimeOut(timer); timer = setTimeOut(() =\u003e { fn.applay(this, arguments); }, 300); }; } 节流：短期内大量触发事件时，只执行第一次。 function throttle(fn) { let timer = null; return function () { if (timer) return; timer = setTimeOut(() =\u003e { fn.applay(this, arguments); timer = null; }, 300); }; } ","date":"2022-08-12","objectID":"/posts/electron-summary/:3:2","tags":["electron"],"title":"electron 踩坑总结","uri":"/posts/electron-summary/"},{"categories":["JavaScript"],"content":"devTools 初始化窗口时设置 webPreferences.devTools 为 true，然后通过 mainWindow.webContents.openDevTools() 打开开发者工具。 如果只在开发环境启用开发者工具，则需要设置 webPreferences.devTools 为 process.env.NODE_ENV === 'development' ","date":"2022-08-12","objectID":"/posts/electron-summary/:3:3","tags":["electron"],"title":"electron 踩坑总结","uri":"/posts/electron-summary/"},{"categories":["JavaScript"],"content":"启动白屏 在创建窗口时设置 show: false，在 ready-to-show 事件之后执行 mainWindow.show()， 可见官方文档 优雅地显示窗口。 启动前 loading 额外创建一个 loading 窗口，该窗口可设置为透明只包含 loading 图标和文字，在 mainWindow.show() 后关闭。 启动后 loading 如果使用了 Vue 框架，在 Vue 初始化之前窗口虽然出现了，但是内容时空白的，可以在 Vue 实例 #app 里写一个 loading, Vue 加载完后会覆盖掉。 \u003cdiv id=\"app\"\u003e \u003c!-- Display the loading icon and text until Vue initialization is complete --\u003e \u003cstyle type=\"text/css\"\u003e html, body { height: 100%; margin: 0; } body { display: flex; } #app { margin: auto; display: flex; align-items: center; } @media (prefers-color-scheme: dark) { body { color: #fff; background-color: #202124; } } \u003c/style\u003e \u003csvg xmlns=\"http://www.w3.org/2000/svg\" style=\"margin:auto;background:0 0\" width=\"60\" height=\"60\" viewBox=\"0 0 100 100\" preserveAspectRatio=\"xMidYMid\" display=\"block\" \u003e \u003ccircle cx=\"50\" cy=\"50\" r=\"20\" stroke-width=\"4\" stroke=\"#a5a5a5\" stroke-dasharray=\"31.416 31.416\" fill=\"none\" stroke-linecap=\"round\" transform=\"rotate(67.21 50 50)\" \u003e \u003canimateTransform attributeName=\"transform\" type=\"rotate\" repeatCount=\"indefinite\" dur=\"1s\" keyTimes=\"0;1\" values=\"0 50 50;360 50 50\" /\u003e \u003c/circle\u003e \u003c/svg\u003e \u003cspan\u003e加载中 ...\u003c/span\u003e \u003c/div\u003e ","date":"2022-08-12","objectID":"/posts/electron-summary/:3:4","tags":["electron"],"title":"electron 踩坑总结","uri":"/posts/electron-summary/"},{"categories":["JavaScript"],"content":"阻止窗口关闭 可以在关闭前一些事件里做拦截，比如：onbeforeunload 等，详见 实例事件。 ","date":"2022-08-12","objectID":"/posts/electron-summary/:3:5","tags":["electron"],"title":"electron 踩坑总结","uri":"/posts/electron-summary/"},{"categories":["JavaScript"],"content":"手动关闭窗口 当自定义关闭时，使用 mainWindow.destroy() 来关闭窗口，因为使用 mainWindow.close() 时，windows 系统打开开发者工具时会出现无法关闭窗口的情况。 ","date":"2022-08-12","objectID":"/posts/electron-summary/:3:6","tags":["electron"],"title":"electron 踩坑总结","uri":"/posts/electron-summary/"},{"categories":["JavaScript"],"content":"全局快捷键 当 electron 版本较低时，比如 13.1.7，会出现在 mac 系统上复制粘贴等常用快捷键失效的问题。可通过设置菜单并绑定快捷键的方式解决。 const main = [ { label: '', submenu: [ { label: '关于', role: 'about' }, { label: '关闭', role: 'close' }, { label: '退出', role: 'quit' } ] }, { label: '编辑', submenu: [ { label: '撤销', role: 'undo' }, { label: '恢复', role: 'redo' }, { type: 'separator' }, { label: '剪切', role: 'cut' }, { label: '复制', role: 'copy' }, { label: '粘贴', role: 'paste' }, { type: 'separator' }, { label: '全选', role: 'selectAll' } ] } ]; const dev = [ { label: '开发者', submenu: [ { label: '刷新', role: 'reload' }, { label: '强制刷新', role: 'forcereload' }, { type: 'separator' }, { label: '开发者工具', role: 'toggledevtools' } ] } ]; if (process.env.NODE_ENV === 'development') { main.push(...dev); } export default main; import memuConfig from './menu'; import { Menu } from 'electron'; if (process.platform === 'darwin') { const menu = Menu.buildFromTemplate(memuConfig); Menu.setApplicationMenu(menu); } ","date":"2022-08-12","objectID":"/posts/electron-summary/:3:7","tags":["electron"],"title":"electron 踩坑总结","uri":"/posts/electron-summary/"},{"categories":["JavaScript"],"content":"electron-builder 下载时，可能因为网络问题导致下载失败，可设置 GitHub 下载镜像。 # GitHub 仓库下载地址前缀镜像 # disturl=https://registry.npmmirror.com/-/binary/ 或者去 GitHub 手动下载，然后解压到缓存目录： macOS: ~/Library/Caches/electron-builder/ linux: ~/.cache/electron-builder/ windows: %LOCALAPPDATA%\\electron-builder\\cache\\ mac 上缓存目录如下，其他可 参考 ▸ nsis/ ▸ nsis-resources-3.4.1/ ▸ nsis-3.0.4.1/ ▸ winCodeSign/ ▸ winCodeSign-2.6.0/ ▸ wine/ ▸ wine-4.0.1-mac/ windows 打包 windows 系统打包配置，当没有配置签名时，sign 字段应删除或者配置为 null，否则可能导致打包时报错。 { \"win\": { \"icon\": \"static/icons/icon.ico\", \"verifyUpdateCodeSignature\": false, \"target\": \"nsis\", \"sign\": null } } 注：win11 打包在 win10 上可能运行不了，最好使用 win10 打包或者 mac 打包指定系统和位数。 macOS 打包 问题：mac 升级之后 electron 打包报错 Exit code: ENOENT. spawn /usr/bin/python ENOENT 解决：网上搜到的下载 python 2.7 是治标不治本，正确做法是升级 electron-builder 到 23.0.2 或更高版本，参考 electron-builder#6726 参考链接 Electron-Mac 应用的签名步骤说明 ","date":"2022-08-12","objectID":"/posts/electron-summary/:3:8","tags":["electron"],"title":"electron 踩坑总结","uri":"/posts/electron-summary/"},{"categories":["JavaScript"],"content":"记录一下前端实现页面加密的思路。 ","date":"2022-08-08","objectID":"/posts/encryption-fe/:0:0","tags":["JavaScript","加密"],"title":"前端页面内容加密总结","uri":"/posts/encryption-fe/"},{"categories":["JavaScript"],"content":"加密基础知识 ","date":"2022-08-08","objectID":"/posts/encryption-fe/:1:0","tags":["JavaScript","加密"],"title":"前端页面内容加密总结","uri":"/posts/encryption-fe/"},{"categories":["JavaScript"],"content":"双向加密 可还原的加密算法，可以逆向解密。 对称加密（单密钥加密） 采用单钥密码系统的加密方法，同一个密钥同时用作信息的加密和解密。 密钥生成算法有 DES、3DES、AES。 非对称加密（公开密钥系统） 两个密钥：公开密钥（publickey）和私有密钥（privatekey）。 公钥/私钥加密/签名，用私钥/公钥解密/验证签名。 密钥生成算法有 RSA（公钥、私钥）、DSA（公钥、私钥、数字签名）。 ","date":"2022-08-08","objectID":"/posts/encryption-fe/:1:1","tags":["JavaScript","加密"],"title":"前端页面内容加密总结","uri":"/posts/encryption-fe/"},{"categories":["JavaScript"],"content":"单向加密 不可还原的加密算法（暴力撞库除外），常见的算法有：MD5、SHA1、SHA256、SHA512。 ","date":"2022-08-08","objectID":"/posts/encryption-fe/:1:2","tags":["JavaScript","加密"],"title":"前端页面内容加密总结","uri":"/posts/encryption-fe/"},{"categories":["JavaScript"],"content":"页面内容加密 内容加密算法 通过比对密码和输入的 md5 值来判断密码是否输入正确 密码验证通过后，开始解密内容 拿到正确的输入值的 sha256 值的部分内容 然后按照加密规则解秘内容 这里利用 Set 进行事件管理，简单模拟了 addEventListener 和 removeEventListener 的操作。并提供了两个事件：decrypted 和 reset，详见 fixit-decryptor.js。 ","date":"2022-08-08","objectID":"/posts/encryption-fe/:2:0","tags":["JavaScript","加密"],"title":"前端页面内容加密总结","uri":"/posts/encryption-fe/"},{"categories":["Node.js","JavaScript"],"content":" 问题 腾讯云云函数从 2022 年 6 月 1 日开始收费了，差不多每个月 12 块，对于可能几个月都用不上一次云函数刷新缓存的人来说，有点太贵了。 使用 Node.js 和 GitHub Actions 刷新 CDN 的方式，可以节省不少钱。 ","date":"2022-08-07","objectID":"/posts/qcloudcdn/:0:0","tags":["CDN","GitHub Actions","Node.js"],"title":"Node.js + GitHub Actions 自动刷新 CDN","uri":"/posts/qcloudcdn/"},{"categories":["Node.js","JavaScript"],"content":"安装依赖 npm install qcloud-cdn-node-sdk ","date":"2022-08-07","objectID":"/posts/qcloudcdn/:1:0","tags":["CDN","GitHub Actions","Node.js"],"title":"Node.js + GitHub Actions 自动刷新 CDN","uri":"/posts/qcloudcdn/"},{"categories":["Node.js","JavaScript"],"content":"编写脚本 vim .scripts/qcloudcdn.js /** * Refresh Qcloud CDN cache * @command `node qcloudcdn.js $SECRET_ID $SECRET_KEY` */ const qcloudSDK = require('qcloud-cdn-node-sdk'); // Get the config from https://console.qcloud.com/capi qcloudSDK.config({ secretId: process?.argv[2], secretKey: process?.argv[3] }); qcloudSDK.request( 'RefreshCdnDir', { // See https://cloud.tencent.com/document/api/228/3947 'dirs.0': 'https://lruihao.cn/' }, (res) =\u003e { res.code \u0026\u0026 console.log(res); } ); ","date":"2022-08-07","objectID":"/posts/qcloudcdn/:2:0","tags":["CDN","GitHub Actions","Node.js"],"title":"Node.js + GitHub Actions 自动刷新 CDN","uri":"/posts/qcloudcdn/"},{"categories":["Node.js","JavaScript"],"content":"增加快捷指令 打开 package.json 增加 scripts: { \"scripts\": { \"qcloudcdn\": \"node .scripts/qcloudcdn.js $SECRET_ID $SECRET_KEY\" } } 运行方式： SECRET_ID=\u003csecretId\u003e SECRET_KEY=\u003csecretKey\u003e npm run qcloudcdn Mac OS 环境变量配置（可选） vim ~/.bash_profile # Qcloud secret key-value export SECRET_ID=\u003csecretId\u003e export SECRET_KEY=\u003csecretKey\u003e source ~/.bash_profile 然后，在本地可简化指令为 npm run qcloudcdn 或者 yarn qcloudcdn。 等同于 SECRET_ID=$SECRET_ID SECRET_KEY=$SECRET_KEY npm run qcloudcdn ","date":"2022-08-07","objectID":"/posts/qcloudcdn/:3:0","tags":["CDN","GitHub Actions","Node.js"],"title":"Node.js + GitHub Actions 自动刷新 CDN","uri":"/posts/qcloudcdn/"},{"categories":["Node.js","JavaScript"],"content":"配置 GitHub Actions 在原有 GitHub Actions 中部署后增加一个步骤： - name: Refresh Qcloud CDN cache env: SECRET_ID: ${{ secrets.SECRET_ID }} SECRET_KEY: ${{ secrets.SECRET_KEY }} run: npm run qcloudcdn 在仓库 Settings \u003e Secrets \u003e Actions 中增加两个 Secret: SECRET_ID 和 SECRET_KEY，原来有配置过的就不用了，比如，我原来的叫 COS_SECRET_ID 和 COS_SECRET_ID，那修改上面配置 env 中的变量名即可。 最后上传代码，以后更新仓库时就会自动刷新 CDN 缓存了。 ","date":"2022-08-07","objectID":"/posts/qcloudcdn/:4:0","tags":["CDN","GitHub Actions","Node.js"],"title":"Node.js + GitHub Actions 自动刷新 CDN","uri":"/posts/qcloudcdn/"},{"categories":["Node.js","JavaScript"],"content":"参考资料 Qcloud_CDN_API/nodejs 本方案使用的旧的 API 请求方式，如果失效，可以参考新的 API，见 SDK 中心。 ","date":"2022-08-07","objectID":"/posts/qcloudcdn/:5:0","tags":["CDN","GitHub Actions","Node.js"],"title":"Node.js + GitHub Actions 自动刷新 CDN","uri":"/posts/qcloudcdn/"},{"categories":["OS"],"content":"换行符（通常称为行尾、行尾 (EOL)、下一行 (NEL) 或换行符）是字符编码规范（例如，ASCII、EBCDIC）中的控制字符或控制字符序列，用于表示一行文本的结尾和新文本的开头。 周五下班的时候想在 windows 电脑上跑一下 FixIt 看看有没有什么 bug, 然后就发现了 typyit shortcode 开头多出一行空行，mermaid shortcode 则直接语法报错了。 看了一下代码明明有 trim \\n 处理，而且 Vercel 打包和 Mac 上运行打包都没问题。debug 了一下才发现 Windows 系统上的换行是 \\r\\n, 而 Mac 系统上的换行是 \\n。于是查了一下不同系统的换行符的差异问题。 ","date":"2022-08-07","objectID":"/posts/newline/:0:0","tags":["newline"],"title":"不同系统的换行符的差异","uri":"/posts/newline/"},{"categories":["OS"],"content":"历史 简单来说，回车换行这些说法是从打字机那个时代开始叫的，然后在不同的标准下换行符有不同的表现符号。 Windows 系统设计遵循了 CR + LF 的约定，而 Unix 系统则遵循了 LF 的约定，之后的 类 Unix (Linux, macOS) 系统也遵循了 LF 的约定。 当然也有异类，老版的 mac 系统使用 CR 作为换行符。 ","date":"2022-08-07","objectID":"/posts/newline/:1:0","tags":["newline"],"title":"不同系统的换行符的差异","uri":"/posts/newline/"},{"categories":["OS"],"content":"表示 CR 回车：\\r LF 换行：\\n 操作系统 换行符号 Windows \\r\\n Unix、Linux、MacOS \\n classic Mac OS \\r ","date":"2022-08-07","objectID":"/posts/newline/:2:0","tags":["newline"],"title":"不同系统的换行符的差异","uri":"/posts/newline/"},{"categories":["OS"],"content":"问题 由于这个差异，会导致文本类的文件在跨系统浏览时会产生一些差异，比如说，Mac 的文本文件在 Windows 打开会全部挤在一行等等。 对于开发人员来说，这很有可能导致某些程序失效，比如正则去除空行等等。 甚至因此，Linux 系统下提供有两个命令用来进行 Windows 和 Unix 文件的转化：dos2unix和 unix2dos。 ","date":"2022-08-07","objectID":"/posts/newline/:3:0","tags":["newline"],"title":"不同系统的换行符的差异","uri":"/posts/newline/"},{"categories":["OS"],"content":"参考 Newline ","date":"2022-08-07","objectID":"/posts/newline/:4:0","tags":["newline"],"title":"不同系统的换行符的差异","uri":"/posts/newline/"},{"categories":["Grocery"],"content":"ohmyzsh 自带了很多主题，也有很多没有收录的扩展主题，我就想要个简约的主题，但是每个都差点意思，干脆改一个主题。 ","date":"2022-07-31","objectID":"/posts/ohmyzsh-custom/:0:0","tags":null,"title":"自定义 ohmyzsh 主题","uri":"/posts/ohmyzsh-custom/"},{"categories":["Grocery"],"content":"自定义主题 复制默认主题，当作模板： cd ~/.oh-my-zsh cat themes/robbyrussell.zsh-theme \u003e custom/custom.zsh-theme vim custom/custom.zsh-theme 然后修改里面的内容： if [[ -z $ZSH_THEME_CUSTOM_PREFIX ]]; then ZSH_THEME_CUSTOM_PREFIX=\"\u003e\" fi PROMPT=\"%(?:%{$fg_bold[blue]%}$ZSH_THEME_CUSTOM_PREFIX:%{$fg_bold[red]%}$ZSH_THEME_CUSTOM_PREFIX)\" PROMPT+=' %{$fg[blue]%}%c%{$reset_color%} $(git_prompt_info)' ZSH_THEME_GIT_PROMPT_PREFIX=\"%{$fg_bold[green]%}git:(%{$fg[magenta]%}\" ZSH_THEME_GIT_PROMPT_SUFFIX=\"%{$reset_color%} \" ZSH_THEME_GIT_PROMPT_DIRTY=\"%{$fg[green]%}) %{$fg[yellow]%}✗\" ZSH_THEME_GIT_PROMPT_CLEAN=\"%{$fg[green]%})\" ","date":"2022-07-31","objectID":"/posts/ohmyzsh-custom/:1:0","tags":null,"title":"自定义 ohmyzsh 主题","uri":"/posts/ohmyzsh-custom/"},{"categories":["Grocery"],"content":"配置 vim ~/.zshrc ZSH_THEME=custom 然后重启终端即可。 ","date":"2022-07-31","objectID":"/posts/ohmyzsh-custom/:2:0","tags":null,"title":"自定义 ohmyzsh 主题","uri":"/posts/ohmyzsh-custom/"},{"categories":["OS"],"content":"记录 linux 系统下文件权限相关的内容，Mac OS 下类似。 ","date":"2022-07-30","objectID":"/posts/linux-permission/:0:0","tags":["linux","Mac","他山之石"],"title":"linux 文件权限","uri":"/posts/linux-permission/"},{"categories":["OS"],"content":"查看文件权限 查看 linux 系统下的文件权限，可以使用 ll 命令或者 ls 命令 带 -l（长列表选项） ➜ ~ ll total 160 drwx------@ 8 liruihao staff 256B Jul 5 14:47 Applications drwx------@ 10 liruihao staff 320B Jul 27 11:31 Desktop drwx------+ 7 liruihao staff 224B Jun 17 15:01 Documents drwx------@ 22 liruihao staff 704B Jul 29 16:35 Downloads drwx------@ 94 liruihao staff 2.9K Jul 23 19:02 Library drwx------ 4 liruihao staff 128B Nov 13 2021 Movies drwx------+ 6 liruihao staff 192B Nov 18 2021 Music drwx------+ 9 liruihao staff 288B Apr 26 10:25 Pictures drwxr-xr-x+ 5 liruihao staff 160B Nov 14 2021 Public drwxr-xr-x 5 liruihao staff 160B Jul 29 17:48 file-share drwxr-xr-x 3 liruihao staff 96B Jul 26 17:17 node_modules -rw-r--r-- 1 liruihao staff 27B Jun 24 13:47 package-lock.json drwxr-xr-x 20 liruihao staff 640B Jul 29 22:20 workspace -rw-r--r-- 1 liruihao staff 86B Jul 26 17:17 yarn.lock 文件列表信息分为：文件类型、权限、链接数、所属用户、所属用户组、文件大小、最后修改时间、文件名。 ","date":"2022-07-30","objectID":"/posts/linux-permission/:1:0","tags":["linux","Mac","他山之石"],"title":"linux 文件权限","uri":"/posts/linux-permission/"},{"categories":["OS"],"content":"文件类型 linux 一共有 7 种文件类型，分别如下： -: 普通文件 d: 目录文件 l: 链接文件 b: 块设备文件 p: 管道文件 c: 字符设备文件 s: 套接口文件/数据接口文件 后四种是特殊文件 ","date":"2022-07-30","objectID":"/posts/linux-permission/:2:0","tags":["linux","Mac","他山之石"],"title":"linux 文件权限","uri":"/posts/linux-permission/"},{"categories":["OS"],"content":"文件权限对应关系 权限 含义 对应数字 r 读权限 4 w 写权限 2 x 执行权限 1 读、写、运行三项权限用数字表示就是 r=4,w=2,x=1。所以，-rw-r--r-- 用数字表示成 644。 权限字段 -rwxrwxrwx 的内容总共会有 10 个 -，第一个表示文件类型，如该文件是文件 (-表示），文件夹 (d 表示）, 连接文件 (l 表示），后面 9 个按照每三位为一组分。 drwxr-xr-x 5 liruihao staff 160B Jul 29 17:48 file-share d: 代表文件夹 rwx: 代表文件所有者 (u 表示）权限，这里是 liruihao，liruihao 对该文件拥有读写执行权限。 r-x: 代表所属（g 表示）的权限，这里同组用户拥有对该文件读和执行的权限。 r-x: 代表其他用户（o 表示）的权限，这里和上面权限一样。 ","date":"2022-07-30","objectID":"/posts/linux-permission/:3:0","tags":["linux","Mac","他山之石"],"title":"linux 文件权限","uri":"/posts/linux-permission/"},{"categories":["Memo"],"content":"记录一下使用 Mac 作为生产工具开发的一些基本配置和经验。 ","date":"2022-07-29","objectID":"/posts/config4mac/:0:0","tags":["Git","Mac","Node.js"],"title":"Mac 上的开发配置总结","uri":"/posts/config4mac/"},{"categories":["Memo"],"content":"配置文件 Mac 上有很多配置文件都可以用来保存环境变量等配置，根据自己的理解记录了四个文件的用途： # etc/profile 系统配置文件 # etc/.bash_profile 系统环境变量配置 # ~/.bash_profile 个人环境变量配置 # ~/.zshrc zsh 的配置文件 # $ZSH_CUSTOM/*.zsh 自定义 zsh 脚本，在 zsh 启动时会自动执行 编辑最多的应该是 ~/.bash_profile 和 ~/.zshrc, 基本上建议所有的个人配置都放在 ~/.bash_profile 中，然后在 ~/.zshrc 最后执行 source ~/.bash_profile, 这样也方便将自己的个人环境变量配置备份。 ","date":"2022-07-29","objectID":"/posts/config4mac/:1:0","tags":["Git","Mac","Node.js"],"title":"Mac 上的开发配置总结","uri":"/posts/config4mac/"},{"categories":["Memo"],"content":"常用命令 # 安装/卸载 homebrew install.sh/uninstall.sh /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\" # 注意：安装 Homebrew 会下载 node, 请做好 node 环境被破坏的准备 # 显示隐藏文件 true/false or cmd+shift+. defaults write com.apple.finder AppleShowAllFiles -boolean true ; killall Finder # 释放端口 lsof -i:$your_port # 1. 查看使用端口进程 kill -9 $your_PID # 2. 释放进程 ","date":"2022-07-29","objectID":"/posts/config4mac/:2:0","tags":["Git","Mac","Node.js"],"title":"Mac 上的开发配置总结","uri":"/posts/config4mac/"},{"categories":["Memo"],"content":"Node # 设置阿里镜像 npm config set registry=https://registry.npmmirror.com # npm config set registry https://registry.npmjs.org # GitHub 仓库下载地址前缀镜像 # disturl=https://registry.npmmirror.com/-/binary/ # 全局安装的依赖 npm install -g npm@8.13.1 npm install -g cnpm npm install -g @vue/cli npm install -g nvm npm install -g nrm npm install -g yarn npm install -g yrm # npm 参数 --ignore-scripts # 忽略脚本错误 --force # 会无视冲突，并强制获取远端 npm 库资源，即使本地有资源也会覆盖掉 --legacy-peer-deps # 安装时忽略所有 peerDependencies，忽视依赖冲突，采用 npm 版本 4 到版本 6 的样式去安装依赖，已有的依赖不会覆盖 # 清除缓存 npm cache clean --force rm -rf node_modules rm -rf package-lock.json npm install # nvm nvm alias default [node_version] # 设置默认版本 # 检查过时依赖 npm outdated # 安全更新 npm update # ncu 更新检查工具 # https://blog.51cto.com/u_13028258/5115637?b=totalstatistic npm install -g npm-check-updates ## 检查 ncu ncu vue ## 更新 ncu -u ncu -u vue electron 相关配置 # 设置 electron 镜像仓库 # https://registry.npmmirror.com/-/binary/electron # 13.1.7 版本 下载链接可能会拼错导致 404，要设置成 https://registry.npmmirror.com/-/binary/electron/v npm config set electron_mirror=https://npmmirror.com/mirrors/electron/ ","date":"2022-07-29","objectID":"/posts/config4mac/:3:0","tags":["Git","Mac","Node.js"],"title":"Mac 上的开发配置总结","uri":"/posts/config4mac/"},{"categories":["Memo"],"content":"SourceTree Custom actions Script target: /bin/bash Parameters: /Users/liruihao/workspace/.shell/sync_tags.sh 技巧 根据不同的 shell 程序选择不同的文件后缀名，并给文件增加可执行权限： zsh: .zsh bash: .sh #! /bin/bash # 同步远程仓库标签分支脚本 git tag -l | xargs git tag -d # git fetch origin --prune # git fetch origin --tags git fetch origin --prune --prune-tags #! /bin/bash # 同步所有子模组 git submodule update --remote --merge #! /bin/zsh # ssh 配置但无法连接时 ssh-agent -s ssh-add ~/.ssh/Lruihao-Github # 私钥路径 技巧 开机启动时系统会去自动读取 id_rsa 的私钥来启动 SSH 链接，若不是默认命令就会失败需要手动执行上诉命令启动，可添加到开机自启动。 SourceTree 相关文章 解决 SourceTree 提交时候 husky 命令失败问题 ","date":"2022-07-29","objectID":"/posts/config4mac/:4:0","tags":["Git","Mac","Node.js"],"title":"Mac 上的开发配置总结","uri":"/posts/config4mac/"},{"categories":["Memo"],"content":"Terminal Terminal: 系统自带 Shell: zsh 美化: ohmyzsh 修改启动语 vim $PREFIX/etc/motd ","date":"2022-07-29","objectID":"/posts/config4mac/:5:0","tags":["Git","Mac","Node.js"],"title":"Mac 上的开发配置总结","uri":"/posts/config4mac/"},{"categories":["Memo"],"content":"sublime-text 3 # Terminal 启用 sublime 别名 subl ## 1.设置软链（推荐） sudo ln -s \"/Applications/Sublime Text.app/Contents/SharedSupport/bin/subl\" /usr/local/bin/subl ## 2.设置别名 vim ~/.bash_profile alias subl=\"'/Applications/Sublime Text.app/Contents/SharedSupport/bin/subl'\" source ~/.bash_profile # 每打开一个命令窗口，需要先让命令生效 ","date":"2022-07-29","objectID":"/posts/config4mac/:6:0","tags":["Git","Mac","Node.js"],"title":"Mac 上的开发配置总结","uri":"/posts/config4mac/"},{"categories":["Memo"],"content":"开机自启动 系统偏好设置 -\u003e 用户与群组 -\u003e 登录项 -\u003e 增删可执行文件 (需配置默认启动软件) 将 shell 命令添加到 /System/Library/StartupItems/ 或 /Library/StartupItems/ 文件夹（测试无效） ","date":"2022-07-29","objectID":"/posts/config4mac/:7:0","tags":["Git","Mac","Node.js"],"title":"Mac 上的开发配置总结","uri":"/posts/config4mac/"},{"categories":["Memo"],"content":"备份 # ------------------------------------- # This configuration is for Lruihao. # https://lruihao.cn/posts/config4mac/ # ------------------------------------- export LC_ALL=en_US.UTF-8 export LANG=en_US.UTF-8 # workspace export WORKSPACE=\"$HOME/workspace\" # alias alias subl=\"'/Applications/Sublime Text.app/Contents/SharedSupport/bin/subl'\" alias mysql=/usr/local/mysql/bin/mysql alias mysqladmin=/usr/local/mysql/bin/mysqladmin alias incr=\"source $WORKSPACE/.shell/incr*.zsh\" alias typora=\"open -a typora\" # maven export M2_HOME=$HOME/Applications/apache-maven-3.8.5 export PATH=$PATH:$M2_HOME/bin # jenv export PATH=\"$HOME/.jenv/bin:$PATH\" eval \"$(jenv init -)\" # java export JAVA_8_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_321.jdk/Contents/Home export JAVA_17_HOME=/Library/Java/JavaVirtualMachines/jdk-17.0.2.jdk/Contents/Home export JAVA_HOME=$JAVA_8_HOME # 设置一个中间变量，为了方便多个 JDK 版本时更换 JAVA_HOME export PATH=$JAVA_HOME/bin:$PATH:. # 冒号前代表 JDK 目录下的 bin 目录，冒号后代表当前目录 export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar # jmeter export JMETER_HOME=$HOME/jmeter/apache-jmeter-5.4.1 export PATH=$JAVA_HOME/bin:$PATH:.:$JMETER_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JMETER_HOME/lib/ext/ApacheJMeter_core.jar:$JMETER_HOME/lib/jorphan.jar:$JMETER_HOME/lib/logkit-2.0.jar # platform-tools of Android SDK export PATH=$PATH:$HOME/Applications/platform-tools # Electron-Mac app development export CSC_LINK=$WORKSPACE/mac_app_dev/Mac.p12 export CSC_KEY_PASSWORD=xxxxxxxxx # yarn export PATH=\"$HOME/.yarn/bin:$HOME/.config/yarn/global/node_modules/.bin:$PATH\" # zsh custom plugin # https://mimosa-pudica.net/zsh-incremental.html # source $WORKSPACE/.shell/incr*.zsh # Qcloud secret key-value export SECRET_ID=\"\" export SECRET_KEY=\"\" # golang export GOROOT=/usr/local/go export GOBIN=$GOROOT/bin export PATH=$PATH:$GOBIN export GOPATH=$HOME/go export GOPROXY=https://goproxy.cn # Go work bin export PATH=$PATH:$GOPATH/bin # sass_embedded export PATH=$PATH:$HOME/Applications/sass_embedded # https://github.com/nvm-sh/nvm#manual-install export NVM_DIR=\"$HOME/.nvm\" [ -s \"$NVM_DIR/nvm.sh\" ] \u0026\u0026 \\. \"$NVM_DIR/nvm.sh\" # This loads nvm [ -s \"$NVM_DIR/bash_completion\" ] \u0026\u0026 \\. \"$NVM_DIR/bash_completion\" # This loads nvm bash_completion # https://github.com/nvm-sh/nvm#deeper-shell-integration autoload -U add-zsh-hook load-nvmrc() { local node_version=\"$(nvm version)\" local nvmrc_path=\"$(nvm_find_nvmrc)\" if [ -n \"$nvmrc_path\" ]; then local nvmrc_node_version=$(nvm version \"$(cat \"${nvmrc_path}\")\") if [ \"$nvmrc_node_version\" = \"N/A\" ]; then nvm install elif [ \"$nvmrc_node_version\" != \"$node_version\" ]; then nvm use fi elif [ \"$node_version\" != \"$(nvm version default)\" ]; then echo \"Reverting to nvm default version\" nvm use default fi # fix husky hook # ref: https://github.com/typicode/husky/issues/390#issuecomment-762213421 echo \"export PATH=\\\"$(dirname $(which node)):\\$PATH\\\"\" \u003e ~/.huskyrc } add-zsh-hook chpwd load-nvmrc load-nvmrc # https://github.com/nvm-sh/nvm#use-a-mirror-of-node-binaries export NVM_NODEJS_ORG_MIRROR=https://mirrors.ustc.edu.cn/node/ 先添加一些基础配置 basic.vim \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" \" =\u003e Custom config for Lruihao \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\" \" Enable mouse set mouse=a \" Enable line-number set number ","date":"2022-07-29","objectID":"/posts/config4mac/:8:0","tags":["Git","Mac","Node.js"],"title":"Mac 上的开发配置总结","uri":"/posts/config4mac/"},{"categories":["Memo"],"content":"作为非安卓专业开发，无需下载 Android SDK， 仅下载 Android SDK 中的 platform-tools 命令行工具即可，并配置好环境变量。 ","date":"2022-07-05","objectID":"/posts/adb-for-mac/:0:0","tags":["Android","ADB"],"title":"Mac 配置 ADB","uri":"/posts/adb-for-mac/"},{"categories":["Memo"],"content":"安装 platform-tools ","date":"2022-07-05","objectID":"/posts/adb-for-mac/:1:0","tags":["Android","ADB"],"title":"Mac 配置 ADB","uri":"/posts/adb-for-mac/"},{"categories":["Memo"],"content":"配置环境变量 open .bash_profile 写入以下内容 # platform-tools of Android SDK export PATH=$PATH:$HOME/Applications/platform-tools source .bash_profile Windows 系统打开高级设置，配置 PATH 变量，增加一条路径即可。 ","date":"2022-07-05","objectID":"/posts/adb-for-mac/:2:0","tags":["Android","ADB"],"title":"Mac 配置 ADB","uri":"/posts/adb-for-mac/"},{"categories":["Memo"],"content":"ADB 命令 通过 USB 连接手机和电脑，执行以下命令 # 1. 打开手机 tcpip 5555 端口 adb tcpip 5555 # 2. 查看手机网络 IP adb shell ifconfig # 3. 在电脑上 ping 手机网络 IP # 4. adb connect [Android IP] Android 调试桥 (adb) awesome-adb ","date":"2022-07-05","objectID":"/posts/adb-for-mac/:3:0","tags":["Android","ADB"],"title":"Mac 配置 ADB","uri":"/posts/adb-for-mac/"},{"categories":["Memo"],"content":"注意 windows 系统下的文件（夹）命名所采用的是 GBK 编码，而 linux 是采用的 UTF-8 编码，使用 adb 的 push 和 pull 命令时由于编码方式的不同会产生错误，因此需要修改 adb 的源代码来支持编码转换。 ","date":"2022-07-05","objectID":"/posts/adb-for-mac/:4:0","tags":["Android","ADB"],"title":"Mac 配置 ADB","uri":"/posts/adb-for-mac/"},{"categories":["JavaScript"],"content":" 前言 前端框架轮替变化越来越快，JavaScript 也在不断地升级迭代，越来越多的新特性让我们的代码写起来变得简洁有趣。 每隔一段时间就该重新认识一下 JS，这篇文章会介绍 6 种新特性，一起研究一下吧。 ","date":"2022-05-01","objectID":"/posts/js-rediscover/:0:0","tags":["JavaScript","ES6"],"title":"重新认识 JavaScript","uri":"/posts/js-rediscover/"},{"categories":["JavaScript"],"content":"数组方法 some, every, find, filter, map 共同点：这几个方法都不会改变原始数组。 some some() 方法测试数组中是不是至少有 1 个元素通过了被提供的函数测试，它返回一个布尔值。 数组中有至少一个元素通过回调函数的测试就会返回 true，所有元素都没有通过回调函数的测试返回值才会为 false。 arr.some(callback(element[, index[, array]])[, thisArg]) [2, 5, 8, 1, 4].some((x) =\u003e x \u003e 10); // false [12, 5, 8, 1, 4].some((x) =\u003e x \u003e 10); // true 技巧 some() 不会对空数组进行检测，空数组返回 false every 助记：every() 和 some() 功能相反 every() 方法测试一个数组内的所有元素是否都能通过某个指定函数的测试，它返回一个布尔值。 如果回调函数的每一次返回都为 truthy 值，返回 true ，否则返回 false。 arr.every(callback(element[, index[, array]])[, thisArg]) [12, 5, 8, 130, 44].every((x) =\u003e x \u003e= 10); // false [12, 54, 18, 130, 44].every((x) =\u003e x \u003e= 10); // true 技巧 every() 不会对空数组进行检测，空数组返回 true Find 助记：功能和 some() 类似，some() 返回布尔值，find() 返回找到的元素 find() 方法返回数组中满足提供的测试函数的第一个元素的值，否则返回 undefined。 arr.find(callback[, thisArg]) const array1 = [5, 12, 8, 130, 44]; const found = array1.find((element) =\u003e element \u003e 10); console.log(found); // expected output: 12 引用 另请参见 findIndex() 方法，它返回数组中找到的元素的索引，而不是其值。 如果你需要找到一个元素的位置或者一个元素是否存在于数组中，使用 Array.prototype.indexOf() 或 Array.prototype.includes()。 filter 助记：如字面意思，它是一个筛子，会筛选出满足条件的元素 filter() 方法创建一个新数组，其包含通过所提供函数实现的测试的所有元素。 返回值是一个新的、由通过测试的元素组成的数组，如果没有任何数组元素通过测试，则返回空数组。 var newArray = arr.filter(callback(element[, index[, array]])[, thisArg]) const words = ['spray', 'limit', 'elite', 'exuberant', 'destruction', 'present']; const result = words.filter((word) =\u003e word.length \u003e 6); console.log(result); // expected output: Array [\"exuberant\", \"destruction\", \"present\"] map 助记：功能和 filter() 类似，filter() 返回筛选的元素，map() 返回筛选的结果值 map() 方法创建一个新数组，这个新数组由原数组中的每个元素都调用一次提供的函数后的返回值组成。 返回值是一个新的、由通过测试的元素组成的数组，如果没有任何数组元素通过测试，则返回空数组。 var new_array = arr.map(function callback(currentValue[, index[, array]]) { // Return element for new_array }[, thisArg]) const array1 = [1, 4, 9, 16]; // pass a function to map const map1 = array1.map((x) =\u003e x * 2); console.log(map1); // expected output: Array [2, 8, 18, 32] ","date":"2022-05-01","objectID":"/posts/js-rediscover/:1:0","tags":["JavaScript","ES6"],"title":"重新认识 JavaScript","uri":"/posts/js-rediscover/"},{"categories":["JavaScript"],"content":"使用 Object.hasOwn 替代 in 操作符 有时，我们想知道对象上是否存在某个属性，一般会使用 in 操作符或 obj.hasOwnProperty，但它们都有各自的缺陷。 in 如果指定的属性位于对象或其原型链中，in 运算符将返回 true。 const Person = function (age) { this.age = age; }; Person.prototype.name = 'fatfish'; const p1 = new Person(24); console.log('age' in p1); // true console.log('name' in p1); // true 注意这里 obj.hasOwnProperty hasOwnProperty 方法会返回一个布尔值，表示对象自身属性中是否具有对应的值（原型链上的属性不会读取）。 const Person = function (age) { this.age = age; }; Person.prototype.name = 'fatfish'; const p1 = new Person(24); console.log(p1.hasOwnProperty('age')); // true console.log(p1.hasOwnProperty('name')); // fasle 注意这里 obj.hasOwnProperty 已经可以过滤掉原型链上的属性，但在某些情况下，它还是不安全。 Object.create(null).hasOwnProperty('name'); // Uncaught TypeError: Object.create(...).hasOwnProperty is not a function Object.hasOwn 别急，我们可以使用 Object.hasOwn 来避免这两个问题，这比 obj.hasOwnProperty 方法更加方便、安全。 let object = { age: 24 }; Object.hasOwn(object, 'age'); // true let object3 = Object.create(null); Object.hasOwn(object3, 'age'); // false ","date":"2022-05-01","objectID":"/posts/js-rediscover/:2:0","tags":["JavaScript","ES6"],"title":"重新认识 JavaScript","uri":"/posts/js-rediscover/"},{"categories":["JavaScript"],"content":"使用 “#” 声明私有属性 以前，我们一般用 _ 表示私有属性，但它并不靠谱，还是会被外部修改。 class Person { constructor(name) { this._money = 1; this.name = name; } get money() { return this._money; } set money(money) { this._money = money; } showMoney() { console.log(this._money); } } const p1 = new Person('fatfish'); console.log(p1.money); // 1 console.log(p1._money); // 1 p1._money = 2; // 依旧可以从外部修改_money 属性，所以这种做法并不安全 console.log(p1.money); // 2 console.log(p1._money); // 2 使用 # 实现真正私有属性 class Person { #money = 1; constructor(name) { this.name = name; } get money() { return this.#money; } set money(money) { this.#money = money; } showMoney() { console.log(this.#money); } } const p1 = new Person('fatfish'); console.log(p1.money); // 1 // p1.#money = 2 // 没法从外部直接修改 p1.money = 2; console.log(p1.money); // 2 console.log(p1.#money); // Uncaught SyntaxError: Private field '#money' must be declared in an enclosing class ","date":"2022-05-01","objectID":"/posts/js-rediscover/:3:0","tags":["JavaScript","ES6"],"title":"重新认识 JavaScript","uri":"/posts/js-rediscover/"},{"categories":["JavaScript"],"content":"有用的数字分隔符 可以使用 _ 分隔数字，当然也可以用于计算 // ✅ 更加易于阅读 const newSixBillion = 6000_000_000; // ❌ 难以阅读 const originSixBillion = 6000000000; console.log(newSixBillion === originSixBillion); // expected output: true const sum = 1000 + 6000_000_000; // expected output: 6000001000 技巧 另外，我们写时间时，24*60*60*1000 的可读性也是远大于 86400000 的。 ","date":"2022-05-01","objectID":"/posts/js-rediscover/:4:0","tags":["JavaScript","ES6"],"title":"重新认识 JavaScript","uri":"/posts/js-rediscover/"},{"categories":["JavaScript"],"content":"“?.”, “??”, “??=” 的使用 可选链 ?. 以前我们为了简化 if else，通常会写出这样的代码 const obj = null; console.log(obj \u0026\u0026 obj.name); const $title = document.querySelector('.title'); const title = $title ? title.innerText : undefined; 使用 ?. 简化 \u0026\u0026 和三元运算符 const obj = null; console.log(obj?.name); const $title = document.querySelector('.title'); const title = $title?.innerText; 空值合并运算符 ?? 之前给变量赋默认值时，我们一般会用 || 来写，比如 let foo = 1; let bar = foo || 2; console.log(bar); // 1 let foo = 0; let bar = foo || 2; console.log(bar); // 2 注意这里 所以，|| 有时候并不是很安全，所以我们不得不加判断 let foo = 0; let bar = foo !== undefined ? foo : 2; console.log(bar); // 0 现在使用 ?? 可以使代码更加优雅 let foo = 1; let bar = foo ?? 2; console.log(bar); // 1 let foo = 0; let bar = foo ?? 2; console.log(bar); // 0 空值赋值运算符 ??= let foo = 0; foo ??= 2; console.log(foo); // 0 let foo = 1; foo ??= 2; console.log(foo); // 1 很好理解，这里的 foo ??= 2 等价于 foo = foo ?? 2 ","date":"2022-05-01","objectID":"/posts/js-rediscover/:5:0","tags":["JavaScript","ES6"],"title":"重新认识 JavaScript","uri":"/posts/js-rediscover/"},{"categories":["JavaScript"],"content":"使用 BigInt 支持大数计算 JS 中超过 Number.MAX_SAFE_INTEGER 的数字计算将是不安全的。 Example: Math.pow(2, 53) === Math.pow(2, 53) + 1; // true // Math.pow(2, 53) =\u003e 9007199254740992 // Math.pow(2, 53) + 1 =\u003e 9007199254740992 使用 BigInt 完全可以避免这个问题 BigInt(Math.pow(2, 53)) === BigInt(Math.pow(2, 53)) + BigInt(1); // false // BigInt(Math.pow(2, 53)) =\u003e 9007199254740992n // BigInt(Math.pow(2, 53)) + BigInt(1) =\u003e 9007199254740993n 要创建一个 BigInt，可以在一个整数的末尾添加字符n，或者调用函数 BigInt()。 let foo = BigInt(1); // 1n let bar = BigInt(2); // 2n console.log(foo \u003e bar); // false console.log(1n \u003e 2n); // false 学无止境，与未来的自己共勉 ","date":"2022-05-01","objectID":"/posts/js-rediscover/:6:0","tags":["JavaScript","ES6"],"title":"重新认识 JavaScript","uri":"/posts/js-rediscover/"},{"categories":["CSS"],"content":"关于 CSS 和 Scss 变量运算那些事","date":"2022-04-30","objectID":"/posts/css-scss-var/","tags":["CSS","Scss"],"title":"关于 CSS 和 Scss 变量运算那些事","uri":"/posts/css-scss-var/"},{"categories":["CSS"],"content":"问题分析 昨天在开发 FixIt 的时候，在 Scss 中写 max(foo, bar) 函数比较不同的单位变量时报错了，但是在 CSS 中使用 max 或者 min 函数函数比较不同的单位变量是没有问题的。 造成这一问题的原因是，在 Scss 中，也实现了 max 和 min 函数，但是在 Scss 中，不同单位的变量是不能进行运算的，所以使得在 Scss 中直接使用 max 或者 min 函数会提示单位不同的报错。（同类 Less 中的变量运算是支持不同单位的） 知道造成问题的原因后，解决这个问题就很简单了，有很多种方法，有些方法感觉像在卡 BUG，有点意思，记录一下。 ","date":"2022-04-30","objectID":"/posts/css-scss-var/:1:0","tags":["CSS","Scss"],"title":"关于 CSS 和 Scss 变量运算那些事","uri":"/posts/css-scss-var/"},{"categories":["CSS"],"content":"奇思淫技 由于 Scss 区分大小写而 CSS 不区分，所以为了不让 Scss 中的函数覆盖 CSS 的函数，我们可以使用除了 max 以外的 23 - 1 种写法，这样就能使用原生 CSS 的 max 函数来比较了，就不会报错了。 .foo { padding-left: MAX(10vh, 3.5rem); } 使用 Scss 没有的 CSS 函数 clamp: clamp(MIN, VAL, MAX) 其实就是表示 max(MIN, min(VAL, MAX)) .foo { padding-left: clamp($header-height, 10vh, 10vh); } 使用 unquote($string) 函数让 Scss 删除字符串最前和最后的单引号或双引号 .foo { padding-left: unquote('max(10vh, #{$header-height})'); } ","date":"2022-04-30","objectID":"/posts/css-scss-var/:2:0","tags":["CSS","Scss"],"title":"关于 CSS 和 Scss 变量运算那些事","uri":"/posts/css-scss-var/"},{"categories":["CSS"],"content":"By the way 如果需要在 CSS 函数内部恢复 Scss 解析（引用 Scss 变量），只需用 #{...} 包围 Scss 代码。 $header-height: 3.5rem !default; .foo { margin: calc(10vh - $header-height); } 上面的 Scss 将解析成 以下无效的 CSS 代码： .foo { margin: calc(10vh - $header-height); } 用 #{...} 包围 Scss 变量 $header-height: 3.5rem !default; .foo { margin: calc(10vh - #{$header-height}); } ","date":"2022-04-30","objectID":"/posts/css-scss-var/:3:0","tags":["CSS","Scss"],"title":"关于 CSS 和 Scss 变量运算那些事","uri":"/posts/css-scss-var/"},{"categories":["Memo"],"content":" 插件地址 https://github.com/robinchenyu/imagepaste ","date":"2021-10-05","objectID":"/posts/subl_imgpaste2/:0:0","tags":["Markdown","Sublime"],"title":"Sublime 剪贴板图片粘贴插件 —— Markdown 必备","uri":"/posts/subl_imgpaste2/"},{"categories":["Memo"],"content":"功能 支持 Windows/Linux 系统下，实现对剪切板图像的处理调用 (Ctrl+Shift+V) 默认使用 JPG 的方式保存，可以显著减小图片的存储体积。 对剪切板图像保存到本地并在 Markdown 文本中插入链接地址 对剪切板中的图像地址，直接插入到 Markdown 文本中 ","date":"2021-10-05","objectID":"/posts/subl_imgpaste2/:1:0","tags":["Markdown","Sublime"],"title":"Sublime 剪贴板图片粘贴插件 —— Markdown 必备","uri":"/posts/subl_imgpaste2/"},{"categories":["Memo"],"content":"食用说明 首先下载 zip 到本地，放到 sublime 安装目录的 xxx\\sublime\\Data\\Packages 中，注意不是 xxx\\sublime\\Packages 下哦。 记得要把 subl_imgpaste2-master 的 -master 删除掉。接着重新打开 sublime, 选择 Preferences-\u003ePackage Settings-\u003eImaPaste2-\u003esettings-Default 输入如下内容： { \"caption\": \"ImagePaste: Paste Image From Clipboard\", \"command\": \"image_paste\", \"image_dir_name\": \"images/\" # 图片保存目录 } 然后就可以愉快的使用截图，然后在 sublime 里使用 ctrl+shift+v 粘贴 Markdown 格式的图片。默认会自动根据 md 文件名在同级目录下新建文件夹，图片就默认保存在那。如图： VScode 也有更好用的插件：Past Image \"pasteImage.defaultName\": \"YY_X\", \"pasteImage.path\": \"${currentFileDir}/images/\" ","date":"2021-10-05","objectID":"/posts/subl_imgpaste2/:2:0","tags":["Markdown","Sublime"],"title":"Sublime 剪贴板图片粘贴插件 —— Markdown 必备","uri":"/posts/subl_imgpaste2/"},{"categories":["Memo"],"content":" 卡片式链接已整合到 FixIt 主题 https://github.com/Lruihao/FixIt 回顧 之前在使用 hexo 的時候也有用到，模仿知乎卡片式链接 和之前的相比，優化之前是后加載，由 JS 在 瀏覽器處理， 使用 shortcodes 方式后，則是在 GO 構建頁面的時候處理，效能上會好很多。 ","date":"2021-10-05","objectID":"/posts/hugo-cardlink/:0:0","tags":["Shortcodes","hugo"],"title":"Hugo 添加知乎卡片式链接 Shortcodes","uri":"/posts/hugo-cardlink/"},{"categories":["Memo"],"content":"源碼 基於 LoveIt 主題的 Link Shortcodes, 主要改到以下幾個文件，完整提交記錄 assets/css/custom.scss assets/css/partial/cardlink.scss # 卡片式鏈接樣式 layouts/partials/plugin/cardlink.html # 卡片式鏈接模板 layouts/shortcodes/cardlink.html static/images/card-link-bg.jpg ","date":"2021-10-05","objectID":"/posts/hugo-cardlink/:1:0","tags":["Shortcodes","hugo"],"title":"Hugo 添加知乎卡片式链接 Shortcodes","uri":"/posts/hugo-cardlink/"},{"categories":["Memo"],"content":"使用 使用參數见 FixIt 擴展 Shortcodes - Link {{\u003c cardlink href=\"https://github.com/Lruihao/hugo-blog/commit/089c303693e806bff855ecf3fee110baa62b870b\" content=\"知乎卡片式链接 Git 記錄\" \u003e}} 💡 注：FixIt 已合併 shortcode cardlink 到 shortcode link，只需添加 card=true {{\u003c link href=\"https://github.com/Lruihao/FixIt\" content=\"卡片式链接已整合到 FixIt 主题\" card=true \u003e}} 信息 我的博客即将同步至腾讯云+社区，邀请大家一同入驻： https://cloud.tencent.com/developer/support-plan?invite_code=3o5dmfzf0xkwk ","date":"2021-10-05","objectID":"/posts/hugo-cardlink/:2:0","tags":["Shortcodes","hugo"],"title":"Hugo 添加知乎卡片式链接 Shortcodes","uri":"/posts/hugo-cardlink/"},{"categories":["Memo"],"content":" 工作上一直常用繁體，最近臨帖也都寫的繁體，所以博客的語言也想換成繁體，但是 LoveIt 主題沒有支持中文繁體。就只好自己添加了。 ","date":"2021-10-05","objectID":"/posts/hugo-i18n-zh-tw/:0:0","tags":["hugo","i18n"],"title":"Hugo i18n 添加中文繁體翻譯","uri":"/posts/hugo-i18n-zh-tw/"},{"categories":["Memo"],"content":"翻譯 屬於直譯，有些詞語可能並不符合現在臺灣或者香港那邊的說法。比如，分類好像臺灣常說歸類吧 新建 i18n/zh-TW.toml # Translations for Traditional Chinese # 簡體中文的翻譯 # https://gohugo.io/content-management/multilingual/#translation-of-strings # === baseof == [backToTop] other = \"回到頂部\" [viewComments] other = \"查看評論\" # === baseof == # === Post === [posts] other = \"文章\" # === Post === # === Taxonomy === [allSome] other = \"所有{{ .Some }}\" [tag] other = \"標籤\" [tags] other = \"標籤\" [category] other = \"分類\" [categories] other = \"分類\" [years] other = \"年度總結\" # === Taxonomy === # === Pagination === [more] other = \"更多\" # === Pagination === # === partials/header.html === [selectLanguage] other = \"選擇語言\" [switchTheme] other = \"切換主題\" # === partials/header.html === # === partials/footer.html === [poweredBySome] other = \"由 {{ .Hugo }} 強力驅動 | 主題 - {{ .Theme }}\" # === partials/footer.html === # === partials/comment.html === [valineLang] other = \"zh-TW\" [valinePlaceholder] other = \"你的評論 ...\" [facebookLanguageCode] other = \"zh-TW\" # === partials/comment.html === # === partials/assets.html === [search] other = \"搜索\" [searchPlaceholder] other = \"搜索文章標題或內容 ...\" [clear] other = \"清空\" [cancel] other = \"取消\" [noResultsFound] other = \"沒有找到結果\" [lunrLanguageCode] other = \"zh\" [lunrLanguageLib] other = \"lib/lunr/lunr.zh.js\" [lunrSegmentitLib] other = \"lib/lunr/lunr.segmentit.js\" [copyToClipboard] other = \"複製到剪貼板\" [cookieconsentMessage] other = \"本網站使用 Cookies 來改善您的流覽體驗。\" [cookieconsentDismiss] other = \"同意\" [cookieconsentLink] other = \"瞭解更多\" # === partials/assets.html === # === partials/plugin/share.html === [shareOn] other = \"分享到\" # === partials/plugin/share.html === # === posts/single.html === [contents] other = \"目錄\" [publishedOnDate] other = \"發佈於 {{ .Date }}\" [includedInCategories] other = \"收錄於 {{ .Categories }}\" [wordCount] other = \"約 {{ .Count }} 字\" [readingTime] other = \"預計閱讀 {{ .Count }} 分鐘\" [views] other = \"次閱讀\" [author] other = \"作者\" [updatedOnDate] other = \"更新於 {{ .Date }}\" [readMarkdown] other = \"閱讀原始文檔\" [back] other = \"返回\" [home] other = \"主頁\" [readMore] other = \"閱讀全文\" # === posts/single.html === # === 404.html === [pageNotFound] other = \"頁面沒找到\" [pageNotFoundText] other = \"抱歉，您要查找的頁面不存在。\" # === 404.html === # === shortcodes/admonition.html === [note] other = \"注意\" [abstract] other = \"摘要\" [info] other = \"信息\" [tip] other = \"技巧\" [success] other = \"成功\" [question] other = \"問題\" [warning] other = \"警告\" [failure] other = \"失敗\" [danger] other = \"危險\" [bug] other = \"Bug\" [example] other = \"示例\" [quote] other = \"引用\" # === shortcodes/admonition.html === # === shortcodes/version.html === [new] other = \"新增\" [changed] other = \"更改\" [deleted] other = \"刪除\" # === shortcodes/version.html === ","date":"2021-10-05","objectID":"/posts/hugo-i18n-zh-tw/:1:0","tags":["hugo","i18n"],"title":"Hugo i18n 添加中文繁體翻譯","uri":"/posts/hugo-i18n-zh-tw/"},{"categories":["Memo"],"content":"配置 打開 config.toml defaultContentLanguage = \"zh-tw\" ","date":"2021-10-05","objectID":"/posts/hugo-i18n-zh-tw/:2:0","tags":["hugo","i18n"],"title":"Hugo i18n 添加中文繁體翻譯","uri":"/posts/hugo-i18n-zh-tw/"},{"categories":["Memo"],"content":" 過程 以前的 hexo 博客是自己寫的友鏈模板，換到 hugo 後想著在網上隨便找一個範本用著就好，然而並沒有自己想要的 layout, 幾乎都是使用 shortcodes 的，代碼風格有點問題且 shortcodes 作為友鏈添加的方式是真的麻煩。就只好自己寫羅。 友情鏈接模板已整合到 FixIt 主題 https://github.com/Lruihao/FixIt 友情鏈接範本 https://lruihao.cn/friends/ ","date":"2021-10-05","objectID":"/posts/hugo-friends/:0:0","tags":["hugo"],"title":"Hugo 友情連結模板","uri":"/posts/hugo-friends/"},{"categories":["Memo"],"content":"創建模板 開始之前去看了 hugo 的官網，再看了一下 go 模板的語法。 新建 layouts/friends/single.html {{- define \"title\" }}{{ .Title }} - {{ .Site.Title }}{{ end -}} {{- define \"content\" -}} {{- $params := .Scratch.Get \"params\" -}} \u003cdiv class=\"page single special\"\u003e {{- /* Title */ -}} \u003ch1 class=\"single-title animated pulse faster\"\u003e{{- .Title -}}\u003c/h1\u003e {{- /* Subtitle */ -}} {{- with $params.subtitle -}} \u003ch2 class=\"single-subtitle\"\u003e{{ . }}\u003c/h2\u003e {{- end -}} {{- /* Friend links */ -}} {{- $loading := resources.Get \"svg/loading.svg\" | minify -}} \u003cscript src=\"//at.alicdn.com/t/font_578712_g26jo2kbzd5qm2t9.js\"\u003e\u003c/script\u003e \u003clink rel=\"stylesheet\" href=\"/friends/css/_friends.css\" /\u003e \u003cdiv class=\"friend-links\"\u003e {{ range $index, $friend := .Site.Data.friends }} \u003ca class=\"friend-link\" title=\"{{ $friend.description }}\" href=\"{{ $friend.url | safeURL }}\" rel=\"external nofollow noopener noreferrer\" target=\"_blank\" \u003e {{ if $friend.avatar }} \u003cimg class=\"friend-avatar lazyload\" src=\"{{ $loading.RelPermalink }}\" data-src=\"{{ $friend.avatar }}\" alt=\"{{ $friend.nickname }}\" /\u003e {{ else }} \u003csvg class=\"friend-avatar\" aria-hidden=\"true\"\u003e \u003cuse xlink:href=\"#icon-{{ add 1 $index }}\"\u003e\u003c/use\u003e \u003c/svg\u003e {{ end }} \u003cspan class=\"friend-nickname\" title=\"{{ $friend.nickname }}\"\u003e@{{ $friend.nickname }}\u003c/span\u003e \u003c/a\u003e {{ end }} \u003c/div\u003e {{- /* Content */ -}} \u003cdiv class=\"content\" id=\"content\"\u003e {{- dict \"Content\" .Content \"Ruby\" $params.ruby \"Fraction\" $params.fraction \"Fontawesome\" $params.fontawesome | partial \"function/content.html\" | safeHTML -}} \u003c/div\u003e {{- /* Comment */ -}} {{- partial \"comment.html\" . -}} \u003c/div\u003e {{- end -}} ","date":"2021-10-05","objectID":"/posts/hugo-friends/:1:0","tags":["hugo"],"title":"Hugo 友情連結模板","uri":"/posts/hugo-friends/"},{"categories":["Memo"],"content":"模板樣式 新建文件 _friends.css /** * @Description: Style of layout named 'Friend links'. * @Author: lruihao.cn * @Updated: 2021/9/20 19:26 */ .friend-links { margin-top: 1rem; display: flex; flex-direction: row; justify-content: space-between; flex-wrap: wrap; } @media (max-width: 576px) { .friend-links { justify-content: space-around; } } .friend-link { width: 150px; height: 200px; font-size: 1rem; text-align: center; background: rgba(255, 255, 255, 0.3); box-sizing: border-box; box-shadow: 3px 3px 5px #aaa; border-radius: 5px; border: none; transition-duration: 0.3s; margin-bottom: 1rem; display: flex; flex-direction: column; justify-content: space-between; } .friend-link:hover { background: #fff; transform: scale(1.03); box-shadow: 0 0 3px #aaa; } .friend-avatar { object-fit: cover; object-position: center; width: 100% !important; height: 150px !important; border-radius: 5px; margin: 0; padding: 0; } .friend-nickname { display: block; position: relative; color: #2bbc8a; font-weight: bold; max-width: 100%; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; line-height: 18px; margin-bottom: 1rem; } .friend-nickname:hover { color: #d480aa; } ","date":"2021-10-05","objectID":"/posts/hugo-friends/:2:0","tags":["hugo"],"title":"Hugo 友情連結模板","uri":"/posts/hugo-friends/"},{"categories":["Memo"],"content":"友鏈頁面 hugo new friends/index.md 將 _friends.css 放到 content/friends/css/ 打開友鏈頁面 content/friends/index.md --- title: '友鏈' date: 2021-09-19T12:33:48+08:00 type: 'friends' --- ","date":"2021-10-05","objectID":"/posts/hugo-friends/:3:0","tags":["hugo"],"title":"Hugo 友情連結模板","uri":"/posts/hugo-friends/"},{"categories":["Memo"],"content":"數據 新建數據文件 data/friends.yml, 數據格式為： # - nickname: 标题 # avatar: 头像 # url: 站点 # description: 描述 - nickname: Lruihao avatar: https://gravatar.loli.net/avatar/3f985efb5907ca52944a3cd7edd51606?d=wavatar\u0026v=1.3.10 url: https://lruihao.cn description: 不怕萬人阻擋，只怕自己投降 ","date":"2021-10-05","objectID":"/posts/hugo-friends/:4:0","tags":["hugo"],"title":"Hugo 友情連結模板","uri":"/posts/hugo-friends/"},{"categories":["Memo"],"content":"結語 這樣每次添加友鏈或者刪除友鏈衹要操作數據文件 friends.yml 就好，乾淨又衛生！ 友鏈頁面 content/friends/index.md 繼承了基礎頁面的功能，內容評論等 ","date":"2021-10-05","objectID":"/posts/hugo-friends/:5:0","tags":["hugo"],"title":"Hugo 友情連結模板","uri":"/posts/hugo-friends/"},{"categories":["Memo"],"content":"使用 Shell 腳本管理 Hugo 本地博客","date":"2021-10-04","objectID":"/posts/hugo-admin/","tags":["shell","hugo"],"title":"Hugo 本地管理 Shell 腳本","uri":"/posts/hugo-admin/"},{"categories":["Memo"],"content":" 摘要 在使用 hugo 寫博客的過程中會使用到一些命令，包括 Git 的使用也會用到 Git 命令，但是這些命令我感覺知道就好，沒必要因輸入命令而增加寫博客和部署博客的額外工作。 自然要想辦法簡化這些過程，Git 還好有 SourceTree 等工具，Hugo 卻沒有，也懶得去網絡上找類似以前 hexo 有 hexo-admin 的插件可以讓大家在瀏覽器寫博客，因為我覺得這和靜態博客初衷背道而馳，於是我就折中方案，寫了一個滿足日常需求的 Shell 腳本，生成管理本地博客。 ","date":"2021-10-04","objectID":"/posts/hugo-admin/:0:0","tags":["shell","hugo"],"title":"Hugo 本地管理 Shell 腳本","uri":"/posts/hugo-admin/"},{"categories":["Memo"],"content":"實現 一共六個腳本，放在 hugo-site/_localadmin/ 下 _localadmin/ ├── auto_push.sh # 自動化提交源碼 ├── hugo_builder.sh # 構建 hugo 命令 ├── hugo_main.sh # 主介面入口 ├── hugo_server.sh # 啟動本地服務 ├── post_generator.sh # 創建文章 └── public_async.sh # 同步 public 子模組 ","date":"2021-10-04","objectID":"/posts/hugo-admin/:1:0","tags":["shell","hugo"],"title":"Hugo 本地管理 Shell 腳本","uri":"/posts/hugo-admin/"},{"categories":["Memo"],"content":"post_generator.sh 輸入文章名稱 （建議使用英文） 文章是否會插入圖片等資源 （默認：否） #!/bin/bash #author: Lruihao cd .. read -p \"Please enter the article name: \" postName if [ -z $postName ];then echo \"The article name is required!\" else read -p \"Will there be pictures in this article? [y/n]...\" choice if [ $choice = \"y\" ];then hugo new posts/$postName/index.md else hugo new posts/$postName.md fi fi ","date":"2021-10-04","objectID":"/posts/hugo-admin/:1:1","tags":["shell","hugo"],"title":"Hugo 本地管理 Shell 腳本","uri":"/posts/hugo-admin/"},{"categories":["Memo"],"content":"hugo_server.sh cd .. hugo server --disableFastRender ","date":"2021-10-04","objectID":"/posts/hugo-admin/:1:2","tags":["shell","hugo"],"title":"Hugo 本地管理 Shell 腳本","uri":"/posts/hugo-admin/"},{"categories":["Memo"],"content":"hugo_builder.sh cd .. hugo --minify ","date":"2021-10-04","objectID":"/posts/hugo-admin/:1:3","tags":["shell","hugo"],"title":"Hugo 本地管理 Shell 腳本","uri":"/posts/hugo-admin/"},{"categories":["Memo"],"content":"public_async.sh cd .. git submodule update --remote git add public git commit -m \"Feat: Update public module commit id\" ","date":"2021-10-04","objectID":"/posts/hugo-admin/:1:4","tags":["shell","hugo"],"title":"Hugo 本地管理 Shell 腳本","uri":"/posts/hugo-admin/"},{"categories":["Memo"],"content":"auto_push.sh 不輸入 Git 提交訊息會使用腳本中默認訊息 Docs: 『菠菜眾長』内容更新 YYYY-MM-DD week hh:mm::ss #!/bin/bash #author: Lruihao cd .. # 是否需要每次提交自動更新子模組 # git submodule update --remote # git add public # git commit -m \"Feat: Update public module commit id\" git add . read -p \"Please enter commit message: \" commitMsg if [ -z $commitMsg ];then commitMsg=\"Docs: 『菠菜眾長』内容更新 $(date +'%F %a %T')\" fi git commit -m \"$commitMsg\" git push ","date":"2021-10-04","objectID":"/posts/hugo-admin/:1:5","tags":["shell","hugo"],"title":"Hugo 本地管理 Shell 腳本","uri":"/posts/hugo-admin/"},{"categories":["Memo"],"content":"hugo_main.sh 可單獨執行子腳本也可以通過主介面來選擇序號執行 #!/bin/bash #author: Lruihao echo \"Please enter the serial number to work\" echo \"--------------------------------------\" echo \"1. post generator\" echo \"2. hugo server\" echo \"3. hugo build\" echo \"4. public async\" echo \"5. auto push\" echo \"--------------------------------------\" echo \"Press Ctrl+C to stop\" read num case $num in 1) sh post_generator.sh ;; 2) sh hugo_server.sh ;; 3) sh hugo_builder.sh ;; 4) sh public_async.sh ;; 5) sh auto_push.sh ;; *) echo \"There is no such serial number\" ;; esac echo \"Press any key to continue...\" read x clear sh hugo_main.sh ","date":"2021-10-04","objectID":"/posts/hugo-admin/:1:6","tags":["shell","hugo"],"title":"Hugo 本地管理 Shell 腳本","uri":"/posts/hugo-admin/"},{"categories":["Memo"],"content":"使用 將 hugo_main.sh 建立桌面快捷鍵 雙擊 hugo_main.sh 進入根據提示使用即可 由於一般寫博客會便邊寫邊預覽，所以一般開兩個主介面窗口，如下圖： 一個選擇 2 啟動本地服務 一個用於生成文章，部署文章等 Hugo Admin ","date":"2021-10-04","objectID":"/posts/hugo-admin/:2:0","tags":["shell","hugo"],"title":"Hugo 本地管理 Shell 腳本","uri":"/posts/hugo-admin/"},{"categories":["Memo","Git"],"content":" 解決痛點 Github Actions 真是靜態博客的福音，有了它 hugo, hexo 等博客構建過程可以丟給 Github 的服務器幫我們做了。 也就是説實現了在線寫靜態博客的需求。 ","date":"2021-10-04","objectID":"/posts/github-actions/:0:0","tags":["hugo","GitHub Actions","Git","腾讯云 cos 桶"],"title":"Hugo 使用 GitHub Actions 部署到 GithHb Pages 和 腾讯云 cos 桶","uri":"/posts/github-actions/"},{"categories":["Memo","Git"],"content":"準備 工作流程涉及到兩個倉庫和一個 cos 桶，例如： Lruihao/hugo-blog # Blog source repository Lruihao/lruihao.github.io # GitHub pages repository blog-1256932288 # COS bucket ","date":"2021-10-04","objectID":"/posts/github-actions/:1:0","tags":["hugo","GitHub Actions","Git","腾讯云 cos 桶"],"title":"Hugo 使用 GitHub Actions 部署到 GithHb Pages 和 腾讯云 cos 桶","uri":"/posts/github-actions/"},{"categories":["Memo","Git"],"content":"Github Actions ","date":"2021-10-04","objectID":"/posts/github-actions/:2:0","tags":["hugo","GitHub Actions","Git","腾讯云 cos 桶"],"title":"Hugo 使用 GitHub Actions 部署到 GithHb Pages 和 腾讯云 cos 桶","uri":"/posts/github-actions/"},{"categories":["Memo","Git"],"content":"創建 workflows 任務 創建 hugo-site/.github/workflows/deploy.yml, 這個文件會寫一些命令告訴 Github 在我們提交源碼的時候，它要幫我們做哪些事情。 name: Auto Deploy hugo on: [push] jobs: Explore-GitHub-Actions: runs-on: ubuntu-latest steps: - name: Check out repository code uses: actions/checkout@v2 with: submodules: recursive # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: latest extended: true - name: Build Hugo static files run: hugo --minify - name: Deploy to Github Pages uses: peaceiris/actions-gh-pages@v3 with: deploy_key: ${{ secrets.GP_DEPLOY_KEY }} external_repository: Lruihao/lruihao.github.io publish_branch: main publish_dir: ./public commit_message: ${{ github.event.head_commit.message }} - name: Install coscmd run: sudo pip install coscmd - name: Configure coscmd env: COS_SECRET_ID: ${{ secrets.COS_SECRET_ID }} COS_SECRET_KEY: ${{ secrets.COS_SECRET_KEY }} COS_BUCKET_NAME: blog-1256932288 # Change for yourself COS_BUCKET_REGION: ap-chengdu # Change for yourself run: coscmd config -a $COS_SECRET_ID -s $COS_SECRET_KEY -b $COS_BUCKET_NAME -r $COS_BUCKET_REGION - name: Deploy to COS Bucket run: coscmd upload -r -s --delete -f public/ / ","date":"2021-10-04","objectID":"/posts/github-actions/:2:1","tags":["hugo","GitHub Actions","Git","腾讯云 cos 桶"],"title":"Hugo 使用 GitHub Actions 部署到 GithHb Pages 和 腾讯云 cos 桶","uri":"/posts/github-actions/"},{"categories":["Memo","Git"],"content":"配置 Github Pages 密鑰 為了讓 Lruihao/hugo-blog 提交代碼后自動部署到 Lruihao/lruihao.github.io, 需要生成一對 ssh key. ssh-keygen -t rsa -b 4096 -C \"$(git config user.email)\" -f gh-pages -N \"\" # You will get 2 files: # gh-pages.pub (public key) # gh-pages (private key) 打開 Lruihao/hugo-blog 倉庫的 settings, 再点击 Secrets, 然後添加 private key, name 为 GP_DEPLOY_KEY 打開 Lruihao/lruihao.github.io, 点击 Deploy keys, 添加 public key, name 隨意，Allow write access 一定要勾上，否則無法提交 ","date":"2021-10-04","objectID":"/posts/github-actions/:2:2","tags":["hugo","GitHub Actions","Git","腾讯云 cos 桶"],"title":"Hugo 使用 GitHub Actions 部署到 GithHb Pages 和 腾讯云 cos 桶","uri":"/posts/github-actions/"},{"categories":["Memo","Git"],"content":"配置 COS 密鑰 打開 Lruihao/hugo-blog 倉庫的 settings, 再点击 Secrets, 然後添加 COS 桶的 secret_id 和 secret_key: COS_SECRET_ID COS_SECRET_KEY 至此，Github Pages 和 COS 都已經可以通過 Github Actions 自動部署了，有部署記錄后， 打開 Lruihao/hugo-blog -\u003e Actions 可以看到構建過程和結果，構建失敗也會收到 Github 發給你的郵件。 ","date":"2021-10-04","objectID":"/posts/github-actions/:2:3","tags":["hugo","GitHub Actions","Git","腾讯云 cos 桶"],"title":"Hugo 使用 GitHub Actions 部署到 GithHb Pages 和 腾讯云 cos 桶","uri":"/posts/github-actions/"},{"categories":["Memo","Git"],"content":"COS 自動同步 （備用） 本小節內容和 Github Actions 無關，僅作為 COS 備用上傳方式。 COSBrowser 下載 COS 官方軟件 COSBrowser 點開右上角 工具箱 選擇 文件同步 選擇 本地文件夹 eg. hugo-site/public 選擇 存储桶目录 同步类型：單次同步、自動同步、定時同步 同步前先執行 hugo 構建命令，eg. hugo --minify 有 Github actions 選單次同步就好，在 Github 不好用時可用。 ","date":"2021-10-04","objectID":"/posts/github-actions/:3:0","tags":["hugo","GitHub Actions","Git","腾讯云 cos 桶"],"title":"Hugo 使用 GitHub Actions 部署到 GithHb Pages 和 腾讯云 cos 桶","uri":"/posts/github-actions/"},{"categories":["Memo"],"content":" 电脑升级 win 11 后，分盘操作存在 bug, 然后又不小心把装代码的盘格式化了，虽然都有备份到 github, 但是当时为了省事，hexo Node 安装的很多以来插件都没有备份，现在又下载不到了，所以 hexo 博客没办法完整复原，另外，早就觉得基于 Node 的 hexo 实在有些臃肿，且博客内容多了以后部署太慢，就干脆乘机换了好了，经过一段时间寻找，最终选择了基于 Go 的 hugo, 记录一下迁移过程及待办事项。 ","date":"2021-10-03","objectID":"/posts/hexo-to-hugo/:0:0","tags":["hugo","hexo"],"title":"个人博客从 Hexo 迁移至 Hugo","uri":"/posts/hexo-to-hugo/"},{"categories":["Memo"],"content":"Hugo 准备 ","date":"2021-10-03","objectID":"/posts/hexo-to-hugo/:1:0","tags":["hugo","hexo"],"title":"个人博客从 Hexo 迁移至 Hugo","uri":"/posts/hexo-to-hugo/"},{"categories":["Memo"],"content":"概念 Hugo is a fast and modern static site generator written in Go, and designed to make website creation fun again. 那 hugo 基于编译语言 GO 构建，对于静态页面的构建肯定是碾压 hexo 的存在，其官方标语也是很直白 \"The world’s fastest framework for building websites\", 作为先后使用过 hexo 和 hugo 的我来说，这确实名副其实。 gohugo ","date":"2021-10-03","objectID":"/posts/hexo-to-hugo/:1:1","tags":["hugo","hexo"],"title":"个人博客从 Hexo 迁移至 Hugo","uri":"/posts/hexo-to-hugo/"},{"categories":["Memo"],"content":"安装 hugo 提供了很多种安装方式，Git, Docker, Binary. 个人电脑使用二进制安装是最方便快捷的，无需安装其他依赖。 到 Hugo Releases 下载对应的 windows 操作系统版本的 Hugo 二进制文件，玩就要玩全的，所以我就选择了扩展版本，此次选择的最新版为 hugo_extended_0.88.1_Windows-64bit.zip, 然后自行解压安装即可。 ","date":"2021-10-03","objectID":"/posts/hexo-to-hugo/:1:2","tags":["hugo","hexo"],"title":"个人博客从 Hexo 迁移至 Hugo","uri":"/posts/hexo-to-hugo/"},{"categories":["Memo"],"content":"生成站点 使用 Hugo 快速生成站点，比如希望生成到 /path/to/site 路径： hugo new site /path/to/site 站点目录结构： ▸ archetypes/ # 配置文章模板，相当于 hexo 的 scaffolds ▸ content/ # 文章页面内容，相当于 hexo 的 source ▸ data/ # 可存放一些 yaml, json, toml 格式的数据 ▸ layouts/ # 页面布局源码，改造主题可不动主题源码 ▸ static/ # 静态文件存放 config.toml # 站点配置文件，相当于 hexo 的 _config.yml ","date":"2021-10-03","objectID":"/posts/hexo-to-hugo/:1:3","tags":["hugo","hexo"],"title":"个人博客从 Hexo 迁移至 Hugo","uri":"/posts/hexo-to-hugo/"},{"categories":["Memo"],"content":"创建文章 注： 路径要写以 content/ 为根目录的相对路径 hugo new path/fileName ","date":"2021-10-03","objectID":"/posts/hexo-to-hugo/:1:4","tags":["hugo","hexo"],"title":"个人博客从 Hexo 迁移至 Hugo","uri":"/posts/hexo-to-hugo/"},{"categories":["Memo"],"content":"添加主题 添加主题的方式选用 Git 子模组的形式，为了日后快速升级，避免在使用 hexo 中因大量魔改 next 主题而导致难以升级的困扰。 精挑细选最终选择了 LoveIt =\u003e FixIt git init git submodule add https://github.com/Lruihao/FixIt.git themes/FixIt 在 config.toml 添加 theme = “LoveIt” theme = \"FixIt\" ","date":"2021-10-03","objectID":"/posts/hexo-to-hugo/:1:5","tags":["hugo","hexo"],"title":"个人博客从 Hexo 迁移至 Hugo","uri":"/posts/hexo-to-hugo/"},{"categories":["Memo"],"content":"在本地启动网站 使用以下命令启动网站： hugo serve --disableFastRender 去查看 http://localhost:1313 ","date":"2021-10-03","objectID":"/posts/hexo-to-hugo/:1:6","tags":["hugo","hexo"],"title":"个人博客从 Hexo 迁移至 Hugo","uri":"/posts/hexo-to-hugo/"},{"categories":["Memo"],"content":"hugo build 使用以下命令生成静态文件，然后自己可手动选择部署到 github pages 或 COS 等服务器 hugo --minify ","date":"2021-10-03","objectID":"/posts/hexo-to-hugo/:1:7","tags":["hugo","hexo"],"title":"个人博客从 Hexo 迁移至 Hugo","uri":"/posts/hexo-to-hugo/"},{"categories":["Memo"],"content":"写作指北 FixIt 主题文档 - 基本概念 FixIt 主题文档 - 内容 FixIt 主题文档 - 内置 Shortcodes FixIt 主题文档 - 扩展 Shortcodes ","date":"2021-10-03","objectID":"/posts/hexo-to-hugo/:2:0","tags":["hugo","hexo"],"title":"个人博客从 Hexo 迁移至 Hugo","uri":"/posts/hexo-to-hugo/"},{"categories":["Memo"],"content":"Todo list 本站源码备份 https://github.com/Lruihao/hugo-blog 原来 hexo 做了大量的美化和扩展功能，迁移到 hugo 想尽可能多的保留。取之精华，去其糟粕。 ","date":"2021-10-03","objectID":"/posts/hexo-to-hugo/:3:0","tags":["hugo","hexo"],"title":"个人博客从 Hexo 迁移至 Hugo","uri":"/posts/hexo-to-hugo/"},{"categories":["Memo"],"content":"Base 迁移 hexo 所有文章内容 迁移 hexo 所有页面内容 留言页面 网友打赏支持页面，整合到留言页面 重写关于页面，一切从简 友情链接页面 重写 404 页面 站点时间和不蒜子计数改到 hello-world 页面 cos-album 和 🍚 饭醉团伙 🍷 整合到博客 cos-album/ #7 (wontfix) 新增 demo/, 以子模组的形式存放前端 demo, serverless 记账本等 （保持原本博客的纯粹性） 博客 valine 评论，阅读数迁移，可用 leancloud API 写代码转化（但似乎没必要） 博客 SEO 优化迁移 baidu_urls.txt Github actions 自动部署到 Github pages 和 COS 脚本编写 hugo 本地管理 shell 脚本工具编写 知乎卡片式链接 改成 hugo shortcodes, 取名 cardlink zxm/沐目体 归档 :( #6 安装 沐目体 压缩 沐目体 fontspider 沐目体 post 修订 typyit 配合 随机诗词和网易云热评 API 实时预览功能 base on Vuejs [恋爱叙事体] love 归档 [光] 归档 hugo 内容加密研究 #3 Lruihao/hugo-blog/README.md 撰写，MIT, 发布 1.0.0 版本做完整备份，base on theme version 更换 gravatar 头像 #4 博客在线编辑器研究 github1s 等 #5 [baidu_urls.txt]:↩︎ 生成百度链接集合小技巧，关掉归档分页，在归档页面控制台执行以下代码即可获得所有文章链接 let urls = []; for (let a of document.querySelectorAll('.archive-item a')) { urls.push(a.href); } console.log(urls.join('\\n')); FixIt 主题已支持自动输出 baidu_urls.txt 文件 ","date":"2021-10-03","objectID":"/posts/hexo-to-hugo/:3:1","tags":["hugo","hexo"],"title":"个人博客从 Hexo 迁移至 Hugo","uri":"/posts/hexo-to-hugo/"},{"categories":["Memo"],"content":"Theme FixIt hugo LoveIt 主题整体优化，必要时建 PR 或 issue 到 LoveIt 仓库 (LoveIt 已停更一年多） 先把自己发现和 LoveIt 原 repo 的 issue 尽可能的修复，修改的原则是：不改动原项目代码， 唯一途径就是在站点相同的目录用新增的方式替代修改、删除操作。 之后再等等看作者是否还会更新，如已做大量的更改，再做考虑整合为一个新的主题。 为了更好的完善博客功能以及修复 BUG 已创建新的主题 FixIt (fork from LoveIt) Hugo theme FixIt https://github.com/Lruihao/FixIt 进度更新至 #8 CSS 优化，背景，元素圆角化，外圆内方，居中对齐等 沐目体引入 TOC 序号生成 Fix: 无标题时也会生成目录的 BUG subtitle 等细节优化 Fix: typeit 打印代码时跑版的问题 Fix: 文章 h1 标题多行跑版 Code Review ","date":"2021-10-03","objectID":"/posts/hexo-to-hugo/:3:2","tags":["hugo","hexo"],"title":"个人博客从 Hexo 迁移至 Hugo","uri":"/posts/hexo-to-hugo/"},{"categories":null,"content":"Lruihao's friends","date":"2021-09-19","objectID":"/friends/","tags":null,"title":"友情鏈接","uri":"/friends/"},{"categories":null,"content":"  Subscribe ours https://lruihao.cn/friends/opml.xml ","date":"2021-09-19","objectID":"/friends/:0:0","tags":null,"title":"友情鏈接","uri":"/friends/"},{"categories":null,"content":"基本資訊 - nickname: jian avatar: url: description: ","date":"2021-09-19","objectID":"/friends/:1:0","tags":null,"title":"友情鏈接","uri":"/friends/"},{"categories":null,"content":"友情提醒 Notice 互換友鏈請按以上格式在評論留言。（僅限個人非商業部落格/網站）  網站失效、停止維護、內容不當都可能被取消連結！ 那些不尊重他人勞動成果，轉載不加出處的，或惡意行為的網站，還請您不要來進行交換了。 ","date":"2021-09-19","objectID":"/friends/:2:0","tags":null,"title":"友情鏈接","uri":"/friends/"},{"categories":null,"content":"互联网的广大朋友们，欢迎光临我的小博客！欢迎留言！","date":"2021-09-13","objectID":"/guestbook/","tags":null,"title":"留言","uri":"/guestbook/"},{"categories":null,"content":" Welcome 关于 FixIt 主题 的问题，请移步 FixIt 官网 相关文章哦～ 温馨提示，音乐自动播放，请带好耳机～ From playlist, Powered By mmt-netease 给博主买杯卡布奇诺～ 赞赏 支付宝 微信 ","date":"2021-09-13","objectID":"/guestbook/:0:0","tags":null,"title":"留言","uri":"/guestbook/"},{"categories":null,"content":"关于我 不卑不亢，不矜不伐，戒骄戒躁 不嗔不怒，不爭不弃，独善其身 自我期許： 用我所學，學我所用。保持謙遜，保持探索欲，砥礪前行。 ","date":"2021-09-07","objectID":"/about/:1:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"訂閱 ","date":"2021-09-07","objectID":"/about/:2:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":null,"content":"致謝 感謝大家的支持 🙏 给博主买杯卡布奇诺～ 赞赏 支付宝 微信 francs 通过 支付宝 打赏了 ¥50.00大学生时期，第一次收到别人的支持，内心表示受宠若惊又非常开心。非常感谢老哥的支持！2018-09-28 francs 通过 QQ 打赏了 ¥8.80今天学校运动会没课，睡到 9 点多起来看到 QQ 收到一个红包，感谢支持！2018-10-26 francs 通过 QQ 打赏了 ¥8.802018-11 ✘昌升 通过 支付宝 打赏了 ¥10.00上课的时候听到了支付宝清脆的支付宝到账 10 元的声音！2018-12-04 ✘昌升 通过 支付宝 打赏了 ¥18.002018-12-04 ✘昌升 通过 微信 打赏了 ¥2.00来自 231****047#qq.com2019-03-19 ✘喜洲 通过 QQ 打赏了 ¥20.20来自 101****0732020-01-17 ✘✘松 通过 支付宝 打赏了 ¥2.002022-12-02 13:01:48 ✘✘波 通过 支付宝 打赏了 ¥20.00留言：“感谢帮忙解决 FixIt 的问题”2023-02-13 10:01:58 K*n 通过 微信 打赏了 ¥50.002023-03-17 14:05:49 D*n 通过 微信 打赏了 ¥11.11留言：“加油”2023-03-17 14:57:41 乐语 通过 微信 打赏了 ¥5.00留言：“很好用的主题，谢谢作者💪”2023-04-03 17:49:12 建议去世 通过 微信 打赏了 ¥20.00留言：“主题不错”2023-04-17 10:35:26 🐟 通过 微信 打赏了 ¥1.00留言：“感谢fixit作者”2023-05-24 15:49:46 ","date":"2021-09-07","objectID":"/about/:3:0","tags":null,"title":"关于我","uri":"/about/"},{"categories":["CSS"],"content":" Sass 和 Less 都屬於 CSS 前置處理器，CSS 前置處理器定義了一種新的語言，其基本思想是，用一種專門的程式設計語言，為 CSS 增加了一些程式設計的特性，將 CSS 作為目標生成檔，然後開發者就只要使用這種語言進行 CSS 的編碼工作。 轉化成通俗易懂的話來說就是 “用一種專門的程式設計語言，進行 Web 頁面樣式設計，再通過編譯器轉化為正常的 CSS 檔，以供專案使用”。 ","date":"2021-06-22","objectID":"/posts/less-sass-scss/:0:0","tags":["Less","Sass","Scss"],"title":"less\u0026sass\u0026scss","uri":"/posts/less-sass-scss/"},{"categories":["CSS"],"content":"為什麼，什麼時候要使用 CSS 前置處理器？ (Why, When) CSS 有具體以下幾個缺點： 語法不夠強大，比如無法嵌套書寫，導致模組化開發中需要書寫很多重複的選擇器 沒有變數和合理的樣式複用機制，使得邏輯上相關的屬性值必須以字面量的形式重複輸出，導致難以維護 這就導致了我們在工作中無端增加了許多工作量。而使用 CSS 前置處理器可大大提高了我們的開發效率： 提供 CSS 缺失的樣式層複用機制 減少冗餘碼 提高樣式代碼的可維護性。 但是，CSS 的好處在於簡便、隨時隨地被使用和調試。這就使得預編譯 CSS 步驟的加入具有以下缺點： 開發工作流中多了一個環節，調試也變得更麻煩 預編譯很容易造成後代選擇器的濫用 所以我們在實際項目中衡量預編譯方案時，還是得想想，比起帶來的額外維護開銷，CSS 前置處理器有沒有解決更大的麻煩。 系統級框架開發 （大型複雜的樣式設計） 持續維護 ","date":"2021-06-22","objectID":"/posts/less-sass-scss/:1:0","tags":["Less","Sass","Scss"],"title":"less\u0026sass\u0026scss","uri":"/posts/less-sass-scss/"},{"categories":["CSS"],"content":"Less、Sass/Scss 是什麼？ (What) ","date":"2021-06-22","objectID":"/posts/less-sass-scss/:2:0","tags":["Less","Sass","Scss"],"title":"less\u0026sass\u0026scss","uri":"/posts/less-sass-scss/"},{"categories":["CSS"],"content":"Less 是一種動態樣式語言。對 CSS 賦予了動態語言的特性，如變數、繼承、運算、函數。 Less 既可以在用戶端上運行 （支援 IE 6+, Webkit, Firefox)，也可在服務端運行。 ","date":"2021-06-22","objectID":"/posts/less-sass-scss/:2:1","tags":["Less","Sass","Scss"],"title":"less\u0026sass\u0026scss","uri":"/posts/less-sass-scss/"},{"categories":["CSS"],"content":"Sass 是一種動態樣式語言，Sass 語法屬於縮排語法， 比 CSS 比多出好些功能（如變數、嵌套、運算，混入 (Mixin)、繼承、顏色處理，函數等），更容易閱讀。 ","date":"2021-06-22","objectID":"/posts/less-sass-scss/:2:2","tags":["Less","Sass","Scss"],"title":"less\u0026sass\u0026scss","uri":"/posts/less-sass-scss/"},{"categories":["CSS"],"content":"Sass 與 Scss 的關係 Sass 的縮排語法，對於寫慣 CSS 的前端開發者來說很不直觀，也不能將 CSS 代碼加入到 Sass 裡面，因此 Sass 語法進行了改良，Sass 3 就變成了 Scss(Sassy CSS)。與原來的語法相容，只是用{}取代了原來的縮進。Sass 相當於 Scss 的嚴格模式。 ","date":"2021-06-22","objectID":"/posts/less-sass-scss/:2:3","tags":["Less","Sass","Scss"],"title":"less\u0026sass\u0026scss","uri":"/posts/less-sass-scss/"},{"categories":["CSS"],"content":"Sass 和 Less 的比較 ","date":"2021-06-22","objectID":"/posts/less-sass-scss/:3:0","tags":["Less","Sass","Scss"],"title":"less\u0026sass\u0026scss","uri":"/posts/less-sass-scss/"},{"categories":["CSS"],"content":"相同點 Less 和 Sass 在語法上有些共性，比如下面這些： 混入 (Mixins)——class 中的 class 參數混入——可以傳遞參數的 class，就像函數一樣 嵌套規則——Class 中嵌套 class，從而減少重複的代碼 運算——CSS 中用上數學 顏色功能——可以編輯顏色 名字空間 (namespace)——分組樣式，從而可以被調用 作用域——局部修改樣式 JavaScript 賦值——在 CSS 中使用 JavaScript 運算式賦值 ","date":"2021-06-22","objectID":"/posts/less-sass-scss/:3:1","tags":["Less","Sass","Scss"],"title":"less\u0026sass\u0026scss","uri":"/posts/less-sass-scss/"},{"categories":["CSS"],"content":"不同點 實現方式 Less 是基於 JavaScript，是在用戶端處理的 Sass 是基於 Ruby 的，是在伺服器端處理的 關於變數在 Less 和 Sass 中的唯一區別就是 Less 用@，Sass 用$ less 中的變量運算可帶、可不帶單位，Sass 需要帶單位元 語法不同，請詳見 Less、Sass 官網 ","date":"2021-06-22","objectID":"/posts/less-sass-scss/:3:2","tags":["Less","Sass","Scss"],"title":"less\u0026sass\u0026scss","uri":"/posts/less-sass-scss/"},{"categories":["CSS"],"content":"選用 Less 還是 Sass ? 無論是學習資料，討論情況，以及項目使用情況 Sass/Scss 都優於 Less，比如 Bootstrap 4 就使用的 Sass, 但是 Less 的使用更加簡單，使用門檻也較低，內網開發的情況，Less 則更加適合。 ","date":"2021-06-22","objectID":"/posts/less-sass-scss/:4:0","tags":["Less","Sass","Scss"],"title":"less\u0026sass\u0026scss","uri":"/posts/less-sass-scss/"},{"categories":["JavaScript"],"content":"簡介 Lightbox （燈箱），用来放大显示图片覆盖于当前页面之上。其是用 CSS 来定义图片容器，用一幅半透明的 png 图片实现渐变阴暗的效果。 一般的網頁，圖片是使用 img 標籤寫在 HTML 頁面中，圖片點擊并不會放大，想放大看圖片要麼方法整個網頁，要麼複製圖片鏈接新開窗口，操作繁瑣，而使用 Lightbox 的網站可以点击缩略图浮层显示大图，放大後可点击键盘 ←、→ 键切换图片，也可以鼠标点击左右箭头切换。按下键盘 Esc 键或者点击关闭按钮可輕鬆關閉圖層，圖片流覽的體驗度是遠遠大於未使用的 Lightbox 的網站。 ","date":"2021-06-21","objectID":"/posts/lightbox/:1:0","tags":["Lightbox","JavaScript"],"title":"Lightbox","uri":"/posts/lightbox/"},{"categories":["JavaScript"],"content":"實現思路 大概思路就在每个图片的点击事件中添加图层与图片副本。 /** * @author github.com@flymysql */ let container = document.documentElement || document.body; let img, div, src, btnleft, btnright; var imgid = 0; let x, y, w, h, tx, ty, tw, th, ww, wh; let closeMove = function () { if (div == undefined) { return false; } div.style.opacity = 0; img.style.height = h + 'px'; img.style.width = w + 'px'; img.style.left = x + 'px'; img.style.top = y - container.scrollTop + 'px'; // 延迟移除 dom setTimeout(function () { div.remove(); img.remove(); btnright.remove(); btnleft.remove(); }, 100); }; let closeFade = function () { if (div == undefined) { return false; } div.style.opacity = 0; img.style.opacity = 0; // 延迟移除 dom setTimeout(function () { div.remove(); img.remove(); btnright.remove(); btnleft.remove(); }, 100); }; let style = function () { btnleft.style.cssText = ` position:fixed; border-radius: 50%;; left:${x - 20}px; top:${y - container.scrollTop + h / 2}px; width:50px; height:50px; border: 0px; background-color: rgba(200,200,200,0.8); font-size: 20px; z-index: 999999999; transition:all .3s cubic-bezier(0.165, 0.84, 0.44, 1); `; btnright.style.cssText = ` position:fixed; border-radius: 50%; left:${x + w + 20}px; top:${y - container.scrollTop + h / 2}px; width:50px; border: 0px; height:50px; font-size: 20px; background-color: rgba(200,200,200,0.8); z-index: 999999999; transition:all .3s cubic-bezier(0.165, 0.84, 0.44, 1); `; btnleft.innerText = '\u003c'; btnright.innerText = '\u003e'; img.style.cssText = ` position:fixed; border-radius: 12px; left:${x}px; top:${y - container.scrollTop}px; width:${w}px; height:${h}px; z-index: 999999999; transition:all .3s cubic-bezier(0.165, 0.84, 0.44, 1); opacity:0; `; }; // 监听滚动关闭层 document.addEventListener('scroll', function () { closeFade(); }); document.querySelectorAll('img').forEach((v) =\u003e { if (v.parentNode.localName != 'a') { v.id = imgid; imgid++; v.addEventListener('click', function (e) { // 注册事件 // 记录小图的位置个大小 x = e.target.offsetLeft; y = e.target.offsetTop; w = e.target.offsetWidth; h = e.target.offsetHeight; src = e.target.src; id = e.target.id; // 创建遮罩层 div = document.createElement('div'); div.style.cssText = ` position:fixed; left:0; top:0; bottom:0; right:0; background-color: rgba(25,25,25,0.8); z-index:99999999; transition:all .3s cubic-bezier(0.165, 0.84, 0.44, 1); `; document.body.appendChild(div); setTimeout(function () { div.style.opacity = 1; }, 0); // （此处可以加 loading) // 创建副本 img = new Image(); btnright = document.createElement('button'); btnleft = document.createElement('button'); img.src = src; style(); btnleft.onclick = function () { if (id === 0) { alert('已经是第一张了！'); return; } var left = document.getElementById(id - 1); img.src = left.src; x = left.offsetLeft; y = left.offsetTop; w = left.offsetWidth; h = left.offsetHeight; style(); id--; }; btnright.onclick = function () { id++; if (id \u003e= imgid) { alert('已经是最后一张了！'); return; } var right = document.getElementById(id); img.src = right.src; x = right.offsetLeft; y = right.offsetTop; w = right.offsetWidth; h = right.offsetHeight; style(); }; img.onload = function () { document.body.appendChild(img); document.body.appendChild(btnright); document.body.appendChild(btnleft); // 浏览器宽高 wh = window.innerHeight; ww = window.innerWidth; // 目标宽高和坐标 if (w / h \u003c ww / wh) { th = wh - 80; tw = ((w / h) * th) \u003e\u003e 0; tx = (ww - tw) / 2; ty = 40; } else { tw = ww * 0.8; th = ((h / w) * tw) \u003e\u003e 0; tx = ww * 0.1; ty = (wh - th) / 2; } // 延迟写入否则不会有动画 setTimeout(function () { img.style.opacity = 1; img.style.height = th + 'px'; img.style.width = tw + 'px'; img.style.left = tx + 'px'; img.style.top = ty + 'px'; btnleft.style.left = tx - 90 + 'px'; btnleft.style.top = ty + th / 2 + 'px'; btnright.style.left = tx + tw + 40 + 'px'; btnright.style.top = ty + th / 2 + 'px'; // 点击隐藏 div.onclick = img.onclick = closeMove; }, 10); }; }); //end event } }); //end forEach ","date":"2021-06-21","objectID":"/posts/lightbox/:2:0","tags":["Lightbox","JavaScript"],"title":"Lightbox","uri":"/posts/lightbox/"},{"categories":["JavaScript"],"content":"fancybox fancybox 是一個完善的 lightbox 插件 jQuery lightbox script for displaying images, videos and more. Touch enabled, responsive and fully customizable. ","date":"2021-06-21","objectID":"/posts/lightbox/:3:0","tags":["Lightbox","JavaScript"],"title":"Lightbox","uri":"/posts/lightbox/"},{"categories":["JavaScript"],"content":"Quick start Add latest jQuery and fancyBox files \u003cscript src=\"https://code.jquery.com/jquery-3.3.1.min.js\"\u003e\u003c/script\u003e \u003clink href=\"/path/to/jquery.fancybox.min.css\" rel=\"stylesheet\" /\u003e \u003cscript src=\"/path/to/jquery.fancybox.min.js\"\u003e\u003c/script\u003e Create links \u003ca data-fancybox=\"gallery\" href=\"big_1.jpg\"\u003e \u003cimg src=\"small_1.jpg\" /\u003e \u003c/a\u003e \u003ca data-fancybox=\"gallery\" href=\"big_2.jpg\"\u003e \u003cimg src=\"small_2.jpg\" /\u003e \u003c/a\u003e Enjoy! ","date":"2021-06-21","objectID":"/posts/lightbox/:3:1","tags":["Lightbox","JavaScript"],"title":"Lightbox","uri":"/posts/lightbox/"},{"categories":["Projects","JavaScript"],"content":"Usage ","date":"2021-05-23","objectID":"/projects/cell-watermark/:0:0","tags":["watermark","JavaScript"],"title":"Cell Watermark","uri":"/projects/cell-watermark/"},{"categories":["Projects","JavaScript"],"content":"Browser Clone source git clone git@github.com:Lruihao/watermark.git Load Watermark \u003cscript type=\"text/javascript\" src=\"./src/watermark.js\"\u003e\u003c/script\u003e \u003cscript type=\"text/javascript\" src=\"./src/watermark.min.js\"\u003e\u003c/script\u003e \u003c!-- Or CDN --\u003e \u003cscript type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm/cell-watermark@1.0.3/src/watermark.js\"\u003e\u003c/script\u003e \u003cscript type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/npm/cell-watermark@1.0.3/src/watermark.min.js\"\u003e\u003c/script\u003e Initialization document.addEventListener('DOMContentLoaded', function () { new Watermark({ content: \"cell-watermark\" }) }); ","date":"2021-05-23","objectID":"/projects/cell-watermark/:1:0","tags":["watermark","JavaScript"],"title":"Cell Watermark","uri":"/projects/cell-watermark/"},{"categories":["Projects","JavaScript"],"content":"NPM Install npm i cell-watermark Import import Watermark from 'cell-watermark' /* Or */ var Watermark = require(\"cell-watermark\") Class: Watermark ","date":"2021-05-23","objectID":"/projects/cell-watermark/:2:0","tags":["watermark","JavaScript"],"title":"Cell Watermark","uri":"/projects/cell-watermark/"},{"categories":["Projects","JavaScript"],"content":"Watermark(options) new Watermark(options) Parameters: Name Type Description options Object The options of watermark（Properties） Properties: Name Type Attributes Default Description content String \u003coptional\u003e watermark’s text appendTo String \u003coptional\u003e ‘body’ parent of watermark’s container width Number \u003coptional\u003e 150 watermark’s width. unit: px height Number \u003coptional\u003e 20 watermark’s height. unit: px rowSpacing Number \u003coptional\u003e 60 row spacing of watermarks. unit: px colSpacing Number \u003coptional\u003e 30 col spacing of watermarks. unit: px rotate Number \u003coptional\u003e 15 watermark’s tangent angle. unit: deg opacity Number \u003coptional\u003e 0.1 watermark’s transparency fontSize Number \u003coptional\u003e 0.85 watermark’s fontSize. unit: rem fontFamily String \u003coptional\u003e ‘inherit’ watermark’s fontFamily Author: Lruihao ","date":"2021-05-23","objectID":"/projects/cell-watermark/:3:0","tags":["watermark","JavaScript"],"title":"Cell Watermark","uri":"/projects/cell-watermark/"},{"categories":["Projects","JavaScript"],"content":"Methods upload(content) Upload watermark’s text content Parameters: Name Type Description content String watermark’s text render(options) Rerender watermark Parameters: Name Type Description options Object The options of watermark（Properties） destroy() Force destroy watermark ","date":"2021-05-23","objectID":"/projects/cell-watermark/:3:1","tags":["watermark","JavaScript"],"title":"Cell Watermark","uri":"/projects/cell-watermark/"},{"categories":["Memo"],"content":"程式碼的持續優化 對一個入門的工程師來說，掌握程式語法與模仿範例實作是基本的能力。那有了這樣的基本能之後，要如何寫出更好的程式呢？怎樣才能夠成為一個「優秀」的新手工程師呢？事實上，寫出會動的程式不難，但想寫出好的程式其實是需要刻意練習的。大部分的人會建議要「多練習、多實作」，但我認為在大量練習之外，適時的「優化程式」也是提升「程式碼品質」重要的關鍵。而在「優化程式」可以分成兩個角度： 程式執行效能更好 程式碼結構更精簡 程式執行效能就是從速度跟空間來思考，執行時間越短、變數佔用空間越小。而程式碼結構則會從可讀性和精簡來衡量，例如：變數的命名有沒有意義、程式碼有沒有冗余、繁瑣的部分等等。只不過新手很容易停留在寫出程式的喜悅以及受到固有的解題思考，而忽略優化的過程。 透過「Code Review」是推薦新手的方法，經由反饋與討論來找出程式中可優化的空間。 ","date":"2021-03-04","objectID":"/posts/codereview/:1:0","tags":["codereview"],"title":"Code Review 怎麼做？新手工程師如何提升「程式碼品質」","uri":"/posts/codereview/"},{"categories":["Memo"],"content":"Code Review 的關注點 以我自己的經驗來說，Review 一份專案的時候會關注： 程式能不能正常操作，有没有什么明显的错误？（低標） 程式碼當中有沒有奇怪的地方？（優化） 第一個關注點是程式碼的低標，結果正確與可正常運行一定是最重要的。如果程式無法運行動或存在很明顯的問題，那再多的優化都沒有意義。除了確保執行之外，同時也會檢查一下是否有低級的邏輯失誤或是安全性的疑慮，像是資料庫沒有正確關閉或密碼明碼沒有加密之類的問題。 第二個關注點是「程式碼品質提升」的部分，我會把它定義成程式運作上沒有問題，但看起來很不舒服或執行效率很差的部分。大致上可以從以下幾點下手： 命名有沒有意義/不一致 資料庫的正規化情況 是否存在特別複雜的程式片段（例如多次的資料庫查詢、多層的迴圈使用） 重複的程式碼有沒有定義成 function 冗長的程式碼能不能拆分成 function 不過一次的 Code Review 建議著重在 3 - 5 個優化地方，比較容易聚焦在優化的品質。根據時程的壓力，決定 Code Review 迭代的次數。 ","date":"2021-03-04","objectID":"/posts/codereview/:2:0","tags":["codereview"],"title":"Code Review 怎麼做？新手工程師如何提升「程式碼品質」","uri":"/posts/codereview/"},{"categories":["Memo"],"content":"從架構的規劃到細節的優化 在拿到一份程式碼時，通常會先掃過一眼程式的檔案結構，是否有不該上傳的檔案或缺漏。 以這個例子來說，第一眼會覺得檔案配置蠻結構化的。但再多看一點會發現存在幾個冗餘的檔案，例如：-filesqqqq、diff，甚至 /icon 資料夾也不該放在最上層。 進入程式的第一步先從 package.json 檔案開始，確認一下專案的基本資訊是否完整、使用到的套件與版本，以及程式的進入點是什麼。然後打開進入點的檔案（通常會命名成 app 或 main），通常有幾個點需要注意：「套件的載入順序」會建議從第三方套件 → 自定義的模組 → 程式內的變數這樣順序定義；「善用 MVC 的架構」將非主程式的部分依照功能拆分模組，避免檔案資訊量太雜亂。接著就會從 Router → Controller → Service → View 的流程一個一個功能，以下分享一些存在優化空間的程式碼： 善用工具，已有的工具，不用自己手刻 變數名稱不建議用大寫開頭（通常是用在 Class 的命名） 保持優化的空間與彈性 「優化其實是一種取捨」，不需要也不應該追求一步到位。開發往往都是在品質跟產出做取捨，初期可以把開發目標放在「先求可以動，再求持續優化」的節奏上。新手需要在意的點有幾下兩點： 很容易把重點全部放在程式碼的產出上而忽略的程式碼的品質。 停留在做出成果的喜悅，而停滯了優化的步調。 因此，會建議在開發當下就「多想」兩秒鐘，感覺可優化但來不及的部分先在旁邊加個註解提醒自己。另外也養成一段時間回頭看之前的程式碼的習慣，試著刻意找出可以優化改進的部分。專案的提交可能會有期限，但程式碼的優化沒有盡頭。面對相同的專案與程式碼，唯有透過不停的迭代優化才能打造更好的程式，同時也見證了你和程式一起變得更好的過程。所以建立逐步優化的空間，養成持續提升程式碼品質的習慣，才是一個新手工程師需要修煉的心法。 ","date":"2021-03-04","objectID":"/posts/codereview/:3:0","tags":["codereview"],"title":"Code Review 怎麼做？新手工程師如何提升「程式碼品質」","uri":"/posts/codereview/"},{"categories":["Projects","瞎折腾"],"content":"起因 起因 事情是這樣，年前和朋友一起合租了一個房子，然後捏，生活嘛，除了開心，當然是乾飯最大啦！ 自然就會有購物，買菜等日常消費，那就要記賬，一開始是各自記在手機的便簽上，最後再算一下； 三個人，一共七种組合消費，排除各自消費的三種情況，也有四種 (AB, AC, BC, ABC)。好麻煩啊！！！ ","date":"2021-03-02","objectID":"/projects/bill-note/:1:0","tags":["JavaScript","leancloud","Vue"],"title":"基于 leancloud-storage 实现的无后端记账本","uri":"/projects/bill-note/"},{"categories":["Projects","瞎折腾"],"content":"經過 作為一個程序猿，怎麼能接受這麼麻煩的記賬方式呢，拿起筆就開始畫，於是有了下面這張圖的公式。簡單說明一下就是： 設前面說的四種組合為：X1, X2, X3, X4，個人實際付款總額為：Y1, Y2, Y3，那麼帶入未知數，我們就可以算出每個人最後結算時的錢：S1, S2, S3， 綜上所述，很好理解，當 S \u003e= 0 時，收紅包，當 S \u003c 0 時，發紅包。 OK，一個簡單的初中方程式已經到位了，下一步，思考一下，用什麼來運作這個這個方程。來，先跑個題，春節期間，不是每天都要在騰訊文檔上填表記錄活動軌跡嗎？ 再回來，那不如就用 excel 實現吧，三個人都可以在手機上編輯。好的，說做就做。 一頓操作，10 minutes later… 只新建了一個 excel 文件，O.o! 不會 excel，果斷放棄，另尋他路。 ","date":"2021-03-02","objectID":"/projects/bill-note/:2:0","tags":["JavaScript","leancloud","Vue"],"title":"基于 leancloud-storage 实现的无后端记账本","uri":"/projects/bill-note/"},{"categories":["Projects","瞎折腾"],"content":"結果 回到本職，那不如寫個網站吧，可是畢業後，學生機服務器也過期了，怎麼搞？那就寫個純前端的，數據呢存哪裡？ 別急，重新擼一擼需求先： 存取消費數據 計算每月，實付（總分），應付以及最後計算結算金額 按月查詢，月結賬單 三人皆可編輯 主要就是存取數據這點，沒有服務器，數據庫怎麼實現？ valine 可以實現無後端，那我是不是也可以，leancloud 文檔走一波，然後“數據表”設計一下，其實是 leancloud-storage Object ，於是有了以下東西，源碼放在 Github bill-note http://github.com/Lruihao/bill-note ","date":"2021-03-02","objectID":"/projects/bill-note/:3:0","tags":["JavaScript","leancloud","Vue"],"title":"基于 leancloud-storage 实现的无后端记账本","uri":"/projects/bill-note/"},{"categories":["Projects","瞎折腾"],"content":"數據設計 去 leancloud 创建一个应用，再新增一个 Bill Class, 补充一下字段： name type description pay Number 消费金额 pay_description String 消费描述 pay_type String 消费类型 pay_user String 付款人 ","date":"2021-03-02","objectID":"/projects/bill-note/:3:1","tags":["JavaScript","leancloud","Vue"],"title":"基于 leancloud-storage 实现的无后端记账本","uri":"/projects/bill-note/"},{"categories":["Projects","瞎折腾"],"content":"主要邏輯 初始化 set for yourself. AV.init({ appId: '', appKey: '', serverURL: '' }); 存數據 //記賬提交按鈕事件監聽 document.querySelector('.submit').addEventListener('click', function (event) { event.preventDefault(); let formPay = document.querySelector('#form-pay'); let bill = new AV.Object('Bill'); bill.set('pay', Number(formPay.pay.value)); bill.set('pay_type', Number(formPay.pay_type.value)); bill.set('pay_user', Number(formPay.pay_user.value)); bill.set('pay_description', formPay.pay_description.value); bill.save().then( (object) =\u003e { formPay.reset(); }, function (error) { console.log(JSON.stringify(error)); alert('保存失敗'); } ); }); 取數據 /** * 獲取歷史消費記錄數據 * @param [start=0] 開始位置 * @param [count=15] 每次查詢筆數 */ function getBillData(start = 0, count = 15) { queryBill .descending('createdAt') .skip(start * count) .limit(count) .find() .then(function (response) { let billLength = response.length; if (billLength \u003e 0) { billVm.noMore = billLength !== count ? true : false; for (bill of response) { billVm.bills.push({ pay: bill.attributes.pay, payType: payType[bill.attributes.pay_type], payUser: payUser[bill.attributes.pay_user], payDescription: bill.attributes.pay_description, payDt: new Date(bill.createdAt).toLocaleString() }); } } else { billVm.noMore = true; } }); } /** * 獲取月賬單數據 * @param month 年月份 fmt: yyyy-MM */ function getMonthBill(month) { let dateTime = `${month} 00:00:00`; let startMonth = new Date(dateTime); let nextMonth = new Date(new Date(dateTime).setMonth(startMonth.getMonth() + 1)); let startDateQuery = new AV.Query('Bill'); startDateQuery.greaterThanOrEqualTo('createdAt', startMonth); let endDateQuery = new AV.Query('Bill'); endDateQuery.lessThan('createdAt', nextMonth); let MonthBillQuery = AV.Query.and(startDateQuery, endDateQuery); MonthBillQuery.find().then(function (response) { billVm.monthBill = { payType0: 0, payType1: 0, payType2: 0, payType3: 0, payUser0: 0, payUser1: 0, payUser2: 0 }; for (bill of response) { let { pay, pay_type, pay_user } = bill.attributes; billVm.monthBill[`payType${pay_type}`] += pay; billVm.monthBill[`payUser${pay_user}`] += pay; } }); } ","date":"2021-03-02","objectID":"/projects/bill-note/:3:2","tags":["JavaScript","leancloud","Vue"],"title":"基于 leancloud-storage 实现的无后端记账本","uri":"/projects/bill-note/"},{"categories":["Projects","瞎折腾"],"content":"技術棧 leancloud-storage Vue.js HTML,CSS,JS ","date":"2021-03-02","objectID":"/projects/bill-note/:3:3","tags":["JavaScript","leancloud","Vue"],"title":"基于 leancloud-storage 实现的无后端记账本","uri":"/projects/bill-note/"},{"categories":["Projects","瞎折腾"],"content":"總結 簡單總結一下，登录功能不做，安不安全自己说了算。删除修改功能也不做，直接上 leancloud 操作，css 美化的样式也不写，干净又卫生！ 然后衍生一下，什么过年斗地主，天炸，麻将，字牌记账系统那不也是同理可得嘛！ over! 效果 ","date":"2021-03-02","objectID":"/projects/bill-note/:4:0","tags":["JavaScript","leancloud","Vue"],"title":"基于 leancloud-storage 实现的无后端记账本","uri":"/projects/bill-note/"},{"categories":["Projects"],"content":" 基于 Laravel7 开发，Markdown 语法的个人独立博客。Cell Blog, 也是我的毕业设计作品，目前已開源。 ","date":"2020-07-25","objectID":"/projects/cell-blog/:0:0","tags":["PHP","Laravel","Markdown"],"title":"cell-blog 功能介绍与安装","uri":"/projects/cell-blog/"},{"categories":["Projects"],"content":"功能 支持 Markdown, 文章实时预览效果 支持多种编程语言代码高亮 编辑器图片上传 后台上传文件管理 文章搜索 文章分类 文章标签 热门文章 随机格言 文章管理（发布，评论开关，排序） 自定义导航（显示开关，排序） 自定义页面（发布开关） 友情链接（显示开关，排序） COS 桶相册 丰富的博客配置（方便扩展，支持自定义 JS 脚本） 不蒜子计数 Leancloud 计数 Valine 评论插件 文章分享插件 ","date":"2020-07-25","objectID":"/projects/cell-blog/:1:0","tags":["PHP","Laravel","Markdown"],"title":"cell-blog 功能介绍与安装","uri":"/projects/cell-blog/"},{"categories":["Projects"],"content":"截图 ","date":"2020-07-25","objectID":"/projects/cell-blog/:2:0","tags":["PHP","Laravel","Markdown"],"title":"cell-blog 功能介绍与安装","uri":"/projects/cell-blog/"},{"categories":["Projects"],"content":"安装 注意事项：PHP 取消禁用函数putenv()和symlink()，安装fileinfo扩展。 下载 git clone https://github.com/Lruihao/cell-blog.git 进入站点 cd cell-blog 生成。env cp .env.example .env 编辑。env 环境配置 APP_URL=http://localhost #使用本地文件系统存储文件时，必须填写正确地址 APP_DEBUG=false #关闭调试 DB_HOST= #数据库地址 DB_PORT=3306 #数据库端口 DB_DATABASE= #数据库名称 DB_USERNAME= #数据库用户 DB_PASSWORD= #数据库密码 打开app\\Providers\\AppServiceProvider.php, 注释SystemController:load() 防止后续步骤报错 public function boot() { Schema::defaultStringLength(191); //SystemController::load(); } 安装项目依赖 composer install 生成 key php artisan key:generate 运行数据迁移和后台数据填充 php artisan admin:install已包含数据迁移命令php artisan migrate G:\\cell-blog\\app\\Admin directory already exists !无需理会，继续执行剩下命令即可。 php artisan admin:install php artisan admin:import media-manager php artisan db:seed 默认下使用了本地文件系统，创建 storage 目录在 public 的软链接 php artisan storage:link 打开app\\Providers\\AppServiceProvider.php, 取消注释SystemController:load() public function boot() { Schema::defaultStringLength(191); SystemController::load(); } 将博客网站根目录指向入口 public 目录 如果使用 Nginx，要设置伪静态 location / { try_files $uri $uri/ /index.php?$query_string; } 启动服务后，在浏览器打开http://localhost/admin/, 使用用户名admin和密码admin登录。 ","date":"2020-07-25","objectID":"/projects/cell-blog/:3:0","tags":["PHP","Laravel","Markdown"],"title":"cell-blog 功能介绍与安装","uri":"/projects/cell-blog/"},{"categories":["Projects"],"content":"License Cell Blog is open-sourced software licensed under the MIT license. ","date":"2020-07-25","objectID":"/projects/cell-blog/:4:0","tags":["PHP","Laravel","Markdown"],"title":"cell-blog 功能介绍与安装","uri":"/projects/cell-blog/"},{"categories":["Memo"],"content":" Cell Blog 开发记录，项目地址 ","date":"2020-07-25","objectID":"/posts/cell-blog-dev/:0:0","tags":["PHP","Laravel","Markdown"],"title":"cell-blog 开发记录","uri":"/posts/cell-blog-dev/"},{"categories":["Memo"],"content":"搭建 php 环境 安装 wampserver 安装 composer 更换 aliyun 源 composer config -g repo.packagist composer https://mirrors.aliyun.com/composer/ ","date":"2020-07-25","objectID":"/posts/cell-blog-dev/:1:0","tags":["PHP","Laravel","Markdown"],"title":"cell-blog 开发记录","uri":"/posts/cell-blog-dev/"},{"categories":["Memo"],"content":"新建 laravel 项目 composer create-project --prefer-dist laravel/laravel cell-blog \"7.*\" 或者 composer global require laravel/installer laravel new blog ","date":"2020-07-25","objectID":"/posts/cell-blog-dev/:2:0","tags":["PHP","Laravel","Markdown"],"title":"cell-blog 开发记录","uri":"/posts/cell-blog-dev/"},{"categories":["Memo"],"content":"下载 debugbar composer require barryvdh/laravel-debugbar --dev ","date":"2020-07-25","objectID":"/posts/cell-blog-dev/:3:0","tags":["PHP","Laravel","Markdown"],"title":"cell-blog 开发记录","uri":"/posts/cell-blog-dev/"},{"categories":["Memo"],"content":"修改语言时区 修改 config/app.php，将 local 的值 en 改成 zh-CN(laravel-admin 自带 zh-CN)： ## 时区 'timezone' =\u003e 'Asia/Shanghai', ## 语言 'locale' =\u003e 'zh-CN', ","date":"2020-07-25","objectID":"/posts/cell-blog-dev/:4:0","tags":["PHP","Laravel","Markdown"],"title":"cell-blog 开发记录","uri":"/posts/cell-blog-dev/"},{"categories":["Memo"],"content":"配置数据库 首先确保安装好了 laravel，并且数据库连接设置正确。 APP_URL=http://cell.blog DB_CONNECTION=mysql DB_HOST=127.0.0.1 DB_PORT=3307 DB_DATABASE=cell_blog DB_USERNAME=root DB_PASSWORD=123456 ","date":"2020-07-25","objectID":"/posts/cell-blog-dev/:5:0","tags":["PHP","Laravel","Markdown"],"title":"cell-blog 开发记录","uri":"/posts/cell-blog-dev/"},{"categories":["Memo"],"content":"下载 laravel-admin cd cell-blog composer require encore/laravel-admin 卸载命令composer remove xxx 然后运行下面的命令来发布资源： php artisan vendor:publish --provider=\"Encore\\Admin\\AdminServiceProvider\" 在该命令会生成配置文件config/admin.php，可以在里面修改安装的地址、数据库连接、以及表名，建议都是用默认配置不修改。 然后运行下面的命令完成安装： php artisan admin:install 运行这个命令的时候，如果遇到了下面的错误： SQLSTATE[42000]: Syntax error or access violation: 1071 Specified key was too long; max key length is 1000 bytes (SQL: alter tableusersadd uniqueusers_email_unique(email)) 参考这个 issue 来解决 https://github.com/z-song/laravel-admin/issues/1541 在app\\Providers\\AppServiceProvider.php添加默认值 \u003c?php namespace App\\Providers; use Illuminate\\Support\\ServiceProvider; use Illuminate\\Support\\Facades\\Schema; //add fixed sql class AppServiceProvider extends ServiceProvider { /** * Bootstrap any application services. * * @return void */ public function boot() { Schema::defaultStringLength(191); //add fixed sql } /** * Register any application services. * * @return void */ public function register() { // } } 启动服务后，在浏览器打开 http://localhost/admin/ , 使用用户名 admin 和密码 admin 登录。 报错Disk [admin] not configured, please add a disk config in config/filesystems.php 在config/filesystems.php中 disks 处添加以下配置后执行php artisan storage:link来创建软链接（windows 和 linux 的软链接不一样不能直接复制！） 宝塔执行时删除禁用函数 putenv(),symlink() 'admin' =\u003e [ 'driver' =\u003e 'local', 'root' =\u003e storage_path('app/public/system'), 'url' =\u003e env('APP_URL').'/storage/system', 'visibility' =\u003e 'public', ], 或 'admin' =\u003e [ 'driver' =\u003e 'local', 'root' =\u003e public_path('uploads'), 'url' =\u003e env('APP_URL').'/public/uploads/', 'visibility' =\u003e 'public', ], ","date":"2020-07-25","objectID":"/posts/cell-blog-dev/:6:0","tags":["PHP","Laravel","Markdown"],"title":"cell-blog 开发记录","uri":"/posts/cell-blog-dev/"},{"categories":["Memo"],"content":"下载 dcat-admin composer require dcat/laravel-admin 然后运行下面的命令来发布资源： php artisan admin:publish 在该命令会生成配置文件config/admin.php，可以在里面修改安装的地址、数据库连接、以及表名，建议都是用默认配置不修改。 然后运行下面的命令完成安装： php artisan admin:install ","date":"2020-07-25","objectID":"/posts/cell-blog-dev/:7:0","tags":["PHP","Laravel","Markdown"],"title":"cell-blog 开发记录","uri":"/posts/cell-blog-dev/"},{"categories":["Memo"],"content":"迁移文件创建表 php artisan make:migration create_articles_table php artisan make:migration create_tags_table php artisan make:migration create_categories_table php artisan make:migration create_article_tags_table php artisan make:migration create_navigations_table php artisan make:migration create_friendship_links_table php artisan make:migration create_pages_table php artisan make:migration create_systems_table php artisan make:migration create_mottoes_table 运行迁移 php artisan migrate ","date":"2020-07-25","objectID":"/posts/cell-blog-dev/:8:0","tags":["PHP","Laravel","Markdown"],"title":"cell-blog 开发记录","uri":"/posts/cell-blog-dev/"},{"categories":["Memo"],"content":"创建模型 model php artisan make:model Models/Article php artisan make:model Models/Category php artisan make:model Models/Tag php artisan make:model Models/Navigation php artisan make:model Models/FriendshipLink php artisan make:model Models/Page php artisan make:model Models/System php artisan make:model Models/Motto ","date":"2020-07-25","objectID":"/posts/cell-blog-dev/:9:0","tags":["PHP","Laravel","Markdown"],"title":"cell-blog 开发记录","uri":"/posts/cell-blog-dev/"},{"categories":["Memo"],"content":"创建控制器 php artisan admin:make ArticleController --model=App\\Models\\Article php artisan admin:make CategoryController --model=App\\Models\\Category php artisan admin:make TagController --model=App\\Models\\Tag php artisan admin:make NavigationController --model=App\\Models\\Navigation php artisan admin:make FriendshipLinkController --model=App\\Models\\FriendshipLink php artisan admin:make PageController --model=App\\Models\\Page php artisan admin:make SystemController --model=App\\Models\\System php artisan admin:make MottoController --model=App\\Models\\Motto ","date":"2020-07-25","objectID":"/posts/cell-blog-dev/:10:0","tags":["PHP","Laravel","Markdown"],"title":"cell-blog 开发记录","uri":"/posts/cell-blog-dev/"},{"categories":["Memo"],"content":"添加后台路由 app/Admin/routes.php $router-\u003eresource('articles', ArticleController::class); $router-\u003eresource('categories', CategoryController::class); $router-\u003eresource('tags', TagController::class); $router-\u003eresource('navigations', NavigationController::class); $router-\u003eresource('friendship-links', FriendshipLinkController::class); $router-\u003eresource('pages', PageController::class); $router-\u003eresource('systems', SystemController::class); $router-\u003eresource('mottoes', MottoController::class); ","date":"2020-07-25","objectID":"/posts/cell-blog-dev/:11:0","tags":["PHP","Laravel","Markdown"],"title":"cell-blog 开发记录","uri":"/posts/cell-blog-dev/"},{"categories":["Memo"],"content":"editormd 安装 editormd github 图像问题 ","date":"2020-07-25","objectID":"/posts/cell-blog-dev/:12:0","tags":["PHP","Laravel","Markdown"],"title":"cell-blog 开发记录","uri":"/posts/cell-blog-dev/"},{"categories":["Memo"],"content":"存放本地表情 public\\vendor\\laravel-admin-ext\\editormd\\editormd-1.5.0\\images\\emojis 修改 editormd.js 及 editormd.min.js // Emoji graphics files url path editormd.emoji = { path : \"/iamges/emojis/\", ext : \".png\" }; ","date":"2020-07-25","objectID":"/posts/cell-blog-dev/:12:1","tags":["PHP","Laravel","Markdown"],"title":"cell-blog 开发记录","uri":"/posts/cell-blog-dev/"},{"categories":["Memo"],"content":"图片上传 csrf 419 错误 可以在VerifyCsrfToken.php中添加白名单跳过验证，或者手动添加 csrf 验证器： 修改 image-dialog.js 的var dialogContent 参考 if (settings.crossDomainUpload) { action += \"\u0026callback=\" + settings.uploadCallbackURL + \"\u0026dialog_id=editormd-image-dialog-\" + guid; } //添加 csrf 验证 var csrfToken = $('meta[name=\"csrf-token\"]').attr('content'); var csrfField = \"\"; if (csrfToken) { csrfField = \"\u003cinput type='hidden' name='_token' value='\" + csrfToken + \"' /\u003e\"; } ","date":"2020-07-25","objectID":"/posts/cell-blog-dev/:12:2","tags":["PHP","Laravel","Markdown"],"title":"cell-blog 开发记录","uri":"/posts/cell-blog-dev/"},{"categories":["Memo"],"content":"markdown 转 HTML https://www.zhiqiexing.com/119.html Laravel Markdown 安装 composer require graham-campbell/markdown php artisan vendor:publish 扩展表格 composer require league/commonmark config/markdown.php 'extensions' =\u003e [ League\\CommonMark\\Extension\\TaskList\\TaskListExtension::class, ], ","date":"2020-07-25","objectID":"/posts/cell-blog-dev/:13:0","tags":["PHP","Laravel","Markdown"],"title":"cell-blog 开发记录","uri":"/posts/cell-blog-dev/"},{"categories":["Memo"],"content":"Eloquent 模型事件 Eloquent 模型可以触发事件，允许你在模型生命周期中的多个时间点调用如下这些方法：retrieved, creating, created, updating, updated, saving, saved, deleting, deleted, restoring, restored。事件允许你在一个指定模型类每次保存或更新的时候执行代码。 retrieved 事件会在从数据库中获取已存在模型时触发。当一个新模型被首次保存的时候，creating 和 created 事件会被触发。如果一个模型已经在数据库中存在并调用 save 方法，updating/updated 事件会被触发，无论是创建还是更新，saving/saved 事件都会被触发。 ","date":"2020-07-25","objectID":"/posts/cell-blog-dev/:14:0","tags":["PHP","Laravel","Markdown"],"title":"cell-blog 开发记录","uri":"/posts/cell-blog-dev/"},{"categories":["Memo"],"content":"添加后台验证码 依赖 php 扩展fileinfo 添加验证码 ","date":"2020-07-25","objectID":"/posts/cell-blog-dev/:15:0","tags":["PHP","Laravel","Markdown"],"title":"cell-blog 开发记录","uri":"/posts/cell-blog-dev/"},{"categories":["Memo"],"content":"Media manager composer require laravel-admin-ext/media-manager php artisan admin:import media-manager ’extensions’ =\u003e [ ‘media-manager’ =\u003e [ // Select a local disk that you configured in config/filesystem.php ‘disk’ =\u003e ‘public’ ], ], ## 给 laravel-admin 增加锁屏功能 composer require laravel-admin-ext/lock-screen 'route' =\u003e [ 'prefix' =\u003e 'demo', 'namespace' =\u003e 'App\\\\Admin\\\\Controllers', // 在中间件数组中加上'admin.lock' 'middleware' =\u003e ['web', 'admin', 'admin.lock'], ], ","date":"2020-07-25","objectID":"/posts/cell-blog-dev/:16:0","tags":["PHP","Laravel","Markdown"],"title":"cell-blog 开发记录","uri":"/posts/cell-blog-dev/"},{"categories":["Memo"],"content":"前台设计 创建控制器 php artisan make:controller HomeController php artisan make:controller ArticleController php artisan make:controller CategoryController php artisan make:controller TagController php artisan make:controller PageController ","date":"2020-07-25","objectID":"/posts/cell-blog-dev/:17:0","tags":["PHP","Laravel","Markdown"],"title":"cell-blog 开发记录","uri":"/posts/cell-blog-dev/"},{"categories":["Memo"],"content":"后台 img 灯箱 https://github.com/laravel-admin-extensions/grid-lightbox composer require laravel-admin-ext/grid-lightbox php artisan vendor:publish --tag=laravel-admin-grid-lightbox ","date":"2020-07-25","objectID":"/posts/cell-blog-dev/:18:0","tags":["PHP","Laravel","Markdown"],"title":"cell-blog 开发记录","uri":"/posts/cell-blog-dev/"},{"categories":["瞎折腾","Python"],"content":" 使用 python 模拟浏览器行为刷 csdn 访问量，脚本仅做学习，请勿滥用~ 直接丢代码，把代码挂到服务器上可以策马奔腾~，也可以生成二进制文件放到 Windows 桌面上随时使用~ 打包 exe 参考 #!/usr/bin/python # -*- coding: utf-8 -*- __author__ = 'lruihao.cn' import urllib.request import re import time from bs4 import BeautifulSoup opener = urllib.request.build_opener() opener.addheaders = [('User-agent', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2125.122 UBrowser/4.0.3214.0 Safari/537.36')] def get_article_url(page,name): endurl = \"/\"+name+\"/article/details/........\" print(name) p = re.compile(endurl) url = \"http://blog.csdn.net/\"+name+\"/article/list/\"+str(page) # 使用 build_opener() 是为了让 python 程序模仿浏览器进行访问 html = opener.open(url).read().decode('utf-8') allfinds = p.findall(html) return allfinds #print('allfinds',allfinds) def start_do(allfinds): urlBase = \"http://blog.csdn.net\" # 需要将网址合并的部分 # 页面中的网址有重复的，需要使用 set 进行去重复 mypages = list(set(allfinds)) for i in range(len(mypages)): mypages[i] = urlBase + mypages[i] print('要刷的网页有：') for index, page in enumerate(mypages): print(str(index), page) # 设置每个网页要刷的次数 brushNum = 1 # 所有的页面都刷 print('下面开始刷了哦：') for index, page in enumerate(mypages): for j in range(brushNum): try: pageContent = opener.open(page).read().decode('utf-8') # 使用 BeautifulSoup 解析每篇博客的标题 soup = BeautifulSoup(pageContent) blogTitle = str(soup.title.string) blogTitle = blogTitle[0:blogTitle.find('-')] print(str(j), blogTitle) except urllib.error.HTTPError: print('urllib.error.HTTPError') time.sleep(3) # 出现错误，停几秒先 except urllib.error.URLError: print('urllib.error.URLError') time.sleep(3) # 出现错误，停几秒先 time.sleep(0.5) # 正常停顿，以免服务器拒绝访问 def main(name): for page in range(1,5): print(\"************第\"+str(page)+\"页*************\") endurl = get_article_url(page,name) start_do(endurl) if __name__ == '__main__': name = input(\"输入你的 csdn 用户名：\") if name==\"\": name = \"qq_39520417\" #cheung99857 while 1: main(name) print(\"开始休息 ...\") time.sleep(40) 主函数也可以这样写实现同时刷多人的访问量，人多可以适当减少休眠时间，当然有兴趣的可以尝试一下多线程~ if __name__ == '__main__': # 多用户 names = [\"qq_39520417\",\"cheung99857\"] while 1: for name in names: main(name) print(\"开始休息 ...\") # 控制休眠时间相当于控制刷新的速度 time.sleep(30) ","date":"2020-03-26","objectID":"/posts/csdnvisiter/:0:0","tags":["Python"],"title":"使用 Python 刷 csdn 访问量","uri":"/posts/csdnvisiter/"},{"categories":["OS"],"content":"基本语法 \u003c秒\u003e \u003c分钟\u003e \u003c小时\u003e \u003c日期 day-of-month\u003e \u003c月份\u003e \u003c星期 day-of-week\u003e Cron 表达式是一个具有时间含义的字符串，字符串以 5 个空格隔开，分为 6 个域，格式为 X X X X X X。其中 X 是一个域的占位符。单个域有多个取值时，使用半角逗号，隔开取值。每个域可以是确定的取值，也可以是具有逻辑意义的特殊字符。 ","date":"2020-03-25","objectID":"/posts/cron/:1:0","tags":["linux","shell","Cron"],"title":"Cron 表达式的基本语法","uri":"/posts/cron/"},{"categories":["OS"],"content":"域取值 位置 字段 约束 取值 可使用的特殊符号 1 秒 必须 0-59 , - * / 2 分钟 必须 0-59 , - * / 3 小时 必须 0-23（0 为午夜） , - * / 4 日期 必须 1-31 , - * ? / L W 5 月份 必须 1-12 或者 JAN-DEC , - * / 6 星期 必须 1-7 或者 SUN-SAT (1 代表星期一） , - ? / L # ","date":"2020-03-25","objectID":"/posts/cron/:2:0","tags":["linux","shell","Cron"],"title":"Cron 表达式的基本语法","uri":"/posts/cron/"},{"categories":["OS"],"content":"特殊符号 符号 含义 示例 * 所有可能的值。 在月域中，*表示每个月；在星期域中，*表示星期的每一天。 , 列出枚举值。 在分钟域中，5,20表示分别在 5 分钟和 20 分钟触发一次。 - 范围。 在分钟域中，5-20表示从 5 分钟到 20 分钟之间每隔一分钟触发一次。 / 指定数值的增量。 在分钟域中，0/15表示从第 0 分钟开始，每 15 分钟。在分钟域中3/20表示从第 3 分钟开始，每 20 分钟。*/ 和 0/ 相同 ? 不指定值，仅日期和星期域支持该字符。 当日期或星期域其中之一被指定了值以后，为了避免冲突，需要将另一个域的值设为?。 L 单词 Last 的首字母，表示最后一天，仅日期和星期域支持该字符。说明 指定L字符时，避免指定列表或者范围，否则，会导致逻辑问题。 在日期域中，L表示某个月的最后一天。在星期域中，L表示一个星期的最后一天，也就是星期日（SUN）。如果在L前有具体的内容，例如，在星期域中的6L表示这个月的最后一个星期六。 W 除周末以外的有效工作日，在离指定日期的最近的有效工作日触发事件。W字符寻找最近有效工作日时不会跨过当前月份，连用字符LW时表示为指定月份的最后一个工作日。 在日期域中5W，如果 5 日是星期六，则将在最近的工作日星期五，即 4 日触发。如果 5 日是星期天，则将在最近的工作日星期一，即 6 日触发；如果 5 日在星期一到星期五中的一天，则就在 5 日触发。 # 确定每个月第几个星期几，仅星期域支持该字符。 在星期域中，4#2表示某月的第二个星期四。 ","date":"2020-03-25","objectID":"/posts/cron/:3:0","tags":["linux","shell","Cron"],"title":"Cron 表达式的基本语法","uri":"/posts/cron/"},{"categories":["OS"],"content":"举个栗子 🌰 表达式 说明 0 0/5 * * * ? 每隔 5 分钟执行一次 10 0/5 * * * ? 每隔 5 分钟执行一次，每次执行都在分钟开始的 10 秒，例如 10:00:10、10:05:10 等等。 0 30 10-13 ? * WED,FRI 每周三和每周五的 10:30、11:30、12:30、13:30 执行。 0 0/30 8-9 5,20 * ? 每个月的 5 号和 20 号的 8 点和 10 点之间每隔 30 分钟执行一次，也就是 8:00、8:30、9:00 和 9:30。 0 15 10 ? * * 每天上午 10:15 执行任务 0 15 10 * * ? 每天上午 10:15 执行任务 0 0 12 * * ? 每天中午 12:00 执行任务 0 0 10,14,16 * * ? 每天上午 10:00 点、下午 14:00 以及下午 16:00 执行任务 0 0/30 9-17 * * ? 每天上午 09:00 到下午 17:00 时间段内每隔半小时执行任务 0 * 14 * * ? 每天下午 14:00 到下午 14:59 时间段内每隔 1 分钟执行任务 0 0-5 14 * * ? 每天下午 14:00 到下午 14:05 时间段内每隔 1 分钟执行任务 0 0/5 14 * * ? 每天下午 14:00 到下午 14:55 时间段内每隔 5 分钟执行任务 0 0/5 14,18 * * ? 每天下午 14:00 到下午 14:55、下午 18:00 到下午 18:55 时间段内每隔 5 分钟执行任务 0 0 12 ? * WED 每个星期三中午 12:00 执行任务 0 15 10 15 * ? 每月 15 日上午 10:15 执行任务 0 15 10 L * ? 每月最后一日上午 10:15 执行任务 0 15 10 ? * 6L 每月最后一个星期六上午 10:15 执行任务 0 15 10 ? * 6#3 每月第三个星期六上午 10:15 执行任务 0 10,44 14 ? 3 WED 每年 3 月的每个星期三下午 14:10 和 14:44 执行任务 ","date":"2020-03-25","objectID":"/posts/cron/:4:0","tags":["linux","shell","Cron"],"title":"Cron 表达式的基本语法","uri":"/posts/cron/"},{"categories":["瞎折腾","Python"],"content":" 信息 这件事还得从一只蝙蝠说起 … 算了，昨天下午 3 点半，我还在王者峡谷 Timing, 突然潇 X 巴哥打了个电话给我说关于自动打卡的想法 … 哎，反正就是由于疫情需要每天健康打卡汇报给学校，然后每天提交一样的太麻烦了，就想写个程序自动打卡 … 我和潇 X 巴哥确定思路后兵分两路： 他用 java 写个后台自动刷多人的，再弄个网页给用户填写账号密码保存在数据库； 我想的就很直接，只刷一个人的，python 模拟浏览器登录后打卡，再设置定时任务（多人则设定多个）； ","date":"2020-03-25","objectID":"/posts/daka/:0:0","tags":["Python","HTTP"],"title":"新冠疫情未返校未返工第 N 天之“自动打卡”","uri":"/posts/daka/"},{"categories":["瞎折腾","Python"],"content":"Windows 运行效果 打卡成功 重复打卡 定时任务日志 ","date":"2020-03-25","objectID":"/posts/daka/:1:0","tags":["Python","HTTP"],"title":"新冠疫情未返校未返工第 N 天之“自动打卡”","uri":"/posts/daka/"},{"categories":["瞎折腾","Python"],"content":"核心代码 适用湖南工程学院的打卡系统。 请勿滥用代码提交不实健康信息，隐瞒疫情将受到相关法律处理！ 完整代码 def lajaDaka(): # 登录 r1 = requests.post(login_url, data=login,headers=headers,verify=False) if r1.status_code == 200: print(time.strftime(\"%Y:%m:%d:%H:%M\", time.localtime())) print(login[\"username\"] + \" 登录成功！\") # 拿到登录后的 cookie 并添加到 header 中 header1 = r1.headers headers[\"Cookie\"] = header1[\"Set-Cookie\"] else: return # 打卡 r2 = requests.post(daka_url, data=daka,headers=headers,verify=False) response2=r2.json() if r2.status_code != 200: print(\"打卡失败！\") return if response2[\"result\"] == True: print(\"打卡成功！\") else: print(response2[\"errorInfoList\"][0][\"message\"]) if __name__==\"__main__\": lajaDaka() ","date":"2020-03-25","objectID":"/posts/daka/:2:0","tags":["Python","HTTP"],"title":"新冠疫情未返校未返工第 N 天之“自动打卡”","uri":"/posts/daka/"},{"categories":["瞎折腾","Python"],"content":"自动运行 ","date":"2020-03-25","objectID":"/posts/daka/:3:0","tags":["Python","HTTP"],"title":"新冠疫情未返校未返工第 N 天之“自动打卡”","uri":"/posts/daka/"},{"categories":["瞎折腾","Python"],"content":"Windows 适用 python 代码控制休眠时间 if __name__==\"__main__\": while True: now_hour = time.strftime(\"%H\", time.localtime()) now_min = time.strftime(\"%M\", time.localtime()) # 设置每天 8 点发送 if now_hour \u003c \"08\": rest = 8 - int(now_hour) sleeptime = (rest-1)*3600 + (60-int(now_min))*60 print(\"启动时北京时间为：\"+time.strftime(\"%H:%M\", time.localtime()),\"\\t 脚本将在\",rest-1,\"小时\",int((sleeptime-(rest-1)*3600)/60),\"分钟后打卡\") time.sleep(sleeptime) elif now_hour \u003e \"08\": rest = 8 - int(now_hour) + 24 sleeptime = (rest-1)*3600 + (60-int(now_min))*60 print(\"启动时北京时间为：\"+time.strftime(\"%H:%M\", time.localtime()),\"\\t 脚本将在\",rest-1,\"小时\",int((sleeptime-(rest-1)*3600)/60),\"分钟后打卡\") time.sleep(sleeptime) elif now_hour == \"08\": print(\"软件明天开始将在每天 8 点发送数据！\") lajaDaka() time.sleep(24*60*60-int(now_min)*60) ","date":"2020-03-25","objectID":"/posts/daka/:3:1","tags":["Python","HTTP"],"title":"新冠疫情未返校未返工第 N 天之“自动打卡”","uri":"/posts/daka/"},{"categories":["瞎折腾","Python"],"content":"linux（云服务器） 搭建 python 环境下载依赖后，使用 shell 脚本定时执行。 python /home/python/yiban_daka/daka.py CRON 表达式的基本语法 ","date":"2020-03-25","objectID":"/posts/daka/:3:2","tags":["Python","HTTP"],"title":"新冠疫情未返校未返工第 N 天之“自动打卡”","uri":"/posts/daka/"},{"categories":["瞎折腾","Python"],"content":"潇 x 巴哥的 java web 版本 符合程序员的应该有的简洁和方便，干净又卫生！ http://39.105.174.214/index.html java web 版 ","date":"2020-03-25","objectID":"/posts/daka/:4:0","tags":["Python","HTTP"],"title":"新冠疫情未返校未返工第 N 天之“自动打卡”","uri":"/posts/daka/"},{"categories":["MySQL"],"content":" SQL 增删改查 (CRUD) 语句与常用函数总结。 ","date":"2020-01-16","objectID":"/posts/sql/:0:0","tags":["MySQL"],"title":"SQL 总结","uri":"/posts/sql/"},{"categories":["MySQL"],"content":"SQL Introduction 一般我们对数据库的操作主要分为四种，增** C**(CREATE)、删** D**(DELETE)、改** U**(UPDATE)、查** R**(READ)，所以，我就从** CRUD **这四个方面来制作查询表。 开发规则： 尽量减少对数据库的访问次数，且不能查询无用的数据，浪费效能（例如：我只要男生的数据，你把所有人的数据都查询出来）。 属于SQL语法的要使用大写 （SELECT, WHERE, INSERT etc…）。 属于使用者自己定义的要使用小写（表名、列名 etc…）。 表名与列名前后使用 ` 包起来，防止与关键字冲突（例如： INSERT INTO `user` VALUES(‘a’,‘b’); ）。 禁止使用 Table Join。 禁止使用 Oracle Trigger。 禁止使用 SELECT * （为了加强代码可读性）。 不能将查询数据库的 SQL 放在循环中查询。 ","date":"2020-01-16","objectID":"/posts/sql/:1:0","tags":["MySQL"],"title":"SQL 总结","uri":"/posts/sql/"},{"categories":["MySQL"],"content":"新增（CREATE） 功能 语句 创建数据库 CREATE DATABASE \u003c数据库名\u003e; 创建数据表 CREATE TABLE \u003c表名\u003e (\u003c列名 1\u003e \u003c数据类型\u003e \u003c约束条件\u003e,\u003c列名 2\u003e \u003c数据类型\u003e \u003c约束条件\u003e,\u003c列名 3\u003e \u003c数据类型\u003e \u003c约束条件\u003e,......\u003c该表的的约束条件 1\u003e \u003c该表的的约束条件 2\u003e...); 插入数据 INSERT INTO \u003c表名\u003e （列名 1, 列名 2,...) VALUES （值 1, 值 2,...);（每列都有数据插入时，可省略列名。但是为了代码的可读性，不建议如此操作。） 增加列 ALTER TABLE \u003c表名\u003e ADD \u003c列名\u003e \u003c数据类型\u003e \u003c约束条件\u003e AFTER \u003c前一列列名\u003e;（默认插入到最后一列） ","date":"2020-01-16","objectID":"/posts/sql/:2:0","tags":["MySQL"],"title":"SQL 总结","uri":"/posts/sql/"},{"categories":["MySQL"],"content":"删除（DELETE） 功能 语句 删除数据库 DROP DATABASE \u003c数据库名\u003e; 删除数据表 DROP TABLE \u003c表名\u003e; 清空表数据 DELETE FROM \u003c表名\u003e; 或者 TRUNCATE TABLE \u003c表名\u003e; 删除行数据 DELETE FROM \u003c表名\u003e WHERE \u003c条件\u003e; 删除列数据 ALTER TABLE \u003c表名\u003e DROP \u003c列名\u003e; ","date":"2020-01-16","objectID":"/posts/sql/:3:0","tags":["MySQL"],"title":"SQL 总结","uri":"/posts/sql/"},{"categories":["MySQL"],"content":"修改（UPDATE） 功能 语句 修改数据库名 RENAME DATABASE \u003c旧名称\u003e TO \u003c新名称\u003e; 修改表名 RENAME TABLE \u003c旧名称\u003e TO \u003c新名称\u003e; 修改数据 UPDATE \u003c表名\u003e SET \u003c列名 1\u003e = \u003c新值 1\u003e,\u003c列名 2\u003e = \u003c新值 2\u003e WHERE \u003c条件\u003e; 修改列名 ALTER TABLE \u003c表名\u003e CHANGE \u003c旧列名\u003e \u003c新列名\u003e \u003c数据类型\u003e \u003c约束条件\u003e; 注意：重命名数据库与数据表一般不推荐使用，若想测试，请先备份好自己的数据库~ ","date":"2020-01-16","objectID":"/posts/sql/:4:0","tags":["MySQL"],"title":"SQL 总结","uri":"/posts/sql/"},{"categories":["MySQL"],"content":"查询（ R E A D ） 功能 语句 查询所有数据库 SHOW DATABASES; 查询指定数据库中所有表名 USE \u003c数据库名\u003e; 然后 SHOW TABLES;或者 SHOW TABLES FROM \u003c数据库名\u003e; 查询表中所有列信息 SHOW COLUMNS FROM \u003c表名\u003e; 查询表中所有数据 SELECT \u003c列名 1\u003e,\u003c列名 2\u003e,\u003c列名 3\u003e,... FROM \u003c表名\u003e; 查询表中某个数据 SELECT \u003c列名\u003e FROM \u003c表名\u003e; 查询表中指定多个数据 SELECT \u003c列名 1\u003e,\u003c列名 2\u003e,\u003c列名 3\u003e,... FROM \u003c表名\u003e WHERE \u003c条件\u003e; 查询表中指定一个数据 SELECT \u003c列名\u003e FROM \u003c表名\u003e WHERE \u003c条件\u003e; 查询指定范围数据 SELECT \u003c列名 1\u003e,\u003c列名 2\u003e,\u003c列名 3\u003e,... FROM \u003c表名\u003e WHERE \u003c某列名\u003e BETWEEN \u003c某列名范围值-小\u003e AND \u003c某列名范围值-大\u003e; 字符串模式匹配查询 SELECT \u003c列名\u003e FROM \u003c表名\u003e WHERE name LIKE 'Y%';（查询以 Y 开头的，更多匹配方式自行百度哦~。） 指定多个值数据查询 SELECT \u003c列名 1\u003e,\u003c列名 2\u003e,\u003c列名 3\u003e,... FROM \u003c表名\u003e WHERE \u003c某列名\u003e IN ('\u003c某列名值 1\u003e','\u003c某列名值 2\u003e','\u003c某列名值 3\u003e',...); 查询结果排序 SELECT \u003c列名 1\u003e,\u003c列名 2\u003e,\u003c列名 3\u003e,... FROM \u003c表名\u003e ORDER BY \u003c某列名\u003e DESC;（此处为递减排列，默认为递增ASC） 查询指定几笔数据 SELECT \u003c列名 1\u003e,\u003c列名 2\u003e,\u003c列名 3\u003e,... FROM \u003c表名\u003e LIMIT n,m;（从n到m笔数据） 分群查询 SELECT \u003c列名 1\u003e,\u003c列名 2\u003e,\u003c列名 3\u003e,...,\u003c函数\u003e FROM \u003c表名\u003e GROUP BY \u003c列名 1\u003e,\u003c列名 2\u003e,\u003c列名 3\u003e,...;（常搭配函数有：SUM()、AVG()、COUNT()、MAX()、MIN()） ","date":"2020-01-16","objectID":"/posts/sql/:5:0","tags":["MySQL"],"title":"SQL 总结","uri":"/posts/sql/"},{"categories":["MySQL"],"content":"常用函数 函数名 用途 ABS（数值） ABS 函数（求绝对值） MOD（被除数，除数） MOD 函数（求余） ROUND（对象数值，保留小数的位数） ROUND 函数（四舍五入） 字符串 1 ΙΙ 字符串 2 ΙΙ 函数（拼接） LENGTH（字符串） LENGTH 函数（求字符串长度） LOWER（字符串） LOWER 函数（小写转换） UPPER（字符串） UPPER 函数（大写转换） REPLACE（对象字符串，替换前的字符串，替换后的字符串） REPLACE 函数（字符串的替换） SUBSTRING （对象字符串，截取的起始位置，截取的字符数） SUBSTRING 函数（字符串的截取） CURRENT_DATE CURRENT_DATE 函数（当前日期） CURRENT_TIME CURRENT_TIME 函数（当前时间） CURRENT_TIMESTAMP CURRENT_TIMESTAMP 函数（当前日期和时间） EXTRACT（日期元素 FROM 日期） EXTRACT 函数（截取日期元素） CAST（转换前的值 AS 想要转换的数据类型） CAST 函数（类型转换） COALESCE（数据 1, 数据 2, 数据 3….) COALESCE 函数（将 NULL 转换为其他值） 补充：CASE 表达式。 CASE WHEN \u003c求值表达式\u003e THEN \u003c表达式\u003e WHEN \u003c求值表达式\u003e THEN \u003c表达式\u003e WHEN \u003c求值表达式\u003e THEN \u003c表达式\u003e ...... ELSE \u003c表达式\u003e END ","date":"2020-01-16","objectID":"/posts/sql/:6:0","tags":["MySQL"],"title":"SQL 总结","uri":"/posts/sql/"},{"categories":["MySQL"],"content":"其他知识 ","date":"2020-01-16","objectID":"/posts/sql/:7:0","tags":["MySQL"],"title":"SQL 总结","uri":"/posts/sql/"},{"categories":["MySQL"],"content":"常见数据类型 ","date":"2020-01-16","objectID":"/posts/sql/:7:1","tags":["MySQL"],"title":"SQL 总结","uri":"/posts/sql/"},{"categories":["MySQL"],"content":"别名 给表设置别名，让 SQL 更简洁。例如： SELECT \u003ccol-1\u003e,\u003ccol-2\u003e,\u003ccol-3\u003e,... FROM \u003ctable1\u003e \u003calias-a\u003e,\u003ctable2\u003e \u003calias-b\u003e WHERE \u003calias-a\u003e.\u003cid\u003e = \u003calias-b\u003e.\u003cid\u003e; 列名也可以设置别名。例如： SELECT \u003ccol-1\u003e \u003calias-a\u003e,\u003ccol-2\u003e \u003calias-b\u003e,\u003ccol-3\u003e \u003calias-c\u003e,... FROM \u003ctable\u003e; 或者 SELECT \u003ccol-1\u003e AS \u003calias-a\u003e,\u003ccol-2\u003e AS \u003calias-b\u003e,\u003ccol-3\u003e AS \u003calias-c\u003e,... FROM \u003ctable\u003e; ","date":"2020-01-16","objectID":"/posts/sql/:7:2","tags":["MySQL"],"title":"SQL 总结","uri":"/posts/sql/"},{"categories":["MySQL"],"content":"总结 以上整理的内容均为基础内容，更多进阶知识还需各位自行 Google。 ","date":"2020-01-16","objectID":"/posts/sql/:8:0","tags":["MySQL"],"title":"SQL 总结","uri":"/posts/sql/"},{"categories":["Projects","JavaScript"],"content":" 信息 cos 桶相册，终于！！终于来了！！，idea 来自 [兰州小红鸡 - 给 hexo 静态博客添加动态相册功能]， 功能虽好，但是还是先友情提示！ 开放 API 是一个很危险的操作，意味着你的 cos 桶里面的所有资源包括目录结构都暴露的整个世界中，所以建议不要放一些比较私密的照片，保护自己的隐私，提防不良用心之人。下面就开始吧！ ","date":"2019-11-24","objectID":"/projects/cos-album/:0:0","tags":["CosAlbum","腾讯云 cos 桶","JavaScript"],"title":"利用腾讯云为静态页面添加“动态”相册","uri":"/projects/cos-album/"},{"categories":["Projects","JavaScript"],"content":"创建腾讯云 cos 存储桶 就创建一个 COS 就好了！有几点注意事项： 权限设置为共有读私有写 policy 权限设置整个桶的读操作 跨域访问 CORS 设置，自己随意 ","date":"2019-11-24","objectID":"/projects/cos-album/:1:0","tags":["CosAlbum","腾讯云 cos 桶","JavaScript"],"title":"利用腾讯云为静态页面添加“动态”相册","uri":"/projects/cos-album/"},{"categories":["Projects","JavaScript"],"content":"上传照片 首先我这个 cos 相册，相册分类就是文件夹分类，所以 cos 桶里面先新建不同的文件夹，文件夹名称就是相册名称， 每个相册里面需要放置一张名称为**“封面.jpg”**的图片作为该相册的封面。 ","date":"2019-11-24","objectID":"/projects/cos-album/:2:0","tags":["CosAlbum","腾讯云 cos 桶","JavaScript"],"title":"利用腾讯云为静态页面添加“动态”相册","uri":"/projects/cos-album/"},{"categories":["Projects","JavaScript"],"content":"上传工具 COSBrowser GUI 工具，桌面/移动版 【官方、推荐】 COSCMD 命令行工具 【官方】 PicGo 图床上传工具 【第三方、推荐】 ","date":"2019-11-24","objectID":"/projects/cos-album/:2:1","tags":["CosAlbum","腾讯云 cos 桶","JavaScript"],"title":"利用腾讯云为静态页面添加“动态”相册","uri":"/projects/cos-album/"},{"categories":["Projects","JavaScript"],"content":"食用方式 cos album 相册源码下载地址，别忘点赞哈 http://github.com/Lruihao/cos-album 首先，下载源码，引入 cos-album.css 和 cos-album.js 然后，在你的 js 中 new 一个 Cosalbum 对象 ( xmlLink 后不需要添加/) ","date":"2019-11-24","objectID":"/projects/cos-album/:3:0","tags":["CosAlbum","腾讯云 cos 桶","JavaScript"],"title":"利用腾讯云为静态页面添加“动态”相册","uri":"/projects/cos-album/"},{"categories":["Projects","JavaScript"],"content":"Step1 \u003clink rel=\"stylesheet\" type=\"text/css\" href=\"cos-album.min.css?v=1.1.2\"\u003e \u003cscript type=\"text/javascript\" src=\"cos-album.min.js?v=1.1.2\"\u003e\u003c/script\u003e ","date":"2019-11-24","objectID":"/projects/cos-album/:3:1","tags":["CosAlbum","腾讯云 cos 桶","JavaScript"],"title":"利用腾讯云为静态页面添加“动态”相册","uri":"/projects/cos-album/"},{"categories":["Projects","JavaScript"],"content":"Step2 \u003cscript type=\"text/javascript\"\u003e new Cosalbum({ 'xmlLink': 'https://img-xxxxxxxxxx.cos.ap-chengdu.myqcloud.com', 'prependTo': '.cos-album', 'viewNum': 8, 'imgUrl': '//img.lruihao.cn' }); \u003c/script\u003e ","date":"2019-11-24","objectID":"/projects/cos-album/:3:2","tags":["CosAlbum","腾讯云 cos 桶","JavaScript"],"title":"利用腾讯云为静态页面添加“动态”相册","uri":"/projects/cos-album/"},{"categories":["Projects","JavaScript"],"content":"Params param type default description xmlLink String 需要解析的騰訊云 COS 桶 XML 鏈接 prependTo String ‘body’ 可選解析相冊到某個節點 viewNum Number 4 每個相冊顯示的照片數目 copyUrl String href CDN 链接，雙擊複製 URL Since: 1.1.6 imgType String [‘jpg’, ‘jpeg’, ‘png’, ‘gif’, ‘svg’] 图片類型 Since: 1.1.6 videoType String [‘mp4’, ‘mp3’, ‘avi’, ‘mov’, ‘qt’] 視頻類型 Since: 1.1.6 viewport 视个人情况添加。 hexo 中使用时 css 和 js 都需要做适当调整，配合加密功能使用等等，这里不再展开。 注：代码设定不加载根目录文件，所以可以利用静态服务把源码部署在根目录，配合 PicGo、COSBrowser 上传来搭建个人图床。 \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\" /\u003e \u003ctitle\u003ecos-album\u003c/title\u003e \u003c!-- \u003cmeta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"\u003e --\u003e \u003clink rel=\"stylesheet\" type=\"text/css\" href=\"cos-album.css\" /\u003e \u003cscript type=\"text/javascript\" src=\"cos-album.js\" defer\u003e\u003c/script\u003e \u003c/head\u003e \u003cbody\u003e \u003cscript type=\"text/javascript\"\u003e new Cosalbum({ xmlLink: 'https://img-xxxxxxxxxx.cos.ap-chengdu.myqcloud.com', prependTo: '.cos-album', viewNum: 8, copyUrl: '//img.lruihao.cn' }); \u003c/script\u003e \u003c!-- 你的其他内容，如评论等 --\u003e \u003c/body\u003e \u003c/html\u003e cos-album demo ","date":"2019-11-24","objectID":"/projects/cos-album/:3:3","tags":["CosAlbum","腾讯云 cos 桶","JavaScript"],"title":"利用腾讯云为静态页面添加“动态”相册","uri":"/projects/cos-album/"},{"categories":["Projects","JavaScript"],"content":"changelog 2020-9-28 22:46 升級：相冊封裝成類，可以更方便 new 出來 優化：相冊圖片樣式優化 2019-11-24 10:52:34 修改整理了一下代码，分割功能为函数，并写了注释，更加方便 伸手党! ","date":"2019-11-24","objectID":"/projects/cos-album/:4:0","tags":["CosAlbum","腾讯云 cos 桶","JavaScript"],"title":"利用腾讯云为静态页面添加“动态”相册","uri":"/projects/cos-album/"},{"categories":["Spec","计算机网络"],"content":" RESTful 是一种系统开发设计风格、原则。可视情况调整，以下参考来源 RFC5789 ","date":"2019-11-14","objectID":"/posts/restful/:0:0","tags":["REST","HTTP"],"title":"RESTful","uri":"/posts/restful/"},{"categories":["Spec","计算机网络"],"content":"Noun 一般资源 通用于一律使用复数名词 例如：/books 或 /books/123。但有部分人认为应该使用单数名词，因为： /book/123 看似比 /books/123 合理。但想想文件系统的目录命名（例如 /Users 或 /Documents)，其实用复数也没问题。复数可以保持 API endpoint 的一致性，所以一般资源建议用复数。 唯一资源：对 client 而言只有一份的资源 通用于单数名词 例如：user 是指目前验证的使用者，使用者永远只能同时登入一个使用者 ","date":"2019-11-14","objectID":"/posts/restful/:1:0","tags":["REST","HTTP"],"title":"RESTful","uri":"/posts/restful/"},{"categories":["Spec","计算机网络"],"content":"Http Method MethodIdempotentSafeCRUDOO生活动词用途GETYYReadgetget取得资料list列出资料POSTCreateaddcreate建立一个可以完全独立存在的实体add增加一个必须依赖于某个实体的实体PUTYUpdatesetreplace取代一个关系，已存在时先删除后建立，不存在时直接建立add附加唯一关系，两个关系实体可以互相独立存在，且已经存在PATCHedit编辑某个实体DELETEDeleteremoveremove delete删除某个实体 Safe：该操作不会改变伺服器端的资源状态（而且结果可以被 cache），属于 Safe 的操作必定属于 Idempotent Idempotent (幂等性)：该操作不管做 1 遍或做 n 遍，都会得到同样的资源状态结果（但不一定得到同样的返回值，例如第 2 次 DELETE 请求可能回传 404），因此 client 端可以放心 retry ","date":"2019-11-14","objectID":"/posts/restful/:2:0","tags":["REST","HTTP"],"title":"RESTful","uri":"/posts/restful/"},{"categories":["Spec","计算机网络"],"content":"GET Safe：每次执行操作时，GET 只有读取 Resource，不会改变到任何的 Resource （资源，资料） Idempotent：每次执行操作时，GET 只有读取 Resource，不会改变到任何的 Resource （资源，资料），所以任何资源的任何状态都是一样的 ","date":"2019-11-14","objectID":"/posts/restful/:2:1","tags":["REST","HTTP"],"title":"RESTful","uri":"/posts/restful/"},{"categories":["Spec","计算机网络"],"content":"POST 每次执行操作时，POST 都会建立一个 Resource （资源，资料） Create：建立一个可以完全独立存在的实体 范例：建立使用者 执行第一次时：建立一个 name = “李四” 的 user，但其 id = 1，执行第二次时：建立一个 name = “李四” 的 user，但其 id = 2，发送同样的请求，可每次都是不同的 Resource 建立使用者前不需要建立任何的东西，就可以建立使用者了，使用者是可以完全独立的存在 POST /users HTTP/1.1 Host: 127.0.0.1 { \"name\": \"李四\" } Add：增加一个必须依赖于某个实体的实体 资料结构：一对多的关系 范例：Add a public key on behalf of a user 增加一个代表使用者的公钥 (Gitea API) 增加这个公钥之前，使用者必须存在，公钥必须归属于某个使用者之下，公钥跟姓名一样，使用相同电脑的公钥就会相同，但不表示是同一个使用者，故公钥也会有自己的 ID 我每次增加公钥时，都将生成不同的公钥 ID POST /api/v1/admin/users/{username}/keys HTTP/1.1 Host: gitea.com { \"key\": \"string\", \"read_only\": true, \"title\": \"string\" } ","date":"2019-11-14","objectID":"/posts/restful/:2:2","tags":["REST","HTTP"],"title":"RESTful","uri":"/posts/restful/"},{"categories":["Spec","计算机网络"],"content":"PUT Idempotent：每次执行操作时，PUT 都会取代 Resource，不管操作几次，使用者获取得 Resource 结果都是一样的 Replace：不论资源如何，最终的资源状态都是一样的，Resource 已存在时，或许不理会、或许先删除后建立（取代）Resource 不存在时，直接建立 Add：添加唯一关系，建立这个唯一关系前，两个关连实体都必须存在。在没有建立关系前，两个关连实体都可以互相独立存在 资料结构：多对多，且两个关连实体的 PK，同时也是关系实体的 PK、FK 范例：增加使用者与角色的关系 增加使用者跟角色的关系前，使用者跟角色都必须存在；增加使用者跟角色的关系前，使用者跟角色可以独立存在， 使用者 12262 跟 角色 2 的关系最多只能有一条关系（ 使用者 12262 有 角色 2)，最少没有关系（使用者 12262 没有 角色 2 ) ，执行第二次操作时，使用者 12262 跟 角色 2 的从属关系仍然存在，也不会跑出第二条 使用者 12262 跟 角色 2 的从属关系 PUT user/{account}/roles HTTP/1.1 Host: 127.0.0.1 { \"role_id\": \"2\" } 范例：Follow a user 关注一个使用者 (Gitea API) 增加关注关系时，关注者与被关注者（都是使用者） 都必须存在；关注者 12262 跟被关注者 12231 的关系最多只能有一条关系（12262 关注 12231），最少没有关系（12262 不关注 12231），执行第二次操作时，关注者 12262 跟被关注者 12231 的关注关系仍然存在，也不会跑出第二条关注者 12262 跟被关注者 12231 的关注关系 PUT /api/v1/user/following/{username} HTTP/1.1 Host: gitea.com ","date":"2019-11-14","objectID":"/posts/restful/:2:3","tags":["REST","HTTP"],"title":"RESTful","uri":"/posts/restful/"},{"categories":["Spec","计算机网络"],"content":"PATCH Edit：编辑可独立存在、且已经存在的实体，也就是产生新版本的实体，可能会影响其他 Resource 范例：编辑使用者 编辑使用者，使用者已经存在，且我们可能有纪录编辑时间、编辑人、编辑 IP，所以每次的编辑都会造成不一样的结果 第一次编辑使用者，更新时间变为 08:00，编辑人 12262，IP 172.18.0.66 第二次编辑使用者，更新时间变为 09:00，编辑人 12263，IP 172.18.0.67 PATCH /users/{account} HTTP/1.1 Host: 127.0.0.1 { \"username\": \"李四\", \"age\": \"18\", \"gender\": \"male\" } ","date":"2019-11-14","objectID":"/posts/restful/:2:4","tags":["REST","HTTP"],"title":"RESTful","uri":"/posts/restful/"},{"categories":["Spec","计算机网络"],"content":"DELETE Idempotent：每次执行操作时，DELETE 都会删除相同的东西 范例：删除使用者 第一次删除使用者 12262，删除使用者 12262, 第二次删除使用者 12262，还是删除使用者 12262，只不过使用者 12262 不存在了 DELETE /users/{account} HTTP/1.1 Host: 127.0.0.1 ","date":"2019-11-14","objectID":"/posts/restful/:2:5","tags":["REST","HTTP"],"title":"RESTful","uri":"/posts/restful/"},{"categories":["Spec","计算机网络"],"content":"HTTP Status Code HTTP 状态码（HTTP Status Code）是用以表示网页服务器 HTTP 响应状态的 3 位数字代码。所有状态码的第一个数字代表了响应的五种状态之一。除非另有说明，状态码是 HTTP/1.1 标准（RFC 7231）的一部分。 而关于 RESTful API 的请求状态，通常有以下两种设计方案： 方案一：使用 HTTP 状态码来表示请求状态，200 时返回的内容就是数据 方案二：所有接口都返回 200 ，在响应内容里约定错误码或错误信息 在实际应用中，应据具体情景及需要进行选择与调整。 方案优劣比较方案一优点对服务端来说较为简单方便缺点客户端难以根据状态码处理复杂问题方案二优点方便对返回资料进行统一处理和细微性的控制缺点相当于放弃了 HTTP 状态码的语义 ","date":"2019-11-14","objectID":"/posts/restful/:3:0","tags":["REST","HTTP"],"title":"RESTful","uri":"/posts/restful/"},{"categories":["Spec","计算机网络"],"content":"常用 HTTP 状态码 Code Message 用途 1XX Informational response 此类状态码通常代表的响应都是信息性的，告诉客户端可以进行下一步操作。 100 Continue 表示服务端已接收到请求头，客户端可以继续发送请求体（如 POST 请求）。 101 Switching Protocols 表示服务端支持更优协议，让客户端在服务端更换协议后重新访问。 2XX Successful 此类状态码通常代表请求已成功被服务端接收、理解并接受。 200 OK 表示请求成功。 201 Created 表示请求已被实现，通常是在成功创建了某个资源。 202 Accepted 表示请求已被服务端接收，但尚未进行处理。 204 No Content 表示请求成功，但不会返回任何内容。 205 Reset Content 表示请求成功，但不会返回任何内容，并且要求客户端重置表单。 3XX Redirect 此类状态码通常代表本次请求需要客户端采取进一步操作才能完成。通常用于重定向。 300 Multiple Choices 表示请求的资源有多个供可选择，客户端可自行选择一个进行请求的重定向。 301 Moved Permanently 表示请求的资源已经永久地移动到了新位置，并且将在 Location 域中携带该资源新的 URI。 304 Not Modified 表示请求的资源无发生修改，将不会返回任何资源。 4XX Client Error 此类状态码通常代表客户端可能出现了错误。 400 Bad Request 表示客户端发出的请求有误（格式、大小、无效的…)，服务端不能/ 不会处理该请求。 401 Unauthorized 表示客户端未能提供必要的验证，服务端拒绝提供资源。 403 Forbidden 表示服务端理解了该请求，但客户端没有足够权限以访问，遂拒绝提供该资源。 404 Not Found 表示服务端无法找到请求的资源，其可能已经暂时（永久）失效。 408 Request Timeout 表示请求超时。 409 Conflict 表示请求的资源发送了冲突，通常是 PUT 请求。 410 Gone 表示请求的资源已经永久失效，客户端不应再次请求。 411 Length Required 表示服务端拒绝在没有定义 Content-Length 头的情况下接收该请求。 5XX Server Error 此类状态码通常代表由于服务端的原因，导致无法完成请求。 500 Internal Server Error 表示由于服务端遇到意料之外的变故，导致无法完成请求。 501 Not Implemented 表示服务端不支持完成请求所需的功能，导致无法完成请求。 502 Bad Gateway 表示作为网关或代理的服务段在执行请求时，从上游服务器获得了无效的响应。 503 Service Unavailable 表示由于某些原因（服务器超载或系统维护等），导致暂时无法完成请求。 504 Gatewy Timeout 表示作为网关或代理的服务段在执行请求时，未能及时从上游服务器获得响应。 505 HTTP Version Not Supported 表示服务端不支持请求的 HTTP 协议版本，导致无法完成请求。 以上内容参考自https://zh.wikipedia.org/zh-cn/HTTP状态码， 需要查看完整 HTTP 状态码请点击 https://www.rfc-editor.org/rfc/rfc9110.html#name-status-codes ","date":"2019-11-14","objectID":"/posts/restful/:3:1","tags":["REST","HTTP"],"title":"RESTful","uri":"/posts/restful/"},{"categories":["PHP"],"content":" php 主动推送站点链接到百度站长，神马站长进行 SEO。 ","date":"2019-09-28","objectID":"/posts/phppushurl/:0:0","tags":["PHP"],"title":"php 同时主动推送链接到百度，神马等站长平台","uri":"/posts/phppushurl/"},{"categories":["PHP"],"content":"代码 把需要提交的链接和各站长 api 分别放在两个 txt 文件里面，然后运行 php 文件进行提交，不同站长提交成功一般返回的都是 200 状态码。 \u003c?php //链接存放路径和站长 api 文件存放路径 $urls_path = \"H:\\\\lruihao.cn\\\\public\\\\baidu_urls.txt\"; $apis_path = \"G:\\\\Demo\\\\lrh01\\\\zhanzhang_api.txt\"; //将文件每一行读到一个数组里面去 $urls = file($urls_path, FILE_IGNORE_NEW_LINES | FILE_SKIP_EMPTY_LINES); $apis = file($apis_path, FILE_IGNORE_NEW_LINES | FILE_SKIP_EMPTY_LINES); for($x=0;$x\u003ccount($apis);$x++){ $ch = curl_init(); $options = array( CURLOPT_URL =\u003e $apis[$x], CURLOPT_POST =\u003e true, CURLOPT_RETURNTRANSFER =\u003e true, CURLOPT_POSTFIELDS =\u003e implode(\"\\n\", $urls), CURLOPT_HTTPHEADER =\u003e array('Content-Type: text/plain'), ); curl_setopt_array($ch, $options); $result = curl_exec($ch); echo \"API: \u003cbr/\u003e\u0026emsp;\".$apis[$x].\"\u003cbr/\u003e\"; echo \"result: \u003cbr/\u003e\u0026emsp;\".$result.\"\u003chr/\u003e\"; } ?\u003e ","date":"2019-09-28","objectID":"/posts/phppushurl/:1:0","tags":["PHP"],"title":"php 同时主动推送链接到百度，神马等站长平台","uri":"/posts/phppushurl/"},{"categories":["PHP"],"content":"提交结果 ","date":"2019-09-28","objectID":"/posts/phppushurl/:2:0","tags":["PHP"],"title":"php 同时主动推送链接到百度，神马等站长平台","uri":"/posts/phppushurl/"},{"categories":["PHP"],"content":"普通方法 首先采用fopen()函数打开文件，得到返回值的就是资源类型。接着采用 while 循环一行行地读取文件，然后输出每行的文字。feof()判断是否到最后一行，fgets()读取一行文本。 \u003c?php //首先采用“fopen”函数打开文件，得到返回值的就是资源类型。 $file_handle = fopen(\"C:\\\\Users\\\\李瑞豪、\\Desktop\\\\备忘录。txt\",\"r\"); if ($file_handle){ //接着采用 while 循环一行行地读取文件，然后输出每行的文字 while (!feof($file_handle)) { //判断是否到最后一行 $line = fgets($file_handle); //读取一行文本 echo $line; //输出一行文本 echo \"\u003cbr /\u003e\"; //换行 } } fclose($file_handle);//关闭文件 ?\u003e readfile（）函数，返回一整个 String echo readfile(\"C:\\\\Users\\\\李瑞豪、\\Desktop\\\\备忘录。txt\"); ","date":"2019-09-28","objectID":"/posts/phpfile/:1:0","tags":["PHP"],"title":"php 按行读取文件信息","uri":"/posts/phpfile/"},{"categories":["PHP"],"content":"快速方法 file()函数把整个文件读入一个数组中。 数组中的每个元素都是文件中相应的一行，包括换行符在内。 语法 file(path,include_path,context) 参数 描述 path 必需。规定要读取的文件。 include_path 可选参数include_path 可以是以下一个或多个常量：**FILE_USE_INCLUDE_PATH在 include_path 中查找文件。FILE_IGNORE_NEW_LINES在数组每个元素的末尾不要添加换行符FILE_SKIP_EMPTY_LINES**跳过空行 context 可选。规定文件句柄的环境。context 是一套可以修改流的行为的选项。若使用 NULL，则忽略。 \u003c?php $filepath=\"H:\\\\lruihao.cn\\\\public\\\\baidu_urls.txt\"; echo \"\u003chr/\u003e\"; //将文件每一行读到一个数组里面去 $texts = file($filepath, FILE_IGNORE_NEW_LINES | FILE_SKIP_EMPTY_LINES); var_dump($texts); ?\u003e ","date":"2019-09-28","objectID":"/posts/phpfile/:2:0","tags":["PHP"],"title":"php 按行读取文件信息","uri":"/posts/phpfile/"},{"categories":["PHP"],"content":"结果 ","date":"2019-09-28","objectID":"/posts/phpfile/:3:0","tags":["PHP"],"title":"php 按行读取文件信息","uri":"/posts/phpfile/"},{"categories":["JavaScript"],"content":" 使用javascript计算博客等网站的运行时间。 话不多说，直接贴码！ function createTime() { var now = new Date(); var run = new Date('05/28/2018 20:01:01'); //總的秒數 var runTime = (now - run) / 1000, days = Math.floor(runTime / 60 / 60 / 24), hours = Math.floor(runTime / 60 / 60 - 24 * days), minutes = Math.floor(runTime / 60 - 24 * 60 * days - 60 * hours), seconds = Math.floor((now - run) / 1000 - 24 * 60 * 60 * days - 60 * 60 * hours - 60 * minutes); //前置零 if (String(hours).length === 1) { hours = '0' + hours; } if (String(minutes).length === 1) { minutes = '0' + minutes; } if (String(seconds).length === 1) { seconds = '0' + seconds; } /*document.querySelector(\".run-times\").innerHTML = days + \"\u0026thinsp; 天\u0026thinsp;\" + hours + \"\u0026thinsp; 时\u0026thinsp;\" + minutes + \"\u0026thinsp; 分\u0026thinsp;\" + seconds + \"\u0026thinsp; 秒\"; */ document.querySelector('.run-times').innerHTML = 'RunTime: ' + days + ',' + hours + ':' + minutes + ':' + seconds + ''; } //setInterval(\"createTime()\", 500); if (!document.hidden) { var siteTime = setInterval('createTime()', 500); } else { clearInterval(siteTime); } /** * HTML 写法 \u003cspan class=\"run-times\" title=\"网站运行时间\"\u003e载入时分秒 ...\u003c/span\u003e \u003cp class=\"run-times\" title=\"主頁运行时间\"\u003eRunTime Loading...\u003c/p\u003e */ ","date":"2019-09-19","objectID":"/posts/site-time/:0:0","tags":["JavaScript"],"title":"设置网站运行时间","uri":"/posts/site-time/"},{"categories":["JavaScript"],"content":" 注意 JS 的加载分为两个部分：下载和执行。 浏览器在执行 HTML 的时候如果遇到\u003cscript\u003e时会停止页面的渲染，去下载和执行 js 的文件直接遇见\u003c/scirpt\u003e会继续渲染页面。故浏览器在执行 js 文件的时候浏览器表现为一片空白，为了解决这个问题 ECMAScript 定义了 defer 和 async 两个属性用于控制 JS 的下载和执行。 ","date":"2019-09-08","objectID":"/posts/async-defer/:0:0","tags":["JavaScript","defer","async"],"title":"script 的三种加载方式 (async, defer)","uri":"/posts/async-defer/"},{"categories":["JavaScript"],"content":"不带任何属性 同步模式，又称阻塞模式，我们平时使用的最多的一种方式。当浏览器解析到\u003cscript\u003e标签时，浏览器会停止解析其后的内容，而优先下载脚本文件，并执行其中的代码，是个同步阻塞的过程。 一般建议把\u003cscript\u003e标签放在\u003cbody\u003e结尾处，这样尽可能减少页面阻塞。 而如果想要异步执行 script，则可以给其加上 async 或 defer 属性。 \u003cscript\u003e ","date":"2019-09-08","objectID":"/posts/async-defer/:1:0","tags":["JavaScript","defer","async"],"title":"script 的三种加载方式 (async, defer)","uri":"/posts/async-defer/"},{"categories":["JavaScript"],"content":"defer defer 属性在 HTML 解析期间异步下载文件，并且只在 HTML 解析完成后才执行它。对于 defer，我们可以理解是将外链的 js 放在了页面底部。js 的加载不会阻塞页面的渲染和资源的加载。不过 defer 会按照原本的 js 的顺序执行，所以如果前后有依赖关系的 js 可以放心使用。 \u003cscript defer\u003e ","date":"2019-09-08","objectID":"/posts/async-defer/:2:0","tags":["JavaScript","defer","async"],"title":"script 的三种加载方式 (async, defer)","uri":"/posts/async-defer/"},{"categories":["JavaScript"],"content":"async async 属性会在 HTML 解析期间异步下载文件，并在完成下载后立即暂停 HTML 解析器去执行 script 中的代码。在执行过程中浏览器处于阻塞状态，响应不了任何需求。如果 js 前后有依赖性，用 async，就很有可能出错。 \u003cscript async\u003e ","date":"2019-09-08","objectID":"/posts/async-defer/:3:0","tags":["JavaScript","defer","async"],"title":"script 的三种加载方式 (async, defer)","uri":"/posts/async-defer/"},{"categories":["JavaScript"],"content":"区别 ","date":"2019-09-08","objectID":"/posts/async-defer/:4:0","tags":["JavaScript","defer","async"],"title":"script 的三种加载方式 (async, defer)","uri":"/posts/async-defer/"},{"categories":["JavaScript"],"content":"相同点 加载文件时不阻塞页面渲染 对于 inline 的 script 无效（只适用有src的外部 js） 使用这两个属性的脚本中不能调用 document.write 方法 有脚本的 onload 的事件回调 ","date":"2019-09-08","objectID":"/posts/async-defer/:4:1","tags":["JavaScript","defer","async"],"title":"script 的三种加载方式 (async, defer)","uri":"/posts/async-defer/"},{"categories":["JavaScript"],"content":"区别点 html4.0 中定义了 defer；html5.0 中定义了 async 浏览器支持不同 每一个 async 属性的脚本都在它下载结束之后立刻执行，同时会在 window 的 load 事件之前执行。所以就有可能出现脚本执行顺序被打乱的情况；每一个 defer 属性的脚本都是在页面解析完毕之后，按照原本的顺序执行，同时会在 document 的 DOMContentLoaded 之前执行。 ","date":"2019-09-08","objectID":"/posts/async-defer/:4:2","tags":["JavaScript","defer","async"],"title":"script 的三种加载方式 (async, defer)","uri":"/posts/async-defer/"},{"categories":["JavaScript"],"content":"那么这三种方式各在什么情况下使用呢？ 通常来说，尽可能使用async，然后是defer，最后不使用属性。 并遵循以下规则： 如果脚本是模块化的，并且不依赖于任何脚本，则使用async。 如果脚本依赖于或依赖于另一个脚本，则使用defer。 如果脚本很小并且有async脚本依赖该脚本，则不加属性。 ","date":"2019-09-08","objectID":"/posts/async-defer/:5:0","tags":["JavaScript","defer","async"],"title":"script 的三种加载方式 (async, defer)","uri":"/posts/async-defer/"},{"categories":["JavaScript"],"content":"兼容性 Internet Explorer 10、Firefox、Opera、Chrome 和 Safari 支持 async 属性。 所有主流浏览器都支持 defer 属性。 ","date":"2019-09-08","objectID":"/posts/async-defer/:6:0","tags":["JavaScript","defer","async"],"title":"script 的三种加载方式 (async, defer)","uri":"/posts/async-defer/"},{"categories":["JavaScript"],"content":"参考 https://www.growingwiththeweb.com/2014/02/async-vs-defer-attributes.html https://www.jianshu.com/p/17dc82bf08f1 ","date":"2019-09-08","objectID":"/posts/async-defer/:7:0","tags":["JavaScript","defer","async"],"title":"script 的三种加载方式 (async, defer)","uri":"/posts/async-defer/"},{"categories":["Memo"],"content":"Sublime Text3 快捷键一览表 ","date":"2019-08-15","objectID":"/posts/sublime-text3/:0:0","tags":["Sublime","他山之石"],"title":"Sublime Text3 快捷键大全","uri":"/posts/sublime-text3/"},{"categories":["Memo"],"content":"tab 转 space 打开 Settings, 加入几行配置 { \"color_scheme\": \"Packages/Color Scheme - Default/Monokai.sublime-color-scheme\", \"font_size\": 14, \"ignored_packages\": [ \"Vintage\" ], \"theme\": \"Adaptive.sublime-theme\", + \"expand_tabs_on_save\": true, + \"tab_size\": 2, + \"translate_tabs_to_spaces\": true } ","date":"2019-08-15","objectID":"/posts/sublime-text3/:1:0","tags":["Sublime","他山之石"],"title":"Sublime Text3 快捷键大全","uri":"/posts/sublime-text3/"},{"categories":["Memo"],"content":"选择类 Ctrl+D 选中光标所占的文本，继续操作则会选中下一个相同的文本。 Alt+F3 选中文本按下快捷键，即可一次性选择全部的相同文本进行同时编辑。举个栗子：快速选中并更改所有相同的变量名、函数名等。 Ctrl+L 选中整行，继续操作则继续选择下一行，效果和 Shift+↓ 效果一样。 Ctrl+Shift+L 先选中多行，再按下快捷键，会在每行行尾插入光标，即可同时编辑这些行。 Ctrl+Shift+M 选择括号内的内容（继续选择父括号）。举个栗子：快速选中删除函数中的代码，重写函数体代码或重写括号内里的内容。 Ctrl+M 光标移动至括号内结束或开始的位置。 Ctrl+Enter 在下一行插入新行。举个栗子：即使光标不在行尾，也能快速向下插入一行。 Ctrl+Shift+Enter 在上一行插入新行。举个栗子：即使光标不在行首，也能快速向上插入一行。 Ctrl+Shift+[ 选中代码，按下快捷键，折叠代码。 Ctrl+Shift+] 选中代码，按下快捷键，展开代码。 Ctrl+K+0 展开所有折叠代码。 Ctrl+← 向左单位性地移动光标，快速移动光标。 Ctrl+→ 向右单位性地移动光标，快速移动光标。 shift+↑ 向上选中多行。 shift+↓ 向下选中多行。 Shift+← 向左选中文本。 Shift+→ 向右选中文本。 Ctrl+Shift+← 向左单位性地选中文本。 Ctrl+Shift+→ 向右单位性地选中文本。 Ctrl+Shift+↑ 将光标所在行和上一行代码互换（将光标所在行插入到上一行之前）。 Ctrl+Shift+↓ 将光标所在行和下一行代码互换（将光标所在行插入到下一行之后）。 Ctrl+Alt+↑ 向上添加多行光标，可同时编辑多行。 Ctrl+Alt+↓ 向下添加多行光标，可同时编辑多行。 ","date":"2019-08-15","objectID":"/posts/sublime-text3/:2:0","tags":["Sublime","他山之石"],"title":"Sublime Text3 快捷键大全","uri":"/posts/sublime-text3/"},{"categories":["Memo"],"content":"编辑类 Ctrl+J 合并选中的多行代码为一行。举个栗子：将多行格式的 CSS 属性合并为一行。 Ctrl+Shift+D 复制光标所在整行，插入到下一行。 Tab 向右缩进。 Shift+Tab 向左缩进。 Ctrl+K+K 从光标处开始删除代码至行尾。 Ctrl+Shift+K 删除整行。 Ctrl+/ 注释单行。 Ctrl+Shift+/ 注释多行。 Ctrl+K+U 转换大写。 Ctrl+K+L 转换小写。 Ctrl+Z 撤销。 Ctrl+Y 恢复撤销。 Ctrl+U 软撤销，感觉和 Gtrl+Z 一样。 Ctrl+F2 设置书签 Ctrl+T 左右字母互换。 F6 单词检测拼写 ","date":"2019-08-15","objectID":"/posts/sublime-text3/:3:0","tags":["Sublime","他山之石"],"title":"Sublime Text3 快捷键大全","uri":"/posts/sublime-text3/"},{"categories":["Memo"],"content":"搜索类 Ctrl+F 打开底部搜索框，查找关键字。 Ctrl+shift+F 在文件夹内查找，与普通编辑器不同的地方是 sublime 允许添加多个文件夹进行查找，略高端，未研究。 Ctrl+P 打开搜索框。举个栗子：1、输入当前项目中的文件名，快速搜索文件，2、输入@和关键字，查找文件中函数名，3、输入：和数字，跳转到文件中该行代码，4、输入#和关键字，查找变量名。 Ctrl+G 打开搜索框，自动带：，输入数字跳转到该行代码。举个栗子：在页面代码比较长的文件中快速定位。 Ctrl+R 打开搜索框，自动带@，输入关键字，查找文件中的函数名。举个栗子：在函数较多的页面快速查找某个函数。 Ctrl+： 打开搜索框，自动带#，输入关键字，查找文件中的变量名、属性名等。 Ctrl+Shift+P 打开命令框。场景栗子：打开命名框，输入关键字，调用 sublime text 或插件的功能，例如使用 package 安装插件。 Esc 退出光标多行选择，退出搜索框，命令框等。 ","date":"2019-08-15","objectID":"/posts/sublime-text3/:4:0","tags":["Sublime","他山之石"],"title":"Sublime Text3 快捷键大全","uri":"/posts/sublime-text3/"},{"categories":["Memo"],"content":"显示类 Ctrl+Tab 按文件浏览过的顺序，切换当前窗口的标签页。 Ctrl+PageDown 向左切换当前窗口的标签页。 Ctrl+PageUp 向右切换当前窗口的标签页。 Alt+Shift+1 窗口分屏，恢复默认 1 屏（非小键盘的数字） Alt+Shift+2 左右分屏-2 列 Alt+Shift+3 左右分屏-3 列 Alt+Shift+4 左右分屏-4 列 Alt+Shift+5 等分 4 屏 Alt+Shift+8 垂直分屏-2 屏 Alt+Shift+9 垂直分屏-3 屏 Ctrl+K+B 开启/关闭侧边栏。 F11 全屏模式 Shift+F11 免打扰模式 ","date":"2019-08-15","objectID":"/posts/sublime-text3/:5:0","tags":["Sublime","他山之石"],"title":"Sublime Text3 快捷键大全","uri":"/posts/sublime-text3/"},{"categories":["Memo"],"content":"安裝 官方下載點 ","date":"2019-08-15","objectID":"/posts/netbeans/:1:0","tags":["NetBeans","PHP"],"title":"NetBeans IDE 开发设置","uri":"/posts/netbeans/"},{"categories":["Memo"],"content":"擴充功能 ","date":"2019-08-15","objectID":"/posts/netbeans/:2:0","tags":["NetBeans","PHP"],"title":"NetBeans IDE 开发设置","uri":"/posts/netbeans/"},{"categories":["Memo"],"content":"安裝擴充功能 下載擴充套件包 官方套件庫 或者在 NetBeans IDE 裏面下載插件（方便） 開啟 NetBeans→Tools→Plugins→Downloaded→Add Plugins 選擇要安裝的擴充套件包 ","date":"2019-08-15","objectID":"/posts/netbeans/:2:1","tags":["NetBeans","PHP"],"title":"NetBeans IDE 开发设置","uri":"/posts/netbeans/"},{"categories":["Memo"],"content":"啟用已安裝的擴充功能 開啟 NetBeans→Tools→Plugins→Installed 選擇要啟用的套件 (*.npm) 點擊 Activate ","date":"2019-08-15","objectID":"/posts/netbeans/:2:2","tags":["NetBeans","PHP"],"title":"NetBeans IDE 开发设置","uri":"/posts/netbeans/"},{"categories":["Memo"],"content":"匯入設定 開啟 NetBeans→Tools→Options 點擊 Import 匯入設定 選擇要匯入的套件包 (*.zip) ","date":"2019-08-15","objectID":"/posts/netbeans/:2:3","tags":["NetBeans","PHP"],"title":"NetBeans IDE 开发设置","uri":"/posts/netbeans/"},{"categories":["Memo"],"content":"常用設定 ","date":"2019-08-15","objectID":"/posts/netbeans/:3:0","tags":["NetBeans","PHP"],"title":"NetBeans IDE 开发设置","uri":"/posts/netbeans/"},{"categories":["Memo"],"content":"程式碼排版 在程式開發中，程式碼排版很重要。一個好的排版利於開發人員程式閱讀，也便於後期維護人員閱讀。 在 NetBeans 中設置程式碼排版 打開 NetBeans-\u003eTools-\u003eOptions-\u003eEditor-\u003eFormatting； Language 選擇 All Languages，勾選\"Expand Tabs to Spaces\", 用兩個空格鍵代替 Tab 鍵，首行留兩個 Tab 鍵。 點擊 Apply 或 Ok 完成設置。具體設置及效果如下圖所示： ","date":"2019-08-15","objectID":"/posts/netbeans/:3:1","tags":["NetBeans","PHP"],"title":"NetBeans IDE 开发设置","uri":"/posts/netbeans/"},{"categories":["Memo"],"content":"程式碼樣板 程式碼樣板可以幫助你快速書寫程序，不必繁瑣地聲明函數或其他代碼塊，更專注與邏輯的書寫。 在 NetBeans 中設置程式碼樣板 打開 NetBeans→Tools→Options→Editor→Code Templates； 選擇你所用的語言（這裡以 JavaScript 為例）； 點擊\"New\"新建屬於你的或修改原有的程式碼樣板（例子僅為演示）； 在編程中應用它。 ","date":"2019-08-15","objectID":"/posts/netbeans/:3:2","tags":["NetBeans","PHP"],"title":"NetBeans IDE 开发设置","uri":"/posts/netbeans/"},{"categories":["Memo"],"content":"前端壓縮 下載擴充套件netbeans minify 或者 minifierBeans 開啟 NetBeans→Tools→Plugins→Downloaded→Add Plugins 選擇你下載的擴充套件開啟 開啟 NetBeans→Tools→options ","date":"2019-08-15","objectID":"/posts/netbeans/:3:3","tags":["NetBeans","PHP"],"title":"NetBeans IDE 开发设置","uri":"/posts/netbeans/"},{"categories":["Memo"],"content":"快捷鍵 键位 作用 Ctrl+/ 注释一行（或选中部分） Ctrl+X 剪切一行（或选中部分） Ctrl+E 删除一行（或选中部分） Shift+Alt+上下方向键 移动当前行 Ctrl+Shift+上下方向键 复制当前行（该操作并非复制到粘贴板） Shift+Alt+F 整理代码 TAB 代碼自動補全/缩进/選中文字同時缩进 Shift+TAB 選中文字同時取消缩进 Ctrl+F 查找某个字 Ctrl+Shift+F 整个项目中查找某个字 Ctrl+H 替换某个字 Ctrl+Enter 增加空白行，光标不动。 Ctrl+(0~7) 打开各种小窗口 Shift+方向键 選中文字 Ctrl+Alt+Space 代码输入提示，不习惯的可以设置为 (Alt+/)，超级好用！！！ Ctrl+Shift+F5 调试当前程序 Shift+F6 运行当前程序 F6 运行主程序 Alt+Enter 显示程式 bug 建议或者警示等 NetBeans 中常用的快捷鍵 ↑： 三種複製行方法 复制一行：Ctrl + Shift + 上下方向键（该操作并非复制到粘贴板）； 复制一行：在该行任何地方连续三击选中一样，然后 Ctrl + C 即可复制一行。； 复制一行（使用宏）: 编辑-开始录制宏 (Home,Shift + End,Ctrl + C)-停止录制宏-设置宏名称（如 select-entire-line)-设置快捷键（如 Ctrl + Alt + C)； 也可自己修改快捷鍵 (Tools→Options→Keympa), 如下圖 {% asset_img quickkey.png quickkey %} ","date":"2019-08-15","objectID":"/posts/netbeans/:3:4","tags":["NetBeans","PHP"],"title":"NetBeans IDE 开发设置","uri":"/posts/netbeans/"},{"categories":["Memo"],"content":"遠程開發 (FTP) 工作为例 新建项目 打开软件，进入新建项目页面（File-New Project），新建 php 项目，选择第一个（PHP-PHP Application） 项目名和地址自己选择（注意，选择地址后需在地址最后面加上\"/项目名\"） FTP 设置 点击下一步，进入 FTP 设置，Run As 选择 Remote Web Site(FTP,SFTP) Project URL 填写http://127.0.0.1/training/工号 Manage 设置 点击 Manage, 进入页面。名字自取。Host Name 填写：127.0.0.1 Encryption 选择 Pure FTP,User Name 和 Password（填写工号/课务系统登录密码） Initial Directory 填写_training 点击 Test Connection 测试是否连接成功 其他设置 Upload Directory, 上传目录不填，直接上传至个人根目录 Upload File 改为保存时上传文件（On Save） ","date":"2019-08-15","objectID":"/posts/netbeans/:3:5","tags":["NetBeans","PHP"],"title":"NetBeans IDE 开发设置","uri":"/posts/netbeans/"},{"categories":["Memo"],"content":"Chrome with NetNeans Connector 打開 chrome 中的應用程式商店（使用 chrome 瀏覽器點擊下方鏈接即可） chrome 應用程式商店 在搜索框中輸入 NetNeans Connector 后搜索，然後點擊右邊的加到 Chrome 即可，安裝成功后右上角會顯示 NetBeans 圖標。 開啟 netbeans 選擇 Run→Set Project Browser→ 選中 Chrome with NetBeans Connector 選擇 default 下的 Customize → 選擇 Browser → 選擇 Browser 下 Chrome with NetBeans Connector 即可 ","date":"2019-08-15","objectID":"/posts/netbeans/:3:6","tags":["NetBeans","PHP"],"title":"NetBeans IDE 开发设置","uri":"/posts/netbeans/"},{"categories":["Spec"],"content":"精神 绝不写死代码，硬编码 不留不要用的、垃圾代码 ","date":"2019-08-15","objectID":"/posts/dev-rules/:1:0","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"Git Master 的 BUG 必须最少且趋近于零，为最稳定的版本 每次 Commit 信息应该准确填写。不可模棱两可，eg: 修复 BUG、增加功能 禁止 Commit IDE 的 project data，e.g: .vscode 禁止上传垃圾代码 更多规则详见文档 Commit 规范 ","date":"2019-08-15","objectID":"/posts/dev-rules/:2:0","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"分支（Branch） 命名规则：应以此分支主要目的命名（修复什么 BUG，新增特定功能） 合并后的分支应该删除 ","date":"2019-08-15","objectID":"/posts/dev-rules/:2:1","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"commit 遵循一个功能一个 commit 的原则 ","date":"2019-08-15","objectID":"/posts/dev-rules/:2:2","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"Restful 资源名词站在 API 的角度思考 复数名词：可以复数笔数据，回传结果为 Array 举例：GET/users 取得多笔使用者资料 刪除，放在复数名词內，让 Router 保持一致性 增加，放在复数名詞內，让 Router 保持一致性 单数名词：仅取得单笔数据，必须指定 PK，两两一组，回传结果为 Object 举例：GET/user/{accont} 取得单笔使用者资料，必须指定 PK URL 中一律不带 id 参数 正确范例： calendar_manager/calendar/29 错误范例： calendar_manager/calendar/29?id=29 更多规则详见文档 RESTful ","date":"2019-08-15","objectID":"/posts/dev-rules/:3:0","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"命名 命名应根据内容做有意义的命名，让后续维护人员可以顾名思义！ 即使不会发生错误，代码英文大小写也需明确区分。 ","date":"2019-08-15","objectID":"/posts/dev-rules/:4:0","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"语意 类型 命名规则 说明 属性 (Attribute, Property) 名词 user_name、userName 方法 (Method, Function) 动词 + 名词 getUserName、get_user_name 常見的动词有：get、set、update、delete、remove ","date":"2019-08-15","objectID":"/posts/dev-rules/:4:1","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"字母与分隔 语言 变量 (Variable, Parameter, Argument) 常量 (Constant) 面向对象 - 类名 (Class Name) 面向对象 - 成员 (mebmer) HTML 全部小写，不同单词以「-」分隔 e.g: user-id CSS、SCSS 全部小写，不同单词以「-」分隔，CSS 变量以「–」开头，SCSS 变量以「$」开头 e.g: .user-id、–header-height、$header-height JavaScript 驼峰式命名法 首字小写，不同单字「首字以大写」分隔 e.g: userId 全部大写，不同单字以「_」分隔 MAX_COUNT 驼峰式命名法 首字大写，不同单字「首字以大写」分隔 一个文件放一个 Class, 文件名即为 Class Name e.g: User 驼峰式命名法 公有 (public) : 首字小写，不同单词「首字以大写」分隔 e.g: name, getName 私有 (private): _公有命名规则 e.g: _name,_getName Vue Java PHP 全部小写，不同单词以「_」分隔 e.g: user_id Python SQL 由使用者定义的：表名、字段名 全部小写，不同单词以「_」分隔 SQL 语法、函数全部大写 e.g: SELECT、INSERT INTO ","date":"2019-08-15","objectID":"/posts/dev-rules/:4:2","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"通用 代码编写 每个函数应该使用块注释，注释应包含函数功能说明、参数说明。规则见：JSDoc、JavaDoc 不必要的代码不要写，也应禁止放到注释里面！ if-else 的 {} 严禁省略 代码规范、代码排版等可通过 eslint 等工具做统一处理 ","date":"2019-08-15","objectID":"/posts/dev-rules/:5:0","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"正确写法 public function test () { // do something if (a === b) { // do something } } ","date":"2019-08-15","objectID":"/posts/dev-rules/:5:1","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"错误写法 public function test () { // do something if (a === b) { // do something } } 代码排版 任何代码应该以 2 个 space 为一个缩进做好排版、不可使用 tab 函数 (Function, Methd) 函数声明时需在函数上方加上函数注释，注释应包含函数说明、参数内容（参数类型、参数英文名称、参数说明）、返回值内容（返回值类型、返回值说明） 类 (Class) 一个类（Class）的声明只能存在一个文件 类（Class）的声明文件，文件名必须为类名 其他 连接本地任何其他资源（图片、文件、网站）皆使用相对路径，禁止使用绝对路径，非本地资源除外 ","date":"2019-08-15","objectID":"/posts/dev-rules/:6:0","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"HTML ","date":"2019-08-15","objectID":"/posts/dev-rules/:7:0","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"代码编写 禁止在 HTML 使用 \u003cstyle\u003e、\u003cscript\u003e，一律使用外部档案引用方式引用 CSS、JavaScript 文件 HTML 标签需成双成对，有头有尾 块级标签：\u003ctag\u003e\u003c/tag\u003e 单标签：\u003ctag /\u003e 禁止使用已被 HTML 舍弃的旧标签、属性，如： \u003c!-- html tag --\u003e \u003ccenter\u003e \u003cfont\u003e \u003cbasefont\u003e \u003cs\u003e \u003cstrike\u003e \u003cu\u003e \u003clisting\u003e \u003cplaintext\u003e \u003cxmp\u003e \u003c!-- html attribute --\u003e align bgcolor color ","date":"2019-08-15","objectID":"/posts/dev-rules/:7:1","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"CSS CSS 的定义应该独立一个 CSS 文件，禁止使用 \u003cstyle\u003e 或 style 属性直接在 HTML 中定义样式。 ","date":"2019-08-15","objectID":"/posts/dev-rules/:8:0","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"JavaScript 禁止使用 HTML 字串，一律使用 Dom 产生 HTML, e.g: document.createDocumentFragment() ","date":"2019-08-15","objectID":"/posts/dev-rules/:9:0","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"注释 JavaScript 注释应该遵循 JSDoc 的标准撰写 全局变量 (Global) /* global ZT */ 常量 (Constant) /** * 常量說明 * @type {常量类型} */ Example /** * 请求地址 * @type {String} */ const REQUEST_URL = 'http://localhost:8080'; 函數、方法 (Function, Method) /** * 函数用途说明 * @param {参数类型} 参数名称参数说明 * @param {参数类型} [选择性参数名称] 参数说明 * @param {参数类型} [选择性参数名称=参数预设值] 参数说明 * @returns {返回值类型} 返回值说明 */ Example /** * 取得使用者 * @param {Int} userId 使用者 ID * @param {Object} [options] 其他选项 * @param {String} [options.query='a'] 查询关键词 默认为 'a' * @returns {Object} 使用者资料 */ function getUser(userId, options) { // do something return user; } ","date":"2019-08-15","objectID":"/posts/dev-rules/:9:1","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"Vue 待补充 ","date":"2019-08-15","objectID":"/posts/dev-rules/:10:0","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"Java Java 注释应该遵循 JavaDoc 的标准撰写 待补充 ","date":"2019-08-15","objectID":"/posts/dev-rules/:11:0","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"PHP ","date":"2019-08-15","objectID":"/posts/dev-rules/:12:0","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"前端参数取得 参数取得需通过 filter_input 函数取得，不得使用 _GET 、_POST ","date":"2019-08-15","objectID":"/posts/dev-rules/:12:1","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"输出到前台 参数命名必须为：全部小写，不同单字以「_」分隔 ","date":"2019-08-15","objectID":"/posts/dev-rules/:12:2","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"注解 PHP 注解应该遵循 PHPDoc 的标准撰写 ","date":"2019-08-15","objectID":"/posts/dev-rules/:12:3","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"成员变量 (Member) 成员变量只的是 Class 内的成员变数，我们都会要求替成员变量增加注解说明。通常 Function 的变量除非太特别否则都不需要特别注解说明。 /** * 成员变量說明 * @type {类型} */ Example /** * 使用者 ID * @type {String} */ $userId = 'Hello'; ","date":"2019-08-15","objectID":"/posts/dev-rules/:12:4","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"函数、方法 (Function, Method) /** * 函数用途说明 * @param 参数型态 参数名称 参数说明 * @option 参数选项类型 参数选项名称 参数选项说明 * @uses 全局变量 全域变数说明 * @returns 返回值类型 返回值说明 */ Example /** * 取得使用者 * @param int userId 使用者 ID * @param object options 其他选项 * @option string options['query'] 查询关键字 * @uses $_POST['role_id'] 从前端以 POST 取得角色 ID * @returns object 使用者资料 */ function getUser ($userId, $options) { // do something return $user; }; ","date":"2019-08-15","objectID":"/posts/dev-rules/:12:5","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"Python 待补充 ","date":"2019-08-15","objectID":"/posts/dev-rules/:13:0","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"Database 禁止使用 Table Join。 禁止使用 Oracle Trigger。 禁止将查询数据库的 SQL 放在循环中查询 ","date":"2019-08-15","objectID":"/posts/dev-rules/:14:0","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"SQL 撰写 属于 SQL 语法使用大写（SELECT，WHERE，INSERT etc..） 属于使用者自己定义的使用小写（表名 table name，字段名 column name etc..） 表名、字段名前后需加上 ` Example INSERT INTO `user` VALUES('a', 'b'); ","date":"2019-08-15","objectID":"/posts/dev-rules/:14:1","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["Spec"],"content":"统一用词 系统中常用词，例如弹出框按钮、搜索框等，仅为举例，不限与此。 用词 统一 最后、最终 最后 关闭、Cancel、取消 取消 存储、保存、修改、OK、确定 确定 搜寻、查询、查找、搜索 搜索 ","date":"2019-08-15","objectID":"/posts/dev-rules/:15:0","tags":["Git","REST","HTML","CSS","Scss","JavaScript","Vue","Java","PHP","Python"],"title":"Web 开发规则，代码规范","uri":"/posts/dev-rules/"},{"categories":["PHP"],"content":" 简单模仿了一个评论模板，当然肯定是没有博客的 valine 这么强大的 hhhh， PHP 表单安全性的重要提示 $_SERVER[\"PHP_SELF\"]变量能够被黑客利用！ 如果页面中使用了PHP_SELF，用户能够输入下划线然后执行跨站点脚本（XSS）。 比如说注入 js 脚本等，valine 以前的版本也有过这样的漏洞。 跨站点脚本（Cross-site scripting，XSS）是一种计算机安全漏洞类型，常见于 Web 应用程序。XSS 能够使攻击者向其他用户浏览的网页中输入客户端脚本。 可以像 valine 一样在用户输入完后保留输入，还有一些正则控制输入提示等简单功能。UI 就丑爆了算了。 \u003c!DOCTYPE HTML\u003e \u003chtml\u003e \u003chead\u003e \u003cstyle\u003e .error {color: #FF0000;} .main{ width: 20%; height: 100%; border: 1px #000 solid; padding: 20px; } \u003c/style\u003e \u003c/head\u003e \u003cbody\u003e \u003c?php // 定义变量并设置为空值 $nameErr = $emailErr = $genderErr = $websiteErr = \"\"; $name = $email = $gender = $comment = $website = \"\"; if ($_SERVER[\"REQUEST_METHOD\"] == \"POST\") { if (empty($_POST[\"name\"])) { $nameErr = \"Name is required\"; } else { $name = test_input($_POST[\"name\"]); // 检查名字是否包含字母和空格 if (!preg_match(\"/^[a-zA-Z ]*$/\",$name)) { $nameErr = \"Only letters and white space allowed\"; } } if (empty($_POST[\"email\"])) { $emailErr = \"Email is required\"; } else { $email = test_input($_POST[\"email\"]); // 检查电邮地址语法是否有效 if (!preg_match(\"/([\\w\\-]+\\@[\\w\\-]+\\.[\\w\\-]+)/\",$email)) { $emailErr = \"Invalid email format\"; } } if (empty($_POST[\"website\"])) { $website = \"\"; } else { $website = test_input($_POST[\"website\"]); // 检查 URL 地址语言是否有效（此正则表达式同样允许 URL 中的下划线） if (!preg_match(\"/\\b(?:(?:https?|ftp):\\/\\/|www\\.)[-a-z0-9+\u0026@#\\/%?=~_|!:,.;]*[-a-z0-9+\u0026@#\\/% =~_|]/i\",$website)) { $websiteErr = \"Invalid URL\"; } } if (empty($_POST[\"comment\"])) { $comment = \"\"; } else { $comment = test_input($_POST[\"comment\"]); } if (empty($_POST[\"gender\"])) { $genderErr = \"Gender is required\"; } else { $gender = test_input($_POST[\"gender\"]); } } function test_input($data) { $data = trim($data); $data = stripslashes($data); $data = htmlspecialchars($data); return $data; } ?\u003e \u003cdiv class=\"main\"\u003e \u003ch2\u003ePHP 验证实例\u003c/h2\u003e \u003cform method=\"post\" action=\"\u003c?php echo htmlspecialchars($_SERVER['PHP_SELF']);?\u003e\"\u003e 姓名：\u003cinput type=\"text\" name=\"name\" value=\"\u003c?php echo $name;?\u003e\"\u003e \u003cspan class=\"error\"\u003e* \u003c?php echo $nameErr;?\u003e\u003c/span\u003e \u003cbr\u003e\u003cbr\u003e 性别： \u003cinput type=\"radio\" name=\"gender\" \u003c?php if (isset($gender) \u0026\u0026 $gender==\"女性\") echo \"checked\";?\u003e value=\"女性\"\u003e女性 \u003cinput type=\"radio\" name=\"gender\" \u003c?php if (isset($gender) \u0026\u0026 $gender==\"男性\") echo \"checked\";?\u003e value=\"男性\"\u003e男性 \u003cspan class=\"error\"\u003e* \u003c?php echo $genderErr;?\u003e\u003c/span\u003e \u003cbr\u003e\u003cbr\u003e 电邮：\u003cinput type=\"text\" name=\"email\" value=\"\u003c?php echo $email;?\u003e\"\u003e \u003cspan class=\"error\"\u003e* \u003c?php echo $emailErr;?\u003e\u003c/span\u003e \u003cbr\u003e\u003cbr\u003e 网址：\u003cinput type=\"text\" name=\"website\" value=\"\u003c?php echo $website;?\u003e\"\u003e \u003cspan class=\"error\"\u003e\u003c?php echo $websiteErr;?\u003e\u003c/span\u003e \u003cbr\u003e\u003cbr\u003e 评论：\u003ctextarea name=\"comment\" rows=\"5\" cols=\"40\"\u003e\u003c?php echo $comment;?\u003e\u003c/textarea\u003e \u003cbr\u003e\u003cbr\u003e \u003cinput type=\"submit\" name=\"submit\" value=\"提交\"\u003e \u003ch2\u003e你的输入是：\u003c/h2\u003e \u003c?php echo $name.\"\u003cbr/\u003e\"; echo $gender.\"\u003cbr/\u003e\"; echo $email.\"\u003cbr/\u003e\"; echo $website.\"\u003cbr/\u003e\"; echo $comment.\"\u003cbr/\u003e\"; ?\u003e \u003cbr/\u003e \u003c/form\u003e \u003c/div\u003e \u003c/body\u003e \u003c/html\u003e ","date":"2019-07-19","objectID":"/posts/phpform/:0:0","tags":["PHP"],"title":"简单评论模块--php 表单练习","uri":"/posts/phpform/"},{"categories":["PHP"],"content":" 练习 php 函数的基本使用。 注： 必选参数在可选参数的前面。 可在函数中定义函数，需要先调用外层函数才能调用内层函数。 \u003c?php /* 创建表格 */ function createTable($rows,$cols,$bgcolor='pink',$content='x'){ $table = \"\u003ctable border='1' bgcolor='{$bgcolor}' cellpadding='10' cellspacing='0' width='50%' \u003e\"; for($i=1;$i\u003c=$rows;$i++){ $table.=\"\u003ctr\u003e\"; for($j=1;$j\u003c=$cols;$j++){ $table.=\"\u003ctd\u003e{$content}\u003c/td\u003e\"; } $table .=\"\u003c/tr\u003e\"; } $table.=\"\u003c/table\u003e\"; return $table; } echo createTable(5,5,'pink','hello lruihao'); ?\u003e ","date":"2019-07-15","objectID":"/posts/phpfunc/:0:0","tags":["PHP"],"title":"php 函数学习","uri":"/posts/phpfunc/"},{"categories":["Memo"],"content":" 使用 WAMPServer 时自定义网站根目录。 ","date":"2019-07-12","objectID":"/posts/wamproot/:0:0","tags":["WAMP","PHP","windows","server"],"title":"WAMPServer 自定义网站根目录等设置","uri":"/posts/wamproot/"},{"categories":["Memo"],"content":"WAMPServer 自定义网站根目录 ","date":"2019-07-12","objectID":"/posts/wamproot/:1:0","tags":["WAMP","PHP","windows","server"],"title":"WAMPServer 自定义网站根目录等设置","uri":"/posts/wamproot/"},{"categories":["Memo"],"content":"修改 apache 配置文件 打开httpd.conf文件搜索documentroot后，找到路径修改为自定义的。 再打开httpd-vhost.conf文件修改对应的路径。 修改完配置文件需要重启所有服务！ ","date":"2019-07-12","objectID":"/posts/wamproot/:1:1","tags":["WAMP","PHP","windows","server"],"title":"WAMPServer 自定义网站根目录等设置","uri":"/posts/wamproot/"},{"categories":["Memo"],"content":"修改 wampmanager 文件 在 wampserver 安装路径根目录知道wampmanager.ini和wampmanager.tpl两个文件。搜索menu.left, 然后也修改为自定义的路径。 然后退出，重启软件！ ","date":"2019-07-12","objectID":"/posts/wamproot/:1:2","tags":["WAMP","PHP","windows","server"],"title":"WAMPServer 自定义网站根目录等设置","uri":"/posts/wamproot/"},{"categories":["Memo"],"content":"编写 php 文件测试 \u003c?php echo \"hello world\"; ?\u003e ","date":"2019-07-12","objectID":"/posts/wamproot/:1:3","tags":["WAMP","PHP","windows","server"],"title":"WAMPServer 自定义网站根目录等设置","uri":"/posts/wamproot/"},{"categories":["Memo"],"content":"WAMPServer 多站点配置 打开httpd-vhost.conf文件，复制原有的几行配置文件，粘贴修改路径和域名等配置。比如 ## Virtual Hosts # \u003cVirtualHost *:80\u003e ServerName localhost ServerAlias localhost DocumentRoot \"g:/Demo\" \u003cDirectory \"g:/Demo\"\u003e Options +Indexes +Includes +FollowSymLinks +MultiViews AllowOverride All Require local \u003c/Directory\u003e \u003c/VirtualHost\u003e \u003cVirtualHost *:80\u003e ServerName test01.com DocumentRoot \"g:/Demo/test01\" \u003c/VirtualHost\u003e \u003cVirtualHost *:80\u003e ServerName test02.com DocumentRoot \"g:/Demo/test02\" \u003c/VirtualHost\u003e 再打开C:\\Windows\\System32\\drivers\\etc\\hosts文件，在文件最后添加类似于云服务器的域名解析，进行本地域名解析，当输入域名时优先从本地申请资源。 ... ## For example: # ## 102.54.94.97 rhino.acme.com ## source server ## 38.25.63.10 x.acme.com ## x client host ## localhost name resolution is handled within DNS itself. # 127.0.0.1 localhost # ::1 localhost 127.0.0.1 steamcommunity.com 192.168.28.1 windows10.microdone.cn 127.0.0.1 localhost ::1 localhost 127.0.0.1 test01.com 127.0.0.1 test02.com ","date":"2019-07-12","objectID":"/posts/wamproot/:2:0","tags":["WAMP","PHP","windows","server"],"title":"WAMPServer 自定义网站根目录等设置","uri":"/posts/wamproot/"},{"categories":["Memo"],"content":"WAMPServer 自拟定端口 WAMP 服务我安装了好几次，每次因为修改配置文件搞崩了。第一次装的时候发现 80 端口被占用了，因为以前玩了一下 Windows 的 IIS，暂停 IIS 的网站，再使用命令或者直接在控制面板关掉就好了。 如果不使用 80 多为默认端口，比如修改为 8080，还是在httpd.conf文件里修改。搜索80都改成8080然后，Ctrl+S 保存，重新启动 WampServer 在浏览器地址栏输入localhost:8000 #监听端口 Listen 0.0.0.0:8080 Listen [::0]:8080 ServerName localhost:8080 使用 Notepad++打开 C:\\wamp 目录下的 wampmanager.ini 和 wampmanager.tpl Ctrl+F 查找 localhost 将其全部替换为localhost:8000 然后，Ctrl+S 保存，重新启动 WampServer ","date":"2019-07-12","objectID":"/posts/wamproot/:3:0","tags":["WAMP","PHP","windows","server"],"title":"WAMPServer 自定义网站根目录等设置","uri":"/posts/wamproot/"},{"categories":["Python"],"content":" 后面几天讲的有点杂，简单记录一下知识点。 ","date":"2019-06-21","objectID":"/posts/pysx2/:0:0","tags":["Python"],"title":"python 实训总结Ⅱ","uri":"/posts/pysx2/"},{"categories":["Python"],"content":"6.19 这些知识点在课上都只是简单的提到了一下。 比如一些库的使用与安装都不会再课上详细讲解，需要课后再去研究。 ","date":"2019-06-21","objectID":"/posts/pysx2/:1:0","tags":["Python"],"title":"python 实训总结Ⅱ","uri":"/posts/pysx2/"},{"categories":["Python"],"content":"切片操作 列表切片操作 ","date":"2019-06-21","objectID":"/posts/pysx2/:1:1","tags":["Python"],"title":"python 实训总结Ⅱ","uri":"/posts/pysx2/"},{"categories":["Python"],"content":"字符串 python 原始字符串 print(r\"D:\\three\\two\") 长字符串 用三个单引号或者双引号包裹，前后呼应，成双成对。 用、换行字符表示字符未结束 ","date":"2019-06-21","objectID":"/posts/pysx2/:1:2","tags":["Python"],"title":"python 实训总结Ⅱ","uri":"/posts/pysx2/"},{"categories":["Python"],"content":"格式化输出 format \"=={}==\"，{}表示占位符，其前后字符保持原样输出。 #TempConvert.py TempStr = input(\"请输入带有符号的温度值：\") if TempStr[-1] in ['F','f']: C = (eval(TempStr[0:-1]) - 32)/1.8 print(\"转换后的温度是{:.2f}C\".format(C)) elif TempStr[-1] in ['C','c']: F = 1.8*eval(TempStr[0:-1]) + 32 print(\"转换后的温度是{:.2f}F\".format(F)) else: print(\"输入格式错误\") ","date":"2019-06-21","objectID":"/posts/pysx2/:1:3","tags":["Python"],"title":"python 实训总结Ⅱ","uri":"/posts/pysx2/"},{"categories":["Python"],"content":"多变量赋值与交换（斐波那契数列） python 3.x 版本 end=\"\" 可使输出不换行 print(x, end=\"\") #斐波那契数列 a, b = 1,1 while a \u003c 500: ## 输出不大于 500 的序列 print(a,end=\",\") a,b = b,a + b #交换变量 ","date":"2019-06-21","objectID":"/posts/pysx2/:1:4","tags":["Python"],"title":"python 实训总结Ⅱ","uri":"/posts/pysx2/"},{"categories":["Python"],"content":"笑傲江湖统计字符 (dict, 文件流） 统计《笑傲江湖》小说中出现的所有中文字符及标点符号的数量，每个字符及数目间用冒号:隔开，例如\"笑：1024\"，将所有字符及数量的对应采用逗号分隔，以 CSV 文件格式保存到“笑傲江湖--字符统计。txt”文件中。注意，统计字符不包括空格和回车。 csv 文件格式： ‘,’逗号连接元素 fi = open(\"data/笑傲江湖-网络版。txt\",\"r\",encoding=\"utf-8\") fo = open(\"data/笑傲江湖-字符统计。txt\",\"w\",encoding=\"utf-8\") txt = fi.read() #打开文件 #txt d = {} for c in txt: d[c] = d.get(c,0)+1 del d[' '] #删除字典中的空格和回车的键值对 del d['\\n'] ls = [] for key in d: ls.append(\"{}:{}\".format(key,d[key])) fo.write(\",\".join(ls)) fi.close() fo.close() ","date":"2019-06-21","objectID":"/posts/pysx2/:1:5","tags":["Python"],"title":"python 实训总结Ⅱ","uri":"/posts/pysx2/"},{"categories":["Python"],"content":"numpy 模块 … ","date":"2019-06-21","objectID":"/posts/pysx2/:1:6","tags":["Python"],"title":"python 实训总结Ⅱ","uri":"/posts/pysx2/"},{"categories":["Python"],"content":"pandas 模块 … ","date":"2019-06-21","objectID":"/posts/pysx2/:1:7","tags":["Python"],"title":"python 实训总结Ⅱ","uri":"/posts/pysx2/"},{"categories":["Python"],"content":"6.20 ","date":"2019-06-21","objectID":"/posts/pysx2/:2:0","tags":["Python"],"title":"python 实训总结Ⅱ","uri":"/posts/pysx2/"},{"categories":["Python"],"content":"matplotlib 绘图 import matplotlib.pyplot as plt import numpy as np x = np.arange(-5,5,0.01) y = 2**x+1 plt.plot(x,y) plt.title(\"y=2^x+1\",fontsize=24) plt.xlabel(\"X\",fontsize=14) plt.ylabel(\"Y\",fontsize=14) plt.tick_params(axis=\"both\",labelsize=14) plt.show() ","date":"2019-06-21","objectID":"/posts/pysx2/:2:1","tags":["Python"],"title":"python 实训总结Ⅱ","uri":"/posts/pysx2/"},{"categories":["Python"],"content":"爬虫 举了一个金融界，炒股，获取数据的爬虫 （今天没仔细听课，这数据爬过什么意思，咱不懂，咱也不敢问！） #! /usr/bin/env python #-*- encoding: utf-8 -*- #author pythontab.com import numpy as np import matplotlib.pyplot as plt import pandas as pd import pandas_datareader.data as web import datetime #import tushare as ts df_stockload = web.DataReader(\"000001.SS\", \"yahoo\", datetime.datetime(2017,1,1), datetime.date.today()) #print(type(datetime.datetime.now().strftime('%Y-%m-%d'))) #df_stockload = ts.get_hist_data('sh',start='2017-01-01',end=datetime.datetime.now().strftime('%Y-%m-%d')) print (df_stockload.columns)#查看列名 print (df_stockload.index)#查看索引 print (df_stockload.describe())#查看各列数据描述性统计 #绘制移动平均线 df_stockload.Close.plot(c='b') df_stockload.Close.rolling(window=30).mean().plot(c='r') #pd.rolling_mean(df_stockload.Close,window=30).plot(c='r') df_stockload.Close.rolling(window=60).mean().plot(c='g') #pd.rolling_mean(df_stockload.Close,window=60).plot(c='g') plt.legend(['Close','30ave','60ave'],loc='best') plt.show() Index(['High', 'Low', 'Open', 'Close', 'Volume', 'Adj Close'], dtype='object') DatetimeIndex(['2017-01-03', '2017-01-04', '2017-01-05', '2017-01-06', '2017-01-09', '2017-01-10', '2017-01-11', '2017-01-12', '2017-01-13', '2017-01-16', ... '2019-06-05', '2019-06-06', '2019-06-10', '2019-06-11', '2019-06-12', '2019-06-13', '2019-06-14', '2019-06-19', '2019-06-20', '2019-06-21'], dtype='datetime64[ns]', name='Date', length=596, freq=None) High Low Open Close Volume \\ count 596.000000 596.000000 596.000000 596.000000 5.960000e+02 mean 3076.147753 3039.201569 3056.960338 3060.169056 5.098201e+06 std 269.276147 273.757358 271.612122 272.072346 1.199107e+08 min 2488.479004 2440.906982 2446.019043 2464.363037 8.820000e+04 25% 2845.308228 2800.168762 2825.239502 2827.754822 1.375250e+05 50% 3153.184937 3118.613525 3134.300537 3139.085449 1.666500e+05 75% 3280.115234 3244.825256 3265.322021 3268.600342 2.091250e+05 max 3587.031982 3534.195068 3563.639893 3559.465088 2.927580e+09 Adj Close count 596.000000 mean 3060.169056 std 272.072346 min 2464.363037 25% 2827.754822 50% 3139.085449 75% 3268.600342 max 3559.465088 ","date":"2019-06-21","objectID":"/posts/pysx2/:2:2","tags":["Python"],"title":"python 实训总结Ⅱ","uri":"/posts/pysx2/"},{"categories":["Python"],"content":"6.21 ","date":"2019-06-21","objectID":"/posts/pysx2/:3:0","tags":["Python"],"title":"python 实训总结Ⅱ","uri":"/posts/pysx2/"},{"categories":["Python"],"content":"类 比第一天稍微仔细一点讲了一下类，有点需要注意： self相当于this表示当前对象 python 类的所有函数的第一个参数都要写self参数，self 也可以是其他的比如lrh等字符替代，但是必须保持一致。 __表示私有的 class 的定义可以不加 (),() 内可写继承的父类 ","date":"2019-06-21","objectID":"/posts/pysx2/:3:1","tags":["Python"],"title":"python 实训总结Ⅱ","uri":"/posts/pysx2/"},{"categories":["Python"],"content":"GUI 设计 wxPython pip install wxPython import wx import wx #导入 wxPython 库 class Panel(wx.Panel): def __init__(self,parent): wx.Panel.__init__(self,parent=parent, id=-1) pass class Frame(wx.Frame): def __init__(self): wx.Frame.__init__(self, parent = None, title = u'量化软件', size=(1000,600), style=wx.DEFAULT_FRAME_STYLE^wx.MAXIMIZE_BOX) self.DispPanel= Panel(self) pass class App(wx.App): def OnInit(self): self.frame = Frame() self.frame.Show() self.SetTopWindow(self.frame) return True if __name__ == '__main__': app = App() app.MainLoop() import wx app = wx.App() window = wx.Frame(None, title=\"wxPython 你好！\", size=(400, 300)) panel = wx.Panel(window) label = wx.StaticText(panel, label=\"Hello World\", pos=(100, 100)) window.Show(True) app.MainLoop() ","date":"2019-06-21","objectID":"/posts/pysx2/:3:2","tags":["Python"],"title":"python 实训总结Ⅱ","uri":"/posts/pysx2/"},{"categories":["Python"],"content":"talib 库的安装 下载 whl 文件 pip install TA_Lib-0.4.17-cp37-cp37m-win_amd64.whl pip install TA-Lib ","date":"2019-06-21","objectID":"/posts/pysx2/:3:3","tags":["Python"],"title":"python 实训总结Ⅱ","uri":"/posts/pysx2/"},{"categories":["Python"],"content":"选择排序递归版 def SelectSort(L): L=L[:] if len(L)\u003c=1: return L min = 0 for i in range(1,len(L)): if L[i]\u003cL[min]: min = i L[min],L[0] = L[0],L[min] return [L[0]]+SelectSort(L[1:]) L = [5,2,3,6,1,9,8,10,0] print(SelectSort(L)) [0, 1, 2, 3, 5, 6, 8, 9, 10] ","date":"2019-06-21","objectID":"/posts/pysx2/:3:4","tags":["Python"],"title":"python 实训总结Ⅱ","uri":"/posts/pysx2/"},{"categories":["Python"],"content":"机房上机系统（自我实践） import time class student(): def __init__(self,stu_no=\"\",stu_name=\"\",stu_xi=\"\",stu_time=\"\"): self.stu_no = stu_no self.stu_name = stu_name self.stu_xi = stu_xi self.stu_time = stu_time def print(self): print(\"学号：\"+self.stu_no+\"\\t 姓名：\"+self.stu_name+\"\\t 系别：\"+self.stu_xi+\"\\t 机时 (h)：\"+self.stu_time) def get_stu_name(self): return self.stu_name def get_stu_time(self): return int(self.stu_time) def set_stu_time(self,add_time): self.stu_time = add_time def menu(): print(\"\\t 机房上机系统 V0.1\") print(\"********************************\") print(\"\\t—\u003e1. 录入学生信息\") print(\"\\t—\u003e2. 上机\") print(\"\\t—\u003e3. 下机\") print(\"\\t—\u003e4. 缴费\") print(\"\\t—\u003e5. 退出\") print(\"********************************\") select = eval(input(\"请输入序号：\")) while select not in [1,2,3,4,5]: print(\"输入错误，请重新输入！\") select = eval(input(\"请输入序号：\")) return select def get_time(): #获取当前时间 return time.strftime(\"%H:%M:%S\", time.localtime()) def main(): ## 全局变量 text = [] ## 上机记录列表 start_time = \"\" end_time = \"\" sum = 0 ## 本系统按小时计费，不足一小时按一小时算 people = student() online_flag = False down_flag = False input_flag = False while True: select = menu() ## 启用菜单 if select == 1: if input_flag: print(\"已录入，无需重复操作，缴费请输入 4:\") continue else: input_flag = True stu_no = input(\"请输入学号：\") stu_name = input(\"请输入姓名：\") stu_xi = input(\"请输入系别：\") stu_time = input(\"请输入机时：\") people = student(stu_no,stu_name,stu_xi,stu_time) people.print() continue elif select == 2: if not input_flag: print(\"未录入学生信息，请录入！\") continue if not online_flag: online_flag = True start_time = get_time() start_num = int(start_time[0:2]) #print(start_num) text.append(\"上机时间：\"+start_time) print(\"已上机！上机时间为：\"+start_time) continue else: print(\"已上机！上机时间为：\"+start_time) continue elif select == 3: if not online_flag: print(\"还未上机，请上机！\") continue else: end_time = get_time() end_num = int(end_time[0:2]) sum = end_num - start_num sum = sum if(sum\u003e=0) else sum+24 sum = sum+1 if(sum==0) else sum print(\"已下机！下机时间为：\"+end_time+\"\\n 上机时长 (h)：\"+str(sum)+\"\\t 剩余机时 (h)：\"+str(people.get_stu_time()-sum)) text.append(\"下机时间：\"+end_time+\"\\n 上机时长 (h)：\"+str(sum)+\"\\t\"+people.get_stu_name()+\"剩余机时 (h)：\"+str(people.get_stu_time()-sum)) people.set_stu_time(str(people.get_stu_time()-sum)) down_flag = True continue elif select == 4: if not input_flag: print(\"未录入学生信息，请录入！\") continue else: people.print() add_time = eval(input(\"请输入机时：\")) people.set_stu_time(str(add_time+people.get_stu_time())) people.print() else: if down_flag: print(\"3s 后退出系统，感谢使用！\") time.sleep(3) ## 延迟 3s，显示提示文字 break ## 退出系统 写入文件 else: print(\"请下机！\") continue #写入 computer.txt 文件 fo = open(\"D:\\\\computer.txt\",\"w\",encoding=\"utf-8\") fo.write(\"\\n\".join(text)) fo.close() if __name__==\"__main__\": main() ","date":"2019-06-21","objectID":"/posts/pysx2/:3:5","tags":["Python"],"title":"python 实训总结Ⅱ","uri":"/posts/pysx2/"},{"categories":["Python"],"content":"量化交易代码分析与调试 由于 python 的版本问题和一些库的导入问题所以还未调试成功，先挂上代码。以后改篇再论。 #! /usr/bin/env python #-*- encoding: utf-8 -*- #author pythontab.com import wx import wx.adv import numpy as np import pandas as pd import pandas_datareader.data as web import matplotlib import matplotlib.pyplot as plt from matplotlib.figure import Figure import matplotlib.dates as mdates import mpl_finance as mpf from matplotlib.backends.backend_wxagg import FigureCanvasWxAgg as FigureCanvas import matplotlib.gridspec as gridspec#分割子图 import datetime import talib import csv,os import codecs from RedefPanelMod import MPL_Panel_Base,Loop_Panel_Base from StockDataMod import GetStockDatPro from IndicatStrateMod import Excave_Indic_Base, QuantPickTimeSys,FactorPickStockAng plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签 plt.rcParams['axes.unicode_minus']=False #用来正常显示负号 class UserDialog(wx.Dialog):## user-defined def __init__(self,parent,text): wx.Dialog.__init__(self,parent,-1,u\"选股提示\",size=(400,500),style=wx.CAPTION|wx.CLOSE_BOX|wx.MAXIMIZE_BOX|wx.MINIMIZE_BOX) sizer = wx.BoxSizer(wx.VERTICAL) pstock_Text = wx.StaticText(self, -1, u'选股策略筛选结果') pstock_Text.SetFont(wx.Font(18,wx.DEFAULT,wx.NORMAL,wx.BOLD)) pstock_sure = wx.TextCtrl(self, -1, \"角度值：\\n\",size=(350,300),style = wx.TE_MULTILINE|wx.TE_READONLY)#多行|只读 pstock_sure.SetFont(wx.Font(10,wx.DEFAULT,wx.NORMAL,wx.BOLD)) okbtn = wx.Button(self,wx.ID_OK,u\"确认\") okbtn.SetDefault() sizer.Add(pstock_Text,flag=wx.ALIGN_CENTER) sizer.Add(pstock_sure,flag=wx.ALIGN_CENTER) sizer.Add(okbtn,flag=wx.ALIGN_CENTER) self.SetSizer(sizer) for i in text:pstock_sure.AppendText(i) class Frame(wx.Frame): def __init__(self): wx.Frame.__init__(self, parent = None, title = u'量化软件', size=(1500,800), style=wx.DEFAULT_FRAME_STYLE^wx.MAXIMIZE_BOX) #创建显示区面板 self.DispPanel = MPL_Panel_Base(self) self.BackPanel = Loop_Panel_Base(self) self.am = self.DispPanel.am self.vol = self.DispPanel.vol self.devol = self.DispPanel.devol self.macd = self.DispPanel.macd #创建参数区面板 self.ParaPanel = wx.Panel(self,-1) paraInput_Box = wx.StaticBox(self.ParaPanel, -1, u'参数输入') paraInput_Sizer = wx.StaticBoxSizer(paraInput_Box, wx.VERTICAL) self.StNameCodedict = {u\"开山股份\":\"300257.SZ\",u\"浙大网新\":\"600797.SS\",u\"水晶光电\":\"002273.SZ\", u\"高鸿股份\":\"000851.SZ\"} #初始化股票代码变量 self.stockName_Val = u\"开山股份\" self.stockCode_Val = self.StNameCodedict[self.stockName_Val] self.stockName_CMBO = wx.ComboBox(self.ParaPanel, -1,self.stockName_Val, choices = list(self.StNameCodedict.keys()), style = wx.CB_READONLY|wx.CB_DROPDOWN) #股票名称 stockCode_Text = wx.StaticText(self.ParaPanel, -1, u'股票名称') #策略选取 strate_Text = wx.StaticText(self.ParaPanel, -1, u'策略名称') strate_Combo_Val = [u\"双趋势融合\", u\"阿尔法\", u\"布林带\"] self.pickstrate_Val = u\"双趋势融合\" self.pickstrate_CMBO = wx.ComboBox(self.ParaPanel, -1, self.pickstrate_Val, choices = strate_Combo_Val, style = wx.CB_READONLY|wx.CB_DROPDOWN) #策略名称 #日历控件选择数据周期 self.dpcEndTime = wx.adv.DatePickerCtrl(self.ParaPanel, -1,style = wx.adv.DP_DROPDOWN|wx.adv.DP_SHOWCENTURY|wx.adv.DP_ALLOWNONE)#结束时间 self.dpcStartTime = wx.adv.DatePickerCtrl(self.ParaPanel, -1,style = wx.adv.DP_DROPDOWN|wx.adv.DP_SHOWCENTURY|wx.adv.DP_ALLOWNONE)#起始时间 DateTimeNow = wx.DateTime.Now()#wx.DateTime 格式\"03/03/18 00:00:00\" #DateTimeNow = datetime.datetime.fromtimestamp(wx.DateTime.Now().GetTicks()) #DateTimeNow = datetime.datetime.fromtimestamp(DateTimeNow) self.dpcEndTime.SetValue(DateTimeNow) DateTimeNow.SetYear(DateTimeNow.year-1) self.dpcStartTime.SetValue(DateTimeNow) stockData_Text = wx.StaticText(self.ParaPanel, -1, u'日期 (Start-End)') #初始化时间变量 dateVal = self.dpcStartTime.GetValue() self.stockSdate_Val = datetime.datetime(dateVal.year,dateVal.month+1,dateVal.day) dateVal = self.dpcEndTime.GetValue() self.stockEdate_Val = datetime.datetime(dateVal.year,dateVal.month+1,dateVal.day) paraInput_Sizer.Add(stockCode_Text,proportion=0,flag=wx.EXPAND|wx.ALL,border=2) paraInput_Sizer.Add(self.stockName_CMBO, 0, wx.EXPAND|wx.ALL|wx.CENTER, 2) paraInput_Sizer.Add(stockData_Text,proportion=0,flag=wx.EXPAND|wx.ALL","date":"2019-06-21","objectID":"/posts/pysx2/:3:6","tags":["Python"],"title":"python 实训总结Ⅱ","uri":"/posts/pysx2/"},{"categories":["Python"],"content":" 以前和前一段时间自己也学习了一下 python，也写了几个小爬虫； 这次正好又课程安排了为期两周的综合实训，主要是“用 python 做量化交易” 进行了两天，讲的都是一些基本的东西，以前也接触过，所以很容易理解。还讲了一些软件，pycharm，anaconda,sublime 等大都也都用过。anaconda 倒是第一次接触。 ","date":"2019-06-18","objectID":"/posts/pysx1/:0:0","tags":["Python","turtle"],"title":"python 实训总结Ⅰ","uri":"/posts/pysx1/"},{"categories":["Python"],"content":"6.17 print(\"Hello World!\") 讲了一下变量和 python 的特色什么的。 还讲了模块定义def和类定义 class zxm(): def __init__(self): self.x=0 self.y=0 def move_up(self): self.y +=1 my_zxm=zxm() print(my_zxm) \u003c__main__.zxm object at 0x000001D99CFEF668\u003e ","date":"2019-06-18","objectID":"/posts/pysx1/:1:0","tags":["Python","turtle"],"title":"python 实训总结Ⅰ","uri":"/posts/pysx1/"},{"categories":["Python"],"content":"6.18 ","date":"2019-06-18","objectID":"/posts/pysx1/:2:0","tags":["Python","turtle"],"title":"python 实训总结Ⅰ","uri":"/posts/pysx1/"},{"categories":["Python"],"content":"输入输出 print 输出 input 输入 eval 执行一个字符串表达式，并返回表达式的值 x=eval(input(\"请输入 x 的值：\")) y=eval(input(\"请输入 y 的值：\")) z=(x**2+y**2)**0.5 print(z) # 导入复数数学模块 import cmath num = int(input(\"请输入一个数字：\")) num_sqrt = cmath.sqrt(num) print('{0} 的平方根为 {1:0.3f}+{2:0.3f}j'.format(num ,num_sqrt.real,num_sqrt.imag)) ","date":"2019-06-18","objectID":"/posts/pysx1/:2:1","tags":["Python","turtle"],"title":"python 实训总结Ⅰ","uri":"/posts/pysx1/"},{"categories":["Python"],"content":"数据类型 今天还讲了一下数据类型 字符串： \"\" '' 元组 tuple(2,3) 列表 list[2,3] 字典 dict{Key:Value} 集合{} x=[1,10] type(x)#判断元素类型 list ","date":"2019-06-18","objectID":"/posts/pysx1/:2:2","tags":["Python","turtle"],"title":"python 实训总结Ⅰ","uri":"/posts/pysx1/"},{"categories":["Python"],"content":"循环判断 for x in range(1,10,2): # (start,stop,step) pass # pass 不做任何事情，一般用做占位语句 for letter in 'Python': if letter == 'h': pass print('这是 pass 块') print('当前字母 :'+ letter) print(\"Good bye!\") 当前字母 :P 当前字母 :y 当前字母 :t 这是 pass 块 当前字母 :h 当前字母 :o 当前字母 :n Good bye! ","date":"2019-06-18","objectID":"/posts/pysx1/:2:3","tags":["Python","turtle"],"title":"python 实训总结Ⅰ","uri":"/posts/pysx1/"},{"categories":["Python"],"content":"str() 、 import 导库 x=10 print(\"整数转字符串\"+str(x)) import this The Zen of Python, by Tim Peters Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren't special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you're Dutch. Now is better than never. Although never is often better than *right* now. If the implementation is hard to explain, it's a bad idea. If the implementation is easy to explain, it may be a good idea. Namespaces are one honking great idea -- let's do more of those! Google 翻译意思是： 美丽胜过丑陋。显式优于隐式。简单比复杂更好。复杂比复杂更好。Flat 优于嵌套。稀疏优于密集。可读性很重要。特殊情况不足以打破规则。虽然实用性胜过纯洁。错误不应该默默地传递。除非明确沉默。面对模棱两可，拒绝猜测的诱惑。应该有一个最好只有一个明显的方法来做到这一点。虽然这种方式起初可能并不明显，除非你是荷兰人。现在比永远好。虽然现在永远不会比正确好。如果实施很难解释，这是一个坏主意。如果实现很容易解释，那可能是个好主意。命名空间是一个很棒的主意，让我们做更多的事情吧！ ","date":"2019-06-18","objectID":"/posts/pysx1/:2:4","tags":["Python","turtle"],"title":"python 实训总结Ⅰ","uri":"/posts/pysx1/"},{"categories":["Python"],"content":"turtle 绘图库（内置模块）","date":"2019-06-18","objectID":"/posts/pysx1/:2:5","tags":["Python","turtle"],"title":"python 实训总结Ⅰ","uri":"/posts/pysx1/"},{"categories":["Grocery"],"content":" 黑盒测试着重测试软件功能，它并不涉及程序的内部结构和内容特性，主要根据规格说明，只依靠被测试程序的输入和输出之间关系或程序的功能来设计测试用例。 白盒测试则清楚程序内部的结构以及是如何运作的，因此白盒测试需要对系统内部的结构和工作原理有一个清楚的了解。 ","date":"2019-05-26","objectID":"/posts/judgetriangle/:0:0","tags":["黑盒测试","C"],"title":"判断三角形的黑盒测试","uri":"/posts/judgetriangle/"},{"categories":["Grocery"],"content":"程序 #include\u003cstdio.h\u003e #include\u003cstdlib.h\u003e #define N 2\u003c\u003c25 int a=N,b=N,c=N,d=N; void shuru(); void panduan(int a1,int b1,int c1); int main() { char se; shuru(); panduan(a,b,c); while(1) { printf(\"是否要继续 y or n :\"); scanf(\"%c\",\u0026se); if(se=='\\n') scanf(\"%c\",\u0026se); switch(se) { case 'y': shuru(); panduan(a,b,c); break; case 'n': return 0; } } } void shuru() { printf(\"Please enter 三角形三边 (a,b,c)\\n\"); while(!scanf(\"%d,%d,%d,%d\",\u0026a,\u0026b,\u0026c,\u0026d)){//判断非数字字符 fflush(stdin);//清理缓存 a=N;b=N;c=N;d=N; printf(\"输入错误、n\"); } fflush(stdin); while((a\u003c1||a\u003e100)||(b\u003c1||b\u003e100)||(c\u003c1||c\u003e100)||d!=N) { if(b==N||c==N||d!=N) printf(\"输入错误、n\");//边数为 1、2、4 条 else if(a==0||b==0||c==0) printf(\"边长不能为 0\\n\"); else if(a\u003c0||b\u003c0||c\u003c0) printf(\"边长不能为负、n\"); else printf(\"Please enter 1-100 之间的整数、n\"); a=N;b=N;c=N;d=N; while(!scanf(\"%d,%d,%d,%d\",\u0026a,\u0026b,\u0026c,\u0026d)){//判断非数字字符 fflush(stdin);//清理缓存 a=N;b=N;c=N;d=N; printf(\"输入错误、n\"); } fflush(stdin); } } void panduan(int a1,int b1,int c1) { if(a1+b1\u003ec1\u0026\u0026b1+c1\u003ea1\u0026\u0026a1+c1\u003eb1) { if(a1==b1\u0026\u0026a1==c1) printf(\"等边三角形、n\"); else if(a1==b1||a1==c1||b1==c1) printf(\"等腰三角形、n\"); else printf(\"一般三角形、n\"); } else printf(\"非三角形、n\"); } ","date":"2019-05-26","objectID":"/posts/judgetriangle/:1:0","tags":["黑盒测试","C"],"title":"判断三角形的黑盒测试","uri":"/posts/judgetriangle/"},{"categories":["Grocery"],"content":"测试 测试 1 测试 2 测试 3 ","date":"2019-05-26","objectID":"/posts/judgetriangle/:2:0","tags":["黑盒测试","C"],"title":"判断三角形的黑盒测试","uri":"/posts/judgetriangle/"},{"categories":["Memo"],"content":" 目前 HustOj 在 GitHUb 地址是：https://github.com/zhblue/hustoj 安装时注意 ubuntu 版本，没条件的可以在自己 ubuntu 上尝试，或者虚拟机上（关注公众号回复ubuntu16.04获取 iso 镜像文件），也可以在云实验室的云服务器上做做实验。 更多说明及 ACM/NOIP 题库下载见官网博客 代码的那些事|程序员回忆录 ","date":"2019-05-17","objectID":"/posts/hustoj/:0:0","tags":["hustoj","ACM","ubuntu","linux"],"title":"HustOJ 基础搭建教程","uri":"/posts/hustoj/"},{"categories":["Memo"],"content":"快速安装 OJ 下载 wget https://raw.githubusercontent.com/zhblue/hustoj/master/trunk/install/install-ubuntu16+.sh 安装 sudo bash install-ubuntu16+.sh 等待中一路回车，当提示 done！ 则表示安装成功： ","date":"2019-05-17","objectID":"/posts/hustoj/:1:0","tags":["hustoj","ACM","ubuntu","linux"],"title":"HustOJ 基础搭建教程","uri":"/posts/hustoj/"},{"categories":["Memo"],"content":"使用 HustOJ 打开网页/IP 地址 注册 admin 用 admin 作为用户名注册一个用户，将会自动成为管理员。 注册成功，会提示： 登录后台 登录账号，并点击右上角的管理： 添加测试题目 在后台选择添加题目，添加成功： 然后再提交代码测试判题机。 ","date":"2019-05-17","objectID":"/posts/hustoj/:2:0","tags":["hustoj","ACM","ubuntu","linux"],"title":"HustOJ 基础搭建教程","uri":"/posts/hustoj/"},{"categories":["Memo"],"content":"说明 安装后几个重要配置文件的位置 /home/judge/etc/judge.conf /home/judge/src/web/include/db_info.inc.php /etc/php5/fpm/php.ini 或 /etc/php7.0/fpm/php.ini /etc/nginx/sites-enabled/default ","date":"2019-05-17","objectID":"/posts/hustoj/:3:0","tags":["hustoj","ACM","ubuntu","linux"],"title":"HustOJ 基础搭建教程","uri":"/posts/hustoj/"},{"categories":["ACM"],"content":" 二进制最大公约数算法避免了欧几里得算法（辗转相除法）的大量取模操作，有效减少了时间消耗，且更为方便。 ","date":"2019-05-17","objectID":"/posts/gcd-bit/:0:0","tags":["欧几里得","数学","数论","C"],"title":"最大公约数（二进制算法）","uri":"/posts/gcd-bit/"},{"categories":["ACM"],"content":"原理 本算法基于以下事实： 对于两个数的最大公约数 gcd(m, n)，有 m\u003cn 时，gcd(m, n)=gcd(n, m) m 偶 n 偶时，gcd(m, n)=2*gcd(m/2, n/2) m 偶 n 奇时，gcd(m, n)=gcd(m/2, n) m 奇 n 偶时，gcd(m, n)=gcd(m, n/2) m 奇 n 奇时，gcd(m, n)=gcd(n, m-n) 采用递归即可。 ","date":"2019-05-17","objectID":"/posts/gcd-bit/:1:0","tags":["欧几里得","数学","数论","C"],"title":"最大公约数（二进制算法）","uri":"/posts/gcd-bit/"},{"categories":["ACM"],"content":"实现 inline int GCD(int x,int y) { int i,j; if(x==0) return y; if(y==0) return x; for(i=0;0==(x\u00261);++i)x\u003e\u003e=1; // 去掉所有的 2 for(j=0;0==(y\u00261);++j)y\u003e\u003e=1; // 去掉所有的 2 if(j\u003ci) i=j; while(1){ if(x\u003cy)x^=y,y^=x,x^=y; // 若 x \u003c y 交换 x, y if(0==(x-=y)) return y\u003c\u003ci; // 若 x == y， gcd == x == y （就是在辗转减，while(1) 控制） while(0==(x\u00261))x\u003e\u003e=1; // 去掉所有的 2 } } int get_lcm(int a,int b)///获得最小公倍数 { int x=a; int y=b; while(b) { int t=a; a=b; b=t%b; } return x/a*y; } ","date":"2019-05-17","objectID":"/posts/gcd-bit/:2:0","tags":["欧几里得","数学","数论","C"],"title":"最大公约数（二进制算法）","uri":"/posts/gcd-bit/"},{"categories":["Grocery"],"content":" ImgURL 是一个开源、免费的图床程序，ImgURL 2.x 之后对环境要求更高，尤其是 ImageMagick 组件的支持，很多朋友不清楚怎样安装这个组件，这篇文章分享宝塔面板安装 ImgURL 2.x 图床的过程（包括 ImgURL 2.x 需要的各种组件） 阅读原文 ","date":"2019-05-16","objectID":"/posts/imgurl/:0:0","tags":["ImgURL","宝塔面板"],"title":"宝塔面板安装 ImgURL 图床","uri":"/posts/imgurl/"},{"categories":["Grocery"],"content":"准备工作 已经安装宝塔面板 在宝塔后台创建一个站点 下载 ImgURL 2.x 上传到站点根目录并解压 ","date":"2019-05-16","objectID":"/posts/imgurl/:1:0","tags":["ImgURL","宝塔面板"],"title":"宝塔面板安装 ImgURL 图床","uri":"/posts/imgurl/"},{"categories":["Grocery"],"content":"设置伪静态 如果您宝塔面板安装的 Apache 则不需要再设置伪静态，直接跳过这个步骤，如果使用的 Nginx 环境，请继续往下看。 找到对应的站点 - 点击后面设置按钮 - 伪静态 - 添加下面的伪静态规则 location / { try_files $uri $uri/ /index.php?$query_string; } location ~* \\.(db3|json)$ { deny all; } location ~* ^/(temp|upload|imgs|data|application|static|system)/.*.(php|php5)$ { return 403; } ","date":"2019-05-16","objectID":"/posts/imgurl/:2:0","tags":["ImgURL","宝塔面板"],"title":"宝塔面板安装 ImgURL 图床","uri":"/posts/imgurl/"},{"categories":["Grocery"],"content":"安装 fileinfo \u0026 imagemagick 在宝塔后台 - 软件管理 - 找到您站点对应的 PHP 版本 - 设置 PHP - 安装扩展 - 勾选fileinfo和imagemagick，如下截图。 ","date":"2019-05-16","objectID":"/posts/imgurl/:3:0","tags":["ImgURL","宝塔面板"],"title":"宝塔面板安装 ImgURL 图床","uri":"/posts/imgurl/"},{"categories":["Grocery"],"content":"安装 ImgURL 2.x 其它所需扩展宝塔默认已经支持，重点是安装fileinfo和imagemagick，扩展安装完毕后就可以访问您自己的域名安装 ImgURL 了，如果正常会看到 ImgURL 安装界面。 ","date":"2019-05-16","objectID":"/posts/imgurl/:4:0","tags":["ImgURL","宝塔面板"],"title":"宝塔面板安装 ImgURL 图床","uri":"/posts/imgurl/"},{"categories":["Grocery"],"content":"其它说明 如果安装遇到任何问题，请留言反馈或到 3T 官方社区 进行反馈 ImgURL 更多使用说明请参考帮助文档：https://dwz.ovh/imgurldoc ","date":"2019-05-16","objectID":"/posts/imgurl/:5:0","tags":["ImgURL","宝塔面板"],"title":"宝塔面板安装 ImgURL 图床","uri":"/posts/imgurl/"},{"categories":["Python"],"content":" 用 python 模拟 post 请求获取“麻小科技”示例酒店后台的数据，再打包发送至指定的微信群或者好友。 要求每天早上 8 点定时把每个酒店的数据发送至每个酒店的微信工作群。 ","date":"2019-05-11","objectID":"/posts/mx2wx/:0:0","tags":["Python","wxpy","pyinstaller","HTTP","JSON","Cron"],"title":"python 实战：模拟 post 请求定时获取后台数据并打包发送至微信","uri":"/posts/mx2wx/"},{"categories":["Python"],"content":"背景 麻小科技： 麻小科技全名深圳市麻小科技有限公司，成立于 2017 年 1 月。是我高一的时候参加Peer 夏令营带我们一个玩的“老师”和他的朋友的创业公司，说老师有点奇怪，我们都是直接叫名字的，比如大家都叫我瑞豪，我也就叫他文捷哥，简称捷哥吧。他们公司主要的开发模式是，小程序前端+php 后端，然后做的是酒店小程序，为每个酒店定制小程序。这些小程序可以贴在客房中给访客提供一些服务，大大节省了成本也提高了效率。 然后每个酒店小程序都有独立的后台，后台会记录一些点击需求的数据。现在他们有一个需求需要把每个酒店小程序后台的数据在每天早上 9 点发送至对应酒店的微信群。 ","date":"2019-05-11","objectID":"/posts/mx2wx/:1:0","tags":["Python","wxpy","pyinstaller","HTTP","JSON","Cron"],"title":"python 实战：模拟 post 请求定时获取后台数据并打包发送至微信","uri":"/posts/mx2wx/"},{"categories":["Python"],"content":"实现代码 缓存登录信息，短时间类无需重复登录，仅第一次需要扫码登录（相当于微信网页版），后面的登录只需在手机上确认登录信息。 #!/usr/bin/python import requests import json import time from wxpy import * ## 基本信息填写： ## 酒店 id，酒店名称及群名列表数据，格式：[\"xxx\",\"xxx\",\"xxx\"] ## 使用时请将以下三个列表一一对应 hotel=[\"xxxx\",\"xxxx\"] ## 酒店后台数据接口二级域名，已匿名 hotel_name=[\"增城宾馆\",\"百丽酒店\"] grouplist = [\"麻小\",\"富强民主文明和谐自由平等公正法治\"] ## post 请求发送的数据 postData = { ## 'username':'test', ## 'password':'123456', } def get_data(): result = [] #结果列表 i = 0 #计数器 for each in hotel: url=\"http://\"+each+\".maxiaokeji.com/xxx/xxxxxxx/xxx\" ## 为保护隐私及权益，这里不提供接口 r = requests.post(url,data=postData) ## print(r.text) ## 把结果转化为 json 字符串 response=json.dumps(r.json(),indent=4,ensure_ascii=False) #sort_keys=True ## 把 json 转换为 dict 字典作为中间结果，再取出昨日数据 midresult=json.loads(response) result.append(\"早上好！\"+hotel_name[i]+\"小程序昨日数据如下：\\n 访问数：\"+str(midresult[\"data\"][\"yesterday_data\"][\"type1\"])+\"\\n 房间数：\"+str(midresult[\"data\"][\"yesterday_data\"][\"type2\"])+\"\\n 需求量：\"+str(midresult[\"data\"][\"yesterday_data\"][\"type3\"])+\"\\n 商品点击量：\"+str(midresult[\"data\"][\"yesterday_data\"][\"type4\"])) i+=1 ## print(result) return result def wechat_send(bot,result): ## my_friend = bot.friends().search('lrh')[0] ## my_friend.send(result) i = 0 ## 计数器 for group in grouplist: my_group = bot.groups().search(group)[0] #依次搜索每一个群名称，每次一个 my_group.send(result[i]) print(result[i]) print(\"已发送至群：\"+group) i+=1 def main(bot): ## 设置最大休眠时间，防止程序长时间占用系统资源 while True: now_hour = time.strftime(\"%H\", time.localtime()) now_min = time.strftime(\"%M\", time.localtime()) ## 设置每天 8 点发送 if now_hour \u003c \"08\": rest = 8 - int(now_hour) sleeptime = (rest-1)*3600 + (60-int(now_min))*60 print(\"启动时北京时间为：\"+time.strftime(\"%H:%M\", time.localtime()),\"\\t 软件将在\",rest-1,\"小时\",int((sleeptime-(rest-1)*3600)/60),\"分钟后发送数据\") time.sleep(sleeptime) elif now_hour \u003e \"08\": rest = 8 - int(now_hour) + 24 sleeptime = (rest-1)*3600 + (60-int(now_min))*60 print(\"启动时北京时间为：\"+time.strftime(\"%H:%M\", time.localtime()),\"\\t 软件将在\",rest-1,\"小时\",int((sleeptime-(rest-1)*3600)/60),\"分钟后发送数据\") time.sleep(sleeptime) elif now_hour == \"08\": print(\"软件明天开始将在每天 8 点发送数据！\") result=get_data() ## 获取数据 wechat_send(bot,result) ## 发送数据 time.sleep(86400-int(now_min)*60) if __name__==\"__main__\": bot = Bot(cache_path=True) ## 初始化机器人，扫码登陆 main(bot); ","date":"2019-05-11","objectID":"/posts/mx2wx/:2:0","tags":["Python","wxpy","pyinstaller","HTTP","JSON","Cron"],"title":"python 实战：模拟 post 请求定时获取后台数据并打包发送至微信","uri":"/posts/mx2wx/"},{"categories":["Python"],"content":"测试结果 ","date":"2019-05-11","objectID":"/posts/mx2wx/:3:0","tags":["Python","wxpy","pyinstaller","HTTP","JSON","Cron"],"title":"python 实战：模拟 post 请求定时获取后台数据并打包发送至微信","uri":"/posts/mx2wx/"},{"categories":["Python"],"content":"程序打包 使用 pyinstaller 工具打包成可执行文件即可。（可执行文件不可跨平台运行，分平台打包） 目前该程序已经上线测试中 … 暂未反馈问题 ","date":"2019-05-11","objectID":"/posts/mx2wx/:4:0","tags":["Python","wxpy","pyinstaller","HTTP","JSON","Cron"],"title":"python 实战：模拟 post 请求定时获取后台数据并打包发送至微信","uri":"/posts/mx2wx/"},{"categories":["Python"],"content":"收获 第一次参与实际公司的项目开发，虽然只是一个小的需求设计，但是我在这个过程中也学到了很多，比如通过实际一两周的编程对 Python 的熟悉度远远好过以前在实验室看的一个月视频。 还有就是在此次开发中，也感受到了实际项目开发的团队合作重要性，刚开始拿到这个需求，由于我对 python 和后台，以及数据接口这些基本的操作都不懂，就拿数据获取来说，我一开始一位要自己模拟登陆后台（已知密码），一顿操作、百度等等失败告终，后来涛哥给了一个数据接口，加上涛哥耐心指点，我才终于拿到了数据。 还有在多人合作的项目中，为保持代码的可读性，要尽量的多些注释，还有函数方法的命名尽量具备可读性。比如我代码中的wechat_send()，一开始的命名是wxfs()，经捷哥指正我才改过来的。 ","date":"2019-05-11","objectID":"/posts/mx2wx/:5:0","tags":["Python","wxpy","pyinstaller","HTTP","JSON","Cron"],"title":"python 实战：模拟 post 请求定时获取后台数据并打包发送至微信","uri":"/posts/mx2wx/"},{"categories":["Grocery"],"content":" \u003c!--[if !IE]\u003e\u003c!--\u003e 除 IE 外都可识别 \u003c!--\u003c![endif]--\u003e \u003c!--[if IE]\u003e 所有的 IE 可识别 \u003c![endif]--\u003e \u003c!--[if IE 6]\u003e 仅 IE6 可识别 \u003c![endif]--\u003e \u003c!--[if lt IE 6]\u003e IE6 以及 IE6 以下版本可识别 \u003c![endif]--\u003e \u003c!--[if gte IE 6]\u003e IE6 以及 IE6 以上版本可识别 \u003c![endif]--\u003e \u003c!--[if IE 7]\u003e 仅 IE7 可识别 \u003c![endif]--\u003e \u003c!--[if lt IE 7]\u003e IE7 以及 IE7 以下版本可识别 \u003c![endif]--\u003e \u003c!--[if gte IE 7]\u003e IE7 以及 IE7 以上版本可识别 \u003c![endif]--\u003e \u003c!--[if IE 8]\u003e 仅 IE8 可识别 \u003c![endif]--\u003e \u003c!--[if IE 9]\u003e 仅 IE9 可识别 \u003c![endif]--\u003e 项目范例说明 ![if !IE]The NOT operator. This is placed immediately in front of the feature, operator, or subexpression to reverse the Boolean meaning of the expression. NOT 运算符。这是摆立即在前面的功能，操作员，或子表达式扭转布尔表达式的意义。lt [if lt IE 5.5] The less-than operator. Returns true if the first argument is less than the second argument. 小于运算符。如果第一个参数小于第二个参数，则返回 true。 lte[if lte IE 6]The less-than or equal operator. Returns true if the first argument is less than or equal to the second argument. 小于或等于运算。如果第一个参数是小于或等于第二个参数，则返回 true。 gt[if gt IE 5]The greater-than operator. Returns true if the first argument is greater than the second argument. 大于运算符。如果第一个参数大于第二个参数，则返回 true。 gte [if gte IE 7]The greater-than or equal operator. Returns true if the first argument is greater than or equal to the second argument. 大于或等于运算。如果第一个参数是大于或等于第二个参数，则返回 true。 ( )[if !(IE 7)]Subexpression operators. Used in conjunction with boolean operators to create more complex expressions. 子表达式运营商。在与布尔运算符用于创建更复杂的表达式。\u0026[if (gt IE 5)\u0026(lt IE 7)]The AND operator. Returns true if all subexpressions evaluate to true AND 运算符。如果所有的子表达式计算结果为 true，返回 true|[if (IE 6)|(IE 7)]The OR operator. Returns true if any of the subexpressions evaluates to true. OR 运算符。返回 true，如果子表达式计算结果为 true。 \u003c!--[if lt IE 9]\u003e 加载 CSS1 \u003c!--[else]\u003e 加载 CSS2 \u003c![endif]--\u003e 这样有效是有效，但是用 HTML VALIDATOR 里，报错，因为这个不符合 XHTML 1.1 的规范， 如果把 ELSE 语句去掉，则正确。 加载 CSS2 \u003c!--[if lt IE 9]\u003e 加载 CSS1（可以把要重写的写在这里）. \u003c![endif]--\u003e ","date":"2019-05-10","objectID":"/posts/ifzhushi/:0:0","tags":["HTML","他山之石"],"title":"条件注释判断浏览器版本\u003c!--[if lt IE 9]\u003e;","uri":"/posts/ifzhushi/"},{"categories":["Python"],"content":" 第一次运行根据程序执行时间，判断程序休眠的时间，尽最大可能休眠，节省系统资源。 第二次运行后直接休眠一天，到每天早上 8 点执行任务。 （该程序需要一直挂着，保持网络不断） import time while True: now_hour = time.strftime(\"%H\", time.localtime()) now_min = time.strftime(\"%M\", time.localtime()) if now_hour \u003c \"08\": rest = 8 - int(now_hour) sleeptime = (rest-1)*3600 + (60-int(now_min))*60 print(\"启动时北京时间为：\"+time.strftime(\"%H:%M\", time.localtime()),\"\\t 软件将在\",rest-1,\"小时\",int((sleeptime-(rest-1)*3600)/60),\"分钟后发送数据\") time.sleep(sleeptime) elif now_hour \u003e \"08\": rest = 8 - int(now_hour) + 24 sleeptime = (rest-1)*3600 + (60-int(now_min))*60 print(\"启动时北京时间为：\"+time.strftime(\"%H:%M\", time.localtime()),\"\\t 软件将在\",rest-1,\"小时\",int((sleeptime-(rest-1)*3600)/60),\"分钟后发送数据\") time.sleep(sleeptime) elif now_hour == \"08\": print(\"启动时北京时间为：\" + time.strftime(\"%H:%M\", time.localtime()), \"\\t 软件将在每天 8 点发送数据！\") # 以下为定时任务 print(\"数据\") time.sleep(86400-int(now_min)*60) ","date":"2019-05-09","objectID":"/posts/pysettime/:0:0","tags":["Python","Cron"],"title":"python 设置程序每天 8 点定时执行任务","uri":"/posts/pysettime/"},{"categories":["Python"],"content":" 用过命令pip install pyinstaller安装失败，此包依赖于 pywin32，安装前需要先pip install pywin32, 我安装了还是出错，稍微百度了一下也没有看到解决办法。 这里通过手动下载安装解决的，记录一下。 ","date":"2019-05-09","objectID":"/posts/pyinstallererror/:0:0","tags":["Python","pyinstaller"],"title":"安装 pyinstaller 出错的解决办法及 csdn 工具实例打包","uri":"/posts/pyinstallererror/"},{"categories":["Python"],"content":"下载 去官网下载 pyinstaller 安装包：https://pypi.org/project/PyInstaller/#files ","date":"2019-05-09","objectID":"/posts/pyinstallererror/:1:0","tags":["Python","pyinstaller"],"title":"安装 pyinstaller 出错的解决办法及 csdn 工具实例打包","uri":"/posts/pyinstallererror/"},{"categories":["Python"],"content":"解压 我这里解压到E:\\应用、Python37\\Lib\\site-packages\\PyInstaller-3.4 ","date":"2019-05-09","objectID":"/posts/pyinstallererror/:2:0","tags":["Python","pyinstaller"],"title":"安装 pyinstaller 出错的解决办法及 csdn 工具实例打包","uri":"/posts/pyinstallererror/"},{"categories":["Python"],"content":"安装 cmd 也进入到上面的路径下，然后执行Python setup.py install，等待安装完毕 ","date":"2019-05-09","objectID":"/posts/pyinstallererror/:3:0","tags":["Python","pyinstaller"],"title":"安装 pyinstaller 出错的解决办法及 csdn 工具实例打包","uri":"/posts/pyinstallererror/"},{"categories":["Python"],"content":"pyinstaller 简介 pyinstaller 将 Python 脚本打包成可执行程序，使在没有 Python 环境的机器上运行。 最新版是 pyinstaller 3.4，可运行在 Windows，Mac 和 Linux 操作系统下。 但它不是跨编译的，也就是说在 Windows 下用 PyInstaller 生成的 exe 只能运行在 Windows 下，在 Linux 下生成的只能运行在 Linux 下。 ","date":"2019-05-09","objectID":"/posts/pyinstallererror/:4:0","tags":["Python","pyinstaller"],"title":"安装 pyinstaller 出错的解决办法及 csdn 工具实例打包","uri":"/posts/pyinstallererror/"},{"categories":["Python"],"content":"打包 打包的 app 里并不包含任何源码，但将脚本的 .pyc 文件打包了。 基本语法： pyinstaller options myscript.py 常用的可选参数如下： --onefile 将结果打包成一个可执行文件 --onedir 将所有结果打包到一个文件夹中，该文件夹包括一个可执行文件和可执行文件执行时需要的依赖文件（默认） --paths=DIR 设置导入路径 --distpath=DIR 设置将打包的结果文件放置的路径 --specpath=DIR 设置将 spec 文件放置的路径 --windowed 使用 windows 子系统执行，不会打开命令行（只对 windows 有效） --nowindowed 使用控制台子系统执行（默认）（只对 windows 有效） --icon=\u003cFILE.ICO\u003e 将 file.ico 添加为可执行文件的资源（只对 windows 有效） 如pyinstaller --paths=\"D:\\\" test.py ","date":"2019-05-09","objectID":"/posts/pyinstallererror/:5:0","tags":["Python","pyinstaller"],"title":"安装 pyinstaller 出错的解决办法及 csdn 工具实例打包","uri":"/posts/pyinstallererror/"},{"categories":["Python"],"content":"CSDN 访问量脚本实例 比如，拿以前写的一个刷 csdn 访问量工具 csdn.py（放在桌面上），代码详见 在 cmd 进入桌面路径，输入如下命令 pyinstaller --onefile --nowindowed csdn.py ","date":"2019-05-09","objectID":"/posts/pyinstallererror/:6:0","tags":["Python","pyinstaller"],"title":"安装 pyinstaller 出错的解决办法及 csdn 工具实例打包","uri":"/posts/pyinstallererror/"},{"categories":["Java"],"content":" 实现一个简单的基于单线程的资源下载器，如图所示，用户可以任意指定下载资源的链接地址，系统根据该地址判断资源是否存在，如果存在，则将该资源下载到本地。 ","date":"2019-05-08","objectID":"/posts/singlethreaddown/:0:0","tags":["GUI","URLConnection","HTTP","Java"],"title":"java 实现一个单线程的资源下载器","uri":"/posts/singlethreaddown/"},{"categories":["Java"],"content":"GUI 设计基本流程 先记录一下 GUI 设计的基本流程： 根据需要从相应的顶层容器继承（如果创建窗体就继承 JFrame，对话框就继承 JDialog），新建一个子类。 然后设置顶层容器的属性，包括大小、位置、标题和关闭事件等。 设置界面上 GUI 组件的事件响应。 public void actionPerformed(ActionEvent e) {} 向顶层容器上添加 GUI 组件，并设置布局。（通常利用 JPanel 组件先作为微型容器） 创建新建子类的实例，调用 setVisible(true) 方法显示页面。（也可以直接在子类中设置 setVisible(true)） ","date":"2019-05-08","objectID":"/posts/singlethreaddown/:1:0","tags":["GUI","URLConnection","HTTP","Java"],"title":"java 实现一个单线程的资源下载器","uri":"/posts/singlethreaddown/"},{"categories":["Java"],"content":"实现代码 package cn.lruihao.base; import java.awt.FlowLayout; import java.awt.Font; import java.awt.HeadlessException; import java.awt.event.ActionEvent; import java.awt.event.ActionListener; import java.io.FileOutputStream; import java.io.InputStream; import java.net.URL; import java.net.URLConnection; import javax.swing.JButton; import javax.swing.JFrame; import javax.swing.JLabel; import javax.swing.JOptionPane; import javax.swing.JPanel; import javax.swing.JTextField; public class SingleThreadDown extends JFrame implements ActionListener { private final JPanel panel=new JPanel(); private final JLabel label1=new JLabel(\"网络资源的单线程下载：\"); private final JLabel label2=new JLabel(\"网络资源的网址：\"); JButton StartButton = new JButton(\"单击开始下载\"); JButton resetButton = new JButton(\"清空\"); JButton exitButton = new JButton(\"退出\"); JTextField urlField = new JTextField(20); public SingleThreadDown() { panel.setLayout(new FlowLayout()); //布局管理器 label1.setFont(new Font(\"雅黑\",Font.BOLD,15)); panel.add(label1); panel.add(label2); panel.add(urlField); panel.add(StartButton); panel.add(resetButton); panel.add(exitButton); setContentPane(panel); setSize(400,200); setLocation(400,400); setVisible(true); //面板可视化，也可以在 main 中通过 JFrame 子类对象调用方法设置 setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); //默认关闭事件 StartButton.addActionListener(this);//添加点击事件，传入 ActionListener 对象，由于子类继承了 ActionListener 接口，所以 this resetButton.addActionListener(this); exitButton.addActionListener(this); } public void download(String address) throws Exception { URL url = new URL(address); URLConnection urlcon = url.openConnection(); urlcon.connect(); InputStream in=urlcon.getInputStream();//获取的字节流对象 String filePath = url.getFile(); int pos=filePath.lastIndexOf(\"/\"); //\"/\"分割的最后一个串的下标 String fileName = filePath.substring(pos+1); FileOutputStream out = new FileOutputStream(\"C:\\\\Users\\\\李瑞豪、\\Desktop\\\\\"+fileName); byte[] b = new byte[1024]; int len=0; while((len=in.read(b,0,1024))!=-1) { out.write(b,0,len); } out.close(); in.close(); JOptionPane.showMessageDialog(this, \"下载完毕\"); } @Override public void actionPerformed(ActionEvent e) { if(e.getSource()==StartButton) { if(\"\".equals(urlField.getText())){ JOptionPane.showMessageDialog(this, \"请输入资源地址\"); } String url = urlField.getText(); try { download(url); } catch (Exception e1) { JOptionPane.showMessageDialog(this, \"资源地址有误，请检查~\"); e1.printStackTrace(); } }else if(e.getSource()==resetButton) { urlField.setText(\"\"); }else { System.exit(0); } } public static void main(String[] args) { new SingleThreadDown(); } } ","date":"2019-05-08","objectID":"/posts/singlethreaddown/:2:0","tags":["GUI","URLConnection","HTTP","Java"],"title":"java 实现一个单线程的资源下载器","uri":"/posts/singlethreaddown/"},{"categories":["Java"],"content":"运行结果测试 通过https://github.com/Lruihao/Grocery/raw/master/fonts/MMT_last.ttf下载沐目体 ttf 字体文件，稍微等待一下弹出对话框“下载完毕”，经检查下载内容正常。 ","date":"2019-05-08","objectID":"/posts/singlethreaddown/:3:0","tags":["GUI","URLConnection","HTTP","Java"],"title":"java 实现一个单线程的资源下载器","uri":"/posts/singlethreaddown/"},{"categories":["Python"],"content":" Json（JavaScript Object Notation）它是一种轻量级的数据交换格式，具有数据格式简单，读写方便易懂等很多优点。许多主流的编程语言都在用它来进行前后端的数据传输，大大的简化了服务器和客户端的开发工作量。相对于 XML 来说，更加的轻量级，更方便解析，因此许多开发者都遵循 Json 格式来进行数据的传输和交换。今天我们详细介绍一下 Python 在 Json 的编解码方面的知识。 ","date":"2019-05-07","objectID":"/posts/jsoninfo/:0:0","tags":["Python","JSON","他山之石"],"title":"Python 如何操作 Json？","uri":"/posts/jsoninfo/"},{"categories":["Python"],"content":"json 的数据格式 在 json 中，遵循“键值对”的这样一种方式，比如：“{“name”:“tom”}”, 就是一个 json 格式的数据，json 的格式归纳下来，一般有以下几点： 对象通过键值对表现； 键通过双引号包裹，后面跟冒号“:”，然后跟该键的值； 值可以是字符串、数字、数组等数据类型； 对象与对象之间用逗号隔开； “{}”用来表达对象； “[]”用来表达数组； 我们看一个略为复杂一点的例子： 上例则是一个典型的 json 格式的数据，强大的 Python 提供了一个“json”模块，可以方便的将各种零散的数据通过模块的内置函数编码形成一个 json 格式的数据，也可以将一个 json 格式的数据解码形成自己需要的数据，非常好用，下面我们就来介绍一下。 ","date":"2019-05-07","objectID":"/posts/jsoninfo/:1:0","tags":["Python","JSON","他山之石"],"title":"Python 如何操作 Json？","uri":"/posts/jsoninfo/"},{"categories":["Python"],"content":"json.dumps() json 模块里的 dumps 函数是对数据进行编码，形成 json 格式的数据，我们看一下下面的例子： 通过输出的结果很容易看出，通过 dumps 方法使字典转换成为了 json 格式，虽然它们非常相似。其中，在 dumps 里的参数“sort_keys=True”，使得输出 json 后对 key 和 value 进行 0~9、a~ z 的顺序排序，如果不填，则按照无序排列。有时候，通过排序可以方便地比较 json 中的数据，因此，适当的排序是很有必要的。 此外，“Indent”参数表示缩进的意思，它可以使得输出的 Json 看起来更加整齐好看，可读性更强，例如： 下面列举一下 dumps（）的可填参数： skipkey：默认为 False，当 dict 对象里的数据不是 Python 的基本数据类型；（str,unicode,int,long,float,bool,None）时，当 skipkey 为 False，就会报错，如果 skipkey 为 True，则可以跳过这类 key； indent：如果填 0 或者不填，则按照一行进行打印，否则按照 indent 的数值显示前面的空格（正整数形式）； separators：分隔符，默认为“(’,’,’:’)”，它表示 key 之间用“,”隔开，key 和 value 之间用“:”隔开； encoding：编码格式，默认值是 UTF-8； sort_keys：对 key、value 进行排序，默认值是 False，即不排序； ensure_ascii：默认为 True，如果 dict 对象里含有 none-ASCII 的字符，则显示、uXX 的格式，如果为 False，则能正常显示出来； ","date":"2019-05-07","objectID":"/posts/jsoninfo/:2:0","tags":["Python","JSON","他山之石"],"title":"Python 如何操作 Json？","uri":"/posts/jsoninfo/"},{"categories":["Python"],"content":"json.loads() 和 dumps 相反，loads 函数则是将 json 格式的数据解码，转换为 Python 字典，我们看一下下面的例子： 有时候，输出结果遇到中文的时候，会出现编码格式不一样的情况，显示出为 Unicode 的编码格式，使得不易读懂，解决办法是添加参数“encoding”参数，即上面的改写成这样：d1 = json.loads(data1,encoding=‘utf-8’) 即可。 ","date":"2019-05-07","objectID":"/posts/jsoninfo/:3:0","tags":["Python","JSON","他山之石"],"title":"Python 如何操作 Json？","uri":"/posts/jsoninfo/"},{"categories":["Python"],"content":"json.dump() 和 json.load() 相对于上面所讲的 dumps 和 loads 来说，dump 和 load 函数的功能类似，只不过前者是用来处理字符串类型的，而后者是用于处理文件类型的，如下所示： 上例列举出了 json 的四个方法：dumps（）和 dump（）、loads（）和 load（）的简单使用方法，可见，Python 对于 json 的处理相当方便，不像 c++那样（谁用谁知道）。 ","date":"2019-05-07","objectID":"/posts/jsoninfo/:4:0","tags":["Python","JSON","他山之石"],"title":"Python 如何操作 Json？","uri":"/posts/jsoninfo/"},{"categories":["Python"],"content":" 通过 requests 可以向某个地址发送请求，可以用来做一些接口的测试；主要有两个方法： requests.get() requests.post() 最近帮朋友的项目做一个小需求，需要把后台数据定期打包发送到微信群，麻小科技涛哥给了我一个接口，post 访问。 #!/usr/bin/python import requests \"\"\" 通过 requests 可以向某个地址发送请求 requests.post(url,json date) post 方法还有其他参数，如 header 等 \"\"\" # post 发送的数据 postData = { # 'username':'test', # 'password':'123456', # 'salary':2000, } # 接口这里不便公开 r = requests.post('http://demo.maxiaokeji.com/xx/xxxxx/xxxx',data=postData) # print(r.text) response=r.json() print(response) 运行后会在屏幕打印出返回的 json 数据 ","date":"2019-05-07","objectID":"/posts/posttest/:0:0","tags":["Python","HTTP"],"title":"python 发送 post 请求进行简单的接口测试","uri":"/posts/posttest/"},{"categories":["Java"],"content":" 该例中首先生成一个 URL 对象 lrh，指向 RUI 豪小栈，然后再调用 lrh.openStream() 方法生成该 URL 的一个输入流，这是一个字节流，在此基础上进一步通过 InputStreamReader 和 BufferedReader 构造一个带缓冲功能的字符流，并通过这个字符流对象读取该 URL 的 html 内容，进而输出到桌面文件和控制台屏幕。URLConnection 类也可以用来对由 URL 引用的资源进行读写操作，前提是先通过 connect() 方法建立连接，然后再去获取响应头信息或响应内容。 package cn.lruihao.base; import java.io.BufferedReader; import java.io.File; import java.io.FileWriter; import java.io.InputStreamReader; import java.net.URL; import java.net.URLConnection; public class URLReader { public static void main(String[] args) throws Exception{ try { URL lrh=new URL(\"https://www.lruihao.cn\"); File file=new File(\"C:\\\\Users\\\\李瑞豪、\\Desktop\\\\lrh.html\"); FileWriter fout=new FileWriter(file); BufferedReader in =new BufferedReader(new InputStreamReader(lrh.openStream()));//字节流转化成字符流，再构建缓冲字符流 String inputLine; while((inputLine=in.readLine())!=null) { System.out.println(inputLine); fout.write(inputLine); } in.close(); fout.close(); //获取响应 header 信息 URLConnection conn=lrh.openConnection(); conn.connect(); System.out.println(\"获取到的响应长度：\"+conn.getContentLength()); System.out.println(\"响应类型：\"+conn.getContentType()); //用 BufferedReader 读取 URL 的响应 in =new BufferedReader(new InputStreamReader(conn.getInputStream())); String line; String result=null; while((line=in.readLine())!=null) { result+=line; } System.out.println(result); } catch (Exception e) { e.printStackTrace(); } } } ","date":"2019-05-06","objectID":"/posts/java-urlreader/:0:0","tags":["URLConnection","Java"],"title":"java 通过 URL 和 URLConnection 访问网页资源","uri":"/posts/java-urlreader/"},{"categories":["Java"],"content":" 基本功能： 给定一个密钥，读取文件内容，加密后，输出到另外一个文件。 这里使用文件输入流读取文件内容，然后每个字节和密码进行异或简单加密。加密完成，使用文件输出流写入另一个文件中。解密和加密方法一样。利用的是对同一个数异或两遍其值不变的性质。因此一个程序可以完成加密和解密功能。只需修改文件名即可。 ","date":"2019-05-02","objectID":"/posts/byteio/:0:0","tags":["Java"],"title":"文件加密解密（字节流）","uri":"/posts/byteio/"},{"categories":["Java"],"content":"文件加密解密 package cn.lruihao.base; import java.io.FileInputStream; import java.io.FileOutputStream; import java.io.IOException; public class EncryptFile { public static void main(String[] args) throws IOException { byte pwd=123;//加密/解密密码 FileInputStream f=new FileInputStream(\"src/cn/lruihao/base/EncryptFile.java\");//待加密文件 FileOutputStream fout=new FileOutputStream(\"encrypted.txt\");//已加密文件 System.out.println(\"开始加密。\"); int n=f.available()/5; byte[] b=new byte[n];//以一个字节数组的长度读取和复制 int count=0; while((count=f.read(b,0,n))!=-1) { //写入之前先加密/解密 for(int i=0;i\u003ccount;i++) { b[i]=(byte)(b[i]^pwd);// } fout.write(b,0,count); } System.out.println(\"完成加密\"); f.close(); fout.close(); // f=new FileInputStream(\"encrypted.txt\"); // fout=new FileOutputStream(\"unencrypted.txt\"); // System.out.println(\"开始解密。\"); // n=f.available()/5; // b=new byte[n];//以一个字节数组的长度读取和复制 // count=0; // while((count=f.read(b,0,n))!=-1) { // //写入之前先加密/解密 // for(int i=0;i\u003ccount;i++) { // b[i]=(byte)(b[i]^pwd); // } // fout.write(b,0,count); // } // System.out.println(\"完成解密\"); // f.close(); // fout.close(); } } ","date":"2019-05-02","objectID":"/posts/byteio/:1:0","tags":["Java"],"title":"文件加密解密（字节流）","uri":"/posts/byteio/"},{"categories":["Java"],"content":"文件复制 package cn.lruihao.base; import java.io.FileInputStream; import java.io.FileOutputStream; import java.io.IOException; public class FileStreamCopy { public static void main(String[] args) throws IOException { int size; FileInputStream f=new FileInputStream(\"src/cn/lruihao/base/FileStreamCopy.java\"); FileOutputStream fout=new FileOutputStream(\"copy-of-file.txt\"); System.out.println(\"总长度：\"+(size=f.available())); int n=size/10; System.out.print(\"使用单字节方法读取后：\"); for(int i=0;i\u003cn;i++) { fout.write(f.read()); } System.out.println(\"剩余长度：\"+f.available()); System.out.println(\"读取一个字节数组后：\"); byte b[]=new byte[n]; f.read(b); fout.write(b); System.out.println(\"剩余长度：\"+f.available()); System.out.println(\"读取余下数据：\"); int count=0; while((count=f.read(b,0,n))!=-1) { //System.out.println(count); fout.write(b,0,count); } System.out.println(\"剩余长度：\"+f.available()); f.close(); fout.flush(); fout.close(); } } package cn.lruihao.base; import java.io.BufferedInputStream; import java.io.BufferedOutputStream; import java.io.FileInputStream; import java.io.FileOutputStream; import java.io.IOException; public class BufferedStreamCopy { public static void main(String[] args) throws IOException { FileInputStream f=new FileInputStream(\"src/cn/lruihao/base/BufferedStreamCopy.java\"); FileOutputStream fout=new FileOutputStream(\"copy-of-file.txt\"); BufferedInputStream bis=new BufferedInputStream(f); BufferedOutputStream bos=new BufferedOutputStream(fout); System.out.println(\"开始复制。\"); int n=f.available()/5; byte[] b=new byte[n]; int count=0; while((count=bis.read(b,0,n))!=-1) { bos.write(b,0,count); } System.out.println(\"复制完成\"); bis.close(); bos.flush(); bos.close(); f.close(); fout.flush(); fout.close(); } } ","date":"2019-05-02","objectID":"/posts/byteio/:2:0","tags":["Java"],"title":"文件加密解密（字节流）","uri":"/posts/byteio/"},{"categories":["Java"],"content":"实现代码 这里的异常主要是InputMismatchException, 可以直接捕获该异常，我直接捕获了父类异常。 package cn.lruihao.Exception; import java.util.Scanner; /** * @author 李瑞豪 * 借书系统（异常练习） */ public class ExceptionDemo { private final Book[] books = { new Book(\"数据结构\"), new Book(\"Java\"), new Book(\"php\"), new Book(\"c\") }; public static void main(String[] args) { System.out.println(\"欢迎来到借书系统！\"); ExceptionDemo jieshu= new ExceptionDemo(); jieshu.menu(); } public void menu() { System.out.println(\"输入命令：1. 书名查找；\\t2. 序号查找；\"); //初始化并捕获用户输入 Scanner sc = new Scanner(System.in); // 捕获异常 try { int id =sc.nextInt(); if(id==1||id==2) { inquire(id); }else { System.out.println(\"输入错误！请根据提示输入~~\");//输入非 1，2 的数字情况 menu(); } }catch (Exception e) {//输入字符为非数字 e.printStackTrace(); System.out.println(\"输入错误，请输入数字命令~~\"); menu(); }finally{ sc.close(); } } private void inquire(int id) { Scanner sc = new Scanner(System.in); if(id==1) { System.out.println(\"请输入要查找的书名！\"); String name=sc.nextLine(); int num=FindName(name); if(num==0?false:true) {//验证书名是否存在 存在则打印 System.out.println(\"book：\"+name+\"\\t 序号：\"+num); //menu();//回到访问起点 也可以去掉终止程序 }else{ System.out.println(\"图书不存在\"); menu(); } sc.close(); }else if(id == 2) { System.out.println(\"请输入您要查找的序号：\"); int id2=sc.nextInt(); FindNum(id2); sc.close(); } } private void FindNum(int num) { try { if(num\u003e=0\u0026\u0026num\u003cbooks.length) { System.out.println(books[num].getName()); //menu();//回到访问起点 也可以去掉终止程序 }else{ System.out.println(\"图书不存在\"); menu(); } }catch (Exception e) { e.printStackTrace(); System.out.println(\"输入有误！~~\"); } } private int FindName(String name) { int num=0; for(Book i:books) { String name1=i.getName(); if(name1.equals(name)) { return num; } num++; } return 0; } } package cn.lruihao.Exception; public class Book { private String name; public String getName() { return name; } public void setName(String name) { this.name = name; } public Book(String name) { this.name = name; } } ","date":"2019-05-01","objectID":"/posts/javaexception/:1:0","tags":["Java"],"title":"模拟借书系统（java 异常练习）","uri":"/posts/javaexception/"},{"categories":["Java"],"content":"大致运行效果 ","date":"2019-05-01","objectID":"/posts/javaexception/:2:0","tags":["Java"],"title":"模拟借书系统（java 异常练习）","uri":"/posts/javaexception/"},{"categories":["瞎折腾","Python"],"content":" Python 二维码生成器是 github 上@sylnsfar 开源的一个 python 生成二维码工具。有 python, 网页及 exe 版本，详见 sylnsfar/qrcode，本文主要介绍记录一下 python 版本使用。exe 可以去 项目开源地址 下载，公众号文章后台回复关键词“qrcode”获取链接。 可生成普通二维码、带图片的艺术二维码（黑白与彩色）、动态二维码（黑白与彩色）。 ","date":"2019-04-27","objectID":"/posts/qrcode/:0:0","tags":["pillow","numpy","imageio","Python"],"title":"用 MyQR 制作专属动态二维码 (py 和 exe 版本）","uri":"/posts/qrcode/"},{"categories":["瞎折腾","Python"],"content":"示例 from MyQR import myqr import os version, level, qr_name = myqr.run( words='https://lruihao.cn', version=1, level='H', picture='2.jpg', colorized=True, contrast=1.0, brightness=1.0, save_name=None, save_dir=os.getcwd() ) # help(myqr) # https://github.com/sylnsfar/qrcode/ ''' Positional parameter words: str # 链接或者文字 Optional parameters version: int, from 1 to 40 # 控制边长 level: str, just one of ('L','M','Q','H') # 控制纠错水平，从左到右依次升高。 picutre: str, a filename of a image # 图片，需在同路径，默认 None colorized: bool # 是否彩色 默认 False constrast: float # 对比度 默认 1.0 brightness: float # 亮度 默认 1.0 save_name: str, the output filename like 'example.png' #控制文件名，默认 None,'qrcode.png' save_dir: str, the output directory # 储存路径 ''' ","date":"2019-04-27","objectID":"/posts/qrcode/:1:0","tags":["pillow","numpy","imageio","Python"],"title":"用 MyQR 制作专属动态二维码 (py 和 exe 版本）","uri":"/posts/qrcode/"},{"categories":["瞎折腾","Python"],"content":"安装 # 通过 pip pip(3) install myqr(or MyQR) ","date":"2019-04-27","objectID":"/posts/qrcode/:2:0","tags":["pillow","numpy","imageio","Python"],"title":"用 MyQR 制作专属动态二维码 (py 和 exe 版本）","uri":"/posts/qrcode/"},{"categories":["瞎折腾","Python"],"content":"使用方法 ","date":"2019-04-27","objectID":"/posts/qrcode/:3:0","tags":["pillow","numpy","imageio","Python"],"title":"用 MyQR 制作专属动态二维码 (py 和 exe 版本）","uri":"/posts/qrcode/"},{"categories":["瞎折腾","Python"],"content":"命令行方式 （提示：如果你尚未安装 MyQR ，以下内容请使用python(3) myqr.py 而非myqr 。） # 概括 myqr Words [-v {1,2,3,...,40}] [-l {L,M,Q,H}] [-n output-filename] [-d output-directory] [-p picture_file] [-c] [-con contrast] [-bri brightness] 普通二维码 介绍了 Words, -v, -l, -n, -d 艺术二维码 介绍了 -p, -c, -con, -bri 动态 GIF 二维码 介绍了动态的生成方法和注意点 普通二维码 #1 Words myqr https://github.com 在命令后输入链接或者句子作为参数，然后在程序的当前目录中产生相应的二维码图片文件，默认命名为 “qrcode.png”。 #2 -v, -l myqr https://github.com -v 10 -l Q 默认边长是取决于你输入的信息的长度和使用的纠错等级； 而默认纠错等级是最高级的 H。 自定义：如果想要控制边长和纠错水平就使用 -v 和 -l 参数。 -v 控制边长，范围是** 1 至 40**，数字越大边长越大； -l 控制纠错水平，范围是** L、M、Q、H**，从左到右依次升高。 #3 -n, -d myqr https://github.com -n github_qr.jpg -d .../paths/ 默认输出文件名是“ qrcode.png “，而默认存储位置是当前目录。 自定义：可以自己定义输出名称和位置。注意同名文件会覆盖旧的。 -n 控制文件名，格式可以是 .jpg， .png ，.bmp ，.gif ； -d 控制位置。 艺术二维码 #1 -p myqr https://github.com -p github.jpg 参数-p 用来将 QR 二维码图像与一张同目录下的图片相结合，产生一张黑白图片。 #2 -c myqr https://github.com -p github.jpg -c 加上参数 -c 可以使产生的图片由黑白变为彩色的。 #3 -con, -bri myqr https://github.com -p github.jpg [-c] -con 1.5 -bri 1.6 参数-con 用以调节图片的对比度，1.0 表示原始图片，更小的值表示更低对比度，更大反之。默认为 1.0。 参数 -bri 用来调节图片的亮度，其余用法和取值与 -con 相同。 动态 GIF 二维码 动态二维码与上述的带图片的二维码的生成方法没什么区别，你只要采用 .gif 格式的图片即可生成黑白或者彩色的动态二维码。但注意如果使用了 -n 参数自定义输出的文件名，切记其格式也必须是 .gif 格式。 ","date":"2019-04-27","objectID":"/posts/qrcode/:3:1","tags":["pillow","numpy","imageio","Python"],"title":"用 MyQR 制作专属动态二维码 (py 和 exe 版本）","uri":"/posts/qrcode/"},{"categories":["瞎折腾","Python"],"content":"作为导入文件 # 安装模块后 from MyQR import myqr version, level, qr_name = myqr.run( words, version=1, level='H', picture=None, colorized=False, contrast=1.0, brightness=1.0, save_name=None, save_dir=os.getcwd() ) 以下各个参数已经在上文命令行方式有所介绍 # help(myqr) Positional parameter words: str Optional parameters version: int, from 1 to 40 level: str, just one of ('L','M','Q','H') picutre: str, a filename of a image colorized: bool constrast: float brightness: float save_name: str, the output filename like 'example.png' save_dir: str, the output directory ","date":"2019-04-27","objectID":"/posts/qrcode/:3:2","tags":["pillow","numpy","imageio","Python"],"title":"用 MyQR 制作专属动态二维码 (py 和 exe 版本）","uri":"/posts/qrcode/"},{"categories":["瞎折腾","Python"],"content":"使用提示 请采用正方形或近似正方形的图片 建议在图片尺寸大的时候使用 -v 的值也应该适当变大。 ","date":"2019-04-27","objectID":"/posts/qrcode/:4:0","tags":["pillow","numpy","imageio","Python"],"title":"用 MyQR 制作专属动态二维码 (py 和 exe 版本）","uri":"/posts/qrcode/"},{"categories":["瞎折腾","Python"],"content":"可用字符 数字 0 到 9 大小写的英文字母 常用英文标点符号和空格 · , . : ; + - * / \\ ~ ! @ # $ % ^ \u0026 ` ' = \u003c \u003e [ ] ( ) ? _ { } | and (space) ","date":"2019-04-27","objectID":"/posts/qrcode/:5:0","tags":["pillow","numpy","imageio","Python"],"title":"用 MyQR 制作专属动态二维码 (py 和 exe 版本）","uri":"/posts/qrcode/"},{"categories":["瞎折腾","Python"],"content":"依赖库 pillow numpy imageio ","date":"2019-04-27","objectID":"/posts/qrcode/:6:0","tags":["pillow","numpy","imageio","Python"],"title":"用 MyQR 制作专属动态二维码 (py 和 exe 版本）","uri":"/posts/qrcode/"},{"categories":["瞎折腾","Python"],"content":"运行环境 Linux, Python 3 Windows, Python 3 Mac, Python 3 ","date":"2019-04-27","objectID":"/posts/qrcode/:7:0","tags":["pillow","numpy","imageio","Python"],"title":"用 MyQR 制作专属动态二维码 (py 和 exe 版本）","uri":"/posts/qrcode/"},{"categories":["随笔"],"content":" 时间过得真快，一下从大一到了大三，马上就要实习毕业等等了。 Success 富士康在学校有一个春招的机会，我和朋友抱着侥幸的心理去试了试。 虽然深知自己还身有很多缺点，但是不面试不知道，一面试都暴露出来了，以下记录一下自己的不足之处： php 和 sql 的经典组合虽然有所接触了解，但是确实什么都会，得花时间学 html/css 等虽然平时折腾博客这些应用的比较多，但是今天竟然紧张地忘记了 margin 和 padding 都不会写了 如上一条，公众表现能力有待加强。正如当今“酒香也怕巷子深”，何况“不香”。 惊喜的事说来就来，本来知道自己这么多缺点，这么菜后，觉得这个实习的 offer 是没戏了，没想到下午技术主管微信发来消息，说录用了。当场懵逼，受宠若惊的感觉！非常谢谢面试官老师！ 无论生活还是学习，希望以后的自己一定要保持一颗谦逊爱学的心，早日实现全栈工程师的梦想，还有早点存钱把大学学费的贷款还掉！ ","date":"2019-04-24","objectID":"/posts/1thintervivew/:0:0","tags":["面试"],"title":"第一次面试经历","uri":"/posts/1thintervivew/"},{"categories":["瞎折腾","Python"],"content":" 以下程序对 该网址 内的手写体图片进行爬取！这个手写体是我在手机上通过《手迹造字》app 书写的，大概 6886 个字符，历时两年多，目前仍在修改中。字体效果查看 ","date":"2019-04-22","objectID":"/posts/mmtimgpy/:0:0","tags":["Python"],"title":"python 爬取网站图片（图片链接相似）","uri":"/posts/mmtimgpy/"},{"categories":["瞎折腾","Python"],"content":"思路设计 通过观察目标网页中字符图片的链接，很容易发现每个字符图片的直链是由两部分组成。 固定链接 图片文件编号 其中固定连接为https://image.xiezixiansheng.com/users/2010/700/unzip/579767/, 图片文件为xxxxx.png@50q，如果去掉@50q，获取到的图片就是透明背景的不然就是白色背景。然后发现编号大多是 5 位数的形式，但是还有一些是 4 位的，甚至还有 2-3 位的数字。仔细看看 127 前的编号都是一些国际符号诸如英文和数字等。比对一下发现正是 ASCII 码对应的命名方式。可想而知中文自然也是通过编码来命名的。一个标准的字库文件至少包含 6763 个汉字，也就是我书写的这个GB2312-80, 范围： 0xA1A1 - 0xFEFE，其中汉字范围： 0xB0A1 - 0xF7FE。两个 16 进制位对应一个字节，一个汉字至少由两个字节组成，这样理解，范围自然是 4 个 16 进制位。所以转换成 10 进制，范围大致在 65278 以下。要了解更加具体一点的范围还需要去查一下汉字编码的分区等。这里暂时不必了解，因为本来就打算暴力下载。 说了这么多，既然图片链接这么简单，所以我是想暴力遍历，搜索图片，判断链接状态码，然后下载图片。 ","date":"2019-04-22","objectID":"/posts/mmtimgpy/:1:0","tags":["Python"],"title":"python 爬取网站图片（图片链接相似）","uri":"/posts/mmtimgpy/"},{"categories":["瞎折腾","Python"],"content":"源码设计 大致分为三个范围吧 英文字符 中文符号 汉字范围 我主要分这几个区间查找 33 ~ 126 8212 ~ 8243 12289 ~ 12305 19968 ~ 40864 65281 ~ 65509 磨刀不误砍柴工，分析观察了这么久，终于可以运行程序了，F5 后就静静等待吧，可以去看看 java，或者打一把王者 hhhhh! import os import requests path=\"C:\\\\Users\\\\李瑞豪、\\Desktop\\\\MMT_images\\\\\" #下载路径： 绝对或者相对路径比如。/image/ os.makedirs(path+\"0\\\\\", exist_ok=True) ## 创建文件夹 os.makedirs(path+\"1\\\\\", exist_ok=True) ## 下载图片 def urllib_download(url,num): ## （下载链接，图片编号） from urllib.request import urlretrieve urlretrieve(url,path+num+\".png\") ## 判断状态码 def get_status(url): r = requests.get(url, allow_redirects = False) return r.status_code def main(): BASE_URL = \"https://image.xiezixiansheng.com/users/2010/700/unzip/579767/\" n=33 total=0 print(\"正在爬取第 1 张图片！\") while n \u003c 65510: #分段爬取，不然会超时！！！## 33 ~ 126 ## 8212 ~ 8243 ## 12289 ~ 12305 ## 19968 ~ 40864 ## 65281 ~ 65509 if n == 127: n = 8212 continue elif n == 8244: n = 12289 continue elif n ==12306: n = 19968 continue elif n == 40865: n = 65281 continue ## for n in range(37341,40865): num = str(n) IMAGE_URL = BASE_URL+num+\".png\" ## xxx.png 是透明背景，xxx.png@50q 是白色背景，分别存放在 0，1 文件夹 p 是中小 w 是小图 if(get_status(IMAGE_URL)==200): ## 同时下载透明和白色背景的图片 total+=1 urllib_download(IMAGE_URL,\"0\\\\\"+num) IMAGE_URL += \"@50q\" urllib_download(IMAGE_URL,\"1\\\\\"+num) print(\"Downloaded \"+num+\".png\") print(\"正在爬取第\",total+1,\"张图片！\") n+=1 print(\"\\n 爬取完毕！共爬取\",total,\"张图片！\") print(\"图片存放路径：\"+path) print(\"作者博客：lruihao.cn\") if __name__==\"__main__\": main(); ","date":"2019-04-22","objectID":"/posts/mmtimgpy/:2:0","tags":["Python"],"title":"python 爬取网站图片（图片链接相似）","uri":"/posts/mmtimgpy/"},{"categories":["瞎折腾","Python"],"content":"爬取过程及结果 文件夹左下角数目变化 爬取过程 危险 说实话看着控制台不停地输出提示信息有没有很爽，对于强迫症来说真的是很治愈了！但是爬取第 6042 张图片的时候，我打开了一下目标网页发现无法加载图片了，就想这应该也算是一次 Dos 攻击了吧！打开控制台果然停了，相当于访问了近两万次！唉，还是太暴力了！！还差 800 多张，只好又重新接着写上次的位置爬！不慎造成目标网站服务器压力，实在对不起！ 错误提示 一个半小时左右后终于下载完了，一共是 6886 张；程序是同时下载了透明和白色背景的图片的！分别在 0,1 子文件夹！ 爬取完毕 ","date":"2019-04-22","objectID":"/posts/mmtimgpy/:3:0","tags":["Python"],"title":"python 爬取网站图片（图片链接相似）","uri":"/posts/mmtimgpy/"},{"categories":["瞎折腾","Python"],"content":"其他思路 模拟浏览器载入 html 文件，获取源码，查找到所有\u003cimg\u003e标签内链接，必要时配合正则表达式，然后下载图片。 ","date":"2019-04-22","objectID":"/posts/mmtimgpy/:4:0","tags":["Python"],"title":"python 爬取网站图片（图片链接相似）","uri":"/posts/mmtimgpy/"},{"categories":["瞎折腾","Python"],"content":" 文中涉及的图片涉及个人隐私，仅做举例，请勿传播 查看微信好友男女比例 查看好友地区分布 群性别统计 ","date":"2019-04-20","objectID":"/posts/wxpy1/:0:0","tags":["Python","wxpy","pyecharts","jieba","他山之石"],"title":"python 玩微信：初探 wxpy","uri":"/posts/wxpy1/"},{"categories":["瞎折腾","Python"],"content":"前期准备 wxpy pyecharts（百度 echarts） ","date":"2019-04-20","objectID":"/posts/wxpy1/:1:0","tags":["Python","wxpy","pyecharts","jieba","他山之石"],"title":"python 玩微信：初探 wxpy","uri":"/posts/wxpy1/"},{"categories":["瞎折腾","Python"],"content":"查看微信好友男女比例 from wxpy import * from pyecharts import Pie bot = Bot(cache_path = True) #定义一个微信机器人 friends = bot.friends(update=False) #获取更新好友列表 male = female = other = 0 for i in friends[1:]: #[1:] 自己是第一个，排除掉 sex = i.sex if sex == 1: male += 1 elif sex == 2: female += 1 else: other += 1 total = len(friends[1:]) #计算总数 #下面为分析 attr = [\"男性\",\"女性\",\"其他\"] v1 = [float(male),float(female),float(other)] pie = Pie(\"饼图-圆环图示例\", title_pos='center') pie.add(\"\", attr, v1, radius=[40, 75], label_text_color=None, is_label_show=True, legend_orient='vertical', legend_pos='left') pie.render(\"sex.html\") ","date":"2019-04-20","objectID":"/posts/wxpy1/:2:0","tags":["Python","wxpy","pyecharts","jieba","他山之石"],"title":"python 玩微信：初探 wxpy","uri":"/posts/wxpy1/"},{"categories":["瞎折腾","Python"],"content":"查看好友地区分布 from wxpy import * from pyecharts import Map #因为获取的列表城市都没有带市字，而 pyecharts 需要带个市字 b = '市' def s(x): return x+b #只提取湖南的 bot = Bot(cache_path = True) friends = bot.friends(update=False).search(province = '湖南') citys = [] for f in friends : city = f.city citys.append(city) r = map(s,citys) cityss = list(r) #为城市计数 a = {} for i in cityss: a[i] = cityss.count(i) a.pop('市') #把字典进行有序拆分为 2 个列表 attrs = [] values = [] for value, attr in a.items(): values.append(attr) attrs.append(value) #开始绘图 map = Map(\"湖南地图示例\", width=1200, height=600) map.add(\"\", attrs, values, maptype='湖南', is_visualmap=True, visual_text_color='#000') map.render(\"city.html\") 以上参考简书 陈思煜 ","date":"2019-04-20","objectID":"/posts/wxpy1/:3:0","tags":["Python","wxpy","pyecharts","jieba","他山之石"],"title":"python 玩微信：初探 wxpy","uri":"/posts/wxpy1/"},{"categories":["瞎折腾","Python"],"content":"统计所有群男女数目 统计结果会自动发送到所有群聊 男女人数和不一定等于总数（有些人不显示性别） #encoding=utf-8 from wxpy import * import numpy def removeAll(the_list, val): return [value for value in the_list if value != val] def stats_text(target_group, group_name): print(group_name + \"群共有：\" + str(len(target_group)) + \"人，其中：\") all_stats_text = [] all_dict = {} ## 乱序先整理一份省份 + 地点的列表 for user in target_group.members: trimed_data = user.province.replace(' ', '') + user.city.replace(' ', '') if trimed_data != '': all_stats_text.append(trimed_data) ## 计数 for data in all_stats_text: if all_stats_text.count(data) != 0: all_dict[data] = all_stats_text.count(data) all_stats_text = removeAll(all_stats_text, data) final_dict = {} for i in sorted(all_dict.keys()): final_dict[i] = all_dict[i] return final_dict def stats_sex(target_group): male = 0 female = 0 other = 0 for user in target_group.members: if user.sex == 1: male = male + 1 if user.sex == 2: female = female + 1 else: other = other + 1 print(\"男的有：\" + str(male) + \"人\") print(\"女的有：\" + str(female) + \"人\") msg = \"男的有：\" + str(male) + \"人、n\" + \"女的有：\" + str(female) + \"人、n\" return msg bot = Bot() target_group = bot.groups(update=True, contact_only=False) for curr_group in target_group: ## 小于 10 人的群过滤掉 if len(curr_group) \u003c 10: continue curr_group.update_group(members_details=True) print(curr_group.name + \"一共有：\" + str(len(curr_group)) + \"人、n\") msg = stats_sex(curr_group) curr_group.send(curr_group.name + \"群，一共有：\" + str(len(curr_group)) + \"人、n\" + msg) ","date":"2019-04-20","objectID":"/posts/wxpy1/:4:0","tags":["Python","wxpy","pyecharts","jieba","他山之石"],"title":"python 玩微信：初探 wxpy","uri":"/posts/wxpy1/"},{"categories":["瞎折腾","Python"],"content":" Python 通过 wxpy 登录微信网页版，爬取好友所有头像并拼接成一张大图。然后删除所有子图。（注释相关代码可以不删除） 文中涉及的图片涉及个人隐私，仅做举例，请勿传播 文中编码由 Sunbelife 提供，来自他的同名微信公众号，本博仅用于学习，侵删 ","date":"2019-04-20","objectID":"/posts/wximgpy/:0:0","tags":["wxpy","pillow","Python"],"title":"基本 python 实现的爬取微信好友头像，并拼接成大图","uri":"/posts/wximgpy/"},{"categories":["瞎折腾","Python"],"content":"依赖 wxpy（Pythone 登录微信） pillow（拼接头像） os（文件夹操作） math（数学计算） wxpy: wxpy 在 itchat 的基础上，通过大量接口优化提升了模块的易用性，并进行丰富的功能扩展。 PIL： Python Imaging Library，已经是 Python 平台事实上的图像处理标准库了。PIL 功能非常强大，但 API 却非常简单易用。由于 PIL 仅支持到 Python 2.7，加上年久失修，于是一群志愿者在 PIL 的基础上创建了兼容的版本，名字叫 Pillow，支持最新 Python 3.x，又加入了许多新特性，因此，我们可以直接安装使用 Pillow。 ","date":"2019-04-20","objectID":"/posts/wximgpy/:1:0","tags":["wxpy","pillow","Python"],"title":"基本 python 实现的爬取微信好友头像，并拼接成大图","uri":"/posts/wximgpy/"},{"categories":["瞎折腾","Python"],"content":"安装 pip install -U wxpy -i \"https://pypi.doubanio.com/simple/\" pip install pillow ","date":"2019-04-20","objectID":"/posts/wximgpy/:2:0","tags":["wxpy","pillow","Python"],"title":"基本 python 实现的爬取微信好友头像，并拼接成大图","uri":"/posts/wximgpy/"},{"categories":["瞎折腾","Python"],"content":"运行 如果在 Python IDE 运行出错，可能是因为微信好友的 id 是特殊字符，在 IDE 打印出错，注释掉代码 36 行即可。 from wxpy import * import math import PIL.Image as Image import os import sys import shutil # ### 获取文件所在的绝对路径 def get_dir(sys_arg): sys_arg = sys_arg.split(\"/\") dir_str = \"\" count = 0 for cur_dir in sys_arg: if count == 0: count = count + 1 if count == len(sys_arg): break dir_str = dir_str + cur_dir + \"/\" count = count + 1 return dir_str curr_dir = get_dir(sys.argv[0]) bot = Bot() ## 机器人账号自身 myself = bot.self my_friends = bot.friends(update=True) if not os.path.exists(curr_dir + \"group-images/\"): os.mkdir(curr_dir + \"group-images/\") count = 0 for friend in my_friends: print(friend.nick_name) friend.get_avatar(curr_dir + \"group-images/\" + str(count) + \".jpg\") count = count + 1 ## 获取下载的头像文件 ls = os.listdir(curr_dir + 'group-images') ## 去除非 .jpg 文件 for filter_ls in ls: if \".jpg\" in filter_ls: continue else: ls.remove(filter_ls) ## 排序 ls.sort(key=lambda x:int(x[:-4])) ## 头像墙尺寸 image_size = 2560 each_size = math.floor(image_size/math.floor(math.sqrt(len(ls)))) x_lines = math.ceil(math.sqrt(len(ls))) y_lines = math.ceil(math.sqrt(len(ls))) image = Image.new('RGB', (each_size * x_lines, each_size * y_lines)) x = 0 y = 0 for file_names in ls: try: img = Image.open(curr_dir + \"group-images/\" + file_names) print(\"正在处理\" + file_names.split('.jpg')[0] + \"/\" + str(len(ls))) except IOError: continue else: img = img.resize((each_size, each_size)) image.paste(img, (x * each_size, y * each_size)) x += 1 if x == x_lines: x = 0 y += 1 img = image.save(curr_dir + \"all.jpg\") try: shutil.rmtree(curr_dir + \"group-images/\") print(\"收尾，清理临时文件\") except FileNotFoundError: print(\"没什么好删的\") print(\"！！！\\n 生成完毕了，放在了目录\" + curr_dir + \"，去看看吧。\") print(\"工具作者：@Sunbelife（新浪微博）\") print(\"公众号：Sunbelife\") print(\"感谢使用\") print(\"v1.2\") print(\"2019.4.18\") ","date":"2019-04-20","objectID":"/posts/wximgpy/:3:0","tags":["wxpy","pillow","Python"],"title":"基本 python 实现的爬取微信好友头像，并拼接成大图","uri":"/posts/wximgpy/"},{"categories":["瞎折腾","Python"],"content":"群友全家福 修改 11 行群名称 import itchat import math import PIL.Image as Image import os import shutil ## 变量 itchat.auto_login(hotReload=True,enableCmdQR=False) roomslist = itchat.get_chatrooms(update=True)[0:] itchat.dump_login_status() ## 显示所有的群聊信息，默认是返回保存到通讯录中的群聊 myroom=itchat.search_chatrooms(name=u'绥宁一中高 396 班') #群聊名称 gsq=itchat.update_chatroom(myroom[0]['UserName'], detailedMember=True) num = 0 if not os.path.exists(\"./group-images/\"): os.mkdir(\"./group-images/\") for i in gsq['MemberList']: print(i[\"UserName\"]) img = itchat.get_head_img(userName=i[\"UserName\"],chatroomUserName=myroom[0]['UserName']) fileImage = open(\"./group-images/\" + str(num) + \".jpg\",'wb') fileImage.write(img) fileImage.close() num += 1 ls = os.listdir('./group-images') each_size = int(math.sqrt(float(640*640)/len(ls))) lines = int(640/each_size) image = Image.new('RGBA', (640, 640)) x = 0 y = 0 for i in range(0,len(ls)+1): try: img = Image.open(\"./group-images/\" + str(i) + \".jpg\") except IOError: print(\"Error\") else: img = img.resize((each_size, each_size), Image.ANTIALIAS) image.paste(img, (x * each_size, y * each_size)) x += 1 if x == lines: x = 0 y += 1 image.save(\"all.png\") shutil.rmtree(\"./group-images\") 绥宁一中高 396 班 加个列表，加个循环实现自动爬取所有群聊头像并发送 import itchat import math import PIL.Image as Image import os import shutil ## 变量 itchat.auto_login(hotReload=True,enableCmdQR=False) roomslist = itchat.get_chatrooms(update=True)[0:] itchat.dump_login_status() ## 显示所有的群聊信息，默认是返回保存到通讯录中的群聊 for room in roomslist: print(room['UserName']) gsq=itchat.update_chatroom(room['UserName'], detailedMember=True) num = 0 if not os.path.exists(\"./group-images/\"): os.mkdir(\"./group-images/\") for i in gsq['MemberList']: print(i[\"UserName\"]) img = itchat.get_head_img(userName=i[\"UserName\"],chatroomUserName=room['UserName']) fileImage = open(\"./group-images/\" + str(num) + \".jpg\",'wb') fileImage.write(img) fileImage.close() num += 1 ls = os.listdir('./group-images') each_size = int(math.sqrt(float(640*640)/len(ls))) lines = int(640/each_size) image = Image.new('RGB', (640, 640)) x = 0 y = 0 for i in range(0,len(ls)+1): try: img = Image.open(\"./group-images/\" + str(i) + \".jpg\") except IOError: print(\"Error\") else: img = img.resize((each_size, each_size), Image.ANTIALIAS) image.paste(img, (x * each_size, y * each_size)) x += 1 if x == lines: x = 0 y += 1 image.save(\"all.jpg\") itchat.send(\"写了个好玩的… 测试一下\", room['UserName']) itchat.send_image(\"all.jpg\", room['UserName']) shutil.rmtree(\"./group-images\") ","date":"2019-04-20","objectID":"/posts/wximgpy/:4:0","tags":["wxpy","pillow","Python"],"title":"基本 python 实现的爬取微信好友头像，并拼接成大图","uri":"/posts/wximgpy/"},{"categories":["Java"],"content":" 之所以用记事本来写不是为了装 X 或者什么的。反而恰恰是返璞归真，因为在用 java 语言进行程序开发时，首先是以纯文本的方式编写所有的 java 源程序，并保存成以.java为后缀的文件；然后将这些源程序用javac编译成.class后缀名的字节代码文件；字节代码不是被本地处理器执行的代码，而是能够被 java 虚拟机（JVM）执行的代码。最后用 java 运行工具在 JVM 执行 java 应用程序。 由于 JVM 可以运行在不同的操作系统上，因此同一个字节代码文件可以跨平台运行。 javac java ","date":"2019-04-19","objectID":"/posts/hellojava/:0:0","tags":["Java"],"title":"用记事本编写第一个 java 程序","uri":"/posts/hellojava/"},{"categories":["Java"],"content":"编写 java 用记事本编辑 java 文件，并且把后缀改成.java，文件名和类名要一样。 public class HelloWorld{ public static void main(String[] args){ System.out.println(\"Hello World!\"); } } ","date":"2019-04-19","objectID":"/posts/hellojava/:1:0","tags":["Java"],"title":"用记事本编写第一个 java 程序","uri":"/posts/hellojava/"},{"categories":["Java"],"content":"打开 cmd ","date":"2019-04-19","objectID":"/posts/hellojava/:2:0","tags":["Java"],"title":"用记事本编写第一个 java 程序","uri":"/posts/hellojava/"},{"categories":["Java"],"content":"邮箱 import java.util.regex.Matcher; import java.util.regex.Pattern; public class RegexDemo { public static void main(String[] args) { // Pattern 类 正则表达式的编译表示。 Pattern pattern = Pattern.compile(\"^[a-zA-Z0-9_!#$%\u0026'*+/=?`{|}~^.-]+@[a-zA-Z0-9.-]+$\"); String[] emails = {\"admin@lruihao.cn\", \"lruihao.cn\"}; for (String email : emails) { //Matcher 通过解释 Pattern 对字符序列执行匹配操作的引擎 Matcher matcher = pattern.matcher(email); System.out.println(email + \"匹配结果：\" + matcher.matches()); } } } admin@lruihao.cn 匹配结果：true lruihao.cn 匹配结果：false ","date":"2019-04-18","objectID":"/posts/java-regex/:1:0","tags":["regex","Java"],"title":"java 正则表达式练习","uri":"/posts/java-regex/"},{"categories":["Java"],"content":"电话 package base; import java.util.Scanner; import java.util.regex.Matcher; import java.util.regex.Pattern; public class RegexTest { public static void main(String[] args) { Pattern patter=Pattern.compile(\"^[1][3,4,5,7,8][0-9]{9}$\"); Scanner sc=new Scanner(System.in); String telnum=sc.nextLine(); sc.close(); Matcher matcher=patter.matcher(telnum); System.out.println(telnum+\"匹配结果： \"+matcher.matches()); } } /** * 获取当前的 httpSession * @return */ public static HttpSession getSession() { return getRequest().getSession(); } /** * 手机号验证 * @param str * @return 验证通过返回 true */ public static boolean isMobile(final String str) { Pattern p = null; Matcher m = null; boolean b = false; p = Pattern.compile(\"^[1][3,4,5,7,8][0-9]{9}$\"); // 验证手机号 m = p.matcher(str); b = m.matches(); return b; } /** * 电话号码验证 * @param str * @return 验证通过返回 true */ public static boolean isPhone(final String str) { Pattern p1 = null, p2 = null; Matcher m = null; boolean b = false; p1 = Pattern.compile(\"^[0][1-9]{2,3}-[0-9]{5,10}$\"); // 验证带区号的 p2 = Pattern.compile(\"^[1-9]{1}[0-9]{5,8}$\"); // 验证没有区号的 if (str.length() \u003e 9) { m = p1.matcher(str); b = m.matches(); } else { m = p2.matcher(str); b = m.matches(); } return b; } ","date":"2019-04-18","objectID":"/posts/java-regex/:2:0","tags":["regex","Java"],"title":"java 正则表达式练习","uri":"/posts/java-regex/"},{"categories":["Java"],"content":"身份证 /* 身份证正则表达式 16 或 18 */ public static final String IDCARD=\"((11|12|13|14|15|21|22|23|31|32|33|34|35|36|37|41|42|43|44|45|46|50|51|52|53|54|61|62|63|64|65)[0-9]{4})\" + \"(([1|2][0-9]{3}[0|1][0-9][0-3][0-9][0-9]{3}\" + \"[Xx0-9])|([0-9]{2}[0|1][0-9][0-3][0-9][0-9]{3}))\"; ","date":"2019-04-18","objectID":"/posts/java-regex/:3:0","tags":["regex","Java"],"title":"java 正则表达式练习","uri":"/posts/java-regex/"},{"categories":["Java"],"content":"StringBuffer/StringBuilder（掌握） ","date":"2019-04-14","objectID":"/posts/stringbuffer/:1:0","tags":["StringBuffer","sort","Java"],"title":"java 常用类","uri":"/posts/stringbuffer/"},{"categories":["Java"],"content":"StringBuffer 是线程安全的可变字符串。 StringBuilder 是线程不安全的可变字符串。 和 StringBuffer 的功能一样。就是效率高一些，但是不安全。 ","date":"2019-04-14","objectID":"/posts/stringbuffer/:1:1","tags":["StringBuffer","sort","Java"],"title":"java 常用类","uri":"/posts/stringbuffer/"},{"categories":["Java"],"content":"构造方法： StringBuffer sb = new StringBuffer(); StringBuffer sb = new StringBuffer(50); StringBuffer sb = new StringBuffer(“hello”); ","date":"2019-04-14","objectID":"/posts/stringbuffer/:1:2","tags":["StringBuffer","sort","Java"],"title":"java 常用类","uri":"/posts/stringbuffer/"},{"categories":["Java"],"content":"成员方法：（自己补齐方法和意思） 添加功能 public StringBuffer append(String str): 追加字符串 public StringBuffer insert(int offset,String str): 在指定位置插入字符串 删除功能 public StringBuffer deleteCharAt(int index): 删除指定位置字符 public StringBuffer delete(int start,int end): 删除从指定开始到结束的字符，左闭右开 替换功能 public StringBuffer replace(int start,int end,String str): 以字符串替代从指定开始到结束的字符 反转功能 public StringBuffer reverse(): 反转 截取功能 public String substring(int start): 从指定索引到末尾的字符串 public String substring(int start,int end): 从指定索引开始到指定索引结束的字符串 ","date":"2019-04-14","objectID":"/posts/stringbuffer/:1:3","tags":["StringBuffer","sort","Java"],"title":"java 常用类","uri":"/posts/stringbuffer/"},{"categories":["Java"],"content":"案例： String 和 StringBuffer 的相互转换，通过构造即可。 把数组转成指定的字符串格式 把字符串反转 判断一个字符串是否是对称字符串 ","date":"2019-04-14","objectID":"/posts/stringbuffer/:1:4","tags":["StringBuffer","sort","Java"],"title":"java 常用类","uri":"/posts/stringbuffer/"},{"categories":["Java"],"content":"数组高级部分（理解） ","date":"2019-04-14","objectID":"/posts/stringbuffer/:2:0","tags":["StringBuffer","sort","Java"],"title":"java 常用类","uri":"/posts/stringbuffer/"},{"categories":["Java"],"content":"排序 冒泡排序 相邻元素，两两比较，大的往后放。 public static void bubbleSort(int[] arr) { for(int x=0; x\u003carr.length-1; x++) { for(int y=0; y\u003carr.length-1-x; y++) { if(arr[y]\u003earr[y+1]) { int temp = arr[y]; arr[y] = arr[y+1]; arr[y+1] = temp; } } } } 选择排序 从 0 开始，依次和后面的比较，小的往前放。 public static void selectSort(int[] arr) { for(int x=0; x\u003carr.length-1; x++) { for(int y=x+1; y\u003carr.length; y++) { if(arr[y] \u003c arr[x]) { int temp = arr[x]; arr[x] = arr[y]; arr[y] = temp; } } } } public static void selectSort(int[] a) { int min=0; int temp=0; if((a==null)||(a.length==0)) return; for(int i=0;i\u003ca.length-1;i++) { min=i;//无序区的最小数据数组下标 for(int j=i+1;j\u003ca.length;j++) { //在无序区中找到最小数据并保存其数组下标 if(a[j]\u003ca[min]) { min=j; } } //将最小元素放到本次循环的前端 temp=a[i]; a[i]=a[min]; a[min]=temp; } } ","date":"2019-04-14","objectID":"/posts/stringbuffer/:2:1","tags":["StringBuffer","sort","Java"],"title":"java 常用类","uri":"/posts/stringbuffer/"},{"categories":["Java"],"content":"查找 基本查找 数组无序 二分查找 数组有序 public static int getIndex(int[] arr,int value) { int max = arr.length-1; int min = 0; int mid = (max+min)/2; while(arr[mid] != value) { if(arr[mid] \u003e value) { max = mid - 1; }else if(arr[mid] \u003c value) { min = mid + 1; } if(max \u003c min) { return -1; } mid = (max+min)/2; } return mid; } ","date":"2019-04-14","objectID":"/posts/stringbuffer/:2:2","tags":["StringBuffer","sort","Java"],"title":"java 常用类","uri":"/posts/stringbuffer/"},{"categories":["Java"],"content":"Arrays 工具类（掌握） ","date":"2019-04-14","objectID":"/posts/stringbuffer/:3:0","tags":["StringBuffer","sort","Java"],"title":"java 常用类","uri":"/posts/stringbuffer/"},{"categories":["Java"],"content":"Arrays 是针对数组进行操作的工具类，提供了排序和查找等功能 ","date":"2019-04-14","objectID":"/posts/stringbuffer/:3:1","tags":["StringBuffer","sort","Java"],"title":"java 常用类","uri":"/posts/stringbuffer/"},{"categories":["Java"],"content":"成员方法：（自己补齐方法和意思） 把数组转成字符串 public static String toString(): 将任意类型数据转换成字符串 排序 public static void sort()： 二分查找 public static int binarySearch(int[] arr,int key) ","date":"2019-04-14","objectID":"/posts/stringbuffer/:3:2","tags":["StringBuffer","sort","Java"],"title":"java 常用类","uri":"/posts/stringbuffer/"},{"categories":["Java"],"content":"案例： 把字符串中的字符进行排序 ","date":"2019-04-14","objectID":"/posts/stringbuffer/:3:3","tags":["StringBuffer","sort","Java"],"title":"java 常用类","uri":"/posts/stringbuffer/"},{"categories":["Java"],"content":"基本类型包装类（掌握） ","date":"2019-04-14","objectID":"/posts/stringbuffer/:4:0","tags":["StringBuffer","sort","Java"],"title":"java 常用类","uri":"/posts/stringbuffer/"},{"categories":["Java"],"content":"为了让我们对基本类型进行更多的操作，java 针对每种基本类型提供了对应的包装类类型。 ","date":"2019-04-14","objectID":"/posts/stringbuffer/:4:1","tags":["StringBuffer","sort","Java"],"title":"java 常用类","uri":"/posts/stringbuffer/"},{"categories":["Java"],"content":"分别是哪些呢？ byte Byte short Short int Integer long Long float Float double Double char Character boolean Boolean 特殊： void Void ","date":"2019-04-14","objectID":"/posts/stringbuffer/:4:2","tags":["StringBuffer","sort","Java"],"title":"java 常用类","uri":"/posts/stringbuffer/"},{"categories":["Java"],"content":"Integer 构造方法 Integer i = new Integer(100); Integer i = new Integer(“100”); 成员方法（自己补齐方法和意思） 把字符串转成 int 类型 String-\u003eint: Integer.parseInt() int-\u003eString: String.valueOf() 或 Integer.toString() JDK5 的新特性 自动装箱： int --\u003e Integer //Integer.valueOf() 自动拆箱： Integer --\u003e int //Integer.intValue() 请解释： Integer i = 100; i+=200; System.out.println(i); byte 缓存池面试题 byte,short,char—\u003e小于 127，否则报-6 的错误（查看 JDK) ","date":"2019-04-14","objectID":"/posts/stringbuffer/:4:3","tags":["StringBuffer","sort","Java"],"title":"java 常用类","uri":"/posts/stringbuffer/"},{"categories":["Java"],"content":"Character 构造方法 Character ch = new Character(‘a’); 成员方法（自己补齐方法和意思） 判断字符是否是大写字母 public boolean isUpperCase(char ch) 判断字符是否是小写字母 public boolean isLowerCase(Char ch) 判断字符是否是数字字符 public boolean isDigit(Char ch) 把字符转成大写 public Char toUpperCase(Char ch) 把字符转成小写 public Char toLowerCase(Char ch) ","date":"2019-04-14","objectID":"/posts/stringbuffer/:4:4","tags":["StringBuffer","sort","Java"],"title":"java 常用类","uri":"/posts/stringbuffer/"},{"categories":["ACM"],"content":"题目大意： 题目链接 老鼠有 M 磅猫食 , 有 N 个房间 , 每个房间前有一只猫 , 房间里有老鼠最喜欢的食品 J[i] , 若要得到房间的食物 , 必须付出相应的猫食 F[i] , 当然这只老鼠没必要每次都付出所有的 F[i]，若它付出 F[i] 的 a%， 则得到 J[i] 的 a%，求老鼠能吃到的最多的食物。 ","date":"2019-04-12","objectID":"/posts/hdu1009/:1:0","tags":["ACM","贪心","HDU"],"title":"HDU 1009 FatMouse' Trade（贪心）","uri":"/posts/hdu1009/"},{"categories":["ACM"],"content":"Sample Input 5 3 7 2 4 3 5 2 20 3 25 18 24 15 15 10 -1 -1 ","date":"2019-04-12","objectID":"/posts/hdu1009/:1:1","tags":["ACM","贪心","HDU"],"title":"HDU 1009 FatMouse' Trade（贪心）","uri":"/posts/hdu1009/"},{"categories":["ACM"],"content":"Sample Output 13.333 31.500 ","date":"2019-04-12","objectID":"/posts/hdu1009/:1:2","tags":["ACM","贪心","HDU"],"title":"HDU 1009 FatMouse' Trade（贪心）","uri":"/posts/hdu1009/"},{"categories":["ACM"],"content":"分析 老鼠要用最少的猫粮来换取最多的食物 , 也就是 J[i]/F[i] 越大越好 , 所以按照 J[i]/F[i] 进行降序排列 , 然后依次用猫粮来换取食物 , 当所剩下的猫粮不足以完全换取食物 , 能换多少是多少。 #include\u003cstdio.h\u003e #include\u003calgorithm\u003e using namespace std; struct node{ double j; double f; double s; }a[1005]; int cmp(node x,node y){ return x.s\u003ey.s; } int main(){ int m,n,i; while(scanf(\"%d%d\",\u0026m,\u0026n)\u0026\u0026(m!=-1\u0026\u0026n!=-1)){ memset(a,0,sizeof(a)); for(i=0;i\u003cn;i++){ scanf(\"%lf%lf\",\u0026a[i].j,\u0026a[i].f); a[i].s=a[i].j/a[i].f; } sort(a,a+n,cmp); double sum=0; for(i=0;i\u003cn;i++){ if(m\u003e=a[i].f){ sum+=a[i].j; m-=a[i].f; }else{ sum+=a[i].s*m; m=0; } if(m\u003c=0) break; } printf(\"%.3lf\\n\",sum); } return 0; } ","date":"2019-04-12","objectID":"/posts/hdu1009/:2:0","tags":["ACM","贪心","HDU"],"title":"HDU 1009 FatMouse' Trade（贪心）","uri":"/posts/hdu1009/"},{"categories":["OS"],"content":" 一直都想在自己电脑上搭建一个网站或者把自己的电脑做成服务器，今天终于简单实现了。还有很多知识需要学习，简单记录一下。 ","date":"2019-04-03","objectID":"/posts/ngrok/:0:0","tags":["ngrok","linux","宝塔面板","server","ubuntu"],"title":"本地搭建网站服务器并穿透内网","uri":"/posts/ngrok/"},{"categories":["OS"],"content":"搭建环境 我的电脑是ubuntu+windows双系统的，所以我先在 ubuntu 上面装了一个宝塔面板，方便通过 web 管理电脑，宝塔安装好后安装相关的环境mysql,php,nginx等。我们现在只能通过本地 ip127.0.0.1:8888访问面板。 ","date":"2019-04-03","objectID":"/posts/ngrok/:1:0","tags":["ngrok","linux","宝塔面板","server","ubuntu"],"title":"本地搭建网站服务器并穿透内网","uri":"/posts/ngrok/"},{"categories":["OS"],"content":"ngrok 穿透 去 ngrok 注册登录，购买隧道（有免费的），然后绑定端口，绑定域名，这里我们拿端口8888和域名test.lruihao.cn做实验，也就是宝塔面板的端口，这样我们就可以透过域名远程访问本地服务器，这样是不是开始有云服务器的感觉了。然后宝塔面板设置也绑定好域名test.lruihao.cn,dns 服务商那里做好相应的解析。 然后在 ngrok 那里下载 sunny 客户端文件，我们是 ubuntu 选择linux-64bits版本。解压后在 ubuntu 打开终端进入 sunny 文件目录，权限给到 755，运行命令./sunny clientid xxxxxxx 后面的你的隧道订单的 id。 现在就可以通过互联网访问我的 ubuntu 服务器了。 ","date":"2019-04-03","objectID":"/posts/ngrok/:2:0","tags":["ngrok","linux","宝塔面板","server","ubuntu"],"title":"本地搭建网站服务器并穿透内网","uri":"/posts/ngrok/"},{"categories":["OS"],"content":"搭建网站 前面两步搞定，搭建网站就没问题了。 我们只要把网站的端口按第二步的在 ngrok 设置好就可以穿透了。 ","date":"2019-04-03","objectID":"/posts/ngrok/:3:0","tags":["ngrok","linux","宝塔面板","server","ubuntu"],"title":"本地搭建网站服务器并穿透内网","uri":"/posts/ngrok/"},{"categories":["OS"],"content":"注意 访问本地网站的必要条件是你的电脑得是开机状态而且有网络。 ","date":"2019-04-03","objectID":"/posts/ngrok/:4:0","tags":["ngrok","linux","宝塔面板","server","ubuntu"],"title":"本地搭建网站服务器并穿透内网","uri":"/posts/ngrok/"},{"categories":["Memo"],"content":" 原文链接 “卓越班”到了大三突然掀起一股毕业慌，一部分人投身于考研的热潮中，一部分人选择了培训机构学习技术。而我出于种种原因既不考研也不培训，选择自学 java 和 web 相关的知识，也希望因此能在以后谋得一份心仪的工作。 如果文章中有出现纰漏、错误之处，还请看到的小伙伴多多指教，先行谢过 ","date":"2019-03-30","objectID":"/posts/ms-html-css/:0:0","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"HTML ","date":"2019-03-30","objectID":"/posts/ms-html-css/:1:0","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"1. Doctype 作用，HTML5 为什么只需要写 \u003c!DOCTYPE HTML\u003e doctype 是一种标准通用标记语言的文档类型声明，目的是告诉标准通用标记语言解析器要使用什么样的文档类型定义（DTD）来解析文档。\u003c!DOCTYPE\u003e声明必须是 HTML 文档的第一行，位于 html 标签之前 HTML5 不基于 SGML，所以不需要引用 DTD。在 HTML5 中\u003c!DOCTYPE\u003e只有一种 SGML: 标准通用标记语言，是现时常用的超文本格式的最高层次标准 ","date":"2019-03-30","objectID":"/posts/ms-html-css/:1:1","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"2. 行内元素有哪些，块级元素有哪些，空 (void) 元素有那些 行内元素：a span i img input select b 等 块级元素：div ul ol li h1~h6 p table 等 空元素：br hr link 等 ","date":"2019-03-30","objectID":"/posts/ms-html-css/:1:2","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"3. 简述一下你对 HTML 语义化的理解 简单来说，就是合适的标签做合适的事情，这样具有以下好处： 有助于构架良好的 HTML 结构，有利于搜索引擎的建立索引、抓取，利于 SEO 有利于不同设备的解析 有利于构建清晰的机构，有利于团队的开发、维护 ","date":"2019-03-30","objectID":"/posts/ms-html-css/:1:3","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"4. 常见的浏览器内核有哪些，介绍一下你对浏览器内核的理解 Trident 内核：IE Gecko 内核：NETSCAPE6 及以上版本，火狐 Presto 内核：Opera7 及以上。[Opera 内核原为：Presto，现为：Blink;] Webkit 内核：Safari，Chrome 等。[Chrome 的：Blink（WebKit 的分支）] 浏览器内核又可以分成两部分：渲染引擎和 JS 引擎。 渲染引擎主要负责取得网页的内容、整理讯息、计算网页的显示方式等，JS 引擎则是解析 Javascript 语言，执行 javascript 语言来实现网页的动态效果。 ","date":"2019-03-30","objectID":"/posts/ms-html-css/:1:4","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"5. html5 有哪些新特性 语义化标签：header footer nav section article aside 等 增强型表单：date（从一个日期选择器选择一个日期） email（包含 e-mail 地址的输入域） number（数值的输入域） range（一定范围内数字值的输入域） search（用于搜索域） tel（定义输入电话号码字段） 等 视频和音频：audio video Canvas 绘图 SVG 绘图 地理定位：Geolocation 拖放 API：drag web worker：是运行在后台的 JavaScript，独立于其他脚本，不会影响页面的性能 web storage: localStorage sessionStorage WebSocket: HTML5 开始提供的一种在单个 TCP 连接上进行全双工通讯的协议 ","date":"2019-03-30","objectID":"/posts/ms-html-css/:1:5","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"6. 描述一下 cookie，sessionStorage 和 localStorage 的区别 特性 Cookie localStorage sessionStorage 生命周期 可设置失效时间，没有设置的话，默认是关闭浏览器后失效 除非被手动清除，否则将会永久保存 仅在当前网页会话下有效，关闭页面或浏览器后就会被清除 存放数据大小 4KB 左右 可以保存 5MB 的信息 可以保存 5MB 的信息 http 请求 每次都会携带在 HTTP 头中，如果使用 cookie 保存过多数据会带来性能问题 仅在客户端（即浏览器）中保存，不参与和服务器的通信 仅在客户端（即浏览器）中保存，不参与和服务器的通信 ","date":"2019-03-30","objectID":"/posts/ms-html-css/:1:6","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"7. 如何实现浏览器内多个标签页之间的通信 使用 localStorage: localStorage.setItem(key,value)、localStorage.getItem(key) websocket 协议 webworker 多个标签页之间的通信 ","date":"2019-03-30","objectID":"/posts/ms-html-css/:1:7","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"8. HTML5 的离线存储怎么使用，解释一下工作原理 HTML5 的离线存储 ","date":"2019-03-30","objectID":"/posts/ms-html-css/:1:8","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"9. src 与 href 的区别 区别：src 用于替代这个元素，而 href 用于建立这个标签与外部资源之间的关系 \u003clink href=\"style.css\" rel=\"stylesheet\" /\u003e浏览器加载到这里的时候，html 的渲染和解析不会暂停，css 文件的加载是同时进行的 \u003cscript src=\"script.js\"\u003e\u003c/script\u003e当浏览器解析到这句代码时，页面的加载和解析都会暂停直到浏览器拿到并执行完这个 js 文件 ","date":"2019-03-30","objectID":"/posts/ms-html-css/:1:9","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"10. 表单提交中 Get 和 Post 方式的区别 Get 一般用于从服务器上获取数据，Post 向服务器传送数据 Get 传输的数据是拼接在 Url 之后的，对用户是可见的；Post 的传输数据对用户是不可见的 Get 传送的数据量较小，不能大于 2KB。Post 传送的数据量较大，一般被默认为不受限制 Get 安全性非常低，Post 安全性较高 在 FORM 提交的时候，如果不指定 Method，则默认为 Get 请求 ","date":"2019-03-30","objectID":"/posts/ms-html-css/:1:10","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"CSS ","date":"2019-03-30","objectID":"/posts/ms-html-css/:2:0","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"1. css 盒子模型，box-sizing 属性的理解 css 的盒模型由 content（内容）、padding（内边距）、border（边框）、margin（外边距）组成。但盒子的大小由 content+padding+border 这几部分决定 box-sizing 是一个 CSS3 属性，与盒子模型有着密切联系。即决定元素的宽高如何计算，box-sizing 有三个属性： box-sizing: content-box|border-box|inherit: content-box 使得元素的宽高即为内容区的宽高（默认模式） border-box: 计算方式 content + padding + border = 本身元素大小，即缩小了 content 大小 inherit 指定 box-sizing 属性的值，应该从父元素继承 ","date":"2019-03-30","objectID":"/posts/ms-html-css/:2:1","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"2. 清除浮动，什么时候需要清除浮动，清除浮动都有哪些方法 浮动的元素是脱离文档标准流的，如果我们不清楚浮动，那么就会造成父元素高度塌陷，影响页面布局。 清除浮动的方式： 为父元素设置高度 为父元素添加overflow:hidden 伪元素 .fix::after { content: ''; display: block; clear: both; } 使用伪元素的好处：不增加冗余的 DOM 节点，符合语义化 overflow:hidden 可以触发 BFC 机制。BFC：块级格式化上下文，创建了 BFC 的元素就是一个独立的盒子，它规定了内部如何布局，并且与这个独立盒子里的布局不受外部影响，当然它也不会影响到外面的元素，计算 BFC 的高度时，浮动元素也参与计算 ","date":"2019-03-30","objectID":"/posts/ms-html-css/:2:2","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"3. 如何让一个不定宽高的盒子水平垂直居中 定位的方式 .father { position: relative; } .son { position: absolute; top: 0; right: 0; bottom: 0; left: 0; margin: auto; } css3 属性 .father { position: relative; } .son { position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); } flex 布局 .father { display: flex; justify-content: center; align-items: center; } ","date":"2019-03-30","objectID":"/posts/ms-html-css/:2:3","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"4. px 和 em 和 rem 的区别 px: 像素，相对长度单位。像素px是相对于显示器屏幕分辨率而言的 em的值并不是固定的，会继承父级元素的字体大小，代表倍数 rem的值并不是固定的，始终是基于根元素 \u003chtml\u003e 的，也代表倍数 ","date":"2019-03-30","objectID":"/posts/ms-html-css/:2:4","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"5. position 的值有哪些 static： 默认值。没有定位，元素出现在正常的流中 relative（相对定位）：生成相对定位的元素，相对于其正常（原先本身）位置进行定位 absolute（绝对定位）：生成绝对定位的元素，相对于 static 定位以外的第一个父元素进行定位 fixed（固定定位）：生成绝对定位的元素，相对于浏览器窗口进行定位 ","date":"2019-03-30","objectID":"/posts/ms-html-css/:2:5","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"6. display:none 与 visibility：hidden 的区别 区别 display:none visibility：hidden 的 是否占据空间 不占据任何空间，在文档渲染时，该元素如同不存在（但依然存在文档对象模型树中） 该元素空间依旧存在 是否渲染 会触发 reflow（回流），进行渲染 只会触发 repaint（重绘），因为没有发现位置变化，不进行渲染 是否是继承属性 不是继承属性，元素及其子元素都会消失 是继承属性，若子元素使用了 visibility:visible，则不继承，这个子孙元素又会显现出 ","date":"2019-03-30","objectID":"/posts/ms-html-css/:2:6","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"7. CSS 中 link 和@import 的区别 link 属于 XHTML 标签，@import 完全是 CSS 提供的一种方式，只能加载 CSS 加载顺序的差别，当一个页面被加载的时候，link 引用的 CSS 会同时被加载，而@import 引用的 CSS 会等到页面全部被下载完再被加载 兼容性的差别。由于@import 是 CSS2.1 提出的所以老的浏览器不支持，而 link 标签无此问题 当使用 javascript 控制 dom 去改变样式的时候，只能使用 link 标签，因为@import 不是 dom 可以控制的 ","date":"2019-03-30","objectID":"/posts/ms-html-css/:2:7","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"8. 什么是响应式设计，响应式设计的基本原理是什么 响应式网站设计是一个网站能够兼容多个终端，而不是为每一个终端做一个特定的版本。基本原理是通过媒体查询检测不同的设备屏幕尺寸做处理 ","date":"2019-03-30","objectID":"/posts/ms-html-css/:2:8","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"9. 为什么要初始化 CSS 样式 因为浏览器的兼容问题，不同浏览器对有些标签的默认值是不同的，如果没对 CSS 初始化往往会出现浏览器之间的页面显示差异 初始化样式会对 SEO 有一定的影响 ","date":"2019-03-30","objectID":"/posts/ms-html-css/:2:9","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"10. CSS3 有哪些新特性 实现圆角border-radius，阴影box-shadow，边框图片border-image 对文字加特效text-shadow，强制文本换行word-wrap，线性渐变linear-gradient 实现旋转transform:rotate(90deg), 缩放scale(0.85,0.90),translate(0px,-30px)定位，倾斜skew(-9deg,0deg); 增加了更多的 CSS 选择器、多背景、rgba() 唯一引入的伪元素是::selection； 实现媒体查询@media，多栏布局flex 过渡transition 动画animation ","date":"2019-03-30","objectID":"/posts/ms-html-css/:2:10","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"11. ::before 和 :after 中双冒号和单冒号有什么区别？解释一下这 2 个伪元素的作用 单冒号 (:) 用于 CSS3 伪类，双冒号 (::) 用于 CSS3 伪元素。（伪元素由双冒号和伪元素名称组成）, 双冒号是在当前规范中引入的，用于区分伪类和伪元素 ","date":"2019-03-30","objectID":"/posts/ms-html-css/:2:11","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"12. CSS 优化、提高性能的方法有哪些 移除空的 css 规则（Remove empty rules） 正确使用 display 的属性 不滥用浮动、web 字体 不声明过多的 font-size 不在选择符中使用 ID 标识符 遵守盒模型规则 尽量减少页面重排、重绘 抽象提取公共样式，减少代码量 ","date":"2019-03-30","objectID":"/posts/ms-html-css/:2:12","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"13. 重绘和回流 重绘和回流 ","date":"2019-03-30","objectID":"/posts/ms-html-css/:2:13","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"14. flex 布局 flex 布局教程–阮一峰 ","date":"2019-03-30","objectID":"/posts/ms-html-css/:2:14","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["Memo"],"content":"15. css 预处理器 提供了一种 css 的书写方式，常见的就是 SAAS 文档 和 LESS 文档 ","date":"2019-03-30","objectID":"/posts/ms-html-css/:2:15","tags":["HTML","CSS"],"title":"前端面试题 - HTML+CSS","uri":"/posts/ms-html-css/"},{"categories":["ACM"],"content":" 我国古代数学家张丘建在《算经》一书中提出的数学问题：鸡翁一值钱五，鸡母一值钱三，鸡雏三值钱一。百钱买百鸡，问鸡翁、鸡母、鸡雏各几何？ 设公鸡，母鸡，小鸡数目分别为 x,y,z(x\u003c=20,y\u003c=33,z\u003c=100) ","date":"2019-03-30","objectID":"/posts/bqbj/:0:0","tags":["ACM"],"title":"百钱百鸡（枚举法）","uri":"/posts/bqbj/"},{"categories":["ACM"],"content":"约束条件 x+y+z=100 5x+3y+z/3=100 ","date":"2019-03-30","objectID":"/posts/bqbj/:1:0","tags":["ACM"],"title":"百钱百鸡（枚举法）","uri":"/posts/bqbj/"},{"categories":["ACM"],"content":"算法分析 若依次枚举 x,y,x, 则至少尝试 21*34*100=71400 次，显然效率太低。 在 x,y 的数目确定后，z 的数目也就确定下来了 100-x-y，无须再进行枚举，此时约束条件只有一个 5x+3y+z/3=100. 只需枚举 x,y，共 21*34=714 次。 ","date":"2019-03-30","objectID":"/posts/bqbj/:2:0","tags":["ACM"],"title":"百钱百鸡（枚举法）","uri":"/posts/bqbj/"},{"categories":["ACM"],"content":"算法设计 #include\u003cstdio.h\u003e int main(){ int x,y,z; for(x=0;x\u003c=20;x++) //21*34=714 for(y=0;y\u003c=33;y++){ z=100-y-x; if(z%3==0 \u0026\u0026 (5*x+3*y+z/3)==100){//限定 z 能被 3 整除，进一步提高效率 printf(\"cock number:%d\\t\",x); printf(\"hen number:%d\\t\",y); printf(\"chick number:%d\\n\",z); } } return 0; } 运行解 cock number:0 hen number:25 chick number:75 cock number:4 hen number:18 chick number:78 cock number:8 hen number:11 chick number:81 cock number:12 hen number:4 chick number:84 ","date":"2019-03-30","objectID":"/posts/bqbj/:3:0","tags":["ACM"],"title":"百钱百鸡（枚举法）","uri":"/posts/bqbj/"},{"categories":["ACM"],"content":" 大数乘法 c 版(基础写法) #include\u003cstdio.h\u003e #include\u003cstring.h\u003e #define N 202 int main() { int a[N] = {0}, b[N] = {0}, c[404] = {0}, la, lb, i, j,k, d = 0, n1, n2;//202位数相乘，最长404位数 int get(int *p); void change(int *a, int *b, int n); la = get(a); lb = get(b); n1 = la \u003e lb ? la : lb;//较长的数长 n2 = la \u003c lb ? la : lb;//较短的数长 if (la \u003c lb) change(a, b, lb); //模拟乘法运算过程（进位等考虑） for (i = 0; i \u003c n2; i++) { for (j = 0; j \u003c n1; j++) { c[j + i] += (b[i] * a[j] + d)%10; d = (b[i] * a[j] + d) / 10; if (c[j+i]\u003e9){ d++; c[j+i]%=10; } if (a[j+1]==0\u0026\u0026d!=0){ k=j+i+1; c[k]=d; } } d=0; } k=k\u003e(j+i-2)?k:j+i-2; for (i = k; i \u003e= 0; i--)//将倒序装入的结果打印 printf(\"%d\", c[i]); return 0; } //输入字符串作为数字，并返回数字去除前导0后的长度 int get(int *p) { char x[N]; int l, i, ex = 0; scanf(\"%s\", x); l = strlen(x); while (x[ex] == '0') ex++; for (i = ex; i \u003c l; i++) //提取字符串数字到int数组，倒序排列 *(p + l - i - 1) = x[i] - '0'; return l - ex; } void change(int *a, int *b, int n) { int i, t; for (i = 0; i \u003c n; i++) { t = a[i]; a[i] = b[i]; b[i] = t; } } 程序运行结果 1234567890123456789 98765432109876543210 121932631124517831023715309991126352690 ","date":"2019-03-28","objectID":"/posts/dacheng/:0:0","tags":["数学","大数运算","ACM","C"],"title":"大数乘法","uri":"/posts/dacheng/"},{"categories":["Grocery"],"content":" 记录自己在配置 vps 及博客 SSL 证书时遇到的问题。 ","date":"2019-03-28","objectID":"/posts/http2https/:0:0","tags":["SSL","redirect","CDN","JavaScript","server"],"title":"vps 配置 ssl 及 https 重定向","uri":"/posts/http2https/"},{"categories":["Grocery"],"content":"强制重定向 https 有一种情况相信很多人都遇到过，就是虽然我们配置了 ssl 证书，但是 https 和 http 地址都是各自都可以单独访问。我们应该也见过类似于 github 的代码托管网站有强制 https 的开关。如果是这种情况我们还可以通过 js 进行 301 定向。 \u003cscript\u003e var targetProtocol = \"https:\"; var host = \"lruihao.cn\"; if (window.location.host == host \u0026\u0026 window.location.protocol != targetProtocol){ window.location.href = targetProtocol + window.location.href.substring(window.location.protocol.length); } \u003c/script\u003e ","date":"2019-03-28","objectID":"/posts/http2https/:1:0","tags":["SSL","redirect","CDN","JavaScript","server"],"title":"vps 配置 ssl 及 https 重定向","uri":"/posts/http2https/"},{"categories":["Grocery"],"content":"腾讯云 CDN 配置 这个博客后来是转到了腾讯云的 cos 桶存储。当时在桶内静态网站设置的时候，设置强制 https 发现会出错。而且还接入了 CDN，所以今天在 CDN 设置那里也看到了 https 的设置，打开强制 https 就 OK 了。这天在三丰云撸了一个免费的主机，搭了一个 WordPress（想试试 wp 的感觉），然后 vps 的 SSL 问题现在也很简单了，第一步，到腾讯云申请免费证书；第二步，配置 CDN，按步骤来，其中接入方式选择自有源站；第三步，强制 https（可选）。 ","date":"2019-03-28","objectID":"/posts/http2https/:2:0","tags":["SSL","redirect","CDN","JavaScript","server"],"title":"vps 配置 ssl 及 https 重定向","uri":"/posts/http2https/"},{"categories":["Memo"],"content":"基于 hexo-theme-next 6.0+的 Pisces 模板做的 DIY 扩展性设计","date":"2019-03-21","objectID":"/posts/hexo-theme-next/","tags":["hexo"],"title":"hexo-theme-next @modified LRH","uri":"/posts/hexo-theme-next/"},{"categories":["Memo"],"content":" 危险 如无必要，不再更新！（2019.09.13） 今晚我做出了一个慎重的决定，由于博主时间精力有限，需要更多的时间来工作和学习。所以我将放弃对 next 的主题的自定义修改，next 主题官方已经更新到了 7.0+的版本，喜欢 next 主题风格的朋友可以在 github 更新。 我这也算是上古版本了，版本差距实在过大，所以我也将放弃博客使用主题的更新。 以下仍为当前博客使用主题，lib 资源已打包 github。 next 基于 hexo-theme-next 6.0+ 的 Pisces 模板做的 DIY 扩展性设计（部分兼容 next 其他几种模板）。主要是一些 custom style 还有一些第三方的 js。修改的地方太多也有点小乱就不提 PR 了。 modified 官方 Demo =\u003e https://theme-next.org 记录一下折腾过程，以后备份恢复博客也好方便自己。本文之前的美化修改请见 hexo 标签。 主题中若有遗漏第三方插件或应用的 key 及 id 值等请修改为自己对应的值 主要的几个自定义文件 _config.swig #主题配置文件 相关账户信息自己注册替换 \\layout\\custom\\head.swig #在头部自定义加入标签 \\layout\\custom\\google_adsense.swig #谷歌广告模块，内有注释暂时弃用 \\layout\\_layout.swig #主布局 \\layout\\_macro\\post.swig #文章布局 \\layout\\_macro\\post-copyright.swig #文章版权 \\layout\\_macro\\siderbar.swig #侧栏模板 \\layout\\_third-party\\copy-code.swig #复制按钮 \\layout\\_partials\\comments.swig #评论主模板 \\layout\\_partials\\footer.swig #底部模板#该模块在 layout.swig 引入，用于在 body 自定义标签 \\layout\\_partials\\footer_custom.swig #footer 自定义文件 \\layout\\_third-party\\custom.swig #该模块在 layout.swig 引入用于在 body 自定义标签 \\source\\css\\_custom\\customs.styl #主要用户自定义样式表 \\source\\fonts\\ #引入了一些我的手写体及外部字体 \\scripts\\qcloudcdn.js #腾讯云 cos 桶刷新缓存的脚本，不需要可删掉 [^1] ^1 ","date":"2019-03-21","objectID":"/posts/hexo-theme-next/:0:0","tags":["hexo"],"title":"hexo-theme-next @modified LRH","uri":"/posts/hexo-theme-next/"},{"categories":["Memo"],"content":"初步安装 安装整个改过的主题，然后下载相应的 lib 资源解压放入 source 文件夹 cd hexo git clone https://github.com/Lruihao/hexo-theme-next themes/next 主题配置文件_config.yml, 选择主题 theme: next lib 下载 http://github.com/Lruihao/hexo-theme-next/releases/tag/v6.9.1 ","date":"2019-03-21","objectID":"/posts/hexo-theme-next/:1:0","tags":["hexo"],"title":"hexo-theme-next @modified LRH","uri":"/posts/hexo-theme-next/"},{"categories":["Memo"],"content":"更新内容 更多自定义详见源码 ","date":"2019-03-21","objectID":"/posts/hexo-theme-next/:2:0","tags":["hexo"],"title":"hexo-theme-next @modified LRH","uri":"/posts/hexo-theme-next/"},{"categories":["Memo"],"content":"links 模板 自定义友链模板，打开hexo\\themes\\next\\layout\\新建links.swig文件，写下以下内容后保存。 {% extends '_layout.swig' %} {% import '_macro/sidebar.swig' as sidebar_template %} {% block title %}{# #}{% set page_title_suffix = ' | ' + title %}{# #}{% if page.type === \"categories\" and not page.title %}{# #}{{ __('title.category') + page_title_suffix }}{# #}{% elif page.type === \"tags\" and not page.title %}{# #}{{ __('title.tag') + page_title_suffix }}{# #}{% elif page.type === \"photos\" and not page.title %}{# #}{{ __('title.photos') + page_title_suffix }}{# #}{% else %}{# #}{{ page.title + page_title_suffix }}{# #}{% endif %}{# #}{% endblock %} {% block page_class %}page-post-detail{% endblock %} {% block content %} \u003cdiv id=\"posts\" class=\"posts-expand\"\u003e {##################} {#### PAGE BLOCK ###} {##################} \u003cdiv class=\"post-block page\"\u003e {% include '_partials/page-header.swig' %} {#################} {#### PAGE BODY ###} {#################} \u003cscript src=\"//at.alicdn.com/t/font_578712_g26jo2kbzd5qm2t9.js\"\u003e\u003c/script\u003e \u003cdiv class=\"post-body{% if theme.han %} han-init-context{% endif %}{% if page.direction \u0026\u0026 page.direction.toLowerCase() === 'rtl' %} rtl{% endif %}\"\u003e \u003cdiv class=\"links-list\"\u003e {% for svg,link in site.data.links %} \u003cdiv class=\"card-box\" title=\"{{ link.info }}\"\u003e \u003ca href=\"{{ link.site }}\" target=\"_blank\"\u003e {% if link.avatar %} \u003cimg class=\"card-avatar\" data-original=\"{{ link.avatar }}\" alt=\"{{ link.nickname }}\"/\u003e {% else %} \u003csvg class=\"card-avatar\" aria-hidden=\"true\"\u003e \u003cuse xlink:href=\"#icon-{{svg+1}}\"\u003e\u003c/use\u003e \u003c/svg\u003e {% endif %} \u003cspan title=\"{{ link.nickname }}\"\u003e@{{ link.nickname }}\u003c/span\u003e \u003c/a\u003e \u003c/div\u003e {% endfor %} \u003c/div\u003e {{ page.content }} \u003c/div\u003e \u003cstyle\u003e /* @Author: lruihao.cn */ .links-list { margin-top: 1rem; display: flex; flex-direction: row; justify-content: space-between; flex-wrap: wrap; } .card-box { width: 150px; height: 200px; font-size: 1rem; text-align: center; background: rgba(255,255,255,0.3); box-sizing: border-box; box-shadow: 3px 3px 5px #aaa; border-radius: 5px; transition-duration: 0.3s; margin-bottom: 1rem; display: flex; flex-direction: column; } .card-box:hover { background: #fff; transform: scale(1.03); box-shadow: 0 0 3px #aaa; } .card-box a { border:none; } .card-avatar { width: 100%!important; height: 150px!important; border-radius: 5px; margin: 0; padding: 0; } .card-box span{ display: block; position: relative; bottom: 1rem; align-self: flex-end; color: #2bbc8a; font-weight: bold; max-width: 100%; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; margin-top: 15px; } .card-box span:hover { color: #d480aa; } \u003c/style\u003e {#####################} {#### END PAGE BODY ###} {#####################} \u003c/div\u003e {% include '_partials/breadcrumb.swig' %} {######################} {#### END PAGE BLOCK ###} {######################} \u003c/div\u003e {% endblock %} {% block sidebar %} {{ sidebar_template.render(false) }} {% endblock %} {% block script_extra %} {% include '_scripts/pages/post-details.swig' %} {% endblock %} 若未使用懒加载请将模板中的data-original属性改为src 若懒加载无法加载预览图请手动添加src=\"/images/loading.gif\" 若 fancybox 显示 alt 内容请更换 fancybox2 或者将 alt 属值删除 \u003cimg class=\"card-avatar\" data-original=\"{{ link.avatar }}\" alt=\"{{ link.nickname }}\"/\u003e 然后hexo n page links新建一个页面文章配置写下如下内容： --- title: 友情链接 layout: links --- 然后在links页面文件夹下面新建文件夹_data，再在里面新建links.yml，内容如下 - nickname: 博採眾長 avatar: http://lruihao.cn/images/avatar.png site: http://lruihao.cn info: 一个菜鸟的博客 - nickname: #友链名称 avatar: #友链头像 site: #友链地址 info: #友链说明 ","date":"2019-03-21","objectID":"/posts/hexo-theme-next/:2:1","tags":["hexo"],"title":"hexo-theme-next @modified LRH","uri":"/posts/hexo-theme-next/"},{"categories":["Memo"],"content":"备案信息自定义 ## ------------------------------------------------------------- ## footer_custom Settings ## ------------------------------------------------------------- beian: enable: true gov: 湘公网安备 43030402000254 号 recordcode: 43030402000254 icp: 湘 ICP 备 18020535 号 ","date":"2019-03-21","objectID":"/posts/hexo-theme-next/:2:2","tags":["hexo"],"title":"hexo-theme-next @modified LRH","uri":"/posts/hexo-theme-next/"},{"categories":["Memo"],"content":"文字抖动特效 \u003cdiv class=\"shaky\"\u003e（づ●'◡'●) づ ❥内容区\u003c/div\u003e （づ●'◡'●) づ ❥内容区 ","date":"2019-03-21","objectID":"/posts/hexo-theme-next/:2:3","tags":["hexo"],"title":"hexo-theme-next @modified LRH","uri":"/posts/hexo-theme-next/"},{"categories":["Memo"],"content":"左下角微信公众号 \\source\\css\\_custom\\customs.styl ","date":"2019-03-21","objectID":"/posts/hexo-theme-next/:2:4","tags":["hexo"],"title":"hexo-theme-next @modified LRH","uri":"/posts/hexo-theme-next/"},{"categories":["Memo"],"content":"相关文章收纳 加入 H5 标签，实现可收纳功能，点击查看详情。 ","date":"2019-03-21","objectID":"/posts/hexo-theme-next/:2:5","tags":["hexo"],"title":"hexo-theme-next @modified LRH","uri":"/posts/hexo-theme-next/"},{"categories":["Memo"],"content":"Chat Services 共 chatra,tidio,daovoice 三个选项，三选一 ## Chatra Support ## See: https://chatra.io ## Dashboard: https://app.chatra.io/settings/general chatra: enable: false async: true id: ## visit Dashboard to get your ChatraID #embed: ## unfinished experimental feature for developers, See: https://chatra.io/help/api/#injectto ## Tidio Support ## See: https://www.tidiochat.com ## Dashboard: https://www.tidiochat.com/panel/dashboard tidio: enable: false key: ## Public Key, get it from Dashboard, See: https://www.tidiochat.com/panel/settings/developer #在线客服 daovoice: true daovoice_app_id: xxxx ## http://www.daovoice.io/ ","date":"2019-03-21","objectID":"/posts/hexo-theme-next/:2:6","tags":["hexo"],"title":"hexo-theme-next @modified LRH","uri":"/posts/hexo-theme-next/"},{"categories":["Memo"],"content":"pdf 和 Mermaid 解析模块 pdf 传送门 pdf: enable: false ## Default height height: 500px pdfobject: cdn: //cdn.jsdelivr.net/npm/pdfobject@2/pdfobject.min.js #cdn: //cdnjs.cloudflare.com/ajax/libs/pdfobject/2.1.1/pdfobject.min.js ## Mermaid tag mermaid: enable: false ## Available themes: default | dark | forest | neutral theme: forest cdn: //cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js #cdn: //cdnjs.cloudflare.com/ajax/libs/mermaid/8.0.0/mermaid.min.js ","date":"2019-03-21","objectID":"/posts/hexo-theme-next/:2:7","tags":["hexo"],"title":"hexo-theme-next @modified LRH","uri":"/posts/hexo-theme-next/"},{"categories":["Memo"],"content":"模仿 csdn 转发样式 ... \u003ca class=\"post-title-link\" href=\"{{ url_for(post.path) }}\" itemprop=\"url\"\u003e + {% if post.repost %} + \u003cspan class=\"repost\"\u003e转\u003c/span\u003e + {% endif %} {{ post.title | default(__('post.untitled'))}} \u003c/a\u003e {% else -%} + {% if post.repost %} + \u003cspan class=\"repost\"\u003e转\u003c/span\u003e + {% endif %} {{- post.title -}} ... .repost { color: #5acc79; border: 1px solid #e7f4df; border-radius: 20px; padding: 2px 5px; font-size: 15px; font-weight: 500; } --- title: xxxx repost: true --- 预览 ","date":"2019-03-21","objectID":"/posts/hexo-theme-next/:2:8","tags":["hexo"],"title":"hexo-theme-next @modified LRH","uri":"/posts/hexo-theme-next/"},{"categories":["Memo"],"content":"热度页面 打开hexo\\themes\\next\\layout新建 top.swig 文件，写下如下内容保存： {% extends '_layout.swig' %} {% import '_macro/sidebar.swig' as sidebar_template %} {% block title %}{# #}{% set page_title_suffix = ' | ' + title %}{# #}{% if page.type === \"categories\" and not page.title %}{# #}{{ __('title.category') + page_title_suffix }}{# #}{% elif page.type === \"tags\" and not page.title %}{# #}{{ __('title.tag') + page_title_suffix }}{# #}{% elif page.type === \"photos\" and not page.title %}{# #}{{ __('title.photos') + page_title_suffix }}{# #}{% else %}{# #}{{ page.title + page_title_suffix }}{# #}{% endif %}{# #}{% endblock %} {% block page_class %}page-post-detail{% endblock %} {% block content %} \u003cdiv id=\"posts\" class=\"posts-expand\"\u003e {##################} {#### PAGE BLOCK ###} {##################} \u003cdiv class=\"post-block page\"\u003e {% include '_partials/page-header.swig' %} {#################} {#### PAGE BODY ###} {#################} \u003cdiv class=\"post-body{% if theme.han %} han-init-context{% endif %}{% if page.direction \u0026\u0026 page.direction.toLowerCase() === 'rtl' %} rtl{% endif %}\"\u003e {{ page.content }} \u003cdiv id=\"top\"\u003e\u003c/div\u003e \u003c/div\u003e \u003cstyle\u003e #top{ display: flex; flex-direction: row; justify-content: space-between; flex-wrap: wrap; width: 100%; min-height: calc({{ page.limit }} * 20px); } #top div{ width: 400px; height: 40px; max-width: 400px; overflow: hidden; white-space: nowrap; text-overflow: ellipsis; } #top a{ color: #555; text-decoration: none; outline: 0; border-bottom: 1px solid #999; word-wrap: break-word; } \u003c/style\u003e \u003cscript src=\"https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js\"\u003e\u003c/script\u003e \u003cscript\u003eAV.initialize(\"{{ theme.valine.appid }}\", \"{{ theme.valine.appkey }}\");\u003c/script\u003e \u003cscript type=\"text/javascript\"\u003e setTimeout(function(){ var time=0 var title=\"\" var url=\"\" var query = new AV.Query('Counter'); query.notEqualTo('id',0); query.descending('time'); query.limit({{ page.limit }}); //设置篇数 query.find().then(function (todo) { for (var i=0;i\u003c{{ page.limit }};i++){ var result=todo[i].attributes; time=result.time; title=result.title; category=result.categories url=result.url; var content=\"\u003cdiv\u003e\"+\"【文章热度：\"+time+\"℃】\"+\"\u003ca href='\"+\"{{ config.url }}\"+\"\"+url+\"'\u003e\"+title+\"\u003c/a\u003e\"+\"\u003c/div\u003e\"; document.getElementById(\"top\").innerHTML+=content; } }, function (error) { console.log(\"error\"); }); },1000) \u003c/script\u003e {#####################} {#### END PAGE BODY ###} {#####################} \u003c/div\u003e {% include '_partials/breadcrumb.swig' %} {######################} {#### END PAGE BLOCK ###} {######################} \u003c/div\u003e {% endblock %} {% block sidebar %} {{ sidebar_template.render(false) }} {% endblock %} {% block script_extra %} {% include '_scripts/pages/post-details.swig' %} {% endblock %} 其中第 36 行改成你自己的 leancloud 的 appid 和 appkey, 比如我的是在主题配置文件里面的 valine 配置下，所以我就写成theme.valine.appid。和我一样就不需要修改，其他自行配置。 然后hexo n page top新建一个页面文章配置写下如下内容，limit 表示显示篇数： --- title: 热度 layout: top limit: 20 --- ","date":"2019-03-21","objectID":"/posts/hexo-theme-next/:2:9","tags":["hexo"],"title":"hexo-theme-next @modified LRH","uri":"/posts/hexo-theme-next/"},{"categories":["Memo"],"content":"复制按钮样式 本来只想简单美化一下变成 night 样式的，后来写完发现 3dbtn 也挺喜欢的。 codeblock: ## Manual define the border radius in codeblock ## Leave it empty for the default 1 border_radius: 5 ## Add copy button on codeblock copy_button: enable: true ## Show text copy result show_result: true ## Style: 'light,night,flat,3dbtn' is currently available, leave it empty or light is default theme style: night ","date":"2019-03-21","objectID":"/posts/hexo-theme-next/:2:10","tags":["hexo"],"title":"hexo-theme-next @modified LRH","uri":"/posts/hexo-theme-next/"},{"categories":["Java"],"content":" 摘要：Java 基本的对象初始化过程，子类的初始化，以及涉及到父类和子类的转化时可能引起混乱的情况。 ","date":"2019-03-21","objectID":"/posts/substatus/:0:0","tags":["Java"],"title":"Java 父类子类的对象初始化过程","uri":"/posts/substatus/"},{"categories":["Java"],"content":"基本初始化过程 对于一个简单类的初始化过程是： static 修饰的模块（static 变量和 static 块） =\u003e 按照代码顺序依次执行。 ↓ 实例变量 及非 static 模块 =\u003e 按照代码顺序依次执行。 ↓ 构造函数 =\u003e 执行对应的构造函数。 ","date":"2019-03-21","objectID":"/posts/substatus/:1:0","tags":["Java"],"title":"Java 父类子类的对象初始化过程","uri":"/posts/substatus/"},{"categories":["Java"],"content":"子类的初始化过程 父类 static 修饰的模块 ↓ 子类 static 修饰模块 ↓ 父类实例变量和非 static 块 ↓ 父类对应构造函数。当子类对应构造函数中没有显示调用时调用的是父类默认的构造函数。 ↓ 子类实例变量和非 static 块 ↓ 子类构造函数 package code0507; public class Demo { public static void main(String[] args) { Sub sub = new Sub(); System.out.println(sub); } } class Super { int a = 6; public Super() { test(); //被子类同名函数覆盖，优先访问子类 test } int b=9; public void test() { System.out.println(a); } } class Sub extends Super { int a = 8; public Sub() { test(); } public void test() { System.out.println(a); } } 运行结果 0 8 ","date":"2019-03-21","objectID":"/posts/substatus/:2:0","tags":["Java"],"title":"Java 父类子类的对象初始化过程","uri":"/posts/substatus/"},{"categories":["OS"],"content":" 双系统默认启动项是 Ubuntu，而日常使用最多的还是 Windows，所以说很不方便，一不小心就开机到 Ubuntu 去了。今天来设置一下。 ","date":"2019-03-21","objectID":"/posts/windefault/:0:0","tags":["linux","windows","ubuntu"],"title":"ubuntu + windows 双系统默认启动项设置","uri":"/posts/windefault/"},{"categories":["OS"],"content":"修改/etc/default/grub文件 同时按住键盘上的“Ctrl Alt T”三个键（即快捷键“Ctrl+Alt+T”），打开终端窗口。在终端内输入 sudo gedit /etc/default/grub 按 Enter 键确认，提示输入用户密码，输入的用户密码是看不见的，不要管它，输入完成确认即可打开 grub 文件。 把 grub 文件中的 GRUB_DEFAULT=0 中的 0 改为 saved, 把 GRUB_TIMEOUT=10 中的 10 改为 5。（这里的 5 表示开机时等待选择操作系统是时间是 5 秒） 在文件末尾添加 GRUB_SAVEDEFAULT=true后保存文件并退出。 ","date":"2019-03-21","objectID":"/posts/windefault/:1:0","tags":["linux","windows","ubuntu"],"title":"ubuntu + windows 双系统默认启动项设置","uri":"/posts/windefault/"},{"categories":["OS"],"content":"更新启动配置文件 在终端输入 sudo update-grub 按 Enter 键确认 ","date":"2019-03-21","objectID":"/posts/windefault/:2:0","tags":["linux","windows","ubuntu"],"title":"ubuntu + windows 双系统默认启动项设置","uri":"/posts/windefault/"},{"categories":["OS"],"content":"重启 sudo reboot或者点击重启，重启到启动菜单时，选择你要更改为默认启动项的系统，按 Enter 键确认启动即可，下次启动时刚刚选择的系统即为默认启动系统，直到你手动选择启动其他的系统为止。以后可以轻松的来回切换默认系统了。 ","date":"2019-03-21","objectID":"/posts/windefault/:3:0","tags":["linux","windows","ubuntu"],"title":"ubuntu + windows 双系统默认启动项设置","uri":"/posts/windefault/"},{"categories":["瞎折腾","PHP"],"content":" 宅音乐播放器，HTML5 网页播放器，集成后台管理及 API 调用，目前正在开发中，敬请关注~ 原项目 由 IT 技术宅 开源，使用 thinkPHP 开发后台。 fork 地址 是我个人学习模仿的库，也是相当于备份源码。 注： 插件修改于明月浩空免费版，仅用于学习交流，无商业价值，如发现商业传播，将禁止软件的免费使用。 ","date":"2019-03-19","objectID":"/posts/player/:0:0","tags":["PHP","ThinkPHP","Layui","MySQL"],"title":"宅音乐播放器","uri":"/posts/player/"},{"categories":["瞎折腾","PHP"],"content":"技术栈 后端：thinkphp 5.1 前端：layui 数据库：mysql ","date":"2019-03-19","objectID":"/posts/player/:1:0","tags":["PHP","ThinkPHP","Layui","MySQL"],"title":"宅音乐播放器","uri":"/posts/player/"},{"categories":["瞎折腾","PHP"],"content":"演示站 已兼容移动端，测试账号仅供测试请勿修改密码！ test test123 https://player.ilt.me/ https://player.lruihao.cn/ ","date":"2019-03-19","objectID":"/posts/player/:2:0","tags":["PHP","ThinkPHP","Layui","MySQL"],"title":"宅音乐播放器","uri":"/posts/player/"},{"categories":["瞎折腾","PHP"],"content":"安装 ","date":"2019-03-19","objectID":"/posts/player/:3:0","tags":["PHP","ThinkPHP","Layui","MySQL"],"title":"宅音乐播放器","uri":"/posts/player/"},{"categories":["瞎折腾","PHP"],"content":"视频安装教程 https://www.bilibili.com/video/av46476706 ","date":"2019-03-19","objectID":"/posts/player/:3:1","tags":["PHP","ThinkPHP","Layui","MySQL"],"title":"宅音乐播放器","uri":"/posts/player/"},{"categories":["瞎折腾","PHP"],"content":"依赖 composer php 5.6+ mysql 5.5+ ","date":"2019-03-19","objectID":"/posts/player/:3:2","tags":["PHP","ThinkPHP","Layui","MySQL"],"title":"宅音乐播放器","uri":"/posts/player/"},{"categories":["瞎折腾","PHP"],"content":"步骤 安装 php 依赖包 composer install 配置数据库，配置链接数据库名以及用户名密码 /config/database.php 创建数据库 字符编码：utf8 -- UTF-8 Unicode 导入数据库脚本，脚本位置 extend/database ","date":"2019-03-19","objectID":"/posts/player/:3:3","tags":["PHP","ThinkPHP","Layui","MySQL"],"title":"宅音乐播放器","uri":"/posts/player/"},{"categories":["瞎折腾","PHP"],"content":"伪静态配置 nginx location / { index index.htm index.html index.php; #访问路径的文件不存在则重写 URL 转交给 ThinkPHP 处理 if (!-e $request_filename) { rewrite ^/(.*)$ /index.php?s=$1 last; break; } } apache 项目自带 apache 静态化无需配置 ","date":"2019-03-19","objectID":"/posts/player/:3:4","tags":["PHP","ThinkPHP","Layui","MySQL"],"title":"宅音乐播放器","uri":"/posts/player/"},{"categories":["瞎折腾","PHP"],"content":"启动项目 添加 public 为 web 根目录 若为 apache 服务器则默认伪静态，nginx 可自行配置伪静态 ","date":"2019-03-19","objectID":"/posts/player/:3:5","tags":["PHP","ThinkPHP","Layui","MySQL"],"title":"宅音乐播放器","uri":"/posts/player/"},{"categories":["瞎折腾","PHP"],"content":"预览 ","date":"2019-03-19","objectID":"/posts/player/:4:0","tags":["PHP","ThinkPHP","Layui","MySQL"],"title":"宅音乐播放器","uri":"/posts/player/"},{"categories":["瞎折腾","PHP"],"content":"首页 ","date":"2019-03-19","objectID":"/posts/player/:4:1","tags":["PHP","ThinkPHP","Layui","MySQL"],"title":"宅音乐播放器","uri":"/posts/player/"},{"categories":["瞎折腾","PHP"],"content":"登陆页面 ","date":"2019-03-19","objectID":"/posts/player/:4:2","tags":["PHP","ThinkPHP","Layui","MySQL"],"title":"宅音乐播放器","uri":"/posts/player/"},{"categories":["瞎折腾","PHP"],"content":"后台首页 ","date":"2019-03-19","objectID":"/posts/player/:4:3","tags":["PHP","ThinkPHP","Layui","MySQL"],"title":"宅音乐播放器","uri":"/posts/player/"},{"categories":["瞎折腾","PHP"],"content":"后台播放器管理页面 ","date":"2019-03-19","objectID":"/posts/player/:4:4","tags":["PHP","ThinkPHP","Layui","MySQL"],"title":"宅音乐播放器","uri":"/posts/player/"},{"categories":["瞎折腾","PHP"],"content":"后台歌单管理页面 ","date":"2019-03-19","objectID":"/posts/player/:4:5","tags":["PHP","ThinkPHP","Layui","MySQL"],"title":"宅音乐播放器","uri":"/posts/player/"},{"categories":["OS"],"content":"极速方便的一键配置与管理，免除繁琐的命令行操作，通过 Web 面板一键即可操作实现。可选择安装 lamp 或者 lnmp 环境，可创建及管理网站，可创建及管理数据库，可创建及管理 FTP 等等。宝塔官网介绍 ","date":"2019-03-18","objectID":"/posts/bt/:0:0","tags":["linux","server","宝塔面板"],"title":"宝塔面板安装","uri":"/posts/bt/"},{"categories":["OS"],"content":"系统要求 操作系统：全新系统（支持 CentOS、Ubuntu、Debian、Fedora、Deepin)， 确保是干净的操作系统，没有安装过其它环境带的 Apache/Nginx/php/MySQL 宝塔 Linux6.0 版本是基于 centos7 开发的，强烈建议使用 centos7.x 系统 内存要求：内存要求最低 512MB，推荐 768MB 以上，纯面板约占系统 60MB 内存. ","date":"2019-03-18","objectID":"/posts/bt/:1:0","tags":["linux","server","宝塔面板"],"title":"宝塔面板安装","uri":"/posts/bt/"},{"categories":["OS"],"content":"安装方法 官方号称 2 分钟装好面板，一键管理服务器。 使用 SSH 连接工具，如宝塔远程桌面助手连接到您的 Linux 服务器后，挂载磁盘，根据系统执行相应命令开始安装（大约 2 分钟完成面板安装）： yum install -y wget \u0026\u0026 wget -O install.sh http://download.bt.cn/install/install_6.0.sh \u0026\u0026 sh install.sh wget -O install.sh http://download.bt.cn/install/install-ubuntu_6.0.sh \u0026\u0026 sudo bash install.sh wget -O install.sh http://download.bt.cn/install/install-ubuntu_6.0.sh \u0026\u0026 bash install.sh wget -O install.sh http://download.bt.cn/install/install_6.0.sh \u0026\u0026 bash install.sh ","date":"2019-03-18","objectID":"/posts/bt/:2:0","tags":["linux","server","宝塔面板"],"title":"宝塔面板安装","uri":"/posts/bt/"},{"categories":["OS"],"content":"搭建 ftp 和云盘服务器 可以很傻瓜式的搭建自己的云盘，和平时用的比较多的 ftp 服务器。搭建静态网站也可以用 ftp 来上传文件。 ","date":"2019-03-18","objectID":"/posts/bt/:3:0","tags":["linux","server","宝塔面板"],"title":"宝塔面板安装","uri":"/posts/bt/"},{"categories":["Memo"],"content":" 下面一些 web 开发的一些总结，还有一些常用到的代码，脚本等！ ","date":"2019-03-18","objectID":"/posts/webbiji/:0:0","tags":["JavaScript"],"title":"web 汇总","uri":"/posts/webbiji/"},{"categories":["Memo"],"content":"front-end ","date":"2019-03-18","objectID":"/posts/webbiji/:1:0","tags":["JavaScript"],"title":"web 汇总","uri":"/posts/webbiji/"},{"categories":["Memo"],"content":"html HTML+CSS oblique 和 intalic 的区别 这两个都是font-style属性的值，这两个值都能实现倾斜的效果，但是有区别的。 intalic: 这个是字体的倾斜，相当于斜体，字体必须有倾斜属性。 oblique: 这个准确地说是让文字倾斜。相当于斜字，字体不一定要有倾斜属性。 title 显示换行 使用\u0026#10;或使用\u0026#13; \u003ca href=\"#\" title=\"第一行\u0026#10; 第二行\u0026#10; 第三行\"\u003e使用`\u0026#10;`\u003c/a\u003e \u003ca href=\"#\" title=\"第一排\u0026#13; 第二排\u0026#13; 第三排\"\u003e使用`\u0026#13;`\u003c/a\u003e 图片类型选择 图片类型选择 ","date":"2019-03-18","objectID":"/posts/webbiji/:1:1","tags":["JavaScript"],"title":"web 汇总","uri":"/posts/webbiji/"},{"categories":["Memo"],"content":"css flexbox Flex 布局将成为未来布局的首选方案，比如说常见的 bootstrap4 的版本就用 flex 替代了 float 来进行排版。 我在网上看到几个很好的教程，图文并茂，一目了然。 A Complete Guide to Flexbox Flex 布局教程：语法篇 实在懒癌发作，笔记本上手抄了笔记我就不写学习总结了，还有网友 Demo 也写了。 ","date":"2019-03-18","objectID":"/posts/webbiji/:1:2","tags":["JavaScript"],"title":"web 汇总","uri":"/posts/webbiji/"},{"categories":["Memo"],"content":"javascript keydown 和 keypress keydown：按下键盘键 keypress：紧接着keydown事件触发（只有按下字符键时触发） 如果用户按下了一个字符键不放，就会重复触发keydown和keypress事件，直到用户松开该键为止。 如果用户按下了一个非字符键不放，就会重复触发keydown事件，直到用户松开该键为止。 详解键盘事件 (keydown，keypress，keyup) textContent、innerText 和 innerHTML 的区别 设置标签中的文本内容，应该使用textContent或innerText（更老）属性，区别在于浏览器支援程度 innerHTML能够获得元素内的所有标签内容，也可以设置标签使之生效。（注意防止 XSS 注入） 如果某个属性在浏览器中不支持，那么这个属性的类型是undefined，判断这个属性的类型是不是undefined，就知道浏览器是否支持。 \u003cscript\u003e // 设置任意的标签中间的任意文本内容 function setInnerText(element, text) { //判断浏览器是否支持这个属性 if (typeof element.textContent == \"undefined\") {//不支持 element.innerText = text; } else {//支持这个属性 element.textContent = text; } }; \u003c/script\u003e ","date":"2019-03-18","objectID":"/posts/webbiji/:1:3","tags":["JavaScript"],"title":"web 汇总","uri":"/posts/webbiji/"},{"categories":["Memo"],"content":"图床方案 自行搭建 比如使用开源图床 ImgURL 搭建的img.lruihao.cn（需要服务器） 使用上传工具加第三方免费空间，比如PicGo + 腾讯云 COS（无需服务器） 使用各大图床 诸如 sm.ms，腾讯云 COS，阿里云 OSS，七牛云，又拍云，Github，微博图床，ImgURL 图床等等 ","date":"2019-03-18","objectID":"/posts/webbiji/:1:4","tags":["JavaScript"],"title":"web 汇总","uri":"/posts/webbiji/"},{"categories":["Memo"],"content":"font-awesome 现在使用 5 的版本，可以使用webfont+css或svg+js \u003clink rel=\"stylesheet\" href=\"https://cdn.staticfile.org/font-awesome/4.7.0/css/font-awesome.css\"\u003e 其他的图标 js \u003cscript src=\"//at.alicdn.com/t/font_578712_g26jo2kbzd5qm2t9.js\"\u003e\u003c/script\u003e \u003csvg class=\"card-avatar\" aria-hidden=\"true\"\u003e \u003cuse xlink:href=\"#icon-{{n+1}}\"\u003e\u003c/use\u003e \u003c!--n 为一个数字--\u003e \u003c/svg\u003e ","date":"2019-03-18","objectID":"/posts/webbiji/:1:5","tags":["JavaScript"],"title":"web 汇总","uri":"/posts/webbiji/"},{"categories":["Memo"],"content":"响应式（自适应） \u003clink rel=\"stylesheet\" href=\"https://apps.bdimg.com/libs/bootstrap/3.3.4/css/bootstrap.min.css\"\u003e \u003cscript src=\"https://apps.bdimg.com/libs/bootstrap/3.3.4/js/bootstrap.min.js\"\u003e \u003cmeta name=\"viewport\" content=\"width=device-width,initial-scale=1.0,maximum-scale=1.0,minimum-scale=1.0,user-scalable=0\"\u003e .col-xs- 超小屏幕 手机 \u003c768px .col-sm- 小屏幕 平板 \u003e=768px .col-md- 中等屏幕 \u003e=992px .col-lg- 大屏幕 \u003e1200px css3 写法 @media （宽度具体调整） /* 手机等小屏幕手持设备 */ @media screen and (min-width: 320px) and (max-width: 480px) { /*手机端 css 样式表*/ } /* 平板之类的宽度 1024 以下设备 */ @media only screen and (min-width: 321px) and (max-width: 1024px) { /*电脑端 css 样式表*/ } link 引入不同 css \u003c!--手机端--\u003e \u003clink rel=\"stylesheet\" type=\"text/css\" href=\"style_phone.css\" media=\"screen and (max-width: 960px)\"/\u003e \u003c!--电脑端--\u003e \u003clink rel=\"stylesheet\" type=\"text/css\" href=\"style_PC.css\" media=\"screen and (min-width: 960px)\"/\u003e ","date":"2019-03-18","objectID":"/posts/webbiji/:1:6","tags":["JavaScript"],"title":"web 汇总","uri":"/posts/webbiji/"},{"categories":["Memo"],"content":"jquery \u003cscript src=\"https://code.jquery.com/jquery-3.3.1.min.js\"\u003e\u003c/script\u003e \u003cscript src=\"https://lib.sinaapp.com/js/jquery/2.0.2/jquery-2.0.2.min.js\"\u003e\u003c/script\u003e \u003cscript src=\"https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js\"\u003e\u003c/script\u003e \u003cscript src=\"http://cdn.bootcss.com/jquery/1.11.0/jquery.min.js\"\u003e\u003c/script\u003e //还有其他的源 ... ","date":"2019-03-18","objectID":"/posts/webbiji/:1:7","tags":["JavaScript"],"title":"web 汇总","uri":"/posts/webbiji/"},{"categories":["Memo"],"content":"QQ 推广链接 QQ 推广 QQ 群 \u003ca target=\"_blank\" href=\"https://wpa.qq.com/msgrd?v=3\u0026uin=1074627678\u0026site=qq\u0026menu=yes\"\u003e\u003cimg border=\"0\" src=\"http://wpa.qq.com/pa?p=2:1074627678:51\" alt=\"点击这里给我发消息\" title=\"点击这里给我发消息\"/\u003e\u003c/a\u003e ","date":"2019-03-18","objectID":"/posts/webbiji/:1:8","tags":["JavaScript"],"title":"web 汇总","uri":"/posts/webbiji/"},{"categories":["Memo"],"content":"Google fonts https://fonts.google.com/ 一般选用国内源镜像替代（待补充 ...） + https://fonts.loli.net + //fonts.lug.ustc.edu.cn ","date":"2019-03-18","objectID":"/posts/webbiji/:1:9","tags":["JavaScript"],"title":"web 汇总","uri":"/posts/webbiji/"},{"categories":["Memo"],"content":"fancybox github 介绍 fancybox 源 \u003clink href=\"https://cdn.bootcss.com/fancybox/3.5.7/jquery.fancybox.min.css\" rel=\"stylesheet\"\u003e \u003cscript src=\"https://cdn.bootcss.com/fancybox/3.5.7/jquery.fancybox.min.js\"\u003e\u003c/script\u003e ","date":"2019-03-18","objectID":"/posts/webbiji/:1:10","tags":["JavaScript"],"title":"web 汇总","uri":"/posts/webbiji/"},{"categories":["Memo"],"content":"back-end 更多学习内容见 学习课件 练习作业 源码+Demo ","date":"2019-03-18","objectID":"/posts/webbiji/:2:0","tags":["JavaScript"],"title":"web 汇总","uri":"/posts/webbiji/"},{"categories":["Java"],"content":" 泛型方法，它在修饰符后，返回值类型前增加了类型参数 (\u003c\u003e) 类型通配符一般使用问号?代替具体的类型实参，注意不是类型形参。 ","date":"2019-03-16","objectID":"/posts/fanxing/:0:0","tags":["泛型","Java"],"title":"java 泛型 test","uri":"/posts/fanxing/"},{"categories":["Java"],"content":"代码 package code0507; public class WildCardTest { public static void main(String[] args) { Box\u003cString\u003ename=new Box\u003cString\u003e(\"hello\"); Box\u003cInteger\u003eage=new Box\u003cInteger\u003e(12); Box\u003cDouble\u003enumber=new Box\u003cDouble\u003e(210.50); Box\u003cInteger\u003epoint=new Box\u003cInteger\u003e(); getData(name); getData(age); getData(number); point.printpoint(520, 1314); point.printpoint(\"me\", \"too\"); } public static void getData(Box\u003c?\u003edata){//类型通配符 System.out.println(\"data:\"+data.getData()); } } class Box\u003cT\u003e{ private T data; public Box() {}//构造方法重载 public Box(T data) { setData(data); } public T getData() { return data; } public void setData(T data) { this.data = data; } //定义泛型方法 public\u003cT1,T2\u003evoid printpoint(T1 x,T2 y){ T1 m=x; T2 n=y; System.out.println(\"This point is:\"+m+\",\"+n); } } ","date":"2019-03-16","objectID":"/posts/fanxing/:1:0","tags":["泛型","Java"],"title":"java 泛型 test","uri":"/posts/fanxing/"},{"categories":["Java"],"content":"运行结果 data:hello data:12 data:210.5 This point is:520,1314 This point is:me,too ","date":"2019-03-16","objectID":"/posts/fanxing/:2:0","tags":["泛型","Java"],"title":"java 泛型 test","uri":"/posts/fanxing/"},{"categories":["Memo"],"content":"基本使用 A: 选择一个工作空间 D:\\develop\\eclipse-SDK-3.7.2-win64\\workspace B: 如何写一个 HelloWorld 案例（代码以项目为基本单位） a: 创建项目（工程） *File -- New -- Java Project *在左边空白处，直接右键 -- New -- Java Project 键入项目名称后直接 Finish。 b: 所有的 java 文件必须写到 src 下面才有效 c: 创建一个包 cn.lruihao d: 在包下创建一个类 HelloWorld 同时让它帮我们写好了 main 方法。 e: 在 main 方法中写内容即可 f: 编译程序 自动编译，在保存的那一刻帮你做好了 g: 运行程序 选择要运行的文件或者在要运行的文件内容中 右键 -- Run as - Java Application 即可 h: 内容显示 在 Console 控制台显示内容 ","date":"2019-03-15","objectID":"/posts/eclipseuse/:1:0","tags":["eclipse","Java"],"title":"eclipse 的基本使用","uri":"/posts/eclipseuse/"},{"categories":["Memo"],"content":"Eclipse 的基本设置 A: 程序的编译和运行的环境配置（如果你的 Eclipse 启动没有问题，就不要配置了） B: 去掉默认注释（可以不用改） C: 行号的显示和隐藏 显示：在代码区域的最左边的空白区域，右键 -- Show Line Numbers 即可。 隐藏：把上面的动作再做一次。 D: 字体大小及颜色 a:Java 代码区域的字体大小和颜色： window -- Preferences -- General -- Appearance -- Colors And Fonts -- Java 修改 -- Java Edit Text Font b: 控制台 window -- Preferences -- General -- Appearance -- Colors And Fonts -- Debug -- Console font c: 其他文件 window -- Preferences -- General -- Appearance -- Colors And Fonts -- Basic -- Text Font E: 窗体给弄乱了，怎么办 window -- Reset Perspective F: 控制台找不到了 Window--Show View—Console ","date":"2019-03-15","objectID":"/posts/eclipseuse/:2:0","tags":["eclipse","Java"],"title":"eclipse 的基本使用","uri":"/posts/eclipseuse/"},{"categories":["Memo"],"content":"快捷键的使用 A: 内容辅助键 Alt+/ 起提示作用 main+alt+/,syso+alt+/, 给出其他提示 B: 快捷键 格式化 ctrl+shift+f 导入包 ctrl+shift+o 注释 ctrl+/ ctrl+shift+/,ctrl+shift+\\ 代码上下移动 选中代码 alt+上/下箭头 查看源码 选中类名 (F3 或者 Ctrl+鼠标点击） ","date":"2019-03-15","objectID":"/posts/eclipseuse/:3:0","tags":["eclipse","Java"],"title":"eclipse 的基本使用","uri":"/posts/eclipseuse/"},{"categories":["Memo"],"content":"Eclipse 中如何提高开发效率 A: 自动生成构造方法 a: 无参构造方法 在代码区域右键--source--Generate Constructors from Superclass b: 带参构造方法 在代码区域右键--source--Generate Constructors using fields.. -- finish B: 自动生成 get/set 方法 在代码区域右键--source--Generate Getters and Setters... ","date":"2019-03-15","objectID":"/posts/eclipseuse/:4:0","tags":["eclipse","Java"],"title":"eclipse 的基本使用","uri":"/posts/eclipseuse/"},{"categories":["Java"],"content":" java 中匿名类用的最多的地方就是可视化界面设计中，特别是将事件监听器注册到某个组件上的时候。 ","date":"2019-03-15","objectID":"/posts/qframe/:0:0","tags":["GUI","Java"],"title":"匿名类在可视化界面中的应用","uri":"/posts/qframe/"},{"categories":["Java"],"content":"代码 package cn.lruihao; import java.awt.event.*; import javax.swing.*; public class QFrame extends JFrame { public QFrame() { JButton jbtnew=new JButton(\"New\");//新建按钮 JPanel panel=new JPanel();//面板容器 panel.add(jbtnew);//添加组件 add(panel); jbtnew.addActionListener(new ActionListener() { //新建一匿名类，并将该对应的事件监听器注册到“新建”按钮 就 jbtnew 上 @Override public void actionPerformed(ActionEvent e) { JOptionPane.showMessageDialog(null, \"单击了新建按钮\"); System.out.println(\"lruihao.cn\"); } }); } public static void main(String[] args) { JFrame frame=new QFrame(); frame.setTitle(\"QFrame\"); frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE); frame.setLocationRelativeTo(null); frame.pack(); frame.setVisible(true); } } 创建一个可视化界面，界面中有一个按钮，单击按钮显示“单击了新建按钮”。 ","date":"2019-03-15","objectID":"/posts/qframe/:1:0","tags":["GUI","Java"],"title":"匿名类在可视化界面中的应用","uri":"/posts/qframe/"},{"categories":["Java"],"content":"结果 ","date":"2019-03-15","objectID":"/posts/qframe/:2:0","tags":["GUI","Java"],"title":"匿名类在可视化界面中的应用","uri":"/posts/qframe/"},{"categories":["Java"],"content":"参考 JOptionPane 的使用 ","date":"2019-03-15","objectID":"/posts/qframe/:3:0","tags":["GUI","Java"],"title":"匿名类在可视化界面中的应用","uri":"/posts/qframe/"},{"categories":["JavaScript"],"content":" 模仿知乎的卡片式链接，idea 来自 [兰州小红鸡] ","date":"2019-03-15","objectID":"/posts/linkcard/:0:0","tags":["JavaScript","hexo"],"title":"模仿知乎卡片式链接","uri":"/posts/linkcard/"},{"categories":["JavaScript"],"content":"源码 2021/10/2 1:29 更新 这是一种后加载，创建linkcard.js放到source/js/src/，然后在next\\layout\\_macro\\post.swig中引用 function cardLink() { let $cardLinks = document.querySelectorAll('.card-link'); if ($cardLinks.length === 0) { return; } //插入样式 let $linkStyle = document.createElement('style'); $linkStyle.innerHTML = '.card-link,.card-link:hover{text-decoration:none;border:none!important;color:inherit!important}.card-link{position:relative;display:block;margin:1em auto;width:390px;box-sizing:border-box;border-radius:12px;max-width:100%;overflow:hidden;color:inherit;text-decoration:none}.ztext{word-break:break-word;line-height:1.6}.card-link-backdrop{position:absolute;top:0;left:0;right:0;bottom:0;background-image:url(/images/card-link-bg.jpg);background-repeat:no-repeat;-webkit-filter:blur(20px);filter:blur(20px);background-size:cover;background-position:center}.card-link,.card-link:hover{text-decoration:none;border:none!important;color:inherit!important}.card-link-content{position:relative;display:flex;align-items:center;justify-content:space-between;padding:12px;border-radius:inherit;background-color:rgba(246,246,246,0.88)}.card-link-text{overflow:hidden}.card-link-title{display:-webkit-box;-webkit-line-clamp:2;overflow:hidden;text-overflow:ellipsis;max-height:calc(16px * 1.25 * 2);font-size:16px;font-weight:500;line-height:1.25;color:#1a1a1a}.card-link-meta{display:flex;margin-top:4px;font-size:14px;line-height:20px;color:#999;white-space:nowrap}.card-link-url{display: inline-flex;align-items: center;}.card-link-imageCell{margin-left:8px;border-radius:6px}.card-link-image{display:block;width:60px;height:60px;border-radius:inherit}'; document.querySelector('body').appendChild($linkStyle); //渲染 DOM for (let $cardLink of $cardLinks) { $cardLink.innerHTML = `\u003cspan class='card-link-backdrop'\u003e\u003c/span\u003e\u003cspan class='card-link-content'\u003e\u003cspan class='card-link-text'\u003e\u003cspan class='card-link-title'\u003e${$cardLink.innerText}\u003c/span\u003e\u003cspan class='card-link-meta'\u003e\u003cspan class='card-link-url'\u003e\u003csvg class='Zi Zi--InsertLink' fill='currentColor' viewBox='0 0 24 24' width='17' height='17'\u003e\u003cpath d='M6.77 17.23c-.905-.904-.94-2.333-.08-3.193l3.059-3.06-1.192-1.19-3.059 3.058c-1.489 1.489-1.427 3.954.138 5.519s4.03 1.627 5.519.138l3.059-3.059-1.192-1.192-3.059 3.06c-.86.86-2.289.824-3.193-.08zm3.016-8.673l1.192 1.192 3.059-3.06c.86-.86 2.289-.824 3.193.08.905.905.94 2.334.08 3.194l-3.059 3.06 1.192 1.19 3.059-3.058c1.489-1.489 1.427-3.954-.138-5.519s-4.03-1.627-5.519-.138L9.786 8.557zm-1.023 6.68c.33.33.863.343 1.177.029l5.34-5.34c.314-.314.3-.846-.03-1.176-.33-.33-.862-.344-1.176-.03l-5.34 5.34c-.314.314-.3.846.03 1.177z' fill-rule='evenodd'\u003e\u003c/path\u003e\u003c/svg\u003e\u003c/span\u003e${$cardLink.href}\u003c/span\u003e\u003c/span\u003e\u003cspan class='card-link-imageCell'\u003e\u003cimg class='card-link-image' alt='card-link icon' src='/images/linkicon.png'\u003e\u003c/span\u003e\u003c/span\u003e`; } } window.onload = () =\u003e { cardLink(); }; ","date":"2019-03-15","objectID":"/posts/linkcard/:1:0","tags":["JavaScript","hexo"],"title":"模仿知乎卡片式链接","uri":"/posts/linkcard/"},{"categories":["JavaScript"],"content":"使用 \u003c!--知乎卡片链接--\u003e \u003cscript type=\"text/javascript\" src=\"/js/src/card-link.js\"\u003e\u003c/script\u003e html 链接写法，a 标签加上class=\"card-link\" \u003ca href=\"https://github.com/Lruihao/lruihao.github.io\" target=\"_blank\" class=\"card-link\"\u003eLruihao 博客\u003c/a\u003e Lruihao 博客 https://github.com/Lruihao/lruihao.github.io ","date":"2019-03-15","objectID":"/posts/linkcard/:2:0","tags":["JavaScript","hexo"],"title":"模仿知乎卡片式链接","uri":"/posts/linkcard/"},{"categories":["OS"],"content":" 我的 Ubuntu 和 Windows 双系统是 Ubuntu 是第一启动项，所以总是开机忘记点下键，一进 Ubuntu 系统时间就不对了（总是少了 8 小时），回到 Windows 时间也是错的。知道是错的调整一下还好。忘记调了有时候真的会误事。比如说 git 版本控制提交会遇到问题种种等。 ","date":"2019-03-15","objectID":"/posts/ubuntutime/:0:0","tags":["ubuntu","linux","windows"],"title":"win10,ubuntu 双系统时间不一致","uri":"/posts/ubuntutime/"},{"categories":["OS"],"content":"原因 在安装 Ubuntu 和 Windows 双系统的情况下，Ubuntu 的时间总会和 Windows 的时间相差 8 小时，原因在于 widows 认为 BIOS 时间是本地时间，Ubuntu 认为 BIOS 时间是 UTC 时间，即协调世界时，(Universal Time Coordinated) 英文缩写，是由国际无线电咨询委员会规定和推荐，并由国际时间局 (BIH) 负责保持的以秒为基础的时间标度。UTC 相当于本初子午线（即经度 0 度）上的平均太阳时，过去曾用格林威治平均时 (GMT) 来表示。北京时间比 UTC 时间早 8 小时，以 1999 年 1 月 1 日 00:00 UTC 为例，UTC 时间是零点，北京时间为 1999 年 1 月 1 日早上 8 点整。)，所以我们在时间上面相隔了 8 个小时。这个时候 bios 的时间和系统的时间当然是不一致，一个代表 utc 时间，一个代表 cst（＋ 8 时区），即我们常用的时间。 ","date":"2019-03-15","objectID":"/posts/ubuntutime/:1:0","tags":["ubuntu","linux","windows"],"title":"win10,ubuntu 双系统时间不一致","uri":"/posts/ubuntutime/"},{"categories":["OS"],"content":"方法一 在 Windows 下 进行如下修改：（博主 win10,win7 自测） 以管理员身份运行 CMD（win+x 后选择 Windows Powershell（管理员） Reg add HKLM\\SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation /v RealTimeIsUniversal /t REG_DWORD /d 1 重启看看时间发现 ok 了。 ","date":"2019-03-15","objectID":"/posts/ubuntutime/:2:0","tags":["ubuntu","linux","windows"],"title":"win10,ubuntu 双系统时间不一致","uri":"/posts/ubuntutime/"},{"categories":["OS"],"content":"方法二 老版 Ubuntu（Ubuntu10 左右）： 修改 /etc/default/rcS 文件 编辑 /etc/default/rcS 将 UTC=yes改成 UTC=no 。 新版 Ubuntu（Ubuntu16.04）： 新版本的 Ubuntu 使用 systemd 启动之后，时间也改成了由 timedatectl 来管理，此方法就不适用了。 $sudo timedatectl set-local-rtc 1 先在 ubuntu 下更新一下时间，确保时间无误： $sudo apt-get install ntpdate $sudo ntpdate time.windows.com 然后将时间更新到硬件上： $sudo hwclock --localtime --systohc 重新进入 windows10，发现时间恢复正常了！ ","date":"2019-03-15","objectID":"/posts/ubuntutime/:3:0","tags":["ubuntu","linux","windows"],"title":"win10,ubuntu 双系统时间不一致","uri":"/posts/ubuntutime/"},{"categories":["JavaScript"],"content":" 以前在 QQ 里面聊天的时候发现，有些链接是卡片式的链接，像知乎里那些一样，就好奇为啥我的域名没有生成卡片。 查了一下百度知道了大概就是 qq 没有抓取到你的网站的 xml。并在其他教程中得到了一个强制提交抓取的 url https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshareget_urlinfo?url= 于是就有了脚本刷新的想法。简陋的写了一下。 ","date":"2019-03-08","objectID":"/posts/qqxml/:0:0","tags":["JavaScript"],"title":"QQ 强制生成卡片式链接","uri":"/posts/qqxml/"},{"categories":["JavaScript"],"content":"批量式刷新 //设置刷新前缀 url=首页地址（最好使用 https） var base_src = 'https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshareget_urlinfo?url=https://lruihao.cn'; //用户地址 //var custom_src = \"https://lruihao.cn\"; //初始化工作地址 var new_src = ''; function createArrayAndOpenWindow() { //alert(\"number function\"); //定义数组存储后缀 var numberArray = new Array(4); //存储后缀 numberArray[0] = '/about/'; numberArray[1] = '/categories/'; numberArray[2] = '/tags/'; numberArray[3] = '/archives/'; //numberArray[4] = \"/guestbook/\"; //遍历 for (var i = 0; i \u003c numberArray.length; i++) { new_src = base_src + numberArray[i]; //打开该地址 open_new(); //清空后缀 new_src = ''; } } //负责打开窗口，并关闭 function open_new() { var new_window = window.open(new_src, '', 'width=400,height=200'); setTimeout(function () { //开启后 200ms（单页）关闭，速度自行把握数组越大时间越多 new_window.close(); }, 2000); } window.onload = function () { createArrayAndOpenWindow(); //设置定时函数，疯狂刷新直到 xml 出现内容 var timer = setInterval('createArrayAndOpenWindow()', 2000); }; ","date":"2019-03-08","objectID":"/posts/qqxml/:1:0","tags":["JavaScript"],"title":"QQ 强制生成卡片式链接","uri":"/posts/qqxml/"},{"categories":["JavaScript"],"content":"单链接刷新 \u003cdiv style=\"text-align: center;\"\u003e \u003cinput type=\"text\" id=\"input\" value=\"\" /\u003e \u003cinput type=\"button\" value=\"疯狂刷新\" onclick=\"yanzheng()\" /\u003e \u003c/div\u003e //设置刷新前缀 url=首页地址（最好使用 https）https://lruihao.cn var base_src = 'https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshareget_urlinfo?url='; //用户地址 var custom_src = ''; //初始化工作地址 var new_src = ''; //负责打开窗口，并关闭 function open_new() { var new_window = window.open(new_src, '', 'width=400,height=200'); setTimeout(function () { //开启后 200ms 关闭 new_window.close(); }, 200); } // 获取验证用户输入 function yanzheng() { var Input = document.getElementById('input'); var oValue = Input.value; custom_src = oValue; new_src = base_src + custom_src; if (oValue == 0) { alert('请输入地址'); } else { var timer = setInterval('open_new()', 200); } } ","date":"2019-03-08","objectID":"/posts/qqxml/:2:0","tags":["JavaScript"],"title":"QQ 强制生成卡片式链接","uri":"/posts/qqxml/"},{"categories":["JavaScript"],"content":"demo 线上 demo 仅做参考请自行下载 效果 ","date":"2019-03-08","objectID":"/posts/qqxml/:3:0","tags":["JavaScript"],"title":"QQ 强制生成卡片式链接","uri":"/posts/qqxml/"},{"categories":["OS"],"content":"外存的组织方式 ","date":"2019-03-04","objectID":"/posts/cipanadmin/:1:0","tags":["OS","磁盘"],"title":"磁盘存储器的管理","uri":"/posts/cipanadmin/"},{"categories":["OS"],"content":"连续组织方式 连续组织方式的优点 顺序访问容易 顺序访问速度快 连续组织方式的缺点 分配连续的存储空间 必须知道文件长度 删除与插入数据不灵活 动态增长的文件分配空间问题 ","date":"2019-03-04","objectID":"/posts/cipanadmin/:1:1","tags":["OS","磁盘"],"title":"磁盘存储器的管理","uri":"/posts/cipanadmin/"},{"categories":["OS"],"content":"链接组织方式 隐式链接 显式链接 ","date":"2019-03-04","objectID":"/posts/cipanadmin/:1:2","tags":["OS","磁盘"],"title":"磁盘存储器的管理","uri":"/posts/cipanadmin/"},{"categories":["OS"],"content":"FAT 技术 FAT12 早期的 FAT12 文件系统 以簇为单位的 FAT12 文件系统 FAT16 FAT32 ","date":"2019-03-04","objectID":"/posts/cipanadmin/:1:3","tags":["OS","磁盘"],"title":"磁盘存储器的管理","uri":"/posts/cipanadmin/"},{"categories":["OS"],"content":"NTFS 的文件组织方式 NTFS 新特征 磁盘组织 文件的组织 ","date":"2019-03-04","objectID":"/posts/cipanadmin/:1:4","tags":["OS","磁盘"],"title":"磁盘存储器的管理","uri":"/posts/cipanadmin/"},{"categories":["OS"],"content":"索引组织方式 单级索引组织方式 多级索引组织方式 增量式索引组织方式 增量式索引组织方式的基本思想 UNIX System V 的组织方式 直接地址 一次间接地址 多次间接地址 ","date":"2019-03-04","objectID":"/posts/cipanadmin/:1:5","tags":["OS","磁盘"],"title":"磁盘存储器的管理","uri":"/posts/cipanadmin/"},{"categories":["OS"],"content":"文件存储空间的管理 ","date":"2019-03-04","objectID":"/posts/cipanadmin/:2:0","tags":["OS","磁盘"],"title":"磁盘存储器的管理","uri":"/posts/cipanadmin/"},{"categories":["OS"],"content":"空闲表法和空闲链表法 空闲表法 空闲表 存储空间的分配与回收 空闲链表法 空闲盘块链 空闲盘区链 ","date":"2019-03-04","objectID":"/posts/cipanadmin/:2:1","tags":["OS","磁盘"],"title":"磁盘存储器的管理","uri":"/posts/cipanadmin/"},{"categories":["OS"],"content":"位示图法 位示图 盘块的分配（步骤） 顺序扫描示图 转换盘块号 修改位示图 盘块的回收（步骤） 盘块号转换成行列号 修改位示图 ","date":"2019-03-04","objectID":"/posts/cipanadmin/:2:2","tags":["OS","磁盘"],"title":"磁盘存储器的管理","uri":"/posts/cipanadmin/"},{"categories":["OS"],"content":"成组链接法 空闲盘块的组织 空闲盘块的分配与回收 ","date":"2019-03-04","objectID":"/posts/cipanadmin/:2:3","tags":["OS","磁盘"],"title":"磁盘存储器的管理","uri":"/posts/cipanadmin/"},{"categories":["OS"],"content":"提高磁盘 I/O 速度的途径 ","date":"2019-03-04","objectID":"/posts/cipanadmin/:3:0","tags":["OS","磁盘"],"title":"磁盘存储器的管理","uri":"/posts/cipanadmin/"},{"categories":["OS"],"content":"磁盘高速缓存 数据交付方式 数据交付 指针交付 置换算法 周期性地写回磁盘 ","date":"2019-03-04","objectID":"/posts/cipanadmin/:3:1","tags":["OS","磁盘"],"title":"磁盘存储器的管理","uri":"/posts/cipanadmin/"},{"categories":["OS"],"content":"提高磁盘 I/O 速度的其他方法 提前读 延迟写 优化物理块的分布 虚拟盘 ","date":"2019-03-04","objectID":"/posts/cipanadmin/:3:2","tags":["OS","磁盘"],"title":"磁盘存储器的管理","uri":"/posts/cipanadmin/"},{"categories":["OS"],"content":"廉价磁盘冗余阵列 (RAID) 并行交叉存取 RAID 的分级 RAID 0 级 RAID 1 级 RAID 2 级 RAID 3 级 RAID 4 级 RAID 5 级 RAID 6 级和 RAID 7 级 RAID 的优点 可靠性高 磁盘 I/O 速度高 性价比高 ","date":"2019-03-04","objectID":"/posts/cipanadmin/:3:3","tags":["OS","磁盘"],"title":"磁盘存储器的管理","uri":"/posts/cipanadmin/"},{"categories":["OS"],"content":"提高磁盘可靠性的技术 ","date":"2019-03-04","objectID":"/posts/cipanadmin/:4:0","tags":["OS","磁盘"],"title":"磁盘存储器的管理","uri":"/posts/cipanadmin/"},{"categories":["OS"],"content":"第一级容错技术 SFT-Ⅰ 双份目录和双份文件分配表 热修复重定向和写后读校验 热修复重定向 写后读校验方式 ","date":"2019-03-04","objectID":"/posts/cipanadmin/:4:1","tags":["OS","磁盘"],"title":"磁盘存储器的管理","uri":"/posts/cipanadmin/"},{"categories":["OS"],"content":"第二级容错技术 SFT-Ⅱ 磁盘镜像 磁盘双工 ","date":"2019-03-04","objectID":"/posts/cipanadmin/:4:2","tags":["OS","磁盘"],"title":"磁盘存储器的管理","uri":"/posts/cipanadmin/"},{"categories":["OS"],"content":"基于集群技术的容错功能 双机热备份模式 双机互为备份模式 公用磁盘模式 ","date":"2019-03-04","objectID":"/posts/cipanadmin/:4:3","tags":["OS","磁盘"],"title":"磁盘存储器的管理","uri":"/posts/cipanadmin/"},{"categories":["OS"],"content":"后备系统 磁带机 硬盘 移动磁盘 固定硬盘驱动器 光盘驱动器 CD-ROM 和 DVD-ROM 刻录机 ","date":"2019-03-04","objectID":"/posts/cipanadmin/:4:4","tags":["OS","磁盘"],"title":"磁盘存储器的管理","uri":"/posts/cipanadmin/"},{"categories":["OS"],"content":"数据一致性控制 ","date":"2019-03-04","objectID":"/posts/cipanadmin/:5:0","tags":["OS","磁盘"],"title":"磁盘存储器的管理","uri":"/posts/cipanadmin/"},{"categories":["OS"],"content":"事务 事务的定义 事务记录 恢复算法 undo \u003cTi\u003e redo \u003cTi\u003e ","date":"2019-03-04","objectID":"/posts/cipanadmin/:5:1","tags":["OS","磁盘"],"title":"磁盘存储器的管理","uri":"/posts/cipanadmin/"},{"categories":["OS"],"content":"检查点 检查点的作用 新的恢复算法 ","date":"2019-03-04","objectID":"/posts/cipanadmin/:5:2","tags":["OS","磁盘"],"title":"磁盘存储器的管理","uri":"/posts/cipanadmin/"},{"categories":["OS"],"content":"并发控制 利用互斥锁实现“顺序性” 利用互斥锁和共享锁实现顺序性 ","date":"2019-03-04","objectID":"/posts/cipanadmin/:5:3","tags":["OS","磁盘"],"title":"磁盘存储器的管理","uri":"/posts/cipanadmin/"},{"categories":["OS"],"content":"重复数据的数据一致性问题 重复文件的一致性 链接数一致性检查 ","date":"2019-03-04","objectID":"/posts/cipanadmin/:5:4","tags":["OS","磁盘"],"title":"磁盘存储器的管理","uri":"/posts/cipanadmin/"},{"categories":["JavaScript"],"content":" 请点击验证码处：↑ ","date":"2019-03-04","objectID":"/posts/js-vcode/:0:0","tags":["JavaScript"],"title":"JS 验证码","uri":"/posts/js-vcode/"},{"categories":["JavaScript"],"content":" 验证码 JS 来源互联网 \u003cscript type=\"text/javascript\"\u003e //设置一个全局的变量，便于保存验证码 var code; function createCode(){ //首先默认 code 为空字符串 code = ''; //设置长度，这里看需求，我这里设置了 4 var codeLength = 4; var codeV = document.getElementById('code'); //设置随机字符 var random = new Array(0,1,2,3,4,5,6,7,8,9,'A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R', 'S','T','U','V','W','X','Y','Z'); //循环 codeLength 我设置的 4 就是循环 4 次 for(var i = 0; i \u003c codeLength; i++){ //设置随机数范围，这设置为 0 ~ 36 var index = Math.floor(Math.random()*36); //字符串拼接 将每次随机的字符 进行拼接 code += random[index]; } //将拼接好的字符串赋值给展示的 Value codeV.value = code; } //下面就是判断是否== 的代码，无需解释，也可以结合 ajax 在后台做判断 function validate(){ var Input = document.getElementById('input'); var oValue = Input.value.toUpperCase(); if(oValue ==0){ alert('请输入验证码'); }else if(oValue != code){ Input.value = ''; alert('验证码不正确，请重新输入'); createCode(); }else{ Input.value = ''; alert('验证码正确！');//window.open('http://lruihao.cn','_self'); } } //设置此处的原因是每次进入界面展示一个随机的验证码，不设置则为空 window.onload = function (){ createCode(); } \u003c/script\u003e ","date":"2019-03-04","objectID":"/posts/js-vcode/:1:0","tags":["JavaScript"],"title":"JS 验证码","uri":"/posts/js-vcode/"},{"categories":["Java"],"content":" 引用 继承的好处： 提高了代码的复用性 提高了代码的维护性 让类与类之间产生了关系，是多态的前提 继承的弊端：类的耦合性很强 设计原则：低耦合，高内聚。 耦合：类与类的关系。 内聚：自己完成事情的能力。 ","date":"2019-01-24","objectID":"/posts/jicheng/:0:0","tags":["Java"],"title":"java 继承 test","uri":"/posts/jicheng/"},{"categories":["Java"],"content":"java 中的继承特点 Java 只支持单继承，不支持多继承。Java 支持多层继承（继承体系） class A { } class B extends A { } /* class C extends A,B { } */ class C extends B { } class ExtendsDemo { public static void main(String[] args) { } } ","date":"2019-01-24","objectID":"/posts/jicheng/:0:1","tags":["Java"],"title":"java 继承 test","uri":"/posts/jicheng/"},{"categories":["Java"],"content":"java 中的继承注意事项 子类只能继承父类所有非私有的成员（成员方法和成员变量） 子类不能继承父类的构造方法，但是可以通过 super 关键字去访问父类构造方法。 不要为了部分功能而去继承 那么，我们什么时候考虑使用继承呢？ 继承中类之间体现的是：”is a”的关系。 如果两个类满足这个关系：xxx is a yyy，那么他们就可以使用继承。 Student,Person 对 Dog,Animal 对 Dog,Pig 错 ","date":"2019-01-24","objectID":"/posts/jicheng/:0:2","tags":["Java"],"title":"java 继承 test","uri":"/posts/jicheng/"},{"categories":["Java"],"content":"继承 继承间的构造方法关系：创建子类对象，会先去访问父类的构造方法。对父类的数据进行初始化。 package jicheng; class Fu{ public int num = 10; public Fu(){ System.out.println(\"父类\"); } } class Zi extends Fu{ public int num = 20; public Zi(){ System.out.println(\"子类\"); } public void show(){ int num = 30; System.out.println(num);//30 System.out.println(this.num);//20 System.out.println(super.num);//10 } } public class test { public static void main(String[] args) { Zi z = new Zi(); z.show(); } } 程序运行结果 父类 子类 30 20 10 ","date":"2019-01-24","objectID":"/posts/jicheng/:0:3","tags":["Java"],"title":"java 继承 test","uri":"/posts/jicheng/"},{"categories":["Java"],"content":"代码块 代码块的执行顺序： 静态代码块 –\u003e 构造代码块 –\u003e 构造方法 代码的执行特点：静态代码块只执行一次，构造代码块每次调用构造方法都执行。 package jicheng; class Fu { static { System.out.println(\"父类静态代码块\"); } { System.out.println(\"父类构造代码块\"); } public Fu() { System.out.println(\"父类构造方法\"); } } class Zi extends Fu { static { System.out.println(\"子类静态代码块\"); } { System.out.println(\"子类构造代码块\"); } public Zi() { System.out.println(\"子类构造方法\"); } } public class test { public static void main(String[] args) { Zi z = new Zi(); Zi z2 = new Zi(); } } 程序运行结果： 父类静态代码块 子类静态代码块 父类构造代码块 父类构造方法 子类构造代码块 子类构造方法 父类构造代码块 父类构造方法 子类构造代码块 子类构造方法 ","date":"2019-01-24","objectID":"/posts/jicheng/:0:4","tags":["Java"],"title":"java 继承 test","uri":"/posts/jicheng/"},{"categories":["Java"],"content":"继承间的成员关系 成员方法 不同名称： 非常简单，一看就知道调用谁 相同名称： 先在子类找，再在父类找 … 找不到就报错。 成员变量： 名字不同： 非常的简单，一看就知道使用的是谁。 名字相同： 就近原则。 使用变量的时候，会先找局部范围。 如果想直接使用成员变量，加关键字：this 即可。 如果想直接使用父类的成员变量，加关键字：super 即可。 ","date":"2019-01-24","objectID":"/posts/jicheng/:0:5","tags":["Java"],"title":"java 继承 test","uri":"/posts/jicheng/"},{"categories":["Java"],"content":"注意事项 子类中所有的构造方法默认都会访问父类中空参数的构造方法。为什么呢？因为子类会继承父类中的数据，可能还会使用父类的数据。所以，子类初始化之前，一定要先完成父类数据的初始化。 ","date":"2019-01-24","objectID":"/posts/jicheng/:0:6","tags":["Java"],"title":"java 继承 test","uri":"/posts/jicheng/"},{"categories":["Memo"],"content":" 本以为 coding pages 与腾讯云合作后会更好，没想到正是这种初期 bug 不断，速度也是非常慢。比 gitee, 甚至 github 都要慢很多了。所以决定放弃 coding 了，本想挂到云服务器上，但是这个云服务器只续费了半年，可能不会再续费，前几天看到用腾讯云的 cos 桶 xml 制作动态相册的文章，知道了对象存储这个玩意，腾讯云 COS 提供免费 50G 的存储空间，还有 CDN 加速服务，我觉得是个不错的选择，部署后发现速度还挺好。 适用于 hexo, hugo 等静态博客的部署。 ","date":"2019-01-22","objectID":"/posts/cos-hexo/:0:0","tags":["hexo","hugo","腾讯云 cos 桶","对象存储"],"title":"利用腾讯云对象存储 COS 桶托管 hexo 博客","uri":"/posts/cos-hexo/"},{"categories":["Memo"],"content":"创建存储桶 打开腾讯云控制台–云产品–存储–对象存储，然后创建存储桶。 ","date":"2019-01-22","objectID":"/posts/cos-hexo/:1:0","tags":["hexo","hugo","腾讯云 cos 桶","对象存储"],"title":"利用腾讯云对象存储 COS 桶托管 hexo 博客","uri":"/posts/cos-hexo/"},{"categories":["Memo"],"content":"开启静态网站设置 在基础配置打开静态网站（关掉强制 https) ","date":"2019-01-22","objectID":"/posts/cos-hexo/:2:0","tags":["hexo","hugo","腾讯云 cos 桶","对象存储"],"title":"利用腾讯云对象存储 COS 桶托管 hexo 博客","uri":"/posts/cos-hexo/"},{"categories":["Memo"],"content":"绑定域名 SSL 设置 ","date":"2019-01-22","objectID":"/posts/cos-hexo/:3:0","tags":["hexo","hugo","腾讯云 cos 桶","对象存储"],"title":"利用腾讯云对象存储 COS 桶托管 hexo 博客","uri":"/posts/cos-hexo/"},{"categories":["Memo"],"content":"域名解析，添加记录 去 dns 服务商添加域名解析记录 CNAME 指向上面的域名 ","date":"2019-01-22","objectID":"/posts/cos-hexo/:4:0","tags":["hexo","hugo","腾讯云 cos 桶","对象存储"],"title":"利用腾讯云对象存储 COS 桶托管 hexo 博客","uri":"/posts/cos-hexo/"},{"categories":["Memo"],"content":"hexo 设置 安装插件 npm install hexo-deployer-cos --save 站点配置文件 deploy: type: cos bucket: yourBucketName #cos 桶名称 appId: yourAppId #cos 桶名称后数字 secretId: yourSecretId #云 API 密钥 secretKey: yourSecretKey #云 API 密钥 region: yourRegion #所属地域 发布还是一样的 hexo clean hexo g -d 结果类似于 ","date":"2019-01-22","objectID":"/posts/cos-hexo/:5:0","tags":["hexo","hugo","腾讯云 cos 桶","对象存储"],"title":"利用腾讯云对象存储 COS 桶托管 hexo 博客","uri":"/posts/cos-hexo/"},{"categories":["Memo"],"content":"CDN 刷新 每次更新博客内容完后，都要登陆腾讯云 CDN–缓存刷新，手动刷新一下 CDN。 用脚本在每次更新后刷新 安装 npm install qcloud-cdn-node-sdk --save 创建qcloudcdn.js放入script文件夹 const qcloudSDK = require('qcloud-cdn-node-sdk'); qcloudSDK.config({ secretId: '你的 ID', secretKey: '你的密钥' }); qcloudSDK.request( 'RefreshCdnDir', { 'dirs.1': 'http://博客地址' }, (res) =\u003e { console.log(res); } ); ","date":"2019-01-22","objectID":"/posts/cos-hexo/:6:0","tags":["hexo","hugo","腾讯云 cos 桶","对象存储"],"title":"利用腾讯云对象存储 COS 桶托管 hexo 博客","uri":"/posts/cos-hexo/"},{"categories":["Memo"],"content":"自动 CDN 刷新配置 （推荐） 进入腾讯云，找到 函数计算 -\u003e CDN 缓存刷新函数 -\u003e 创建 CDN 缓存刷新函数 修改 index.js 内容后重新部署 'use strict'; const CosSdk = require('cos-nodejs-sdk-v5'); const CdnSdk = require('./common/CdnSdk'); const CdnRefreshTask = require('./common/CdnRefreshTask'); const { getParams, getObjectUrl, logger, getLogSummary } = require('./common/utils'); exports.main_handler = async (event, context, callback) =\u003e { /** * parse param from event and process.env */ const { objects, cdnHosts, secretId, secretKey, token } = getParams(event); logger({ title: 'param is parsed success, param as follow: ', data: { objects, cdnHosts, event } }); /** * init cos instance */ if (!secretId || !secretKey || !token) { throw new Error(`secretId, secretKey or token is missing`); } const cdnSdkInstance = new CdnSdk({ secretId, secretKey, token }); const cosInstance = new CosSdk({ SecretId: secretId, SecretKey: secretKey, XCosSecurityToken: token }); const taskList = objects.map(({ bucket, region, key }) =\u003e { /* 变更内容-START */ const purgeUrls = []; cdnHosts.forEach((host) =\u003e { const tempUrl = getObjectUrl({ cosInstance, bucket, region, key, origin: `${/^(http\\:\\/\\/|https\\:\\/\\/)/.test(host) ? '' : 'https://'}${host}` }); purgeUrls.push(tempUrl); // 如果以 /index.html 结尾，则增加目录首页/。 // 例如 https://www.xxxx.com/index.html, 则增加 https://www.xxxx.com/。 if (tempUrl.lastIndexOf('/index.html') == tempUrl.length - 11) { purgeUrls.push(tempUrl.substr(0, tempUrl.length - 10)); } }); return new CdnRefreshTask({ cdnSdkInstance, urls: purgeUrls }); /* 变更内容-END */ }); const taskResults = []; for (const task of taskList) { const results = await task.runPurgeTasks(); taskResults.push(...results); } logger({ title: 'cdn refresh full logs:', data: taskResults }); const { status, messages } = getLogSummary(taskResults); logger({ messages: messages.map((item) =\u003e item.replace(/\\,\\ /g, '\\n')) }); if (status === 'fail') { throw messages.join('; '); } else { return messages.join('; '); } }; ","date":"2019-01-22","objectID":"/posts/cos-hexo/:7:0","tags":["hexo","hugo","腾讯云 cos 桶","对象存储"],"title":"利用腾讯云对象存储 COS 桶托管 hexo 博客","uri":"/posts/cos-hexo/"},{"categories":["Java"],"content":"主要方法 static type[] copyof(type[] original,int length) static int binarysearch(type[] a,type key) static boolean equals(type[] a,type[] b) static void fill(type[] a,type val) static void fill(type[] a,int fromindex,int toindex,type val) static void sort(type[] a) ","date":"2019-01-18","objectID":"/posts/java-arrays/:0:1","tags":["Java","Collator","Comparator"],"title":"Arrays 类及基本使用","uri":"/posts/java-arrays/"},{"categories":["Java"],"content":"实例代码 package Arrays; import java.text.Collator; import java.util.Arrays; import java.util.Comparator; public class ArraysDemo { public static void main(String agrs[]) { Integer arr[]=new Integer[9]; for(int i=0;i\u003c9;i++) arr[i]=(int)(Math.random()*100); //显示，排序数组 System.out.print(\"原内容：\"); display(arr); Arrays.sort(arr); System.out.print(\"排序后：\"); display(arr); //将值-1 分配给数组 arr 中下标从 0 到 3-1 的位置 Arrays.fill(arr, 0,3,-1); System.out.print(\"fill() 后：\"); display(arr); //搜索 23 System.out.print(\"值 23 的位置：\"); int index =Arrays.binarySearch(arr, 23);//二分查找 System.out.print(index);//如果查找不到，index 为负 System.out.print(\"\\n 插入 0 在 3 号位置：\"); Arrays.fill(arr,3,4,0); display(arr); System.out.print(\"值 0 的位置：\"); index =Arrays.binarySearch(arr, 0); System.out.print(index); Integer arr2[]=new Integer[8]; arr2=Arrays.copyOf(arr, arr2.length); //复制 8 个 System.out.print(\"\\n 复制后的数组：\"); display(arr2); if(Arrays.equals(arr, arr2)) System.out.println(\"两数组相同！\"); else System.out.println(\"两数组不相同！\"); System.out.println(\"----------------------------------------\"); String[] str = {\"计算机\",\"黄桑\",\"通信\",\"李瑞豪\"}; Arrays.sort(str); for(int i=0;i\u003cstr.length;i++) System.out.print(str[i]+\" \"); System.out.println(\"\"); //Collator 类是用来执行分语言环境的字符串比较，这里用的 CHINA Comparator com=Collator.getInstance(java.util.Locale.CHINA);//获取 Comparator 对象，参数表示按中文排序 //根据指定的 \"比较器\" 产生的顺序对 \"指定对象数组\" 进行排序 Arrays.sort(str,com);//sort(T[] a,Comparator\u003c?super T\u003ec) for(int i=0;i\u003cstr.length;i++) System.out.print(str[i]+\" \"); } static void display(Integer arr[]) { for(int i=0;i\u003carr.length;i++) System.out.print(arr[i]+\" \"); System.out.println(\"\"); } } ","date":"2019-01-18","objectID":"/posts/java-arrays/:0:2","tags":["Java","Collator","Comparator"],"title":"Arrays 类及基本使用","uri":"/posts/java-arrays/"},{"categories":["Java"],"content":"程序运行结果 原内容：41 0 44 96 49 96 30 6 87 排序后：0 6 30 41 44 49 87 96 96 fill() 后：-1 -1 -1 41 44 49 87 96 96 值 23 的位置：-4 插入 0 在 3 号位置：-1 -1 -1 0 44 49 87 96 96 值 0 的位置：3 复制后的数组：-1 -1 -1 0 44 49 87 96 两数组不相同！ ---------------------------------------- 李瑞豪 计算机 通信 黄桑 黄桑 计算机 李瑞豪 通信 ","date":"2019-01-18","objectID":"/posts/java-arrays/:0:3","tags":["Java","Collator","Comparator"],"title":"Arrays 类及基本使用","uri":"/posts/java-arrays/"},{"categories":["Memo"],"content":" 首先在主题配置文件添加以下关键字 recent_posts: enable: true search: true post: false sidebar: false icon: history title: 近期文章 layout: block ","date":"2019-01-16","objectID":"/posts/recent-posts/:0:0","tags":["hexo"],"title":"在搜索、文章底部、侧栏添加最近文章模块","uri":"/posts/recent-posts/"},{"categories":["Memo"],"content":"侧栏 在 next/layout/_macro/sidebar.swig 中的 if theme.links 对应的 endif 后面。 {% if theme.recent_posts.enable and theme.recent_posts.sidebar %} \u003cdiv class=\"links-of-blogroll motion-element {{ \"links-of-blogroll-\" + theme.recent_posts.layout }}\"\u003e \u003cdiv class=\"links-of-blogroll-title\"\u003e \u003ci class=\"fa fa-history fa-{{ theme.recent_posts.icon | lower }}\" aria-hidden=\"true\"\u003e\u003c/i\u003e {{ theme.recent_posts.title }} \u003c/div\u003e \u003cul class=\"links-of-blogroll-list\"\u003e {% set posts = site.posts.sort('-date') %} {% for post in posts.slice('0', '3') %} \u003cli\u003e \u003ca href=\"{{ url_for(post.path) }}\" title=\"{{ post.title }}\" target=\"_blank\"\u003e{{ post.title }}\u003c/a\u003e \u003c/li\u003e {% endfor %} \u003c/ul\u003e \u003c/div\u003e {% endif %} ","date":"2019-01-16","objectID":"/posts/recent-posts/:1:0","tags":["hexo"],"title":"在搜索、文章底部、侧栏添加最近文章模块","uri":"/posts/recent-posts/"},{"categories":["Memo"],"content":"搜索结果处添加 找到路径H:\\hexo\\themes\\hexo-theme-next\\layout\\_partials\\search下localsearch.swig文件 把\u003cdiv id=\"local-search-result\"\u003e\u003c/div\u003e修改成以下内容（这里显示 15 篇） \u003cdiv id=\"local-search-result\"\u003e {% if theme.recent_posts.enable and theme.recent_posts.search %} \u003cdiv style=\"text-align: center;padding: 3px 0 0;\"\u003e \u003cdiv style=\"margin-top: 20px;font-size: 18px;font-weight: 600;border-bottom: 1px solid #ccc;\"\u003e \u003ci class=\"fa fa-{{ theme.recent_posts.icon }}\" aria-hidden=\"true\"\u003e\u003c/i\u003e {{ theme.recent_posts.title }} \u003c/div\u003e \u003cul style=\"margin: 0;padding: 0;list-style: none;\"\u003e {% set posts = site.posts.sort('-date') %} {% for post in posts.slice('0', '15') %} \u003cli\u003e \u003ca href=\"{{ url_for(post.path) }}\" title=\"{{ post.title }}\" target=\"_blank\"\u003e{{ post.title }}\u003c/a\u003e \u003c/li\u003e {% endfor %} \u003c/ul\u003e \u003c/div\u003e {% endif %} \u003c/div\u003e ","date":"2019-01-16","objectID":"/posts/recent-posts/:2:0","tags":["hexo"],"title":"在搜索、文章底部、侧栏添加最近文章模块","uri":"/posts/recent-posts/"},{"categories":["Memo"],"content":"文章尾部添加 把代码加在H:\\hexo\\themes\\hexo-theme-next\\layout\\_macro\\post.swig里的相应位置（我加在 tags 后） {% if not is_index and theme.recent_posts.enable and theme.recent_posts.post %} \u003cdiv style=\"text-align: center;padding: 10px 0 0;\"\u003e \u003cdiv style=\"margin: 60px 0px 10px;font-size: 18px;border-bottom: 1px solid #eee;\"\u003e \u003ci class=\"fa fa-{{ theme.recent_posts.icon }}\" aria-hidden=\"true\"\u003e\u003c/i\u003e {{ theme.recent_posts.title }} \u003c/div\u003e \u003cul style=\"margin: 0;padding: 0;list-style: none;font-size: 11px;\"\u003e {% set posts = site.posts.sort('-date') %} {% for post in posts.slice('0', '5') %} \u003ca href=\"{{ url_for(post.path) }}\" title=\"{{ post.title }}\" target=\"_blank\"\u003e{{ post.title }}\u003c/a\u003e\u0026emsp; {% endfor %} \u003c/ul\u003e \u003c/div\u003e {% endif %} ","date":"2019-01-16","objectID":"/posts/recent-posts/:3:0","tags":["hexo"],"title":"在搜索、文章底部、侧栏添加最近文章模块","uri":"/posts/recent-posts/"},{"categories":["Memo"],"content":"其他 可尝试将-date改为-update ","date":"2019-01-16","objectID":"/posts/recent-posts/:4:0","tags":["hexo"],"title":"在搜索、文章底部、侧栏添加最近文章模块","uri":"/posts/recent-posts/"},{"categories":["Java"],"content":" 大一刚学 c 的时候以前写过 c 语言版 的。 Math: 针对数学进行运算的类 特点：没有构造方法，因为它的成员都是静态的 产生随机数： public static double random(): 产生随机数，范围 [0.0,1.0) 产生 1-100 之间的随机数 int number = (int)(Math.random()*100)+1; 猜数字小游戏案例 class MathDemo { public static void main(String[] args) { //获取随机数 //double d = Math.random(); //System.out.println(d); /* for(int x=0; x\u003c10; x++) { //System.out.println(Math.random()); System.out.println(Math.random()*100); } */ //我们如何获取 1-100 之间的随机数呢？ for(int x=0; x\u003c100; x++) { int number = (int)(Math.random()*100)+1; System.out.println(number); } } } ","date":"2019-01-15","objectID":"/posts/mathclass/:0:0","tags":["Java"],"title":"java 猜数字小游戏（Math 类）","uri":"/posts/mathclass/"},{"categories":["Java"],"content":"小游戏 该游戏可以由程序随机产生或由用户输入四个 0 到 9 之间的数字，且不重复。玩游戏者通过游戏提示输入八次来匹配上面所输入的数字。A 表示位置正确且数字正确，B 表示数字正确而位置不正确。 算法： 可以直接算出 A 类的数目，但是 B 类的数目直接算出或许会很麻烦，正好我们可以先算出 C 类数目恰好减去 A 类就是 B 类了。 package caishuzi; import java.util.Scanner; class Num { private int[] a= {0,0,0,0}; public Num() {} public void setx() { /*for(int i=0;i\u003c4;i++) { a[i]=(int)(Math.random()*10); }*/ //为了四个互不相同的随机数 a[0]=(int)Math.random()*10+1; for(int i=1;i\u003c4;i++) { int t=(int)(Math.random()*10); for(int j=0;j\u003ci;j++) { if(t==a[j]) { t=(int)(Math.random()*10); j=0; } } a[i]=t; } } public int[] getx() { return a; } public void show() { System.out.println(); for(int i=0;i\u003c4;i++) System.out.print(a[i]+\" \"); System.out.println(); } } public class caishuzi { public static void main(String agrs[]) { int a[] = {0,0,0,0},b[] = {0,0,0,0}; System.out.println(\"* * * *\\n 请输入 4 个数字！A 表示位置数字都正确，B 表示数字正确位置错误。\"); Scanner sc=new Scanner(System.in); Num n=new Num(); n.setx(); a=n.getx(); /*for(int i=0;i\u003c4;i++) System.out.print(a[i]+\" \"); n.show();*/ for(int k=0;k\u003c10;k++) {//猜测次数 int A=0,B=0,C=0; for(int i=0;i\u003c4;i++) { b[i]=sc.nextInt(); } sc.close(); for(int i=0;i\u003c4;i++){ if (b[i]==a[i])A++; for(int j=0;j\u003c4;j++){ C=b[i]==a[j]?++C:C;//C 表示猜测数内和随机数中 A 类和 B 类数的数目 if (b[i]==a[j])break; } } B=C-A;// 关键算法（感叹数学魅力） if(A==4) { System.out.println(\"恭喜猜对啦！\"); }else { System.out.println(A+\"A\"+B+\"B\"); } } } } ","date":"2019-01-15","objectID":"/posts/mathclass/:0:1","tags":["Java"],"title":"java 猜数字小游戏（Math 类）","uri":"/posts/mathclass/"},{"categories":["Java"],"content":"一次游戏过程 * * * * 请输入 4 个数字！A 表示位置数字都正确，B 表示数字正确位置错误。 0 1 2 3 0A1B 0 1 2 4 0A1B 0 1 2 5 1A1B 6 1 2 5 1A2B 1 6 2 5 3A0B 1 6 7 5 恭喜猜对啦！ ","date":"2019-01-15","objectID":"/posts/mathclass/:0:2","tags":["Java"],"title":"java 猜数字小游戏（Math 类）","uri":"/posts/mathclass/"},{"categories":["Java"],"content":"面向对象思想（理解） 面向对象是基于面向过程的一种编程思想 思想特点： A: 是一种更符合我们思考习惯的思想 B: 把复杂的问题简单化 C: 让我们从执行者变成了指挥者 举例： A: 洗衣服 B: 吃饭 C: 买电脑 举例并代码体现 把大象装进冰箱 ","date":"2019-01-15","objectID":"/posts/duixiang/:0:1","tags":["面向对象","Java"],"title":"面向对象基础知识总结","uri":"/posts/duixiang/"},{"categories":["Java"],"content":"类与对象（掌握） 我们学习编程是为了把现实世界的事物用编程语言描述来实现信息化。 现实世界事物是如何表达的呢？ 属性：外在特征 行为：内在行为 我们学习的是 java 语言，它最基本的单位是类。 所以我们要学会用类来体现一个事物。 类：是一组相关的属性和行为的集合 对象：是该类事物的具体个体。 举例： 学生 类 张三 对象 ","date":"2019-01-15","objectID":"/posts/duixiang/:0:2","tags":["面向对象","Java"],"title":"面向对象基础知识总结","uri":"/posts/duixiang/"},{"categories":["Java"],"content":"类的组成（掌握） 成员变量 其实就是变量，只不过定义在类中，方法外，并且可以不用初始化。 成员方法 其实就是方法，只不过不需要 static 了 案例： 学生类 class Student { String name; int age; public void study() {} } ","date":"2019-01-15","objectID":"/posts/duixiang/:0:3","tags":["面向对象","Java"],"title":"面向对象基础知识总结","uri":"/posts/duixiang/"},{"categories":["Java"],"content":"类的使用（掌握） 创建对象 格式：类名 对象名 = new 类名 (); 使用成员 成员变量：对象名。变量名； 成员方法：对象名。方法名 (…); ","date":"2019-01-15","objectID":"/posts/duixiang/:0:4","tags":["面向对象","Java"],"title":"面向对象基础知识总结","uri":"/posts/duixiang/"},{"categories":["Java"],"content":"成员变量和局部变量的区别（理解） 在类中的位置不同 A: 成员变量 类中，方法外 B: 局部变量 方法的形式参数，或者方法体中 在内存中的位置不同 A: 成员变量 在堆中 B: 局部变量 在栈中 生命周期不同 A: 成员变量 随着对象的存在而存在，随着对象的消失而消失 B: 局部变量 随着方法的调用而存在，随着方法的调用完毕而消失 初始化值不同 A: 成员变量 有默认初始化值 B: 局部变量 没有默认值，必须先声明，赋值，最后才能使用 ","date":"2019-01-15","objectID":"/posts/duixiang/:0:5","tags":["面向对象","Java"],"title":"面向对象基础知识总结","uri":"/posts/duixiang/"},{"categories":["Java"],"content":"形式参数问题（理解） 基本类型 基本类型作为形式参数，需要的是该基本类型的值。 引用类型 引用类型作为形式参数，需要的是该引用类型的地址值。（对象） ","date":"2019-01-15","objectID":"/posts/duixiang/:0:6","tags":["面向对象","Java"],"title":"面向对象基础知识总结","uri":"/posts/duixiang/"},{"categories":["Java"],"content":"匿名对象（理解） 匿名对象：没有名字的对象。是对象的简化书写方式。 使用场景 A: 调用方法，仅仅只调用一次 B: 作为实际参数传递 ","date":"2019-01-15","objectID":"/posts/duixiang/:0:7","tags":["面向对象","Java"],"title":"面向对象基础知识总结","uri":"/posts/duixiang/"},{"categories":["Java"],"content":"封装（掌握） 隐藏实现细节，提供公共的访问方式 好处： A: 隐藏实现细节，提供公共的访问方式 B: 提高了代码的复用性 C: 提高了代码的安全性 使用原则 A: 把成员变量隐藏 B: 给出该成员变量对应的公共访问方式 ","date":"2019-01-15","objectID":"/posts/duixiang/:0:8","tags":["面向对象","Java"],"title":"面向对象基础知识总结","uri":"/posts/duixiang/"},{"categories":["Java"],"content":"private 关键字（掌握） 是一个权限修饰符 可以修饰类的成员（成员变量和成员方法） 仅仅在本类中可以访问，对外提供对应的 GetXXX()，SetXXX() 等方法 标准代码： class Student { private String name; private int age; public void setName(String n) { name = n; } public String getName() { return name; } public void setAge(int a) { age = a; } public int getAge() { return age; } public void study() {} } ","date":"2019-01-15","objectID":"/posts/duixiang/:0:9","tags":["面向对象","Java"],"title":"面向对象基础知识总结","uri":"/posts/duixiang/"},{"categories":["Java"],"content":"this 关键字（掌握） this：代表本类的对象 应用场景： 解决了局部变量隐藏成员变量的问题。 其他用法和 super 一起讲。 标准代码： class Student { private String name; private int age; public void setName(String name) {//局部变量 this.name = name; } public String getName() { return name; } public void setAge(int age) { this.age = age; } public int getAge() { return age; } public void show() { System.out.println(\"姓名是：\"+name+\", 年龄是：\"+age); } public void study() { System.out.println(\"学生爱学习\"); } public void eat() { System.out.println(\"学生要吃饭\"); } public void sleep() { System.out.println(\"学生想睡觉\"); } } class StudentTest { public static void main(String[] args) { Student s = new Student(); s.setName(\"林青霞\"); s.setAge(28); s.show(); s.study(); s.eat(); s.sleep(); System.out.println(\"姓名是：\"+s.getName()); System.out.println(\"年龄是：\"+s.getAge()); } } ","date":"2019-01-15","objectID":"/posts/duixiang/:0:10","tags":["面向对象","Java"],"title":"面向对象基础知识总结","uri":"/posts/duixiang/"},{"categories":["Java"],"content":"构造方法（掌握） 作用：对对象的数据进行初始化。 特点： A: 方法名和类名相同 B: 没有返回值类型 C: 没有返回值 注意事项 A: 如果我们没写构造方法，系统将默认给出无参构造方法 B: 如果我们写了构造方法，系统将不再给出默认无参构造方法 建议：我们自己手动给出无参构造方法 给成员变量赋值： A: 无参+setXxx() B: 带参 一个标准的代码： class Student { private String name; private int age; public Student() {} public Student(String name,int age) {//构造方法 this.name = name; this.age = age; } public void setName(String name) { this.name = name; } public String getName() { return name; } public void setAge(int age) { this.age = age; } public int getAge() { return age; } public void show() { System.out.println(\"姓名是：\"+name+\", 年龄是：\"+age); } } class StudentTest { public static void main(String[] args) { //无参+setXxx() Student s = new Student(); s.setName(\"林青霞\"); s.setAge(28); s.show(); //带参 Student ss = new Student(\"张曼玉\",20); ss.show(); } } ","date":"2019-01-15","objectID":"/posts/duixiang/:0:11","tags":["面向对象","Java"],"title":"面向对象基础知识总结","uri":"/posts/duixiang/"},{"categories":["Java"],"content":"对象的初始化过程（理解） Student s = new Student(); 做了哪些事情 A: 加载 Student.class 文件进内存 B: 在栈中为 s 开辟空间 C: 在堆中为学生对象开辟空间 D: 为学生对象的成员变量赋默认值 E: 为学生对象的成员变量赋显示值 F: 通过构造方法给成员变量赋值 G: 对象构造完毕，把地址赋值给 s 变量 ","date":"2019-01-15","objectID":"/posts/duixiang/:0:12","tags":["面向对象","Java"],"title":"面向对象基础知识总结","uri":"/posts/duixiang/"},{"categories":["Java"],"content":"static 关键字（掌握） 是一个状态修饰符。静态的意思 它可以修饰成员变量和成员方法 特点： A: 随着类的加载而加载 B: 优先于对象存在 C: 被所有对象共享 这也是判断我们是不是该使用静态的条件 举例：饮水机（可共享 static) 和水杯例子。 D: 可以通过类名调用 静态修饰的内容，可以通过类名调用，也可以通过对象名调用 方法访问特点 A: 普通成员方法 可以访问静态成员变量，非静态成员变量，静态成员方法，非静态成员方法 B: 静态成员方法 只能访问静态成员变量，静态成员方法 简记：静态只能访问静态 注意： 静态中是不能有 this 的。 先进内存的不能访问后进内存的。反之可以。 /* 班级编号应该是被班级每个人都共享的，所以定义一个就应该可以了。 而姓名和年龄，每个人应该是不一样的，所以，每个对象，都应该定义自己的。 在 java 中，用什么来表示成员变量是被共享的呢？static */ class Student { //姓名 String name; //年龄 int age; //班级编号 //String classNumber; static String classNumber; public Student(String name,int age) { this.name = name; this.age = age; } public Student(String name,int age,String classNumber) { this.name = name; this.age = age; this.classNumber = classNumber; } public void show() { System.out.println(name+\"---\"+age+\"---\"+classNumber); } } class StudentDemo { public static void main(String[] args) { //创建学生对象 Student s1 = new Student(\"林青霞\",28,\"20150306\"); s1.show(); /* Student s2 = new Student(\"马云\",35,\"20150306\"); s2.show(); Student s3 = new Student(\"马化腾\",33,\"20150306\"); s3.show(); */ Student s2 = new Student(\"马云\",35); s2.show(); Student s3 = new Student(\"马化腾\",33); s3.show(); } } /* static: 静态关键字。 作用： 可以修饰成员变量和成员方法 特点： A: 随着类的加载而加载 B: 优先于对象存在 C: 被类的所有对象共享 这也是我们判断是否使用静态关键字的条件 饮水机：可以被静态修饰 水杯：不可以被静态修饰 D: 可以通过类名调用 我们的调用既可以是对象，还可以是类名 */ class Student { public void show() { System.out.println(\"show\"); } public static void show2() { System.out.println(\"show2\"); } } class StudentDemo2 { public static void main(String[] args) { Student s = new Student(); s.show(); s.show2(); Student.show2(); //Student.show();\u0026ensp; } } /* static 的注意事项： A: 在静态方法中是没有 this 关键字的 因为静态是随着类的加载而加载，优先于对象而存在。而 this 是随着对象的创建而存在。 先进内存的， 不能访问后进内存的；而后进内存的，可以访问先进内存的。 B: 静态只能访问静态。 非静态的成员方法： 可以访问静态成员变量，非静态成员变量，静态成员方法，非静态成员方法 静态的成员方法： 只能访问静态的成员变量，静态的成员方法 */ /* class Student { private String name; public static void setName(String name) {//\u0026ensp; 静态方法不能用 this this.name = name; } public void show() { System.out.println(name); } }*/ class Demo { int x = 10; static int y = 20; public void show() { System.out.println(x); System.out.println(y); } public static void show2() { //System.out.println(x);\u0026ensp; System.out.println(y);//√ } public void show3() { show(); show2(); } public static void show4() { //show(); 只能访问静态的成员方法 show2(); } } class StudentDemo3 { public static void main(String[] args) { //Student.setName(\"林青霞\"); } } ","date":"2019-01-15","objectID":"/posts/duixiang/:0:13","tags":["面向对象","Java"],"title":"面向对象基础知识总结","uri":"/posts/duixiang/"},{"categories":["Java"],"content":"静态成员变量和普通成员变量的区别（理解） 所属不同 静态属于类的，称为类变量 非静态属于对象的，称为对象变量，实例变量 内存空间不同 静态在方法区的静态区 非静态在堆内存 生命周期不同 静态随着类的加载而加载，随着类的消失而消失 非静态随着对象的创建而存在，随着对象的消失而消失 调用不同 静态可以通过类名调用，也可以通过对象名调用。建议通过类名调用 非静态只能通过对象名调用 ","date":"2019-01-15","objectID":"/posts/duixiang/:0:14","tags":["面向对象","Java"],"title":"面向对象基础知识总结","uri":"/posts/duixiang/"},{"categories":["Java"],"content":"main 方法是静态的（理解） public static void main(String[] args) public: 访问权限修饰符，表示最大的访问权限，被 jvm 调用，所有权限要够大。 static: 被 jvm 调用，不用创建对象，直接类名访问 void: 被 jvm 调用，不需要给 jvm 返回值 main: 一个通用的名称，虽然不是关键字，但是被 jvm 识别 String[] args: 早期出现是为了接收键盘录入数据的。 ","date":"2019-01-15","objectID":"/posts/duixiang/:0:15","tags":["面向对象","Java"],"title":"面向对象基础知识总结","uri":"/posts/duixiang/"},{"categories":["Java"],"content":"实例 /*求和*/ class Demo { private int x; private int y; public Demo() {} public Demo(int x,int y) { this.x = x; this.y = y; } public void setX(int x) { this.x = x; } public int getX() { return x; } public void setY(int y) { this.y = y; } public int getY() { return y; } //成员变量已经有 x,y 了。这里就没有必要在定义了 /* public int sum(int x,int y) { return x + y; } */ public int sum() { return x + y; } } class Test { public static void main(String[] args) { Demo d = new Demo(); d.setX(10); d.setY(20); int result = d.sum(); System.out.println(result); } } /*求和*/ class Demo { public int sum(int x,int y) { return x + y; } } class Test2 { public static void main(String[] args) { Demo d = new Demo(); int result = d.sum(10,20); System.out.println(result); } } /* 定义一个员工类，自己分析出几个成员， 然后给出成员变量，构造方法，getXxx()/setXxx() 方法， 以及一个显示所有成员信息的方法。并测试。 Employee： 成员变量：员工编号，姓名，职位 构造方法：无参，带参 成员方法：getXxx()/setXxx() 方法，show() */ class Employee { private String eid; private String name; private String job; public Employee() {} public Employee(String eid,String name,String job) { this.eid = eid; this.name = name; this.job = job; } public void setEid(String eid) { this.eid = eid; } public String getEid() { return eid; } public void setName(String name) { this.name = name; } public String getName() { return name; } public void setJob(String job) { this.job = job; } public String getJob() { return job; } public void show() { System.out.println(\"员工编号是：\"+eid+\", 姓名是：\"+name+\", 职位是：\"+job); } } class EmployeeDemo { public static void main(String[] args) { //无参 Employee e = new Employee(); e.setEid(\"itcast007\"); e.setName(\"周星驰\"); e.setJob(\"高级工程师\"); e.show(); //带参 Employee e2 = new Employee(\"itcast003\",\"刘德华\",\"挖掘机工程师\"); e2.show(); } } ","date":"2019-01-15","objectID":"/posts/duixiang/:0:16","tags":["面向对象","Java"],"title":"面向对象基础知识总结","uri":"/posts/duixiang/"},{"categories":["Java"],"content":"java 类中的成员变量和方法访问权限 关键词 同一个类 同一个包 不同包中的子类 不同包中的非子类 private √ default √ √ protected √ √ √ public √ √ √ √ ","date":"2019-01-15","objectID":"/posts/duixiang/:0:17","tags":["面向对象","Java"],"title":"面向对象基础知识总结","uri":"/posts/duixiang/"},{"categories":["Java"],"content":" 水仙花数（Narcissistic number）也被称为超完全数字不变数（pluperfect digital invariant, PPDI）、自恋数、自幂数、阿姆斯壮数或阿姆斯特朗数（Armstrong number），水仙花数是指一个 3 位数，它的每个位上的数字的 3 次幂之和等于它本身（例如：1^3 + 5^3+ 3^3 = 153）。 ","date":"2019-01-14","objectID":"/posts/java-range/:0:0","tags":["水仙花数","Java"],"title":"java 水仙花数（循环）","uri":"/posts/java-range/"},{"categories":["Java"],"content":"定义 水仙花数只是自幂数的一种，严格来说 3 位数的 3 次幂数才称为水仙花数。 附：其他位数的自幂数名字 一位自幂数：独身数 两位自幂数：没有 三位自幂数：水仙花数 四位自幂数：四叶玫瑰数 五位自幂数：五角星数 六位自幂数：六合数 七位自幂数：北斗七星数 八位自幂数：八仙数 九位自幂数：九九重阳数 十位自幂数：十全十美数 package xunhuan; import java.util.Scanner; public class shuixianhua { public static void main(String[] agrs) { System.out.print(\"指定最大位数 N:\"); Scanner input = new Scanner(System.in); int N = input.nextInt(); input.close(); for (int i = 3; i \u003c= N; i++) { int a[] = new int[i]; int num = (int) Math.pow(10, i - 1) + 1; System.out.print(i + \"位的水仙花数有：\\t\"); while (num \u003c= Math.pow(10, i)) { int sum = 0; for (int j = 0; j \u003c i; j++) a[j] = (int) (num / Math.pow(10, j) % 10);//取各个位的数 for (int j = 0; j \u003c i; j++) sum = sum + (int) Math.pow(a[j], i); if (num == sum) System.out.print(num + \"\\t\"); num++; } System.out.print(\"\\n\"); } } } 由于 int 精度限制，最多算到 9 位，而且使用常规算法，算到 8，9 位的时候就特别慢了。 指定最大位数 N:10 3 位的水仙花数有： 153 370 371 407 4 位的水仙花数有： 1634 8208 9474 5 位的水仙花数有： 54748 92727 93084 6 位的水仙花数有： 548834 7 位的水仙花数有： 1741725 4210818 9800817 9926315 8 位的水仙花数有： 24678050 24678051 88593477 9 位的水仙花数有： 146511208 ","date":"2019-01-14","objectID":"/posts/java-range/:0:1","tags":["水仙花数","Java"],"title":"java 水仙花数（循环）","uri":"/posts/java-range/"},{"categories":["Java"],"content":"记忆格式： (1) 导包： import java.util.Scanner; 注意：位置在 class 的上面。 (2) 创建键盘录入对象： Scanner sc = new Scanner(System.in); (3) 获取数据 int i = sc.nextInt(); (4) 练习： A: 求两个数据的和 B: 获取两个数据中较大的值 C: 获取三个数据中较大的值 D: 比较两个数是否相等 ","date":"2019-01-14","objectID":"/posts/java-input/:0:1","tags":["Java"],"title":"java 录入数据","uri":"/posts/java-input/"},{"categories":["Java"],"content":"实例 package helloworld; import java.util.Scanner; public class helloworld { public static void main(String[] args) { Scanner sc = new Scanner(System.in); int i=sc.nextInt(),j=sc.nextInt(),k=sc.nextInt(); sc.close(); System.out.println(i+\"+\"+j+\"=\"+(i+j)); System.out.println(\"MAXij=\"+Max(i,j)); System.out.println(\"MAXijk=\"+Max(i,j,k)); } //Max() 方法重载 static int Max(int i,int j) { return i\u003ej?i:j; } static int Max(int i,int j,int k) { if(i==j) System.out.println(\"i 和 j 相等\"); else if(i==k) System.out.println(\"i 和 k 相等\"); else if(j==k) System.out.println(\"j 和 k 相等\"); return (i=i\u003ej?i:j)\u003ek?i:k; } } 结果 5 5 6 5+5=10 MAXij=5 i 和 j 相等 MAXijk=6 ","date":"2019-01-14","objectID":"/posts/java-input/:0:2","tags":["Java"],"title":"java 录入数据","uri":"/posts/java-input/"},{"categories":["Java"],"content":"标识符： 给类，接口，方法或者变量起名字的符号 ","date":"2019-01-14","objectID":"/posts/biaoshi/:0:1","tags":["Java"],"title":"java 标识符","uri":"/posts/biaoshi/"},{"categories":["Java"],"content":"组成规则： A: 英文字母大小写 B: 数字 C:_和$ ","date":"2019-01-14","objectID":"/posts/biaoshi/:0:2","tags":["Java"],"title":"java 标识符","uri":"/posts/biaoshi/"},{"categories":["Java"],"content":"注意事项： A: 不能以数字开头 B: 不能是 Java 中的关键字 C: 区分大小写 Student,student 这是两个名称 ","date":"2019-01-14","objectID":"/posts/biaoshi/:0:3","tags":["Java"],"title":"java 标识符","uri":"/posts/biaoshi/"},{"categories":["Java"],"content":"常见命名方式： A: 包 其实就是文件夹，用于解决相同类名问题 全部小写 单级：com 多级：cn.itcast B: 类或者接口 一个单词：首字母大写 Student,Person,Teacher 多个单词：每个单词的首字母大写 HelloWorld,MyName,NameDemo C: 方法或者变量 一个单词：全部小写 name,age,show() 多个单词：从第二个单词开始，每个单词首字母大写 myName,showAllStudentNames() D: 常量 一个单词：全部大写 AGE 多个单词：每个单词都大写，用_连接 STUDENT_MAX_AGE ","date":"2019-01-14","objectID":"/posts/biaoshi/:0:4","tags":["Java"],"title":"java 标识符","uri":"/posts/biaoshi/"},{"categories":["Study"],"content":"常见情况 ","date":"2019-01-12","objectID":"/posts/subject-verb/:1:0","tags":["English"],"title":"英语语法--主谓一致","uri":"/posts/subject-verb/"},{"categories":["Study"],"content":"由 and 或 both and 连接的并列主语，谓语动词一般用复数 English and chinese are two quite different languages. Both brother and sister tire of city life. ","date":"2019-01-12","objectID":"/posts/subject-verb/:1:1","tags":["English"],"title":"英语语法--主谓一致","uri":"/posts/subject-verb/"},{"categories":["Study"],"content":"一但主语前被 no,every,each 所修饰时，谓语动词用单数 No desk and (no) chair is seen in the hall. All work and no play makes Jack a dull boy. They each have been to the Forbidden city. each 位于主语后，所以谓语动词用复数 ","date":"2019-01-12","objectID":"/posts/subject-verb/:1:2","tags":["English"],"title":"英语语法--主谓一致","uri":"/posts/subject-verb/"},{"categories":["Study"],"content":"当主语表示同一事物的两个部分，同一个人的两个身份（第二个名词前无冠词），谓语动词用单数 比如 the（a）horse and cart a watch and chain a knife and fork a cup and soucer the butter and bread The horse and cart has fallen down the cliff（悬崖）. Butter and bread is his favourate. The poet（诗人） and writer has been sentenced（判决） to death. The poet and the writer have been sentenced（判决） to death. ","date":"2019-01-12","objectID":"/posts/subject-verb/:1:3","tags":["English"],"title":"英语语法--主谓一致","uri":"/posts/subject-verb/"},{"categories":["Study"],"content":"两数相加或相乘，单复皆可，相减或相除，只能用单数，量词做主语，用单数 等于： be,equal,be equal to,make 相加： and,plus 相减： minus 相乘： multily,time 相除： divided by One and one make(makes) two. ","date":"2019-01-12","objectID":"/posts/subject-verb/:1:4","tags":["English"],"title":"英语语法--主谓一致","uri":"/posts/subject-verb/"},{"categories":["Study"],"content":"就近原则 not only…but also there/here be or,nor,either…or,neither…nor,not…but There is a desk and two chairs in the room. Are you or your sister fond of classical music? An apple or two lies on the desk.（数量词后用单数） One or two apples lie on the desk. Not he but you have come. ","date":"2019-01-12","objectID":"/posts/subject-verb/:2:0","tags":["English"],"title":"英语语法--主谓一致","uri":"/posts/subject-verb/"},{"categories":["Study"],"content":"就远原则 两单体两结构三 with 四除外 like,including rather than,as well as with,together with,along with except,besides,but,in addition to The couple in addition to their child are mean. Lauren,rather than anyone else was chose his partener. A library together with 3000 books was destroyed in the fire. ","date":"2019-01-12","objectID":"/posts/subject-verb/:3:0","tags":["English"],"title":"英语语法--主谓一致","uri":"/posts/subject-verb/"},{"categories":["Study"],"content":"时间，金钱，距离，温度，天气，重量等不可数名词，to do,doing, 从句做主语时，谓 v 用单数 To go to bed early and rise early is a good habit. What he says and behaives doesn’t concern me. ","date":"2019-01-12","objectID":"/posts/subject-verb/:4:0","tags":["English"],"title":"英语语法--主谓一致","uri":"/posts/subject-verb/"},{"categories":["Study"],"content":"分数，百分数，the rest(+of+n) 做主语，用单数 谓语动词由 of 后面的名词决定，一般用单数。 分数用法： 通常分子读基数，分母读序数，分子超过 1 时，分母加 s。即 基+序 (s)+of+n+谓 Most students are in favaour of the contract（契约） but the rest disagree. be favaour of: be for,approve of,support,agree with About two thirds of the earth’s surface is covered by water. ","date":"2019-01-12","objectID":"/posts/subject-verb/:5:0","tags":["English"],"title":"英语语法--主谓一致","uri":"/posts/subject-verb/"},{"categories":["Study"],"content":"一些短语 one of+n 或 the only one of+n, 一般用单数（定从根据中心词在 of 前后） a number of+n（用复数） \u0026 the number of+n（用单数） one in 或 one out of+n （用单数） a large quantity of \u0026 large quantity of + 可、不可数 n a large amount of \u0026 large amounts of + 不可数 n He is one of the students who were awarded the other day. He is the only one of the students who was awarded the other day. One of his family was a traitor（卖国贼，叛徒） during the world war two. A number of teenagers are addicted to the Internet. The number of students who are addicted to the Internet is up to（接近于） 15. Large amounts of power are foused on him alone.==a large amount of power is foused on him alone. ","date":"2019-01-12","objectID":"/posts/subject-verb/:6:0","tags":["English"],"title":"英语语法--主谓一致","uri":"/posts/subject-verb/"},{"categories":["Study"],"content":"不定代词做主语，谓语动词用单数 all 修饰人，谓语动词用复数，修饰物，谓语动词用单数 All are present besides the professor. All that glitters（发光体） is not gold. not 与 all/both 等连用表部分否定 ","date":"2019-01-12","objectID":"/posts/subject-verb/:7:0","tags":["English"],"title":"英语语法--主谓一致","uri":"/posts/subject-verb/"},{"categories":["Study"],"content":"the +adj 表一类人做主语时，谓语动词用复数 The injured are taken good care of in hospital. The agreeable is not always the useful.（不表人） ","date":"2019-01-12","objectID":"/posts/subject-verb/:8:0","tags":["English"],"title":"英语语法--主谓一致","uri":"/posts/subject-verb/"},{"categories":["Study"],"content":"成双成对的词做主语，用复数 trousers（裤子）,chopsticks,scissors（剪刀）,glasses Pants are what I want. The pair of glasses seems expensive.（谓语动词与表示计量单位的名词形式一致） Three set of fashionable socks are shown in today’s evening proper（恰当地）. 一系列： a piece/pair/set/suit/series of ","date":"2019-01-12","objectID":"/posts/subject-verb/:9:0","tags":["English"],"title":"英语语法--主谓一致","uri":"/posts/subject-verb/"},{"categories":["Study"],"content":"以 s 结尾特殊专用名词，用单数 表学科，疾病，山脉，河流，书名，歌名，格言等 maths,physicsa（物理）,politics（政治）,classics,economics,Aids,SARs,diabetes（糖尿病）,arthritis（关节炎）,bronchitis（支气管炎）,Himalayas,Arabian Night Arabian Night sounds beautiful. ","date":"2019-01-12","objectID":"/posts/subject-verb/:10:0","tags":["English"],"title":"英语语法--主谓一致","uri":"/posts/subject-verb/"},{"categories":["Study"],"content":"many a +单 n+单谓： “许多” more than one +单 n+单谓： “不止一个” Many a man thinks life is meaningless without a purpose/an aim. More than one student has put forward the suggestion. More students than one are against the proposal. More than 20% students were absent at the meeting yesterday.（不止） ","date":"2019-01-12","objectID":"/posts/subject-verb/:11:0","tags":["English"],"title":"英语语法--主谓一致","uri":"/posts/subject-verb/"},{"categories":["Study"],"content":"police,people,cattle 做主语，用复数 It is reported that police are trying their best to capture the murder. ","date":"2019-01-12","objectID":"/posts/subject-verb/:12:0","tags":["English"],"title":"英语语法--主谓一致","uri":"/posts/subject-verb/"},{"categories":["Study"],"content":"the Olympics \u0026 the Olympic games The Olympices is hold every four years. == The Olympic games are hold every four year. ","date":"2019-01-12","objectID":"/posts/subject-verb/:13:0","tags":["English"],"title":"英语语法--主谓一致","uri":"/posts/subject-verb/"},{"categories":["Study"],"content":"集体名词做主语，表整体用单数，表成员用复数 family,class,group,team,army,public,crew,population The innovation experiment（革新实验） class consists of 24 students and enjoy chinese. Population in China is 1.4 billion or so(about) 20% (Population) have no access to clean water. ","date":"2019-01-12","objectID":"/posts/subject-verb/:14:0","tags":["English"],"title":"英语语法--主谓一致","uri":"/posts/subject-verb/"},{"categories":["Study"],"content":"单复同形，sheep,deer,means,Chinese 等谓语动词依据情况而定 Many deer live on the African grassland. ","date":"2019-01-12","objectID":"/posts/subject-verb/:15:0","tags":["English"],"title":"英语语法--主谓一致","uri":"/posts/subject-verb/"},{"categories":["Study"],"content":"地点状语位于句首 Among the crow stand his parents. On the wall hangs an alarm clock. ","date":"2019-01-12","objectID":"/posts/subject-verb/:16:0","tags":["English"],"title":"英语语法--主谓一致","uri":"/posts/subject-verb/"},{"categories":["Study"],"content":"“of”: of 表所属时，中心词在 of 之前，谓语动词由中心词决定，特例除外。 ","date":"2019-01-12","objectID":"/posts/subject-verb/:17:0","tags":["English"],"title":"英语语法--主谓一致","uri":"/posts/subject-verb/"},{"categories":["Study"],"content":" 形式倒装，句子本不是本来的语序。 ","date":"2018-12-10","objectID":"/posts/inversion-3/:0:0","tags":["English"],"title":"英语语法--形式倒装","uri":"/posts/inversion-3/"},{"categories":["Study"],"content":"may 位于句首，标祝愿 例句 May you succeed. May you have a happy holiday. Long live chairman Mao.（毛主席万古长青） ","date":"2018-12-10","objectID":"/posts/inversion-3/:0:1","tags":["English"],"title":"英语语法--形式倒装","uri":"/posts/inversion-3/"},{"categories":["Study"],"content":"whatever 直接做成分或放在名词之前，however 放在 adv,adj 之前或 many,much 等词之前 例句 Whatever the weather is,he sticks out（坚持） walking outside. Go to stamp sales and buy whatever you can offord. Whatever reasons you have,you should carry out your promise. However many difficulties(n.) you meet with,you should try to overcome them. Whatever difficulties(n.) you meet with,you should try to overcome them. However difficult(adj.) the problem is,we must work it out today. ","date":"2018-12-10","objectID":"/posts/inversion-3/:0:2","tags":["English"],"title":"英语语法--形式倒装","uri":"/posts/inversion-3/"},{"categories":["Study"],"content":"the + 比较级，the + 比较级 --\u003e“越 … 越 …” 例句 The hander you study,the greater progress you will make. The more you listen to English,the easier it becomes. The older you grow,the more challenges you will meet. ","date":"2018-12-10","objectID":"/posts/inversion-3/:0:3","tags":["English"],"title":"英语语法--形式倒装","uri":"/posts/inversion-3/"},{"categories":["Study"],"content":"感叹句 例句 What an interesting talk they had! How interesting the talk was! ","date":"2018-12-10","objectID":"/posts/inversion-3/:0:4","tags":["English"],"title":"英语语法--形式倒装","uri":"/posts/inversion-3/"},{"categories":["Study"],"content":" 完全倒装： 把整个谓语动词放到主语前。 ","date":"2018-12-10","objectID":"/posts/inversion-2/:0:0","tags":["English"],"title":"英语语法--完全倒装","uri":"/posts/inversion-2/"},{"categories":["Study"],"content":"表方位或时间的副词 (adv)、表地点的介词短语位于句首时 例句 Here comes the bus. In the lecture hall of a university sits a professor. Out rushed the children. Now comes your turn. Up jumped the cat and caught the mouse. Down came the rain and up went the umbrellas. Among the people stood his friend,Jim. (To be) South of the river lies a small factory. 但主语为表示人称的代词时无需倒装 Here are you. Away it flew. ","date":"2018-12-10","objectID":"/posts/inversion-2/:0:1","tags":["English"],"title":"英语语法--完全倒装","uri":"/posts/inversion-2/"},{"categories":["Study"],"content":"表语（词/短语）位于句首时，adj/doing/done 例句 Written on the blackboard are the name of these who were late. Gone are the days when we worked together. Standing at the tree is a shy girl with two big eges. Present(adj) at the conference were all leaders of this city. Lying on the grassland is the boy who was injured in the fire. ","date":"2018-12-10","objectID":"/posts/inversion-2/:0:2","tags":["English"],"title":"英语语法--完全倒装","uri":"/posts/inversion-2/"},{"categories":["Study"],"content":"存在句 there be 中，其中 be -\u003eexist/arise/follow/enter/appear/live 等表状态 vi 例句 There come shows for help from the river. There seems something wrong with machine. There remains nothing to be done. There happened an event last week. ","date":"2018-12-10","objectID":"/posts/inversion-2/:0:3","tags":["English"],"title":"英语语法--完全倒装","uri":"/posts/inversion-2/"},{"categories":["Study"],"content":" 虽然我英语四级没过，词汇量也不很多，甚至下降了很多，但是对于英语的语法我还是很喜欢的，马上快四级了又，复习整理一下以前的语法笔记。以下内容纯手打！！ 先从倒装句开始吧！分为三大类，部分倒装，完全倒装和形式倒装。先复习第一种。 部分倒装： 把谓语动词的一部分（助动词，be 动词，情态动词）提到主语前面。 ","date":"2018-12-08","objectID":"/posts/inversion-1/:0:0","tags":["English"],"title":"英语语法--部分倒装","uri":"/posts/inversion-1/"},{"categories":["Study"],"content":"xx 也如此，xx 也一样 表示前面的内容也适用于后者，用\"so/nor/neither + 动词 + 主语\"句型。表“xx 也如此，xx 也一样”。可用,、;、and隔开（注意情形）。 例句 They love having lots of friends, so dothe disabled.（这里the + 形容词表一类人） I have had a new idea; so hasmy friends. Lily can’t ride bicycle, nor/neither canlucy. The injured look disappointed（沮丧的）, so didsenior citizens.（老人） （否定前缀词 ≠ 否定） If you aren’t for the plan; nor/neither willI. , 或 ; 前的句子若为从句，先将主句补充出，其后再根据主句改。 这里主句应为： I will not be for the plan.(be for 同意） It is burning（燃烧） hot today, so it is（那确实） and/; so was (it)yesterday.（这里只用用 and 或；) Everyone is here and looks upset, so it is with Mary = it is the same withMary. 这个句型同样适用于前面的六个例子，但是前面是并列句必须用这个句型。 The truth is that no one is perfect.When all potential（潜在的） for ugliness in removed, so is all of the potential for beauty. ","date":"2018-12-08","objectID":"/posts/inversion-1/:0:1","tags":["English"],"title":"英语语法--部分倒装","uri":"/posts/inversion-1/"},{"categories":["Study"],"content":"否定副词或含有否定的介词短位于句首 例句 Neither does Mr.Green know the matter（事件） nor does he care about it. neither……nor…… 既不也不 either……or……要么要么，不是就是 Not only did we lose our way but also (we) came close to losing our lives.(come close to 接近，差一点就） Not until I began to work hard did I realize how much time I had wasted. 从句不倒装，原句为： I didn’t realize how much time I had wasted until I began to work hard. No sooner had they arrived at the tomb than they fell ill.（一……就……) In no case will we give up half-way. Hardly does Jim think it possible to finish the task before/when dark. hardly…before/when 一……就…… 这里取\"几乎不\"释义应该更合适。 Not a (single) mistake has Mary made so far.（玛丽到目前为止一个错误也没犯。) not a (single) + 单数名词 表示“一个也没有”%} In no time（立刻马上） Jone worked out the figure（体积）. （无否定不倒装） ","date":"2018-12-08","objectID":"/posts/inversion-1/:0:2","tags":["English"],"title":"英语语法--部分倒装","uri":"/posts/inversion-1/"},{"categories":["Study"],"content":"only + 状语位于句首 例句 Only in this way are you able to do it well. 倒装前： You are able to do it well only in this way. Only when they returned home did they understand what had happened. Only on such a trip will you gain a better appreciation（理解） of Eurepean literature. Only the teacher got the news that our school could have a 4-day holiday.（同位语从句，only+主语所以不倒装） ","date":"2018-12-08","objectID":"/posts/inversion-1/:0:3","tags":["English"],"title":"英语语法--部分倒装","uri":"/posts/inversion-1/"},{"categories":["Study"],"content":"So/Such…that… 句型位于句首 So + adj + a/an + 单数名词 = Such + a/an + adj + 单数名词 如此 ... 以至于 ... so 侧重于 adj/adv such 侧重于 n. 比如，so many/much/few/little 例句 So crowded was the art gallery（展览会） that I couldn’t move about (it). Such good weather was it that we all went out last week. Such a lovely girl is kate that everyone likes her. So loudly did he speak that even people next room could hear him. ","date":"2018-12-08","objectID":"/posts/inversion-1/:0:4","tags":["English"],"title":"英语语法--部分倒装","uri":"/posts/inversion-1/"},{"categories":["Study"],"content":"as 引导让步狀语从句 as 引导让步状语从句（虽然，即使，尽管，无论），把从句中的表语，动词，副词提至句首 (as 后不用再倒装了），当表语是名词时，提至句首时一律用零冠词（其中 as 可用 though 替代，倒装后省略 but,though,however,even,though,although 等） 例句 Child as he is,he knows a lot. Poor as King was,he tried his best to help others. Try as he may,he has never made his boss satisfied. Search as you would,you could find no body in the room. Much as I want to buy the car,I can’t afford（支付） it. ","date":"2018-12-08","objectID":"/posts/inversion-1/:0:5","tags":["English"],"title":"英语语法--部分倒装","uri":"/posts/inversion-1/"},{"categories":["Study"],"content":"把虚拟语气从句中的 were,had,should 提至句首，并省略 if 例句 Had you followwed my advice,you couldn’t have made such a silly mistake. Were you not a boy,you could wear a dress. Should he invite me,I might take part in this party. ","date":"2018-12-08","objectID":"/posts/inversion-1/:0:6","tags":["English"],"title":"英语语法--部分倒装","uri":"/posts/inversion-1/"},{"categories":["Study"],"content":"表肯定含义的时间频率词位于句首 always,often,many a time(many times 多次）,every + 时间，now and then（时不时的） 例句 Many a time has he offered me some good suggestions. Now and then does my class teacher warn us not yo use cellphones in the classroom. ","date":"2018-12-08","objectID":"/posts/inversion-1/:0:7","tags":["English"],"title":"英语语法--部分倒装","uri":"/posts/inversion-1/"},{"categories":["Study"],"content":"疑问句用部分倒装 普通的疑问句： How do you do that? 除了： What is wrong? = What is the matter? … ","date":"2018-12-08","objectID":"/posts/inversion-1/:0:8","tags":["English"],"title":"英语语法--部分倒装","uri":"/posts/inversion-1/"},{"categories":["Memo"],"content":" 2021/10/2 更新 博客已迁移至 Hugo, 插件演示不适用，已删除。 让文章写的好看又简洁又好用的插件！hexo 完整的标签列表，next 插件列表 ","date":"2018-11-24","objectID":"/posts/nextplugin/:0:0","tags":["hexo"],"title":"hexo 插件及 next 内置样式集","uri":"/posts/nextplugin/"},{"categories":["Memo"],"content":"hexo 插件 hexo-lazyload-image npm install hexo-lazyload-image --save First add configuration in _config.yml from your hexo project. lazyload: enable: true onlypost: false loadingImg: # eg ./images/loading.gif hexo-ruby-marks 不支持ruby新标签的浏览器将显示rp中的内容。 \u003cruby\u003e博採眾長\u003crp\u003e（\u003c/rp\u003e \u003crt\u003elruihao.cn\u003c/rt\u003e\u003crp\u003e）\u003c/rp\u003e\u003c/ruby\u003e 博採眾長（ lruihao.cn） 插件使用 npm i hexo-ruby-marks {% ruby _**base**_|_**top text**_ %} hexo-pwa npm install --save hexo-pwa You can configure this plugin in _config.yml.（配置完即可使用不许单独设置manifest.json文件及配置，插件生成） pwa: manifest: path: /manifest.json body: name: hexo short_name: hexo icons: - src: /images/android-chrome-192x192.png sizes: 192x192 type: image/png - src: /images/android-chrome-512x512.png sizes: 512x512 type: image/png start_url: /index.html theme_color: '#ffffff' background_color: '#ffffff' display: standalone serviceWorker: path: /sw.js preload: urls: - / posts: 5 opts: networkTimeoutSeconds: 5 routes: - pattern: !!js/regexp /hm.baidu.com/ strategy: networkOnly - pattern: !!js/regexp /.*\\.(js|css|jpg|jpeg|png|gif)$/ strategy: cacheFirst - pattern: !!js/regexp /\\// strategy: networkFirst priority: 5 hexo-tag-dplayer hexo-tag-dplayer npm install hexo-tag-dplayer --save {% dplayer key=value ... %} key can be dplayer options: 'autoplay', 'loop', 'screenshot', 'hotkey', 'mutex', 'dmunlimited' : bool options, use \"yes\" \"y\" \"true\" \"1\" \"on\" or just without value to enable 'preload', 'theme', 'lang', 'logo', 'url', 'pic', 'thumbnails', 'vidtype', 'suburl', 'subtype', 'subbottom', 'subcolor', 'subcolor', 'id', 'api', 'token', 'addition', 'dmuser' : string arguments 'volume', 'maximum' : number arguments container options: 'width', 'height' : string, used in container element style other: 'code' : value of this key will be append to script tag {% dplayer \"url=https://moeplayer.b0.upaiyun.com/dplayer/hikarunara.mp4\" \"addition=https://dplayer.daoapp.io/bilibili?aid=4157142\" \"api=https://api.prprpr.me/dplayer/\" \"pic=https://moeplayer.b0.upaiyun.com/dplayer/hikarunara.jpg\" \"id=9E2E3368B56CDBB4\" \"loop=yes\" \"theme=#FADFA3\" \"autoplay=false\" \"token=tokendemo\" %} hexo-tag-aplayer more npm install --save hexo-tag-aplayer {% aplayer title author url [picture_url, narrow, autoplay, width:xxx, lrc:xxx] %} 标签参数 title : 曲目标题 author: 曲目作者 url: 音乐文件 URL 地址 picture_url: （可选） 音乐对应的图片地址 narrow: （可选）播放器袖珍风格 autoplay: （可选） 自动播放，移动端浏览器暂时不支持此功能 width:xxx: （可选） 播放器宽度 （默认：100%) lrc:xxx: （可选）歌词文件 URL 地址 当开启 Hexo 的 文章资源文件夹 功能时，可以将图片、音乐文件、歌词文件放入与文章对应的资源文件夹中，然后直接引用： {% aplayer \"Caffeine\" \"Jeff Williams\" \"caffeine.mp3\" \"picture.jpg\" \"lrc:caffeine.txt\" %} {% aplayer \"你离开了南京，从此没人和我说话\" \"李志\" \"https://cdn-1256932288.cos.ap-chengdu.myqcloud.com/files/nanjing.mp3\" \"https://p2.music.126.net/UuSe-Vc6rS7JtRJSQgDU2g==/2323268069553116.jpg?param=300x300\" %} hexo-pdf pdf 传送门 hexo-filter-flowchart（流程图） 语法 npm install --save hexo-filter-flowchart ```%flow #去掉%号 st=\u003estart: Start|past:\u003ehttps://lruihao.cn[blank] e=\u003eend: End:\u003ehttps://www.lruihao.cn[blank] op1=\u003eoperation: My Operation|past op2=\u003eoperation: Stuff|current sub1=\u003esubroutine: My Subroutine|invalid cond=\u003econdition: Yes or No?|approved:\u003e/hexo/nextplugin.html c2=\u003econdition: Good idea|rejected io=\u003einputoutput: catch something...|request st-\u003eop1(right)-\u003econd cond(yes, right)-\u003ec2 cond(no)-\u003esub1(left)-\u003eop1 c2(yes)-\u003eio-\u003ee c2(no)-\u003eop2-\u003ee ``` hexo-spoiler npm install hexo-spoiler --save If hexo can’t detect this plugin automatically, you need to modify the plugins section of [path_to_your_site]/_config.yml manually, like: plugins: - hexo-spoiler {% spoiler [text] %} It will pixelate your text, and click to reveal. Click again to hide your text again. But you need to add \u003cbr\u003e manually if you want line breaks after/before it. When you writes: {% spoiler text %} {% spoiler ~~text~~ %} {% spoiler *text* %} {% spoiler **text** %}\u003cbr\u003e {% spoiler **hello welcome to 博採眾長！** %} ","date":"2018-11-24","objectID":"/posts/nextplugin/:0:1","tags":["hexo"],"title":"hexo 插件及 next 内置样式集","uri":"/posts/nextplugin/"},{"categories":["Memo"],"content":"宅音乐侧栏播放器插件 体验 源码 目前在 next 中可能引起部分 css 冲突，建议在 next 中使用在单个页面中。 依赖于 jQuery，一行 js 可以引入播放器插件。 ","date":"2018-11-24","objectID":"/posts/nextplugin/:0:2","tags":["hexo"],"title":"hexo 插件及 next 内置样式集","uri":"/posts/nextplugin/"},{"categories":["Memo"],"content":"caniuse 使用 {% caniuse feature @ periods %} \u003c!-- Tag Alias --\u003e {% can feature @ periods %} feature : Search for the feature you want on https://caniuse.com, then click on the hash sign to the left of the search result heading and you will get the unique name of this feature. periods : Select the browser versions to display. Supported values: past_1, past_2, past_3, past_4, past_5, current, future_3, future_2, future_1. If this value is empty, the default value 'current' will be used. 栗子 Caniuse without periods {% caniuse fetch %} Caniuse with current period {% can sharedarraybuffer @ current %} Caniuse with future periods {% caniuse loading-lazy-attr @ future_3,future_2,future_1 %} Caniuse with past periods {% caniuse link-rel-modulepreload @ past_1,past_2,past_3,past_4,past_5 %} ","date":"2018-11-24","objectID":"/posts/nextplugin/:0:3","tags":["hexo"],"title":"hexo 插件及 next 内置样式集","uri":"/posts/nextplugin/"},{"categories":["Memo"],"content":"Include Raw This tag include any raw content into your posts. Path is relative to your site source directory. {% include_raw '_data/path/to/file.html' %} Let’s create include-raw.html file in _data directory under site root directory with following content: Any \u003cstrong\u003eraw content\u003c/strong\u003e may be included with this tag. Then in any post we can use this content with include_raw tag: {% include_raw '_data/path/to/include-raw.html' %} Any raw content may be included with this tag. ","date":"2018-11-24","objectID":"/posts/nextplugin/:0:4","tags":["hexo"],"title":"hexo 插件及 next 内置样式集","uri":"/posts/nextplugin/"},{"categories":["Memo"],"content":"button more info {% button url, text, icon [class], [title] %} \u003c!-- Tag Alias --\u003e {% btn url, text, icon [class], [title] %} url : Absolute or relative path to URL. text : Button text. Required if no icon specified. icon : FontAwesome icon name (without 'fa-' at the begining). Required if no text specified. [class] : FontAwesome class(es): fa-fw | fa-lg | fa-2x | fa-3x | fa-4x | fa-5x Optional parameter. [title] : Tooltip at mouseover. Optional parameter. {% btn #, Text \u0026 Large Icon \u0026 Title, home fa-fw fa-lg, Title %} ``` ","date":"2018-11-24","objectID":"/posts/nextplugin/:0:5","tags":["hexo"],"title":"hexo 插件及 next 内置样式集","uri":"/posts/nextplugin/"},{"categories":["Memo"],"content":"Mermaid more info example {% mermaid gitGraph: %} options { \"nodeSpacing\": 150, \"nodeRadius\": 10 } end commit branch newbranch checkout newbranch commit checkout master commit merge newbranch {% endmermaid %} ","date":"2018-11-24","objectID":"/posts/nextplugin/:0:6","tags":["hexo"],"title":"hexo 插件及 next 内置样式集","uri":"/posts/nextplugin/"},{"categories":["Memo"],"content":"video Usage {% video url %} Examples {% video https://example.com/sample.mp4 %} {% video /path/to/your/video.mp4 %} ","date":"2018-11-24","objectID":"/posts/nextplugin/:0:7","tags":["hexo"],"title":"hexo 插件及 next 内置样式集","uri":"/posts/nextplugin/"},{"categories":["Memo"],"content":"tab 选项卡 “tab\"为选项卡的名称，可以自定义，数字是几表示从第几个选项卡开始。非必须，若数值为-1 则隐藏选项卡内容。 查看更多 {% tabs Unique name, [index] %} \u003c!-- tab [Tab caption] [@icon] --\u003e Any content (support inline tags too). \u003c!-- endtab --\u003e {% endtabs %} Unique name : Unique name of tabs block tag without comma. Will be used in #id's as prefix for each tab with their index numbers. If there are whitespaces in name, for generate #id all whitespaces will replaced by dashes. Only for current url of post/page must be unique! [index] : Index number of active tab. If not specified, first tab (1) will be selected. If index is -1, no tab will be selected. It's will be something like spoiler. Optional parameter. [Tab caption] : Caption of current tab. If not caption specified, unique name with tab index suffix will be used as caption of tab. If not caption specified, but specified icon, caption will empty. Optional parameter. [@icon] : FontAwesome icon name (without 'fa-' at the begining). Can be specified with or without space; e.g. 'Tab caption @icon' similar to 'Tab caption@icon'. Optional parameter. {% tabs tab,2 %} \u003c!-- tab --\u003e this is tab1 \u003c!-- endtab --\u003e \u003c!-- tab --\u003e this is tab2 \u003c!-- endtab --\u003e \u003c!-- tab --\u003e this is tab3 \u003c!-- endtab --\u003e {% endtabs %} 数值为-1 {% tabs 选项，-1 %} \u003c!-- tab --\u003e **选项 1** \u003c!-- endtab --\u003e \u003c!-- tab --\u003e **选项 2** \u003c!-- endtab --\u003e \u003c!-- tab --\u003e **选项 3** \u003c!-- endtab --\u003e {% endtabs %} 名字写在选项里面 {% tabs Fourth unique name %} \u003c!-- tab Solution 1 --\u003e **This is Tab 1.** \u003c!-- endtab --\u003e \u003c!-- tab Solution 2 --\u003e **This is Tab 2.** \u003c!-- endtab --\u003e \u003c!-- tab Solution 3 --\u003e **This is Tab 3.** \u003c!-- endtab --\u003e {% endtabs %} ","date":"2018-11-24","objectID":"/posts/nextplugin/:0:8","tags":["hexo"],"title":"hexo 插件及 next 内置样式集","uri":"/posts/nextplugin/"},{"categories":["Memo"],"content":"note 便签 主题配置文件搜索 note, 可设置风格和图标是否显示。 # Note tag (bs-callout). note: # Note tag style values: # - simple bs-callout old alert style. Default. # - modern bs-callout new (v2-v3) alert style. # - flat flat callout style with background, like on Mozilla or StackOverflow. # - disabled disable all CSS styles import of note tag. style: flat icons: true border_radius: 15 # Offset lighter of background in % for modern and flat styles (modern: -12 | 12; flat: -18 | 6). # Offset also applied to label tag variables. This option can work with disabled note tag. light_bg_offset: 0 写法 {% note default %} default 类型还有以下几种 {% endnote %} {% note primary %} primary 内容 {% endnote %} {% note success %} success 内容 {% endnote %} {% note info %} info 内容 {% endnote %} {% note warning %} warning 内容 {% endnote %} {% note danger %} danger 内容 {% endnote %} {% note %} 不填 内容 {% endnote %} {% note danger no-icon %} danger no-icon 内容 {% endnote %} ### 引用（文本居中） {% cq %} there are test words {% endcq %} ### [Font Awesome 图标](https://www.runoob.com/font-awesome/fontawesome-tutorial.html) \u003e Font Awesome 是一套绝佳的图标字体库和 CSS 框架。 \u003e Font Awesome 字体为您提供可缩放矢量图标，它可以被定制大小、颜色、阴影以及任何可以用 CSS 的样式。 \u003e 要使用 Font Awesome 图标，请在 HTML 页面的 部分中添加以下行： #### 1、国内推荐 CDN ``` #### 2、海外推荐 CDN \u003clink rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css\"\u003e next 已经引用了，可以直接用，比如： \u003ci class=\"fa fa-car\"\u003e\u003c/i\u003e \u003ci class=\"fa fa-car\" style=\"font-size:48px;\"\u003e\u003c/i\u003e \u003ci class=\"fa fa-car\" style=\"font-size:60px;color:red;\"\u003e\u003c/i\u003e \u003ci class=\"fa fa-car fa-lg\"\u003e\u003c/i\u003e \u003ci class=\"fa fa-car fa-2x\"\u003e\u003c/i\u003e \u003ci class=\"fa fa-car fa-3x\"\u003e\u003c/i\u003e \u003ci class=\"fa fa-car fa-4x\"\u003e\u003c/i\u003e \u003ci class=\"fa fa-car fa-5x\"\u003e\u003c/i\u003e 动态图标 \u003ci class=\"fa fa-spinner fa-spin\"\u003e\u003c/i\u003e \u003ci class=\"fa fa-circle-o-notch fa-spin\"\u003e\u003c/i\u003e \u003ci class=\"fa fa-refresh fa-spin\"\u003e\u003c/i\u003e \u003ci class=\"fa fa-cog fa-spin\"\u003e\u003c/i\u003e \u003ci class=\"fa fa-spinner fa-pulse\"\u003e\u003c/i\u003e ","date":"2018-11-24","objectID":"/posts/nextplugin/:0:9","tags":["hexo"],"title":"hexo 插件及 next 内置样式集","uri":"/posts/nextplugin/"},{"categories":["Memo"],"content":"代码块等 [language] [title] [url] [link text] code snippet - printf(\"Hello World!\"); + printf(\"Hello_World!\"); iframe 在文章中插入 iframe。 {% iframe url [width] [height] %} ","date":"2018-11-24","objectID":"/posts/nextplugin/:0:10","tags":["hexo"],"title":"hexo 插件及 next 内置样式集","uri":"/posts/nextplugin/"},{"categories":["Memo"],"content":"Todo list 已完成 未完成 \u003cul\u003e \u003cli\u003e\u003ci class=\"fa fa-check-square\"\u003e\u003c/i\u003e 已完成\u003c/li\u003e \u003cli\u003e\u003ci class=\"fa fa-square\"\u003e\u003c/i\u003e 未完成\u003c/li\u003e \u003c/ul\u003e \u003c!--或者--\u003e - \u003ci class=\"fa fa-check-square\"\u003e\u003c/i\u003e 已完成 - \u003ci class=\"fa fa-square\"\u003e\u003c/i\u003e 未完成 ","date":"2018-11-24","objectID":"/posts/nextplugin/:0:11","tags":["hexo"],"title":"hexo 插件及 next 内置样式集","uri":"/posts/nextplugin/"},{"categories":["Memo"],"content":"Label 主题配置文件中打开 # Label tag. label: true @前面的是 label 的名字，后面的是要显示的文字 {% label default@default %} primary success info warning danger ","date":"2018-11-24","objectID":"/posts/nextplugin/:0:12","tags":["hexo"],"title":"hexo 插件及 next 内置样式集","uri":"/posts/nextplugin/"},{"categories":["Memo"],"content":"其他 包括小色块、左侧色条、右侧色条、上方色条、数字色块（需要自定义样式） ","date":"2018-11-24","objectID":"/posts/nextplugin/:0:13","tags":["hexo"],"title":"hexo 插件及 next 内置样式集","uri":"/posts/nextplugin/"},{"categories":["OS"],"content":" 前面我有文章提到怎么提交本地文件到 github,coding 等远程仓库。每次可以分为三个步骤 git add * （添加需要提交的文件，这里全选） git commit -m “提交信息” git push 但是这样感觉很麻烦每次都要重复输入提交命令和提示信息。 这个时候可以用到 windows 批处理 bat 文件 (linux 的话可以用 shell 脚本）。用完发现好用到不行！ ","date":"2018-11-17","objectID":"/posts/commit-bat/:0:0","tags":["bat"],"title":"通过 bat 批处理文件自动提交博客代码","uri":"/posts/commit-bat/"},{"categories":["OS"],"content":"新建文本文档 @echo off title Commit git add . set /p m=Message: git commit -m \"%m%\" git push 然后另存为commit.bat文件，只要后缀是bat就行了。 ","date":"2018-11-17","objectID":"/posts/commit-bat/:0:1","tags":["bat"],"title":"通过 bat 批处理文件自动提交博客代码","uri":"/posts/commit-bat/"},{"categories":["OS"],"content":"使用 把文件放到你原本需要提交代码的本地文件夹。双击运行，输入提交信息回车即可。 ","date":"2018-11-17","objectID":"/posts/commit-bat/:0:2","tags":["bat"],"title":"通过 bat 批处理文件自动提交博客代码","uri":"/posts/commit-bat/"},{"categories":["OS"],"content":"hexo 博客新姿势 hexo 提交也很麻烦，当然也要批处理一下呀 hexo clean\u0026\u0026hexo g -d ","date":"2018-11-17","objectID":"/posts/commit-bat/:0:3","tags":["bat"],"title":"通过 bat 批处理文件自动提交博客代码","uri":"/posts/commit-bat/"},{"categories":["OS"],"content":"其他 死机脚本 (友情提醒千万不要在真机实验，请在虚拟机运行) start cmd ifconfig 另外也说一下 linux 死机命令。fork 炸弹。 死机无非是耗尽系统资源 _(){ _ | _ \u0026 }; _ 这个\u0026指后台运行的意思。 统计文件名 dir \\\\?\\%1 /a:-d /b /o /p /w \u003eFilelist.txt 将需要统计的文件夹拖到 bat 文件上。 ","date":"2018-11-17","objectID":"/posts/commit-bat/:0:4","tags":["bat"],"title":"通过 bat 批处理文件自动提交博客代码","uri":"/posts/commit-bat/"},{"categories":["Grocery"],"content":"介绍 使用 fusion app 对网页进行的封装。 功能： 浏览本博客，主页 私人网盘 2048 等小游戏 在线客服，QQ 等 pc 与移动浏览器标识切换 留言，打赏，博主日志等 分享功能，分享到 QQ，微信，浏览器打开等 app 内添加书签，自动记录历史记录，刷新等 配合博客的PWA + quicklink功能可实现离线浏览 ","date":"2018-11-12","objectID":"/posts/fas-app/:0:1","tags":["lua","fusion"],"title":"博採眾長 app","uri":"/posts/fas-app/"},{"categories":["Grocery"],"content":"下载 app 内也可以更新，不过就我自己用，懒得更新。 百度云，密码：479l github 下载 PWA 应用 地址栏输入：Chrome://flags 搜索并启用以下项目：Desktop PWAs（桌面 PWAs)、App Banners（应用横幅）、Experimental App Banners（实验性应用横幅） 重启浏览器使修改的设置生效 点击地址栏最右边按钮 安装“博採眾長” ","date":"2018-11-12","objectID":"/posts/fas-app/:0:2","tags":["lua","fusion"],"title":"博採眾長 app","uri":"/posts/fas-app/"},{"categories":["Grocery"],"content":"部分源码 看到这些中文的函数总觉得怪怪的哈哈哈 😂 语言：lua 检测更新 --检查测当前是否最新版本 local dl=ProgressDialog.show(activity,nil,'更新检测中…') dl.show() local tt=Ticker() tt.start() packinfo=this.getPackageManager().getPackageInfo(this.getPackageName(),((32552732/2/2-8183)/10000-6-231)/9) version=tostring(packinfo.versionName) versioncode=tostring(packinfo.versionCode) url=\"https://share.weiyun.com/43fa66d8fc95db27141530ed2d006be2\"; function 过滤 (content) 版本名=content:match(\"【版本名】(.-)【版本名】\") 版本=content:match(\"【版本】(.-)【版本】\") 内容=content:match(\"【内容】(.-)【内容】\") 链接=content:match(\"【链接】(.-)【链接】\") if（版本名==nil) then 版本名=\"获取失败\" end if（版本==nil) then 版本=\"0\" end if（内容==nil) then 内容=\"获取失败\" end if（链接==nil) then 弹出消息 (\"服务器参数配置错误，请过段时间再次尝试\") end if（版本 \u003e versioncode) then dl.dismiss() tt.stop() 对话框 () . 设置标题 (\"检测到更新\") . 设置消息 (\"版本：\"..version..\"→\".. 版本名。.\"\\n 更新内容：\".. 内容） . 设置积极按钮 (\"下载更新\",function() 下载文件（链接） 弹出消息 (\"下载更新中…\") end) . 设置消极按钮 (\"取消更新\") . 显示 () else dl.dismiss() tt.stop() 弹出消息 (\"当前已是最新版本！\") end Http.get(url,nil,\"UTF-8\",nil,function(code,content,cookie,header) if(code==200 and content)then content=content:match(\"\\\"html_content\\\":(.-),\"):gsub(\"\\\\u003C/?.-%\u003e\",\"\"):gsub(\"\\\\\\\\\",\"\u0026revs;\"):gsub(\"\\\\n\",\"\\n\"):gsub(\"\u0026nbsp;\",\" \"):gsub(\"\u0026lt;\",\"\u003c\"):gsub(\"\u0026gt;\",\"\u003e\"):gsub(\"\u0026quot;\",\"\\\"\"):gsub(\"\u0026apos;\",\"'\"):gsub(\"\u0026revs;\",\"\\\\\"):gsub(\"\u0026amp;\",\"\u0026\"); 过滤 (content) else dl.dismiss() tt.stop() 弹出消息 (\"本地网络或服务器异常 \"..code) end end) 方向锁定 --flag 在程序启动事件声明的全局变量 if flag==1 then activity.setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_SENSOR); SetHSP=\"H\" else SetHSP=nil end if SetHSP==nil then --竖屏锁定 activity.setRequestedOrientation(1); flag=1 else flag=0 end 程序启动事件 弹出消息 (\"©2018 李瑞豪\") --自动，由物理感应器决定 import \"android.content.pm.ActivityInfo\" flag=1 --程序退出时执行对话框 function onKeyDown(key,event) if(key==4)then if(webView.canGoBack())then webView.goBack() else appinfo=this.getPackageManager().getApplicationInfo(this.getPackageName(),0) applabel=this.getPackageManager().getApplicationLabel(appinfo) 退出确认=对话框 () . 设置消息 (\"您确定要退出 \"..applabel..\" 吗？\") 退出按钮={ [1]=function() 退出确认 . 设置积极按钮 (\"确认\",function() 退出程序 () end ) . 设置中立按钮 (\"清除缓存\",function() 对话框 () . 设置消息 (\"清除缓存后再次运行程序将变得缓慢、n 您确定要清除 \"..applabel..\" 的缓存吗？\") . 设置积极按钮 (\"确定\",function() os.execute(\"pm clear \"..this.packageName) 退出程序 () end) . 设置消极按钮 (\"取消\",function() end) . 显示 () end ) . 设置消极按钮 (\"取消\") end } math.randomseed(tonumber(tostring(os.time()):reverse():sub(1, 6))) 退出按钮 [math.random(1,1)]() 退出确认。show() end return true end end --历史记录 lstads=\"/data/data/\"..activity.getPackageName()..\"/lst.lua\" lstwebads=\"/data/data/\"..activity.getPackageName()..\"/lstweb.lua\" --2. 序列化 function slz(obj) local lua = \"\" local t = type(obj) if t == \"number\" then lua = lua .. obj elseif t == \"boolean\" then lua = lua .. tostring(obj) elseif t == \"string\" then lua = lua .. string.format(\"%q\", obj) elseif t == \"table\" then lua = lua .. \"{\\n\" for k, v in pairs(obj) do lua = lua .. \"[\" .. slz(k) .. \"]=\" .. slz(v) .. \",\\n\" end local metatable = getmetatable(obj) if metatable ~= nil and type(metatable.__index) == \"table\" then for k, v in pairs(metatable.__index) do lua = lua .. \"[\" .. slz(k) .. \"]=\" .. slz(v) .. \",\\n\" end end lua = lua .. \"}\" elseif t == \"nil\" then return nil else error(\"can not serialize a \" .. t .. \" type.\") end return lua end function rslz(lua) local t = type(lua) if t == \"nil\" or lua == \"\" then return {} elseif t == \"number\" or t == \"string\" or t == \"boolean\" then lua = tostring(lua) else error(\"can not unserialize a \" .. t .. \" type.\") end lua = \"return \" .. lua local func = loadstring(lua) if func == nil then return nil end return func() end --3. 历史记录框布局 function hstshow() hstlayout={ LinearLayout, orientation=\"1\", gravity=\"center\", layout_width=\"wrap_content\", layout_height=\"wrap_content\", { TextView, text=\"\", gravity=\"center\", layout_width=\"wrap_content\", textSize=\"0sp\", background=\"#000000\", layout_height=\"15dp\",}, { TextView, text=\"历史记录\", gravity=\"center\", layout_width=\"wrap_content\", textSize=\"30sp\", textStyle=\"bold\", layout_height=\"50dp\",}, { ListView, id=\"hlst\", items=","date":"2018-11-12","objectID":"/posts/fas-app/:0:3","tags":["lua","fusion"],"title":"博採眾長 app","uri":"/posts/fas-app/"},{"categories":["Grocery"],"content":"安装 cd ~ curl https://getcaddy.com | bash -s personal http.filemanager ","date":"2018-11-11","objectID":"/posts/caddy-file/:1:0","tags":["云盘","caddy","server"],"title":"caddy-两步搭建超简单云盘","uri":"/posts/caddy-file/"},{"categories":["Grocery"],"content":"编写配置文件 vim Caddyfile 内容如下： :80 { filemanager / /sdcard timeouts none gzip } 这里的 8080 端口号可以随意指定，如果在手机 termux 等搭建，由于手机权限比较低，所以一般设置 1024 以上的端口。80端口可以直接通过 ip 访问。如118.24.217.167 如果用域名，先在域名服务商解析 ip, 再配置文件如下 https://pan.lruihao.cn { filemanager / /sdcard timeouts none tls admin@lruihao.cn gzip } 指定邮箱是为了申请 ssl, 实现 https. ","date":"2018-11-11","objectID":"/posts/caddy-file/:2:0","tags":["云盘","caddy","server"],"title":"caddy-两步搭建超简单云盘","uri":"/posts/caddy-file/"},{"categories":["Grocery"],"content":"demo 启动 caddy caddy 账号密码默认admin ","date":"2018-11-11","objectID":"/posts/caddy-file/:3:0","tags":["云盘","caddy","server"],"title":"caddy-两步搭建超简单云盘","uri":"/posts/caddy-file/"},{"categories":["Grocery"],"content":"设置定时器启动 caddy（好像没用，我不会） 为了断开 xshell 后 caddy 还在运行。 vim run.sh 编辑以下内容 #!/bin/bash caddy 加权 chmod +x run.sh 设置任务 参考 crontab -e 加入 * * * * * /root/run.sh service crond start ","date":"2018-11-11","objectID":"/posts/caddy-file/:4:0","tags":["云盘","caddy","server"],"title":"caddy-两步搭建超简单云盘","uri":"/posts/caddy-file/"},{"categories":["Grocery"],"content":"？？？ 最后误打误撞开启了 caddy 昨晚双十一要抢裤子，加上湘潭天气太 tm 冷了，就上床了，接着用 termux 远程连接服务器继续搞。结果连接的时候命令输错了-_-! 本来是ssh root@118.24.217.167再输入密码就可以了。这次搞错了多写了个-T, 然后运行caddy,ctrl+c 再断开，意外地发现 filemanager 竟然可以访问了。 ssh -T root@118.24.217.167 caddy Ctrl+c ","date":"2018-11-11","objectID":"/posts/caddy-file/:5:0","tags":["云盘","caddy","server"],"title":"caddy-两步搭建超简单云盘","uri":"/posts/caddy-file/"},{"categories":["Memo"],"content":" 最新的 next 主题已经更新了支持 PDF 功能，写法也和链接写法一样，可是我没有更新，我按 github 上那个 readme 试了一下好像不可以，所以用了另外一种插件的方法。 ","date":"2018-11-09","objectID":"/posts/next-pdf/:0:0","tags":["hexo"],"title":"next添加支持pdf","uri":"/posts/next-pdf/"},{"categories":["Memo"],"content":"iframe(推荐) \u003ciframe src=\"/posts/next-pdf/1.pdf\" style=\"width: 100%;height: 800px;\"\u003e\u003c/iframe\u003e ","date":"2018-11-09","objectID":"/posts/next-pdf/:1:0","tags":["hexo"],"title":"next添加支持pdf","uri":"/posts/next-pdf/"},{"categories":["Memo"],"content":"模板自带 今天（2019.4.3）又看了一下，改了写法，写法和插件一样，我在我的模板里也更新了。（插件模板二选一即可,个人更喜欢插件） 但是如果安装插件后，也是优先模板的 pdf 脚本解析 pdf,所以在我的模板中把模板的 pdf 脚本先注释了。要启用去掉注释即可。 /* 'use strict'; function pdf(args) { return `\u003cdiv class=\"pdf\" target=\"${args[0]}\" height=\"${args[1] || ''}\"\u003e\u003c/div\u003e`; } hexo.extend.tag.register('pdf', pdf, {ends: false}); */ ","date":"2018-11-09","objectID":"/posts/next-pdf/:2:0","tags":["hexo"],"title":"next添加支持pdf","uri":"/posts/next-pdf/"},{"categories":["Memo"],"content":"pdf 插件(推荐) ","date":"2018-11-09","objectID":"/posts/next-pdf/:3:0","tags":["hexo"],"title":"next添加支持pdf","uri":"/posts/next-pdf/"},{"categories":["Memo"],"content":"安装 npm install --save hexo-pdf ","date":"2018-11-09","objectID":"/posts/next-pdf/:3:1","tags":["hexo"],"title":"next添加支持pdf","uri":"/posts/next-pdf/"},{"categories":["Memo"],"content":"使用 {% pdf url %} 比如本文 {% pdf /posts/next-pdf/1.pdf %} ","date":"2018-11-09","objectID":"/posts/next-pdf/:3:2","tags":["hexo"],"title":"next添加支持pdf","uri":"/posts/next-pdf/"},{"categories":["JavaScript"],"content":"前端开发经常遇到需要判断用户的浏览设备，是 pc 端还是移动端，移动端使用的是什么手机系统？android、ios、ipad、windows phone 等等，有时候还需要知道用户浏览页面是在微信中打开还是在移动端浏览器中打开，等等一系列判断做一些相应的处理。 ","date":"2018-11-03","objectID":"/posts/js-device/:0:0","tags":["JavaScript","他山之石"],"title":"js 判断用户设备类型及平台","uri":"/posts/js-device/"},{"categories":["JavaScript"],"content":"首先判断 pc 端还是移动端 function IsPC() { var userAgentInfo = navigator.userAgent; var Agents = [\"Android\", \"iPhone\", \"SymbianOS\", \"Windows Phone\", \"iPad\", \"iPod\"]; var flag = true; for (var v = 0; v \u003c Agents.length; v++) { if (userAgentInfo.indexOf(Agents[v]) \u003e 0) { flag = false; break; } } return flag; } ","date":"2018-11-03","objectID":"/posts/js-device/:0:1","tags":["JavaScript","他山之石"],"title":"js 判断用户设备类型及平台","uri":"/posts/js-device/"},{"categories":["JavaScript"],"content":"判断用户移动端使用的系统平台 var u = navigator.userAgent; if (u.indexOf('Android') \u003e -1 || u.indexOf('Linux') \u003e -1) { //安卓手机 } else if (u.indexOf('iPhone') \u003e -1) { //苹果手机 } else if (u.indexOf('Windows Phone') \u003e -1) { //winphone 手机 } ","date":"2018-11-03","objectID":"/posts/js-device/:0:2","tags":["JavaScript","他山之石"],"title":"js 判断用户设备类型及平台","uri":"/posts/js-device/"},{"categories":["JavaScript"],"content":"判断用户是否在微信中打开 function isWeiXin(){ var ua = navigator.userAgent.toLowerCase(); if(ua.indexOf('micromessenger') != -1) { return true; } else { return false; } } ","date":"2018-11-03","objectID":"/posts/js-device/:0:3","tags":["JavaScript","他山之石"],"title":"js 判断用户设备类型及平台","uri":"/posts/js-device/"},{"categories":["JavaScript"],"content":"实际运用 根据 pc 或者移动端控制飘花数目，降低 cpu 消耗，减少卡顿。demo \u003cscript\u003e function sakuraInit() { $(document).snowfall('clear'); var userAgentInfo = navigator.userAgent; var Agents = [\"Android\", \"iPhone\", \"SymbianOS\", \"Windows Phone\", \"iPad\", \"iPod\"]; var flag = true; for (var v = 0; v \u003c Agents.length; v++) { if (userAgentInfo.indexOf(Agents[v]) \u003e 0) { flag = false; break; } } if (flag) { $(document).snowfall({image:\"images/1.png\", flakeCount:5, minSpeed:1, minSize:8, maxSize:15,}); $(document).snowfall({image:\"images/2.png\", flakeCount:5, minSpeed:1, minSize:8, maxSize:15,}); $(document).snowfall({image:\"images/3.png\", flakeCount:5, minSpeed:1, minSize:8, maxSize:15,}); $(document).snowfall({image:\"images/4.png\", flakeCount:5, minSpeed:1, minSize:8, maxSize:15,}); } else { $(document).snowfall({image:\"images/1.png\", flakeCount:2, minSpeed:1, minSize:8, maxSize:15,}); $(document).snowfall({image:\"images/2.png\", flakeCount:2, minSpeed:1, minSize:8, maxSize:15,}); $(document).snowfall({image:\"images/3.png\", flakeCount:2, minSpeed:1, minSize:8, maxSize:15,}); $(document).snowfall({image:\"images/4.png\", flakeCount:2, minSpeed:1, minSize:8, maxSize:15,}); } } window.onload = sakuraInit(); \u003c/script\u003e ","date":"2018-11-03","objectID":"/posts/js-device/:0:4","tags":["JavaScript","他山之石"],"title":"js 判断用户设备类型及平台","uri":"/posts/js-device/"},{"categories":["Memo","Git"],"content":"备份 hexo 博客 //如果 themes/next（主题文件）下面有。git，请删除这个。git 文件夹。 cd hexo git init //初始化本地仓库 git add source themes scaffolds _config.yml package.json package-lock.json //将必要的文件依次添加 git commit -m \"blog hexo\" git branch hexo //新建 hexo 分支 git checkout hexo //切换到 hexo 分支上 git remote add origin git@github.com:username/username.github.io.git //将本地与 Github 项目对接 git push origin hexo //push 到 Github 项目的 hexo 分支上 ","date":"2018-11-03","objectID":"/posts/blog-backup/:1:0","tags":["Git","Node.js","hexo"],"title":"hexo 博客源码备份","uri":"/posts/blog-backup/"},{"categories":["Memo","Git"],"content":"在其他终端克隆和更新 hexo 博客 nodejs,git,hexo 已经安装好，即搭建完成 ","date":"2018-11-03","objectID":"/posts/blog-backup/:2:0","tags":["Git","Node.js","hexo"],"title":"hexo 博客源码备份","uri":"/posts/blog-backup/"},{"categories":["Memo","Git"],"content":"克隆 hexo 博客备份 git clone -b hexo git@github.com:username/username.github.io.git //将 Github 中 hexo 分支 clone 到本地 cd user.github.io npm install //注意，这里一定要切换到刚刚 clone 的文件夹内执行，安装必要的所需组件，不用再 init 这样我们的备份文件就会原封不动的拷贝到本地。 ","date":"2018-11-03","objectID":"/posts/blog-backup/:2:1","tags":["Git","Node.js","hexo"],"title":"hexo 博客源码备份","uri":"/posts/blog-backup/"},{"categories":["Memo","Git"],"content":"写新文章并备份和部署（备用操作） 其实源码拷下来了，这步不做我们也知道怎么做了，完全没必要按照教程死搬硬套。灵活一点就行了。 //进入 username.github.io 文件夹，应是 hexo 分支 git pull origin hexo //本地和远端的融合 hexo new post \"new post name\" //写新文章 git add source git commit -m \"xxx\" git push origin hexo //备份 hexo d -g //部署 参考 ","date":"2018-11-03","objectID":"/posts/blog-backup/:2:2","tags":["Git","Node.js","hexo"],"title":"hexo 博客源码备份","uri":"/posts/blog-backup/"},{"categories":["随笔"],"content":" 备案 经过时间长达 20 多天的备案之旅今天终于结束了，也闭馆了 20 多天，也按相关要求把 ICP 备案号和公安备案号加载了网站和博客底部。只是今天去岳塘分局签网络安全告知书的时候不小心把身份证落在那个办公室了。亏我走之前一秒还在提醒自己，唉！不过那个办公室的大姐姐挺好的，前面跟我说好星期一来，我还今天上午提前给她打了电话，她还下楼给我开办公楼楼道的门禁，还有我身份证落在那里她说先帮我收着，有时间再去拿！总之，这个姐姐的服务态度五星好评！手动@岳塘分局 B204 的姐姐。 备案完成也算放下一块提着的石头，可以睡个好觉了！ZzZzzzz ","date":"2018-10-29","objectID":"/posts/beian/:0:0","tags":["随笔","网站备案"],"title":"网站备案之旅","uri":"/posts/beian/"},{"categories":["OS"],"content":"今天上机学了几个小命令 read echo if 然后自己写了一个小脚本觉得还挺有趣的 #!/bin/bash #liruihao #menu.sh #sudo apt curl install nyancat sl figlet toilet cowsay echo \"-------------菜-单--------------\" echo \"------------1-打印二维码--------\" echo \"------------2-彩虹猫------------\" echo \"------------3-小火切------------\" echo \"------------4-打字机------------\" echo \"------------5-小许牛------------\" echo \"----------Ctrl+c 暂停程序--------\" echo \"\" echo \"请输入序号！\" read i if test $i -eq 1 then echo \"请输入网址！\" read s1 echo $s1 |curl -F-=\\\u003c- qrenco.de fi if test $i -eq 2 then nyancat fi if test $i -eq 3 then sl fi if test $i -eq 4 then echo \"请输入字符串！\" read s2 echo \"选择样式：\" echo \"------样式 1-----\" echo \"------样式 2-----\" read j if test $j -eq 1 then figlet $s2 else toilet -f mono12 -F gay $s2 fi fi if test $i -eq 5 then echo \"请输入字符串！\" read s3 cowsay $s3 fi echo \"任意建继续！\" read x clear ./menu.sh ","date":"2018-10-29","objectID":"/posts/shell/:0:0","tags":["shell","linux"],"title":"shell 脚本初体验","uri":"/posts/shell/"},{"categories":["OS"],"content":"搭建 Apache web 服务 安装 Apache 超文本传输协议 (HTTP) 服务器的主程序 [root@VM_0_6_centos /]# yum install -y httpd 注意安装目录，可通过 cd 命令切换。 启动 HTTP 服务 [root@VM_0_6_centos /]# systemctl start httpd.service 如果启动失败，可通过 systemctl status httpd.service 查看错误原因。 启动成功，证明 http 服务已经可以使用，发现还需要把本地文件传到服务器。 默认根目录/var/www/html/ ","date":"2018-10-29","objectID":"/posts/web-server-yun/:0:1","tags":["server","linux","他山之石"],"title":"云服务器 CentOS 系统搭建 web 服务","uri":"/posts/web-server-yun/"},{"categories":["OS"],"content":"使用 SSH 连接服务器 尝试了两种方式：PuTTY 和 Xshell（推荐） Xshell 方式 官网下载安装 Xshell 打开，输入 ip 账号密码连接主机。 使用 lrzsz 方式上传下载文件 步骤 1：在服务器安装 lrzsz [root@VM_0_6_centos /]# yum -y install lrzsz 步骤 2：输入命令rz打开上传窗口（可以选择多个文件。) 使用sz文件名命令可打开从服务器下载文件的保存窗口。 ","date":"2018-10-29","objectID":"/posts/web-server-yun/:0:2","tags":["server","linux","他山之石"],"title":"云服务器 CentOS 系统搭建 web 服务","uri":"/posts/web-server-yun/"},{"categories":["OS"],"content":"修改 HTTP 配置 1.VIM 编辑器打开配置文件 [root@VM_0_6_centos /]# vim /etc/httpd/conf/httpd.conf 按I键进入编辑模式 找到并修改以下内容 ServerAdmin 管理员邮箱，用于浏览器请求报错时展示 DocumentRoot 访问根目录（默认：/var/www/html），如项目存放在其他地方，可修改为项目存放位置 \u003cDirectory \"/var/www/html\"\u003e 同 DocumentRoot 配置 ServerName 服务器 IP 或 域名 按下 ESC 键输入:wq保存退出 重启服务service httpd restart 打开浏览器，输入地址访问 如：我的项目索引 html 路径为 love/index.html，输入 http://IP 地址或域名/love/index.html 访问不成功，先检查网络，再查看 http 服务是否开启，最后检查配置； 访问成功，配置完成。 ","date":"2018-10-29","objectID":"/posts/web-server-yun/:0:3","tags":["server","linux","他山之石"],"title":"云服务器 CentOS 系统搭建 web 服务","uri":"/posts/web-server-yun/"},{"categories":["JavaScript"],"content":"获取链接（转） 传送门 在 WEB 开发中，时常会用到 javascript 来获取当前页面的 url 网址信息，在这里是我的一些获取 url 信息的小总结。 下面我们举例一个 URL，然后获得它的各个组成部分：http://i.cnblogs.com/EditPosts.aspx?opt=1 window.location.href（设置或获取整个 URL 为字符串） var test = window.location.href; alert(test); 返回：http://i.cnblogs.com/EditPosts.aspx?opt=1 window.location.protocol（设置或获取 URL 的协议部分） var test = window.location.protocol; alert(test); 返回：http: window.location.host（设置或获取 URL 的主机部分） var test = window.location.host; alert(test); 返回：i.cnblogs.com window.location.port（设置或获取与 URL 关联的端口号码） var test = window.location.port; alert(test); 返回：空字符（如果采用默认的 80 端口 (update: 即使添加了：80)，那么返回值并不是默认的 80 而是空字符） window.location.pathname（设置或获取与 URL 的路径部分（就是文件地址）) var test = window.location.pathname; alert(test); 返回：/EditPosts.aspx window.location.search（设置或获取 href 属性中跟在问号后面的部分） var test = window.location.search; alert(test); 返回：?opt=1 PS：获得查询（参数）部分，除了给动态语言赋值以外，我们同样可以给静态页面，并使用 javascript 来获得相信应的参数值。 window.location.hash（设置或获取 href 属性中在井号“#”后面的分段） var test = window.location.hash; alert(test); 返回：空字符（因为 url 中没有） js 获取 url 中的参数值 正则法 function getQueryString(name) { var reg = new RegExp('(^|\u0026)' + name + '=([^\u0026]*)(\u0026|$)', 'i'); var r = window.location.search.substr(1).match(reg); if (r != null) { return unescape(r[2]); } return null; } // 这样调用： alert(GetQueryString(\"参数名 1\")); alert(GetQueryString(\"参数名 2\")); alert(GetQueryString(\"参数名 3\")); split 拆分法 function GetRequest() { var url = location.search; //获取 url 中\"?\"符后的字串 var theRequest = new Object(); if (url.indexOf(\"?\") != -1) { var str = url.substr(1); strs = str.split(\"\u0026\"); for(var i = 0; i \u003c strs.length; i ++) { theRequest[strs[i].split(\"=\")[0]] = unescape(strs[i].split(\"=\")[1]); } } return theRequest; } var Request = new Object(); Request = GetRequest();\u003cbr\u003e// var id=Request[\"id\"]; // var 参数 1, 参数 2, 参数 3, 参数 N; // 参数 1 = Request['参数 1']; // 参数 2 = Request['参数 2']; // 参数 3 = Request['参数 3']; // 参数 N = Request['参数 N']; 指定取 比如说一个 url：http://i.cnblogs.com/?j=js, 我们想得到参数 j 的值，可以通过以下函数调用。 function GetQueryString(name) { var reg = new RegExp(\"(^|\u0026)\" + name + \"=([^\u0026]*)(\u0026|$)\", \"i\"); var r = window.location.search.substr(1).match(reg); //获取 url 中\"?\"符后的字符串并正则匹配 var context = \"\"; if (r != null) context = r[2]; reg = null; r = null; return context == null || context == \"\" || context == \"undefined\" ? \"\" : context; } alert(GetQueryString(\"j\")); ","date":"2018-10-28","objectID":"/posts/href-301/:0:1","tags":["redirect","JavaScript","他山之石"],"title":"使用 js 准确获取当前页面 url 网址信息及 301 重定向实战","uri":"/posts/href-301/"},{"categories":["JavaScript"],"content":"301 重定向（实践） 由于之前把 blog 和网站主页分开在两个仓库所以要想在 blog 中 menu 里跳转到站外链接就要做一些处理。以前一直百度不到。 其实想法早就有了，只要在 blog 首页或者网站首页检测到https://lruihao.cn/home这个链接，或者检测到 home 字段就自动跳转。想法很简单。可是对 js 真的一点都不了解，以前百度也找不到实际的效果案例。所以还是自己写吧！附上蹩脚代码。 var path = window.location.href; //alert(path); if (path=='https://lruihao.cn/home/') { window.location.replace(\"https://www.lruihao.cn\"); } 或者 var path = window.location.pathname; //alert(path); if (path=='/home/') { window.location.replace(\"https://www.lruihao.cn\"); } http 强制重定向 https \u003cscript\u003e var targetProtocol = \"https:\"; var host = \"lruihao.cn\"; //域名判断，因为 localhost 仅支持 http if (window.location.host == host \u0026\u0026 window.location.protocol != targetProtocol){ window.location.href = targetProtocol + window.location.href.substring(window.location.protocol.length); } \u003c/script\u003e ","date":"2018-10-28","objectID":"/posts/href-301/:0:2","tags":["redirect","JavaScript","他山之石"],"title":"使用 js 准确获取当前页面 url 网址信息及 301 重定向实战","uri":"/posts/href-301/"},{"categories":["Grocery"],"content":" 我用的 win10 ","date":"2018-10-26","objectID":"/posts/web-server-win/:0:0","tags":["server","windows"],"title":"windows 上搭建 web 服务器","uri":"/posts/web-server-win/"},{"categories":["Grocery"],"content":"打开控制面板 选择并进入“程序”，双击“启用或关闭 Windows 服务”，在弹出的窗口中选择“Internet Information Services”下面所有地选项，点击确定后，开始更新服务。 打开控制面板 ","date":"2018-10-26","objectID":"/posts/web-server-win/:0:1","tags":["server","windows"],"title":"windows 上搭建 web 服务器","uri":"/posts/web-server-win/"},{"categories":["Grocery"],"content":"查看 更新完成后，打开浏览器，输入http://localhost或者127.0.0.1回车，如果此时出现 IIS7 欢迎界面，说明 Web 服务器已经搭建成功。 查看 ","date":"2018-10-26","objectID":"/posts/web-server-win/:0:2","tags":["server","windows"],"title":"windows 上搭建 web 服务器","uri":"/posts/web-server-win/"},{"categories":["Grocery"],"content":"网站设置 当 web 服务器搭建成功后，我们下一步所要做的就是把我们开发的网站安装到 Web 服务器的目录中。一般情况下，当 Web 服务器安装完成后，会创建路径%系统根目录%inetpub/wwwroot，将我们开发的网站 COPY 到该路径下。即可实现本地访问该网站。 也可以更改根目录，搜索 IIS，点击网站，Default Web Site，基本设置修改物理路径（默认站点名称不要改） 我这里改到了 hexo 的 public 相当于 hexo 部署在本地服务器58.45.227.225 ","date":"2018-10-26","objectID":"/posts/web-server-win/:0:3","tags":["server","windows"],"title":"windows 上搭建 web 服务器","uri":"/posts/web-server-win/"},{"categories":["Grocery"],"content":"设置防火墙 让局域网当其它计算机也能访问本地网站资源。具体方法：打开控制面板，选择“系统和安全”，点击“允许程序通过 Windows 防火墙”，在弹出的对话框中勾选“万维网服务 HTTP”右侧的两个复选框，最后点击确定退出。 在局域网中其它计算机上，打开浏览器就可以通过你电脑的 ip 地址访问了（手机也可以） 本地 ip 可以通过 cmd 用 ipconfig 查看 ","date":"2018-10-26","objectID":"/posts/web-server-win/:0:4","tags":["server","windows"],"title":"windows 上搭建 web 服务器","uri":"/posts/web-server-win/"},{"categories":["Git"],"content":"config git config --global user.name \"Your Name\" git config --global user.email \"email@example.com\" 第一次使用 git 的时候需要设置提交者信息。 注意： 如果用了 --global 选项，那么更改的配置文件就是位于你用户主目录下的那个，以后你所有的项目都会默认使用这里配置的用户信息。 如果要在某个特定的项目中使用其他名字或者电邮，只要去掉 --global 选项重新配置即可，新的设定保存在当前项目的 .git/config 文件里。 ","date":"2018-10-26","objectID":"/posts/gituse/:0:1","tags":["Git"],"title":"使用 Git 上传代码到 github, coding 等仓库","uri":"/posts/gituse/"},{"categories":["Git"],"content":"生成 ssh 由于你的本地 Git 仓库和 GitHub 仓库之间的传输是通过 SSH 加密的，所以我们需要配置验证信息： 使用以下命令生成 SSH Key： ssh-keygen -t rsa -C \"youremail@example.com\" 后面的 your_email@youremail.com 改为你在 Github 上注册的邮箱，之后会要求确认路径和输入密码，我们这使用默认的一路回车就行。成功的话会在 C:\\Users\\用户名、或者~/ 下生成 .ssh文件夹，进去，打开 id_rsa.pub，复制里面的 key。去 github、coding 等平台配置 SSH 公钥（根据自己情况） ","date":"2018-10-26","objectID":"/posts/gituse/:0:2","tags":["Git"],"title":"使用 Git 上传代码到 github, coding 等仓库","uri":"/posts/gituse/"},{"categories":["Git"],"content":"创建本地代码库 在本地创建一个文件夹，作为你上传代码的本地仓库，在这个文件夹内点击右键，选择 Git Bash Here，首先要初始化本地仓库： git init 接下来进行远程代码库克隆（事先在 coding 等中建立一个项目，就是你需要链接的仓库） git clone https://github.com/Lruihao/Lruihao.github.io.git 克隆时会出现输入账号密码的环节正确输入即可。 ","date":"2018-10-26","objectID":"/posts/gituse/:0:3","tags":["Git"],"title":"使用 Git 上传代码到 github, coding 等仓库","uri":"/posts/gituse/"},{"categories":["Git"],"content":"代码推送（重点） git status git add * git commit -m \"代码备注随便写\" git push origin master Gearn Git Branching ","date":"2018-10-26","objectID":"/posts/gituse/:0:4","tags":["Git"],"title":"使用 Git 上传代码到 github, coding 等仓库","uri":"/posts/gituse/"},{"categories":["Memo"],"content":" 前面有一篇文章写到一些，在 Android 上搭建 hexo 博客 本文当初摘要自 国光个人博客 如若作者博客 IP 被墙，可前往国光第三方博客诸如 csdn 等。备用 ","date":"2018-10-23","objectID":"/posts/termux1/:0:0","tags":["Node.js","linux","termux"],"title":"termux 基本使用教程","uri":"/posts/termux1/"},{"categories":["Memo"],"content":"初始化 下载并初始化 termux 安装 vim 安装编辑器 vim pkg install vim 解决中文乱码问题 在 home 目录下，新建 .vimrc 文件 vim .vimrc 添加内容如下： set fileencodings=utf-8,gb2312,gb18030,gbk,ucs-bom,cp936,latin1 set enc=utf8 set fencs=utf8,gbk,gb2312,gb18030 然后 source 下变量： source .vimrc 修改启动问候语 vim $PREFIX/etc/motd 按 i 然后编辑，比如 www.lruihao.cn 李瑞豪 Esc 然后：wq 退出 管理员权限 手机已经 root, 安装 tsu, 这是一个 su 的 termux 版本，用来在 termux 上替代 su: pkg install tsu 然后终端下面输入： tsu 即可切换 root 用户，这个时候会弹出 root 授权提示。在管理员身份下，输入 exit 可回到普通用户身份。 ","date":"2018-10-23","objectID":"/posts/termux1/:0:1","tags":["Node.js","linux","termux"],"title":"termux 基本使用教程","uri":"/posts/termux1/"},{"categories":["Memo"],"content":"美化 Termux-ohmyzsh 作用 ： 美化之外，主要使用了 zsh 来替代 bash 作为默认 shell。使用一键安装脚本来安装，一步到位，顺便启动了外置存储，可以直接访问 SD 卡下的目录，创建软文件夹。 使用 sh -c \"$(curl -fsSL https://github.com/Cabbagec/termux-ohmyzsh/raw/master/install.sh)\" 设置色彩样式： 运行 chcolor 更换色彩样式，或者： ~/.termux/colors.sh 设置字体 运行 chfont 更换字体，或者： ~/.termux/fonts.sh 需要软件包： curl ","date":"2018-10-23","objectID":"/posts/termux1/:0:2","tags":["Node.js","linux","termux"],"title":"termux 基本使用教程","uri":"/posts/termux1/"},{"categories":["Memo"],"content":"访问外置存储 执行过上面的 zsh 一键配置脚本后，并且授予文件访问权限的话，会在家目录生成 storage 目录，并且生成若干目录，软连接都指向外置存储卡的相应目录 可以让从外置储存复制文件进 system 分区 创建 QQ 文件夹软连接 ln -s /data/data/com.termux/files/home/storage/shared/tencent/QQfile_recv QQ 创建 blog2 文件夹软连接备份文件 ln -s /data/data/com.termux/files/home/storage/shared/blog2 blog2 ","date":"2018-10-23","objectID":"/posts/termux1/:0:3","tags":["Node.js","linux","termux"],"title":"termux 基本使用教程","uri":"/posts/termux1/"},{"categories":["Memo"],"content":"安装 hexo 安装准备 pkg install nodejs pkg install git npm install hexo-cli -g npm install hexo-deployer-git --save pkg install openssh 初始化 hexo hexo init blog cd blog hexo g hexo s 浏览器输入127.0.0.1:4000查看效果 链接 github,coding,gitee 等远程仓库 ssh-keygen -t rsa -C \"your_email@example.com\" #这将按照你提供的邮箱地址，创建一对密钥（个人喜欢一路回车） 找到~/.ssh/id_rsa.pub这个文件复制里面的内容，到对应的平台生成 SSH 公钥 设置用户信息 git config --global user.name \"lruihao\" git config --global user.email \"1074627678@qq.com\" 测试链接 ssh -T git@github.com #github ssh -T git@coding.net #coding ssh -T git@gitee.com #gitee 注意#注释部分不要的 站点配置文件 打开站点配置文件填写代码库 例如我的 deploy: - type: git repository: github: git@github.com:Lruihao/Lruihao.github.io.git,master coding: git@git.coding.net:liruihao/liruihao.git,master #message: \"日常更新\" 部署 hexo clean hexo g -d 没出错就可以正常通过相应域名访问了。 https://lruihao.github.io https://liruihao.coding.me https://lruihao.gitee.io //手机 hexo 效果展示 ","date":"2018-10-23","objectID":"/posts/termux1/:0:4","tags":["Node.js","linux","termux"],"title":"termux 基本使用教程","uri":"/posts/termux1/"},{"categories":["Memo"],"content":"ssh 连接电脑或者服务器 ssh root@118.24.217.167 会提示输入密码，linux 下输入密码是看不到的，大家都知道，小心点别输入错误。 之后就可以手机操作服务器了。 ","date":"2018-10-23","objectID":"/posts/termux1/:0:5","tags":["Node.js","linux","termux"],"title":"termux 基本使用教程","uri":"/posts/termux1/"},{"categories":["Memo"],"content":"解决 npm 安装报错（未验证） vim $PREFIX/lib/node_modules/npm/node_modules/worker-farm/lib/farm.js 把里面的 length 改成 4，我默认的是 1。 ","date":"2018-10-23","objectID":"/posts/termux1/:0:6","tags":["Node.js","linux","termux"],"title":"termux 基本使用教程","uri":"/posts/termux1/"},{"categories":["Memo"],"content":"nyancat 彩虹猫 彩虹貓（英语：Nyan Cat）是在 2011 年 4 月上传在 Youtube 的视频，并且迅速爆红于网络，並在 2011 年 YouTube 浏览量最高的视频中排名第五。 pkg install nyancat nyancat 还有更多姿势这里就不写了，只写一下日常用到的，就这样 OK 睡觉！ ","date":"2018-10-23","objectID":"/posts/termux1/:0:7","tags":["Node.js","linux","termux"],"title":"termux 基本使用教程","uri":"/posts/termux1/"},{"categories":["Memo"],"content":"termux 更多常用有趣命令（适用于 linux） vim $PREFIX/etc/motd chcolor chfont ~/.termux/colors.sh ~/.termux/fonts.sh echo \"https://www.lruihao.cn\" |curl -F-=\\\u003c- qrenco.de pkg install nyancat nyancat pkg install sl sl pkg install figlet figlet hello pkg install toilet toilet hello toilet -f mono12 -F gay \"hello\" pkg cowsay cowsay \"hello\" pkg install cmatrix cmatrix pkg install w3m w3m www.lruihao.cn cmatrix 常用命令如下： cmatrix-a : 异步滚动（默认） cmatrix-b : 随机粗体 cmatrix-B : 全部粗体 cmatrix-o : 使用旧风格滚动 cmatrix-x :X window 模式 cmatrix-V : 显示版本信息 cmatrix-u : 刷新频率，0-9，也就是滚动的快慢 cmatrix-C : 显示的颜色，支持 green（默认）,red,blue,white,yellow,cyan, magenta and black 例如：使用红色 cmatrix -b -C red 使用蓝色 cmatrix -b -C blue 等等 ........ 主义：在运行状态下，使用 0-9 数字，可以改变运行速度快慢。 开启你的装逼之路把，骚年！ ","date":"2018-10-23","objectID":"/posts/termux1/:0:8","tags":["Node.js","linux","termux"],"title":"termux 基本使用教程","uri":"/posts/termux1/"},{"categories":["Grocery"],"content":"html 网页引用中文字体，文件过大，加载缓慢的解决办法","date":"2018-10-17","objectID":"/posts/web-font/","tags":["Node.js","字体压缩"],"title":"ttf 字体压缩","uri":"/posts/web-font/"},{"categories":["Grocery"],"content":"安装 nodeJs 这个不多说，都有。 ","date":"2018-10-17","objectID":"/posts/web-font/:0:1","tags":["Node.js","字体压缩"],"title":"ttf 字体压缩","uri":"/posts/web-font/"},{"categories":["Grocery"],"content":"安装字蛛 输入命令 npm install font-spider -g ","date":"2018-10-17","objectID":"/posts/web-font/:0:2","tags":["Node.js","字体压缩"],"title":"ttf 字体压缩","uri":"/posts/web-font/"},{"categories":["Grocery"],"content":"运行 安装成功之后就开始压缩了 我的 css \u003cstyle type=\"text/css\"\u003e @font-face { font-family: MMT; src: url(\"font/MMT_579767_SOAJ0_0.ttf\"); } \u003c/style\u003e 生成新的字体库，命令行输入 font-spider C:\\Users\\李瑞豪、Desktop\\love\\index.html 官网 ","date":"2018-10-17","objectID":"/posts/web-font/:0:3","tags":["Node.js","字体压缩"],"title":"ttf 字体压缩","uri":"/posts/web-font/"},{"categories":["OS"],"content":" 在 Linux 上编译 c 语言文件。 ","date":"2018-10-15","objectID":"/posts/linux-hello-c/:0:0","tags":["linux","C"],"title":"linux 编程初体验","uri":"/posts/linux-hello-c/"},{"categories":["OS"],"content":"打开 vim 编辑器 （没有就用 vi, 或者先安装 vimsudo apt-get install vim) $ vim ","date":"2018-10-15","objectID":"/posts/linux-hello-c/:0:1","tags":["linux","C"],"title":"linux 编程初体验","uri":"/posts/linux-hello-c/"},{"categories":["OS"],"content":"编辑文件 打开文件编辑器之后编辑文件 首先按Esc再:进入末行命令 再保存为 hello.c 文件后退出 : w hello.c : q 打开目录看看生成的文件 $ ls ","date":"2018-10-15","objectID":"/posts/linux-hello-c/:0:2","tags":["linux","C"],"title":"linux 编程初体验","uri":"/posts/linux-hello-c/"},{"categories":["OS"],"content":"编译生成可执行文件并执行 $ gcc hello.c -o hello $ ./hello 若权限不够则加可执行权限chmod +x hello ","date":"2018-10-15","objectID":"/posts/linux-hello-c/:0:3","tags":["linux","C"],"title":"linux 编程初体验","uri":"/posts/linux-hello-c/"},{"categories":["Projects"],"content":"预览 {{ message || '「沐目之，湘也」\\n 从下笔到停笔，从开始到结束，沐目体见证了我们稚嫩到成熟。\\n故事的开头往往极具温柔，但结局常常不尽人意。\\n那些忘不掉的人和事，岁月都已替我轻描淡写。' }} From playlist, Powered By mmt-netease 点击展开更多 《富士山下》 《爱情转移》 前尘硬化像石头 阳光在身上流转 随缘地抛下便逃走 等所有业障被原谅 我绝不罕有 爱情不停站 往街里绕过一周 想开往地老天荒 我便化乌有 需要多勇敢 你还嫌不够 你不要失望 我把这陈年风褛 荡气回肠是为了 送赠你解咒 最美的平凡 ","date":"2018-10-12","objectID":"/projects/font-mmt/:1:0","tags":["沐目体"],"title":"沐目体","uri":"/projects/font-mmt/"},{"categories":["Projects"],"content":"下载 警告 沐目体 仅用于个人非商用！ ","date":"2018-10-12","objectID":"/projects/font-mmt/:2:0","tags":["沐目体"],"title":"沐目体","uri":"/projects/font-mmt/"},{"categories":["Grocery"],"content":"概念 流水线是指在程序执行时多条指令重叠进行操作的一种准并行处理实现技术。各种部件同时处理是针对不同指令而言的，它们可同时为多条指令的不同部分进行工作，以提高各部件的利用率和指令的平均执行速度。 未使用流水线 使用流水线 流水线周期为执行时间最长的一段。 ","date":"2018-10-09","objectID":"/posts/liushuixian/:1:0","tags":["流水线","计算机组成与体系结构"],"title":"流水线","uri":"/posts/liushuixian/"},{"categories":["Grocery"],"content":"流水线计算公式 首先使用理论公式，没有答案用实践公式。 ","date":"2018-10-09","objectID":"/posts/liushuixian/:2:0","tags":["流水线","计算机组成与体系结构"],"title":"流水线","uri":"/posts/liushuixian/"},{"categories":["Grocery"],"content":"流水线吞吐率计算 流水线吞吐率是指单位时间内处理的任务的数量。 基本公式 最大吞吐率 ","date":"2018-10-09","objectID":"/posts/liushuixian/:3:0","tags":["流水线","计算机组成与体系结构"],"title":"流水线","uri":"/posts/liushuixian/"},{"categories":["Grocery"],"content":"流水线加速比 完成一批任务，不使用流水线所用的时间与使用流水线所用的时间之比称为流水线的加速比。 公式： S=不使用流水线执行时间/使用流水线执行时间 流水线加速比越高越好，说明使用流水线的效果。 ","date":"2018-10-09","objectID":"/posts/liushuixian/:4:0","tags":["流水线","计算机组成与体系结构"],"title":"流水线","uri":"/posts/liushuixian/"},{"categories":["Grocery"],"content":"流水线的效率 ","date":"2018-10-09","objectID":"/posts/liushuixian/:5:0","tags":["流水线","计算机组成与体系结构"],"title":"流水线","uri":"/posts/liushuixian/"},{"categories":["Grocery"],"content":"例题 ","date":"2018-10-09","objectID":"/posts/liushuixian/:6:0","tags":["流水线","计算机组成与体系结构"],"title":"流水线","uri":"/posts/liushuixian/"},{"categories":["Grocery"],"content":"其他 ","date":"2018-10-09","objectID":"/posts/liushuixian/:7:0","tags":["流水线","计算机组成与体系结构"],"title":"流水线","uri":"/posts/liushuixian/"},{"categories":["Grocery"],"content":"主机 ","date":"2018-10-09","objectID":"/posts/liushuixian/:7:1","tags":["流水线","计算机组成与体系结构"],"title":"流水线","uri":"/posts/liushuixian/"},{"categories":["Grocery"],"content":"CISC 和 RISC 类型 指令 寻址方式 实现方式 其他 CISC（复杂指令集） 数量多，使用频率差别大，可变长格式 支持多种 微程序控制技术（微码） 研制周期长 RISC（精简指令集） 数量少，使用频率接近，定长格式，大部分为单周期指令，操作寄存器，只有 Load/Store 操作内存 支持方式少 增加了通用寄存器；硬布线逻辑控制为主；适合采用流水线 优化编码，有效支持高级语言 ","date":"2018-10-09","objectID":"/posts/liushuixian/:7:2","tags":["流水线","计算机组成与体系结构"],"title":"流水线","uri":"/posts/liushuixian/"},{"categories":["Grocery"],"content":"数据的表示 数据的表示可分为：原码，反码和补码。（二进制） 原码： 符号位 0 为正，1 为负。 反码： 符号位 0 为正，1 为负。 正数： 反码同原码。 负数： 符号位除外其他位按位取反。 补码： 正数： 同原码。 负数： 符号位除外其他位按位取反再+1。 移码： 补码符号位取反。 ","date":"2018-10-08","objectID":"/posts/data/:0:1","tags":["计算机数据","计算机组成与体系结构"],"title":"计算机数据","uri":"/posts/data/"},{"categories":["Grocery"],"content":"数据表示范围 原码： -(z^n-1 - 1) ~ 2^n-1 - 1 反码： -(z^n-1 - 1) ~ 2^n-1 - 1 补码： -z^n-1 ~ 2^n-1 - 1 （补码正 0 和负 0 相同，少占一数位，就多一个范围） 例： 8 位二进制，除去符号位还有 7 位，7 个 1 为最大数，相当于 8 个 1 减 1，也就是 2^7-1, 所以范围就算出来了。 ","date":"2018-10-08","objectID":"/posts/data/:0:2","tags":["计算机数据","计算机组成与体系结构"],"title":"计算机数据","uri":"/posts/data/"},{"categories":["Grocery"],"content":"浮点数运算 对阶（小阶对大阶）+ 尾数计算（科学计数法）+ 结果规格化（科学技术法） ","date":"2018-10-08","objectID":"/posts/data/:0:3","tags":["计算机数据","计算机组成与体系结构"],"title":"计算机数据","uri":"/posts/data/"},{"categories":["JavaScript"],"content":" 这几天看到别人的博客有开关灯效果，就想给自己的博客也加一个，其实以前就在想了。经过谷歌百度后这样实现了。css+js 如何给 Web 页面增加夜间模式功能？其实所谓的夜间模式就是在页面上增加一个透明的遮罩层，但是遮罩层会挡住页面元素， 解决方法是 添加 DIV，给 DIV 的 outline 属性一个很大的 outline-width 值，用 outline 的边框作为遮罩，这样既能正常点击页面元素，又能达到夜间模式的效果。 ","date":"2018-09-27","objectID":"/posts/night/:0:0","tags":["JavaScript"],"title":"网页夜间效果","uri":"/posts/night/"},{"categories":["JavaScript"],"content":"css 部分 \u003cstyle\u003e .cover{ position:fixed; top: 0px; left: 0px; outline:5000px solid rgba(0, 0, 0, 0);//初始亮度 z-index: 99999; } \u003c/style\u003e ","date":"2018-09-27","objectID":"/posts/night/:0:1","tags":["JavaScript"],"title":"网页夜间效果","uri":"/posts/night/"},{"categories":["JavaScript"],"content":"js 部分 \u003cscript\u003e var brightness; //显示遮罩 function cover(brightness) { if (typeof(div) == 'undefined') { div = document.createElement('div'); div.setAttribute('style', 'position:fixed;top:0;left:0;outline:5000px solid;z-index:99999;'); document.body.appendChild(div); } else { div.style.display = ''; } div.style.outlineColor = 'rgba(0,0,0,' + brightness + ')'; } //事件监听 window.addEventListener('keydown', function(e) { if (e.altKey \u0026\u0026 e.keyCode == 90) { cover(brightness = 0.3); } if (e.altKey \u0026\u0026 e.keyCode == 88) { cover(brightness = 0); } if (e.altKey \u0026\u0026 e.keyCode == 38) { if (brightness - 0.05 \u003e 0.05) cover(brightness -= 0.05); } if (e.altKey \u0026\u0026 e.keyCode == 40) { if (brightness + 0.05 \u003c 0.95) cover(brightness += 0.05); } }, false); \u003c/script\u003e ","date":"2018-09-27","objectID":"/posts/night/:0:2","tags":["JavaScript"],"title":"网页夜间效果","uri":"/posts/night/"},{"categories":["JavaScript"],"content":"html 部分 \u003cdiv class=\"cover\"\u003e\u003c/div\u003e ","date":"2018-09-27","objectID":"/posts/night/:0:3","tags":["JavaScript"],"title":"网页夜间效果","uri":"/posts/night/"},{"categories":["JavaScript"],"content":"使用 Alt+Z: 打开夜间模式 Alt+X: 关闭 Alt+↑: 增加亮度 Alt+↓: 降低亮度 ","date":"2018-09-27","objectID":"/posts/night/:0:4","tags":["JavaScript"],"title":"网页夜间效果","uri":"/posts/night/"},{"categories":["JavaScript"],"content":" 从暑假到现在有好几个小伙伴问我博客的标题怎么变来变去的，不想再和每个人都说一遍了，耽误时间，索性写一下。 ","date":"2018-09-26","objectID":"/posts/crash-cheat/:0:0","tags":["JavaScript","hexo"],"title":"网页离开时改变标题“崩溃欺骗”","uri":"/posts/crash-cheat/"},{"categories":["JavaScript"],"content":"创建一个 js 文件 我们先创建一个 js 文件，我们用记事本就好了，然后改个文件名，不妨就叫crash-cheat.js吧，你们可以随意！ 然后把文件放到 source 文件夹的 js 文件夹的 src 里面。（我用的 next 主题，放这里统一存放，其他主题随意） 崩溃欺骗 (Jquery 版） var OriginTitle = document.title; var titleTime; document.addEventListener('visibilitychange', function () { if (document.hidden) { $('[rel=\"icon\"]').attr('href', 'https://i.loli.net/2018/08/24/5b7fcb00ed9bf.png'); document.title = '怎么回事╭(°A°`)╮'; clearTimeout(titleTime); } else { $(\"[rel='icon']\").attr('href', 'https://i.loli.net/2018/09/25/5baa4f21661e7.png'); document.title = '小老弟 (ฅ\u003eω\u003c*ฅ)'; titleTime = setTimeout(function () { document.title = OriginTitle; $(\"[rel='icon']\").attr('href', '/images/favicon-32x32-next.png'); }, 2000); } }); 崩溃欺骗 (JS 版） var oldTitle = document.title; var titleTime; //標題恢復計時器 document.addEventListener('visibilitychange', function () { if (document.hidden) { document.querySelector(\"[rel='icon']\").setAttribute('href', '/images/icons/favicon-32.png'); document.title = '網站崩潰了！'; clearTimeout(titleTime); } else { document.title = '其實並沒有！'; document.querySelector(\"[rel='icon']\").setAttribute('href', '/images/icons/crash.png'); titleTime = setTimeout(function () { document.title = oldTitle; }, 1000); } }); ","date":"2018-09-26","objectID":"/posts/crash-cheat/:1:0","tags":["JavaScript","hexo"],"title":"网页离开时改变标题“崩溃欺骗”","uri":"/posts/crash-cheat/"},{"categories":["JavaScript"],"content":"使用 在hexo\\themes\\hexo-theme-next\\layout文件路径找到layout.swig文件，其他有些主题用的是.ejs后缀，一样的。 然后打开文件，在\u003cbody\u003e\u003c/body\u003e之间加入调用刚刚的 js。 \u003cscript type=\"text/javascript\" src=\"/js/src/crash-cheat.js\"\u003e\u003c/script\u003e 重新部署博客就可以了。 ","date":"2018-09-26","objectID":"/posts/crash-cheat/:2:0","tags":["JavaScript","hexo"],"title":"网页离开时改变标题“崩溃欺骗”","uri":"/posts/crash-cheat/"},{"categories":["Git","OS"],"content":"下载 git wget https://github.com/git/git/archive/v2.14.1.zip ","date":"2018-09-22","objectID":"/posts/linux-git/:0:1","tags":["Git","linux"],"title":"linux/centos 下的安装 git","uri":"/posts/linux-git/"},{"categories":["Git","OS"],"content":"安装依赖 sudo yum -y install zlib-devel openssl-devel cpio expat-devel gettext-devel curl-devel perl-ExtUtils-CBuilder perl-ExtUtils-MakeMaker ","date":"2018-09-22","objectID":"/posts/linux-git/:0:2","tags":["Git","linux"],"title":"linux/centos 下的安装 git","uri":"/posts/linux-git/"},{"categories":["Git","OS"],"content":"解压 git unzip v2.14.1.zip 注： unzip 命令用不了，具体步骤如下： #yum list | grep zip/unzip #yum install zip #yum install unzip 基本完成，如果在编译的时候出现错误：gcc : error trying to exec 'cc1plus': execvp : No sunch file or directory 可以用gcc -v/g++ -v 来查看 gcc 版本，会发现没有安装。安装如下： #yum list | grep gcc #yum install gcc-c++ #yum install unzip ","date":"2018-09-22","objectID":"/posts/linux-git/:0:3","tags":["Git","linux"],"title":"linux/centos 下的安装 git","uri":"/posts/linux-git/"},{"categories":["Git","OS"],"content":"将 git 安装到/usr/local 上 先进入 git 文件夹 编译 安装 cd git-2.14.1 make prefix=/usr/local all make prefix=/usr/local install ","date":"2018-09-22","objectID":"/posts/linux-git/:0:4","tags":["Git","linux"],"title":"linux/centos 下的安装 git","uri":"/posts/linux-git/"},{"categories":["Git","OS"],"content":"验证是否安装完成 git --version … ","date":"2018-09-22","objectID":"/posts/linux-git/:0:5","tags":["Git","linux"],"title":"linux/centos 下的安装 git","uri":"/posts/linux-git/"},{"categories":["Memo"],"content":"Vim 速查表-帮你提高 N 倍效率 ","date":"2018-08-31","objectID":"/posts/vim/:0:0","tags":["vim","他山之石"],"title":"Vim 速查表","uri":"/posts/vim/"},{"categories":["Memo"],"content":"进入 vim 命令 描述 vim filename 打开或新建文件，并将光标置于第一行首 vim +n filename 打开文件，并将光标置于第 n 行首 vim + filename 打开文件，并将光标置于最后一行首 vim +/pattern filename 打开文件，并将光标置于第一个与 pattern 匹配的串处 vim -r filename 在上次正用 vim 编辑时发生系统崩溃，恢复 filename vim filename….filename 打开多个文件，依次编辑 ","date":"2018-08-31","objectID":"/posts/vim/:1:0","tags":["vim","他山之石"],"title":"Vim 速查表","uri":"/posts/vim/"},{"categories":["Memo"],"content":"vim 配置 命令 描述 all 列出所有选项设置情况 term 设置终端类型 ignorance 在搜索中忽略大小写 list 显示制表位 (Ctrl+I) 和行尾标志（$) number 显示行号 report 显示由面向行的命令修改过的数目 terse 显示简短的警告信息 warn 在转到别的文件时若没保存当前文件则显示 NO write 信息 nomagic 允许在搜索模式中，使用前面不带“\\”的特殊字符 nowrapscan 禁止 vi 在搜索到达文件两端时，又从另一端开始 mesg 允许 vi 显示其他用户用 write 写到自己终端上的信息 :set number / set nonumber 显示/不显示行号 :set ruler /set noruler 显示/不显示标尺 :set hlsearch 高亮显示查找到的单词 :set nohlsearch 关闭高亮显示 :syntax on 语法高亮 :set nu 显示行号 :set tabstop=8 设置 tab 大小，8 为最常用最普遍的设置 :set softtabstop=8 4:4 个空格，8: 正常的制表符，12: 一个制表符 4 个空格，16: 两个制表符 :set autoindent 自动缩进 :set cindent C 语言格式里面的自动缩进 ","date":"2018-08-31","objectID":"/posts/vim/:2:0","tags":["vim","他山之石"],"title":"Vim 速查表","uri":"/posts/vim/"},{"categories":["Memo"],"content":"移动光标 命令 描述 k nk 上 向上移动 n 行 j nj 下 向下移动 n 行 h nh 左 向左移动 n 行 l nl 右 向右移动 n 行 Space 光标右移一个字符 Backspace 光标左移一个字符 Enter 光标下移一行 w/W 光标右移一个字至字首 b/B 光标左移一个字至字首 e 或 E 光标右移一个字至字尾 ) 光标移至句尾 ( 光标移至句首 } 光标移至段落开头 { 光标移至段落结尾 n$ 光标移至第 n 行尾 H 光标移至屏幕顶行 M 光标移至屏幕中间行 L 光标移至屏幕最后行 0 （注意是数字零）光标移至当前行首 ^ 移动光标到行首第一个非空字符上去 $ 光标移至当前行尾 gg 移到第一行 G 移到最后一行 f 移动光标到当前行的字符 a 上 F 相反 % 移动到与制匹配的括号上去（），{}，[]，\u003c\u003e等 nG 移动到第 n 行上 G 到最后一行 ","date":"2018-08-31","objectID":"/posts/vim/:3:0","tags":["vim","他山之石"],"title":"Vim 速查表","uri":"/posts/vim/"},{"categories":["Memo"],"content":"屏幕滚动 命令 描述 Ctrl+u 向文件首翻半屏 Ctrl+d 向文件尾翻半屏 Ctrl+f 向文件尾翻一屏 Ctrl ＋ b 向文件首翻一屏 nz 将第 n 行滚至屏幕顶部，不指定 n 时将当前行滚至屏幕顶部 ","date":"2018-08-31","objectID":"/posts/vim/:4:0","tags":["vim","他山之石"],"title":"Vim 速查表","uri":"/posts/vim/"},{"categories":["Memo"],"content":"插入文本类 命令 描述 i 在光标前 I 在当前行首 a 光标后 A 在当前行尾 o 在当前行之下新开一行 O 在当前行之上新开一行 r 替换当前字符 R 替换当前字符及其后的字符，直至按 ESC 键 s 从当前光标位置处开始，以输入的文本替代指定数目的字符 S 删除指定数目的行，并以所输入文本代替之 ncw/nCW 修改指定数目的字 nCC 修改指定数目的行 ","date":"2018-08-31","objectID":"/posts/vim/:5:0","tags":["vim","他山之石"],"title":"Vim 速查表","uri":"/posts/vim/"},{"categories":["Memo"],"content":"删除命令 命令 描述 x/X 删除一个字符，x 删除光标后的，而 X 删除光标前的 dw 删除一个单词（删除光标位置到下一个单词开始的位置） dnw 删除 n 个单词 dne 也可，只是删除到单词尾 do 删至行首 d$ 删至行尾 dd 删除一行 ndd 删除当前行及其后 n-1 行 dnl 向右删除 n 个字母 dnh 向左删除 n 个字母 dnj 向下删除 n 行，当前行+其上 n 行 dnk 向上删除 n 行，当期行+其下 n 行 cnw[word] 将 n 个 word 改变为 word C$ 改变到行尾 cc 改变整行 shift+j 删除行尾的换行符，下一行接上来了 ","date":"2018-08-31","objectID":"/posts/vim/:6:0","tags":["vim","他山之石"],"title":"Vim 速查表","uri":"/posts/vim/"},{"categories":["Memo"],"content":"复制粘贴 命令 描述 p 粘贴用 x 或 d 删除的文本 ynw 复制 n 个单词 yy 复制一行 ynl 复制 n 个字符 y$ 复制当前光标至行尾处 nyy 拷贝 n 行 ","date":"2018-08-31","objectID":"/posts/vim/:7:0","tags":["vim","他山之石"],"title":"Vim 速查表","uri":"/posts/vim/"},{"categories":["Memo"],"content":"撤销 命令 描述 u 撤销前一次的操作 shif+u(U) 撤销对该行的所有操作 ","date":"2018-08-31","objectID":"/posts/vim/:8:0","tags":["vim","他山之石"],"title":"Vim 速查表","uri":"/posts/vim/"},{"categories":["Memo"],"content":"搜索及替换 命令 描述 /pattern 从光标开始处向文件尾搜索 pattern ?pattern 从光标开始处向文件首搜索 pattern n 在同一方向重复上一次搜索命令 N 在反方向上重复上一次搜索命令 cw newword 替换为 newword n 继续查找 . 执行替换 :s/p1/p2/g 将当前行中所有 p1 均用 p2 替代，g 表示执行 用 c 表示需要确认 :n1,n2 s/p1/p2/g 将第 n1 至 n2 行中所有 p1 均用 p2 替代 :g/p1/s//p2/g 将文件中所有 p1 均用 p2 替换 :1,$ s/string1/string2/g 在全文中将 string1 替换为 string2 ","date":"2018-08-31","objectID":"/posts/vim/:9:0","tags":["vim","他山之石"],"title":"Vim 速查表","uri":"/posts/vim/"},{"categories":["Memo"],"content":"书签 命令 描述 m[a-z] 在文中做标记，标记号可为 a-z 的 26 个字母 `a 移动到标记 a 处 ","date":"2018-08-31","objectID":"/posts/vim/:10:0","tags":["vim","他山之石"],"title":"Vim 速查表","uri":"/posts/vim/"},{"categories":["Memo"],"content":"visual 模式 命令 描述 v 进入 visual 模式 V 进入行的 visual 模式 ctrl+v 进如块操作模式用 o 和 O 改变选择的边的大小 在所有行插入相同的内容如 include\u003c 将光标移到开始插入的位置，按 CTRL+V 进入 VISUAL 模式，选择好模块后按 I（shift+i)，后插入要插入的文本，按 [ESC] 完成 ","date":"2018-08-31","objectID":"/posts/vim/:11:0","tags":["vim","他山之石"],"title":"Vim 速查表","uri":"/posts/vim/"},{"categories":["Memo"],"content":"行方式命令 命令 描述 :n1,n2 co n3 将 n1 行到 n2 行之间的内容拷贝到第 n3 行下 :n1,n2 m n3 将 n1 行到 n2 行之间的内容移至到第 n3 行下 :n1,n2 d 将 n1 行到 n2 行之间的内容删除 :n1,n2 w!command 将文件中 n1 行至 n2 行的内容作为 command 的输入并执行之 若不指定 n1，n2，则表示将整个文件内容作为 command 的输入 ","date":"2018-08-31","objectID":"/posts/vim/:12:0","tags":["vim","他山之石"],"title":"Vim 速查表","uri":"/posts/vim/"},{"categories":["Memo"],"content":"宏 命令 描述 q[a-z] 开始记录但前开始的操作为宏，名称可为【a-z】，然后用 q 终止录制宏 reg 显示当前定义的所有的宏，用@[a-z] 来在当前光标处执行宏 [a-z] ","date":"2018-08-31","objectID":"/posts/vim/:13:0","tags":["vim","他山之石"],"title":"Vim 速查表","uri":"/posts/vim/"},{"categories":["Memo"],"content":"窗口操作 命令 描述 :split 分割一个窗口 :split file.c 为另一个文件 file.c 分隔窗口 :nsplit file.c 为另一个文件 file.c 分隔窗口，并指定其行数 ctrl ＋ w 在窗口中切换 :close 关闭当前窗口 ","date":"2018-08-31","objectID":"/posts/vim/:14:0","tags":["vim","他山之石"],"title":"Vim 速查表","uri":"/posts/vim/"},{"categories":["Memo"],"content":"文件及其他 命令 描述 :q 退出 vi :q! 不保存文件并退出 vi :e filename 打开文件 filename 进行编辑 :e! 放弃修改文件内容，重新载入该文件编辑 :w 保存当前文件 :wq 存盘退出 :ZZ 保存当前文档并退出 VIM :!command 执行 shell 命令 command :r!command 将命令 command 的输出结果放到当前行 :n1,n2 write temp.c :read file.c 将文件 file.c 的内容插入到当前光标所在的下面 ","date":"2018-08-31","objectID":"/posts/vim/:15:0","tags":["vim","他山之石"],"title":"Vim 速查表","uri":"/posts/vim/"},{"categories":["Memo"],"content":" 警告 2018/11/1 说明 next 主题好像更新了，现在自带的可以用了，如果可以用了，以下教程可以忽略！！！ 最近有几个小伙伴问我博客的字数统计怎么实现的，怎么网上的教程不管用啊？一开始我搭建博客的时候也遇到了类似的问题，按照 github 上 wordcount 的 readme 操作后，并没有什么用，我打开 post 相关配置文件并没有发现发现 wordcount 这个关键词，next 本身似乎也并没有在主题配置文件提供选项（或许是个人原因），所以只好自己动手加一个了。为了不重复回答问题，先做个原创记录。转载请注明出处。在此抛转引玉，如果有更好的方法请在留言区提出，我会及时更改。同时也希望小伙伴多发扬折腾精神，多专研，少提问，毕竟还是 RTFSC 大法好！(Read the fucking source code) ","date":"2018-08-30","objectID":"/posts/hexo-wordcount/:0:0","tags":["hexo","字数统计"],"title":"hexo next 主题添加字数统计（2018）","uri":"/posts/hexo-wordcount/"},{"categories":["Memo"],"content":"安装 wordcount github 如果没有安装 hexo-wordcount 插件，先安装该插件： npm i --save hexo-wordcount # Node 版本 7.6.0 之前，请安装 2.x 版本 (Node.js v7.6.0 and previous) npm install hexo-wordcount@2 --save ","date":"2018-08-30","objectID":"/posts/hexo-wordcount/:1:0","tags":["hexo","字数统计"],"title":"hexo next 主题添加字数统计（2018）","uri":"/posts/hexo-wordcount/"},{"categories":["Memo"],"content":"post 添加 打开hexo\\themes\\hexo-theme-next\\layout\\_macro路径下的 post.swig 文件，既然没有字数统计那么我们就加一个，简单暴力地直接在阅读数后面加上一条就好了，在文件类搜索关键词busuanzi, 我用的是不蒜子，如果用的了 leancloud 的搜 leancloud 就好了，其他类似。找到这段代码后 {% if not is_index and theme.busuanzi_count.enable and theme.busuanzi_count.post_views %} \u003cspan class=\"post-meta-divider\"\u003e|\u003c/span\u003e \u003cspan class=\"post-meta-item-icon\" {% if not theme.post_meta.item_text %} title=\"{{ __('post.views') }}\" {% endif %}\u003e \u003ci class=\"fa fa-{{ theme.busuanzi_count.post_views_icon }}\"\u003e\u003c/i\u003e {% if theme.post_meta.item_text %} {{__('post.views') + __('symbol.colon') }} {% endif %} \u003cspan class=\"busuanzi-value\" id=\"busuanzi_value_page_pv\" \u003e\u003c/span\u003e \u003c/span\u003e {% endif %} 在endif上面，即本文代码块那个空行处添加以下代码 \u003cspan class=\"post-meta-divider\"\u003e|\u003c/span\u003e \u003cspan title=\"{{ __('post.wordcount') }}\"\u003e\u003cspan class=\"post-meta-item-icon\"\u003e\u003ci class=\"fa fa-file-word-o\"\u003e\u003c/i\u003e\u003c/span\u003e字数： {{ wordcount(post.content) }}\u003c/span\u003e ","date":"2018-08-30","objectID":"/posts/hexo-wordcount/:2:0","tags":["hexo","字数统计"],"title":"hexo next 主题添加字数统计（2018）","uri":"/posts/hexo-wordcount/"},{"categories":["Memo"],"content":"全站添加 打开hexo\\themes\\hexo-theme-next\\layout\\_partials路径下 footer.swig 文件，在你喜欢的位置添加以下代码 \u003cdiv class=\"theme-info\"\u003e \u003cdiv class=\"powered-by\"\u003e\u003c/div\u003e \u003cspan class=\"post-count\"\u003e全站共 {{ totalcount(site) }} 字\u003c/span\u003e \u003c/div\u003e ","date":"2018-08-30","objectID":"/posts/hexo-wordcount/:3:0","tags":["hexo","字数统计"],"title":"hexo next 主题添加字数统计（2018）","uri":"/posts/hexo-wordcount/"},{"categories":["Memo"],"content":"搭建这个博客以来，隔一段时间就出现一次部署失败的错误，每次都差不多，莫名其妙地出现的。前几次不知道怎么瞎搞就好了。 现在做一下记录，防止以后出错用。 错误如下 Connection reset by 13.229.188.59 port 22 fatal: sha1 file '\u003cstdout\u003e' write error: Broken pipe fatal: The remote end hung up unexpectedly FATAL Something's wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.html Error: Connection reset by 13.229.188.59 port 22 fatal: sha1 file '\u003cstdout\u003e' write error: Broken pipe fatal: The remote end hung up unexpectedly at ChildProcess.\u003canonymous\u003e (H:\\Hexo\\node_modules\\hexo-util\\lib\\spawn.js:37:17) at emitTwo (events.js:106:13) at ChildProcess.emit (events.js:191:7) at ChildProcess.cp.emit (H:\\Hexo\\node_modules\\cross-spawn\\lib\\enoent.js:40:29) at maybeClose (internal/child_process.js:850:16) at Socket.\u003canonymous\u003e (internal/child_process.js:323:11) at emitOne (events.js:96:13) at Socket.emit (events.js:188:7) at Pipe._handle.close [as _onclose] (net.js:492:12) ... 确保 ssh 正常，hexo-deploy-git 插件正常的情况下删除。deploy_git 文件夹就好了。 最后吐槽一下，这个鬼错误，搞我一晚上醉了。我又打算重装了的。/吐血 ","date":"2018-08-21","objectID":"/posts/hexo-d-error/:0:0","tags":["hexo"],"title":"hexo d 出错","uri":"/posts/hexo-d-error/"},{"categories":["Memo"],"content":" 本文适合我这种纯小白。 目前为止，全网也就只有一个博主写到过这样动态显示 subtitle 的文章。传送门（关键词：js, 后加载） 但是嘞，该博写的不怎么详细，17 年底写的。当然更大的可能是 next 更新了一些文件结构，所以不适合现在使用了。以前我按原博的流程配置了一下没成功就搁在那里了，今天突然心血来潮。翻了翻原博主博客的源码，再与自己的对比了一下，发现了一些端倪。稍作调整后如下： ","date":"2018-08-20","objectID":"/posts/dongtaisub/:0:0","tags":["hexo","JavaScript"],"title":"hexo 个性化 - next 主题动态显示 subtitle","uri":"/posts/dongtaisub/"},{"categories":["Memo"],"content":"修改站点配置文件，主要修改 subtitle subtitle: 不怕万人阻挡，只怕自己投降。W 你如何回忆，决定你是一个怎样的人！W 这是一个句子。W 这是另一个句子。W 这些句子你们不要搞一样的不然怎么叫个性签名-_-！。 句子与句子之间以 W 分割，后续需要根据该标志位去拆分句子组。 小伙伴们博主这里只是提供一个思路，不要和我用一模一样的啊，不然撞了多尴尬呀 ","date":"2018-08-20","objectID":"/posts/dongtaisub/:1:0","tags":["hexo","JavaScript"],"title":"hexo 个性化 - next 主题动态显示 subtitle","uri":"/posts/dongtaisub/"},{"categories":["Memo"],"content":"修改 header\\index.swig 修改 themes\\next\\layout_partials\\header 下面的 index.swig 文件 在最开头添加如下代码： （这里用的原博的 js) \u003cscript\u003e function GetRandomNum(Min,Max) { var Range = Max - Min; var Rand = Math.random(); return(Min + Math.round(Rand * Range)); } function setSidebarMarginTop (headerOffset) { return $('#sidebar').css({ 'margin-top': headerOffset }); } function getHeaderOffset () { return $('.header-inner').height() + CONFIG.sidebar.offset; } window.onload=function(){ var subtitle = \"{{config.subtitle}}\"; var mytitle = subtitle.split(\"W\"); var max = mytitle.length-1; var index = GetRandomNum(0,max); var text = mytitle[index]; $(\"#helloTitle\").html(text); var headOffset = getHeaderOffset(); setSidebarMarginTop(headOffset); //动态 subtitle 设置 } \u003c/script\u003e ","date":"2018-08-20","objectID":"/posts/dongtaisub/:2:0","tags":["hexo","JavaScript"],"title":"hexo 个性化 - next 主题动态显示 subtitle","uri":"/posts/dongtaisub/"},{"categories":["Memo"],"content":"修改 brand.swig 找到 {% if subtitle %} {% if theme.seo %} ... {% else %} ... {% endif %} {% endif %} 把这一段，把原来的修改成以下代码即可 ps: title和subtitle的字体还有颜色也可以在这个文件修改，即使用style标签，按个人爱好修改也可不要。 {% if subtitle %} {% if theme.seo %} \u003cp class=\"site-subtitle\" id=\"helloTitle\" itemprop=\"description\"\u003e\u003c/p\u003e {% else %} \u003cp id=\"helloTitle\" class=\"site-subtitle\"\u003e\u003c/p\u003e {% endif %} {% endif %} 之后部署后每次刷新就可以看到不同的 subtitle 了，开心 😀 ","date":"2018-08-20","objectID":"/posts/dongtaisub/:3:0","tags":["hexo","JavaScript"],"title":"hexo 个性化 - next 主题动态显示 subtitle","uri":"/posts/dongtaisub/"},{"categories":["Memo"],"content":"今日诗词 今日诗词 \u003cspan id=\"jinrishici-sentence\"\u003e正在加载今日诗词 ....\u003c/span\u003e \u003cscript src=\"https://sdk.jinrishici.com/v2/browser/jinrishici.js\" charset=\"utf-8\"\u003e\u003c/script\u003e 正在加载今日诗词 .... ","date":"2018-08-20","objectID":"/posts/dongtaisub/:4:0","tags":["hexo","JavaScript"],"title":"hexo 个性化 - next 主题动态显示 subtitle","uri":"/posts/dongtaisub/"},{"categories":["Memo"],"content":"api 调用 直接 js 调用 api 简单快速 2021/9/30 更新 一言 api-参数详见 已经挂了 \u003cdiv\u003e \u003cscript type=\"text/javascript\" src=\"https://api.imjad.cn/hitokoto/?cat=\u0026charset=utf-8\u0026length=\u0026encode=js\u0026fun=sync\u0026source=\"\u003e\u003c/script\u003e \u003cdiv id=\"hitokoto\"\u003e \u003cscript\u003e hitokoto(); \u003c/script\u003e \u003c/div\u003e \u003c/div\u003e ","date":"2018-08-20","objectID":"/posts/dongtaisub/:5:0","tags":["hexo","JavaScript"],"title":"hexo 个性化 - next 主题动态显示 subtitle","uri":"/posts/dongtaisub/"},{"categories":["Git"],"content":"在 git 没有运行完成之前强制关闭，下次提交的时候会产以下生错误，或者类似的。 fatal: Unable to create '/xxx/xx/.git/index.lock': File exists. If no other git process is currently running, this probably means a git process crashed in this repository earlier. Make sure no other git process is running and remove the file manually to continue. 原因是在你进行某些比较费时的 git 操作时自动生成，操作结束后自动删除，相当于一个锁定文件，目的在于防止对一个目录同时进行多个操作。 有时强制关闭进行中的 git 操作，这个文件没有被自动删除，之后你就无法进行其他操作，必须手动删除，进入。git 文件中删除，打开显示隐藏文件。如果没有看见。git 文件夹，可以直接用命令 rm -f ./.git/index.lock。之后就可以正常使用。 ","date":"2018-08-14","objectID":"/posts/git-index-lock/:0:0","tags":["Git"],"title":"git index.lock","uri":"/posts/git-index-lock/"},{"categories":["Memo"],"content":" 暑假刚开始的时候放假回家没带电脑，只能玩手机，想折腾一下博客都没有条件，在一个发现一个 app, 卧槽 😱，termux 真的强大！（初始化需要科学上网）安卓手机上的 linux 简直了，在手机就可以搭了一个 hexo 博客，只要在 github 上实现分支管理就可以多终端同步更新了。恕我学疏才浅，还只想到这些！一开始想回校后，折腾一下 hexo-admin 实现类似动态博客一样的多终端管理（手动滑稽），现在发现 termux 这样子的操作也不错嘛，挺装哔 hhhhhh**部署后的效果** ","date":"2018-08-11","objectID":"/posts/termux/:0:0","tags":["Node.js","hexo","termux"],"title":"在 Android 上搭建 hexo 博客","uri":"/posts/termux/"},{"categories":["Memo"],"content":"准备 Termux 文件管理器（RE,MT 文件管理器等高级一点的） ","date":"2018-08-11","objectID":"/posts/termux/:1:0","tags":["Node.js","hexo","termux"],"title":"在 Android 上搭建 hexo 博客","uri":"/posts/termux/"},{"categories":["Memo"],"content":"开始 打开 Termux，输入$pkg install nodejs安装 Nodejs，在输入pkg install git安装 Git。 过程会出现一个提示，输入 y 回车确认即可。 按照 Hexo 官网提示安装 Hexo。 npm install hexo-cli -g hexo init blog cd blog 注意 ssh 配置先安装：pkg install openssh 然后按照基本操作配置 Hexo，GitHub 或者 gitee,coding 等连上，部署测试一次。 安装部署插件npm install hexo-deployer-git --save，部署hexo d -g 没有问题的话进行下一步。 ","date":"2018-08-11","objectID":"/posts/termux/:2:0","tags":["Node.js","hexo","termux"],"title":"在 Android 上搭建 hexo 博客","uri":"/posts/termux/"},{"categories":["Memo"],"content":"编辑 写文章的话创建 md 文件命令和电脑上一样，文件管理器打开/data/data/com.termux/files/home/i/source/_posts/ 编辑文章 md 文件。这种方式需要 Root。 没有 Root 的话可以使用 Vim，网上很多教程。但是这种方式相对来说更麻烦。 ","date":"2018-08-11","objectID":"/posts/termux/:3:0","tags":["Node.js","hexo","termux"],"title":"在 Android 上搭建 hexo 博客","uri":"/posts/termux/"},{"categories":["Memo"],"content":"参考 termux 高级终端安装使用配置教程 使用 Termux 在手机上运行 linux 黑科技 hexo 搭建过程 超详细教程 ","date":"2018-08-11","objectID":"/posts/termux/:4:0","tags":["Node.js","hexo","termux"],"title":"在 Android 上搭建 hexo 博客","uri":"/posts/termux/"},{"categories":["Memo"],"content":"效果图（未连接 github，coding 等） 效果图 1 效果图 2 效果图 3 效果图 4 ","date":"2018-08-11","objectID":"/posts/termux/:5:0","tags":["Node.js","hexo","termux"],"title":"在 Android 上搭建 hexo 博客","uri":"/posts/termux/"},{"categories":["ACM"],"content":"链接：https://www.nowcoder.com/acm/contest/157/A 来源：牛客网 ","date":"2018-08-10","objectID":"/posts/nowcoder157a/:0:0","tags":["数学","组合数学","ACM","Nowcoder","C++"],"title":"石子阵列（组合数学）","uri":"/posts/nowcoder157a/"},{"categories":["ACM"],"content":"题目描述 xb 有 m 种石子，每种无限个，Ta 想从这些石子中取出 n 个，并按顺序排列起来，为了好看，相邻的石子不能相同。xb 想知道有多少种排列的方法。 ","date":"2018-08-10","objectID":"/posts/nowcoder157a/:0:1","tags":["数学","组合数学","ACM","Nowcoder","C++"],"title":"石子阵列（组合数学）","uri":"/posts/nowcoder157a/"},{"categories":["ACM"],"content":"输入描述： 第一行有两个正整数 n，m。 ","date":"2018-08-10","objectID":"/posts/nowcoder157a/:0:2","tags":["数学","组合数学","ACM","Nowcoder","C++"],"title":"石子阵列（组合数学）","uri":"/posts/nowcoder157a/"},{"categories":["ACM"],"content":"输出描述： 第一行一个整数，表示在 m 种石子中取出 n 个的排列方案数模 1000000007 后的值。 ","date":"2018-08-10","objectID":"/posts/nowcoder157a/:0:3","tags":["数学","组合数学","ACM","Nowcoder","C++"],"title":"石子阵列（组合数学）","uri":"/posts/nowcoder157a/"},{"categories":["ACM"],"content":"示例 1 输入 1 1 输出 1 ","date":"2018-08-10","objectID":"/posts/nowcoder157a/:0:4","tags":["数学","组合数学","ACM","Nowcoder","C++"],"title":"石子阵列（组合数学）","uri":"/posts/nowcoder157a/"},{"categories":["ACM"],"content":"示例 2 输入 2 3 输出 6 ","date":"2018-08-10","objectID":"/posts/nowcoder157a/:0:5","tags":["数学","组合数学","ACM","Nowcoder","C++"],"title":"石子阵列（组合数学）","uri":"/posts/nowcoder157a/"},{"categories":["ACM"],"content":"示例 3 输入 3 3 输出 12 ","date":"2018-08-10","objectID":"/posts/nowcoder157a/:0:6","tags":["数学","组合数学","ACM","Nowcoder","C++"],"title":"石子阵列（组合数学）","uri":"/posts/nowcoder157a/"},{"categories":["ACM"],"content":"备注： 对于 100%的测试数据： 1 ≤ n, m ≤ 1000 数据量较大，注意使用更快的输入输出方式。 水题。 #include\u003cbits/stdc++.h\u003e using namespace std; int main(){ long long n,m,ans; scanf(\"%lld%lld\",\u0026n,\u0026m); ans=m; for(int i=1;i\u003cn;i++) ans=(ans*(m-1))%1000000007; printf(\"%lld\\n\",ans); return 0; } ","date":"2018-08-10","objectID":"/posts/nowcoder157a/:0:7","tags":["数学","组合数学","ACM","Nowcoder","C++"],"title":"石子阵列（组合数学）","uri":"/posts/nowcoder157a/"},{"categories":["ACM"],"content":"题目链接 Dreamoon wants to climb up a stair of n steps. He can climb 1 or 2 steps at each move. Dreamoon wants the number of moves to be a multiple of an integer m. What is the minimal number of moves making him climb to the top of the stairs that satisfies his condition? ","date":"2018-08-10","objectID":"/posts/codeforces476a/:0:0","tags":["Codeforces","ACM","数学","C++","C"],"title":"Dreamoon and Stairs","uri":"/posts/codeforces476a/"},{"categories":["ACM"],"content":"Input The single line contains two space separated integers n, m (0 \u003c n ≤ 10000, 1 \u003c m ≤ 10). ","date":"2018-08-10","objectID":"/posts/codeforces476a/:0:1","tags":["Codeforces","ACM","数学","C++","C"],"title":"Dreamoon and Stairs","uri":"/posts/codeforces476a/"},{"categories":["ACM"],"content":"Output Print a single integer — the minimal number of moves being a multiple of m. If there is no way he can climb satisfying condition print - 1 instead. ","date":"2018-08-10","objectID":"/posts/codeforces476a/:0:2","tags":["Codeforces","ACM","数学","C++","C"],"title":"Dreamoon and Stairs","uri":"/posts/codeforces476a/"},{"categories":["ACM"],"content":"Examples input 10 2 output 6 input 3 5 output -1 ","date":"2018-08-10","objectID":"/posts/codeforces476a/:0:3","tags":["Codeforces","ACM","数学","C++","C"],"title":"Dreamoon and Stairs","uri":"/posts/codeforces476a/"},{"categories":["ACM"],"content":"Note For the first sample, Dreamoon could climb in 6 moves with following sequence of steps: {2, 2, 2, 2, 1, 1}. For the second sample, there are only three valid sequence of steps {2, 1}, {1, 2}, {1, 1, 1} with 2, 2, and 3 steps respectively. All these numbers are not multiples of 5. 有一个 n 级台阶，每次可以走一级或两级，问最少的步数是多少，且步数必须是 m 的倍数。 找一下数学公式就好了。 具体看代码。 #include\u003cbits/stdc++.h\u003e using namespace std; int main(){ int x,n,m; cin\u003e\u003en\u003e\u003em; if(n\u003cm){ cout\u003c\u003c-1\u003c\u003cendl; return 0; } if(n==m){ cout\u003c\u003cn\u003c\u003cendl; return 0; } if(n%2==0){ x=n/2%m; if(x==0) cout\u003c\u003cn/2\u003c\u003cendl; else cout\u003c\u003cn/2+m-x\u003c\u003cendl; }else if(n%2!=0){ x=(n/2+1)%m; if(x==0) cout\u003c\u003cn/2+1\u003c\u003cendl; else cout\u003c\u003c(n/2+1)+m-x\u003c\u003cendl; } return 0; } ","date":"2018-08-10","objectID":"/posts/codeforces476a/:0:4","tags":["Codeforces","ACM","数学","C++","C"],"title":"Dreamoon and Stairs","uri":"/posts/codeforces476a/"},{"categories":["ACM"],"content":"题目链接 ","date":"2018-08-10","objectID":"/posts/codeforces476b/:0:0","tags":["组合数学","Codeforces","ACM","数学","C++","C"],"title":"Dreamoon and WiFi（组合数学）","uri":"/posts/codeforces476b/"},{"categories":["ACM"],"content":"题目大意 就是给定两个字符串，第一个字符串由\"+\",\"-“组成，第二个字符串由”+\",\"-\",\"?“组成，“+”代表加 1，”-“代表减一，“?“代表可取正也可取负，问第二个字符串的位置和第一个字符串相等的概率是多少。 我一开始的想法是把（+1，-1）^n 看成和二项式定理一样的展开始式，只不过把乘法改为加法，然后得到公式 c(n,0)(n+(-1)0)+c(n,1)(n-1+(-1)1)+c(n,i)(n-i+(-1)i)+...+c(n,n)(n-n+(-1)n) 化简一下可知通项为c(n,i)(n-2*i) 然后我对第一个串求出位置 sum, 第二个串先求出已知位置 sum1，然后记录下？的个数，然后遍历找出展开式中某一项 n-2i+sum1==sum，这样 x 的系数就是可能出现位置相等的所有情况，用 (n-2i)/系数和就是概率了啊，可是为什么不对呢，本地调试，数据没问题，可是交到 cf 上第二组都过不了，烦亏我还觉得想到一个独辟的方法呢，过不了。 //cf 错误报告，思前恐后不晓得 why,wtf??? 先码着吧 Test: #2, time: 0 ms., memory: 0 KB, exit code: 0, checker exit code: 1, verdict: WRONG_ANSWER Input +-+- +-?? Output -0.000000000000 Answer 0.500000000000 Checker Log wrong answer 1st numbers differ - expected: '0.5000000', found: '-0.0000000', error = '0.5000000' ","date":"2018-08-10","objectID":"/posts/codeforces476b/:0:1","tags":["组合数学","Codeforces","ACM","数学","C++","C"],"title":"Dreamoon and WiFi（组合数学）","uri":"/posts/codeforces476b/"},{"categories":["ACM"],"content":"错误代码 #include\u003cbits/stdc++.h\u003e using namespace std; int main(){ int i,j,cnt=0; long long c[11][11],sum=0,sum1=0; for(i = 0; i \u003c 11; i++){//杨辉三角 c[i][0] = 1; c[i][i] = 1; for(j = 1; j \u003c i; j++) c[i][j] = c[i-1][j] + c[i-1][j-1]; } string a,b; cin\u003e\u003ea\u003e\u003eb; //cout\u003c\u003ca\u003c\u003cendl\u003c\u003cb\u003c\u003cendl; int len=a.length(); for(i=0;i\u003clen;i++) if(a[i]=='+') sum+=1; else sum-=1; for(i=0;i\u003cb.length();i++){ if(b[i]=='+') sum1+=1; else if(b[i]=='-')sum1-=1; if(b[i]=='?') cnt++; } if(sum==sum1\u0026\u0026cnt==0){ printf(\"1.000000000000\\n\"); return 0; } int flag=0; int x=0; for(j=0;j\u003c=cnt;j++) x+=c[cnt][j]; //cout\u003c\u003cx\u003c\u003cendl; for(i=0;i\u003c=cnt;i++) if(cnt-2*i+sum1==sum){ flag=1; long double y=c[cnt][i]*1.0/x; printf(\"%.12llf\\n\",y); } if(!flag)printf(\"0.000000000000\\n\"); return 0; } 想不通，没办法只好换思路。 我先分别记下 a,b 串的’+’,’-’,’?‘个数，然后后我们很容易知道，如要 a,b 位置相等，则加号和减号的数目，两串要相等，且 a 中的加号要比 b 中已知的加号要多，减号也要比 b 中已知的要多，否则打死都不会相等的，仔细比划一下就知道了。然后有 z 个‘?’，相当于有 z 个坑，让我们去填使得 a,b 相等。只能填+或-，设加号差等于 x-p, 所以概率就等于 c(z,x-p)/2^z。 ","date":"2018-08-10","objectID":"/posts/codeforces476b/:0:2","tags":["组合数学","Codeforces","ACM","数学","C++","C"],"title":"Dreamoon and WiFi（组合数学）","uri":"/posts/codeforces476b/"},{"categories":["ACM"],"content":"AC 代码 #include\u003cbits/stdc++.h\u003e using namespace std; int main(){ string a,b; int x,y,z,p,q,c[11][11],i,j; for(i = 0; i \u003c 11; i++){ c[i][0] = 1; c[i][i] = 1; for(j = 1; j \u003c i; j++) c[i][j] = c[i-1][j] + c[i-1][j-1]; } cin\u003e\u003ea; cin\u003e\u003eb; x=y=z=p=q=0; for(i=0;i\u003ca.length();i++) if(a[i]=='+') x++; else y++; for(i=0;i\u003cb.length();i++){ if(b[i]=='+') p++; else if(b[i]=='-') q++; else z++; } if(x==p\u0026\u0026z==0){ printf(\"1.000000000000\\n\"); return 0; } if(x-p\u003c0||y-q\u003c0) { printf(\"0.000000000000\\n\"); return 0; } x=x-p; printf(\"%0.12f\",c[z][x]*1.0/(2\u003c\u003c(z-1))); return 0; } 几分钟写完后面的代码，心中一万头草泥马在奔腾。 ","date":"2018-08-10","objectID":"/posts/codeforces476b/:0:3","tags":["组合数学","Codeforces","ACM","数学","C++","C"],"title":"Dreamoon and WiFi（组合数学）","uri":"/posts/codeforces476b/"},{"categories":["ACM"],"content":"题意： 给出 a,b,c,x1,x2,y1,y2，求满足 ax+by+c=0，且 x∈[x1,x2],y∈[y1,y2] 的整数解个数。 ","date":"2018-08-10","objectID":"/posts/euclid/:0:1","tags":["数学","数论","ACM","欧几里得","他山之石","C++","C"],"title":"The equation-SGU106（扩展欧几里得）","uri":"/posts/euclid/"},{"categories":["ACM"],"content":"分析： 对于解二元一次不定方程，容易想到利用扩展欧几里得求出一组可行解后找到通解，下面来介绍一下欧几里得以及扩展欧几里得。 欧几里得： 又名辗转相除法，是用来计算两个数的最大公约数，其中就是利用 gcd(a,b)=gcd(b,a mod b) 来求解。下证 gcd(a,b)=gcd(b,a mod b) 的正确性： 设 a,b 的一个公约数为 d 设 a mod b=r，则 a=kb+r(k 为整数），r=a-kb 因为 d|a,d|b 所以 d|a-kb, 即 d|r，而 r=a mod b 所以 d 为 b,a mod b 的公约数 又因为 d 也为 a,b 的公约数，所以（a,b) 和 (b,a mod b) 的公约数一样，所以最大公约数必然一样，得证。 代码描述： int gcd(int a,int b) { if (b==0) return a; return gcd(b,a%b); } 扩展欧几里得 顾名思义，为上述欧几里得算法的扩展。欧几里得是用来求 a,b 的最大公约数，那么扩展欧几里得不仅能求出 a,b 的最大公约数，还能求出满足 ax+by=gcd(a,b) 的一组可行解。 求解过程中，扩展欧几里得比欧几里得多了一个赋值过程，具体证明如下： 设 ax1+by1=gcd(a,b),bx2+(a mod b)y2=gcd(b,a mod b) 因为由欧几里得算法可知，gcd(a,b)=gcd(b,a mod b) 所以 ax1+by1=bx2+(a mod b)y2 因为a mod b=a-(a div b)*b（div 为整除 所以有ax1+by1=bx2+(a-(a div b)*b)y2 将右边移项，展开得： ax1+by1=ay2+bx2-(a div b)*b*y2 =ay2+b[x2-(a div b)]y2 所以可得： x1=y2 y1=x2-(a div b)*y2 将得到的的 x1,y1 递归操作求解 x2,y2，如此循环往复，将会像欧几里得一样得到 b=0 的情况，此时递归结束，返回 x=1,y=0，回溯得解。 代码描述： 此函数返回的是 a,b 的最大公约数，同时也求解出满足 ax+by=gcd(a,b) 的一组可行的 (x,y) int exgcd(int a,int b,int \u0026x,int \u0026y) { if (b==0) {x=1;y=0;return a;} int t=exgcd(b,a%b,x,y); int x0=x,y0=y; x=y0;y=x0-(a/b)*y0; return t; } 关于求解二元一次不定方程 ax+by=c 首先，如果 c 不是 gcd(a,b) 的倍数，方程显然无解。 扩展欧几里得求解的是 ax+by=gcd(a,b)=1 的可行解，但是题目中并没有说 c 与 a,b 互质之类的条件，所以需要在开始时两边同时除以 gcd(a,b)。 设 d=gcd(a,b) 设 a’=a/d,b’=b/d,c’=c/d, 则下面需要求解 a’x+b’y=c’的整数解，而 gcd(a’,b’)=1， 则我们只需求 a’x+b’y=1 的可行解 直接使用扩展欧几里得，得到 (x’,y’), 则最终解为x'*c',y'*c'设为 (x0,y0)。 现在得到了一组可行解，但是如何得到通解呢？ 将 (x0,y0) 代入 ax+by=c，则有 a*(x0)+b*(y0)=c 通过拆添项，可有： a*(x0+1*b)+b*(y0-1*a)=c a*(x0+2*b)+b*(y0-2*a)=c a*(x0+3*b)+b*(y0-3*a)=c …… a*(x0+k*b)+b*(y0-k*a)=c (k∈Z) 至此，我们得到了通解的方程 x=x0+k*b y=y0-k*a (k∈Z) 这样，所有满足 ax+by=c 的可行解都可求出。 ","date":"2018-08-10","objectID":"/posts/euclid/:0:2","tags":["数学","数论","ACM","欧几里得","他山之石","C++","C"],"title":"The equation-SGU106（扩展欧几里得）","uri":"/posts/euclid/"},{"categories":["ACM"],"content":"具体实现 有了主体算法，下面要谈到具体实现了。 先处理一下无解的情况： 当 a=0 并且 b=0，而 c≠0 时，显然无解； 当 a=0,b=0，而 c=0 时，[x1,x2],[y1,y2] 都为可行解，根据乘法原理，可行解的个数为(x2-x1+1)*(y2-y1+1); 当 a=0 b≠0 时： 此时即为求解 by=c，则 y=c/b， 如果 c/b 不是整数或 c/b 不在 [y1,y2] 的范围内，无解 否则 [x1,x2] 内全部整数都为可行解。 当 b=0,a≠0 时，同上。 若 c 不是 gcd(a,b) 的个数，方程显然无解。 处理完了一些繁琐的细节后，下面是具体的求解过程： 扩展欧几里得求解的是 ax+by=c，而本题是 ax+by+c=0，需将 c 移项。 对于本道题，首先要注意的是，对于负数的模运算在此算法中无法得到正确解，所以要处理一下 a,b,c 的正负情况。 如果 a 为负数，只需将 a 取相反数后，再处理一下 x∈[x1,x2] 的范围。当 a 取了相反数，相当于把 x 也取反，则需要把 x 的范围由 [x1,x2] 转变成 [-x2,-x1], 类似于把数轴反了过来。b 同理。 利用扩展欧几里得解二元一次不定方程，得到一组可行解 (x0,y0)。 因为题目中对 x,y 有条件约束，而有 x=x0+kb,y=y0-kb，我们可以求出满足 x∈[x1,x2],y∈[y1,y2] 的 k 的取值范围， 即为求解 x1\u003c=x0+kb\u003c=x2,y1\u003c=y0-kb\u003c=y2 的整数 k 的个数 但是在求解这两个一次函数的过程中，会有除不尽的现象，该如何取整呢？ 举个例子 当出现 2.5\u003c=k\u003c=5.5 时，我们需要的可行的 k 为 3,4,5，所以需要将 2.5 向上取整得到 3，5.5 向下取整得到 5，即为 3\u003c=k\u003c=5； 当出现-5.5\u003c=\u003c=-2.5 时，我们需要的可行的 k 为-5,-4,-3, 所以需要将-5.5 向上取整得到-5,-2.5 向下取整得到-3，即为-5\u003c=k\u003c=-3； 正负数的情况都已经考虑完全了，可以得到取整的结论：上界下取整，下界上取整。 最后，将得到的两个范围取交集，得到 [l,r]，则最终答案为 r-l+1。 这样，本题就可以完美解决了。 // BY Rinyo #include\u003ccstdio\u003e #include\u003ccmath\u003e long long a,b,c,x1,x2,yy1,y2,x0,yy0; inline long long cmin(const long long \u0026x,const long long \u0026y) {return x\u003cy?x:y;} inline long long cmax(const long long \u0026x,const long long \u0026y) {return x\u003ey?x:y;} long long gcd(long long a,long long b) { if (b==0) return a; return gcd(b,a % b); } void exgcd(long long a,long long b) { if (b==0){x0=1;yy0=0;return;} exgcd(b,a%b); long long t=x0;x0=yy0;yy0=t-a/b*yy0; return; } int main() { scanf(\"%I64d%I64d%I64d%I64d%I64d%I64d%I64d\",\u0026a,\u0026b,\u0026c,\u0026x1,\u0026x2,\u0026yy1,\u0026y2); c=-c; if (c\u003c0) {a=-a;b=-b;c=-c;} if (a\u003c0) {a=-a;long long t=x1;x1=-x2;x2=-t;} if (b\u003c0) {b=-b;long long t=yy1;yy1=-y2;y2=-t;} if (a==0 \u0026\u0026 b==0) { if (c==0) { printf(\"%I64d\",(x2-x1+1)*(y2-yy1+1)); return 0; } printf(\"0\");return 0; } else if (a==0) { if (c %b ==0) if (c/b\u003c=y2 \u0026\u0026 c/b\u003e=yy1) {printf(\"%I64d\",x2-x1+1);return 0;} printf(\"0\");return 0; } else if (b==0) { if (c%a==0) if (c/a\u003c=x2 \u0026\u0026 c/a\u003e=x1) {printf(\"%I64d\",y2-yy1+1);return 0;} printf(\"0\");return 0; } long long d=gcd(a,b); if (c%d!=0){printf(\"0\");return 0;} a=a/d;b=b/d;c=c/d; exgcd(a,b); x0=x0*c;yy0=yy0*c; double tx2=x2,tx1=x1,tx0=x0,ta=a,tb=b,tc=c,ty1=yy1,ty2=y2,ty0=yy0; long long down1=floor(((tx2-tx0)/tb)),down2=floor(((ty0-ty1)/ta)); long long r=cmin(down1,down2); long long up1=ceil(((tx1-tx0)/tb)),up2=ceil(((ty0-ty2)/ta)); long long l=cmax(up1,up2); if (r\u003cl) printf(\"0\"); else printf(\"%I64d\",r-l+1); return 0; } 扩展欧几里得模板 #include\u003ciostream\u003e using namespace std; int exgcd(int a,int b,int \u0026x,int \u0026y) { if(b==0) { x=1; y=0; return a; } int gcd=exgcd(b,a%b,x,y); int x2=x,y2=y; x=y2; y=x2-(a/b)*y2; return gcd; } int main() { int x,y,a,b; cout\u003c\u003c\"请输入 a 和 b:\"\u003c\u003cendl; cin\u003e\u003ea\u003e\u003eb; cout\u003c\u003c\"a 和 b 的最大公约数：\"\u003c\u003cendl; cout\u003c\u003cexgcd(a,b,x,y)\u003c\u003cendl; cout\u003c\u003c\"ax+by=gcd(a,b) 的一组解是：\"\u003c\u003cendl; cout\u003c\u003cx\u003c\u003c\" \"\u003c\u003cy\u003c\u003cendl; return 0; } ","date":"2018-08-10","objectID":"/posts/euclid/:0:3","tags":["数学","数论","ACM","欧几里得","他山之石","C++","C"],"title":"The equation-SGU106（扩展欧几里得）","uri":"/posts/euclid/"},{"categories":["ACM"],"content":"题目链接 ","date":"2018-08-09","objectID":"/posts/lightoj1282/:0:1","tags":["数论","数学","快速幂","ACM","C"],"title":"Leading and Trailing-lightoj1282（快速幂+对数运算）","uri":"/posts/lightoj1282/"},{"categories":["ACM"],"content":"题目大意： 给定两个数 n,k 求 n^k 的前三位和最后三位。 ","date":"2018-08-09","objectID":"/posts/lightoj1282/:0:2","tags":["数论","数学","快速幂","ACM","C"],"title":"Leading and Trailing-lightoj1282（快速幂+对数运算）","uri":"/posts/lightoj1282/"},{"categories":["ACM"],"content":"分析 求后三位的话：直接快速幂，对 1000 取模就好了。 求前三位，对于给定的一个数 n, 它可以写成 n=10^a, 其中这个 a 为浮点数，则t=n^k=(10^a)^k=10^a*k=(10^x)*(10^y);其中 x,y 分别是a*k的整数部分和小数部分，对于 t=n^k 这个数，它的位数由 (10^x) 决定，它的位数上的值则有 (10^y) 决定，因此我们要求 t 的前三位，只需要将 10^y 求出，在乘以 100，就得到了它的前三位。 分析完，我们再整体看，设 n^k=10^z; 那么z=k*log10(n) fmod(z,1)可以求出 x 的小数部分。 //再一次吐槽 lightoj 的头文件，让我不能用万能头\u003cbits/stdc++.h\u003e #include\u003cstdio.h\u003e #include\u003cmath.h\u003e typedef long long LL; int quickpow (int m, int n, int k) { int b = 1; while (n \u003e 0) { if (n \u0026 1) b = (b * m) % k; n \u003e\u003e= 1; m = (m * m) % k; } return b%k; } int main () { int t, flag = 1; scanf (\"%d\", \u0026t); while (t--) { LL n, k; scanf (\"%lld %lld\", \u0026n, \u0026k); int first = pow (10.0, 2.0 + fmod (k*log10(n*1.0), 1)); int last = quickpow (n%1000, k, 1000); printf (\"Case %d: %d %03d\\n\", flag++, first, last); } return 0; } ","date":"2018-08-09","objectID":"/posts/lightoj1282/:0:3","tags":["数论","数学","快速幂","ACM","C"],"title":"Leading and Trailing-lightoj1282（快速幂+对数运算）","uri":"/posts/lightoj1282/"},{"categories":["ACM"],"content":"注： C 库函数 - fmod() C 库函数 double fmod(double x, double y) 返回 x 除以 y 的余数。 x – 代表分子的浮点值。 y – 代表分母的浮点值。 该函数返回 x/y 的余数。 下面的实例演示了 fmod() 函数的用法。 #include \u003cstdio.h\u003e #include \u003cmath.h\u003e int main () { float a, b; int c; a = 9.2; b = 3.7; c = 2; printf(\"%f / %d 的余数是 %lf\\n\", a, c, fmod(a,c)); printf(\"%f / %f 的余数是 %lf\\n\", a, b, fmod(a,b)); return(0); } 结果： 9.200000 / 2 的余数是 1.200000 9.200000 / 3.700000 的余数是 1.800000 ","date":"2018-08-09","objectID":"/posts/lightoj1282/:0:4","tags":["数论","数学","快速幂","ACM","C"],"title":"Leading and Trailing-lightoj1282（快速幂+对数运算）","uri":"/posts/lightoj1282/"},{"categories":["ACM"],"content":"A. The Rank 题目大意： 给出 n 个学生的成绩，Thomas Smith 的成绩是第一行，然后要按总成绩进行排序，总分相同的按编号从小到大排； 开始看还以为要写 sort 的 cmp 函数进行多条件排序，敲完才发现其实只要按总分就可以了，因为托马斯的 id 是一，必然会排在前面。 #include\u003cbits/stdc++.h\u003e using namespace std; int a[4],sum[1005]; int main(){ int n,s,f1; cin\u003e\u003en; for(int j=1;j\u003c=n;j++){ s=0; for(int i=0;i\u003c4;i++){ cin\u003e\u003ea[i]; s+=a[i]; } sum[j]=s; if(j==1) f1=s; } sort(sum+1,sum+n+1,greater\u003cint\u003e()); for(int i=1;i\u003c=n;i++) if(sum[i]==f1){ cout\u003c\u003ci\u003c\u003cendl; break; } return 0; } ","date":"2018-08-09","objectID":"/posts/cfcontest1017/:0:1","tags":["ACM","Codeforces","组合数学","C++"],"title":"Codeforces Round 502(Div.1 + Div.2)","uri":"/posts/cfcontest1017/"},{"categories":["ACM"],"content":"B. The Bits 题目大意： 先给出二进制数的长度，然后输入两个二进制数 a,b，问交换 a 中的某些位数的数，使得 a|b（按位或）的结果不同，求有多少种不同的或值。 a,b 上下对应的情况：a/b 个数 1/0 m 0/0 n 1/1 x 0/1 y 用组合数学的思想来想： 只要看 b 为 0 的位就行了，如果 0/0,a 只能换 1 的位置，为了避免重复，所以这里总数为n*x, 再考虑 1/0 的情况，只能和 0 的位置换，这是后可以把 0/0 没算的都算上，所以总数m*(n+y) 所以最后总数为sum=n*x+m*(n+y) #include\u003cbits/stdc++.h\u003e using namespace std; int main(){ long long n,m,x,y,t; n=m=x=y=0; char a[100005],b[100005]; cin\u003e\u003et; cin\u003e\u003ea\u003e\u003eb; for(int i=0;i\u003ct;i++){ int p=a[i]-'0'; int q=b[i]-'0'; if(p==0\u0026\u0026q==0) n++; if(p==1\u0026\u0026q==0) m++; if(p==1\u0026\u0026q==1) x++; if(p==0\u0026\u0026q==1) y++; } long long sum=n*x+m*(y+n); cout\u003c\u003csum\u003c\u003cendl; return 0; } ","date":"2018-08-09","objectID":"/posts/cfcontest1017/:0:2","tags":["ACM","Codeforces","组合数学","C++"],"title":"Codeforces Round 502(Div.1 + Div.2)","uri":"/posts/cfcontest1017/"},{"categories":["ACM"],"content":"欧拉函数是求小于 x 并且和 x互质 的数的个数 通式：φ(x)=x(1-1/p1)(1-1/p2)(1-1/p3)(1-1/p4)…..(1-1/pn) 其中 p1, p2……pn 为 x 的所有质因数，x 是不为 0 的整数 φ(1)=1（唯一和 1 互质的数就是 1 本身）【注意：每种质因数只一个。比如 12=223】 ","date":"2018-08-08","objectID":"/posts/euler/:0:1","tags":["数学","数论","euler","C"],"title":"欧拉函数","uri":"/posts/euler/"},{"categories":["ACM"],"content":"定理： 若 n 是素数 p 的 k 次幂，φ(n)=p^k-p^(k-1)=(p-1)p^(k-1)，因为除了 p 的倍数外，其他数都跟 n 互质 欧拉函数是积性函数——若 m,n 互质，φ(mn)=φ(m)φ(n) ","date":"2018-08-08","objectID":"/posts/euler/:0:2","tags":["数学","数论","euler","C"],"title":"欧拉函数","uri":"/posts/euler/"},{"categories":["ACM"],"content":"特殊性质： 当 n 为奇数时，φ(2n)=φ(n) p 是素数，φ(p) = p - 1，φ(p) 称为 p 的欧拉值 若 a 为素数，b mod a=0,φ(a*b)=φ(b)*a ","date":"2018-08-08","objectID":"/posts/euler/:0:3","tags":["数学","数论","euler","C"],"title":"欧拉函数","uri":"/posts/euler/"},{"categories":["ACM"],"content":"模板 //直接法 int Euler(int n){ int res = n,i; //由于任何一个合数都至少有一个不大于根号 n 的素因子，所以只要遍历到根号 n 即可 for(i=2;i * i \u003c= n;i++) if(n%i == 0){ //第一次找到的必为素因子 n /=i ; res = res - res/i; //x(1-1/p1) while(n % i ==0) n/=i; //将该素因子的倍数也全部筛掉 } if (n \u003e 1) res = res - res/n; return res; } 以上转载注明 //素数筛选法，先素数筛选，再求欧拉 /* 特性 : 1. 若 a 为质数，phi[a]=a-1; 2. 若 a 为质数，b mod a=0,phi[a*b]=phi[b]*a 3. 若 a,b 互质，phi[a*b]=phi[a]*phi[b](当 a 为质数时，if b mod a!=0 ,phi[a*b]=phi[a]*phi[b]) */ int m[n],phi[n],p[n],nump; //m[i] 标记 i 是否为素数，0 为素数，1 不为素数；p 是存放素数的数组；nump 是当前素数个数；phi[i] 为欧拉函数 int make() { phi[1]=1; for (int i=2;i\u003c=n;i++) { if (!m[i])//i 为素数，m[] 初始化为 0 { p[++nump]=i;//将 i 加入素数数组 p 中 phi[i]=i-1;//因为 i 是素数，由特性得知 } for (int j=1;j\u003c=nump\u0026\u0026p[j]*i\u003cn;j++) //用当前已的到的素数数组 p 筛，筛去 p[j]*i { m[p[j]*i]=1;//可以确定 i*p[j] 不是素数 if (i%p[j]==0) //看 p[j] 是否是 i 的约数，因为素数 p[j], 等于判断 i 和 p[j] 是否互质 { phi[p[j]*i]=phi[i]*p[j]; //特性 2 break; } else phi[p[j]*i]=phi[i]*(p[j]-1); //互质，特性 3,p[j]-1 就是 phi[p[j]] } } } 附素数打表 int p[N]={1,1,0}; void prime(){ for(int i=2;i\u003cN;i++) if(!p[i]){ for(int j=2*i;j\u003c=N;j+=i)//筛掉 i 的倍数 p[j]=1; } } ","date":"2018-08-08","objectID":"/posts/euler/:0:4","tags":["数学","数论","euler","C"],"title":"欧拉函数","uri":"/posts/euler/"},{"categories":["ACM"],"content":"例题 Bi-shoe and Phi-shoe LightOJ - 1370 题意： 给一些数 Ai（第 i 个数），Ai 这些数代表的是某个数欧拉函数的值，我们要求出数 Ni 的欧拉函数值不小于 Ai。而我们要求的就是这些 Ni 这些数字的和 sum，而且我们想要 sum 最小，求出 sum 最小多少。 解题思路： 要求和最小，我们可以让每个数都尽量小，那么我们最后得到的肯定就是一个最小值。 给定一个数的欧拉函数值 ψ(N)，我们怎么样才能求得最小的 N? 我们知道，一个素数 P 的欧拉函数值 ψ(P)=P-1。所以如果我们知道 ψ(N)，那么最小的 N 就是最接近 ψ(N)，并且大于 ψ(N) 的素数。我们把所有素数打表之后再判断就可以了。 这个 lightoj 有毒，什么头文件都不支持，卡了我好久。 #include\u003cstdio.h\u003e #define N 1000005 #define ll long long int m[N]={1,1,0}; int p[100000],cnt=0; int max(int x,int y){ return x\u003ey?x:y; } void prime(){ for(int i=2;i\u003cN;i++) if(!m[i]){ for(int j=2*i;j\u003c=N;j+=i) m[j]=1; p[cnt++]=i; } } int binary_search(int x){//二分查找 int l=0,r=cnt; while(l\u003c=r){ int mid=(l+r)/2; if(p[mid]\u003ex) r=mid-1; else l=mid+1; } for(int i=max(r,0);;i++) if(p[i]\u003ex) return p[i]; } int main(){ prime(); int T,n,cas=1,temp; scanf(\"%d\",\u0026T); while(T--){ scanf(\"%d\",\u0026n); ll sum=0; for(int i=0;i\u003cn;i++){ scanf(\"%d\",\u0026temp); sum+=binary_search(temp); } printf(\"Case %d: %lld Xukha\\n\",cas++,sum); } return 0; } ","date":"2018-08-08","objectID":"/posts/euler/:0:5","tags":["数学","数论","euler","C"],"title":"欧拉函数","uri":"/posts/euler/"},{"categories":["ACM"],"content":"题目链接](http://poj.org/problem?id=1797) 大意： 要从城市 1 到城市 N 运送货物，有 M 条道路，每条道路都有它的最大载重量，问从城市 1 到城市 N 运送最多的重量是多少。 其实题意很简单，就是找一条 1–\u003eN 的路径，在不超过每条路径的最大载重量的情况下，使得运送的货物最多。一条路径上的最大载重量为这个路径上权值最小的边； //dijkstra #include\u003ciostream\u003e #include\u003ccstdio\u003e #define min(a,b) (a\u003cb?a:b) using namespace std; int n,m,v[1010],maps[1010][1010],d[1010];//此时 d 表示 1 到每一个点的能通过的最大的重量 int dijkstra(){ int i,j,k; for(i=1;i\u003c=n;i++){ v[i]=0; d[i]=maps[1][i];//这个时候 d 不代表最短路径，而是从 1 到 n 的最大承载量 } for(i=1;i\u003c=n;i++){//n 个点 int f=-1; for(j=1;j\u003c=n;j++) if(!v[j]\u0026\u0026d[j]\u003ef){ f=d[j]; k=j; } v[k]=1; for(j=1;j\u003c=n;j++) if(!v[j]\u0026\u0026d[j]\u003cmin(d[k],maps[k][j]))//更新说明见图解 d[j]=min(d[k],maps[k][j]); } return d[n]; } int main(){ int ans=1; int a,b,w; int T; scanf(\"%d\",\u0026T); while(T--){ for(int i=0;i\u003c=n;i++) for(int j=0;j\u003c=n;j++) maps[i][j]=0; scanf(\"%d%d\",\u0026n,\u0026m); for(int i=1;i\u003c=m;i++){ scanf(\"%d%d%d\",\u0026a,\u0026b,\u0026w); maps[a][b]=maps[b][a]=w; } printf(\"Scenario #%d:\\n%d\\n\\n\",ans++,dijkstra()); } return 0; } ","date":"2018-08-06","objectID":"/posts/poj1797/:0:0","tags":["ACM","POJ","最短路","C++"],"title":"Heavy Transportation-poj1797(dijkstra 或最大生成树）","uri":"/posts/poj1797/"},{"categories":["JavaScript"],"content":"看到知乎，百度的页面 F12 检查后都会有一些有趣的招聘信息。于是乎我也想给我的博客加一个。 我主要用到的工具： console.log() Notepad++ 在线图片转文字工具 ","date":"2018-08-04","objectID":"/posts/console-log/:0:0","tags":["hexo","JavaScript"],"title":"hexo 博客自定义 console log","uri":"/posts/console-log/"},{"categories":["JavaScript"],"content":"用法 用 js 在\u003cbody\u003e\u003c/body\u003e使用 console.log() 就行了，hexo 的主题文件在_layout.swig里，所以我们打开该文件，在该位置，添加 js 就行了； ","date":"2018-08-04","objectID":"/posts/console-log/:1:0","tags":["hexo","JavaScript"],"title":"hexo 博客自定义 console log","uri":"/posts/console-log/"},{"categories":["JavaScript"],"content":"图案 我用的我自己的一张照片（电脑上照片就那么几张。)，然后用 在线图片转文字工具 转字符， 选择文件，设置大小，然后生成， 生成后，复制 TXT 文件（下面那个框，上面的是 HTML 代码） 粘贴到 Notepad++ 里面，然后按图操作； Ctrl+H 替换 最后就变成一个字符串了。 ","date":"2018-08-04","objectID":"/posts/console-log/:2:0","tags":["hexo","JavaScript"],"title":"hexo 博客自定义 console log","uri":"/posts/console-log/"},{"categories":["JavaScript"],"content":"效果图 线上 demo, 按 F12 找到 console ","date":"2018-08-04","objectID":"/posts/console-log/:3:0","tags":["hexo","JavaScript"],"title":"hexo 博客自定义 console log","uri":"/posts/console-log/"},{"categories":["JavaScript"],"content":"我的 txt \\n` @@#``@@@@@@@@@@@@@@@@@@##,` \\n` @@#`;@@@@@@@@@@@@@@@@@@@':' \\n` @@#`@@@@@@@@@@@@@@@@@@@#+#;` \\n` @@#`@@@@@@@@@@@@@@@@@@###@'. \\n` @@+.@@@@@@@@@@@@@@@@@@@@@##, \\n` @@#,@@@@@@@@@@@@@@@@@@@@@@#, \\n` #@#:@@@@@@@@@@@@@@@@@@@@@@@, \\n` #@#'@@@@@@@@@@@@@@@@@@@@@@@. \\n` +@#;@@@@@@@@@@@@@@@@@@@@@@# \\n` `;: ;@#'@@@@@@@@@@@@@@@@@@+'+@' \\n` `,,;';'+';'@@+:@@@@@@@@@@@@##@#',.:#; \\n,, `` ``..,:;@@#'@@@@@@@@#####@@@@#:`:. \\n` `````:++@@@@@@@@@@@@@###@@@@#+,.. \\n ``````.#@@@@@@@@@@@@@@#@@@#++#'`` \\n` ```.,,:,.`:@@@@@@@@@@@@@###@@@##'.` \\n``..`````..,::;+@@@@@@@@@@@@#+`::+##'`. \\n` ````.```,@@@@@@@@@@@##;``.,';` ` \\n``.;@@@@@@@@@@@@@@@@@@@@@@###;``..`````` \\n#@@@@@@@@@@@@@@@@@@@@@@@@##@#;``,``,.`` \\n@@@@@@@@@@@@@@@@@@@.`````..``.. +` `:` \\n@+''++#####@@#`.@@@``````` ` `,``` `` \\n';;;;'+##+'+.`;+@@@,..```` `` :,. \\n;::,,:;+#++``,,#@@@'..``````` ,`.`` \\n;,,,,...'#.,,..#@@@#,,.`````` .```` \\n:,,,,....`,::;''+#@#;,..`````````.`` \\n:,,,.....'##++''';:+':,.`..,,...` \\n:,,,...#####+'+#@@@'.';+:. ` `` \\n;,,.`'####'#,`.`+@@@+'``` `.` \\n;,.`#@@@#+:'+++##+@##@,,,,` \\n',.#@@###'''';:,.```,+#. \\n+,#@@@####;,,..``````````````` `.:,::\\n+@@@@###+;,,..`````````````````` `.,\\n#@@@##+',,,........`````````````` \\n@@@@#+:,,,,`........`````````` \\n@@@#+:,,,,.`````.....`````````` `` \\n@@##':,......`````....``` ````` ```\\n@@@#':,....,..``````..```` ``` ```\\n@@@#',....,,,..``````````` ``` ..\\n@@@#,.....,,,,.`` ```````` `````` \\n@@@+....,,,,,..````````````` `````````` \\n@@@:....,,,,.LiRuihao```````` ```````````` \\n#@@,....,,,,.Always Be Yourself !````````````\\n,##,,...,::,.````````````..`````` `......``\\n,'#,,..,,:::.`````````........`````` `.,,..\\n\\n 你好！\\n 欢迎进入什么都不会的李瑞豪的个人网站！\\nhttps://lruihao.cn\\nhttps://www.lruihao.cn\\nhttps://lruihao.github.io\\nhttps://liruihao.coding.me\\n\\n\\n\\n 其他个人网站，个人博客也是可以的。 ","date":"2018-08-04","objectID":"/posts/console-log/:4:0","tags":["hexo","JavaScript"],"title":"hexo 博客自定义 console log","uri":"/posts/console-log/"},{"categories":["ACM"],"content":"题目链接 题目大意： 说的是，一只奶牛位于 N 号节点，输入 N 个节点和 T 对双向的边，求出由 N 到 1 的最短的距离，其实就是问的单源最短路问题。 两个点可能有多条路，选择最短的。 #include\u003cstdio.h\u003e #include\u003cstring.h\u003e #include\u003calgorithm\u003e using namespace std; const int INF=99999999; //设为无穷大 int maps[1005][1005],v[1005],d[1005]; //v 表示是否已经过遍历 d 表示从源到点当前最短路 int n; void Dijkstra(int s,int t) { int i,j,k,mini; for(i=1;i\u003c=n;i++) d[i]=INF; //除源点设为 0 距离外 其他先设为无穷大 d[s]=0; for(i=1;i\u003c=n;i++) //n 点循环 n 次 , 找出 n 个 k, 找 n 个点 { mini=INF; k=-1; for(j=1;j\u003c=n;j++) //在所有未标记点中 选 d 值最小的点 if(!v[j] \u0026\u0026 d[j]\u003cmini) mini=d[k=j]; v[k]=1; //标记节点 if(k==t) { printf(\"%d\\n\",d[t]); return; } for(j=1;j\u003c=n;j++) if(!v[j] \u0026\u0026 (d[k]+maps[k][j])\u003cd[j]) //表示从 k 出发的点，对于所有边，更新相连点 d[j]=d[k]+maps[k][j]; } } int main() { int T,i,j,x,y,D; while(scanf(\"%d %d\",\u0026T,\u0026n)!=EOF) { memset(v,0,sizeof(v)); //清除标记 for(i=1;i\u003c=n;i++) for(j=1;j\u003c=n;j++) maps[i][j]=INF; for(i=1;i\u003c=T;i++){ scanf(\"%d%d%d\",\u0026x,\u0026y,\u0026D); if(maps[x][y]\u003eD) //可能有多条路，只记录最短的 maps[x][y]=D,maps[y][x]=D; } Dijkstra(1,n); } return 0; } ","date":"2018-08-03","objectID":"/posts/poj2387/:0:0","tags":["ACM","最短路","C++","C"],"title":"Til the Cows Come Home-poj2387(dijkstra 判断重边）","uri":"/posts/poj2387/"},{"categories":["ACM"],"content":"Dijkstra 算法 ","date":"2018-08-03","objectID":"/posts/zuiduanlu/:1:0","tags":["最短路","ACM"],"title":"最短路入门","uri":"/posts/zuiduanlu/"},{"categories":["ACM"],"content":"1. 定义概览 Dijkstra（迪杰斯特拉）算法是典型的单源最短路径算法，用于计算一个节点到其他所有节点的最短路径。主要特点是以起始点为中心向外层层扩展，直到扩展到终点为止。Dijkstra 算法是很有代表性的最短路径算法，在很多专业课程中都作为基本内容有详细的介绍，如数据结构，图论，运筹学等等。注意该算法要求图中不存在负权边。 问题描述：在无向图 G=(V,E) 中，假设每条边 E[i] 的长度为 w[i]，找到由顶点 V0 到其余各点的最短路径。（单源最短路径） ","date":"2018-08-03","objectID":"/posts/zuiduanlu/:1:1","tags":["最短路","ACM"],"title":"最短路入门","uri":"/posts/zuiduanlu/"},{"categories":["ACM"],"content":"2. 算法描述 1) 算法思想： 设 G=(V,E) 是一个带权有向图，把图中顶点集合 V 分成两组，第一组为已求出最短路径的顶点集合（用 S 表示，初始时 S 中只有一个源点，以后每求得一条最短路径 , 就将加入到集合 S 中，直到全部顶点都加入到 S 中，算法就结束了），第二组为其余未确定最短路径的顶点集合（用 U 表示），按最短路径长度的递增次序依次把第二组的顶点加入 S 中。在加入的过程中，总保持从源点 v 到 S 中各顶点的最短路径长度不大于从源点 v 到 U 中任何顶点的最短路径长度。此外，每个顶点对应一个距离，S 中的顶点的距离就是从 v 到此顶点的最短路径长度，U 中的顶点的距离，是从 v 到此顶点只包括 S 中的顶点为中间顶点的当前最短路径长度。 2) 算法步骤： a. 初始时，S 只包含源点，即 S ＝{v}，v 的距离为 0。U 包含除 v 外的其他顶点，即：U={其余顶点}，若 v 与 U 中顶点 u 有边，则\u003cu,v\u003e正常有权值，若 u 不是 v 的出边邻接点，则\u003cu,v\u003e权值为 ∞。 b. 从 U 中选取一个距离 v 最小的顶点 k，把 k，加入 S 中（该选定的距离就是 v 到 k 的最短路径长度）。 c. 以 k 为新考虑的中间点，修改 U 中各顶点的距离；若从源点 v 到顶点 u 的距离（经过顶点 k）比原来距离（不经过顶点 k）短，则修改顶点 u 的距离值，修改后的距离值的顶点 k 的距离加上边上的权。 d. 重复步骤 b 和 c 直到所有顶点都包含在 S 中。 执行动画过程如下图 ","date":"2018-08-03","objectID":"/posts/zuiduanlu/:1:2","tags":["最短路","ACM"],"title":"最短路入门","uri":"/posts/zuiduanlu/"},{"categories":["ACM"],"content":"spfa 算法 spfa 是一种求单源最短路的算法 算法中需要用到的主要变量 int n; //表示 n 个点，从 1 到 n 标号 int s,t; //s 为源点，t 为终点 int d[N]; //d[i] 表示源点 s 到点 i 的最短路 int p[N]; //记录路径（或者说记录前驱） queue q; //一个队列，用 STL 实现，当然可有手打队列，无所谓 bool vis[N]; //vis[i]=1 表示点 i 在队列中 vis[i]=0 表示不在队列中 ","date":"2018-08-03","objectID":"/posts/zuiduanlu/:2:0","tags":["最短路","ACM"],"title":"最短路入门","uri":"/posts/zuiduanlu/"},{"categories":["ACM"],"content":"几乎所有的最短路算法其步骤都可以分为两步 初始化 松弛操作 ","date":"2018-08-03","objectID":"/posts/zuiduanlu/:3:0","tags":["最短路","ACM"],"title":"最短路入门","uri":"/posts/zuiduanlu/"},{"categories":["ACM"],"content":"初始化： d 数组全部赋值为 INF（无穷大）；p 数组全部赋值为 s（即源点），或者赋值为-1，表示还没有知道前驱，然后 d[s]=0; 表示源点不用求最短路径，或者说最短路就是 0。将源点入队； （另外记住在整个算法中有顶点入队了要记得标记 vis 数组，有顶点出队了记得消除那个标记） ","date":"2018-08-03","objectID":"/posts/zuiduanlu/:3:1","tags":["最短路","ACM"],"title":"最短路入门","uri":"/posts/zuiduanlu/"},{"categories":["ACM"],"content":"队列+松弛操作 读取队头顶点 u，并将队头顶点 u 出队（记得消除标记）；将与点 u 相连的所有点 v 进行松弛操作，如果能更新估计值（即令 d[v] 变小），那么就更新，另外，如果点 v 没有在队列中，那么要将点 v 入队（记得标记），如果已经在队列中了，那么就不用入队 以此循环，直到队空为止就完成了单源最短路的求解 ","date":"2018-08-03","objectID":"/posts/zuiduanlu/:3:2","tags":["最短路","ACM"],"title":"最短路入门","uri":"/posts/zuiduanlu/"},{"categories":["ACM"],"content":"SPFA 可以处理负权边 定理：只要最短路径存在，上述 SPFA 算法必定能求出最小值。 证明： 每次将点放入队尾，都是经过松弛操作达到的。换言之，每次的优化将会有某个点 v 的最短路径估计值 d[v] 变小。所以算法的执行会使 d 越来越小。由于我们假定图中不存在负权回路，所以每个结点都有最短路径值。因此，算法不会无限执行下去，随着 d 值的逐渐变小，直到到达最短路径值时，算法结束，这时的最短路径估计值就是对应结点的最短路径值。（证毕） 期望的时间复杂度 O(ke)， 其中 k 为所有顶点进队的平均次数，可以证明 k 一般小于等于 2。 判断有无负环： 如果某个点进入队列的次数超过 N 次则存在负环（SPFA 无法处理带负环的图） 代码 ","date":"2018-08-03","objectID":"/posts/zuiduanlu/:4:0","tags":["最短路","ACM"],"title":"最短路入门","uri":"/posts/zuiduanlu/"},{"categories":["ACM"],"content":"题目链接 密码：l9sn 终于不爆零了，但是还是 wa 了无数次，有时候代码感觉都差不多 ","date":"2018-08-02","objectID":"/posts/nowcodersummer-5th/:0:0","tags":["Nowcoder","ACM","C++"],"title":"牛客暑假多校第五场","uri":"/posts/nowcodersummer-5th/"},{"categories":["ACM"],"content":"G-max /* //wa #include\u003cbits/stdc++.h\u003e using namespace std; int main(){ int n,c;//好像不会爆 int 吧，头晕 cin\u003e\u003ec\u003e\u003en; int t=n/c; if(t\u003c1) cout\u003c\u003c\"-1\\n\";// else if(t==1) cout\u003c\u003cc*c\u003c\u003cendl; else cout\u003c\u003c(t*c)*((t-1)*c)\u003c\u003cendl; return 0; }*/ //AC #include\u003cbits/stdc++.h\u003e using namespace std; int main(){ long long n,c; cin\u003e\u003ec\u003e\u003en; long long t=n/c; if(t\u003c1) cout\u003c\u003c-1\u003c\u003cendl; else if(t==1) cout\u003c\u003cc*c\u003c\u003cendl; else cout\u003c\u003c(t*c)*((t-1)*c)\u003c\u003cendl; return 0; } ","date":"2018-08-02","objectID":"/posts/nowcodersummer-5th/:1:0","tags":["Nowcoder","ACM","C++"],"title":"牛客暑假多校第五场","uri":"/posts/nowcodersummer-5th/"},{"categories":["ACM"],"content":"J-plan /*枚举所有情况 全买双人 n%2 0 or 1//剩 1 个人的时候，可以多开一间房或者退一间 2 人房开一间 3 人房 全买 3 人 n%3 0 or 1 or 2 再比较大小 */ #include\u003cbits/stdc++.h\u003e #define INF 1\u003c\u003c20 using namespace std; typedef long long ll; ll min(ll a,ll b){ return a\u003cb?a:b; } int main(){ ll n,p2,p3,sum,sum1; while(cin\u003e\u003en\u003e\u003ep2\u003e\u003ep3){ if(n%2==0) sum=p2*(n/2); else sum=p2*(n/2)+min(min(p2,p3),p3-p2);//退二买三； if(n%3==0) sum1=p3*(n/3); else if(n%3==1) sum1=p3*(n/3)+min(min(p2,p3),2*p2-p3);//退 3 买 2*2 else if(n%3==2) sum1=p3*(n/3)+min(p3,p2);//退 3 买 3*2 cout\u003c\u003cmin(sum1,sum)\u003c\u003cendl; } return 0; } ","date":"2018-08-02","objectID":"/posts/nowcodersummer-5th/:2:0","tags":["Nowcoder","ACM","C++"],"title":"牛客暑假多校第五场","uri":"/posts/nowcodersummer-5th/"},{"categories":["ACM"],"content":"题目链接 思路参考 1,思路参考 2（没看懂） 先占坑，有时间再理理思路。 同一棵树中 d=1, 即 x 和 y 是同类，则需满足 r[x]==r[y] d=2,x 应该吃了 y, 也就是 (r[x]+1)%3 == r[y] 不同树合并且更新关系 (x 树做主根) ’ 如果 x 和 y 为关系 r1, y 和 z 为关系 r2， 那么 x 和 z 的关系就是（r1+r2）%3 如果 d==1 则 x 和 y 是同类 ，那么 y 对 x 的关系是 0, 如果 d==2 , 则 x 吃了 y, 那么 y 对 x 的关系是 1, x 对 y 的关系是 2。综上所述 , 无论 d 为 1 或者是为 2, y 对 x 的关系都是 d-1。 fy 对 y 的关系为 3-r[y] （有点互补的感觉，注意这里是不同类喔） y 对 x 的关系为 d-1, x 对 fx 的关系为 r[x] 所以 fy 对 fx 的关系是（3-r[y] + d-1 + r[x]）%3。可以借助向量图理解 fy-\u003ey-\u003ex-\u003efx #include\u003ccstdio\u003e const int maxn = 50000+10; int p[maxn]; //存父节点 int r[maxn];//存与父节点的关系 0 同一类，1 被父节点吃，2 吃父节点 void set(int n) //初始化 { for(int x = 1; x \u003c= n; x++) { p[x] = x; //开始自己是自己的父亲节点 r[x] = 0;//开始自己就是自己的父亲，每一个点均独立 } } int find(int x) //找父亲节点 { if(x == p[x]) return x; int t = p[x]; p[x] = find(p[x]); r[x] = (r[x]+r[t])%3; //回溯由子节点与父节点的关系和父节点与根节点的关系找子节点与根节点的关系 return p[x]; } void Union(int x, int y, int d) { int fx = find(x); int fy = find(y); p[fy] = fx; //合并树 注意：被 x 吃，所以以 x 的根为父 r[fy] = (r[x]-r[y]+3+(d-1))%3; //对应更新与父节点的关系 } int main() { int n, m; scanf(\"%d%d\", \u0026n, \u0026m); set(n); int ans = 0; int d, x, y; while(m--) { scanf(\"%d%d%d\", \u0026d, \u0026x, \u0026y); if(x \u003e n || y \u003e n || (d == 2 \u0026\u0026 x == y)) ans++; //如果节点编号大于最大编号，或者自己吃自己，说谎 else if(find(x) == find(y)) //如果原来有关系，也就是在同一棵树中，那么直接判断是否说谎 { if(d == 1 \u0026\u0026 r[x] != r[y]) ans++; //如果 x 和 y 不属于同一类 if(d == 2 \u0026\u0026 (r[x]+1)%3 != r[y]) ans++; // 如果 x 没有吃 y （注意要对应 Uinon(x, y) 的情况，否则一路 WA 到死啊！！！) } else Union(x, y, d); //如果开始没有关系，则建立关系 } printf(\"%d\\n\", ans); return 0; } ","date":"2018-08-02","objectID":"/posts/poj1182/:0:0","tags":["ACM","并查集","POJ","C++","C"],"title":"食物链-poj1182（带权并查集经典模板）","uri":"/posts/poj1182/"},{"categories":["ACM"],"content":"题目链接：小希的迷宫 ","date":"2018-08-01","objectID":"/posts/hdu1272/:1:0","tags":["ACM","并查集","HDU","C++","C"],"title":"小希的迷宫-HDU-1272（并查集 or 树性质）","uri":"/posts/hdu1272/"},{"categories":["ACM"],"content":"并查集： 无回路 单连通 并查集做，首先想到的是判断两个点是否连通，不连通就合并，已连通的话说明会形成回路，则可以判定 No，交了一发错了。 想了一下没有考虑到多个连通域的情况，该题必须只有一个连通域 ","date":"2018-08-01","objectID":"/posts/hdu1272/:2:0","tags":["ACM","并查集","HDU","C++","C"],"title":"小希的迷宫-HDU-1272（并查集 or 树性质）","uri":"/posts/hdu1272/"},{"categories":["ACM"],"content":"树的性质： 既然单连通无回路，则这肯定是一棵树；那么 edge=v-1; 最后注意空树的情况，至于自环我这里 No 也过了，没有去验证自环 Yes 的情况了 //并查集 #include\u003cbits/stdc++.h\u003e using namespace std; int pre[100001]; int find(int root){ int son,t; son=root; while(root!=pre[root]) root=pre[root]; while(son!=root){ t=pre[son]; pre[son]=root; son=t; } return root; } void join(int a,int b){ int x=find(a),y=find(b); if(x!=y) pre[y]=x; } int main(){ int a,b,flag,i,sum; while(1) { flag = 0; while(~scanf(\"%d%d\",\u0026a,\u0026b) \u0026\u0026 a!=0 \u0026\u0026 b!=0){ if(a==-1 \u0026\u0026 b==-1) return 0; if(pre[a]==0)pre[a]=a; if(pre[b]==0)pre[b]=b; if(find(a)==find(b))flag = 1; else if(flag!=1) join(a,b); } for(sum = 0,i=1;i\u003c100001;i++){ if(pre[i]==i)sum++; pre[i] = 0; } if(sum\u003e1 || flag == 1) printf(\"No\\n\"); else printf(\"Yes\\n\"); } } //1 2 3 4 0 0 No 没有连通 //0 0 Yes //1 1 0 0 No（该代码） //树性质 #include \u003cstdio.h\u003e bool s[100001]; int main() { int a,b,i,len,num,v; for(i=0;i\u003c100001;++i) s[i]=false; len=0,num=0,v=0; while(1) { scanf(\"%d%d\",\u0026a,\u0026b); if(a==-1\u0026\u0026b==-1) break; if(a==0\u0026\u0026b==0) { if(v==0) { printf(\"Yes\\n\"); continue; } if(num==len-1) //划重点！！ printf(\"Yes\\n\"); else printf(\"No\\n\"); num=len=v=0; for(i=0;i\u003c100001;++i) s[i]=false; continue; } v=1; if(s[a]==false) len++;//点数 if(s[b]==false) len++; s[a]=s[b]=true; num++;//边数 } return 0; ","date":"2018-08-01","objectID":"/posts/hdu1272/:3:0","tags":["ACM","并查集","HDU","C++","C"],"title":"小希的迷宫-HDU-1272（并查集 or 树性质）","uri":"/posts/hdu1272/"},{"categories":["ACM"],"content":"题目链接：How Many Answers Are Wrong 思路参考：本题直接参考,图文解释 #include\u003cbits/stdc++.h\u003e using namespace std; typedef long long LL; int pre[200010],ranks[200010]; int find(int root){ if(pre[root] != root) { int f = pre[root]; pre[root] = find(pre[root]);//递归路径压缩 ranks[root] += ranks[f]; /*精髓假如一开始没关系，那么用 rank 数组来表示 a，b 各自到各自祖先的距离。 那么在把 a 的祖先给 b 的祖先当父亲之后，那么 b 到祖先的距离也就是 rank[b] 就要再加上 b 原本的祖先到 a 的祖先的距离，更新一下， 其中 find 函数（找根节点的函数）里 rank[x]+=rank[pre[x]]（这里 pre 数组存的是对应数的父节点）*/ } return pre[root]; } int main(){ int n,m; while(~scanf(\"%d%d\",\u0026n,\u0026m)){ int ans=0; for(int i=1; i\u003c=n; i++) pre[i]=i; memset(ranks,0,sizeof(ranks)); while(m--){ int a,b,c; scanf(\"%d%d%d\",\u0026a,\u0026b,\u0026c); a--;//[a,b]~~(a--,b] int fa=find(a); int fb=find(b); if(fa!=fb){ pre[fb]=fa;//注意合并顺序，反过来下面的也要改 ranks[fb]=ranks[a]-ranks[b]+c;//更新距离 } else { if(ranks[b]-ranks[a]!=c) ans++; } } printf(\"%d\\n\",ans); } return 0; } ","date":"2018-08-01","objectID":"/posts/hdu3038/:0:0","tags":["并查集","ACM","HDU","C++"],"title":"How Many Answers Are Wrong-hdu3038（带权并查集）","uri":"/posts/hdu3038/"},{"categories":["ACM"],"content":"题目链接：Bear and Finding Criminals 大致题意就是小熊警察住在某个城市，他要抓各个城市的罪犯，现在用一个 BCD 可以知道那个城市里一定有罪犯。 一定能确定该城市有小偷的几种情况： 警察所住城市有罪犯，则一定能检测到 警察所住城市的左边和右边位置若都不为 0，则说明两座城市都有罪犯（只有一边为 1 是不能确定到底哪个城市有罪犯的） 警察所在城市的一边检测到有罪犯，但在另一边已经没有城市了，则说明该城市一定有罪犯 #include\u003cbits/stdc++.h\u003e using namespace std; int t[107]; int main() { int n, a; while(cin\u003e\u003en\u003e\u003ea){ int sum = 0; for(int i =1; i \u003c= n; i++) cin \u003e\u003e t[i]; if(t[a]) sum++;//小熊所在城市有罪犯 for(int i = 1; i \u003c= n; i++){ if(a-i \u003e 0\u0026\u0026a+i \u003c= n) { if(t[a-i] == 1\u0026\u0026t[a+i] == 1) sum+=2; } else if(a-i \u003c= 0\u0026\u0026a+i \u003c= n){//警察在第一个点 if(t[a+i]) sum++; } else if(a-i \u003e 0\u0026\u0026a+i \u003e n){ if(t[a-i]) sum++; } } cout \u003c\u003csum\u003c\u003cendl; } return 0; } ","date":"2018-07-31","objectID":"/posts/codeforces680b/:0:0","tags":["Codeforces","ACM","C++"],"title":"Bear and Finding Criminals-Codeforces680B","uri":"/posts/codeforces680b/"},{"categories":["ACM"],"content":"题目链接：Bear and Five Cards 大致题意就是小熊有 5 张卡片，每张卡片有对应的分数，他可以选择丢弃 2 张相同的或者 3 张相同的卡片，没有相同的就无法丢弃，问小熊剩下的分数最少是多少。 没有想得那么复杂，由于分数最大才 100，所以直接暴力就好了。 #include\u003cbits/stdc++.h\u003e using namespace std; int main(){ int a[5],b[107],i,j,sum=0,sum1=0; for(i=0;i\u003c5;i++){ cin\u003e\u003ea[i]; sum+=a[i]; } sort(a,a+5); memset(b,0,sizeof(b)); for(i=0;i\u003c5;i++) b[a[i]]++; for(i=0;i\u003c107;i++){ if(b[i]==2) sum1=max(2*i,sum1); if(b[i]\u003e=3) {sum1=max(3*i,sum1);/*cout\u003c\u003c3*i\u003c\u003c\" \"\u003c\u003csum1\u003c\u003cendl;*/} } cout\u003c\u003csum-sum1\u003c\u003cendl; return 0; } ","date":"2018-07-31","objectID":"/posts/codeforces680a/:0:0","tags":["Codeforces","ACM","C++"],"title":"Bear and Five Cards-Codeforces680A","uri":"/posts/codeforces680a/"},{"categories":["ACM"],"content":"并查集求连通域数目，初始化 sum=n； 题目链接： how many tables #include\u003cbits/stdc++.h\u003e using namespace std; int pre[1005]; int find(int root){ int son,t; son=root; while(root!=pre[root]) root=pre[root]; while(son!=root){ t=pre[son]; pre[son]=root; son=t; } return root; } int main(){ int n,m,t,sum,root1,root2; cin\u003e\u003et; while(t--){ cin\u003e\u003en\u003e\u003em; sum=n; for(int i=1;i\u003c=n;i++) pre[i]=i; for(int i=0;i\u003cm;i++){ cin\u003e\u003eroot1\u003e\u003eroot2; int xx=find(root1); int yy=find(root2); if(xx!=yy){ pre[xx]=yy; sum--; } } cout\u003c\u003csum\u003c\u003cendl; } return 0; } ","date":"2018-07-31","objectID":"/posts/how-tables/:0:0","tags":["并查集","HDU","C++","ACM"],"title":"how many tables-HDU-1213（并查集求连通域数目）","uri":"/posts/how-tables/"},{"categories":["ACM"],"content":"题目链接：The-suspects ","date":"2018-07-31","objectID":"/posts/poj-1611/:1:0","tags":["并查集","POJ","ACM","C","C++"],"title":"The-suspects-POJ-1611（并查集）","uri":"/posts/poj-1611/"},{"categories":["ACM"],"content":"翻译： 警察抓贩毒集团。有不同类型的犯罪集团，人员可能重复，集团内的人会相互接触。现在警察在其中一人（0 号）身上搜出毒品，认为与这个人直接接触或通过其他人有间接接触的人都是嫌疑犯。问包括 0 号犯人共有多少嫌疑犯？ ","date":"2018-07-31","objectID":"/posts/poj-1611/:2:0","tags":["并查集","POJ","ACM","C","C++"],"title":"The-suspects-POJ-1611（并查集）","uri":"/posts/poj-1611/"},{"categories":["ACM"],"content":"Input 多样例输入。 每个测试用例以两个整数 n 和 m 开头，其中 n 为人数，m 为犯罪集团数。你可以假定 0 \u003c n \u003c= 30000 和 0 \u003c= m \u003c= 500。在所有的情况下，每个人都有自己独特的整数编号 0 到 n−1, 且 0 号是公认的嫌疑犯。 接下来 m 行输入，每个犯罪集团一行。每一行从一个整数 k 开始，它本身表示集团内成员的数量。按照成员的数量，在这个组中有 k 个整数表示人员。一行中的所有整数都被至少一个空格隔开。 n = 0 且 m = 0 时输入结束。 ","date":"2018-07-31","objectID":"/posts/poj-1611/:2:1","tags":["并查集","POJ","ACM","C","C++"],"title":"The-suspects-POJ-1611（并查集）","uri":"/posts/poj-1611/"},{"categories":["ACM"],"content":"Output 对于每个样例，输出嫌疑犯人数。 ","date":"2018-07-31","objectID":"/posts/poj-1611/:2:2","tags":["并查集","POJ","ACM","C","C++"],"title":"The-suspects-POJ-1611（并查集）","uri":"/posts/poj-1611/"},{"categories":["ACM"],"content":"Sample Input 100 4 2 1 2 5 10 13 11 12 14 2 0 1 2 99 2 200 2 1 5 5 1 2 3 4 5 1 0 0 0 ","date":"2018-07-31","objectID":"/posts/poj-1611/:2:3","tags":["并查集","POJ","ACM","C","C++"],"title":"The-suspects-POJ-1611（并查集）","uri":"/posts/poj-1611/"},{"categories":["ACM"],"content":"Sample Output 4 1 这题也很好理解，AC 代码如下： #include\u003ccstdio\u003e int pre[30010],x[30010]; int find(int root){ int son,t; son=root; while(root!=pre[root]) root=pre[root]; while(son!=root){ t=pre[son]; pre[son]=root; son=t; } return root; } void join(int x,int y){ int fx=find(x),fy=find(y); if(fx!=fy) pre[fy]=fx; } int main(){ int n,m,i,k,sum; while(scanf(\"%d%d\",\u0026n,\u0026m),n||m){ sum=0; for(i=0;i\u003cn;i++) pre[i]=i; while(m--){ scanf(\"%d\",\u0026k); for(i=0;i\u003ck;i++) scanf(\"%d\",\u0026x[i]); for(i=1;i\u003ck;i++) join(x[i-1],x[i]); } for(i=0;i\u003cn;i++) if(find(0)==find(i)) sum++;//再次查找并压缩路径，注不用 pre[i] printf(\"%d\\n\",sum); } return 0; } ","date":"2018-07-31","objectID":"/posts/poj-1611/:2:4","tags":["并查集","POJ","ACM","C","C++"],"title":"The-suspects-POJ-1611（并查集）","uri":"/posts/poj-1611/"},{"categories":["ACM"],"content":"题目链接：wireless network ","date":"2018-07-31","objectID":"/posts/poj-2236/:1:0","tags":["并查集","ACM","POJ","C++","C"],"title":"wireless network-POJ-2236（并查集）","uri":"/posts/poj-2236/"},{"categories":["ACM"],"content":"翻译： 南亚发生了一次地震。ACM (Asia Cooperated Medical 亚洲联合医疗队） 已经为膝上型电脑搭建了一个无线网络，但受到了一次不可预知的余震攻击，因此网络中的所有电脑都被破坏了。电脑被逐台修复，网络逐步恢复了工作。由于受到硬件的约束，每台电脑只能与距离它不超过 d 米的其它电脑直接通信。但每台电脑可被看作其它两台电脑的通信中转点，也就是说，如果电脑 A 和电脑 B 可以直接通信，或存在一台电脑 C 既可与 A 也可与 B 通信，那么电脑 A 和电脑 B 之间就能够通信。 在处理网络修复的过程中，工作人员们在任何一个时刻，可以执行两种操作：维修一台电脑，或测试两台电脑是否能够通信。请您找出全部的测试操作。 ","date":"2018-07-31","objectID":"/posts/poj-2236/:2:0","tags":["并查集","ACM","POJ","C++","C"],"title":"wireless network-POJ-2236（并查集）","uri":"/posts/poj-2236/"},{"categories":["ACM"],"content":"输入 第一行包含了两个整数 N 和 d (1 \u003c= N \u003c= 1001, 0 \u003c= d \u003c= 20000)。此处 N 是电脑的数目，编号从 1 到 N；同时，D 是两台电脑之间能够直接通信的最大距离。接下来的 N 行，每行包含两个整数 xi, yi (0 \u003c= xi, yi \u003c= 10000)，表示 N 台电脑的坐标。从第 (N+1) 行到输入结束，是逐一执行的操作，每行包含一个操作，格式是以下两者之一： “O p” (1 \u003c= p \u003c= N)，表示维护电脑 p 。 “S p q” (1 \u003c= p, q \u003c= N)，表示测试电脑 p 和 q 是否能够通信。 输入不超过 300000 行。 ","date":"2018-07-31","objectID":"/posts/poj-2236/:2:1","tags":["并查集","ACM","POJ","C++","C"],"title":"wireless network-POJ-2236（并查集）","uri":"/posts/poj-2236/"},{"categories":["ACM"],"content":"输出 对于每个测试操作，如果两台电脑能够通信，则打印 “SUCCESS”；否则，打印 “FAIL”。 ","date":"2018-07-31","objectID":"/posts/poj-2236/:2:2","tags":["并查集","ACM","POJ","C++","C"],"title":"wireless network-POJ-2236（并查集）","uri":"/posts/poj-2236/"},{"categories":["ACM"],"content":"示例输入 4 1 0 1 0 2 0 3 0 4 O 1 O 2 O 4 S 1 4 O 3 S 1 4 ","date":"2018-07-31","objectID":"/posts/poj-2236/:2:3","tags":["并查集","ACM","POJ","C++","C"],"title":"wireless network-POJ-2236（并查集）","uri":"/posts/poj-2236/"},{"categories":["ACM"],"content":"示例输出 FAIL SUCCESS ","date":"2018-07-31","objectID":"/posts/poj-2236/:2:4","tags":["并查集","ACM","POJ","C++","C"],"title":"wireless network-POJ-2236（并查集）","uri":"/posts/poj-2236/"},{"categories":["ACM"],"content":"AC 代码： #include \"iostream\" #include \"cstring\" using namespace std; int pre[1005]; int x[1005],y[1005],use[1005]; int findd(int root){ int son,t; son=root; while(root!=pre[root]) root=pre[root]; while(son!=root){ t=pre[son]; pre[son]=root; son=t; } return root; } void join(int x,int y){ int fx=findd(x),fy=findd(y); if(fx!=fy) pre[fx]=fy; } int dis(int i,int num,int d){ d=d*d; int xx=x[i]-x[num]; int yy=y[i]-y[num]; if((xx*xx+yy*yy)\u003c=d) return 1; return 0; } int main(){ int n,d; char s; memset(use,0,sizeof(use)); cin\u003e\u003en\u003e\u003ed; for(int i=0;i\u003c=n;i++) pre[i]=i; for(int i=1;i\u003c=n;i++) cin\u003e\u003ex[i]\u003e\u003ey[i]; while(cin\u003e\u003es){ if(s=='O'){ int num; cin\u003e\u003enum; use[num]=1; findd(num);//路径压缩 for(int i=1;i\u003c=n;i++) if(i!=num\u0026\u0026use[i]==1\u0026\u0026dis(i,num,d))//修好了，且可以被合并（自己除外） join(i,num); } else if(s=='S'){ int q,p; cin\u003e\u003eq\u003e\u003ep; if(findd(q)==findd(p)) cout\u003c\u003c\"SUCCESS\"\u003c\u003cendl; else cout\u003c\u003c\"FAIL\"\u003c\u003cendl; } } return 0; } ","date":"2018-07-31","objectID":"/posts/poj-2236/:2:5","tags":["并查集","ACM","POJ","C++","C"],"title":"wireless network-POJ-2236（并查集）","uri":"/posts/poj-2236/"},{"categories":["ACM"],"content":"Codeforces Round #500 (Div. 2) 题目链接：Piles With Stones 大致题意就是有 n 堆石头，第一天每堆有一定数目的石头，第二天石头可能被小朋友移动或者带走，求满足题意的两天的石碓； 所以第二天的石头总数不会大于第一天的，所以是 sum1-sum2\u003e=0 即可。 //又只打了一道题，扣了 80 多分。 #include\u003cbits/stdc++.h\u003e using namespace std; int x[55],y[55],n,s1=0,s2=0; int main(){ scanf(\"%d\",\u0026n); for(int i=0;i\u003cn;i++){ scanf(\"%d\",\u0026x[i]); s1+=x[i]; } for(int i=0;i\u003cn;i++){ scanf(\"%d\",\u0026y[i]); s2+=y[i]; } if((s1-s2)\u003e=0) printf(\"Yes\\n\"); else printf(\"No\\n\"); return 0; } ","date":"2018-07-31","objectID":"/posts/piles-with-stones/:0:0","tags":["ACM","Codeforces","C++"],"title":"Piles-with-stones","uri":"/posts/piles-with-stones/"},{"categories":["ACM"],"content":"并查集入门推荐：超有爱的并查集~ 题目链接：畅通工程 题意分析： 首先在地图上给你若干个城镇，这些城镇都可以看作点，然后告诉你哪些对城镇之间是有道路直接相连的。最后要解决的是整幅图的连通性问题。比如随意给你两个点，让你判断它们是否连通，或者问你整幅图一共有几个连通分支，也就是被分成了几个互相独立的块。像畅通工程这题，问还需要修几条路，实质就是求有几个连通分支。 #include\u003ciostream\u003e #include\u003ccstdio\u003e using namespace std; int pre[1010]; int findd(int root){ int son,t; son=root; while(root!=pre[root]) root=pre[root]; while(son!=root){ t=pre[son]; pre[son]=root; son=t; } return root; } int main(){ int n,m,i,sum,r1,r2,star,end1; while(scanf(\"%d\",\u0026n)\u0026\u0026n){ sum=n-1; for(i=1;i\u003c=n;i++) pre[i]=i; scanf(\"%d\",\u0026m); while(m--){ scanf(\"%d%d\",\u0026star,\u0026end1); r1=findd(star); r2=findd(end1); if(r1!=r2){ pre[r1]=r2; sum--; } } printf(\"%d\\n\",sum); } return 0; } 基础回顾： find() 函数找根结点的两种写法如下： 第一种递归： int find(int x) { return x == pre[x] ? x : find(pre[x]); } 第二种： int find(int x) { int root, temp; root = x; while(root != pre[root]) root = pre[root]; while(x != root) { temp = pre[x]; pre[temp] = root; x = temp; } return root; } 合并函数 void join(int x,int y){ int fx=find(x); int fy=find(y); if(fx!=fy) pre[fx]=fy; } ","date":"2018-07-31","objectID":"/posts/%E7%95%85%E9%80%9A%E5%B7%A5%E7%A8%8B/:0:0","tags":["ACM","并查集","HDU","C++","C"],"title":"畅通工程-HDU-1232（并查集经典模板）","uri":"/posts/%E7%95%85%E9%80%9A%E5%B7%A5%E7%A8%8B/"},{"categories":["ACM"],"content":"两题水过，暴力，找规律。 ","date":"2018-07-27","objectID":"/posts/%E7%89%9B%E5%AE%A2%E7%BB%83%E4%B9%A0%E8%B5%9B23/:0:0","tags":["Nowcoder","ACM","C++","C"],"title":"牛客练习赛 23","uri":"/posts/%E7%89%9B%E5%AE%A2%E7%BB%83%E4%B9%A0%E8%B5%9B23/"},{"categories":["ACM"],"content":"托米的赌球 ","date":"2018-07-27","objectID":"/posts/%E7%89%9B%E5%AE%A2%E7%BB%83%E4%B9%A0%E8%B5%9B23/:1:0","tags":["Nowcoder","ACM","C++","C"],"title":"牛客练习赛 23","uri":"/posts/%E7%89%9B%E5%AE%A2%E7%BB%83%E4%B9%A0%E8%B5%9B23/"},{"categories":["ACM"],"content":"托米的划分 ","date":"2018-07-27","objectID":"/posts/%E7%89%9B%E5%AE%A2%E7%BB%83%E4%B9%A0%E8%B5%9B23/:2:0","tags":["Nowcoder","ACM","C++","C"],"title":"牛客练习赛 23","uri":"/posts/%E7%89%9B%E5%AE%A2%E7%BB%83%E4%B9%A0%E8%B5%9B23/"},{"categories":["ACM"],"content":"a #include\u003cbits/stdc++.h\u003e using namespace std; int main(){ int c[13],d[13]={100,50,20,10,5,2,1,50,20,10,5,2,1}; int i,t; cin\u003e\u003et; int a,b; while(t--){ memset(c,0,sizeof(c)); cin\u003e\u003ea\u003e\u003eb; for(i=0;i\u003c7;i++){ int x=0; if(a\u003ec[i]){ x=a/d[i]; c[i]+=x; a-=x*d[i]; } for(i=7;i\u003c13;i++){ int x=0; if(b\u003ec[i]){ x=b/d[i]; c[i]+=x; b-=x*d[i]; } cout\u003c\u003cc[0]; for(i=1;i\u003c13;i++) cout\u003c\u003c\" \"\u003c\u003cc[i]; cout\u003c\u003cendl; } return 0; } ","date":"2018-07-27","objectID":"/posts/%E7%89%9B%E5%AE%A2%E7%BB%83%E4%B9%A0%E8%B5%9B23/:3:0","tags":["Nowcoder","ACM","C++","C"],"title":"牛客练习赛 23","uri":"/posts/%E7%89%9B%E5%AE%A2%E7%BB%83%E4%B9%A0%E8%B5%9B23/"},{"categories":["ACM"],"content":"b f(n)=f(n-1)+n-1; #include\u003cbits/stdc++.h\u003e using namespace std; long long sum; int main(){ int n; int t; cin\u003e\u003et; while(t--){ sum=1; cin\u003e\u003en; if(n==1) sum=0; for(int i=3;i\u003c=n;i++) sum+=i-1; cout\u003c\u003csum\u003c\u003cendl; } return 0; } ","date":"2018-07-27","objectID":"/posts/%E7%89%9B%E5%AE%A2%E7%BB%83%E4%B9%A0%E8%B5%9B23/:4:0","tags":["Nowcoder","ACM","C++","C"],"title":"牛客练习赛 23","uri":"/posts/%E7%89%9B%E5%AE%A2%E7%BB%83%E4%B9%A0%E8%B5%9B23/"},{"categories":["Grocery"],"content":"在线算法 在线算法是指它可以以序列化的方式一个个的处理输入，也就是说在开始时并不需要已经知道所有的输入。 在计算机科学中，一个在线算法是指它可以以序列化的方式一个个的处理输入，也就是说在开始时并不需要已经知道所有的输入。相对的，对于一个离线算法，在开始时就需要知道问题的所有输入数据，而且在解决一个问题后就要立即输出结果。例如，选择排序在排序前就需要知道所有待排序元素，然而插入排序就不必。 因为在线算法并不知道整个的输入，所以它被迫做出的选择最后可能会被证明不是最优的，对在线算法的研究主要集中在当前环境下怎么做出选择。对相同问题的在线算法和离线算法的对比分析形成了以上观点。如果想从其他角度了解在线算法可以看一下流算法（关注精确呈现过去的输入所使用的内存的量），动态算法（关注维护一个在线输入的结果所需要的时间复杂度）和在线机器学习。 一个很好的展示在线算法概念的例子是 加拿大旅行者问题，这个问题的目标是在一个有权图中以最小的代价到达一个目标节点，但这个有权图中有些边是不可靠的可能已经被剔除。然而一个旅行者只有到某个边的一个端点时才能确定该边是否已经被移除了。最坏情况下，该问题会变得简单了，即所有的不确定的边都被移除该问题将会变成通常的最短路径问题。 ","date":"2018-07-26","objectID":"/posts/%E5%9C%A8%E7%BA%BF%E7%A6%BB%E7%BA%BF%E7%AE%97%E6%B3%95/:1:0","tags":["在线离线算法"],"title":"在线离线算法","uri":"/posts/%E5%9C%A8%E7%BA%BF%E7%A6%BB%E7%BA%BF%E7%AE%97%E6%B3%95/"},{"categories":["Grocery"],"content":"离线算法 离线算法 ( off line algorithms)，是指基于在执行算法前输入数据已知的基本假设，也就是说，对于一个离线算法，在开始时就需要知道问题的所有输入数据，而且在解决一个问题后就要立即输出结果。 设计策略 在执行算法前输入已知的基本假设 前提 具有问题完全信息 算法设计策略都是基于在执行算法前输入数据已知的基本假设，也就是说，对于一个离线算法，在开始时就需要知道问题的所有输入数据，而且在解决一个问题后就要立即输出结果，通常将这类具有问题完全信息前提下设计出的算法称为离线算法 ( off line algorithms) ","date":"2018-07-26","objectID":"/posts/%E5%9C%A8%E7%BA%BF%E7%A6%BB%E7%BA%BF%E7%AE%97%E6%B3%95/:2:0","tags":["在线离线算法"],"title":"在线离线算法","uri":"/posts/%E5%9C%A8%E7%BA%BF%E7%A6%BB%E7%BA%BF%E7%AE%97%E6%B3%95/"},{"categories":["ACM"],"content":"非常可乐 大家一定觉的运动以后喝可乐是一件很惬意的事情，但是 seeyou 却不这么认为。因为每次当 seeyou 买了可乐以后，阿牛就要求和 seeyou 一起分享这一瓶可乐，而且一定要喝的和 seeyou 一样多。但 seeyou 的手中只有两个杯子，它们的容量分别是 N 毫升和 M 毫升 可乐的体积为 S （S\u003c101）毫升　（正好装满一瓶） ，它们三个之间可以相互倒可乐 （都是没有刻度的，且 S==N+M，101 ＞ S ＞ 0，N ＞ 0，M ＞ 0) 。聪明的 ACMER 你们说他们能平分吗？如果能请输出倒可乐的最少的次数，如果不能输出\"NO\"。 ","date":"2018-07-24","objectID":"/posts/hdu-1495/:0:0","tags":["ACM","HDU","搜索","C++"],"title":"HDU-1495-非常可乐（bfs 模拟倒水 or 数论）","uri":"/posts/hdu-1495/"},{"categories":["ACM"],"content":"Input 三个整数 : S 可乐的体积 , N 和 M 是两个杯子的容量，以\"0 0 0\"结束。 ","date":"2018-07-24","objectID":"/posts/hdu-1495/:0:1","tags":["ACM","HDU","搜索","C++"],"title":"HDU-1495-非常可乐（bfs 模拟倒水 or 数论）","uri":"/posts/hdu-1495/"},{"categories":["ACM"],"content":"Output 如果能平分的话请输出最少要倒的次数，否则输出\"NO\"。 ","date":"2018-07-24","objectID":"/posts/hdu-1495/:0:2","tags":["ACM","HDU","搜索","C++"],"title":"HDU-1495-非常可乐（bfs 模拟倒水 or 数论）","uri":"/posts/hdu-1495/"},{"categories":["ACM"],"content":"Sample Input 7 4 3 4 1 3 0 0 0 ","date":"2018-07-24","objectID":"/posts/hdu-1495/:0:3","tags":["ACM","HDU","搜索","C++"],"title":"HDU-1495-非常可乐（bfs 模拟倒水 or 数论）","uri":"/posts/hdu-1495/"},{"categories":["ACM"],"content":"Sample Output NO 3 模拟一下倒水的过程，一共有三种倒法，a 向 bc，b 向 ac，c 向 ab。（相当于一共六个方向）搜索并记录搜索过的过程就好了。 #include\u003cbits/stdc++.h\u003e using namespace std; int a,b,c; int used[111][111][111]; struct node { int x,y,z; int step; }m,n; int bfs() { queue\u003cnode\u003eq; m.x = a; m.y = 0; m.z = 0; m.step = 0; used[a][0][0] = 1; q.push(m); while (!q.empty()) { int trans; //倒水量 m = q.front(); q.pop(); //成功分好的三种情况 if ((m.x == 0 \u0026\u0026 m.y == m.z) || (m.y == 0 \u0026\u0026 m.x == m.z) || (m.z == 0 \u0026\u0026 m.x == m.y)) return m.step; //下面开始 6 个搜索（由一个杯子向另外两个倒水） if (m.x) { //第一 trans = min(m.x , b - m.y);//自己模拟一下倒水过程就知道了 n.x = m.x - trans; n.y = m.y + trans; n.z = m.z; n.step = m.step + 1; if (!used[n.x][n.y][n.z]) { q.push(n); used[n.x][n.y][n.z] = 1; } //第二 trans = min(m.x , c - m.z); n.x = m.x - trans; n.y = m.y; n.z = m.z + trans; n.step = m.step + 1; if (!used[n.x][n.y][n.z]) { q.push(n); used[n.x][n.y][n.z] = 1; } } if (m.y) { //第三 trans = min(m.y , a - m.x); n.x = m.x + trans; n.y = m.y - trans; n.z = m.z; n.step = m.step + 1; if (!used[n.x][n.y][n.z]) { used[n.x][n.y][n.z] = 1; q.push(n); } //第四 trans = min(m.y , c - m.z); n.x = m.x; n.y = m.y - trans; n.z = m.z + trans; n.step = m.step + 1; if (!used[n.x][n.y][n.z]) { used[n.x][n.y][n.z] = 1; q.push(n); } } if (m.z) { //第五 trans = min(m.z , a - m.x); n.x = m.x + trans; n.y = m.y; n.z = m.z - trans; n.step = m.step + 1; if (!used[n.x][n.y][n.z]) { used[n.x][n.y][n.z] = 1; q.push(n); } //第六 trans = min(m.z , b - m.y); n.x = m.x; n.y = m.y + trans; n.z = m.z - trans; n.step = m.step + 1; if (!used[n.x][n.y][n.z]) { q.push(n); used[n.x][n.y][n.z] = 1; } } } return 0; } int main() { while (~scanf (\"%d %d %d\",\u0026a,\u0026b,\u0026c) \u0026\u0026 (a || b || c)) { if (a\u00261) //先简单的剪枝一下，奇数肯定不能平分 printf (\"NO\\n\"); else { memset (used,0,sizeof (used)); int ans = bfs(); if (ans) printf (\"%d\\n\",ans); else printf (\"NO\\n\"); } } return 0; } 然后杭电上讨论板子上提供一种数论题解，但是数据存在一点问题，只不过有些数据好像不对；比如： 10 6 5 的结果应该是 1 而不是 9， 也提示我们多维思考同一个问题！ 数论推导 #include\u003cbits/stdc++.h\u003e using namespace std; int main(){ int s,n,m; while(cin\u003e\u003es\u003e\u003en\u003e\u003em,s+n+m){ s/=__gcd(n,m); if(s\u00261)//奇数 cout\u003c\u003c\"NO\\n\"; else cout\u003c\u003cs-1\u003c\u003cendl; } return 0; } ","date":"2018-07-24","objectID":"/posts/hdu-1495/:0:4","tags":["ACM","HDU","搜索","C++"],"title":"HDU-1495-非常可乐（bfs 模拟倒水 or 数论）","uri":"/posts/hdu-1495/"},{"categories":["ACM"],"content":"Find a way 圣诞节要到了，坤神和瑞瑞这对基佬想一起去召唤师大峡谷开开车。百度地图一下，发现周围的召唤师大峡谷还不少，这对基佬纠结着，该去哪一个。坤神：我要去左边的这个（因为离自己比较近 哈哈~）。瑞瑞：我要去右边的这个（因为离自己比较近 嘿嘿~） …….. 这对基佬闹矛盾了，开车有危险了！ 为了不让他们去召唤师大峡谷坑人，riot 决定让他们去 X 召唤师大峡谷，保证他俩所走的路程和最短。每走一个点需要花费 11 分钟，输出他们一共花费多少时间（最短时间噢） ","date":"2018-07-23","objectID":"/posts/hdu-2612/:0:1","tags":["ACM","HDU","搜索","C++"],"title":"hdu-2612-Find a way（双 bfs）","uri":"/posts/hdu-2612/"},{"categories":["ACM"],"content":"Input 多组测试数据 每组数据，开始一行 n，m (2\u003c=n,m\u003c=200) 接下来是个 n x m 的矩阵 ‘Y’ 表示坤神所在的初始位置 ‘M’ 表示瑞瑞所在的初始位置 ‘#’ 该点禁止通行 ‘.’ 该点可通行 ‘@’ 召唤师大峡谷 ","date":"2018-07-23","objectID":"/posts/hdu-2612/:0:2","tags":["ACM","HDU","搜索","C++"],"title":"hdu-2612-Find a way（双 bfs）","uri":"/posts/hdu-2612/"},{"categories":["ACM"],"content":"Output 每组测试数据，输出坤神和瑞瑞到达同一个召唤师大峡谷所花费的最短时间。 ","date":"2018-07-23","objectID":"/posts/hdu-2612/:0:3","tags":["ACM","HDU","搜索","C++"],"title":"hdu-2612-Find a way（双 bfs）","uri":"/posts/hdu-2612/"},{"categories":["ACM"],"content":"Sample Input 4 4 Y.#@ .... .#.. @..M 4 4 Y.#@ .... .#.. @#.M 5 5 Y..@. .#... @..M. `#...#` ","date":"2018-07-23","objectID":"/posts/hdu-2612/:0:4","tags":["ACM","HDU","搜索","C++"],"title":"hdu-2612-Find a way（双 bfs）","uri":"/posts/hdu-2612/"},{"categories":["ACM"],"content":"Sample Output 66 88 66 ","date":"2018-07-23","objectID":"/posts/hdu-2612/:0:5","tags":["ACM","HDU","搜索","C++"],"title":"hdu-2612-Find a way（双 bfs）","uri":"/posts/hdu-2612/"},{"categories":["ACM"],"content":"Hint 对于第一组样例，坤神和瑞瑞去矩阵（4,1） 这个召唤师大峡谷，耗费的时间为 3 _ 11 + 3 _ 11 = 66， 去矩阵（1,4）这个召唤师大峡谷，耗费的时间为 5 _ 11 + 3 _ 11 = 88 。所以，最终答案：66。思路参考 写代码总是好粗心！！ #include \u003cbits/stdc++.h\u003e #define inf 0x3f3f3f3f //acm 中“无穷大”的一般定义 using namespace std; const int M=202; char mp[M][M]; //地图 int a[M][M],b[M][M]; bool vis[M][M]; //标记数组 int n,m; int ans; struct node { int x,y,step; }; void init() //初始化函数 { ans=inf; for(int i=0; i\u003cn; i++) for(int j=0; j\u003cm; j++) { a[i][j]=inf; b[i][j]=inf; } } void bfs(int x,int y,bool flag){ int dir[4][2]={-1,0,1,0,0,1,0,-1}; node u,v; queue\u003cnode\u003e q; //初始化队列第一个元素 u.x=x; u.y=y; u.step=0; vis[x][y]=true; q.push(u); while(!q.empty()){ u=q.front(); q.pop(); if(mp[u.x][u.y]=='@'){ if(!flag) a[u.x][u.y]=u.step; else b[u.x][u.y]=u.step; } for(int i=0;i\u003c4;i++){ int tx=u.x+dir[i][0]; int ty=u.y+dir[i][1]; if(tx\u003e=0\u0026\u0026ty\u003e=0\u0026\u0026tx\u003cn\u0026\u0026ty\u003cm\u0026\u0026!vis[tx][ty]\u0026\u0026mp[tx][ty]!='#'){//注意@和 M，Y 也是可以走的。 v.x=tx; //每次写搜索都忘记 vis!!!! v.y=ty; vis[tx][ty]=true; //我总是忘记。 v.step=u.step+1; q.push(v); } } } } int main() { while(~scanf(\"%d%d\",\u0026n,\u0026m)) { init(); for(int i=0; i\u003cn; i++) scanf(\"%s\",mp[i]); for(int i=0; i\u003cn; i++) for(int j=0; j\u003cm; j++) { if(mp[i][j]=='Y') { memset(vis,false,sizeof(vis)); bfs(i,j,false); } if(mp[i][j]=='M') { memset(vis,false,sizeof(vis)); //记得再次初始化标记数组 bfs(i,j,true); } } for(int i=0; i\u003cn; i++) for(int j=0; j\u003cm; j++) if(mp[i][j]=='@') ans=min(ans,a[i][j]+b[i][j]); printf(\"%d\\n\",ans*11); } return 0; } ","date":"2018-07-23","objectID":"/posts/hdu-2612/:0:6","tags":["ACM","HDU","搜索","C++"],"title":"hdu-2612-Find a way（双 bfs）","uri":"/posts/hdu-2612/"},{"categories":["ACM"],"content":"Farmer John has been informed of the location of a fugitive cow and wants to catch her immediately. He starts at a point N (0 ≤ N ≤ 100,000) on a number line and the cow is at a point K (0 ≤ K ≤ 100,000) on the same number line. Farmer John has two modes of transportation: walking and teleporting. Walking: FJ can move from any point X to the points X\",“1 or X + 1 in a single minute Teleporting: FJ can move from any point X to the point 2 × X in a single minute. If the cow, unaware of its pursuit, does not move at all, how long does it take for Farmer John to retrieve it? ","date":"2018-07-22","objectID":"/posts/poj-3278/:0:0","tags":["BFS","ACM","搜索","POJ","C++"],"title":"POJ-3278-Catch That Cow(bfs)","uri":"/posts/poj-3278/"},{"categories":["ACM"],"content":"Input Line 1: Two space-separated integers: N and K ","date":"2018-07-22","objectID":"/posts/poj-3278/:0:1","tags":["BFS","ACM","搜索","POJ","C++"],"title":"POJ-3278-Catch That Cow(bfs)","uri":"/posts/poj-3278/"},{"categories":["ACM"],"content":"Output Line 1: The least amount of time, in minutes, it takes for Farmer John to catch the fugitive cow. ","date":"2018-07-22","objectID":"/posts/poj-3278/:0:2","tags":["BFS","ACM","搜索","POJ","C++"],"title":"POJ-3278-Catch That Cow(bfs)","uri":"/posts/poj-3278/"},{"categories":["ACM"],"content":"Sample Input 5 17 ","date":"2018-07-22","objectID":"/posts/poj-3278/:0:3","tags":["BFS","ACM","搜索","POJ","C++"],"title":"POJ-3278-Catch That Cow(bfs)","uri":"/posts/poj-3278/"},{"categories":["ACM"],"content":"Sample Output 4 ","date":"2018-07-22","objectID":"/posts/poj-3278/:0:4","tags":["BFS","ACM","搜索","POJ","C++"],"title":"POJ-3278-Catch That Cow(bfs)","uri":"/posts/poj-3278/"},{"categories":["ACM"],"content":"Hint The fastest way for Farmer John to reach the fugitive cow is to move along the following path: 5-10-9-18-17, which takes 4 minutes. ","date":"2018-07-22","objectID":"/posts/poj-3278/:0:5","tags":["BFS","ACM","搜索","POJ","C++"],"title":"POJ-3278-Catch That Cow(bfs)","uri":"/posts/poj-3278/"},{"categories":["ACM"],"content":"题意： 农场主的牛不见了，主人和牛在一条直线上，且牛没有新的目标，它不会走动，主人的位置是你 n，牛的位置是 k，主人可以有三种走路的方法，右左（距离+-1），闪现（距离+x,x 为当前位置），每走一步，一分钟，问几分钟主人能找到牛。bfs 搜索方向即为三个“方向”。搜索所有走法； #include\"iostream\" #include\u003cqueue\u003e #include\"string.h\" using namespace std; int n,k; bool sign[200007]; struct node{ int x,step; }; bool check(int a) { if(!sign[a]\u0026\u0026a\u003e=0\u0026\u0026a\u003c110000) return true; return false; } void bfs() { node u,v; queue\u003cnode\u003e q; v.x=n;//初始化起点 v.step=0; q.push(v); sign[v.x]=true; while(!q.empty()){ u=q.front(); q.pop(); if(u.x==k){ cout\u003c\u003cu.step\u003c\u003cendl; return ; } //三种前进方向，左右和闪现 v=u; v.x++; v.step++; if(check(v.x)){ sign[v.x]=true; q.push(v); } v=u; v.x--; v.step++; if(check(v.x)){ sign[v.x]=true; q.push(v); } v=u; v.x=2*v.x; v.step++; if(check(v.x)){ sign[v.x]=true; q.push(v); } } } int main() { cin\u003e\u003en\u003e\u003ek; memset(sign,0,sizeof(sign)); bfs(); return 0; } ","date":"2018-07-22","objectID":"/posts/poj-3278/:0:6","tags":["BFS","ACM","搜索","POJ","C++"],"title":"POJ-3278-Catch That Cow(bfs)","uri":"/posts/poj-3278/"},{"categories":["ACM"],"content":"英文原题链接 ","date":"2018-07-22","objectID":"/posts/poj-2251/:0:0","tags":["BFS","ACM","搜索","POJ","C++","C"],"title":"poj-2251-Dungeon Master（三维 bfs 最短路）","uri":"/posts/poj-2251/"},{"categories":["ACM"],"content":"Description - 题目描述 你被困在一个三维的空间中，现在要寻找最短路径逃生！ 空间由立方体单位构成 你每次向上下前后左右移动一个单位需要一分钟 你不能对角线移动并且四周封闭 是否存在逃出生天的可能性？如果存在，则需要多少时间？ ","date":"2018-07-22","objectID":"/posts/poj-2251/:0:1","tags":["BFS","ACM","搜索","POJ","C++","C"],"title":"poj-2251-Dungeon Master（三维 bfs 最短路）","uri":"/posts/poj-2251/"},{"categories":["ACM"],"content":"Input - 输入 输入第一行是一个数表示空间的数量。 每个空间的描述的第一行为 L，R 和 C（皆不超过 30）。 L 表示空间的高度。R 和 C 分别表示每层空间的行与列的大小。 随后 L 层地牢，每层 R 行，每行 C 个字符。 每个字符表示空间的一个单元。’#‘表示不可通过单元，’.‘表示空白单元。你的起始位置在’S’，出口为’E’。 每层空间后都有一个空行。L，R 和 C 均为 0 时输入结束。 ","date":"2018-07-22","objectID":"/posts/poj-2251/:0:2","tags":["BFS","ACM","搜索","POJ","C++","C"],"title":"poj-2251-Dungeon Master（三维 bfs 最短路）","uri":"/posts/poj-2251/"},{"categories":["ACM"],"content":"Output - 输出 每个空间对应一行输出。 如果可以逃生，则输出如下 Escaped in x minute(s). x 为最短脱离时间。 如果无法逃生，则输出如下 Trapped! ","date":"2018-07-22","objectID":"/posts/poj-2251/:0:3","tags":["BFS","ACM","搜索","POJ","C++","C"],"title":"poj-2251-Dungeon Master（三维 bfs 最短路）","uri":"/posts/poj-2251/"},{"categories":["ACM"],"content":"Sample Input - 输入样例 3 4 5 S.... .###. .##.. ###.# ##### ##.## ##... ##### #.### ####E 1 3 3 S## #E# ### 0 0 0 ","date":"2018-07-22","objectID":"/posts/poj-2251/:0:4","tags":["BFS","ACM","搜索","POJ","C++","C"],"title":"poj-2251-Dungeon Master（三维 bfs 最短路）","uri":"/posts/poj-2251/"},{"categories":["ACM"],"content":"Sample Output - 输出样例 Escaped in 11 minute(s). Trapped! 类似二维四个方向的 bfs 最短路，改成上下东西南北就行了，三维 bfs 最短路 #include \u003ciostream\u003e #include \u003cstdio.h\u003e #include \u003cstring.h\u003e #include \u003cqueue\u003e #include \u003calgorithm\u003e using namespace std; char map[35][35][35]; int vis[35][35][35]; int k,n,m,sx,sy,sz,ex,ey,ez; int to[6][3] = {{0,0,1},{0,0,-1},{0,1,0},{0,-1,0},{1,0,0},{-1,0,0}};//上下东西南北 struct node { int x,y,z,step; }; int check(int x,int y,int z)//检查是否可走 { if(x\u003c0 || y\u003c0 || z\u003c0 || x\u003e=k || y\u003e=n || z\u003e=m)//越界判断 return 1; else if(map[x][y][z] == '#') return 1; else if(vis[x][y][z]) return 1; return 0; } int bfs() { int i; node a,next; queue\u003cnode\u003e Q; a.x = sx,a.y = sy,a.z = sz; a.step = 0; vis[sx][sy][sz] = 1; Q.push(a); while(!Q.empty()) { a = Q.front(); Q.pop(); if(a.x == ex \u0026\u0026 a.y == ey \u0026\u0026 a.z == ez) return a.step; for(i = 0; i\u003c6; i++) { next = a; next.x = a.x+to[i][0]; next.y = a.y+to[i][1]; next.z = a.z+to[i][2]; if(check(next.x,next.y,next.z)) continue; vis[next.x][next.y][next.z] = 1; next.step = a.step+1; Q.push(next); } } return 0; } int main() { int i,j,r; while(scanf(\"%d%d%d\",\u0026k,\u0026n,\u0026m),n+m+k) { for(i = 0; i\u003ck; i++) { for(j = 0; j\u003cn; j++) { scanf(\"%s\",map[i][j]); for(r = 0; r\u003cm; r++) { if(map[i][j][r] == 'S') { sx = i,sy = j,sz = r; } else if(map[i][j][r] == 'E') { ex = i,ey = j,ez = r; } } } } memset(vis,0,sizeof(vis)); int ans; ans = bfs(); if(ans) printf(\"Escaped in %d minute(s).\\n\",ans); else printf(\"Trapped!\\n\"); } return 0; } ","date":"2018-07-22","objectID":"/posts/poj-2251/:0:5","tags":["BFS","ACM","搜索","POJ","C++","C"],"title":"poj-2251-Dungeon Master（三维 bfs 最短路）","uri":"/posts/poj-2251/"},{"categories":["ACM"],"content":"Time Limit: 1000MS Memory Limit: 10000K Total Submissions: 63659 Accepted: 30423 ","date":"2018-07-22","objectID":"/posts/poj-1321/:0:0","tags":["DFS","ACM","搜索","POJ","C++"],"title":"poj-1321 棋盘问题（dfs）","uri":"/posts/poj-1321/"},{"categories":["ACM"],"content":"Description 在一个给定形状的棋盘（形状可能是不规则的）上面摆放棋子，棋子没有区别。要求摆放时任意的两个棋子不能放在棋盘中的同一行或者同一列，请编程求解对于给定形状和大小的棋盘，摆放 k 个棋子的所有可行的摆放方案 C。 ","date":"2018-07-22","objectID":"/posts/poj-1321/:0:1","tags":["DFS","ACM","搜索","POJ","C++"],"title":"poj-1321 棋盘问题（dfs）","uri":"/posts/poj-1321/"},{"categories":["ACM"],"content":"Input 输入含有多组测试数据。 每组数据的第一行是两个正整数，n k，用一个空格隔开，表示了将在一个 n * n 的矩阵内描述棋盘，以及摆放棋子的数目。 n \u003c= 8 , k \u003c= n 当为-1 -1 时表示输入结束。 随后的 n 行描述了棋盘的形状：每行有 n 个字符，其中 # 表示棋盘区域， . 表示空白区域（数据保证不出现多余的空白行或者空白列）。 ","date":"2018-07-22","objectID":"/posts/poj-1321/:0:2","tags":["DFS","ACM","搜索","POJ","C++"],"title":"poj-1321 棋盘问题（dfs）","uri":"/posts/poj-1321/"},{"categories":["ACM"],"content":"Output 对于每一组数据，给出一行输出，输出摆放的方案数目 C （数据保证 C\u003c2^31）。 ","date":"2018-07-22","objectID":"/posts/poj-1321/:0:3","tags":["DFS","ACM","搜索","POJ","C++"],"title":"poj-1321 棋盘问题（dfs）","uri":"/posts/poj-1321/"},{"categories":["ACM"],"content":"Sample Input 2 1 #. .# 4 4 ...# ..#. .#.. #... -1 -1 ","date":"2018-07-22","objectID":"/posts/poj-1321/:0:4","tags":["DFS","ACM","搜索","POJ","C++"],"title":"poj-1321 棋盘问题（dfs）","uri":"/posts/poj-1321/"},{"categories":["ACM"],"content":"Sample Output 2 1 ","date":"2018-07-22","objectID":"/posts/poj-1321/:0:5","tags":["DFS","ACM","搜索","POJ","C++"],"title":"poj-1321 棋盘问题（dfs）","uri":"/posts/poj-1321/"},{"categories":["ACM"],"content":"Source 蔡错@pku ","date":"2018-07-22","objectID":"/posts/poj-1321/:0:6","tags":["DFS","ACM","搜索","POJ","C++"],"title":"poj-1321 棋盘问题（dfs）","uri":"/posts/poj-1321/"},{"categories":["ACM"],"content":"思路 下子方案数就相当于遍历图的不同遍历数，用 dfs 变形。 理解以下数据还有样例应该差不多了 3 2 #.. .#. ..# 3 3 2 #.. .## ..# 4 ","date":"2018-07-22","objectID":"/posts/poj-1321/:0:7","tags":["DFS","ACM","搜索","POJ","C++"],"title":"poj-1321 棋盘问题（dfs）","uri":"/posts/poj-1321/"},{"categories":["ACM"],"content":"AC 代码 #include\u003ciostream\u003e #include\u003ccstdio\u003e #include\u003ccstring\u003e #include\u003calgorithm\u003e using namespace std; char mp[8][8]; int v[8]; int n,k,w,r;//状态计数器 r void dfs(int x)//逐行深搜，x 为当前搜索行 { if(w==k)//下子数 w { r++;return; } if(x==n)return; for(int i=0;i\u003cn;i++) { if(v[i]!=1\u0026\u0026mp[x][i]=='#') { v[i]=1; w++; dfs(x+1); w--; v[i]=0; } } dfs(x+1);//搜索下一行 } int main() { while(cin\u003e\u003en\u003e\u003ek) { if(n==-1\u0026\u0026k==-1) return 0; memset(mp,0,sizeof(mp)); memset(v,0,sizeof(v)); for(int i=0;i\u003cn;i++) cin\u003e\u003emp[i]; w=0;r=0; dfs(0); cout\u003c\u003cr\u003c\u003cendl; } } 传送门 ","date":"2018-07-22","objectID":"/posts/poj-1321/:0:8","tags":["DFS","ACM","搜索","POJ","C++"],"title":"poj-1321 棋盘问题（dfs）","uri":"/posts/poj-1321/"},{"categories":["ACM"],"content":"Find The Multiple Time Limit: 1000MS Memory Limit: 10000K Total Submissions: 40713 Accepted: 17088 Special Judge ","date":"2018-07-22","objectID":"/posts/poj-1426/:1:0","tags":["DFS","ACM","搜索","POJ","C++"],"title":"poj-1426-Find The Multiple(dfs)","uri":"/posts/poj-1426/"},{"categories":["ACM"],"content":"Description Given a positive integer n, write a program to find out a nonzero multiple m of n whose decimal representation contains only the digits 0 and 1. You may assume that n is not greater than 200 and there is a corresponding m containing no more than 100 decimal digits. ","date":"2018-07-22","objectID":"/posts/poj-1426/:1:1","tags":["DFS","ACM","搜索","POJ","C++"],"title":"poj-1426-Find The Multiple(dfs)","uri":"/posts/poj-1426/"},{"categories":["ACM"],"content":"Input The input file may contain multiple test cases. Each line contains a value of n (1 \u003c= n \u003c= 200). A line containing a zero terminates the input. ","date":"2018-07-22","objectID":"/posts/poj-1426/:1:2","tags":["DFS","ACM","搜索","POJ","C++"],"title":"poj-1426-Find The Multiple(dfs)","uri":"/posts/poj-1426/"},{"categories":["ACM"],"content":"Output For each value of n in the input print a line containing the corresponding value of m. The decimal representation of m must not contain more than 100 digits. If there are multiple solutions for a given value of n, any one of them is acceptable. ","date":"2018-07-22","objectID":"/posts/poj-1426/:1:3","tags":["DFS","ACM","搜索","POJ","C++"],"title":"poj-1426-Find The Multiple(dfs)","uri":"/posts/poj-1426/"},{"categories":["ACM"],"content":"Sample Input 2 6 19 0 ","date":"2018-07-22","objectID":"/posts/poj-1426/:1:4","tags":["DFS","ACM","搜索","POJ","C++"],"title":"poj-1426-Find The Multiple(dfs)","uri":"/posts/poj-1426/"},{"categories":["ACM"],"content":"Sample Output 10 100100100100100100 111111111111111111 给定一个正整数 n，请编写一个程序来寻找 n 的一个非零的倍数 m，这个 m 应当在十进制表示时每一位上只包含 0 或者 1。你可以假定 n 不大于 200 且 m 不多于 100 位。 提示：本题采用 Special Judge，你无需输出所有符合条件的 m，你只需要输出任一符合条件的 m 即可。 #include\"iostream\" using namespace std; typedef unsigned long long ll; int n; bool sign; void dfs(ll x,int count) { if(sign) return ; if(x%n==0){ sign=true; cout\u003c\u003cx\u003c\u003cendl; return ; } if(count==19)//m 最多 200 位 return ; dfs(x*10,count+1); dfs(x*10+1,count+1); //每两位数后两位有两种情况，10 或 11，深搜所有情况，找到一种就返回，找不到找另外一颗子树 } int main() { while(cin\u003e\u003en\u0026\u0026n) { sign=false; dfs(1,0); } return 0; } ","date":"2018-07-22","objectID":"/posts/poj-1426/:1:5","tags":["DFS","ACM","搜索","POJ","C++"],"title":"poj-1426-Find The Multiple(dfs)","uri":"/posts/poj-1426/"},{"categories":["ACM"],"content":"Codeforces Round 498 (Div. 3) A. Adjacent Replacements（水）","date":"2018-07-22","objectID":"/posts/adjacent-replacements/","tags":["Codeforces","ACM","C++"],"title":"Adjacent Replacements","uri":"/posts/adjacent-replacements/"},{"categories":["ACM"],"content":"A. Adjacent Replacements 第一次打 cf 就做出一道这样的找规律的题，打到自闭。 #include\u003cbits/stdc++.h\u003e using namespace std; int main(){ int n,a[1001]; cin\u003e\u003en; int i; int flag=0; for(i=0;i\u003cn;i++){ cin\u003e\u003ea[i]; if(!(a[i]\u00261)) a[i]--; if(!flag) {cout\u003c\u003ca[i];flag=1;} else cout\u003c\u003c\" \"\u003c\u003ca[i]; } return 0; } ","date":"2018-07-22","objectID":"/posts/adjacent-replacements/:0:0","tags":["Codeforces","ACM","C++"],"title":"Adjacent Replacements","uri":"/posts/adjacent-replacements/"},{"categories":["ACM"],"content":"迷宫问题 Time Limit: 1000MS Memory Limit: 65536K Total Submissions: 32323 Accepted: 18471 ","date":"2018-07-22","objectID":"/posts/poj-3984/:0:1","tags":["BFS","ACM","POJ","C++","C"],"title":"poj-3984-迷宫问题 (bfs 路径）","uri":"/posts/poj-3984/"},{"categories":["ACM"],"content":"Description 定义一个二维数组： int maze[5][5] = { 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, }; 它表示一个迷宫，其中的 1 表示墙壁，0 表示可以走的路，只能横着走或竖着走，不能斜着走，要求编程序找出从左上角到右下角的最短路线。 ","date":"2018-07-22","objectID":"/posts/poj-3984/:0:2","tags":["BFS","ACM","POJ","C++","C"],"title":"poj-3984-迷宫问题 (bfs 路径）","uri":"/posts/poj-3984/"},{"categories":["ACM"],"content":"Input 一个 5 × 5 的二维数组，表示一个迷宫。数据保证有唯一解。 ","date":"2018-07-22","objectID":"/posts/poj-3984/:0:3","tags":["BFS","ACM","POJ","C++","C"],"title":"poj-3984-迷宫问题 (bfs 路径）","uri":"/posts/poj-3984/"},{"categories":["ACM"],"content":"Output 左上角到右下角的最短路径，格式如样例所示。 ","date":"2018-07-22","objectID":"/posts/poj-3984/:0:4","tags":["BFS","ACM","POJ","C++","C"],"title":"poj-3984-迷宫问题 (bfs 路径）","uri":"/posts/poj-3984/"},{"categories":["ACM"],"content":"Sample Input 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 ","date":"2018-07-22","objectID":"/posts/poj-3984/:0:5","tags":["BFS","ACM","POJ","C++","C"],"title":"poj-3984-迷宫问题 (bfs 路径）","uri":"/posts/poj-3984/"},{"categories":["ACM"],"content":"Sample Output (0, 0) (1, 0) (2, 0) (2, 1) (2, 2) (2, 3) (2, 4) (3, 4) (4, 4) 对于新手来说，主要是 bfs 路径的问题有点难度，搞得晕晕的。 #include\u003ciostream\u003e #include\u003ccstring\u003e using namespace std; int map[5][5]; int visited[5][5]; int dx[4]={0, 1, 0, -1}; int dy[4]={ 1, 0,-1, 0}; int head,tail; struct node{ int xx,yy; int fa;//父节点 }pre[25],way[25]; void BFS(int x,int y) { int x1,y1; head=0,tail=1; visited[x][y]=1; pre[0].xx=x,pre[0].yy=y; while(tail\u003ehead)//栈空 { x=pre[head].xx; y=pre[head].yy; if(x==4\u0026\u0026y==4)//结束标志 return ; for(int i=0;i\u003c4;i++) { x1=x+dx[i];y1=y+dy[i]; if(x1\u003e=0\u0026\u0026x1\u003c=4\u0026\u0026y1\u003e=0\u0026\u0026y1\u003c=4) if(map[x1][y1]==0\u0026\u0026!visited[x1][y1]) { pre[tail].xx=x1; pre[tail].yy=y1; pre[tail].fa=head; visited[x1][y1]=1; tail+=1;//入栈 } } head++;//相当于出栈 } } int main() { int i,j; ios::sync_with_stdio(false); memset(map,0,sizeof(map)); memset(visited,0,sizeof(visited)); for(i=0;i\u003c5;i++) for(j=0;j\u003c5;j++) cin\u003e\u003emap[i][j]; BFS(0,0); i=0; while(head)//逆序进行赋值输出就是通路 { way[i].xx=pre[head].xx; way[i].yy=pre[head].yy; head=pre[head].fa; i++; } //画一下队列 way[i].xx=0;way[i].yy=0; while(i!=-1) { cout\u003c\u003c\"(\"\u003c\u003cway[i].xx\u003c\u003c\", \"\u003c\u003cway[i].yy\u003c\u003c\")\"\u003c\u003cendl; i--; } return 0; } ","date":"2018-07-22","objectID":"/posts/poj-3984/:0:6","tags":["BFS","ACM","POJ","C++","C"],"title":"poj-3984-迷宫问题 (bfs 路径）","uri":"/posts/poj-3984/"},{"categories":["ACM"],"content":"链接：https://www.nowcoder.com/acm/contest/133/A 来源：牛客网 ","date":"2018-07-22","objectID":"/posts/wannafly-20/:0:0","tags":["ACM","Nowcoder","C++","C"],"title":"Wannafly 挑战赛 20-染色","uri":"/posts/wannafly-20/"},{"categories":["ACM"],"content":"题目描述 现在有一棵被 Samsara-Karma 染了 k 种颜色的树，每种颜色有着不同的价值，Applese 觉得 Samsara-Karma 染的太难看了，于是打算把整棵树重新染成同一种颜色，但是，由于一些奥妙重重的原因，每一次染色 Applese 可以选择两个有边相连的点，将其中一个染成另一个的颜色。而进行一次这样的操作需要付出两种颜色价值和的代价， 现在，Applese 的钱要用来买书 (game)，所以他想要最小化代价 ","date":"2018-07-22","objectID":"/posts/wannafly-20/:0:1","tags":["ACM","Nowcoder","C++","C"],"title":"Wannafly 挑战赛 20-染色","uri":"/posts/wannafly-20/"},{"categories":["ACM"],"content":"输入描述： 输入包括若干行第一行包括一个数 n，表示这棵树有 n 个节点第二行包括 n 个数，第 i 个数表示第 i 个节点的颜色 coli 注意：一个颜色的标号即价值接下来的 n - 1 行，每行包括两个数 u, v，表示 u 节点与 v 节点之间有一条无向边 n ≤ 100000, 1 ≤ coli ≤ 1e9，数据保证是一棵树 ","date":"2018-07-22","objectID":"/posts/wannafly-20/:0:2","tags":["ACM","Nowcoder","C++","C"],"title":"Wannafly 挑战赛 20-染色","uri":"/posts/wannafly-20/"},{"categories":["ACM"],"content":"输出描述： 输出包括一行第一行包括一个数，表示最小代价 ","date":"2018-07-22","objectID":"/posts/wannafly-20/:0:3","tags":["ACM","Nowcoder","C++","C"],"title":"Wannafly 挑战赛 20-染色","uri":"/posts/wannafly-20/"},{"categories":["ACM"],"content":"示例 1 输入 4 2 3 4 3 1 2 2 3 3 4 输出 12 蒟蒻暴力枚举-_-! #include \u003cbits/stdc++.h\u003e using namespace std; const int MAXN=1e5+10; int a[MAXN]; map\u003cint, int \u003ema; set\u003cint\u003ese; int x[MAXN],y[MAXN]; int main() { int n; scanf(\"%d\",\u0026n); for (int i = 1; i \u003c=n ; ++i) { scanf(\"%d\",\u0026a[i]); se.insert(a[i]); } for (int i = 1; i \u003cn ; ++i) { scanf(\"%d%d\",\u0026x[i],\u0026y[i]); } long long ans=1e14,sum=0; set\u003cint\u003e::iterator it; for (it=se.begin(); it !=se.end() ; ++it) { sum=0; for (int j = 1; j \u003c=n ; ++j) { if((*it)!=a[j]) sum+=((*it)+a[j]); } ans=min(sum,ans); } printf(\"%lld\\n\",ans); return 0; } 最后想说这都过了什么鬼，不会数据这么弱吧？？！? 我只枚举了最小的价值颜色的情况，唉，不管了不管了。 #include\u003cbits/stdc++.h\u003e using namespace std; int a[1000000],n,m,k=1,t,ans=0; int main() { scanf(\"%d\",\u0026n); for(int i=1;i\u003c=n;++i) scanf(\"%d\",\u0026a[i]); sort(a+1,a+n+1); for(int i=2;i\u003c=n;++i) if(a[i]!=a[1]) ans+=a[i]+a[1]; printf(\"%d\",ans); return 0; } ","date":"2018-07-22","objectID":"/posts/wannafly-20/:0:4","tags":["ACM","Nowcoder","C++","C"],"title":"Wannafly 挑战赛 20-染色","uri":"/posts/wannafly-20/"},{"categories":["ACM"],"content":"Oil Deposits 翻译 Time Limit: 2000/1000 MS (Java/Others) Memory Limit: 65536/32768 K (Java/Others) Total Submission(s): 41406 Accepted Submission(s): 23977 Problem Description The GeoSurvComp geologic survey company is responsible for detecting underground oil deposits. GeoSurvComp works with one large rectangular region of land at a time, and creates a grid that divides the land into numerous square plots. It then analyzes each plot separately, using sensing equipment to determine whether or not the plot contains oil. A plot containing oil is called a pocket. If two pockets are adjacent, then they are part of the same oil deposit. Oil deposits can be quite large and may contain numerous pockets. Your job is to determine how many different oil deposits are contained in a grid. Input The input file contains one or more grids. Each grid begins with a line containing m and n, the number of rows and columns in the grid, separated by a single space. If m = 0 it signals the end of the input; otherwise 1 \u003c= m \u003c= 100 and 1 \u003c= n \u003c= 100. Following this are m lines of n characters each (not counting the end-of-line characters). Each character corresponds to one plot, and is either ’ * ‘, representing the absence of oil, or ‘@’, representing an oil pocket. Output For each grid, output the number of distinct oil deposits. Two different pockets are part of the same oil deposit if they are adjacent horizontally, vertically, or diagonally. An oil deposit will not contain more than 100 pockets. Sample Input 1 1 * 3 5 *@*@* **@** *@*@* 1 8 @@****@* 5 5 ****@ *@@*@ *@**@ @@@*@ @@**@ 0 0 Sample Output 0 1 2 Source Mid-Central USA 1997 Recommend Eddy | We have carefully selected several similar problems for you: 1016 1010 1312 1242 1240 思路 dfs 模板题吧，八个方向搜索；（像 i，j 这样的计数器还是写在局部比较好，我尽然被定义域的问题搞了一晚上醉了醉了。） #include\u003cbits/stdc++.h\u003e using namespace std; int n,m,s; char maze[107][107]; int vx[8]={-1,1,0,0,-1,-1,1,1}; int vy[8]={0,0,-1,1,-1,1,1,-1}; void dfs(int x,int y){ maze[x][y]='*'; for(int i=0;i\u003c8;i++){ int tx=x+vx[i]; int ty=y+vy[i]; if(tx\u003e=0\u0026\u0026tx\u003cm\u0026\u0026ty\u003e=0\u0026\u0026ty\u003cn\u0026\u0026maze[tx][ty]=='@') dfs(tx,ty); } } int main(){ int i,j; while(cin\u003e\u003em\u003e\u003en\u0026\u0026m){ s=0; for(i=0;i\u003cm;i++) cin\u003e\u003emaze[i]; for(i=0;i\u003cm;i++){//相当于不连通的情况 for(j=0;j\u003cn;j++){ if(maze[i][j]=='@'){ dfs(i,j); s++; } } } cout\u003c\u003cs\u003c\u003cendl; } return 0; } ","date":"2018-07-22","objectID":"/posts/hdu-1241/:1:0","tags":["DFS","搜索","HDU","ACM","C++"],"title":"hdu-1241-Oil Deposits (dfs)","uri":"/posts/hdu-1241/"},{"categories":["ACM"],"content":"假设有一个 n 行 m 列的迷宫，每个单位要么是空地（用 1 表示）要么是障碍物（用 0 表示）. 如何找到从起点到终点的最短路径？利用 BFS 搜索，逐步计算出每个节点到起点的最短距离， 以及最短路径每个节点的前一个节点。最终将生成一颗以起点为根的 BFS 树。此时 BFS 可以求出任意一点到起点的距离。 ","date":"2018-07-22","objectID":"/posts/bfs%E6%B1%82%E6%9C%80%E7%9F%AD%E8%B7%AF/:0:0","tags":["BFS","搜索","C++"],"title":"BFS 求最短路","uri":"/posts/bfs%E6%B1%82%E6%9C%80%E7%9F%AD%E8%B7%AF/"},{"categories":["ACM"],"content":"图 1 3 0 21 23 2 0 17 20 22 4 0 14 0 0 5 0 12 15 18 6 8 10 0 19 7 9 11 13 16 ","date":"2018-07-22","objectID":"/posts/bfs%E6%B1%82%E6%9C%80%E7%9F%AD%E8%B7%AF/:1:0","tags":["BFS","搜索","C++"],"title":"BFS 求最短路","uri":"/posts/bfs%E6%B1%82%E6%9C%80%E7%9F%AD%E8%B7%AF/"},{"categories":["ACM"],"content":"输入 6 5 1 1 0 1 1 1 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 ","date":"2018-07-22","objectID":"/posts/bfs%E6%B1%82%E6%9C%80%E7%9F%AD%E8%B7%AF/:2:0","tags":["BFS","搜索","C++"],"title":"BFS 求最短路","uri":"/posts/bfs%E6%B1%82%E6%9C%80%E7%9F%AD%E8%B7%AF/"},{"categories":["ACM"],"content":"输出 1 2 4 5 6 8 10 12 14 17 20 21 23 12//最短距离 ","date":"2018-07-22","objectID":"/posts/bfs%E6%B1%82%E6%9C%80%E7%9F%AD%E8%B7%AF/:3:0","tags":["BFS","搜索","C++"],"title":"BFS 求最短路","uri":"/posts/bfs%E6%B1%82%E6%9C%80%E7%9F%AD%E8%B7%AF/"},{"categories":["ACM"],"content":"代码 #include\u003ciostream\u003e #include\u003cqueue\u003e #include\u003ccstdio\u003e #include\u003ccstring\u003e #include\u003cvector\u003e using namespace std; const int maxn=100+5; int G[maxn][maxn]; //存图的 d=id int path[maxn]; //存每个节点的父节点，即路径 int n,m; //n 行 m 列 int k=1;//记录编号 int end_num; int vx[5] = {-1,1,0,0}; //vx vy 用来计算一个节点周围上下左右 4 个节点 int vy[5] = {0,0,-1,1}; bool vis[maxn][maxn]; //判断某节点是否已经被访问过 struct node { int x; int y; int id; int parent=0; node(int a,int b,int c) { x=a; y=b; id=c; } }; int main() { //freopen(\"in.txt\",\"r\",stdin); memset(G,0,sizeof(G)); memset(vis,0,sizeof(vis)); memset(path,0,sizeof(path)); cin\u003e\u003en\u003e\u003em; for(int i=1; i\u003c=n; i++) for(int j=1; j\u003c=m; j++) { cin\u003e\u003eG[i][j]; } queue\u003cnode\u003e q; node v=node(1,1,1); q.push(v); vis[1][1]=1; while(!q.empty()) { node u=q.front(); q.pop(); path[u.id]=u.parent;//记录每个点的父节点 for(int i=0; i\u003c4; i++) { int tx=u.x+vx[i]; int ty=u.y+vy[i]; if(G[tx][ty]\u0026\u0026!vis[tx][ty])//有路可走且未访问 { vis[tx][ty]=1; //cout\u003c\u003ctx\u003c\u003cty\u003c\u003cendl; node v=node(tx,ty,++k); end_num=k; v.parent=u.id; q.push(v); } } } vector\u003cint\u003e ans; //cout\u003c\u003cend_num\u003c\u003cendl; while(end_num)//从后面开始找父亲节点 { ans.push_back(end_num); end_num=path[end_num]; } int s=0; while(!ans.empty()) { s++; cout\u003c\u003c*(ans.end()-1)\u003c\u003c' ';//ans 最后一个元素是 0 ans.pop_back(); } cout\u003c\u003cendl\u003c\u003cs-1; return 0; } ","date":"2018-07-22","objectID":"/posts/bfs%E6%B1%82%E6%9C%80%E7%9F%AD%E8%B7%AF/:4:0","tags":["BFS","搜索","C++"],"title":"BFS 求最短路","uri":"/posts/bfs%E6%B1%82%E6%9C%80%E7%9F%AD%E8%B7%AF/"},{"categories":["ACM"],"content":"那天晚上报名了没打，第二天早上打的，也只出了两题。 ","date":"2018-07-22","objectID":"/posts/cf-1009/:0:0","tags":["Codeforces","ACM","C++","C"],"title":"Educational Codeforces Round 47 (Rated for Div. 2)","uri":"/posts/cf-1009/"},{"categories":["ACM"],"content":"A. Game Shopping #include\u003ciostream\u003e using namespace std; int main(){ int n,m,s=0; cin\u003e\u003en\u003e\u003em; int i,j; int c[1000],a[1000]; for(i=0;i\u003cn;i++) cin\u003e\u003ec[i]; for(i=0;i\u003cm;i++) cin\u003e\u003ea[i]; for(i=0,j=0;i\u003cn;){ if(j==m) break; if(c[i]\u003c=a[j]){ s++; j++; i++; } else i++; } if(i==n\u0026\u0026s==0) cout\u003c\u003c\"0\\n\"; else cout\u003c\u003cs\u003c\u003cendl; return 0; } ","date":"2018-07-22","objectID":"/posts/cf-1009/:1:0","tags":["Codeforces","ACM","C++","C"],"title":"Educational Codeforces Round 47 (Rated for Div. 2)","uri":"/posts/cf-1009/"},{"categories":["ACM"],"content":"B. Minimum Ternary String #include \u003cbits/stdc++.h\u003e using namespace std; string s, ans; int main(){ cin \u003e\u003e s; int one = 0; for (int i = 0; i \u003c s.size(); i++){ if (s[i] == '0') ans += \"0\"; if (s[i] == '1') one++; if (s[i] == '2') ans += \"2\"; } bool flag = false; for (int i = 0; i \u003c ans.size(); i++){ if (ans[i] == '2' \u0026\u0026 !flag) flag = true, cout \u003c\u003c string(one, '1'); cout \u003c\u003c ans[i]; } if (!flag) cout \u003c\u003c string(one, '1'); return 0; } /* 100210 11222121 20 2001 020201 2012101 111 000 */ ","date":"2018-07-22","objectID":"/posts/cf-1009/:2:0","tags":["Codeforces","ACM","C++","C"],"title":"Educational Codeforces Round 47 (Rated for Div. 2)","uri":"/posts/cf-1009/"},{"categories":["ACM"],"content":" 2018 年全国多校算法寒假训练营练习比赛（第二场）B(0 1 背包变化 特殊处理一个物品） 链接：https://www.nowcoder.com/acm/contest/74/B 来源：牛客网 ","date":"2018-07-22","objectID":"/posts/taotao%E8%A6%81%E5%90%83%E9%B8%A1/:0:0","tags":["背包问题","Nowcoder","C++"],"title":"TaoTao 要吃鸡","uri":"/posts/taotao%E8%A6%81%E5%90%83%E9%B8%A1/"},{"categories":["ACM"],"content":"题目描述 Taotao 的电脑带不动绝地求生，所以 taotao 只能去玩 pc 版的荒野行动了， 和绝地求生一样，游戏人物本身可以携带一定重量 m 的物品，装备背包 之后可以多携带 h（h 为 0 代表没有装备背包）重量的东西。玩了几天 taotao 发现了一个 BUG，当装备背包之后，如果可携带重量没有满，就 可以拿一个任意重的东西。（解释看样例）有一天 taotao 空降到了一个 奇怪的岛上，岛上有 n 件装备，每个装备都有重量 Wi 和威力值 Vi, 但 taotao 不认识这些装备，所以他来求助你，挑选威力最大的装备，帮助他吃鸡。 ","date":"2018-07-22","objectID":"/posts/taotao%E8%A6%81%E5%90%83%E9%B8%A1/:0:1","tags":["背包问题","Nowcoder","C++"],"title":"TaoTao 要吃鸡","uri":"/posts/taotao%E8%A6%81%E5%90%83%E9%B8%A1/"},{"categories":["ACM"],"content":"输入描述： 本题有多组输入（小于 10），当 n=0 时结束输入。第一行输入 n,m,h。n，m，h 为整数，并且 0\u003c=n,m,h\u003c=100，接下来 n 行，每行输入第 i 个物品的物品的重量 Wi 和威力值 Vi。0\u003c=Wi,Vi\u003c=100. ","date":"2018-07-22","objectID":"/posts/taotao%E8%A6%81%E5%90%83%E9%B8%A1/:0:2","tags":["背包问题","Nowcoder","C++"],"title":"TaoTao 要吃鸡","uri":"/posts/taotao%E8%A6%81%E5%90%83%E9%B8%A1/"},{"categories":["ACM"],"content":"输出描述： 输出最大威力值，每组输出一行。 ","date":"2018-07-22","objectID":"/posts/taotao%E8%A6%81%E5%90%83%E9%B8%A1/:0:3","tags":["背包问题","Nowcoder","C++"],"title":"TaoTao 要吃鸡","uri":"/posts/taotao%E8%A6%81%E5%90%83%E9%B8%A1/"},{"categories":["ACM"],"content":"示例 1 输入 3 3 3 2 3 3 2 2 3 0 输出 8 ","date":"2018-07-22","objectID":"/posts/taotao%E8%A6%81%E5%90%83%E9%B8%A1/:0:4","tags":["背包问题","Nowcoder","C++"],"title":"TaoTao 要吃鸡","uri":"/posts/taotao%E8%A6%81%E5%90%83%E9%B8%A1/"},{"categories":["ACM"],"content":"说明 可携带的总重量为 6，当拿了前两件装备，此时容量为 5/6，还可以再拿第三件物品。 思路：0-1 背包的变形题目，h=0 的时候为背包的模板，h！=0 的时候枚举每一个需要特殊处理的物品再背包 #include \u003cbits/stdc++.h\u003e using namespace std; int v[105]; int w[105]; int n,m,h; int dp[205]; int main() { while(scanf(\"%d\",\u0026n)==1\u0026\u0026n!=0){ int sum=0; scanf(\"%d%d\",\u0026m,\u0026h); for(int i=1;i\u003c=n;i++) scanf(\"%d%d\",\u0026w[i],\u0026v[i]); if(h==0){ memset(dp,0,sizeof(dp)); for(int i=1;i\u003c=n;i++) //前 i 个物品 for(int j=m;j\u003e=w[i];j--) //枚举背包重量 dp[j]=max(dp[j],dp[j-w[i]]+v[i]); // sum=dp[m]; } else{ m+=h for(int k=1;k\u003c=n;k++) //枚举可以被剩下的物品 { memset(dp,0,sizeof(dp)); for(int i=1;i\u003c=n;i++){ //前 i 个物品 if(i!=k){ for(int j=m;j\u003e=w[i];j--) //枚举背包重量 dp[j]=max(dp[j],dp[j-w[i]]+v[i]); } } //留下来一个重量，即初始化威力为那个重量的威力 for(int j=m-1;j\u003e=m-w[k];j--) //枚举背包重量+剩下物品 dp[m]=max(dp[m],dp[j]+v[k]); // printf(\"%d\\n\",dp[m]); sum=max(sum,dp[m]); } } printf(\"%d\\n\",sum); } return 0; } ","date":"2018-07-22","objectID":"/posts/taotao%E8%A6%81%E5%90%83%E9%B8%A1/:0:5","tags":["背包问题","Nowcoder","C++"],"title":"TaoTao 要吃鸡","uri":"/posts/taotao%E8%A6%81%E5%90%83%E9%B8%A1/"},{"categories":["ACM"],"content":"百度知道 1 1 1 1 2 1 1 3 3 1 1 4 6 4 1 1 5 10 10 5 1 1 6 15 20 15 6 1 1、每行数字左右对称，由 1 开始逐渐变大，然后变小，回到 1。 2、第 n 行的数字个数为 n 个。 3、第 n 行数字和为 2^(n－1)。 4、每个数字等于上一行的左右两个数字之和。可用此性质写出整个帕斯卡三角形。 5、将第 2n+1 行第 1 个数，跟第 2n+2 行第 3 个数、第 2n+3 行第 5 个数……连成一线，这些数的和是第 2n 个斐波那契数。将第 2n 行第 2 个数，跟第 2n+1 行第 4 个数、第 2n+2 行第 6 个数……这些数之和是第 2n-1 个斐波那契数。 6、第 n 行的第 1 个数为 1，第二个数为 1×(n-1)，第三个数为 1×(n-1)×（n-2）/2，第四个数为 1×(n-1)×（n-2）/2×（n-3）/3…依此类推。 此数列中各行中的数字正好是二项式 a+b 乘方后，展开始终各项的系数。如： (a+b)^1=a^1+b^1 (a+b)^2=a^2+2ab+b^2 (a+b)^3=a^3+3a^2b+3ab^2+b^3 …… (a+b)^6=a^6+6a^5b+15a^4b^2+20a^3b^3+15a^2b^4+6ab^5+b^6（注意发现规律） …… 二项式展开式： ","date":"2018-07-22","objectID":"/posts/%E6%9D%A8%E8%BE%89%E4%B8%89%E8%A7%92/:0:0","tags":["数学","杨辉三角"],"title":"杨辉三角","uri":"/posts/%E6%9D%A8%E8%BE%89%E4%B8%89%E8%A7%92/"},{"categories":["ACM"],"content":"广度优先搜索（BFS） 广度优先搜索在进一步遍历图中顶点之前，先访问当前顶点的所有邻接结点。访问了就入队。 ","date":"2018-07-22","objectID":"/posts/dfs_bfs/:0:1","tags":["ACM","BFS","DFS","搜索","C","C++"],"title":"深搜广搜","uri":"/posts/dfs_bfs/"},{"categories":["ACM"],"content":"深度优先搜索（DFS） 深度优先搜索在搜索过程中访问某个顶点后，需要递归地访问此顶点的所有未访问过的相邻顶点。 #include \u003cbits/stdc++.h\u003e #define N 5 using namespace std; int maze[N][N] = {//无权有向图邻接矩阵 { 0, 1, 0, 1, 0 }, { 0, 0, 1, 0, 0 }, { 0, 0, 0, 0, 1 }, { 0, 0, 1, 0, 0 }, { 0, 0, 0, 0, 0 } }; int visited[N]; void DFS(int start) { cout \u003c\u003c start\u003c\u003c \" \"; visited[start] = 1; for (int i = 0; i \u003c N; i++) { if (!visited[i] \u0026\u0026 maze[start][i] == 1)//没访问过且为邻居节点 DFS(i); } } void BFS(int start){ queue\u003cint\u003e Q;//队列 Q.push(start); visited[start] = 1; while (!Q.empty()) { int front = Q.front();//头 cout \u003c\u003c front \u003c\u003c \" \"; Q.pop(); for (int i = 0; i \u003cN; i++) { if (!visited[i] \u0026\u0026 maze[front][i] == 1) { visited[i] = 1; Q.push(i); } } } } int main() { memset(visited,0,sizeof(visited)); for (int i = 0; i \u003c N; i++)//不连通的情况 { if (visited[i] == 1)//访问过 continue; DFS(i); } cout\u003c\u003cendl; memset(visited,0,sizeof(visited)); for (int i = 0; i \u003c N; i++)//不连通的情况 { if (visited[i] == 1)//访问过 continue; BFS(i); } return 0; } 传送门 ","date":"2018-07-22","objectID":"/posts/dfs_bfs/:0:2","tags":["ACM","BFS","DFS","搜索","C","C++"],"title":"深搜广搜","uri":"/posts/dfs_bfs/"},{"categories":["ACM"],"content":"时间限制：C/C++ 1 秒，其他语言 2 秒 空间限制：C/C++ 262144K，其他语言 524288K 64bit IO Format: %lld 题目描述 有一个长度为 n 的序列 a，已知 a[1]=a[n]=1，且对于 2 \u003c= x \u003c= n，a[x] / a[x-1] 是以下三个数字之一 [ 1，-2，0.5 ], 问有多少种不同的序列满足题意。 两个序列不同当且仅当它们有至少一个位置上的数字不同，序列 a 可以为任何实数。 输入描述： 一个整数 表示 n (1\u003c= n \u003c= 1e3) 输出描述： 一个整数 表示答案模 109+7 示例 1 输入 5 输出 7 解题思路： 整体来看，a[x] = a[x-1] _ [1, -2, 0.5]，那么等于从 n-1 个 [1,-2,0.5] 中选出 n-1 个数值相乘（a[x-1]=a[x-2] _ [1,-2,0.5] 同理化简式子）， 最后答案要是 1，所以-2 就必须有偶数个，同理 0.5 的个数要等于-2. 顺序无关。 那所有的转换中，就只要保证有若干组 (-2,-2,0.5,0.5) 存在 表示偶数个 2 的个数与偶数个 0.5 的个数组合；组合数用二项式系数，杨辉三角来求。 #include \u003cbits/stdc++.h\u003e using namespace std; const int maxn = 1e3 + 5; const int mod = 1e9 + 7; long long c[maxn][maxn]; int main(){ for(int i = 0; i \u003c maxn; i++){//杨辉三角 c[i][0] = 1; c[i][i] = 1; for(int j = 1; j \u003c i; j++) c[i][j] = (c[i-1][j] + c[i-1][j-1]) % mod; } int n; while(~scanf(\"%d\", \u0026n)){ n--; long long ans = 0; for(int i = 0; i*2 \u003c= n; i += 2){ ans = (ans%mod + (c[n][i]*c[n-i][i])%mod)%mod; } printf(\"%lld\\n\", ans); } return 0; } ","date":"2018-07-18","objectID":"/posts/wannafly-18/:0:0","tags":["组合数学","ACM","Nowcoder","C++","C"],"title":"Wannafly 挑战赛 18-序列","uri":"/posts/wannafly-18/"},{"categories":["ACM"],"content":"弱鸡还是弱鸡啊最简单的背包问题——。——！ ","date":"2018-06-16","objectID":"/posts/%E7%AE%80%E5%8D%95%E8%83%8C%E5%8C%85/:0:0","tags":["背包问题","C"],"title":"简单背包","uri":"/posts/%E7%AE%80%E5%8D%95%E8%83%8C%E5%8C%85/"},{"categories":["ACM"],"content":"1) 问题描述： 假设有一个能装入总体积为 T 的背包和 n 件体积分别为 W1，W2，···，Wn 的物品，能否从 n 件物品中挑选若干件恰好装满背包，即使 W1+W2+···+Wn=T，要求找出所有满足上述条件的解。例如：当 T=10，共 6 件物品，物品的体积为{1，2，3，4，5，8}，那么可找到下列 4 组解：（1，2，3，4）、（1，4，5）、（2，3，5）、（2、8）。 ","date":"2018-06-16","objectID":"/posts/%E7%AE%80%E5%8D%95%E8%83%8C%E5%8C%85/:1:0","tags":["背包问题","C"],"title":"简单背包","uri":"/posts/%E7%AE%80%E5%8D%95%E8%83%8C%E5%8C%85/"},{"categories":["ACM"],"content":"2) 实现提示： 可利用回溯法的设计思想来解决背包问题。首先，将物品排成一列，然后顺序选取物品装入背包，假设已选取了前 i 件物品之后背包还没有装满，则继续选取第 i+1 件物品，若该件物品“太大”不能装入，则丢弃而继续选取下一件，直至背包装满为止。但如果在剩余的物品中找不到合适的物品以填满背包，则说明“刚刚”装入背包的那件物品“不合适”，应将它取出“丢弃一边”，继续再从“它之后”的物品中选取，如此重复，直至求得满足条件的解，或者无解。由于回溯求解的规则是“后进先出”，因此要用到栈。 使用栈作为该程序的数据结构，利用栈进行语法检查，以深度优先的搜索方式解空间，实现递归过程和函数的调用，在设计时还使用 C 语言的数组及其循环语言来实现程序。 运用回溯法解题，在搜索解空间树时，只要其左儿子节点是一个可行结点，搜索就进入左子树，在右子树中有可能包含最优解是才进入右子树搜索。否则将右子树剪去。 #include \u003cstdio.h\u003e #include \u003cwindows.h\u003e #define size 50 struct stacks { int data[size]; int top; } stack; void backpack(int number,int V,int w[]){ int i,j=1,k=0; int flag=0; do { while (V \u003e 0 \u0026\u0026 k \u003c= number) { if (V \u003e= w[k]) { stack.data[stack.top] = k;//第 k 个物品的体积下标 stack.top++; V -= w[k]; } k++; } if (V == 0) { flag=1; printf(\"第%d 个符合条件的解：\", j); for (i = 0; i \u003c stack.top; i++) { printf(\"%d \", w[stack.data[i]]); } j++; printf(\"\\n\"); } //k 满时回溯 k = stack.data[--stack.top]; stack.data[stack.top] = 0; V += w[k]; k++; } while (!(stack.top == 0 \u0026\u0026 k == number)); if(!flag){ printf(\"背包无解！\\n\"); } } void judge(int number,int V,int w[]){ int i,s = 0; for (i = 0; i \u003c number; i++) s = s + w[i]; if(V \u003e s){ printf(\"背包无解！\\n\"); exit(0); } if(V==s){ printf(\"只有一个符合条件的解：%d\\n\", V); exit(0); } } int main() { int w[size]; int V; int i = 0; int j = 0; int number; printf(\"\\t **简单背包问题**\\n\\n\"); printf(\"\\n 请输入可供选择装入物品的个数：\\n\"); scanf(\"%d\", \u0026number); printf(\"\\n 请输入各件物品的体积：\\n\"); for (i = 0; i \u003c number; i++) scanf(\"%d\", \u0026w[i]); //排序 for(i=0;i\u003cnumber;i++) for(j=i+1;j\u003cnumber;j++) if(w[i]\u003ew[j]){ w[i]=w[i]^w[j]; w[j]=w[i]^w[j]; w[i]=w[i]^w[j]; } printf(\"\\n 请输入背包的总体积：\\n\"); scanf(\"%d\", \u0026V); while(V \u003c 0){ printf(\"输入背包体积错误！重新输入！\\n\"); scanf(\"%d\",\u0026V); } judge(number,V,w); //初始化栈 for (i = 0; i \u003c number; i++) stack.data[i] = 0; stack.top = 0; backpack(number,V,w); return 0; } --这么简单的问题我都费力，太辣鸡了 ","date":"2018-06-16","objectID":"/posts/%E7%AE%80%E5%8D%95%E8%83%8C%E5%8C%85/:2:0","tags":["背包问题","C"],"title":"简单背包","uri":"/posts/%E7%AE%80%E5%8D%95%E8%83%8C%E5%8C%85/"},{"categories":["ACM"],"content":" 来自一位大佬的演讲 尊敬的领导、教练，亲爱的参赛选手们： 大家好，我是来自广东工业大学的 tmk。今天很荣幸能够站在这里代表全体参赛选手发言，与大家分享我的经历和感受。 刚开始来到大学的时候，我一心向学，本着“好好学习，天天向上，为校争光，不搞对象”的信念，想在大学一展宏图。因为高中 OI 的挫败，我在刚上大学的时候就选择了 ACM 这条“不归路”。一开始是因为高中的遗憾，到后来就完全是因为信念和兴趣慢慢一直搞到现在。当时的我还不知道踏上 ACM 这条路的苦，而如今的我却也尝到了 ACM 带给我的乐。 在这三年里，有数不清的夜晚，我的舍友们在寝室里开黑，而我和我的队友在机房里开黑；在这三年里，有数不清的周末，我的舍友们在校园里驰骋，而我和我的队友在题库里驰骋；在这三年里，有数不清的假期，我的舍友们在召唤师峡谷里征战，而我和我的队友在中国各省市征战。三年过去了，我的舍友们成为了 offer 收割机，而我和我的队友成为了气球收割机。 为了变强是一个痛苦且漫长的过程，只有耐得住寂寞，才能守得住繁华。我的一位队友为了变强甚至牺牲了自己的头发，仅仅是因为他担心他的头发阻碍了他思维的发散。他变秃了也变强了。 三年的 ACM 让我成长很多，收获很多。我也从一个“好好学习天天向上为校争光不搞对象”的无知青年变成了一个写的了工程查得出异常的准程序员。我觉得三年献身于 ACM 的日子是值得的，和一大堆萌萌的男孩子们在屋子里面一个又一个通宵奋斗的酣畅淋漓的日子是值得的，看着谈恋爱的大家一会儿哀伤一会儿忧愁而我与代码自得其乐矢志不渝的日子是值得的。此外他还给我带来两个最好的小伙伴，是他们的一路陪伴，让我有勇气一直走下去。我和他们走过的地方，比我和女朋友去过的地方还要多。噢，对了，我好像没有女朋友。总而言之，请珍惜你们的队友，他们是你们在大学里为数不多一起奋斗的小伙伴。希望大家像我一样，也爱着 ACM，为自己心爱的努力。 最后预祝各位参赛选手们取得理想的成绩，也预祝本次大赛圆满成功。谢谢大家。 ","date":"2018-06-15","objectID":"/posts/18%E6%B9%98%E6%BD%AD%E9%82%80%E8%AF%B7%E8%B5%9B%E9%98%9F%E5%91%98%E4%BB%A3%E8%A1%A8%E5%8F%91%E8%A8%80/:0:0","tags":["ACM","2018 湘潭邀请赛"],"title":"18 湘潭邀请赛参赛队员代表发言","uri":"/posts/18%E6%B9%98%E6%BD%AD%E9%82%80%E8%AF%B7%E8%B5%9B%E9%98%9F%E5%91%98%E4%BB%A3%E8%A1%A8%E5%8F%91%E8%A8%80/"},{"categories":["ACM"],"content":"题目链接（hdu 复赛） 2018 年湘潭邀请赛，在湘大举行，当时一起打的过去的，因为没出市就方便点。第一次参加现场赛，首先反省一下自己，比赛前算法先不说（没有好好搞过），就连普通的题，数学性质的题都很少刷，什么都不会，然后英语不说四六级的东西，很多专业英语词汇都没有好好了解过，主要的原因还是刷题刷少了，英文题刷少了。理所当然，成功拿下一铁，湘潭赛打铁告终。 比赛开始，这次是三个人没人一份纸质题目，拿到题目，看最后一题，k.2018 发现可以做，（事实证明确实是一道水题），我就在做这题，他们看了 a 题，好像是 k 题一顿操作后提交，错了，一直到比赛结束都没做出来，后来回去看别人的题解，发现自己情况没有分析全面，其实是完全可以解出来的，真的做的太少太少了。a 题最后也是没过，还有一个 f 题，sort，我最初的想法是用 stl 里的那个 sort 排序，只要对 sort 的 compare 函数做处理应该可以完成排序，比赛之前我看过，但是不熟悉，zxm 她也看了我就交给她了，最后好像因为爆 long double 的问题也没做出来。 哎，菜还是菜，很多算法都不懂，数据结构也没学好，很有一段时间我都特别头疼算法，不想学，费劲，觉得自己不适合学计算机，更不适合 ACM。有时候又想，不适合好像总是 loser 的借口！总是在后悔和偷懒的矛盾中！ 最后，放上，“参赛奖\"羞辱自己，也是鞭策！ ","date":"2018-06-14","objectID":"/posts/18%E6%B9%98%E6%BD%AD%E9%82%80%E8%AF%B7%E8%B5%9B%E6%80%BB%E7%BB%93/:0:0","tags":["ACM","2018 湘潭邀请赛","Summaries"],"title":"18 湘潭邀请赛总结","uri":"/posts/18%E6%B9%98%E6%BD%AD%E9%82%80%E8%AF%B7%E8%B5%9B%E6%80%BB%E7%BB%93/"},{"categories":["ACM"],"content":"Sample Input 2 1 1 1 1 1 2 2 1 1 2 1 1 1 3 1 3 1 2 2 1 3 1 1 ","date":"2018-06-14","objectID":"/posts/f-sorting/:1:0","tags":["2018 湘潭邀请赛","ACM"],"title":"F.sorting","uri":"/posts/f-sorting/"},{"categories":["ACM"],"content":"Sample Output 2 1 1 2 1 2 3 题意：给定 n 个元组 (a1,b1,c1),(a2,b2,c2),…,(an,bn,cn)，将其按 (ai+bi)/(ai+bi+ci) 的值从小到大排序，输出排序后的 n 个元组的原序号； 思路：编写 sort 里的 cmp 函数（形参为元组结构体元素，设为 Tuple x,Tuple y)，若直接算出 (x.a+x.b)(y.a+y.b+y.c) 和 (y.a+y.b)(x.a+x.b+x.c) 再比较大小，这两个结果会爆 unsigned long long； 可以把因式乘积展开成多项式的和，约去两式中相同的项，得到 x.ay.c+x.by.c 和 y.ax.c+y.bx.c，因此只需计算它俩再比较即可，结果不会爆 unsigned long long 后 AC 代码 #include \"bits/stdc++.h\" using namespace std; struct node{ long double a,b,c; int numb; }ss[1005]; bool cmp(const node \u0026a,const node \u0026b){ long double suma,sumb; //suma=a.a*b.c+a.b*b.c; //sumb=b.a*a.c+b.b*a.c; suma=(a.a+a.b)/(a.a+a.b+a.c); sumb=(b.a+b.b)/(b.a+b.b+b.c); if(suma!=sumb)return suma\u003csumb; return a.numb\u003cb.numb; } int main(){ int n; while(cin\u003e\u003en){ for(int i=0;i\u003cn;i++){ cin\u003e\u003ess[i].a\u003e\u003ess[i].b\u003e\u003ess[i].c; ss[i].numb=i+1; } stable_sort(ss,ss+n,cmp); int i; for(i=0;i\u003cn-1;i++) cout\u003c\u003css[i].numb\u003c\u003c\" \"; cout\u003c\u003css[i].numb\u003c\u003cendl; } return 0; } ","date":"2018-06-14","objectID":"/posts/f-sorting/:2:0","tags":["2018 湘潭邀请赛","ACM"],"title":"F.sorting","uri":"/posts/f-sorting/"},{"categories":["ACM"],"content":"K. 2018 Given a,b,c,d, ﬁnd out the number of pairs of integers (x,y) where a ≤ x ≤ b,c ≤ y ≤ d and x·y is a multiple of 2018. ","date":"2018-06-14","objectID":"/posts/k-2018/:1:0","tags":["2018 湘潭邀请赛","ACM","C++"],"title":"K.2018","uri":"/posts/k-2018/"},{"categories":["ACM"],"content":"Input The input consists of several test cases and is terminated by end-of-ﬁle. Each test case contains four integers a,b,c,d. ","date":"2018-06-14","objectID":"/posts/k-2018/:1:1","tags":["2018 湘潭邀请赛","ACM","C++"],"title":"K.2018","uri":"/posts/k-2018/"},{"categories":["ACM"],"content":"Output For each test case, print an integer which denotes the result. ","date":"2018-06-14","objectID":"/posts/k-2018/:1:2","tags":["2018 湘潭邀请赛","ACM","C++"],"title":"K.2018","uri":"/posts/k-2018/"},{"categories":["ACM"],"content":"Constraint • 1≤ a ≤ b ≤109,1≤ c ≤ d ≤109 • The number of tests cases does not exceed 104. ","date":"2018-06-14","objectID":"/posts/k-2018/:1:3","tags":["2018 湘潭邀请赛","ACM","C++"],"title":"K.2018","uri":"/posts/k-2018/"},{"categories":["ACM"],"content":"Sample Input 1 2 1 2018 1 2018 1 2018 1 1000000000 1 1000000000 ","date":"2018-06-14","objectID":"/posts/k-2018/:1:4","tags":["2018 湘潭邀请赛","ACM","C++"],"title":"K.2018","uri":"/posts/k-2018/"},{"categories":["ACM"],"content":"Sample Output 3 6051 1485883320325200 题意：给定区间 [a,b]、[c,d]，问有多少对有序数组 (x,y)(x∈[a,b],y∈[c,d]) 使得 xy 是 2018 的倍数 思路：2018=21009（分解质因数），则对 x 分类讨论：1) 仅为 2 的倍数；2）仅为 1009 的倍数；3）即为 2 又为 1009 的倍数；4）既不为 2 又不为 1009 的倍数 等价于如下分类讨论： 若 x 是偶数：1）若 x 是 1009 的倍数，则 y 可为 [c,d] 中任意数； 2）若 x 不是 1009 的倍数，则 y 必定为 [c,d] 中 1009 的倍数 若 x 是奇数：1）若 x 是 1009 的倍数，则 y 必定为 [c,d] 中 2 的倍数； 2）若 x 不是 1009 的倍数，则 y 必定为 [c,d] 中 2018 的倍数 后 AC 代码 #include\u003ccstdio\u003e #include\u003ciostream\u003e typedef unsigned long long ll; using namespace std; int main(){ ll a,b,c,d; while(cin\u003e\u003ea\u003e\u003eb\u003e\u003ec\u003e\u003ed){ ll num1_all_1009=b/1009-(a-1)/1009; ll num1_even=b/2-(a-1)/2; ll num1_1009_in_even=b/2018-(a-1)/2018; ll num1_rest_in_even=num1_even-num1_1009_in_even; ll num1_odd=(b-a+1)-num1_even; ll num1_1009_in_odd=num1_all_1009-num1_1009_in_even; ll num1_rest_in_odd=num1_odd-num1_1009_in_odd; ll ans=0; ans+=num1_1009_in_even*(d-c+1); ll num2_all_1009=d/1009-(c-1)/1009; ans+=num1_rest_in_even*num2_all_1009; ll num2_even=d/2-(c-1)/2; ans+=num1_1009_in_odd*num2_even; ll num2_all_2018=d/2018-(c-1)/2018; ans+=num1_rest_in_odd*num2_all_2018; cout\u003c\u003cans\u003c\u003cendl; } return 0; } ","date":"2018-06-14","objectID":"/posts/k-2018/:1:5","tags":["2018 湘潭邀请赛","ACM","C++"],"title":"K.2018","uri":"/posts/k-2018/"},{"categories":["ACM"],"content":"B. Higher h-index The h-index of an author is the largest h where he has at least h papers with citations not less than h. Bobo has no papers and he is going to publish some subsequently. If he works on a paper for x hours, the paper will get (a·x) citations, where a is a known constant. It’s clear that x should be a positive integer. There is also a trick – one can cite his own papers published earlier. Given Bobo has n working hours, ﬁnd the maximum h-index of him. ","date":"2018-06-14","objectID":"/posts/b-higher/:1:0","tags":["ACM","2018 湘潭邀请赛","C++","C"],"title":"B.Higher h-index","uri":"/posts/b-higher/"},{"categories":["ACM"],"content":"Input The input consists of several test cases and is terminated by end-of-ﬁle. Each test case contains two integers n and a. ","date":"2018-06-14","objectID":"/posts/b-higher/:1:1","tags":["ACM","2018 湘潭邀请赛","C++","C"],"title":"B.Higher h-index","uri":"/posts/b-higher/"},{"categories":["ACM"],"content":"Output For each test case, print an integer which denotes the maximum h-index. ","date":"2018-06-14","objectID":"/posts/b-higher/:1:2","tags":["ACM","2018 湘潭邀请赛","C++","C"],"title":"B.Higher h-index","uri":"/posts/b-higher/"},{"categories":["ACM"],"content":"Constraint • 1≤ n ≤109 • 0≤ a ≤ n • The number of test cases does not exceed 104. ","date":"2018-06-14","objectID":"/posts/b-higher/:1:3","tags":["ACM","2018 湘潭邀请赛","C++","C"],"title":"B.Higher h-index","uri":"/posts/b-higher/"},{"categories":["ACM"],"content":"Sample Input 3 0 3 1 1000000000 1000000000 ","date":"2018-06-14","objectID":"/posts/b-higher/:1:4","tags":["ACM","2018 湘潭邀请赛","C++","C"],"title":"B.Higher h-index","uri":"/posts/b-higher/"},{"categories":["ACM"],"content":"Sample Output 1 2 1000000000 ","date":"2018-06-14","objectID":"/posts/b-higher/:1:5","tags":["ACM","2018 湘潭邀请赛","C++","C"],"title":"B.Higher h-index","uri":"/posts/b-higher/"},{"categories":["ACM"],"content":"Note For the ﬁrst sample, Bobo can work 3 papers for 1 hour each. With the trick mentioned, he will get papers with citations 2,1,0. Thus, his h-index is 1. For the second sample, Bobo can work 2 papers for 1 and 2 hours respectively. He will get papers with citations 1+1,2+0. Thus, his h-index is 2. 题意：给定 n 个小时，可以用其中 x(1\u003c=x\u003c=n) 个小时写一篇论文，那么这篇论文的\"既定\"引用数将会是x*a(a 为给定正整数）；此外，已经写好的论文将会被其后写成的论文所引用，也就是说，这篇论文的总引用数将会是\"既定\"引用数+其后论文篇数；问在所有的写论文方案中（例如一种方案就是用 n 个小时写 n 篇论文，每篇论文各花 1 小时（可以得到这 n 篇论文的引用数）)，h 最大为多少 (h 的含义同上题）（每一种方案都对应着一个 h，求这些 h 中的最大者） 思路：最优方案（即对应 h 值最大的方案）是平摊 n 小时写成 n 篇论文（证明未知）；此时 n 篇论文的引用数为 a,a+1,a+2,…,a+n-1，引用数为 a+i 时，引用数大于等于它的论文有 n-i 篇，令 a+i=n-i 得 i=(n-a)/2, 所以 h=a+(n-a)/2; 后 AC 代码 #include\u003ccstdio\u003e int main(){ int n,a; while(scanf(\"%d%d\",\u0026n,\u0026a)!=EOF){ printf(\"%d\\n\",a+(n-a)/2); } return 0; } ","date":"2018-06-14","objectID":"/posts/b-higher/:1:6","tags":["ACM","2018 湘潭邀请赛","C++","C"],"title":"B.Higher h-index","uri":"/posts/b-higher/"},{"categories":["ACM"],"content":"A. Easy h-index The h-index of an author is the largest h where he has at least h papers with citations not less than h. Bobo has published many papers. Given a0,a1,a2,…,an which means Bobo has published ai papers with itations exactly i, ﬁnd the h-index of Bobo. ","date":"2018-06-14","objectID":"/posts/a-easy/:1:0","tags":["2018 湘潭邀请赛","ACM","C++"],"title":"A.Easy h-index","uri":"/posts/a-easy/"},{"categories":["ACM"],"content":"Input The input consists of several test cases and is terminated by end-of-ﬁle. The ﬁrst line of each test case contains an integer n. The second line contains (n+1) integers a0,a1,…,an. ","date":"2018-06-14","objectID":"/posts/a-easy/:1:1","tags":["2018 湘潭邀请赛","ACM","C++"],"title":"A.Easy h-index","uri":"/posts/a-easy/"},{"categories":["ACM"],"content":"Output For each test case, print an integer which denotes the result. ","date":"2018-06-14","objectID":"/posts/a-easy/:1:2","tags":["2018 湘潭邀请赛","ACM","C++"],"title":"A.Easy h-index","uri":"/posts/a-easy/"},{"categories":["ACM"],"content":"Constraint • 1≤ n ≤2·105 • 0≤ ai ≤109 • The sum of n does not exceed 250,000. ","date":"2018-06-14","objectID":"/posts/a-easy/:1:3","tags":["2018 湘潭邀请赛","ACM","C++"],"title":"A.Easy h-index","uri":"/posts/a-easy/"},{"categories":["ACM"],"content":"Sample Input 1 1 2 2 1 2 3 3 0 0 0 0 ","date":"2018-06-14","objectID":"/posts/a-easy/:1:4","tags":["2018 湘潭邀请赛","ACM","C++"],"title":"A.Easy h-index","uri":"/posts/a-easy/"},{"categories":["ACM"],"content":"Sample Output 1 2 0 题意：给定被引用次数为 0~n 的论文分别有几张，找到最大的 h，满足被引用次数大于等于 h 的论文至少有 h 张 思路：在区间 [0,n] 内二分答案；或直接从 n~0 遍历找到第一个满足条件的 h 后 AC 代码 #include \"bits/stdc++.h\" using namespace std; int main(){ int a[200005]; int n; int i; while(cin\u003e\u003en){ for(i=0;i\u003c=n;i++) cin\u003e\u003ea[i]; int sum=a[n]; for(i=n;i\u003e=0;){ if(sum\u003e=i){ cout\u003c\u003ci\u003c\u003cendl; break; } else sum+=a[--i]; } if(i\u003c0) cout\u003c\u003c\"0\"\u003c\u003cendl; } return 0; } ","date":"2018-06-14","objectID":"/posts/a-easy/:1:5","tags":["2018 湘潭邀请赛","ACM","C++"],"title":"A.Easy h-index","uri":"/posts/a-easy/"},{"categories":["ACM"],"content":"sort 使用#include\u003calgorithm\u003e头文件， sort（开始地址，结束地址，排序方式），其中第三参数可以没有，则默认为升序排序。 或者简单的用 less\u003c参数类型\u003e()表示升序 greater\u003c参数类型\u003e()表示降序 也可以用一个 bool 型函数，比如： bool cmp(int a,int b){ return a\u003eb;//表从大到小，即降序 } 假设自己定义了一个结构体 node typedef struct node { int a; int b; double c; }note; 有一个 node 类型的数组 node arr[100]，想对它进行排序：先按 a 值升序排列，如果 a 值相同，再按 b 值降序排列，如果 b 还相同，就按 c 降序排列。就可以写这样一个比较函数： 以下是代码片段： bool cmp(node x,node y) { if(x.a!=y.a) return x.a\u003cy.a; if(x.b!=y.b) return x.b\u003ey.b; return x.c\u003ey.c; } sort() 函数是完全通用的，你可以用它来操作几乎任何数据集合，包括链表，容器和数组，数组类型可以是 int,char 等。 实例：先降序再升序 #include\u003ciostream\u003e #include\u003calgorithm\u003e using namespace std; typedef struct data{ int a; double b; }date; bool cmp(date a,date b){ if(a.b!=b.b) return a.b\u003eb.b; return a.a\u003cb.a; } int main(){ date a[3]={{5,56.5},{4,56.5},{8,85}}; sort(a,a+3,cmp); for(int i=0;i\u003c3;i++) cout\u003c\u003ca[i].a\u003c\u003c\"-\"\u003c\u003ca[i].b\u003c\u003cendl; cout\u003c\u003cendl; return 0; } 传送门 ","date":"2018-06-14","objectID":"/posts/c-sort/:0:0","tags":["C++","sort","STL","ACM"],"title":"sort 排序","uri":"/posts/c-sort/"},{"categories":["ACM"],"content":"1.swap（交换两元素值，在 algorithm 下，用法：swap(a,b);） 交换两元素的值在 C 语言课上作为指针讲解的典例。 int a=1,b=2; swap(a,b); //此时 a=2,b=1 （可以是其他类型） ","date":"2018-06-14","objectID":"/posts/c-with-stl/:1:0","tags":["ACM","STL","C++"],"title":"C++ with STL","uri":"/posts/c-with-stl/"},{"categories":["ACM"],"content":"2.sort(,,) sort 排序是不稳定的，stl 中的 stable_sort 才是稳定的 inta[10]={1,6,2,3,5,4,3,8,9,7}; stable_sort(a,a+10,greater\u003cint\u003e()); for(int i=0;i\u003c10;i++) cout\u003c\u003ca[i]\u003c\u003c\" \"; ","date":"2018-06-14","objectID":"/posts/c-with-stl/:2:0","tags":["ACM","STL","C++"],"title":"C++ with STL","uri":"/posts/c-with-stl/"},{"categories":["ACM"],"content":"3.reverse（翻转序列，在 algorithm 下） //常用在字符串上 int a[5]={1,2,3,4,5}; reverse(a,a+5); //序列现在是 5 4 3 2 1 char s[]=“ericxie”; reverse(s,s+strlen(s)); //序列现在是 “eixcire” //同样适用于 string string s=“qwer”; reverse(s.begin(),s.end()); ","date":"2018-06-14","objectID":"/posts/c-with-stl/:3:0","tags":["ACM","STL","C++"],"title":"C++ with STL","uri":"/posts/c-with-stl/"},{"categories":["ACM"],"content":"4.min，max（取大，取小） int a=1,b=2,c; c=min(a,b); //此时 c 等于 1 c=max(a,b); //此时 c 等于 2 string s=“qwer”,d=“asjk”,c; c=min(s,d); //c=“asjk” ","date":"2018-06-14","objectID":"/posts/c-with-stl/:4:0","tags":["ACM","STL","C++"],"title":"C++ with STL","uri":"/posts/c-with-stl/"},{"categories":["ACM"],"content":"5.__gcd（最大公约数） 手写 gcd 函数也行，辗转相除，辗转相减； int gcd(int a,int b){ return a%b ? b : gcd(b,a%b); } //直接用 int a=4,b=6; int c=__gcd(a,b); //注意下划线，此时 c 等于 2 ","date":"2018-06-14","objectID":"/posts/c-with-stl/:5:0","tags":["ACM","STL","C++"],"title":"C++ with STL","uri":"/posts/c-with-stl/"},{"categories":["ACM"],"content":"6.lower_bound 和 upper_bound（二分查找） lower_bound 意思就是：找到第一个位置，使得：如果在这个位置插入 value 后，原有序序列依旧有序。 upper_bound 是找到最后一个符合数位置后一个位置，使得：如果在这个位置插入 value 后，原有序序列依旧有序。 //数组 int a[8]={1,2,4,4,9,12,12,15}; int pos1 = lower_bound(a,a+8,4)-a; int pos2 = upper_bound(a,a+8,4)-a-1; //在这个样例下 pos1!=pos2;pos1=2;pos2=3; 根据我的理解 lower_bound(a,a+8,value) 得到的是一个地址，拿这个地址减去数组首地址 a[0]，那么刚好就是 value 应该放入的位置。 //vector vector\u003cint\u003e a; 若 a 中目前的元素也是{1,2,4,4,9,12,12,15}; 那么这里用 lower_bound 得到的应该也是一个类似于指针的东西，为什么不叫它指针呢？因为他有了一个名字，叫做迭代器。 vector\u003cint\u003e::iterator it; it = lower_bound(a.begin(),a.end(),4); //这里的 it 就是迭代器，那么* it 就是该下标对应的 value 了。 //set 集合 set\u003cint\u003e a; set\u003cint\u003e::iterator it; it = a.lower_bound(value); ","date":"2018-06-14","objectID":"/posts/c-with-stl/:6:0","tags":["ACM","STL","C++"],"title":"C++ with STL","uri":"/posts/c-with-stl/"},{"categories":["ACM"],"content":"7.next_permutation （排列） bool next_permutation( iterator start, iterator end ); 通常用于生成序列的全排列。用之前先保证有序； int a[]={1,2,3}; do{ for(int i=0;i\u003c3;i++) cout\u003c\u003ca[i]\u003c\u003c\" \"; cout\u003c\u003cendl; }while(next_permutation(a,a+3)); 结果为： 1 2 3 1 3 2 2 1 3 2 3 1 3 1 2 3 2 1 string str=\"STL\"; sort(str.begin(), str.end()); do{ cout \u003c\u003c str \u003c\u003c endl; }while (next_permutation(str.begin(),str.end()))； 结果： LST LTS SLT STL TLS TSL 大数据 c 比 c++效率高 int length; char str[MAX]; gets(str); length = strlen(str); sort(str, str + length); do{ puts(str); }while(next_permutation(str, str+length))； ","date":"2018-06-14","objectID":"/posts/c-with-stl/:7:0","tags":["ACM","STL","C++"],"title":"C++ with STL","uri":"/posts/c-with-stl/"},{"categories":["ACM"],"content":"8.unique （去重） 如何把序列 a 中的重复元素去除呢？首先需要对原序列 a 进行排序，保证有序后，调用 unique(a.head , a.tail ) 就可以了。unique 会返回一个类似指针的东西（和 lower_bound 有点像），-a 后表示去重之后序列的长度。 下面是实例。 int a[]={1,3,5,7,9,2,2,2,1,1,1}; sort(a,a+11); int len = unique(a,a+11)-a; for(int i=0;i\u003clen;i++) cout\u003c\u003ca[i]\u003c\u003c\" \"; 输出结果为：1 2 3 5 7 9 传送门 ","date":"2018-06-14","objectID":"/posts/c-with-stl/:8:0","tags":["ACM","STL","C++"],"title":"C++ with STL","uri":"/posts/c-with-stl/"},{"categories":["Grocery"],"content":"1. \u0026运算 \u0026运算通常用于二进制取位操作，例如一个数 \u0026 1 的结果就是取二进制的最末位。这可以用来判断一个整数的奇偶，二进制的最末位为 0 表示该数为偶数，最末位为 1 表示该数为奇数。 ","date":"2018-06-14","objectID":"/posts/%E4%BD%8D%E8%BF%90%E7%AE%97/:1:0","tags":["位运算"],"title":"位运算","uri":"/posts/%E4%BD%8D%E8%BF%90%E7%AE%97/"},{"categories":["Grocery"],"content":"2. |运算 |运算通常用于二进制特定位上的无条件赋值，例如一个数 or 1 的结果就是把二进制最末位强行变成 1。如果需要把二进制最末位变成 0，对这个数| 1 之后再减一就可以了，其实际意义就是把这个数强行变成最接近的偶数。 ","date":"2018-06-14","objectID":"/posts/%E4%BD%8D%E8%BF%90%E7%AE%97/:2:0","tags":["位运算"],"title":"位运算","uri":"/posts/%E4%BD%8D%E8%BF%90%E7%AE%97/"},{"categories":["Grocery"],"content":"3. ^运算 ^运算通常用于对二进制的特定一位进行取反操作，因为异或可以这样定义：异或 0 都不变，异或 1 则取反。 ^运算的逆运算是它本身，也就是说两次异或同一个数最后结果不变，即 a ^ b ^ b = a。^运算可以用于简单的加密，比如你想对你 MM 说 1314520，但怕别人知道，于是双方约定拿你的生日 19880516 作为密钥。1314520^19880516 = 20665500，你就把 20665500 告诉 MM。MM 再次计算 20665500 ^ 19880516 的值，得到 1314520，于是她就明白了你的企图。 还可以用异或来进行快速地交换数据， a=2;b=3;//先转化成二进制 a=a^b; b=a^b; a=a^b; 操作后 a=3;b=2; ","date":"2018-06-14","objectID":"/posts/%E4%BD%8D%E8%BF%90%E7%AE%97/:3:0","tags":["位运算"],"title":"位运算","uri":"/posts/%E4%BD%8D%E8%BF%90%E7%AE%97/"},{"categories":["Grocery"],"content":"4. ~ 运算 ~运算的定义是把内存中的 0 和 1 全部取反。使用~运算时要格外小心，你需要注意整数类型有没有符号。如果~的对象是无符号整数（不能表示负数），那么得到的值就是它与该类型上界的差，因为无符号类型的数是用$0000 到$FFFF 依次表示的。 ","date":"2018-06-14","objectID":"/posts/%E4%BD%8D%E8%BF%90%E7%AE%97/:4:0","tags":["位运算"],"title":"位运算","uri":"/posts/%E4%BD%8D%E8%BF%90%E7%AE%97/"},{"categories":["Grocery"],"content":"5. «运算 a « b 就表示把 a 转为二进制后左移 b 位（在后面添 b 个 0）。例如 100 的二进制为 1100100，而 110010000 转成十进制是 400，那么 100 «2 = 400。可以看出，a « b 的值实际上就是 a 乘以 2 的 b 次方，因为在二进制数后添一个 0 就相当于该数乘以 2。 通常认为 a « 1 比 a * 2 更快，因为前者是更底层一些的操作。因此程序中乘以 2 的操作请尽量用左移一位来代替。 定义一些常量可能会用到«运算。你可以方便地用 1 «16 – 1 来表示 65535。很多算法和数据结构要求数据规模必须是 2 的幂，此时可以用«来定义 Max_N 等常量。 ","date":"2018-06-14","objectID":"/posts/%E4%BD%8D%E8%BF%90%E7%AE%97/:5:0","tags":["位运算"],"title":"位运算","uri":"/posts/%E4%BD%8D%E8%BF%90%E7%AE%97/"},{"categories":["Grocery"],"content":"6. »运算 和«相似，a » b 表示二进制右移 b 位（去掉末 b 位），相当于 a 除以 2 的 b 次方（取整）。我们也经常用» 1 来代替 div 2，比如二分查找、堆的插入操作等等。想办法用»代替除法运算可以使程序效率大大提高。最大公约数的二进制算法用除以 2 操作来代替慢得出奇的 mod 运算，效率可以提高 60% 传送门 原文：http://www.matrix67.com/blog/archives/263 ","date":"2018-06-14","objectID":"/posts/%E4%BD%8D%E8%BF%90%E7%AE%97/:6:0","tags":["位运算"],"title":"位运算","uri":"/posts/%E4%BD%8D%E8%BF%90%E7%AE%97/"},{"categories":["Memo"],"content":" 2021/10/1 更新 使用 Chrome 等浏览器管理书签是更好更方便的方式，登陆 google 账号，或者导出 html 书签文件都挺方便。 我们在平时学习生活总会遇到很多很多有用的网站，也许我们收藏在了浏览器书签里，可过久了，不做说明，这些链接的价值就被时间淹没了，我们自己都记不起来了，所以这篇文章因此而生。对自己收藏的链接做些简单的说明（第一次编写用了我一个下午）；也相当于我的链接收藏夹，分享一些有趣的网站， ","date":"2018-06-07","objectID":"/posts/links/:0:0","tags":["ACM"],"title":"各种 Links 汇总与分享","uri":"/posts/links/"},{"categories":["Memo"],"content":"ACM 相关 链接 描述 各大 OJ 题目分类 各种算法分类，对应 OJ 题号超链接 ACM 题目分类 codeforces 俄国 CF 在线编程，一般比赛在晚上 9:30 和 11：00 牛客网 国内求职学习网，有很多程序设计比赛 vjudge 这个不用说了吧 hihocoder 打得少，感觉好多数据结构的题 百练 OpenJudge 的一个小组，很多题目来自 POJ；也是我 ACM 启蒙地 HDUOJ 杭州电子科技大学 OJ POJ 北京大学 OJ 洛谷 lintcode 领扣（国外） leedcode 力扣 codewar 国外 更多 OJ，在线刷题网站 … ","date":"2018-06-07","objectID":"/posts/links/:1:0","tags":["ACM"],"title":"各种 Links 汇总与分享","uri":"/posts/links/"},{"categories":["Memo"],"content":"编程，学习 链接 描述 visualgo 算法学习，数据结构和算法动态可视化 c,c++学习 很详细的知识讲解 Tomcat 下载 Tomcat 各版本下载，Tomcat 解压即安装；\\bin下可以启动和关闭服务器；可手动在\\webapps里创建 web 应用，也可以配合Eclisp IDE for Java EE Developers等 Java IDE 工具创建 w3school 可在线测试，Web 技术教程，HTML, 浏览器脚本，服务器脚本，xml 教程等 w3cschool 和上面不同哦，是不是和上面的很像哈哈哈！我估计是上一个网站的新版，功能更强大，内容更丰富，还有微信小程序教程等 菜鸟教程 和上面两个差不多，还有一些数据库、安卓的东西，git 学习 python 学习 Python 库安装包下载，python,Django,HTML,ACM 学习 python123 Python123 是专注于为中国高等院校教学 Python 语言的而开发的一款学习工具网站 python 学习 pypi Find, install and publish Python packages with the Python Package Index 优矿 python 在线测试，笔记 阮一峰的网络日志 开发者手册，JavaScript 等等 廖雪峰 git,python,javascript 学习 新晴网 PS 学习，摄影教程等 实验楼 在线做实验，高效学编程 慕课网 在线学习，免费，付费视频 wxpy 一个 python 关于微信的库 So1n python 学习 ","date":"2018-06-07","objectID":"/posts/links/:2:0","tags":["ACM"],"title":"各种 Links 汇总与分享","uri":"/posts/links/"},{"categories":["Memo"],"content":"云服务及站长工具 链接 描述 腾讯云 dnspod 解析新版入口，腾讯云控制台 dnspod 解析 域名解析，其他：阿里云等 cloudflare 解析 域名解析，https 解析，[介绍](https://oliverqueen.cn/2018/01/25/可能是最全的使用 HEXO 搭建个人博客教程) cloud studio 这是腾讯云和 coding 合作后的一个东西，简单来说就是云端开发环境。试了一下完全可以把 hexo 博客源码挂上面编辑。这也就不用只局限于一台电脑发布博客了。 腾讯云大学开放实验室 可以在线进行一些云服务应用搭建等的实验。与之对应的还有阿里云开放实验室 宝塔面板 宝塔面板是一款使用方便、功能强大且终身免费的服务器管理软件，支持 Linux 与 Windows 系统。一键配置：LAMP/LNMP、网站、数据库、FTP、SSL，通过 Web 端轻松管理服务器。 leancloud 一站式后端云服务 daovoice 网站在线客服 百度网站收录 网站 seo Bing 站长 Bing 网站管理员工具 站长工具 网站信息查询，权重，seo，网站速度查询，ping 等 站长工具大全 各种 seo 优化，工具等 ","date":"2018-06-07","objectID":"/posts/links/:3:0","tags":["ACM"],"title":"各种 Links 汇总与分享","uri":"/posts/links/"},{"categories":["Memo"],"content":"前端工具 链接 描述 全栈开发者 顾名思义，有很多 web 开发的教程，也可以在线执行代码 JSFuck JSFuck 是一种基于 JavaScript 原子部分的深奥教育编程风格。它只使用六个不同的字符来编写和执行代码。（代码极丑化） BootCDN 稳定、快速、免费的前端开源项目 CDN 加速服务，共收录了 3441 个前端开源项目。比如vue,fancybox等 bootstrap 中文网 简洁、直观、强悍的前端开发框架，让 web 开发更迅速、简单。还有一些基于 bootstrap 开发或扩充的项目的 cdn，BootCDN也是在该网站旗下 Font Awesome 图标库 hexo 指定图标库 iconfont 阿里巴巴矢量图标库 easyicon 图标库 图标下载，格式转换，可外链 semantic-ui.com 图标库 semantic-ui.com 还有很多前端样式对应代码 colorhunt 配色方案推荐，调试 grabient 渐变色 渐变色调色 gradient 渐变色调色 渐变色调色，获取代码 encycolorpedia encycolorpedia 取色器 优酷视频上传 获取视频外链，其他：腾讯视频 sm.ms 非常好用的图床 imgURL 一个开源的图床，很不错，有兴趣的可以自己尝试搭建，比如 img.lruihao.cn 现实君外链 支持多种文件外链，唯一不好的是 http PEXELS 美图 文章配图，无版权美图网，避免配图侵权 unsplash 美图 API 还可以获取 随机图 图标工厂 移动应用图标生成工具，一键生成所有尺寸的应用图标 emoji 在线复制 Simple emoji copy and paste HTML 字符实体 网页特殊符号大全 特效字转换工具集 各种特效字转换工具，彩虹字生成器，RGB 转 16 进制颜色等 压缩图 在线 ps，图片去底，证件照换底等操作很方便的 web 图片处理工具 改图宝 在线改图压缩，加水印，生成二维码，印章制作等 GIF 之家 一个压缩效果很好且免费的 gif 压缩工具 二维码解码器 草料二维码 https://cli.im 联图二维码 第九工厂 死磕艺术二维码 模板码 动态二维码等 ","date":"2018-06-07","objectID":"/posts/links/:4:0","tags":["ACM"],"title":"各种 Links 汇总与分享","uri":"/posts/links/"},{"categories":["Memo"],"content":"实用工具 链接 描述 Gearn Git Branching 通过游戏闯关的方式学习 git！ PicGo 一个很好的开源的图床管理桌面程序，图床神器支持微博图床、七牛图床、腾讯云 COS、又拍云、GitHub 图床、阿里云 OSS、Imgur 图床等等 Proxyee Down 百度云下载解决方案，满速下载，但不限于百度云的下载，感觉比迅雷还好用！ PanDownload 这是 pandownload 网页版，把需要下载的百度网盘链接baidu改成baiduwp即可加速，也有桌面版。 ubuntu pastebin 代码展示托管，生成分享网址，防止代码直接分享缩进消失 图片转字符工具 Img–\u003eString everyfont 中文字库在线压缩 字蛛 font-spider 中文字库压缩 mdtr2pdf markdown 转 pdf AD’s API 包括动态签名，网易音乐等 在线工具 w3cschool 的在线工具集合 在线工具 开源中国社区 菜鸟工具 菜鸟教程 在线工具，编译，加密，压缩代码等 msdn windows 系统上 office 等软件下载（备用） 老殁科技 Adobe 等各种绿色破解软件 百度接口 百度搜索关键词接口 在线短信 不想泄露个人的电话号码，注册一些一次性网站可以用到 配音阁 文字转换语音/语音合成广告叫卖录音在线配音网络软件_促销宣传片配音-配音阁-配音阁，国内专业的广告配音平台 hacknical 在线个性简历，个人 Github 总结分析 ","date":"2018-06-07","objectID":"/posts/links/:5:0","tags":["ACM"],"title":"各种 Links 汇总与分享","uri":"/posts/links/"},{"categories":["Memo"],"content":"其他 链接 描述 俄罗斯方块 这是一个开源的游戏，小白的我看来简直牛逼爆了，好逼真，刷新都不会打断游戏进度！！ 网址迷宫 nazo_game 一个程序员的网页游戏，我只玩到 12 关。 无损音乐下载 手写体制作 北京大学计算机科学技术研究所的一个项目59.108.48.27 （我的字体至今还未完成） 大象代理 收费，口碑不错 蒲公英 应用内测发布平台 ","date":"2018-06-07","objectID":"/posts/links/:6:0","tags":["ACM"],"title":"各种 Links 汇总与分享","uri":"/posts/links/"},{"categories":["Memo"],"content":"博客文章 文章 概括 Web 笔记 记录一下自己 web 相关学习的笔记 Git 常用指令汇总 可能用到按需自查 hexo 插件及 next 内置样式集 让文章写的好看又简洁又好用的插件！hexo 更多请看分类 hexo-theme-next @modified LRH 对 next 主题的 DIY 设计记录日志 一款自己写的字体 - 沐目体 沐目体–release ","date":"2018-06-07","objectID":"/posts/links/:7:0","tags":["ACM"],"title":"各种 Links 汇总与分享","uri":"/posts/links/"},{"categories":["Memo"],"content":"更多关于 hexo ","date":"2018-06-01","objectID":"/posts/hexobuild/:0:0","tags":["Node.js","hexo"],"title":"hexo+github 搭建个人博客及美化","uri":"/posts/hexobuild/"},{"categories":["Memo"],"content":"首先 官方文档 是我们的第一手资料，也是最好的。 安装 Hexo 相当简单。然而在安装前，您必须检查电脑中是否已安装下列应用程序： Node.js Git ","date":"2018-06-01","objectID":"/posts/hexobuild/:1:0","tags":["Node.js","hexo"],"title":"hexo+github 搭建个人博客及美化","uri":"/posts/hexobuild/"},{"categories":["Memo"],"content":"hexo 安装 如果您的电脑中已经安装上述必备程序，那么恭喜您！接下来只需要使用 npm 即可完成 Hexo 的安装。 npm install -g hexo-cli ","date":"2018-06-01","objectID":"/posts/hexobuild/:2:0","tags":["Node.js","hexo"],"title":"hexo+github 搭建个人博客及美化","uri":"/posts/hexobuild/"},{"categories":["Memo"],"content":"建站 安装 Hexo 完成后，请执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。 hexo init \u003cfolder\u003e cd \u003cfolder\u003e npm install 为一个文件夹的名字 新建完成后，指定文件夹的目录如下： . ├── _config.yml ├── package.json ├── scaffolds ├── source | ├── _drafts | └── _posts └── themes ","date":"2018-06-01","objectID":"/posts/hexobuild/:3:0","tags":["Node.js","hexo"],"title":"hexo+github 搭建个人博客及美化","uri":"/posts/hexobuild/"},{"categories":["Memo"],"content":"安装 hexo 插件 全装上吧，没事。 npm install hexo-generator-index --save npm install hexo-generator-archive --save npm install hexo-generator-category --save npm install hexo-generator-tag --save npm install hexo-server --save npm install hexo-deployer-git --save npm install hexo-deployer-heroku --save npm install hexo-deployer-rsync --save npm install hexo-deployer-openshift --save npm install hexo-renderer-marked@0.2 --save npm install hexo-renderer-stylus@0.2 --save npm install hexo-generator-feed@1 --save npm install hexo-generator-sitemap@1 --save ","date":"2018-06-01","objectID":"/posts/hexobuild/:4:0","tags":["Node.js","hexo"],"title":"hexo+github 搭建个人博客及美化","uri":"/posts/hexobuild/"},{"categories":["Memo"],"content":"本地查看效果 执行下面语句，执行完再登录 localhost:4000 查看效果（执行完不要按 Ctrl+C，不然就停止了） hexo g hexo s 其他步骤在这里不赘述，参见 超详细教程 安卓上搭建 hexo 博客 ","date":"2018-06-01","objectID":"/posts/hexobuild/:5:0","tags":["Node.js","hexo"],"title":"hexo+github 搭建个人博客及美化","uri":"/posts/hexobuild/"},{"categories":["Memo"],"content":"部署 hexo g -d 部署后我们可以浏览器搜 username.github.io 查看自己的博客效果，比如我的 lruihao.github.io ","date":"2018-06-01","objectID":"/posts/hexobuild/:6:0","tags":["Node.js","hexo"],"title":"hexo+github 搭建个人博客及美化","uri":"/posts/hexobuild/"},{"categories":["Memo"],"content":"美化 这些美化都写的很详细，我建议你们自己好好看看吧，我也是在这里看到的，如果问我和这里说的是一样的。 hexo 个性化教程 valine 特别鸣谢赵俊 👍 asdfv1929 hexo 官方主题集合，我用的是 aloha 主题，该主题 官方文档，后改用 next 主题 next 主题 hexo 官方插件 说说我的主题遇到的一些问题，由于这个主题用的人少，所以作者优化的不是很好（next 使用最多），当然也可以反过来说，所以自己美化了一点 ","date":"2018-06-01","objectID":"/posts/hexobuild/:7:0","tags":["Node.js","hexo"],"title":"hexo+github 搭建个人博客及美化","uri":"/posts/hexobuild/"},{"categories":["Memo"],"content":"博文置顶 修改 hero-generator-index 插件，把文件：node_modules/hexo-generator-index/lib/generator.js 内的代码替换为： 'use strict'; var pagination = require('hexo-pagination'); module.exports = function(locals){ var config = this.config; var posts = locals.posts; posts.data = posts.data.sort(function(a, b) { if(a.top \u0026\u0026 b.top) { // 两篇文章 top 都有定义 if(a.top == b.top) return b.date - a.date; // 若 top 值一样则按照文章日期降序排 else return b.top - a.top; // 否则按照 top 值降序排 } else if(a.top \u0026\u0026 !b.top) { // 以下是只有一篇文章 top 有定义，那么将有 top 的排在前面（这里用异或操作居然不行 233） return -1; } else if(!a.top \u0026\u0026 b.top) { return 1; } else return b.date - a.date; // 都没定义按照文章日期降序排 }); var paginationDir = config.pagination_dir || 'page'; return pagination('', posts, { perPage: config.index_generator.per_page, layout: ['index', 'archive'], format: paginationDir + '/%d/', data: { __index: true } }); }; ","date":"2018-06-01","objectID":"/posts/hexobuild/:7:1","tags":["Node.js","hexo"],"title":"hexo+github 搭建个人博客及美化","uri":"/posts/hexobuild/"},{"categories":["Memo"],"content":"about 页面 about 页面可以用 HTML 写，你想怎么写都行，我用的最简单的方法，直接hexo n page \"about\"后，会生成一个 md 文件，也就是后面说的文章，直接写文章就行了。 ","date":"2018-06-01","objectID":"/posts/hexobuild/:7:2","tags":["Node.js","hexo"],"title":"hexo+github 搭建个人博客及美化","uri":"/posts/hexobuild/"},{"categories":["Memo"],"content":"添加搜索，评论，分享 搜索功能真心好用，当文章多起来的时候，标签提供的作用已经很少了，只能简单索引，搜索却能精确查找，这里我用的依旧是最简单的本地站内搜索。 安装hexo-generator-searchdb 在站点的根目录下执行以下命令： npm install hexo-generator-searchdb --save 配置站点配置文件 新增以下内容到任意位置： search: path: search.xml field: post format: html limit: 10000 配置主题配置文件 ## Local search local_search: enable: true algolia 参考文件 让搜索引擎找到你的博客，还是看到邱承佳学长博文有写到 传送门 ","date":"2018-06-01","objectID":"/posts/hexobuild/:7:3","tags":["Node.js","hexo"],"title":"hexo+github 搭建个人博客及美化","uri":"/posts/hexobuild/"},{"categories":["Memo"],"content":"添加访客数，阅读量等 评论有多说（多说好像挂了），计数有不蒜，我用的不蒜子，还有其他的。 文章阅读量 以下适合非 next 主题的部分主题，next 主题已经自带，到主题配置文件修改就好了。 打开以下路径在你喜欢的地方添加代码，\\blog\\hexo\\themes\\主题名字、layout\\_partial，找到 article.ejs文件 \u003cdiv align=\"left\"\u003e \u003cspan id=\"busuanzi_container_page_pv\"\u003e 本文总阅读量\u003cspan id=\"busuanzi_value_page_pv\"\u003e\u003c/span\u003e次 \u003c/span\u003e \u003c/div\u003e 站点访问量，访客数 打开以下路径在你喜欢的地方添加代码，\\blog\\hexo\\themes\\主题名字、layout\\_partial，找到 footer.ejs文件 \u003cscript src=\"//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js\" async defer\u003e\u003c/script\u003e \u003cspan id=\"busuanzi_container_page_pv\"\u003e 本站总访问量\u003cspan id=\"busuanzi_value_site_pv\"\u003e\u003c/span\u003e次 | \u003c/span\u003e \u003cspan id=\"busuanzi_container_site_uv\"\u003e 本站访客数\u003cspan id=\"busuanzi_value_site_uv\"\u003e\u003c/span\u003e人次 \u003c/span\u003e 2018.10.08 更新 不蒜子官网说七牛强制过期域名dn-lbstatics.qbox.me, 所以 js 文件位置发生改变，改为busuanzi.ibruce.info ","date":"2018-06-01","objectID":"/posts/hexobuild/:7:4","tags":["Node.js","hexo"],"title":"hexo+github 搭建个人博客及美化","uri":"/posts/hexobuild/"},{"categories":["Memo"],"content":"写文章 hexo 文章用轻量型标签语言 Markdown 编写 markdown 入门 繁体原始文件 繁体原始文件 github ","date":"2018-06-01","objectID":"/posts/hexobuild/:8:0","tags":["Node.js","hexo"],"title":"hexo+github 搭建个人博客及美化","uri":"/posts/hexobuild/"},{"categories":["Memo"],"content":" 如果实在搞得头晕直接去 简书 写文章，再把简书生成的 md 文章复制过来就好了（简书是个不错的 Markdown 在线编辑器），还可以去 马克飞象，专为印象笔记打造的 Markdown 编辑器，typora 也是不错的，突然发现 csdn 也支持 Markdown 编译器了 ","date":"2018-05-31","objectID":"/posts/hexowrite/:0:0","tags":["hexo"],"title":"hexo 添加图片，音乐，链接，视频","uri":"/posts/hexowrite/"},{"categories":["Memo"],"content":"1. 首先 刚刚搭博客，很多都不懂，就连插入图片的路径问题都把我整的要命。（我用的 Sublime Text 3 编译器） 下面讲讲： ","date":"2018-05-31","objectID":"/posts/hexowrite/:1:0","tags":["hexo"],"title":"hexo 添加图片，音乐，链接，视频","uri":"/posts/hexowrite/"},{"categories":["Memo"],"content":"1.1 设置站点配置_config.yml post_asset_folder: true ","date":"2018-05-31","objectID":"/posts/hexowrite/:1:1","tags":["hexo"],"title":"hexo 添加图片，音乐，链接，视频","uri":"/posts/hexowrite/"},{"categories":["Memo"],"content":"1.2 安装插件 npm install https://github.com/CodeFalling/hexo-asset-image -- save ","date":"2018-05-31","objectID":"/posts/hexowrite/:1:2","tags":["hexo"],"title":"hexo 添加图片，音乐，链接，视频","uri":"/posts/hexowrite/"},{"categories":["Memo"],"content":"1.3 下次再运行 hexo n “xxxx\"来生成 md 博文时，下路径 /source/_posts 文件夹内除了 xxxx.md 文件还有一个同名的文件夹，在 xxxx.md 中想引入图片时，先把图片复制到 xxxx 这个文件夹中，然后只需要在 xxxx.md 中按照 markdown 的格式引入图片。 ","date":"2018-05-31","objectID":"/posts/hexowrite/:1:3","tags":["hexo"],"title":"hexo 添加图片，音乐，链接，视频","uri":"/posts/hexowrite/"},{"categories":["Memo"],"content":"2. 添加图片 首先大家可以查看 hexo 官方文档 资源文件夹章节 ","date":"2018-05-31","objectID":"/posts/hexowrite/:2:0","tags":["hexo"],"title":"hexo 添加图片，音乐，链接，视频","uri":"/posts/hexowrite/"},{"categories":["Memo"],"content":"2.1 markdown 添加 相对路径添加（我被这个相对路径搞得要死，前面各种出错，大家可以对照我的来插入图片 …） #直接写图片名就好了，图片实例见下 ![kyrie irving](294136.jpg) #如果改了 Permalink 就要加上文章名，即同名文件夹名 ![kyrie irving](hexo-添加图片，音乐，链接，视频/294136.jpg) #代码压缩后前面还要加一个/ ![kyrie irving](/hexo-添加图片，音乐，链接，视频/294136.jpg) ","date":"2018-05-31","objectID":"/posts/hexowrite/:2:1","tags":["hexo"],"title":"hexo 添加图片，音乐，链接，视频","uri":"/posts/hexowrite/"},{"categories":["Memo"],"content":"2.2 插件添加 传送门 这种方式被很多人诟病，但有时候也不失一种好方式，简单快捷。 还有图片名字显示，不错的。 {% asset_img 297787.jpg kyrie irving %} ","date":"2018-05-31","objectID":"/posts/hexowrite/:2:2","tags":["hexo"],"title":"hexo 添加图片，音乐，链接，视频","uri":"/posts/hexowrite/"},{"categories":["Memo"],"content":"3. 音乐 大家可以看 网易云音乐 的官网，播放音乐可以生成外链，直接拿来用就行了。iframe 插件可以在代码中设置宽高等参数，auto 为自动播放。flash 不可以自己设置参数。看喜好，随便你。 其他音乐，把插件中的链接替换成要播放的链接就可以了 #iframe 插件 \u003ciframe frameborder=\"no\" border=\"0\" marginwidth=\"0\" marginheight=\"0\" width=330 height=86 src=\"//music.163.com/outchain/player?type=2\u0026id=66651\u0026auto=0\u0026height=66\"\u003e \u003c/iframe\u003e #flash 插件 \u003cembed src=\"//music.163.com/style/swf/widget.swf?sid=40249713\u0026type=2\u0026auto=0\u0026width=320\u0026height=66\" width=\"340\" height=\"86\" allowNetworking=\"all\"\u003e \u003c/embed\u003e ","date":"2018-05-31","objectID":"/posts/hexowrite/:3:0","tags":["hexo"],"title":"hexo 添加图片，音乐，链接，视频","uri":"/posts/hexowrite/"},{"categories":["Memo"],"content":"4. 添加链接 [我的微博](https://weibo.com/liahao) {% link text url title %} ","date":"2018-05-31","objectID":"/posts/hexowrite/:4:0","tags":["hexo"],"title":"hexo 添加图片，音乐，链接，视频","uri":"/posts/hexowrite/"},{"categories":["Memo"],"content":"5. 添加视频 视频链接最好是打开就是视频的链接（youku，YouTube，抖音等） 可以把视频上传到优酷，抖音等生成外链再拿来用。（优酷上传需要注册和实名认证） 插件参考资料 自拍手写视频（优酷） 实验室无聊拍的 \u003ciframe height=500 width=100% src=\"https://player.youku.com/embed/XMzY0MzgxNDMyOA==\" frameborder=0 allowfullscreen\u003e \u003c/iframe\u003e ","date":"2018-05-31","objectID":"/posts/hexowrite/:5:0","tags":["hexo"],"title":"hexo 添加图片，音乐，链接，视频","uri":"/posts/hexowrite/"},{"categories":["Memo"],"content":"工具集合 Picgo 马克飞象、CSDN、简书 SM.MS 图床 ","date":"2018-05-31","objectID":"/posts/hexowrite/:6:0","tags":["hexo"],"title":"hexo 添加图片，音乐，链接，视频","uri":"/posts/hexowrite/"},{"categories":["随笔"],"content":" “每天早晨叫醒你的不是鬧鐘，而是你的夢想。” 我有過靠著這種信念撐下來的日子，我見過自己努力的樣子，至於現在的自己配不配得上當初努力的自己， 其實也不重要了，還望披荊斬棘，不改初心。 不怕萬人阻擋，只怕自己投降。你如何回憶，決定你是一個怎樣的人！ 從大一伊始，打 ACM 比賽，訓練刷題，再到毅然決然離開實驗室，選擇陌生的 Web 開發，從工作前的一無所知到，到前端開發，後端開發，到教實習生，到面試新人，到開始乏味。這一路走來，好奇心，探索欲，瞎擇騰，或許還有愛意，都是支撐我的動力。 時間並不會因為你的迷茫和遲疑而停留，就像你在看到這篇博客的時候，不知道有多少人正風雨兼程趕赴夢想。沒有誰生來就是神牛，千裏之行，始於足下！比自己優秀的人有很多，永遠不要感動自己，保持謙遜，沉澱自己，感謝每一個曾經努力的自己。不必執著於過去，也不必過度擔憂未來，望披荊斬棘，不忘初心。 最開始寫博客，是在打 ACM 的時候，深受一個學長的博客影響，他的博客是 hexo 搭建的，ID 是 [戎碼一生]，所以我也照葫蘆畫瓢用 hexo 搭建了一個，一用就是 3 年，博客名字原 “博採眾長” 改为 “菠菜眾長”，因為不能用成語作為網站名字，就這個原因。 直到 21 年下半年，升級 windows 11, 系統出了 BUG, 整理磁盤不小心把代碼刪掉了，就乾脆換成 hugo 了。 現在並沒有刀槍入庫，馬放南山，衹是在奔赴另一片山海 ","date":"2018-05-28","objectID":"/posts/hello-world/:0:0","tags":["随笔"],"title":"Hello World","uri":"/posts/hello-world/"},{"categories":null,"content":"离线 - 菠菜眾長","date":"0001-01-01","objectID":"/offline/","tags":null,"title":"","uri":"/offline/"}]