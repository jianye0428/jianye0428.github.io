<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>yejian's blog</title><link>https://jianye0428.github.io/</link><description>Lruihao's Note 李瑞豪的博客：探索、分享、记录自己在工作生活学习到一些东西。人知道得越多，就就会发现无知的越多。有更广袤世界可以探索，真是莫大的快乐啊！</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>18817571704@163.com (Jian YE)</managingEditor><webMaster>18817571704@163.com (Jian YE)</webMaster><lastBuildDate>Sun, 30 Jul 2023 09:21:58 +0800</lastBuildDate><atom:link href="https://jianye0428.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Effective STL [11] | 理解自定义分配器的正确用法</title><link>https://jianye0428.github.io/posts/clause_11/</link><pubDate>Sun, 30 Jul 2023 09:21:58 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/clause_11/</guid><description><![CDATA[<!-- <div class="details admonition quote">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-quote-right fa-fw" aria-hidden="true"></i>quote<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">note abstract info tip success question warning failure danger bug example quote</div>
    </div>
  </div> -->
<h2 id="自定义分配器">自定义分配器</h2>
<p>很多时候，你会有建立自定义分配器的想法：</p>
<ul>
<li><code>allocator&lt;T&gt;</code>对线程安全采取了措拖，但是你只对单线程的程序感兴趣，你不想花费不需要的同步开销</li>
<li>在某些容器里的对象通常一同被使用，所以你想在一个特别的堆里把它们放得很近使引用的区域性最大化</li>
<li>你想建立一个相当共享内存的唯一的堆，然后把一个或多个容器放在那块内存里，因为这样它们可以被其他进程共享。</li>
</ul>
<h3 id="管理共享内存">管理共享内存</h3>
<p>假定你有仿效<code>malloc</code>和<code>free</code>的特别程序，用于管理共享内存的堆</p>
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">void</span><span class="o">*</span> <span class="nf">mallocShared</span><span class="p">(</span><span class="n">size_t</span> <span class="n">bytesNeeded</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">freeShared</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">ptr</span><span class="p">);</span></span></span></code></pre></td></tr></table>
</div>
</div><p>并且你希望能把STL容器的内容放在共享内存中:</p>
<div class="highlight" id="id-2"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span> <span class="n">T</span><span class="o">&gt;</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">SharedMemoryAllocator</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl"><span class="p">...</span>
</span></span><span class="line"><span class="cl">    <span class="n">pointer</span> <span class="n">allocate</span><span class="p">(</span><span class="n">size_type</span> <span class="n">numObiects</span><span class="p">,</span> <span class="k">const</span> <span class="kt">void</span> <span class="o">*</span><span class="n">localityHint</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="k">static_cast</span><span class="o">&lt;</span><span class="n">pointer</span><span class="o">&gt;</span><span class="p">(</span><span class="n">mallocShared</span><span class="p">(</span><span class="n">numObiects</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">T</span><span class="p">)));</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="kt">void</span> <span class="nf">deallocate</span><span class="p">(</span><span class="n">pointer</span> <span class="n">ptrToMemory</span><span class="p">,</span> <span class="n">size_type</span> <span class="n">numObjects</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">freeShared</span><span class="p">(</span><span class="n">ptrToMiemory</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">...</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span></span></span></code></pre></td></tr></table>
</div>
</div><p>使用<code>SharedMemoryAllocator</code>：</p>
<div class="highlight" id="id-3"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="c1">// 方便的typedef
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">typedef</span> <span class="n">vector</span><span class="o">&lt;</span><span class="kt">double</span><span class="p">,</span> <span class="n">SharedMemoryAllocator</span><span class="o">&lt;</span><span class="kt">double</span><span class="o">&gt;</span> <span class="o">&gt;</span>
</span></span><span class="line"><span class="cl"><span class="n">SharedDoubleVec</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">...</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span> <span class="c1">// 开始一个块
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">SharedDoubleVec</span> <span class="n">v</span><span class="p">;</span> <span class="c1">// 建立一个元素在
</span></span></span><span class="line"><span class="cl"><span class="c1">// 共享内存中的vector
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">...</span> <span class="c1">// 结束这个块
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div><p>「问题：」<strong>v</strong>使用<code>SharedMemoryAllocator</code>，所以<strong>v</strong>分配来容纳它元素的内存将来自共享内存，但<strong>v本身——包括它的全部数据成员——几乎将肯定不被放在共享内存里，v只是一个普通的基于堆的对象，所以它将被放在运行时系统为所有普通的基于堆的对象使用的任何内存</strong>。那几乎不会是共享内存。</br></p>
<p>为了把v的内容和v本身放进共享内存，必须这么做:</p>
<div class="highlight" id="id-4"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">void</span> <span class="o">*</span><span class="n">pVectorMemory</span> <span class="o">=</span> <span class="n">mallocShared</span><span class="p">(</span><span class="k">sizeof</span><span class="p">(</span><span class="n">SharedDoubleVec</span><span class="p">));</span><span class="c1">// 分配足够的共享内存来容纳一个SharedDoubleVec对象
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">SharedDoubleVec</span> <span class="o">*</span><span class="n">pv</span> <span class="o">=</span> <span class="k">new</span> <span class="p">(</span><span class="n">pVectorMemory</span><span class="p">)</span> <span class="n">SharedDoubleVec</span><span class="p">;</span> <span class="c1">// 使用“placement new”来 在那块内存中建立 一个SharedDoubleVec对象；
</span></span></span><span class="line"><span class="cl"><span class="c1">// 参见下面这个对象的使用（通过pv）
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">...</span>
</span></span><span class="line"><span class="cl"><span class="n">pv</span><span class="o">-&gt;~</span><span class="n">SharedDoubleVec</span><span class="p">();</span> <span class="c1">// 销毁共享内存中的对象
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">freeShared</span><span class="p">(</span><span class="n">pVectorMemory</span><span class="p">);</span> <span class="c1">// 销毁原来的共享内存块
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>这就是<code>「手工的四步分配/建造/销毁/回收的过程」</code>：获得一些共享内存 <code>——&gt;</code> 在里面建立一个用共享内存为自己内部分配的vector <code>——&gt;</code> 用完这个vector时，调用它的析构函数 <code>——&gt;</code> 释放vector占用的内存。</p>
<p>这段代码有2点需要注意：</p>
<ul>
<li>
<p>忽略了<code>mallocShared</code>可能返回一个null指针。</p>
</li>
<li>
<p>共享内存中的vector的建立由“placement new”完成。</p>
</li>
</ul>
<h3 id="管理分配和回收的堆">管理分配和回收的堆</h3>
<p>假设有2个堆，类<code>Heap1</code>和<code>Heap2</code>。</p>
<p>每个堆类有用于进行「分配」和「回收」的「静态成员函数」：</p>
<div class="highlight" id="id-5"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Heap1</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl"><span class="p">...</span>
</span></span><span class="line"><span class="cl">    <span class="k">static</span> <span class="kt">void</span><span class="o">*</span> <span class="n">alloc</span><span class="p">(</span><span class="n">size_t</span> <span class="n">numBytes</span><span class="p">,</span> <span class="k">const</span> <span class="kt">void</span> <span class="o">*</span><span class="n">memoryBlockToBeNear</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">static</span> <span class="kt">void</span> <span class="nf">dealloc</span><span class="p">(</span><span class="kt">void</span> <span class="o">*</span><span class="n">ptr</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">...</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Heap2</span> <span class="p">{</span> <span class="p">...</span> <span class="p">};</span> <span class="c1">// 有相同的alloc/dealloc接口
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>你想在不同的堆里联合定位一些STL容器的内容。</p>
<p>首先，设计一个分配器，使用像Heap1和Heap2那样用于真实内存管理的类：</p>
<div class="highlight" id="id-6"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">template</span><span class="o">&lt;</span><span class="n">typenameT</span><span class="p">,</span> <span class="k">typename</span> <span class="n">Heap</span><span class="o">&gt;</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">SpecificHeapAllocator</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">pointer</span> <span class="n">allocate</span><span class="p">(</span><span class="n">size_type</span> <span class="n">numObjects</span><span class="p">,</span> <span class="k">const</span> <span class="kt">void</span> <span class="o">*</span><span class="n">localityHint</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="k">static_cast</span><span class="o">&lt;</span><span class="n">pointer</span><span class="o">&gt;</span><span class="p">(</span><span class="n">Heap</span><span class="o">::</span><span class="n">alloc</span><span class="p">(</span><span class="n">numObjects</span> <span class="o">*</span> <span class="k">sizeof</span><span class="p">(</span><span class="n">T</span><span class="p">),</span> <span class="n">localityHint</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="kt">void</span> <span class="nf">deallocate</span><span class="p">(</span><span class="n">pointer</span> <span class="n">ptrToMemory</span><span class="p">,</span> <span class="n">size_type</span> <span class="n">numObjects</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">Heap</span><span class="o">::</span><span class="n">dealloc</span><span class="p">(</span><span class="n">ptrToMemory</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">...</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span></span></span></code></pre></td></tr></table>
</div>
</div><p>然后，使用<code>SpecificHeapAllocator</code>来把容器的元素集合在一起：</p>
<div class="highlight" id="id-7"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="n">SpecificHeapAllocator</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="n">Heap1</span> <span class="o">&gt;&gt;</span> <span class="n">v</span><span class="p">;</span> <span class="c1">// 把v和s的元素放进Heap1
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">set</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="n">SpecificHeapAllocator</span><span class="o">&lt;</span><span class="kt">int</span> <span class="n">Heap1</span> <span class="o">&gt;&gt;</span> <span class="n">s</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">list</span><span class="o">&lt;</span><span class="n">Widget</span><span class="p">,</span> <span class="n">SpecificHeapAllocator</span><span class="o">&lt;</span><span class="n">Widget</span><span class="p">,</span> <span class="n">Heap2</span><span class="o">&gt;&gt;</span> <span class="n">L</span><span class="p">;</span> <span class="c1">// 把L和m的元素 放进Heap2
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">map</span><span class="o">&lt;</span><span class="kt">int</span><span class="p">,</span> <span class="n">string</span><span class="p">,</span> <span class="n">less</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">SpecificHeapAllocator</span><span class="o">&lt;</span><span class="n">pair</span><span class="o">&lt;</span><span class="k">const</span> <span class="kt">int</span><span class="p">,</span> <span class="n">string</span><span class="o">&gt;</span><span class="p">,</span> <span class="n">Heap2</span><span class="o">&gt;&gt;</span> <span class="n">m</span><span class="p">;</span></span></span></code></pre></td></tr></table>
</div>
</div><p>在这个例子里，很重要的一点是「<strong>Heap1和Heap2是类型而不是对象</strong>」。</p>
<p>STL为用不同的分配器对象初始化相同类型的不同STL容器提供了语法。那是「<strong>因为如果Heap1和Heap2是对象而不是类型，那么它们将是不等价的分配器，那就违反了分配器的等价约束</strong>」。</p>
<p>只要遵循「<strong>相同类型的所有分配器都一定等价的限制条件</strong>」，你将毫不费力地使用自定义分配器来「<strong>控制一般内存管理策略，群集关系和使用共享内存以及其他特殊的堆</strong>」。</p>]]></description></item><item><title>Effective C++ (第3版) 精读总结 [1]</title><link>https://jianye0428.github.io/posts/partone/</link><pubDate>Sat, 29 Jul 2023 18:51:19 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/partone/</guid><description><![CDATA[<h1 id="序言">序言</h1>
<p>这本C++的经典之作，作者是大佬<code>Scott Meyers</code>👉<a href="https://www.aristeia.com/books.html"target="_blank" rel="external nofollow noopener noreferrer">大佬主页<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>，还写过其他几本影响深远的C++经典，例如<code>《Effective STL》</code>,<code>《More Effective C++》</code>,<code>《Effective Mordern C++》</code>,<code>《Overview of the New C++(C++11/14)》</code>等等。本人看的是中文版，侯捷老师翻译的，精读分析并实践推敲后，整理成博客记录下来。</p>
<blockquote>
<p>(Effective-C++总结系列分为四部分，本文为第一部分，涉及原书第1~2章，内容范围Rule01~12。为方便书写，Rule01简写为R01)。</p>
</blockquote>
<div class="details admonition Note">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Effective-C++系列List<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">本博客站点系列内容如下：</br>
💡 <a href="https://jianye0428.github.io/posts/partone/"target="_blank" rel="external nofollow noopener noreferrer">Effective C++(第3版)精读总结(一)<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
💡 Effective C++(第3版)精读总结(二)</br>
💡 Effective C++(第3版)精读总结(三)</br>
💡 Effective C++(第3版)精读总结(四)</br></div>
    </div>
  </div>
<h1 id="ch1让自己习惯c">CH1.让自己习惯C++</h1>
<h2 id="r01-视c为一个语言联邦">R01 视C++为一个语言联邦</h2>
<p>如今的C++已经是个多重范式(multiparadigm)语言，同时支持面向过程形式、面向对象形式、函数形式、泛型形式、元编程形式。 要理解这么多特性，可以简单的归结为<code>四种次语言</code>(sublanguage)组成：</p>
<ul>
<li><strong>C语言：</strong><code>C++仍以C为基础</code>。C++是C的超集，区块 、语句、预处理、内置数据类型、数组、指针等全部来自于C语言；
<ul>
<li>说到底 C++ 仍然以 C 为基础。区块、语句、预处理器、内置数据类型 、数组、指针等统统来自C，许多时候C++对问题的解决其实不过就是较高级的 C 解法，但当你C++内的 C 成分工作时，高效编程守则映照出 C 语言的局限：没有模板(template) ，没有异常(exceptions)，没有重载(overloading)……</li>
</ul>
</li>
<li><strong>Object-Oriented C++:</strong> 面向对象特性。这部分也就是 C with classes 所诉求的：classes(包括构造函数和析构函数)，封装(encapsulation)、继承(inheritance)、多态(polymorhpism)、virtual函数(动态绑定)……等等，这一部分是面向对象设计之古典守则在C++ 上的直接实施。</li>
<li>**Template C++:**C++的泛型(generic)编程的部分，也带来了黑魔法-模板元编程(TMP,Metaprogramming)；</li>
<li>**STL：**STL(Standard Temlate Library)即标准模板库，它是template程序库。封装了各类容器(container)、配置器(allocator)、迭代器(iterator)、算法以及常用对象。</li>
</ul>
<p><strong>总结:</strong>
C++高效编程守则视状况而变化，取决于你使用C++的哪一部分</p>
<h2 id="r02-尽量以constenuminline替换define">R02 尽量以<code>const</code>,<code>enum</code>,<code>inline</code>替换<code>#define</code></h2>
<ul>
<li><strong>对于宏定义的常量，建议用const常量或者枚举enum替换</strong>
这样做的好处是方便调试，因为宏报错就是个常数值，没有符号表；并且宏不具有封装性(宏的作用域是在编译时是其定义之事)。
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="c1">// 举例：MAX_DATA_COUNT在预处理阶段就会被替换，编译器不会见到它，所以一旦有相关报错，给的是100这个值
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="cp">#define MAX_DATA_COUNT   100
</span></span></span><span class="line"><span class="cl"><span class="cp"></span><span class="k">const</span>  <span class="kt">int</span> <span class="n">MAX_DATA_COUNT</span> <span class="o">=</span> <span class="mi">100</span> <span class="p">;</span><span class="c1">//常量只有一份，宏会导致多份常量值
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">class</span> <span class="nc">Buffer</span><span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span><span class="c1">//...类其他部分省略
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">static</span> <span class="k">const</span> <span class="kt">double</span> <span class="n">factor_</span> <span class="p">;</span><span class="c1">//static常量,类内声明
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">static</span> <span class="k">const</span> <span class="kt">int</span>  <span class="n">times_</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span><span class="c1">// int类型允许类内初始化,规范上还是建议拿到类外
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">private</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">static</span> <span class="k">const</span>  <span class="kt">int</span> <span class="n">ArrLength</span> <span class="o">=</span> <span class="mi">5</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">arr</span><span class="p">[</span><span class="n">ArrLength</span><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span>
</span></span><span class="line"><span class="cl"><span class="k">const</span> <span class="kt">double</span> <span class="n">Buffer</span><span class="o">::</span><span class="n">factor_</span>  <span class="o">=</span> <span class="mf">0.1</span><span class="p">;</span><span class="c1">//类外初始化,一般写在实现文件*.cpp,*.cc中
</span></span></span></code></pre></td></tr></table>
</div>
</div>如果编译器不允许声明时&quot;in-class初值设定&quot;,如果是整形常量，可以让枚举值来替代，而且<font color=red><code>枚举值不能被取地址</code></font>。</li>
<li><strong>对于宏定义的函数，建议用内联inline函数替换</strong>
宏函数没办法单行debug调试，而内联函数可以；
宏的写法即使小心翼翼的加好了括号，也可能造成意想不到的<font color=red><code>宏函数重复计算</code></font>的问题。
<div class="highlight" id="id-2"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="cp">#define  GET_MAX(a,b)   ((a)&gt;(b) ? (a) :(b))
</span></span></span><span class="line"><span class="cl"><span class="cp"></span><span class="kt">int</span> <span class="n">a</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">GET_MAX</span><span class="p">(</span><span class="o">++</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">);</span>    <span class="c1">// a累加二次
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">GET_MAX</span><span class="p">(</span><span class="o">++</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="o">+</span><span class="mi">10</span><span class="p">);</span> <span class="c1">// a累加一次
</span></span></span><span class="line"><span class="cl"><span class="c1">// 定义个inline函数就不会有这个问题,(a,b)作为函数入参就只会计算一次
</span></span></span></code></pre></td></tr></table>
</div>
</div><div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>By the way<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content"><p>上述情况，从纯C语言角度，想避免“宏函数重复计算”，其实还有个方法，就是使用GNU C 扩展的 typeof 或 GCC 的 <code>__auto_type</code> 关键字，详细可参考GCC官方文档页面。2者都适用于GCC和Clang，都不适用MSVC），示例如下：</p>
<div class="highlight" id="id-3"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="cp">#define  GET_MAX_ONCE(a,b) \
</span></span></span><span class="line"><span class="cl"><span class="cp">      ( {typeof(a) _a = (a);   \
</span></span></span><span class="line"><span class="cl"><span class="cp">         typeof(b) _b = (b);   \
</span></span></span><span class="line"><span class="cl"><span class="cp">         (_a) &gt; (_b) ? (_a) : (_b); } )</span></span></span></code></pre></td></tr></table>
</div>
</div><p>测试代码如下：</p>
<div class="highlight" id="id-4"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-C" data-lang="C"><span class="line"><span class="cl"><span class="kt">int</span> <span class="n">a</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span><span class="n">b</span> <span class="o">=</span> <span class="mi">20</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="kt">int</span> <span class="n">c</span> <span class="o">=</span> <span class="nf">GET_MAX</span><span class="p">(</span><span class="o">++</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="o">++</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&#34;a = &#34;</span> <span class="o">&lt;&lt;</span> <span class="n">a</span> <span class="o">&lt;&lt;</span> <span class="s">&#34;, b = &#34;</span><span class="o">&lt;&lt;</span> <span class="n">b</span> <span class="o">&lt;&lt;</span> <span class="s">&#34;, c = &#34;</span> <span class="o">&lt;&lt;</span> <span class="n">c</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">a</span> <span class="o">=</span> <span class="mi">10</span> <span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="mi">20</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">c</span> <span class="o">=</span> <span class="nf">GET_MAX_ONCE</span><span class="p">(</span><span class="o">++</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="o">++</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">std</span><span class="o">::</span><span class="n">cout</span> <span class="o">&lt;&lt;</span> <span class="s">&#34;a = &#34;</span> <span class="o">&lt;&lt;</span> <span class="n">a</span> <span class="o">&lt;&lt;</span> <span class="s">&#34;, b = &#34;</span><span class="o">&lt;&lt;</span> <span class="n">b</span> <span class="o">&lt;&lt;</span> <span class="s">&#34;, c = &#34;</span> <span class="o">&lt;&lt;</span> <span class="n">c</span> <span class="o">&lt;&lt;</span> <span class="n">std</span><span class="o">::</span><span class="n">endl</span><span class="p">;</span></span></span></code></pre></td></tr></table>
</div>
</div><p>测试代码输出：</p>
<div class="highlight" id="id-5"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl"><span class="nv">a</span> <span class="o">=</span> 11, <span class="nv">b</span> <span class="o">=</span> 22, <span class="nv">c</span> <span class="o">=</span> <span class="m">21</span>
</span></span><span class="line"><span class="cl"><span class="nv">a</span> <span class="o">=</span> 11, <span class="nv">b</span> <span class="o">=</span> 21, <span class="nv">c</span> <span class="o">=</span> <span class="m">20</span></span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>🤔 <code>使用 __auto_type</code> 来取代时要赋初值，关键的 typeof 那行用法改为<code>__auto_type _a = (a);</code> 。
__auto_type 比 typeof 的优势之处在于面对变长数组(VLA)，只解析1次；以及面对嵌套宏定义时也是只严格解析一次。</p>
</blockquote>
</div>
    </div>
  </div></li>
</ul>
<p>ref:
[1]. <a href="https://blog.csdn.net/cltcj/category_12098441.html"target="_blank" rel="external nofollow noopener noreferrer">https://blog.csdn.net/cltcj/category_12098441.html<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
[2]. <a href="https://kissingfire123.github.io/2021/12/06_effective-c-%e4%b9%8b%e5%ad%a6%e4%b9%a0%e6%80%bb%e7%bb%93%e4%b8%80/"target="_blank" rel="external nofollow noopener noreferrer">https://kissingfire123.github.io/2021/12/06_effective-c-%e4%b9%8b%e5%ad%a6%e4%b9%a0%e6%80%bb%e7%bb%93%e4%b8%80/<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>]]></description></item><item><title>Effective STL [9] | 在删除选项中仔细选择</title><link>https://jianye0428.github.io/posts/clause_9/</link><pubDate>Fri, 28 Jul 2023 07:59:27 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/clause_9/</guid><description><![CDATA[<!-- <div class="details admonition quote">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-quote-right fa-fw" aria-hidden="true"></i>quote<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">note abstract info tip success question warning failure danger bug example quote</div>
    </div>
  </div> -->
<h2 id="删除指定值对象">删除指定值对象</h2>
<p>假定你有一个容纳<code>int</code>标准STL容器:</p>
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">Container</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">c</span><span class="p">;</span></span></span></code></pre></td></tr></table>
</div>
</div><p>而你想把c中所有值为2023的对象都去掉。</p>
<p>令人吃惊的是，完成这项任务的方法因不同的容器类型而不同：没有一种方法是通用的。</p>
<ul>
<li>当c是连续内存容器（vector、deque或string），最好的方法是erase-remove惯用法</li>
</ul>
<div class="highlight" id="id-2"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">c</span><span class="p">.</span><span class="n">erase</span><span class="p">(</span><span class="n">remove</span><span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">c</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span> <span class="mi">2023</span><span class="p">),</span> <span class="n">c</span><span class="p">.</span><span class="n">end</span><span class="p">());</span>
</span></span><span class="line"><span class="cl"><span class="c1">// 当c是vector、string或deque时，
</span></span></span><span class="line"><span class="cl"><span class="c1">// erase-remove惯用法是去除特定值的元素的最佳方法
</span></span></span></code></pre></td></tr></table>
</div>
</div><div class="details admonition Note">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content"><ul>
<li>STL 和 vector中的remove的作用是<strong>将等于value的元素放到vector的尾部</strong>，但并不减少vector的size；</li>
<li>vector中erase的作用是删除掉某个位置position或一段区域(begin, end)中的元素，减少其size，返回被删除元素下一个元素的位置。</li>
</ul>
</div>
    </div>
  </div>
<ul>
<li>这方法也适合于<code>list</code>，但是<code>list</code>的成员函数<code>remove</code>更高效：</li>
</ul>
<div class="highlight" id="id-3"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="c1">// 当c是list时，remove成员函数是去除特定值的元素的最佳方法
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">c</span><span class="p">.</span><span class="n">remove</span><span class="p">(</span><span class="mi">1963</span><span class="p">);</span></span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>当c是标准关联容器（即<code>set</code>、<code>multiset</code>、<code>map</code>或<code>multimap</code>）时，使用任何叫做<code>remove</code>的东西都是完全错误的。这样的容器没有叫做remove的成员函数，而且使用remove算法可能覆盖容器值，潜在地破坏容器。对于关联容器，解决问题的适当方法是调用erase：</li>
</ul>
<div class="highlight" id="id-4"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="c1">// 当c是标准关联容器时,erase成员函数是去除特定值的元素的最佳方法
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">c</span><span class="p">.</span><span class="n">erase</span><span class="p">(</span><span class="mi">2023</span><span class="p">);</span></span></span></code></pre></td></tr></table>
</div>
</div><p>这很高效，只花费对数时间，<strong>序列容器的基于删除的技术需要线性时间</strong>。并且，关联容器的<code>erase</code>成员函数有基于等价而不是相等的优势。</p>
<h2 id="消除判断式">消除判断式</h2>
<p>消除下面判断式，返回真的每个对象:</p>
<div class="highlight" id="id-5"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">bool</span> <span class="nf">badValue</span><span class="p">(</span><span class="kt">int</span> <span class="n">x</span><span class="p">);</span> <span class="c1">// 返回x是否是“bad”
</span></span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>对于序列容器（<code>vector</code>、<code>string</code>、<code>deque</code>和<code>list</code>），把每个<code>remove</code>替换为<code>remove_if</code>：</li>
</ul>
<div class="highlight" id="id-6"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">c</span><span class="p">.</span><span class="n">erase</span><span class="p">(</span><span class="n">remove_if</span><span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">c</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span> <span class="n">badValue</span><span class="p">),</span> <span class="c1">// 当c是vector、string或deque时
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">c</span><span class="p">.</span><span class="n">end</span><span class="p">());</span> <span class="c1">// 这是去掉badValue返回真的对象的最佳方法
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl"><span class="n">c</span><span class="p">.</span><span class="n">remove_if</span><span class="p">(</span><span class="n">badValue</span><span class="p">);</span> <span class="c1">// 当c是list时这是去掉badValue返回真的对象的最佳方法
</span></span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>对于标准关联容器，有两种方法处理该问题，一个更容易编码，另一个更高效。</li>
</ul>
<div class="highlight" id="id-7"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">AssocContainer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">c</span><span class="p">;</span> <span class="c1">// c现在是一种标准关联容器
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl"><span class="n">AssocContainer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">goodValues</span><span class="p">;</span> <span class="c1">// 用于容纳不删除的值的临时容器
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl"><span class="n">remove_copy_if</span><span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">c</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span><span class="n">inserter</span><span class="p">(</span><span class="n">goodValues</span><span class="p">,</span> <span class="n">goodValues</span><span class="p">.</span><span class="n">end</span><span class="p">()),</span> <span class="n">badValue</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">c</span><span class="p">.</span><span class="n">swap</span><span class="p">(</span><span class="n">goodValues</span><span class="p">);</span> <span class="c1">// 交换c和goodValues的内容
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>对这种方法的<strong>缺点</strong>是它拷贝了所有不删除的元素。</p>
<p>因为关联容器没有提供类似<code>remove_if</code>的成员函数，所以必须写一个循环来迭代c中的元素，和原来一样删除元素。不幸的是，那些正确工作的代码很少是跃出脑海的代码。例如，这是很多程序员首先想到的：</p>
<div class="highlight" id="id-8"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">AssocContainer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">c</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">...</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="p">(</span><span class="n">AssocContainer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;::</span><span class="n">iterator</span> <span class="n">i</span> <span class="o">=</span> <span class="n">c</span><span class="p">.</span><span class="n">begin</span><span class="p">();</span> <span class="n">i</span><span class="o">!=</span> <span class="n">c</span><span class="p">.</span><span class="n">end</span><span class="p">();</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>  <span class="c1">// 清晰，直截了当而漏洞百出的,用于删除c中badValue返回真的每个元素的代码
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">if</span> <span class="p">(</span><span class="n">badValue</span><span class="p">(</span><span class="o">*</span><span class="n">i</span><span class="p">))</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">c</span><span class="p">.</span><span class="n">erase</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span> <span class="c1">// 不要这么做！
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>这有未定义的行为。当容器的一个元素被删时，<strong>指向那个元素的所有迭代器都失效了</strong>。</p>
<p>当<code>c.erase(i)</code>返回时，<code>i</code>已经失效。那对于这个循环是个坏消息，因为在<code>erase</code>返回后，<code>i</code>通过for循环的<code>++i</code>部分自增。为了避免这个问题，我们必须保证在调用<code>erase</code>之前就得到了c中下一元素的迭代器。最容易的方法是当我们调用时在i上使用后置递增：</p>
<div class="highlight" id="id-9"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">AssocContainer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">c</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">...</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="p">(</span><span class="n">AssocContainer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;::</span><span class="n">iterator</span> <span class="n">i</span> <span class="o">=</span> <span class="n">c</span><span class="p">.</span><span class="n">begin</span><span class="p">();</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">c</span><span class="p">.</span><span class="n">end</span><span class="p">();</span><span class="cm">/*nothing*/</span> <span class="p">){</span><span class="c1">// for循环的第三部分是空的；i现在在下面自增
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">if</span> <span class="p">(</span><span class="n">badValue</span><span class="p">(</span><span class="o">*</span><span class="n">i</span><span class="p">))</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">c</span><span class="p">.</span><span class="n">erase</span><span class="p">(</span><span class="n">i</span><span class="o">++</span><span class="p">);</span> <span class="c1">// 对于坏的值，把当前的i传给erase，然后作为副作用增加i；
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="o">++</span><span class="n">i</span><span class="p">;</span> <span class="c1">// 对于好的值，只增加i
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div><p>精髓的地方在于：这种调用<code>erase</code>的解决方法可以工作，因为表达式i++的值是i的旧值，但作为副作用，i增加了。</p>
<p>因此，我们把i的旧值（没增加的）传给<code>erase</code>，但在<code>erase</code>开始执行前i已经自增了。</p>
<p>现在不仅删除<code>badValue</code>返回真的每个元素，而且每当一个元素被删掉时，我们也想把一条消息写到日志文件中。</p>
<ul>
<li>可以通过<strong>直接从原容器删除元素来避开拷贝</strong>。</li>
<li>“更容易但效率较低”的解决方案用<code>remove_copy_if</code><strong>把需要的值拷贝到一个新容器中，然后把原容器的内容和新的交换</strong>：</li>
</ul>
<p>对于<strong>关联容器</strong>，这说多容易就有多容易，因为只需要对刚才开发的循环做一个微不足道的修改就行了：</p>
<div class="highlight" id="id-10"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">ofstream</span> <span class="n">logFile</span><span class="p">;</span> <span class="c1">// 要写入的日志文件
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">AssocContainer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">c</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">...</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="p">(</span><span class="n">AssocContainer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;::</span><span class="n">iterator</span> <span class="n">i</span> <span class="o">=</span> <span class="n">c</span><span class="p">.</span><span class="n">begin</span><span class="p">();</span> <span class="n">i</span> <span class="o">!=</span><span class="n">c</span><span class="p">.</span><span class="n">end</span><span class="p">();){</span><span class="c1">// 循环条件和前面一样
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">if</span> <span class="p">(</span><span class="n">badValue</span><span class="p">(</span><span class="o">*</span><span class="n">i</span><span class="p">)){</span>
</span></span><span class="line"><span class="cl">        <span class="n">logFile</span> <span class="o">&lt;&lt;</span> <span class="s">&#34;Erasing &#34;</span> <span class="o">&lt;&lt;</span> <span class="o">*</span><span class="n">i</span> <span class="o">&lt;&lt;</span><span class="sc">&#39;\n&#39;</span><span class="p">;</span> <span class="c1">// 写日志文件
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="n">c</span><span class="p">.</span><span class="n">erase</span><span class="p">(</span><span class="n">i</span><span class="o">++</span><span class="p">);</span> <span class="c1">// 删除元素
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="o">++</span><span class="n">i</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div><p>现在是<code>vector</code>、<code>string</code>和<code>deque</code>不能再使用<code>erase-remove</code>惯用法，因为没有办法让<code>erase</code>或<code>remove</code>写日志文件。</p>
<p>而且，我们不能使用刚刚为关联容器开发的循环，因为它为<code>vector</code>、<code>string</code>和<code>deque</code>产生未定义的行为！</p>
<p>要记得对于那样的容器，<strong>调用<code>erase</code>不仅使所有指向被删元素的迭代器失效，也使被删元素之后的所有迭代器失效</strong>。</p>
<p>包括所有i之后的迭代器。我们写<code>i++</code>，<code>++i</code>或你能想起的其它任何东西都没有用，因为没有能导致迭代器有效的。必须利用erase的返回值。那个返回值正是我们需要的：<strong>一旦删除完成，它就是指向紧接在被删元素之后的元素的有效迭代器。</strong></p>
<p>我们这么写：</p>
<div class="highlight" id="id-11"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">for</span> <span class="p">(</span><span class="n">SeqContainer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;::</span><span class="n">iterator</span> <span class="n">i</span> <span class="o">=</span> <span class="n">c</span><span class="p">.</span><span class="n">begin</span><span class="p">();</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">c</span><span class="p">.</span><span class="n">end</span><span class="p">();){</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">badValue</span><span class="p">(</span><span class="o">*</span><span class="n">i</span><span class="p">)){</span>
</span></span><span class="line"><span class="cl">        <span class="n">logFile</span> <span class="o">&lt;&lt;</span> <span class="s">&#34;Erasing &#34;</span> <span class="o">&lt;&lt;</span> <span class="o">*</span><span class="n">i</span> <span class="o">&lt;&lt;</span> <span class="sc">&#39;\n&#39;</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">i</span> <span class="o">=</span> <span class="n">c</span><span class="p">.</span><span class="n">erase</span><span class="p">(</span><span class="n">i</span><span class="p">);</span> <span class="c1">// 通过把erase的返回值
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="p">}</span> <span class="c1">// 赋给i来保持i有效
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">       <span class="o">++</span><span class="n">i</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div><p><strong><font color=blue>这可以很好地工作，但只用于标准序列容器</font></strong>。</p>
<p>标准关联容器的<code>erase</code>的返回类型是<code>void</code>。对于那些容器，你必须使用“<strong>后置递增你要传给erase的迭代器</strong>”技术。为了避免你奇怪<code>list</code>的适当方法是什么，事实表明对于迭代和删除，你可以像<code>vector/string/deque</code>一样或像关联容器一样对待list；两种方法都可以为list工作。</p>
<h2 id="结论">结论</h2>
<ol>
<li><strong>去除一个容器中有特定值的所有对象</strong>：</li>
</ol>
<ul>
<li>如果容器是<code>vector</code>、<code>string</code>或<code>deque</code>，使用<code>erase-remove</code>惯用法</li>
<li>如果容器是<code>list</code>，使用<code>list::remove</code></li>
<li>如果容器是标准关联容器，使用它的<code>erase</code>成员函数</li>
</ul>
<ol start="2">
<li><strong>去除一个容器中满足一个特定判定式的所有对象</strong>：</li>
</ol>
<ul>
<li>如果容器是<code>vector</code>、<code>string</code>或<code>deque</code>，使用<code>erase-remove_if</code>惯用法</li>
<li>如果容器是<code>list</code>，使用<code>list::remove_if</code></li>
<li>如果容器是标准关联容器，使用<code>remove_copy_if</code>和<code>swap</code>，或写一个循环来遍历容器元素，当你把迭代器传给<code>erase</code>时记得后置递增它</li>
</ul>
<ol start="3">
<li><strong>在循环内做某些事情（除了删除对象之外）</strong>：</li>
</ol>
<ul>
<li>如果容器是标准<strong>序列容器</strong>，写一个循环来遍历容器元素，<strong>每当调用<code>erase</code>时记得都用它的返回值更新你的迭代器</strong>。</li>
<li>如果容器是标准<strong>关联容器</strong>，写一个循环来遍历容器元素，当<strong>你把迭代器传给<code>erase</code>时记得后置递增它</strong>。</li>
</ul>
<p>如你所见，与仅仅调用erase相比，有效地删除容器元素有更多的东西。</p>
<p><strong>解决问题的最好方法取决于你是怎样鉴别出哪个对象是要被去掉的，储存它们的容器的类型，和当你删除它们的时候你还想要做什么（如果有的话）。</strong></p>
<p>这仅对带有迭代器实参的<code>erase</code>形式是正确的。关联容器也提供一个带有一个值的实参的<code>erase</code>形式，而那种形式返回被删掉的元素个数。但这里，我们只关心通过迭代器删除东西。</p>]]></description></item><item><title>变分自编码器 VAE 详解</title><link>https://jianye0428.github.io/posts/vae_1/</link><pubDate>Thu, 27 Jul 2023 10:53:41 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/vae_1/</guid><description><![CDATA[<!-- <div class="details admonition quote">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-quote-right fa-fw" aria-hidden="true"></i>quote<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">note abstract info tip success question warning failure danger bug example quote</div>
    </div>
  </div> -->
<h2 id="引入">引入</h2>
<p></p>
<div class="details admonition Notes open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Notes<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">本文也是为写 Stable Diffusion 相关文章做的铺垫，主要参考了李宏毅老师的视频课以及B站的白板推导系列。有关GMM、蒙特卡洛、ELBO、变分推断、重参数化的细节本文不做详细介绍，主要围绕VAE的结构以及loss优化推导做讲解。</div>
    </div>
  </div>
<p>我们先来简单的引入一下：</p>
<ul>
<li>V：变分推断，它的意思来自于概率图模型，本文会给出变分下界的详细推导；</li>
<li>AE：Auto-Encoder，自编码器；</li>
<li>VAE：Variational Auto-Encoder，变分自编码器，将概率图模型和神经网络相结合的模型；</li>
</ul>
<h2 id="一ae">一、AE</h2>
<p></p>
<p>先来介绍一下自编码器（Auto-Encoder），它是一种无监督学习方法，如上图所示，原理可概述为：</p>
<ul>
<li>将高维原始数据（如图片）送入 Encoder，利用 Encoder 将高维数据映射到一个低维空间，将n维压缩到m维($m&laquo;n$)，我们用隐变量来表示；</li>
<li>然后将低维空间的特征送入 Decoder 进行解码，以此来重建原始输入数据。</li>
</ul>
<div class="details admonition Note">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">Encoder、Decoder网络可以为普通的全连接、也可以为CNN、或者类似于Unet都可以，没有固定的要求。</div>
    </div>
  </div>
<p>这里为和后文的推导联系起来，我们将 Encoder 网络的映射函数定义为 $q_{\phi}$ 、Decoder 网络定义为 $p_{\theta}$，$\phi$、$\theta$ 皆为网络参数。</br>
那么对于输入 $x$，我们可以通过Encoder得到 Latent Variable：$z = q_{\phi}(x)$，然后Decoder可以从隐变量z中对原始数据进行重建：$x&rsquo; = p_{\theta}(z) = p_{\theta}(q_{\phi}(x))$。</p>
<p>我们希望重建的数据和原来的数据近似一致，即最小化输入和输出之间的重构误差，那么AE的训练损失可以采用简单的MSE：</p>
<p>$$L_{\text{AE}}(\theta, \phi) = \frac{1}{n}\sum_{i=1}^{n} (x^{(i)} - p_{\theta}(q_{\phi}(x^{(i)})))^2$$</p>
<div class="details admonition Note">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">可以理解为比较输入和重构输入的像素点的误差。</div>
    </div>
  </div>
<h2 id="二ae-存在的问题">二、AE 存在的问题</h2>
<p>上面我们通过AE可以构建一个重构图像的模型，但是这个模型并不能满足要求，或者说它并不是真正意义上的生成模型。对于一个生成模型而言，它满足：</p>
<ul>
<li><strong>Encoder 和 Decoder 可以独立拆分（类比 GAN 的 Generator 和 Discriminator）；</strong></li>
<li><strong>固定维度下任意采样出来的编码，都应该能通过 Decoder 产生一张清晰且逼真的图片。</strong></li>
</ul>
<p>当然对于第一点它是满足的，我们主要分析第二点，也就是AE存在的问题，从而引出VAE。</p>
<p></p>
<p>如上图所示，用一张全月图和一张半月图去训练一个AE，经过训练模型是能够很好的还原出这两张图片。</p>
<p>接下来，我们在 latent code 中任取一点，将其交给 Decoder 进行解码，直觉上我们会得到一张介于全月和半月之前的图片（比如阴影面积覆盖的样子）。然而<font color=red>实际上的输出图片不仅模糊而且还是乱码的</font>。</p>
<p>对于这个现象，一个直观的解释就是AE的 Encoder 和 Decoder 都用了DNN，那么NN只会干一件事情：学习、记住、用记住的东西预测，我们从 latent space 中采样的点，编码器都没有学习过，怎么能够指望它生成希望的值呢。</p>
<p>换句话说，NN只记住了左边全月图片的隐向量和右边半月图片的隐向量，并不能泛化到中间就是$\frac{3}{4}$月亮的图片。</p>
<p>为了解决这个问题，一个最直接的思想就是<strong>引入噪声</strong>，扩大图片的编码区域，从而能够覆盖到失真的空白编码区，如下图所示：</p>
<p></p>
<p>其实说白了就是<strong>通过增加输入的多样性从而增强输出的鲁棒性</strong>。</p>
<p>当我们给输入图片进行编码之前引入一点噪声，使得每张图片的编码点出现在绿色箭头范围内，这样一来所得到的 latent space 就能覆盖到更多的编码点。此时我们再从中间点抽取还原便可以得到一个比较希望的输出。</p>
<p>虽然我们给输入的图片增加了一些噪声，使得 latent space 能够覆盖到比较多的区域，但是还有不少地方没有覆盖到，比如上图的黄色点位置。</p>
<p>因此，我们是不是可以尝试利用更多的噪声，使得对于每一个输入样本，它的编码都能够覆盖到整个编码空间？只不过我们这里需要保证的是：对于编码附近的我们应该给定一个高的概率值，对于距离原编码点远的应该给定一个低的概率值。</p>
<p>这样总体来说，我们就是要将原先的一个单点拉伸到整个编码空间，即将离散的编码点拉伸为一条连续的接近正太分布的编码曲线，如下图所示：</p>
<p></p>
<p>这个其实就是VAE的思想，熟悉GMM的同学应该知道，它是K个高斯分布（Gaussian Distribution）的混合，其实<strong>VAE可以说是无限个高斯分布的混合</strong>。</p>
<h2 id="三vae-结构预览">三、VAE 结构预览</h2>
<p></p>
<p>如上图所示VAE的结构，我们可以看到VAE里的编码器不是输出隐向量$z$，而是一个概率分布，分布的均值为$m$、方差为$\sigma$，$e$ 即为给编码添加的噪声，来自于正态分布。</p>
<p>公式怎么得到的后面会给出推导，我们先来描述一下这个过程：</p>
<p>$$z_{i} = c_{i} = \exp(\sigma_i) * e_i + m_i$$</p>
<ul>
<li>Encoder会计算出两组编码，一组为均值m、一组为控制噪声干扰程度的方差$\sigma$；</li>
<li>方差$\sigma$主要用来为噪声编码 $e$ 分配权重；</li>
<li>取指数主要是为了保证分配到的权重是正值；</li>
<li>也就是说数据分布会在 $\exp(\sigma_i) * e$ 方差范围内采样一个值，得到一个偏移量，就是相当于把原始的样本加上了一个噪声。从结构图中我们可以看到，损失除了AE的 重构损失（reconstruction error）外，还多出了下面这一项：
$$c = (c_1, c_2, c_3) = \sum_{i=1}^{3} (e^{\sigma_i} - (1 + \sigma_i) + (m_i)^2)$$</li>
</ul>
<p>这个辅助loss可以认为是一个约束，也就是说生成的 $\sigma$ 要满足这个约束。</p>
<p><strong>为什么要加这个辅助loss？</strong></p>
<ul>
<li>我们最小化了 reconstruction error，如果不加这个辅助loss的话，Encoder肯定希望噪声对自身生成的图片干扰越小越好，为了保证生成图片的质量，于是分配给噪声的权重也就是越低。如果不加这个约束的话，网络只需要将方差设置为接近负无穷大的值 $\exp ^ {-\infty} = 0$，即可消除噪声带来的影响，这样必然会过拟合导致鲁棒性不佳。</li>
</ul>
<p><strong>为什么加这个辅助loss有用？</strong></p>
<ul>
<li>我们对 $\sigma$ 求导可得 $c = e^{\sigma} - 1$，令其等于0可求出 $\sigma = 0$ 时取得极小值，这样一来便可以约束方差不会一路走向负无穷，从而起到正则化约束的作用；</li>
<li>如下图所示，$e^{\sigma}$ 是蓝色曲线，$1 + \sigma$ 是红色线条，那么 $e^{\sigma} - (1 + \sigma)$就是蓝色曲线减去红色直线，得到绿色曲线，显而易见的可以发现它的最小值为0。</li>
</ul>
<p></p>
<h2 id="四数学描述">四、数学描述</h2>
<h3 id="41作者的-intuition">4.1、作者的 Intuition</h3>
<p>
</p>
<p>借用作者原文的表述，我们来引入定义。如上图所示，首先我们会有一个高维的随机变量，与之相关联的我们叫它隐变量 $z$，$z$ 的维度一般要比 $x$ 低很多，用来描述 $x$ 中所包含的信息。</p>
<p>我们假设 $z$ 满足分布 $p_{\theta}(z)$，$x$ 也是一个条件概率，也就是说：</p>
<ul>
<li>在已知 $z$ 的情况下，$p_{\theta}(z)$能生成一个sample $x$ ；</li>
<li>给定一个sample $x$，$q_{\phi}(x)$ 就可以尝试推测出这个来。</li>
</ul>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content"><p>因为假设$z$满足一定分布，所以也有从$\theta$到$z$的箭头；</p>
<p>之后提到的$z$都是Decoder里的参数。</p>
</div>
    </div>
  </div>
<p>这么说可能有点抽象，我们举个例子：</p>
<p></p>
<p>如上图所示，假设有一个图像，里面有3个颜色不一致的形状，这个就是我们的输入$x$。通过右图的参数，可以控制$x$，这就是隐变量$z$。</p>
<p>那么回到实际的应用场景，我们想要通过$x$获得$z$，又想通过$z$得到相应的$x$，也就是图中的双箭头就是我们想要做的事情。</p>
<p>那么对于生成模型而言，VAE的数据产生包括两个过程：</p>
<ul>
<li>从一个先验分布 $p_{\theta}(z)$ 中采样一个 $z^{(i)}$；</li>
<li>根据条件分布 $p_{\theta}(x|z)$，用 $z^{(i)}$ 生成 $x^{(i)}$。</li>
</ul>
<p>我们希望找到一个参数 $\theta^*$ 来<strong>最大化生成真实数据</strong>的概率：</p>
<p>$$\theta^*=\argmax_{\theta} \prod_{i=1}^{n}p_{\theta}(x^{(i)})$$</p>
<p>这里 $p_{\theta}(x^{(i)})$ 可以通过对 $z$ 积分得到：</p>
<p>$$p_{\theta}(x^{(i)}) = \int_{z} p_{\theta}(x, z) \mathrm{d}{z} = \int_{z} p_{\theta}(z) p_{\theta}(x^{(i)}|z)\mathrm{d}{z}$$</p>
<p>实际上我们要根据上述积分是不可能实现的，先验分布 $p_{\theta}(z)$ 是未知的，而且如果分布比较复杂且高维，对其穷举计算也是不现实的。</p>
<p>变分推断引入后验概率来联合建模，即given $x$ 想要得到它的 $z$，根据贝叶斯公式表示为：</p>
<p>$$p_{\theta}(z | x) = \frac{p_{\theta}(x|z) p_{\theta}(z)}{p_{\theta}(x)}$$</p>
<p>我们又回到最上面的图：</p>
<p></p>
<ul>
<li>实线箭头就是我们要得到的生成模型 $p_{\theta}(z) p_{\theta}(x|z)$，这里 $p_{\theta} (z)$ 往往是事先定义好的，比如标准正态分布，而 $p_{\theta}(x|z)$ 可以用一个网络来学习，它就可以看成是 <strong>Probabilistic Decoder</strong>。</li>
<li>虚线箭头代表对后验分布 $p_{\theta}(z|x)$ 的变分估计，它也可以用一个网络去近似，我们记为 $q_{\phi}(z|x)$，则这个网络称为 <strong>Probabilistic Encoder</strong>。</li>
</ul>
<p>所以VAE的优化目标就有了，为了<strong>达到从x估计z的过程</strong>，对于估计的后验 $q_{\phi}(z|x)$，我们希望它<strong>接近</strong>真实的后验分布 $p_{\theta}(z|x)$ ，即：</p>
<p>$$p_{\theta}(z|x) \cong q_{\phi}(z|x)$$</p>
<p>说白了就是使用另一个模型，参数由 $\phi$ 表示，在参数 $\phi$ 的帮助下，有了一个分布 $q$ ，现在希望分布 $q$ 能够尽量接近 $p$，从而达到从 $x$ 估计 $z$ 的过程。</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content"><p>可以看到VAE和AE架构上还是相似的，VAE的最终目标是得到生成模型即Decoder，Encoder只是辅助建模。</p>
<p>而AE常常是为了得到Encoder来进行特征提取或压缩。</p>
</div>
    </div>
  </div>
<h3 id="42变分下界">4.2、变分下界</h3>
<p>为了衡量两个 distribution 的相似程度，我们应该很自然的想到了KL divergence，因为我们实际上计算的是分布 $q$ ，所以我们从 $q$ 的视角来计算它到 $p$ 的KL散度：</p>
<p>$$q_{\phi}(z|x) \cong p_{\theta}(z|x) \rightarrow D_{\text{KL}}(q_{\phi}(z|x) || p_{\theta}(z|x))$$</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content"><p>需要再次强调的是：</p>
<p>$\theta$ 为 decoder 的参数；</p>
<p>$\phi$ 为 encoder 的参数。</p>
</div>
    </div>
  </div>
<p>根据定义我们将KL divergence展开，对 $z$ 求和，表示如下：</p>
<p>$$
\begin{align}
D_{\text{KL}}(q_{\phi}(z|x) || p_{\theta}(z|x)) &amp;= \sum_{z} q_{\phi}(z | x) \log (\frac{q_{\phi}(z | x)}{p_{\theta}(z | x)}) \cr
&amp;= - \sum_{z} q_{\phi}(z | x) \log (\frac{p_{\theta}(z | x)}{q_{\phi}(z | x)})\cr
&amp;= - \sum_{z} q_{\phi}(z | x) \log (\frac{\frac{p_{\theta}(z,x)}{p_{\theta}(x)}}{q_{\phi}(z | x)})\cr
&amp;= - \sum_{z} q_{\phi}(z | x) [\log({\frac{p_{\theta}(x, z)}{p_{\theta}(x)}}) - \log({q_{\phi}(z | x)})]\cr
&amp;= - \sum_{z} q_{\phi}(z | x) [\log({\frac{p_{\theta}(x, z)}{q_{\phi}(z|x)}}) - \log({p_{\theta}(x)})]\cr
\end{align}
$$</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">$p_{\theta}(z | x)$ 是根据条件概率公式拆开的。</div>
    </div>
  </div>
<p>这个时候我们注意到 $\log(p_{\theta}(x))$ 是和 $z$ 没有关系的，并且log项是常数，所以在乘求和的时候直接提到 $\sum$ 外面去就可以了，并且 $q_{\phi} (z | x)$ 对 $z$ 求和的结果是1，那所以 $-\sum_{z}(q_{\phi}(z|x))(-\log(p_{\theta}(x)))$ 的结果就是 $\log(p_{\theta}(x))$，它是个const。</p>
<p>我们将它移到等式的左边，表示如下：</p>
<p>$$
\begin{align}
\log(p_{\theta}(x)) &amp;= D_{KL}(q_{\phi}(z|x) || p_{\theta}(z|x)) + \sum_{z}q_{\phi}(z|x)\log(\frac{p_{\theta}(x, z)}{q_{\phi}(z|x)}) \cr
&amp;= D_{KL}(q_{\phi}(z|x) || p_{\theta}(z|x)) + L(\theta, \phi; x)
\end{align}
$$</p>
<p>我们将 $\sum_{z}q_{\phi}(z|x)\log(\frac{p_{\theta}(x, z)}{q_{\phi}(z|x)})$ 写成 $L(\theta, \phi; x)$ ，等式左边是一个const，也就是说不管 $x$ 的分布是什么样，它对 $\theta$ 来说没什么影响。等式右边，KL divergence是一个非负的，所以我们只要把 $L(\theta, \phi; x)$ 的值尽可能的拉大，那么KL divergence的值就会随之缩小。</p>
<p><strong>想要最大化的$L(\theta, \phi; x)$，就被称为变分下界（Variational lower bound）。</strong></p>
<h3 id="43loss-function">4.3、Loss Function</h3>
<p>现在我们只要想办法将这个 lower bound 提升就可以了，那么这个 lower bound 就可以作为我们的 loss function：</p>
<p>$$
\begin{aligned}
L(\theta, \phi; x) &amp;= \sum_{z}q_{\phi}(z|x)\log(\frac{p_{\theta}(x, z)}{q_{\phi}(z|x)}) \cr
&amp;= \sum_{z}q_{\phi}(z|x)\log(\frac{p_{\theta}(x|z) p_{\theta}(z)}{q_{\phi}(z|x)}) \cr
&amp;= \sum_{z}q_{\phi}(z|x)[\log(p_{\theta}(x|z)) + \log(\frac{p_{\theta}(z)}{q_{\phi}(z | x)})] \cr
&amp;= {E}<em>{q</em>{\phi}(z|x)}[\log(p_{\theta}(x|z))] - D_{KL}(q_{\theta}(z | x) || p_{\theta}(z))\cr
\end{aligned}
$$</p>
<p>上述等式，我们将 lower bound 再展开，将 $p_{\theta}(x, z)$ 展成条件概率，然后再将log拆分。</p>
<p>第三行中括号内，左边的可以写成期望的形式，右边的因为都有 $q_{\phi}$ 和 $p_{\theta}$ 所以符合KL divergence的公式。</p>
<ul>
<li>我们将 ${E}<em>{q</em>{\phi}(z|x)}[\log(p_{\theta}(x|z))]$ 称为<strong>Reconstruction Loss</strong>，</li>
<li>将 $- D_{KL}(q_{\theta}(z | x) || p_{\theta}(z))$ 称为 <strong>Regularization Loss</strong>。</li>
</ul>
<p>所以我们只需要估计出这两项的梯度来，就可以对 lower bound 进行优化了。</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">我们的目的是想让 Probabilistic Encoder 接近于 $p_{\theta}(z)$，因为两个损失，这样KL divergence就越大越好，实际-KL才是训练用的loss。</div>
    </div>
  </div>
<h3 id="44蒙特卡洛法求梯度">4.4、蒙特卡洛法求梯度</h3>
<p>接下来讲如何求出这两项的导数，来优化提升 lower bound。我们看到想要优化的这个loss，其实是可以写成期望的形式的，假定期望里的这一项是 $f(z)$，对于估计这种期望它的导数，最直接的我们就想到了蒙特卡洛的方法。</p>
<p></p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">虽然这里有个 $\phi$，但我们假定这个 $f(z)$ 和 $\phi$ 是没有关系的。(假设！！！！)</div>
    </div>
  </div>
<p>使用蒙特卡洛方法，对 $f(z)$ 在 $q_{\phi}$ 上的期望，对 $\phi$ 求导数，表示如下：</p>
<p>$$
\begin{aligned}
&amp;max=2<em>x1+3</em>x2;\
&amp;x1+2<em>x2&lt;=8;\
&amp;4</em>x1&lt;=16;\
&amp;s4*x2&lt;=12;
\end{aligned}
$$</p>
<p>$$
\begin{aligned}
\eta &amp;= \triangle_{\phi} E_{q_{\phi}(z)}[f(z)]\cr
&amp;= \triangle_{\phi} \int {q_{\phi}(z)}f(z) \mathrm{d}z\cr
&amp;= \int \triangle_{\phi}{q_{\phi}(z)}f(z) \mathrm{d}z\cr
&amp;= \int {q_{\phi}(z)}f(z)\triangle_{\phi} \log {q_{\phi}(z)}\mathrm{d}z\cr
&amp;= E_{q_{\phi}(z)}[f(z)\triangle_{\phi} \log {q_{\phi}(z)}]\cr
\end{aligned}
$$</p>
<ul>
<li>$line 1 \sim 2:$ 根据期望的定义展开，因为我们假设 $f(z)$ 和 $\phi$ 没有关系，所以可以将导数符号拿进来；</li>
<li>$line 3: $ 根据变换 $\triangle_{\phi} \log q_{\phi}(z) = \frac{\triangle_{\phi}q_{\phi}(z)}{q_{\phi}(z)}$ 带入可得;</li>
</ul>
<p>套用蒙特卡洛公式，最终表示如下：</p>
<p>$$
\begin{aligned}
\triangle_{\phi}E_{q_{\phi}(z)}[f(z)] &amp;= E_{q_{\phi}(z)}[f(z) \triangle_{q_{\phi}(z)} \log{q_{\phi}(z)}] \cr
&amp;\cong \frac{1}{L}\sum_{l=1}^{L} f(z) \triangle_{q_{\phi}(z^{(l)})} \log{q_{\phi}(z^{(l)})}, where z^{(l)} \sim q_{\phi}(z|x^{(i)})
\end{aligned}
$$</p>
<p>但是作者实验发现使用这个 estimator 是有很高的 variance 的，就是直观上来说会导致训练很不稳定。</p>
<p>在此基础上作者提出了 Generic Stochastic Gradient Variational Bayes (<strong>SGVB</strong>) estimator，并使用**重参数化（Reparameterization）**trick，我们先来说下重参数化。</p>
<h3 id="45重参数化-trick">4.5、重参数化 Trick</h3>
<p>上面我们用蒙特卡洛的时候，有一个非常强的假设，那就是假设 $f(z)$ 和 $\phi$ 是没有关系的，但实际表达式中：
</p>
<p>我们可以看到它还是有关系的，所以我们得考虑它们之间存在的关系、这个关系会带来什么样的问题。</p>
<p>我们把它打开来看：</p>
<p>$$
\begin{aligned}
\triangle_{\phi}E_{q_{\phi}}[f(z)] &amp;= \triangle_{\phi}\int q_{\phi}(z)f(z) \mathrm{d}z \cr
&amp;= \int \triangle_{\phi}[q_{\phi}(z)f(z)] \mathrm{d}z\cr
&amp;= \int f(z) \triangle_{\phi}q_{\phi}(z) \mathrm{d}z + \int q_{\phi}(z)\triangle_{\phi}f(z) \mathrm{d}z\cr
&amp;= \underbrace{\int f(z) \triangle_{\phi}q_{\phi}(z) \mathrm{d}z}<em>{what \ about \ this \ ?} + E</em>{q_{\phi}(z)}[\triangle_{\phi}f(z)]
\end{aligned}
$$</p>
<p>分别求导之后，后面一项可以写成期望的形式，但是前面这一项就无法处理了，为了解决这个问题，作者使用了<strong>重参数化技巧（Reparameterization Trick）</strong>。</p>
<p>核心思想就是引入一个辅助的随机变量 $\epsilon$，$\epsilon \in p(\epsilon)$，这个随机变量和其它变量没有关系，它是一个独立的随机变量，用来表示产生 $z$ 的过程中所有的随机性。也就是说抽样产生 $z$ 的过程中，所有的随机性都是由这个 $\epsilon \in p(\epsilon)$ 产生的。</p>
<p>这样我们就可以把 $z$ 写成这种形式： $z = g_{\phi}(\epsilon, x)$，从而可以把 $q_{\phi}(z)$ 这个概率分布转移到 $p_{\epsilon}$ 上，而 $\epsilon$ 有一个非常好的特性，那就是和 $\phi$ 是没有关系的。</p>
<p>这种 trick 就是重参数化，得到新的变形后重新对 $\phi$ 求导：</p>
<p>$$
\begin{aligned}
E_{q_{\phi(z)}}[f(z^{(i)})] &amp;= E_{p(\epsilon)}[f(g_{\phi}(\epsilon, x^i))] \cr
\triangle_{\phi}E_{q_{\phi(z)}}[f(z^{(i)})] &amp;= \triangle_{\phi}E_{p(\epsilon)}[f(g_{\phi}(\epsilon, x^i)]\cr
&amp;=E_{p(\epsilon)}[\triangle_{\phi}f(g_{\phi}(\epsilon, x^i)]\cr
&amp;\approx \frac{1}{L} \sum_{l=1}^{L} \triangle_{\phi}f(g_{\phi}(\epsilon^{(l)}, x^{(i)}))
\end{aligned}
$$</p>
<p>估计这个期望也是采样然后求平均得到最后的式子，这样就可以把loss的梯度给估计出来了。</p>
<p>以上是从数学角度来分析的重参数化技巧，这里作者给出了一个更加直观的表达：</p>
<p></p>
<ul>
<li>左图为原来的形式，我们使用 $\phi$ 和 $x$ 产生一个distribution，然后在这个distribution中抽样产生一个z，然后再得到最终的 $f$ 。但是在传递梯度的时候，怎么把梯度通过抽样这个过程传递回来呢？这个是没法传递梯度的。
在使用了重参数化trick后，随机性移动到了 $\epsilon$ 上，之前所有抽样的过程包括的随机性，都让 $\epsilon$ 包括了，这样就可以顺利地将梯度通过 $z$ 传递到 $\phi$，这是一个非常巧妙的方法.</li>
</ul>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">可以理解成用多余参数逼近抽样的过程。</div>
    </div>
  </div>
<h3 id="46-generic-sgvb">4.6 Generic SGVB</h3>
<p>简单说完重参数化，我们回到SGVB:
</p>
<p>这里是想求这一串期望，它就是我们的 $f(z)$ ，根据之前的 Reparameterization Trick，我们把 $z$ 写成这样的形式：</p>
<p>$$z^{(i, l)} = g_{\phi} (\epsilon^{(i,l)}, x^{(i)}) \ and \ \epsilon^{(l)} \sim p(\epsilon)$$</p>
<p>让 $\epsilon$ 从这个 distribution 中抽样产生，$\epsilon$ 是一个与 $\phi$ 、$\theta$ 都没有关系的随机变量，然后 loss 就变成：</p>
<p>$$L(\theta, \phi, x^{(i)}) = \frac{1}{L} \sum_{l=1}^{L} \log p_{\theta}(x^{(i)}, z^{(i,l)}) - \log q_{\phi}(z^{(i,l)} | x^{(i)})$$</p>
<p>想要求它对 $\phi$ 的导数，只需要两边同时求导即可。</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">因为期望这个积分已经被替换成了 $\epsilon$ 的distribution，它跟 $\phi$ 是没有关系的，所以我们在估计整个loss的导数的时候，我们直接对 $\phi$ 求导就可以了。</div>
    </div>
  </div>
<p>这个就是作者提出的第一种估计梯度的方法。</p>
<h3 id="47another-sgvb">4.7、Another SGVB</h3>
<p>在此基础上作者还发现，有一些好的性质可以直接拿来利用，比如期望的一些性质。</p>
<p>在 4.3 节中我们讲到原来的 loss 可以写成 KL散度 + 期望 的形式：</p>
<p>$$L(\theta, \phi, x^{(i)}) = -D_{KL}(q_{\phi}(z|x^{(i)})||p_{\theta}(z)) + E_{q_{\phi}(z|x)}[\log(p_{\theta}(x^{(i)}|z))]$$</p>
<p>这里我们假设这两个distribution：$q_{\phi}$ 、$p_{\theta}$ 都是 Gaussian distribution，说白了就是0均值1方差，根据定义：</p>
<p>$$
\begin{cases}
D_{KL}(P||Q) = E_{x \sim P}[\log(\frac{P(x)}{Q(x)})]\cr
E_{x\sim P(x)} = \int P(x)Q(x)\mathrm{d}x
\end{cases}
$$</p>
<p>我们根据上述定义打开这个KL divergence：</p>
<p>$$-D_{KL}(q_{\phi}(z|x)||p_{\theta}(z)) = \int q_{\phi}(z|x)(\log p_{\theta}(z)) - \log q_{\phi}(z|x) \mathrm{d}z$$</p>
<p>我们先来看 $\int q_{\phi}(z|x)\log p_{\theta}(z) \mathrm{d}z$:</p>
<p>$$
\begin{align}
\int q_{\phi}(z|x)\log p_{\theta}(z) \mathrm{d}z &amp;= \int N(z; \mu, \sigma^2) \log N(z; 0, 1)\mathrm{d}z\cr
&amp;= \int N(z; \mu, \sigma^2) (-\frac{1}{2}z^2 - \frac{1}{2}\log(2\pi))\mathrm{d}z\cr
&amp;= -\frac{1}{2} \int N(z; \mu, \sigma^2) z^2\mathrm{d}z - \frac{J}{2}\log(2\pi) \cr
&amp;= -\frac{J}{2} \log (2\pi) - \frac{1}{2}(E_{z \sim N(z;\mu, \sigma^2)}[z]^2 + Var(z))\cr
&amp;= -\frac{J}{2} \log (2\pi) - \frac{1}{2}\sum_{J}^{j=1}(\mu^2 + \sigma_j^2)
\end{align}
$$</p>
<ul>
<li>$line 1\sim 2:$ 我们让左面分布 $N(z; \mu, \sigma^2)$ 保持不动，将 normal distribution 的PDF带进去；
<ul>
<li>normal distribution 的PDF为:
</li>
<li>将常数项直接拿出来，指数的部分也通过log直接拿下来了；</li>
</ul>
</li>
<li>$line 3:$ 因为 $\frac{1}{2}\log(2\pi)$ 是个常数、$N(z; \mu, \sigma^2)$ 这个分布积分之后是1，所以可以直接把常数项拿到积分外面；但是因为 $z$ 是一个向量，我们假设 $z$ 有 $J$ 个元素element，那么每个元素都会积出一个值来，所以要乘上 $J$，即 $\frac{J}{2}\log(2\pi)$;</li>
<li>$line 4:$ 对于积分 $\int N(z;\mu,\sigma^2) z^2\mathrm{d}z$ 我们可以换个角度理解它：这里我们把它就当成一个概率分布，所以整个这个积分其实也是一个期望的形式，不过它是对 $z^2$ 的期望，经过变形可以写成 $-\frac{1}{2} E_{z \sim N(z; \mu, \sigma^2)}[z]^2$
。在这个基础上我们使用期望的性质 $E[z^2] = E[z]^2 + variance(z)$，即 $z^2$ 的期望等于期望的平方加上 $z$ 的方差；</li>
<li>那么对于一个 normal distribution 来说它的期望和方差是显而易见的：$\mu$ 和 $\sigma$，对于 $z$ 里的每个元素（脚标是 $j$）都加起来就好了，这样最开始的积分就可以简化成最后的形式。</li>
</ul>
<p>我们再来看 $\int q_{\phi}(z|x)\log q_{\phi}(z|x)\mathrm{d}z$:</p>
<p>$$
\begin{aligned}
\int q_{\phi}(z|x)\log q_{\phi}(z|x)\mathrm{d}z &amp;=\int N(z; \mu, \sigma^2)\log N(z;\mu,\sigma^2)\mathrm{d}z\cr
&amp;= \int N(z; \mu, \sigma^2)(-\frac{1}{2}(\frac{z - \mu}{\sigma})^2- \frac{1}{2}\log (2 \pi) - \frac{1}{2}\log(\sigma^2))\mathrm{d}z\cr
&amp;=-\frac{1}{2}\int N(z;\mu,\sigma^{2})(\frac{z-\mu}{\sigma})^{2}\mathrm{d}z-\frac{J}{2}log(2\pi)-\frac{1}{2}\sum_{j=1}^{J}log(\sigma_{j}^{2}) \cr
&amp;=-\frac J2log(2\pi)-\frac12\sum_{j=1}^{J}log(\sigma_{j}^{2})-\frac12E_{z\sim N(z;\mu,\sigma^{2})}[(\frac{z-\mu}\sigma)^{2}] \cr
&amp;=-\frac{J}{2}log(2\pi)-\frac{1}{2}\sum_{j=1}^{J}log(\sigma_{j}^{2})-\frac{1}{2}(E_{z\sim N(z;\mu,\sigma^{2})}[\frac{z-\mu}{\sigma}]^{2}+Var(\frac{z-\mu}{\sigma})) \cr
&amp;=-\frac{J}{2}log(2\pi)-\frac{1}{2}\sum_{j=1}^{J}(1+log(\sigma_j^2))
\end{aligned}
$$</p>
<p>同样的还是把它的PDF带进来，展成上面相似的形式，但是这个地方的常数项和变量要显得复杂一点，相似的是我们一样可以把常数部分拿到积分外面去，然后对于前面这项积分也把它理解成期望的形式，同样利用期望的性质将平方化简，就可以得到最后的结果。</p>
<p>随后我们把 KL散度 这两项给合并起来：
$$
\begin{aligned}
-D_{KL}(q_{\phi}(z\mid x)\mid\mid p_{\theta}(z))&amp; =\int q_\phi(z\mid x)(logp_\theta(z))-logq_\phi(z\mid x))\mathrm{d}z  \cr
&amp;=\frac12\sum_{j=1}^J(1+log((\sigma_j)^2)-(\mu_j)^2-(\sigma_j)^2)
\end{aligned}
$$</p>
<p>把刚刚上面的结果带进来做减法即可得到这个等式，也就是说可以通过这个式子来估计出KL散度。</p>
<p>对于另一部分的loss $E_{q_{\phi}(z|x)}[\log(p_{\theta}(x^{(i)} | z))]$，就像我们上面说的，这部分的概率我们希望given $z$ 产生的 $x$ 尽量的接近输入 $x$，为了实现这个逼近，我们使用MSE来让$f(z)$逼近这个x，就可以最大化这个loss：</p>
<p></p>
<p>以上就是最终使用的SGVB，作者通过 KL散度 的性质和 Regularization Loss 的近似，给我们提供了一种相对稳定的估计loss和梯度的方法。</p>
<h2 id="五vae-结构回顾">五、VAE 结构回顾</h2>
<p></p>
<p>总的来看 Variational Auto-Encoder 的model就是：</p>
<ul>
<li>输入一个 $x$，进了Encoder，这个 Encoder 是由参数来决定的，Encoder 会产生 $μ$和 $σ$；</li>
<li>$μ$和 $σ$首先被我们用来计算 KL divergence，作为辅助损失；</li>
<li>同时在 $μ$ 和 $σ$之后我们对它抽样产生一个 $z$，加上 $\epsilon$ 帮我们产生随机的项；</li>
<li>得到隐变量 $z$后，放到 Dencoder 里，它是由参数 $\theta$ 来决定的；</li>
<li>经过这个 Decoder 之后，我们重建出了一个 $x$；</li>
<li>对比重建后的 $x$ 和输入 $x$ 之间的 MSE 就构成了loss的另一部分，</li>
<li>两个loss加起来就是最终的loss。</li>
</ul>
<p>这个就是最经典的 Variational Auto-Encoder。</p>
<p>对比第一大节AE的图，可以画成一下形式：</p>
<p></p>
<h2 id="六原文实验">六、原文实验</h2>
<p>作者基于MNIST 和 Frey Face做了实验验证，看下原文的结果图：</p>
<p></p>
<p>首先作者说了使用不同的学习方法能把这个 lower bound 提升多少，lower bound 的提升越大，说明 Encoder 和我们想要逼近的这个Distruction，它的KL散度是越来越小。</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">由图中可以看出AEVB与wake-sleep算法的比较，可以看出AEVB训练效果更好。且随着隐变量维度增大，并未出现过拟合现象。</div>
    </div>
  </div>
<p>
</p>
<p>图4是限定2个维度的隐变量 $z$，并调节两个维度的值，生成的图片。</p>
<p>图5是不同维度的隐变量随机采样的图片。</p>
<h2 id="七torch复现-aevae">七、torch复现 AE、VAE</h2>
<p><a href="https://wangguisen.blog.csdn.net/article/details/128476638"target="_blank" rel="external nofollow noopener noreferrer">https://wangguisen.blog.csdn.net/article/details/128476638<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<h2 id="references">References</h2>
<p>[1]. <a href="https://arxiv.org/abs/1312.6114"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/abs/1312.6114<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[2]. <a href="http://www.gwylab.com/note-vae.html"target="_blank" rel="external nofollow noopener noreferrer">http://www.gwylab.com/note-vae.html<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[3]. <a href="https://zhuanlan.zhihu.com/p/452743042"target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/452743042<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[4]. <a href="https://www.bilibili.com/video/BV1q64y1y7J2/"target="_blank" rel="external nofollow noopener noreferrer">https://www.bilibili.com/video/BV1q64y1y7J2/<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[5]. <a href="https://www.bilibili.com/video/av15889450/?p=33"target="_blank" rel="external nofollow noopener noreferrer">https://www.bilibili.com/video/av15889450/?p=33<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[6]. <a href="https://gregorygundersen.com/blog/2018/04/29/reparameterization/"target="_blank" rel="external nofollow noopener noreferrer">https://gregorygundersen.com/blog/2018/04/29/reparameterization/<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
</br>
[7]. <a href="https://mp.weixin.qq.com/s?__biz=Mzk0MzIzODM5MA==&amp;mid=2247486014&amp;idx=1&amp;sn=2ff34f72c869907408ed1b08bec1a238&amp;chksm=c337b7a7f4403eb14a1b5cdc3e1a1b11dca6f957591957cc29a4c270f0ace0a4674a7ae33214&amp;scene=21#wechat_redirect"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s?__biz=Mzk0MzIzODM5MA==&mid=2247486014&idx=1&sn=2ff34f72c869907408ed1b08bec1a238&chksm=c337b7a7f4403eb14a1b5cdc3e1a1b11dca6f957591957cc29a4c270f0ace0a4674a7ae33214&scene=21#wechat_redirect<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>]]></description></item><item><title>Effective STL [8] | 永不建立auto_ptr的容器</title><link>https://jianye0428.github.io/posts/clause_8/</link><pubDate>Thu, 27 Jul 2023 07:45:11 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/clause_8/</guid><description><![CDATA[<!-- <div class="details admonition quote">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-quote-right fa-fw" aria-hidden="true"></i>quote<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">note abstract info tip success question warning failure danger bug example quote</div>
    </div>
  </div> -->
<h2 id="拷贝一个auto_ptr将改变它的值">拷贝一个auto_ptr将改变它的值</h2>
<p>当你拷贝一个<code>auto_ptr</code>时，<code>auto_ptr</code>所指向对象的所有权被转移到拷贝的<code>auto_ptr</code>，而被拷贝的<code>auto_ptr</code>被设为<code>NULL</code>。</p>
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Widget</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"> <span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">  <span class="k">explicit</span> <span class="n">Widget</span><span class="p">(</span><span class="kt">int</span> <span class="n">in</span><span class="p">)</span> <span class="o">:</span> <span class="n">randy</span><span class="p">(</span><span class="n">in</span><span class="p">)</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl">  <span class="kr">inline</span> <span class="kt">bool</span> <span class="k">operator</span><span class="o">&lt;</span><span class="p">(</span><span class="n">Widget</span><span class="o">&amp;</span> <span class="n">in</span><span class="p">)</span> <span class="p">{</span> <span class="k">return</span> <span class="n">randy</span> <span class="o">&lt;</span> <span class="n">in</span><span class="p">.</span><span class="n">randy</span><span class="p">;</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"> <span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">  <span class="kt">int</span> <span class="n">randy</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">auto_ptr</span><span class="o">&lt;</span><span class="n">Widget</span><span class="o">&gt;</span> <span class="n">pw1</span><span class="p">(</span><span class="k">new</span> <span class="n">Widget</span><span class="p">);</span> <span class="c1">// pw1指向一个Widget
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">auto_ptr</span><span class="o">&lt;</span><span class="n">Widget</span><span class="o">&gt;</span> <span class="n">pw2</span><span class="p">(</span><span class="n">pw1</span><span class="p">);</span> <span class="c1">// pw2指向pw1的Widget; pw1被设为NULL。（Widget的所有权从pw1转移到pw2。）
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">pw1</span> <span class="o">=</span> <span class="n">pw2</span><span class="p">;</span> <span class="c1">// pw1现在再次指向Widget； pw2被设为NULL
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>有意思的是，如果你建立一个<code>auto_ptr&lt;Widget&gt;</code>的<code>vector</code>，然后使用一个指向的<code>Widget</code>的值的函数对它进行排序：</p>
<div class="highlight" id="id-2"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">bool</span> <span class="nf">widgetAPCompare</span><span class="p">(</span><span class="k">const</span> <span class="n">auto_ptr</span><span class="o">&lt;</span><span class="n">Widget</span><span class="o">&gt;&amp;</span> <span class="n">lhs</span><span class="p">,</span> <span class="k">const</span> <span class="n">auto_ptr</span><span class="o">&lt;</span><span class="n">Widget</span><span class="o">&gt;&amp;</span> <span class="n">rhs</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"> <span class="k">return</span> <span class="o">*</span><span class="n">lhs</span> <span class="o">&lt;</span> <span class="o">*</span><span class="n">rhs</span><span class="p">;</span> <span class="c1">// 假设Widget 存在operator&lt;
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="n">auto_ptr</span><span class="o">&lt;</span><span class="n">Widget</span><span class="o">&gt;</span> <span class="n">w1</span><span class="p">(</span><span class="k">new</span> <span class="n">Widget</span><span class="p">(</span><span class="mi">3</span><span class="p">));</span>
</span></span><span class="line"><span class="cl"><span class="n">auto_ptr</span><span class="o">&lt;</span><span class="n">Widget</span><span class="o">&gt;</span> <span class="n">w2</span><span class="p">(</span><span class="k">new</span> <span class="n">Widget</span><span class="p">(</span><span class="mi">2</span><span class="p">));</span>
</span></span><span class="line"><span class="cl"><span class="n">widgets</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">w1</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">widgets</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">w2</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">vector</span><span class="o">&lt;</span><span class="n">auto_ptr</span><span class="o">&lt;</span><span class="n">Widget</span><span class="o">&gt;</span> <span class="o">&gt;</span> <span class="n">widgets</span><span class="p">;</span> <span class="c1">// 建立一个vector，然后用Widget的auto_ptr填充它；
</span></span></span><span class="line"><span class="cl"><span class="c1">// 记住这将不能编译！
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">sort</span><span class="p">(</span><span class="n">widgets</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">widgets</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span> <span class="n">widgetAPCompare</span><span class="p">);</span><span class="c1">// 排序这个vector
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>这段代码将不能编译</p>
<div class="highlight" id="id-3"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">warning: ‘template&lt;class&gt; class std::auto_ptr’ is deprecated <span class="o">[</span>-Wdeprecated-declarations<span class="o">]</span>
</span></span><span class="line"><span class="cl">   <span class="m">30</span> <span class="p">|</span>   std::vector&lt;auto_ptr&lt;Widget&gt; &gt;
</span></span><span class="line"><span class="cl">      <span class="p">|</span>               ^~~~~~~~
</span></span><span class="line"><span class="cl">In file included from /usr/include/c++/9/memory:80,
</span></span><span class="line"><span class="cl">                 from temp.cpp:10:
</span></span><span class="line"><span class="cl">/usr/include/c++/9/bits/unique_ptr.h:53:28: note: declared here
</span></span><span class="line"><span class="cl">   <span class="m">53</span> <span class="p">|</span>   template&lt;typename&gt; class auto_ptr<span class="p">;</span>
</span></span><span class="line"><span class="cl">      <span class="p">|</span>                            ^~~~~~~~
</span></span><span class="line"><span class="cl">temp.cpp:33:3: warning: ‘template&lt;class&gt; class std::auto_ptr’ is deprecated <span class="o">[</span>-Wdeprecated-declarations<span class="o">]</span>
</span></span><span class="line"><span class="cl">   <span class="m">33</span> <span class="p">|</span>   auto_ptr&lt;Widget&gt; w1<span class="o">(</span>new Widget<span class="o">(</span>3<span class="o">))</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">      <span class="p">|</span>   ^~~~~~~~</span></span></code></pre></td></tr></table>
</div>
</div><p>从概念上看所有东西也都很合理，但结果却完全不合理。例如，在排序过程中widgets中的一个或多个auto_ptr可能已经被设为NULL。</p>
<p>排序这个vector的行为可能已经改变了它的内容！</p>
<h2 id="剖析">剖析</h2>
<p>实现<code>sort</code>的方法是使用了<strong>快速排序算法</strong>的某种变体。</p>
<p>排序一个容器的<strong>基本思想</strong>是，选择容器的某个元素作为“主元”，然后对大于和小于或等于主元的值进行递归排序。</p>
<p>在sort内部，这样的方法看起来像这样：</p>
<div class="highlight" id="id-4"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">template</span><span class="o">&lt;</span><span class="k">class</span> <span class="nc">RandomAccessIterator</span><span class="p">,</span> <span class="k">class</span> <span class="nc">Compare</span><span class="o">&gt;</span><span class="c1">// 这个sort的声明直接来自于标准
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="kt">void</span> <span class="n">sort</span><span class="p">(</span><span class="n">RandomAccessIterator</span> <span class="n">first</span><span class="p">,</span> <span class="n">RandomAccessIterator</span> <span class="n">last</span><span class="p">,</span> <span class="n">Compare</span> <span class="n">comp</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// 这个typedef在下面解释
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">typedef</span> <span class="k">typename</span> <span class="n">iterator_traits</span><span class="o">&lt;</span><span class="n">RandomAccessIterator</span><span class="o">&gt;::</span><span class="n">value_type</span> <span class="n">ElementType</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">RandomAccessIterator</span> <span class="n">i</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">...</span> <span class="c1">// 让i指向主元
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">ElementType</span> <span class="n">pivotValue</span><span class="p">(</span><span class="o">*</span><span class="p">);</span> <span class="c1">// 把主元拷贝到一个局部临时变量中；
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="p">...</span> <span class="c1">// wor
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div><p>源码为：</p>
<div class="highlight" id="id-5"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span> <span class="n">_RandomAccessIterator</span><span class="p">,</span> <span class="k">typename</span> <span class="n">_Compare</span><span class="o">&gt;</span>
</span></span><span class="line"><span class="cl"><span class="kr">inline</span> <span class="kt">void</span>
</span></span><span class="line"><span class="cl"><span class="n">sort</span><span class="p">(</span><span class="n">_RandomAccessIterator</span> <span class="n">__first</span><span class="p">,</span> <span class="n">_RandomAccessIterator</span> <span class="n">__last</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"> <span class="n">_Compare</span> <span class="n">__comp</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="c1">// concept requirements
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="n">__glibcxx_function_requires</span><span class="p">(</span><span class="n">_Mutable_RandomAccessIteratorConcept</span><span class="o">&lt;</span>
</span></span><span class="line"><span class="cl">    <span class="n">_RandomAccessIterator</span><span class="o">&gt;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">__glibcxx_function_requires</span><span class="p">(</span><span class="n">_BinaryPredicateConcept</span><span class="o">&lt;</span><span class="n">_Compare</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="k">typename</span> <span class="n">iterator_traits</span><span class="o">&lt;</span><span class="n">_RandomAccessIterator</span><span class="o">&gt;::</span><span class="n">value_type</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="k">typename</span> <span class="n">iterator_traits</span><span class="o">&lt;</span><span class="n">_RandomAccessIterator</span><span class="o">&gt;::</span><span class="n">value_type</span><span class="o">&gt;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">__glibcxx_requires_valid_range</span><span class="p">(</span><span class="n">__first</span><span class="p">,</span> <span class="n">__last</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">  <span class="n">__glibcxx_requires_irreflexive_pred</span><span class="p">(</span><span class="n">__first</span><span class="p">,</span> <span class="n">__last</span><span class="p">,</span> <span class="n">__comp</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="n">std</span><span class="o">::</span><span class="n">__sort</span><span class="p">(</span><span class="n">__first</span><span class="p">,</span> <span class="n">__last</span><span class="p">,</span> <span class="n">__gnu_cxx</span><span class="o">::</span><span class="n">__ops</span><span class="o">::</span><span class="n">__iter_comp_iter</span><span class="p">(</span><span class="n">__comp</span><span class="p">));</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// 上面 __gnu_cxx::__ops::__iter_comp_iter(__comp) 的实现如下
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span> <span class="n">_Compare</span><span class="p">,</span> <span class="k">typename</span> <span class="n">_Iterator</span><span class="o">&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="kr">inline</span> <span class="n">_Iter_comp_to_iter</span><span class="o">&lt;</span><span class="n">_Compare</span><span class="p">,</span> <span class="n">_Iterator</span><span class="o">&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="n">__iter_comp_iter</span><span class="p">(</span><span class="n">_Iter_comp_iter</span><span class="o">&lt;</span><span class="n">_Compare</span><span class="o">&gt;</span> <span class="n">__comp</span><span class="p">,</span> <span class="n">_Iterator</span> <span class="n">__it</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">      <span class="k">return</span> <span class="n">_Iter_comp_to_iter</span><span class="o">&lt;</span><span class="n">_Compare</span><span class="p">,</span> <span class="n">_Iterator</span><span class="o">&gt;</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">   <span class="n">_GLIBCXX_MOVE</span><span class="p">(</span><span class="n">__comp</span><span class="p">.</span><span class="n">_M_comp</span><span class="p">),</span> <span class="n">__it</span><span class="p">);</span> <span class="c1">// 这里有move
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div><p>当涉及<code>iterator_traits&lt;RandomAccessIterator&gt;::value_type</code>时，必须在它前面写上<code>typename</code>，因为它是一个<strong>依赖于模板参数类型的名字</strong>，在这里是<code>RandomAccessIterator</code>。</p>
<p>上面代码中棘手的是这一行:</p>
<div class="highlight" id="id-6"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">ElementType</span> <span class="nf">pivotValue</span><span class="p">(</span><span class="o">*</span><span class="n">i</span><span class="p">);</span></span></span></code></pre></td></tr></table>
</div>
</div><p>因为它把一个元素从保存的区间拷贝到局部临时对象中。</p>
<p>在例子里，这个元素是一个<code>auto_ptr&lt;Widget&gt;</code>，所以这个拷贝操作默默地把被拷贝的<code>auto_ptr——vector</code>中的那个——设为<code>NULL</code>。</p>
<p>另外，当<code>pivotValue</code>出了生存期，它会自动删除指向的<code>Widget</code>。这时sort调用返回了，<code>vector</code>的内容已经改变了，而且至少一个<code>Widget</code>已经被删除了。</p>
<p>也可能有几个<code>vector</code>元素已经被设为<code>NULL</code>，而且几个<code>widget</code>已经被删除，因为快速排序是一种递归算法，递归的每一层都会拷贝一个主元。</p>
<h2 id="结论">结论</h2>
<p>智能指针的容器是很好的， 但是<code>auto_ptr</code><font color=red>完全不是那样的智能指针</font>。</p>]]></description></item><item><title>Effective STL [7] | 当使用new得指针的容器时，记得在销毁容器前delete那些指针</title><link>https://jianye0428.github.io/posts/clause_7/</link><pubDate>Wed, 26 Jul 2023 18:18:11 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/clause_7/</guid><description><![CDATA[<!-- <div class="details admonition quote">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-quote-right fa-fw" aria-hidden="true"></i>quote<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">note abstract info tip success question warning failure danger bug example quote</div>
    </div>
  </div> -->
<h2 id="stl容器能够做的事情">STL容器能够做的事情</h2>
<ul>
<li>
<p>提供了前向和逆向遍历的迭代器（通过<code>begin</code>、<code>end</code>、<code>rbegin</code>等）；</p>
</li>
<li>
<p>能告诉你所容纳的对象类型（通过<code>value_type</code>的<code>ttypedef</code>）；</p>
</li>
<li>
<p>在插入和删除中，负责任何需要的内存管理；</p>
</li>
<li>
<p>报告容纳了多少对象和最多可能容纳的数量（分别通过<code>size</code>和<code>max_size</code>）；</p>
</li>
<li>
<p>当容器自己被销毁时会自动销毁容纳的每个对象。</p>
</li>
</ul>
<h2 id="容器内包含指针">容器内包含指针</h2>
<p>虽然STL容器被销毁时，能够自动销毁容纳的每个对象，但是如果这些对象是通过new分配的对象的指针时，它不会调用<code>delete</code>，销毁指针所指向的对象。</p>
<p><strong>Example</strong></p>
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">doSomething</span><span class="p">()</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">vector</span><span class="o">&lt;</span><span class="n">Widget</span><span class="o">*&gt;</span> <span class="n">vwp</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">SOME_MAGIC_NUMBER</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">vwp</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="k">new</span> <span class="n">Widget</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">...</span> <span class="c1">// work
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">}</span> <span class="c1">// Widgets在这里泄漏！
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>这段代码将直接导致内存泄露。</p>
<p>当<code>vwp</code>结束其生命周期后，<code>vwp</code>的每个元素都被销毁，但不会<code>delete</code>每个<code>new</code>得到的对象。</p>
<p>那样的删除是你的职责，而不是vector的。这是一个特性。只有你知道一个指针是否应该被删除。</p>
<p>可以很简单地实现：</p>
<div class="highlight" id="id-2"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">doSomething</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">vector</span><span class="o">&lt;</span><span class="n">Widget</span><span class="o">*&gt;</span> <span class="n">vwp</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">...</span> <span class="c1">// work
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">for</span> <span class="p">(</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Widget</span><span class="o">*&gt;::</span><span class="n">iterator</span> <span class="n">i</span> <span class="o">=</span> <span class="n">vwp</span><span class="p">.</span><span class="n">begin</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="n">i</span> <span class="o">!=</span> <span class="n">vwp</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">     <span class="k">delete</span> <span class="o">*</span><span class="n">i</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div><p>这段销毁的代码，仍然有2个问题：</p>
<ul>
<li>新的for循环代码比for_each多得多，没有使用for_each来的清楚</li>
<li>这段代码不是异常安全的。如果在用指针填充了vwp的时候和你要删除它们之间抛出了一个异常，你会再次资源泄漏。</li>
</ul>
<p><strong>for_each删除对象</strong></p>
<p>要把你的类似for_each的循环转化为真正使用for_each，你需要把delete转入一个函数对象中。</p>
<div class="highlight" id="id-3"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span> <span class="n">T</span><span class="o">&gt;</span>
</span></span><span class="line"><span class="cl"><span class="k">struct</span> <span class="nc">DeleteObject</span> <span class="o">:</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span> <span class="n">unary_function</span><span class="o">&lt;</span><span class="k">const</span> <span class="n">T</span><span class="o">*</span><span class="p">,</span> <span class="kt">void</span><span class="o">&gt;</span> <span class="p">{</span> <span class="c1">// 这里有这个继承
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">void</span> <span class="nf">operator</span><span class="p">()(</span><span class="k">const</span> <span class="n">T</span><span class="o">*</span> <span class="n">ptr</span><span class="p">)</span> <span class="k">const</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">     <span class="k">delete</span> <span class="n">ptr</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span></span></span></code></pre></td></tr></table>
</div>
</div><p>现在可以这么删除对象</p>
<div class="highlight" id="id-4"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">HappyWork</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="p">...</span> <span class="c1">// work
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">for_each</span><span class="p">(</span><span class="n">vwp</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">vwp</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span> <span class="n">DeleteObject</span><span class="o">&lt;</span><span class="n">Widget</span><span class="o">&gt;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div><p><strong>问题</strong></p>
<p>如果有人编写了一个类，该类继承了 string</p>
<div class="highlight" id="id-5"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">SpecialString</span><span class="o">:</span> <span class="k">public</span> <span class="n">string</span> <span class="p">{</span> <span class="p">...</span> <span class="p">};</span></span></span></code></pre></td></tr></table>
</div>
</div><p>这是很危险的行为，因为string，就像所有的标准STL容器，<strong>缺少虚析构函数</strong>，而从没有虚析构函数的类公有继承是一个大的C++禁忌。</p>
<p>当他删除 SpecialString 时就会资源泄露</p>
<div class="highlight" id="id-6"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">doSomething</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">deque</span><span class="o">&lt;</span><span class="n">SpecialString</span><span class="o">*&gt;</span> <span class="n">dssp</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">...</span>
</span></span><span class="line"><span class="cl">    <span class="n">for_each</span><span class="p">(</span><span class="n">dssp</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">dssp</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span> <span class="c1">// 行为未定义！通过没有
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">DeleteObject</span><span class="o">&lt;</span><span class="n">string</span><span class="o">&gt;</span><span class="p">());</span> <span class="c1">// 虚析构函数的基类
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">}</span> <span class="c1">// 指针来删除派生对象
</span></span></span></code></pre></td></tr></table>
</div>
</div><p><strong>解决</strong></p>
<p>可以通过编译器推断传给<code>DeleteObject::operator()</code>的指针的类型来消除这个错误（也减少DeleteObject的用户需要的击键次数）。</p>
<p><strong>把模板化从DeleteObject移到它的operator()</strong>：</p>
<div class="highlight" id="id-7"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">struct</span> <span class="nc">DeleteObject</span> <span class="p">{</span> <span class="c1">// 删除这里的
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="c1">// 模板化和基类
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span> <span class="n">T</span><span class="o">&gt;</span> <span class="c1">// 模板化加在这里
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">void</span> <span class="k">operator</span><span class="p">()(</span><span class="k">const</span> <span class="n">T</span><span class="o">*</span> <span class="n">ptr</span><span class="p">)</span> <span class="k">const</span>
</span></span><span class="line"><span class="cl">    <span class="p">{</span>
</span></span><span class="line"><span class="cl">     <span class="k">delete</span> <span class="n">ptr</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div><p>通过传给<code>DeleteObject::operator()</code>的指针的类型，自动实例化一个<code>operator()</code>。这种类型演绎下降让我们放弃使<code>DeleteObject</code>可适配的能力</p>
<p>现在删除 SpecialString 就会正常了</p>
<div class="highlight" id="id-8"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">doSomething</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">deque</span><span class="o">&lt;</span><span class="n">SpecialString</span><span class="o">*&gt;</span> <span class="n">dssp</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">...</span>
</span></span><span class="line"><span class="cl">    <span class="n">for_each</span><span class="p">(</span><span class="n">dssp</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">dssp</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span> <span class="n">DeleteObject</span><span class="p">());</span> <span class="c1">// good！
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div><p><font color=red>现在仍不是异常安全的。</font></p>
<p>果在SpecialString被new但在调用for_each之前抛出一个异常，就会发生泄漏。</p>
<p>这个问题可以以多种方式被解决，但最简单的可能是用<strong>智能指针的容器来代替指针的容器，典型的是引用计数指针</strong>。</p>
<h2 id="boost库中的shared_ptr">Boost库中的shared_ptr</h2>
<p>利用Boost的shared_ptr，本条款的原始例子可以重写为这样：</p>
<div class="highlight" id="id-9"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">doSomething</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">typedef</span> <span class="n">boost</span><span class="o">::</span><span class="n">shared_</span> <span class="n">ptr</span><span class="o">&lt;</span><span class="n">Widget</span><span class="o">&gt;</span> <span class="n">SPW</span><span class="p">;</span> <span class="c1">//SPW = &#34;shared_ptr to Widget&#34;
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">vector</span><span class="o">&lt;</span><span class="n">SPW</span><span class="o">&gt;</span> <span class="n">vwp</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">SOME_MAGIC_NUMBER</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">     <span class="n">vwp</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">SPW</span><span class="p">(</span><span class="k">new</span> <span class="n">Widget</span><span class="p">));</span> <span class="c1">// 从一个Widget建立SPW,然后进行一次push_back
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="p">...</span> <span class="c1">// work
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">}</span> <span class="c1">// 这里没有Widget泄漏，甚至在上面代码中抛出异常
</span></span></span></code></pre></td></tr></table>
</div>
</div><h2 id="结论">结论</h2>
<p>STL容器很智能，但它们没有智能到知道是否应该删除它们所包含的指针。</p>
<p>当你要删除指针的容器时要避免资源泄漏，你必须<strong>用智能引用计数指针对象</strong>（比如<code>Boost</code>的<code>shared_ptr</code>）来代替指针，或者你<strong>必须在容器销毁前手动删除容器中的每个指针</strong>。</p>]]></description></item><item><title>生成对抗网络GAN</title><link>https://jianye0428.github.io/posts/gan_1/</link><pubDate>Wed, 26 Jul 2023 10:03:45 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/gan_1/</guid><description><![CDATA[<!-- <div class="details admonition quote">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-quote-right fa-fw" aria-hidden="true"></i>quote<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">note abstract info tip success question warning failure danger bug example quote</div>
    </div>
  </div> -->
<h2 id="一gan的引入">一、GAN的引入</h2>
<p></p>
<p>GAN（Generative Adversarial Networks）是一种无监督的深度学习模型，提出于2014年，被誉为“近年来复杂分布上无监督学习最具前景的方法之一”。</p>
<div class="details admonition quote">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-quote-right fa-fw" aria-hidden="true"></i>quote<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content"><p>Yann Lecun对其的评价是：对抗式训练是迄今为止最酷的一件事情。</p>
<p>Adversarial training is the coolest thing since sliced bread.</p>
</div>
    </div>
  </div>
<p>我们来看下原文的标题：</p>
<ul>
<li>Generative：我们知道机器学习模型有两大类，第一个是分辨模型：对于一个数据去分辨它的类别，或者是预测一个实数值；另一类是生成模型，意思是怎么样生成这个数据本身。显然GAN是属于生成模型。</li>
<li>Adversarial：对抗的，这里指的是GAN提出的这种 framework 采用对抗训练的方式来work。</li>
<li>Nets：Network的简写。</li>
</ul>
<h2 id="二gan的应用举例">二、GAN的应用举例</h2>
<ul>
<li>数据生成：生成一些假的图像数据，比如海报中的人脸、文本生成图像等；</br></li>
<li>数据增强：从分割图生成假的真实街景，比如可以方便训练无人汽车等；</br></li>
<li>风格化和艺术的图像创造：比如转换图像风格、AI换脸、修补图像等；</br></li>
<li>声音的转换：比如一个人的声音转为另一个的声音、去除噪声等；</br></li>
<li>&hellip;&hellip;</br></li>
</ul>
<h2 id="三gan的快速概述">三、GAN的快速概述</h2>
<p>比如人脸检测、图像识别、语音识别等，<strong>机器总是在现有事物的基础上，做出描述和判断</strong>。能不能创造这个世界不存在的东西？</p>
<p>GAN就是为此而来，它包含三个部分：<strong>生成</strong>、<strong>判别</strong>、<strong>对抗</strong>。其中 <u>生成</u> 和 <u>判别</u> 是它的结构组成，<u>对抗</u>则是它的训练过程。</p>
<ul>
<li>生成：<strong>生成</strong> 和 <strong>判别</strong> 指的是两个独立的模型，生成器会根据随机向量产生假数据，这些假数据既可以是图片、也可以是文本，并<strong>试图</strong><font color=red>欺骗判别网络</font>；</li>
<li>判别：<strong>判别器</strong>负责判断接受到的数据是否是真实的，即对生成数据进行<font color=red>真伪鉴别</font>，试图正确识别所有假数据，它其实是一个二分类问题，会给出一个概率，代表着内容的真实程度；两者使用哪种网络并没有明确的规定，所以原文中作者称其为framework。比如可以使用擅长处理图片的CNN、常见的全连接等等，只要能够完成相应的功能就可以了。</li>
<li>对抗：这指的是 GAN 的交替训练过程。以图片生成为例，先让<font color=green><strong>生成器</strong></font>产生一些假图片，和收集到的真图片一起交给辨别器，让它学习区分两者，给真的高分，给假的低分，当判别器能够熟练判断现有数据后；再让 <font color=green><strong>生成器</strong></font> 以从 <font color=green><strong>判别器</strong></font> 处获得高分为目标，不断生成更好的假图片，直到能骗过判别器，重复进行这个过程，直到辨别器对任何图片的预测概率都接近0.5，也就是无法分辨图片的真假，就停止训练。</li>
</ul>
<p>也就是说在训练迭代的过程中，两个网络持续地进化和对抗，直到到达一个平衡状态，即判别网络无法识别真假。虽说是对抗，但是生成器和辨别器的关系更像是朋友，最初大家都是“无名之辈”，随着不断的训练“切磋”，共同成为“一代高手”。</p>
<p>我们<font color=red><strong>训练GAN的最终目标</strong></font>是获得好用的生成器，也就是生成足够以假乱真的内容，能完成类似功能的还有波尔斯曼机、变分自编码器等，它们被称为生成模型。</p>
<h2 id="四原文的摘要">四、原文的摘要</h2>
<p></p>
<div class="details admonition quote">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-quote-right fa-fw" aria-hidden="true"></i>quote<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">到底什么是GAN？</div>
    </div>
  </div>
<p>首先作者提出一个新的framework，通过一个<strong>对抗过程</strong>来估计一个生成模型。</p>
<p>同时会训练两个模型：</p>
<ul>
<li>第一个模型叫做 <mark><strong>生成模型G</strong></mark>，用来捕获整个数据的分布，其实就是通过 <font color=red>生成器</font> 去拟合和逼近真实的数据分布；</li>
<li>第二个是 <mark><strong>辨别模型D</strong></mark>，它是用来估计一个样本是来自真正的数据、还是来自于<strong>G</strong>生成的。</li>
</ul>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">这里稍微解释一下：<strong>生成模型</strong> 它就是对整个数据的分布进行建模，使得能够生成各种分布。这里“分布”是一个很一般化的词，比如生成图片、生成文本、生成视频等。在统计学眼里，整个世界是通过采样不同的分布来得到的，所以想要生成东西，目的就是要抓住整个数据的一个分布。</div>
    </div>
  </div>
<p>生成模型的任务是尽量的想<strong>让辨别模型犯错</strong>，这个过程是一个<strong>最大最小的博弈</strong>。在任何函数空间的<strong>G</strong>和<strong>D</strong>里面，存在一个独一无二的解，这个解是代表：<strong>G</strong>能够找出训练数据的真实分布（生成的数据分布趋向于真实数据分布），此时辨别器就判别不出来了，所以概率值为$\frac{1}{2}$。</p>
<p>如果<strong>G</strong>和<strong>D</strong>是一个MLP的话，那么整个系统就可以通过误差反向传播来进行训练。作者说这里不需要使用任何的马尔科夫链，或者说是对一个近似的推理过程展开（说白了意思好像就是和别人的方法比比较简单一点），最后就是说实验的效果非常好。</p>
<h2 id="五原文的例子">五、原文的例子</h2>
<p></p>
<p>在对抗网络的框架里有两类模型：一个是<mark><strong>生成模型</strong></mark>、一个是<mark><strong>判别模型</strong></mark>：</p>
<ul>
<li>生成模型比喻成造假的人，它要去产生假币；</li>
<li>判别模型比喻成警察，警察的任务就是很好的鉴别假币和真币；</li>
</ul>
<p>造假者和警察会不断的学习，造假者会提升自己的造假技能，警察也会提升自己判别真币和假币的性能。最后希望造假者能够赢，就是说造的假钱和真钱一模一样，然后警察没有能力去区分真币和假币，那么这个时候就可以使用生成器生成和真实数据一样的数据了。</p>
<h2 id="六gan模型结构--训练gan的目的">六、GAN模型结构 &amp; 训练GAN的目的</h2>
<p>摘要说的已经很清楚了，GAN由两部分组成：</p>
<ul>
<li>生成器G（Generator）；</li>
<li>判别器D（Discriminator）；</li>
</ul>
<p>我们的最终目的是希望生成器<strong>G</strong>，能够<font color=purple>学习到样本的真实分布$P_{\text{data}}(x)$</font>，那么就能生成之前不存在的、但是却又很真实的样本。</p>
<p>那再啰嗦的说明白一点就是：</p>
<ul>
<li>我们把随机向量（随机噪声）定义为 $z$，$z \in F$，可以是任意分布，比如正态分布、均匀分布。</li>
<li>将随机噪声输入到 <strong>生成器G</strong> 中，<strong>G</strong>其实看成一个函数就可以，它可以是任意的一个神经网络，因为神经网络可以逼近任何形式的函数。</li>
<li>随机噪声 $z$ 经过<strong>生成器G</strong>后会产生一个 $G(z)$，生成的这个新的向量 $G(z)$，它可以记为服从$P_G(x)$。但是$P_G(x)$这个分布不是我们想要的，我们想要的是<strong>生成器G</strong>生成一个满足于真实分布$P_{\text{data}}(x)$的数据。</li>
<li>通过不断的训练迭代，更新调整生成器G的参数，使得$P_G(x)$近似于 $P_{\text{data}}(x)$。</li>
</ul>
<p>通过调整 <strong>生成器G</strong> 的参数，使得<font color=violet>它生成的分布和真实的分布尽可能的像</font>，这个就是最终要达到的目的，可以通过 生成器G 生成一些满足真实分布，但又不是真实存在的数据。</p>
<p>我们以手写数字识别为例，图例如下：</p>
<p></p>
<p>GAN模型结构图如下示例：</p>
<p></p>
<ul>
<li>我们将随机噪声输入到<strong>生成器G</strong>中，产生 $G(z)$，我们把它叫做$x_{\text{fake}}$，$x_{\text{fake}}$为生成的图片，就是假的图片；</li>
<li>我们还有满足于真实分布$P_{\text{data}}(x)$的数据，记为$x_{\text{real}}$；</li>
<li>我们把 $x_{\text{real}}$ 和 $x_{\text{fake}}$ 同时送到<strong>判别器D</strong>中去训练，做一个二分类任务，判断是真还是假；</li>
</ul>
<h2 id="七举例理解gan的原理">七、举例理解GAN的原理</h2>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">因为原文举的例子比较敏感，我们以李宏毅老师的例子（中央电视台鉴宝节目：一槌定音）来进行GAN原理的阐述。</div>
    </div>
  </div>
<p></p>
<p>假设现在有一个人，我们称它为小王，小王是一个收藏家，它的收藏室里收藏了很多“国宝”。但是小王不想只做一个收藏家，他还想高仿这些“国宝”，我们这里将高仿的赝品定义为“工艺品”。</p>
<p>基于GAN的目标，我们知道：</p>
<ul>
<li>小王最终想成为一个水平很高的“工艺品大师”；</li>
</ul>
<p>但是如果想成为一个“工艺品”方面的专家，小王自己在家闭门造车肯定是行不通的，因为我们的总目标是想让小王成为一个高水平的、可以以假乱真的工艺品大师。为了达到这个目标，首先需要一个高水平的鉴赏专家（高水平的对手），其次小王本身就要是个高水平的工艺品大师。所以小王还需要找一个水平很高的国宝鉴赏专家。鉴赏专家负责辨别出真的“国宝”和小王的“工艺品”，小王负责高仿生产“工艺品”。</p>
<p></p>
<p>概述来说：<strong>小王需要先有一个高水平的专家，然后才可能成为一个高水平的大师。高水平的专家可以看成一种手段，成为高水平的大师才是我们的目标。</strong></p>
<h2 id="八数学描述">八、数学描述</h2>
<h3 id="81-相关符号">8.1 相关符号</h3>
<p>基于上述鉴宝例子，我们来看一下GAN的数学描述，首先需要强调的是：</p>
<ul>
<li>工艺品经过鉴赏专家判断后，是会受到一个 feedback 的；</li>
<li>对于鉴赏专家而言，它也会从工艺品受到一个 feedback ，当然这是潜在的；</li>
</ul>
<p>我们就来看一下，这个例子如何用数学符号去表示：</p>
<ul>
<li>
<p>&ldquo;国宝&quot;是静态的，它相当于我们的真实样本 ${x_{\text{real}<em>i}}^N</em>{i=1}$ ，这里我们以 $P_{data}$ 表示；</p>
</li>
<li>
<p>工艺品也是从一个概率分布里抽样出来的，我们将工艺品记作 ${x_{\text{fake}<em>i}}^N</em>{i=1}$ ，我们把这个概率分布称作 $P_g(x;\theta_{g})$，g就代表Generator的意思；</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">注意我们并不直接对 $P_g$ 建模，即不直接对生成模型本身进行建模，我们用一个神经网络去逼近这个分布，纯粹的神经网络它是不具备随机性的，所以我们会假设它有一个 $z$，就是前面提到的随机噪声，是来自于一个简单的分布，比如高斯分布： $z \sim P_Z(z)$ ；</div>
    </div>
  </div>
</li>
<li>
<p>原始的GAN里，神经网络就用NN表示，它本身就是一个确定性变换，即是一个复杂函数，表示为 $G(z;\theta_{g})$；</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">$\theta_g$ 在NN里就是表示权重参数，在 $P_g$ 里就是代表概率分布参数。</div>
    </div>
  </div>
</li>
<li>
<p>鉴赏专家也可以看成一个概率分布，我们也用一个NN来描述它：$D(x; \theta_{d})$，代表 $x$ 是国宝的概率</p>
</li>
</ul>
<p></p>
<p>对于鉴赏专家 <strong>(判别器D)</strong> 接收到的来说：</p>
<ul>
<li>可以是来自国宝、也可以是来自于工艺品，是无所谓的，重要的是本身是代表是国宝的概率。</li>
</ul>
<p>对于判别器D的输出来说：</p>
<ul>
<li>$D(x)$ 的值越趋近于1，说明它是国宝的概率就越大；越趋近于0，说明它是工艺品的概率就越大。</li>
</ul>
<p>上图又可简化为：</p>
<p></p>
<p>一方面是从 $P_{data}$ 里来的 $x_{real}$，一方面是 $z$ 输入到生成器后的输出 $x_{fake}$，$z$ 为噪声。</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">换句话说, $z$ 是从简单分布中采样，经过生成器后变成 $x$，此时生成的由的先验分布和生成器共同决定。</div>
    </div>
  </div>
<h3 id="82高专家的目标函数">8.2、“高专家”的目标函数</h3>
<p>符号描述表述清楚后，我们看一下GAN的目标函数，首先回顾一下GAN的目标：<u><strong>成为一个高水平的、可以以假乱真的大师</strong></u>。为了达到这个目标，我们又可以分为一个手段和一个目标：</p>
<ul>
<li>手段：<strong>需要一个高水平的鉴别专家</strong>；</li>
<li>目标：<strong>成为高水平的工艺品大师</strong>。</li>
</ul>
<p>也就是说我们需要<u><strong>先成就一个高水平的专家，才有可能成就一个高水平的大师</strong></u>，所以它们的关系是：(高大师(高专家))。</p>
<p>首先看高专家，高专家水平高体现在：国宝判别为真、工艺品判别为假：</p>
<p>$$
高专家：
\begin{equation}
\left{
\begin{aligned}
%\nonumber
if \ x \ is \ from \ P_{data}, \ then D(x) \uparrow\
if \ x \ is \ from \ P_{g}, \ then D(x) \downarrow\
(z \ is \ from \ P_{z}) \
\end{aligned}
\right.
\end{equation}
$$</p>
<p>为了将式子统一起来，我们改写为：</p>
<p>$$
高专家：
\begin{equation}
\left{
\begin{aligned}
%\nonumber
if \ x \ is \ from \ P_{data}, \ then D(x) \uparrow\
if \ x \ is \ from \ P_{g}, \ then \ 1-D(x) \uparrow\
(z \ is \ from \ P_{z}) \
\end{aligned}
\right.
\end{equation}
$$</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">因为 $D(x)$ 是一个概率值分布，范围是0~1， $D(x)$ 偏小， $1-D(x)$ 则相应的就偏大。</div>
    </div>
  </div>
<p>对于工艺品，$x$ 是从<strong>生成器G</strong>来的，所以可以表示成 $G(z)$：</p>
<p>$$
高专家：
\begin{equation}
\left{
\begin{aligned}
%\nonumber
if \ x \ is \ from \ P_{data}, \ then D(x) \uparrow\
if \ x \ is \ from \ P_{g}, \ then \ 1 - D(G(z)) \uparrow\
(z \ is \ from \ P_{z}) \
\end{aligned}
\right.
\end{equation}
$$</p>
<p>为了使目标函数更容易表达，或者说计算更加方便，我们加上，所以进一步表达为：
$$
高专家：
\begin{equation}
\left{
\begin{aligned}
%\nonumber
if \ x \ is \ from \ P_{data}, \ then \ \log{D(x)} \uparrow\
if \ x \ is \ from \ P_{g}, \ then \ \log{(1 - D(G(z)))} \uparrow\
(z \ is \ from \ P_{z}) \
\end{aligned}
\right.
\end{equation}
$$</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">$\log$ 为增函数，$\log(x)$ 与 $x$ 的增减性保持一致，在极大化参数的时候，与原始求解是一样的。</div>
    </div>
  </div>
<p>所以对于成就一个高专家来说，目标函数如下：</p>
<p>$$\max_{D} E_{x \sim P_{data}}[\log{D(x)}] + E_{z \sim P_{z}}[\log (1 - D(G(z)))]$$</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content"><p>可能有同学不明白为什么原文这里用期望，其实很简单，我们假设数据分布总共有个样本，那么它的期望可以表示为：</p>
<p>$$E_{x \sim P_{data}}[\log(D(x))] = \frac{1}{N} \sum_{i=1}^{N} \log(D(x_i)), x_i \sim P_{data}$$</p>
</div>
    </div>
  </div>
<h3 id="83高大师的目标函数">8.3、“高大师”的目标函数</h3>
<p>我们再来看高大师的目标函数，<strong>高大师是建立在高专家的水平之上</strong>，对于高大师来讲，希望高专家将所有的工艺品都判断为真：</p>
<p>$$高大师: if \ x \ from \ P_g,\ then \ D(G(z)) \uparrow $$</p>
<p>为了统一起来，我们改写为:</p>
<p>$$高大师: if \ x \ from \ P_g,\ then \ (1 - D(G(z))) \downarrow $$</p>
<p>所以对于高大师来讲，目标函数为:</p>
<p>$$\min_{G} E_{z \sim P_z}[\log (1 - D(G(z)))]$$</p>
<h3 id="84总目标函数">8.4、总目标函数</h3>
<p>本着<strong>先成就 高专家, 再成就 高大师</strong>的原则，GAN的目标函数为：</p>
<p>$$\min_{G} \max_{D} V(D, G) = \mathbb{E_{x\sim p_{data}(x)}}[\log(D(x))] + \mathbb{E_{z\sim p_{z}(z)}}[\log(1 - D(G(z)))]$$</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">通过目标函数我们也能看出，GAN模型的复杂度，不在于模型的定义，而在于模型的traning，也就是D和G的学习。</div>
    </div>
  </div>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">还有一点需要强调的是，自始至终我们都没有去直接面对 $P_g$，我们实际上使用一个可微神经网络 $G(z)$ 去逼近这个 $P_g$ ，而且是从采样的角度去逼近，换句话说，对于生成网络 $P_g$，GAN是绕过了它，并没有直接去解决 $P_g$，而是从采样的角度去逼近它。所以GAN又被称做：Implicit Density Model.</div>
    </div>
  </div>
<p>公式比较多，所以对目标函数再啰嗦的介绍下：</p>
<p>我们可以得出，它实际上就要对价值函数 $V(D, G)$ 进行min、max的博弈，还有需要注意的是：$D(x)$ 是判别器的输出，它要做二分类，所以经过sigmoid之后 $D(x) \in [0, 1]$；</p>
<p>我们来看一下它是怎么工作的：</p>
<ul>
<li>首先固定住G不动，通过调整D的参数，来最大化价值函数 $V(D, G)$：
<ul>
<li>要想最大化 $V$ ，左边的 $D(x)$ 要趋近于1（这样才能保证log的值尽可能大），同时要让右边的 $D(G(z))$ 趋近于0（这样才能保证 $log(1-D(G(z)))$ 尽可能大）；</li>
<li>$\max V(D, G)$ 其实就是把真实数据和假数据区分的一个过程.
$$\min_{G} \max_{D} V(D, G) = \mathbb{E_{x\sim p_{data}(x)}}[\log(D(x))] + \mathbb{E_{z\sim p_{z}(z)}}[\log(1 - D(G(z)))]$$</li>
</ul>
</li>
<li>然后固定住D不动，此时公式的左部分已经是个定值了，我们<strong>调整G的参数</strong>，来最小化价值函数 $V(D, G)$：
<ul>
<li>要让 $V(D, G)$ 最小，那么就要让 $D(G(z))$ 趋近于1，只有 $V(G(z))$ 趋近于1的时候，定义域里的值才能趋近于0，也就是log会变得越来越小，达到最小化 $V$ 的过程；</li>
<li>这个过程就是想让 $D(G(z))$ 趋近于1，z满足生成数据的分布，它是假的，那么 $min_G$ 的过程就是想要调整生成器，来骗过判别器，从而<strong>使得假数据被判别为真</strong>。
$$\min_{G} \max_{D} V(D, G) = \mathbb{E_{x\sim p_{data}(x)}}[\log(D(x))] + \mathbb{E_{z\sim p_{z}(z)}}[\log(1 - D(G(z)))]$$</li>
</ul>
</li>
</ul>
<p>总结如下：</p>
<ul>
<li>固定G, 调整D, 最大化 $V(D, G)$, 导致 $D(x) \rightarrow 1, D(G(z)) \rightarrow 0$</li>
<li>固定D, 调整G, 最小化 $\max_{D}V(D, G)$, 导致 $D(G(z)) \rightarrow 1$</li>
</ul>
<p>想必肯定有同学会发现这里出现的一个矛盾：上面的趋近于0，下面的趋近于1，这个矛盾、冲突，就理解为GAN中的<strong>对抗</strong>的意思。</p>
<h2 id="九全局最优解推导">九、全局最优解推导</h2>
<p>因为公式多、篇幅长，所以在推导最优解之前，我们先回顾一下GAN里的三个角色：</p>
<ul>
<li>真实样本分布$P_{data}$；</li>
<li><strong>生成器 Generator</strong> 对应概率分布为:$P_g$，即代表生成器生成数据的概率分布；</li>
<li><strong>判别器 Discriminator</strong> 对应的条件概率分布是离散的，就是0-1分布（伯努利分布），给定x的情况下，1代表正品、0代表工艺品（赝品）；</li>
</ul>
<p>我们的最终目标，就<strong>是想让生成器生成的样本的概率分布$P_g$无限的接近于$P_{data}$</strong>，即：$P_g \rightarrow P_{data}$；</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content"><p>我们常规的生成模型（不是GAN），是直接对$P_g$进行建模: $P_g \rightarrow \theta_{g}$, 极大似然估计表示如下：</p>
<p>$$\theta_g = \argmax_{\theta_g} \sum_{i=1}^N \log{P_g}(x_i) = \argmin KL(P_{data} || P_g)$$</p>
<p>从距离的角度讲，是最小化KL散度，最终想让$P_{data} = P_g$，这就是原先如何把参数求出来的策略。</p>
</div>
    </div>
  </div>
<h3 id="91关于-d-的最大值">9.1、关于 D 的最大值</h3>
<p>GAN从<strong>对抗学习</strong>的角度去构造目标函数，我们上面构造的目标函数，只是从逻辑上觉得它没有问题，那么我们可能会考虑：</p>
<ul>
<li>这个最大最小问题，它的最优解存在不存在？</li>
<li>如果最优解 $P_g$（就是G）存在，那么全局最优的情况下，$P_g$是否等于$P_{data}$？</li>
</ul>
<p>如果这个不成立的话，那么其实这个目标函数是没有意义的，我们来看一下，方便记作，直接用论文中的符号来描述：</p>
<p></p>
<p>我们记：</p>
<p>$$V(D, G) = \mathbb{E}<em>{x\sim p</em>{data}(x)}[\log{D(x)}] + \mathbb{E}<em>{z\sim p</em>{z}}[\log{1 - D(G(z))}]$$</p>
<p>我们先求max，根据期望的定义：$E_{x \sim P(x)} = \int_x p(x)f(x)dx$，将其展为积分的形式：</p>
<p>$\quad For \quad fixed \quad G, 求： \max_D(V(D, G))$
$$
\begin{align}
\max_D V(D, G) &amp;= \int P_{data} \cdot \log D dx + \int P_g \cdot \log (1 - D) dx \
&amp;= \int {[P_{data} \cdot \log D + P_g \cdot \log(1 - D)]} dx
\end{align}
$$</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">这里两个积分中的x确实是不同的变量，但是积分微元的符号可以做任意变换，不用纠结这里。</div>
    </div>
  </div>
<p>我们要求里面函数关于x积分的最大值，那么就看一下它的导数：</p>
<p>$$
\begin{align}
\frac{\partial}{\partial{D}}(\max V(D, G)) &amp;= \frac{\partial}{\partial D}\int {[P_{data} \cdot \log D + P_g \cdot \log(1 - D)]} \
&amp;= \int \frac{\partial}{\partial D} {[P_{data} \cdot \log D + P_g \cdot \log(1 - D)]} \
&amp;= \int {[P_{data} \cdot \frac{1}{D} + P_g \cdot \frac{-1}{\log(1 - D)}]} \Longleftrightarrow 0\
\end{align}
$$</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content"><p>因为积分是对x积的，求导是对D求的，两者互不干扰可以交换词序。</p>
<p>最优的时候导数为0。</p>
</div>
    </div>
  </div>
<p>$$\therefore P_{data} \cdot \frac{1}{D} = P_g \cdot \frac{1}{1-D}$$</p>
<p>所以当固定G时，最优的D为:</p>
<p>$$D^*<em>G = \frac{P</em>{data}}{P_{data} + P_g}$$</p>
<h3 id="92-关于-g-的最小值">9.2 关于 G 的最小值</h3>
<p>最大值求出来之后，我们再来看关于G的最小值，我们将$D^*$带进去：</p>
<p>$$
\begin{align}
\min_G \max_D V(D, G) &amp;= \min_G V(D^*<em>G, G) \
&amp;= \min_G E</em>{x \sim P_{data}}[\log(\frac{P_{data}}{P_{data} + P_g})] + E_{x \sim P_{g}}[\log(1 - \frac{P_{data}}{P_{data} + P_g})] \
&amp;= \min_G E_{x \sim P_{data}}[\log(\frac{P_{data}}{P_{data} + P_g})] + E_{x \sim P_{g}}[\log(\frac{P_{g}}{P_{data} + P_g})]\
\end{align}
$$</p>
<p>这里 $P_{data}$ 和 $P_g$，和KL散度的定义非常类似，KL divergence定义：</p>
<p>$$KL(P||Q) = E_{x \sim P}[\log(\frac{P(x)}{Q(x)})]$$</p>
<p>但是我们不能直接这么写，我们需要保证分子和分母必须同时为两个概率分布，但是分母是$P_{data} + P_g$，是两个概率分布相加，那它的取值就变成[0, 2]了。</p>
<p>所以我们给它再除以个2就可以了，取值范围就又变成[0, 1]了。换句话说，可以把它看成概率密度函数，具体什么样子无所谓，它的取值在[0, 1]之间，并且是连续的。</p>
<p>$$
\begin{align}
\min_G \max_D V(D, G) &amp;= \min_G V(D^*<em>G, G) \
&amp;= \min_G E</em>{x \sim P_{data}}[\log(\frac{P_{data}}{P_{data} + P_g})] + E_{x \sim P_{g}}[\log(1 - \frac{P_{data}}{P_{data} + P_g})] \
&amp;= \min_G E_{x \sim P_{data}}[\log(\frac{P_{data}}{P_{data} + P_g})] + E_{x \sim P_{g}}[\log(\frac{P_{g}}{P_{data} + P_g})]\
&amp;= \min_G E_{x \sim P_{data}}[\log(\frac{P_{data}}{(P_{data} + P_g)/2} \cdot\frac{1}{2})] + E_{x \sim P_{g}}[\log(\frac{P_{g}}{(P_{data} + P_g)/2}\cdot\frac{1}{2})]\
&amp;= \min_{G} KL (P_{data} || \frac{P_{data} + P_g}{2}) + KL (P_{g} || \frac{P_{data} + P_g}{2}) - \log4\
\end{align}
$$</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>tips<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">将两个$\log(\frac{1}{2})$拿出去，$\log(\frac{1}{2}) = \log1 - \log2 = -\log2,$，$-\log2$的期望就是它自己，两个就是$-\log2-\log2 = -\log4$</div>
    </div>
  </div>
<p>我们得出上式，发现它又满足 JS divergence 的定义：</p>
<p>$$JSD(P||Q) = \frac{1}{2} KL(P || M) + \frac{1}{2} KL (Q||M), 其中 M = \frac{P + Q}{2}$$</p>
<p>所以上式又可写成：</p>
<p>$$\min_G - \log 4 + 2 JSP(P_{data}||P_g)$$</p>
<p>JS divergence是衡量两个分布之间的距离，所以只有当这两个分布越来越相等的时候，就找到这个式子的最小值了，故：</p>
<p>当$P_g(x) = P_{data}(x)$时，上式可得最小值。</p>
<p>所以我们只需要优化：</p>
<p>$$\min_G\max_D V(D, G) = \mathbb{E}<em>{x\sim{p</em>{data}(x)}}[\log D(x)] + \mathbb{E}<em>{z\sim{p</em>{z}(z)}}[1 - \log D(G(z))]$$</p>
<p>就可以得到$P_g(x) = P_{data}(x)$.</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>tips<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">另外，当 $P_g(x) = P_{data}(x)$ 时，又因为 $D^<em><em>G = \frac{P</em>{data}}{P_{data} + P_g}$， 所以此时 $D^</em> = \frac{1}{2}$ 。意思是，在最优的情况下，鉴赏专家已经没有分辨真假的能力了，概率都0.5，这个时候判别器对于生成器而言，已经没有继续学习的必要了。</div>
    </div>
  </div>
<h2 id="十原文给出的训练步骤">十、原文给出的训练步骤</h2>
<p></p>
<ul>
<li>在每一个step里先采样m个噪音样本；</li>
<li>再采样m个来自于真实数据的样本；这样就组成了一个大小为2m的小批量；</li>
<li>将样本分别放到 <strong>生成器</strong> 和 <strong>辨别器</strong> 去求梯度，更新 <strong>辨别器</strong> 参数；</li>
</ul>
<p>做完之后：</p>
<ul>
<li>再采样m个噪音样本，放到公式的第二项里面（因为我们要<strong>更新生成器</strong>，生成器与第一项无关），算出它的梯度；</li>
<li>然后对生成器进行参数更新。</li>
</ul>
<p>这样就完成了一次迭代，可以看到每次迭代里，我们是<strong>先更新辨别器，再更新生成器</strong>。</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>tips<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content"><p>k是一个超参数，不能太小也不能太大，要保证辨别器有足够的更新，但也不要更新太好了。如果没有足够好的更新，就是生成器变换了之后，没有把辨别器更新的足够好，</p>
<p>
G已经做了变化，但是D没有做什么改变，再更新G来糊弄D，其实意义不大。</p>
<p>反过来讲，如果一更新就把D训练到完美，那么1-D就会变成0，对一个0的东西求导，那么就会在生成模型上更新有困难。</p>
<p>回到原文的例子，辨别器是警察，生成器就是造假者，假设警察特别厉害，造假者产一点假钞出来就被连锅端了，那造假者就没能力改进和提升自己了，但反过来讲，如果警察无力，造假者随便造点东西，警察也看不出来，那造假者就不会有动力去改进和提升自己。</p>
<p>所以最好是两者实力相当、相爱相杀，大家一起进步。所以k的调参，要使得D的更新和G的更新进度都差不多。</p>
</div>
    </div>
  </div>
<h2 id="十一gan原理及训练过程总结">十一、GAN原理及训练过程总结</h2>
<h3 id="111gan原理总结">11.1、GAN原理总结</h3>
<p>GAN主要包括了两部分：</p>
<ul>
<li><mark>生成器（Generator）</mark>：生成器主要用来学习真实数据的分布，从而让自身生成的数据更加真实，骗过判别器；</li>
<li><mark>判别器（Discriminator）</mark>：判别器则需要对接受的数据进行真假判断。</li>
</ul>
<p>在训练过程中，生成器努力地让生成的数据更加真实，而判别器则努力地去识别出数据的真假，这个过程相当于一个二人博弈，随着时间的推移，生成器和判别器在不断的进行对抗，这就是它对抗的含义。</p>
<p>最终两个网络达到了一个动态均衡：生成器生成的数据接近于真实数据分布，而判别器识别不出真假数据，对于给定数据的预测为真的概率基本接近0.5（相当于随机猜测类别）。</p>
<p>GAN设计的关键在于损失函数的处理：</p>
<ul>
<li>对于判别模型，损失函数是容易定义的，判断一张图片是真实的还是生成的，显然是一个二分类问题。</li>
<li>对于生成模型，损失函数的定义就不是那么容易，我们希望生成器可以生成接近于真实的图片，对于生成的图片是否像真实的，我们人类肉眼容易判断，但具体到代码中，是一个抽象的，难以数学公里化定义的范式。</li>
</ul>
<p>针对这个问题，我们不妨把生成模型的输出，交给判别模型处理，让判别器判断这是一个真实的图像还是假的图像，因为深度学习模型很适合做分类，这样就将生成器和判别器紧密地联合在了一起。</p>
<div class="details admonition Note open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>tips<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">假如我们直接用生成器训练，它的训练结果并不会得到一个真实的图像，而会得到一个比较模糊的图像，因为我们无法构建一个合适的损失去判断它是否像真实图片，所以它会将所有训练样本做平均，产生一个比较糊的图片。这就是为什么要将生成器的样本交给判别器来构建损失。</div>
    </div>
  </div>
<h3 id="112gan算法流程总结">11.2、GAN算法流程总结</h3>
<ul>
<li>$G$ 是一个生成图片的网络，它接收一个随机的噪声z，通过这个噪声生成图片$G(z)$，记作；</li>
<li>$D$ 是一个判别网络，判别一张图片是不是“真实的”，它的输入参数是x，x代表一张图片，输出$D(x)$，代表x为真实图片的概率，如果为1，就代表100%是真实的图片，输出为0，就代表不是真实图片。</li>
</ul>
<p>在训练过程中，将随机噪声输入生成网络G，得到生成的图片；判别器接受生成的图片和真实的图片，并尽量将两者区分开来。在这个计算过程中，能否正确区分生成的图片和真实的图片将作为判别器的损失；而能否生成近似真实的图片、并使得判别器将生成的图片判定为真，将作为生成器的损失。</p>
<p>生成器的损失是通过判别器的输出来计算的，而判别器的输出是一个概率值，我们可以通过交叉熵来计算。</p>
<h2 id="十二torch复现">十二、torch复现</h2>
<p><a href="https://wangguisen.blog.csdn.net/article/details/127820071"target="_blank" rel="external nofollow noopener noreferrer">https://wangguisen.blog.csdn.net/article/details/127820071<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
ref:</br>
[1]. <a href="https://arxiv.org/abs/1406.2661"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/abs/1406.2661<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[2]. <a href="https://www.bilibili.com/video/BV1eE411g7xc"target="_blank" rel="external nofollow noopener noreferrer">https://www.bilibili.com/video/BV1eE411g7xc<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[3]. <a href="https://www.bilibili.com/video/BV1rb4y187vD"target="_blank" rel="external nofollow noopener noreferrer">https://www.bilibili.com/video/BV1rb4y187vD<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[4]. <a href="https://www.bilibili.com/video/BV1HD4y1S7Pe"target="_blank" rel="external nofollow noopener noreferrer">https://www.bilibili.com/video/BV1HD4y1S7Pe<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br></p>]]></description></item><item><title>Transformer 详解</title><link>https://jianye0428.github.io/posts/transformerdetailedexplanation/</link><pubDate>Mon, 24 Jul 2023 17:37:50 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/transformerdetailedexplanation/</guid><description><![CDATA[<!-- <div class="details admonition quote">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-quote-right fa-fw" aria-hidden="true"></i>quote<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content"></div>
    </div>
  </div> -->
<p>ref:
[1]. <a href="https://www.bilibili.com/video/BV1mk4y1q7eK?p=1"target="_blank" rel="external nofollow noopener noreferrer">B站讲解视频<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
[2]. <a href="https://wmathor.com/index.php/archives/1438/"target="_blank" rel="external nofollow noopener noreferrer">https://wmathor.com/index.php/archives/1438/<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
[3]. <a href="https://wmathor.com/index.php/archives/1455/"target="_blank" rel="external nofollow noopener noreferrer">Transformer的pytorch实现<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<h2 id="transformer-详解">Transformer 详解</h2>
<p>Transformer 是谷歌大脑在 2017 年底发表的论文 <a href="https://arxiv.org/pdf/1706.03762.pdf"target="_blank" rel="external nofollow noopener noreferrer">attention is all you need<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> 中所提出的 seq2seq 模型。现在已经取得了大范围的应用和扩展，而 BERT 就是从 Transformer 中衍生出来的预训练语言模型</p>
<p>这篇文章分为以下几个部分</p>
<ul>
<li>Transformer 直观认识</br></li>
<li>Positional Encoding</br></li>
<li>Self Attention Mechanism</br></li>
<li>残差连接和 Layer Normalization</br></li>
<li>Transformer Encoder 整体结构</br></li>
<li>Transformer Decoder 整体结构</br></li>
<li>总结</br></li>
<li>参考文章</br></li>
</ul>
<h3 id="0-transformer-直观认识">0. Transformer 直观认识</h3>
<p>Transformer 和 LSTM 的最大区别，就是 LSTM 的训练是迭代的、串行的，必须要等当前字处理完，才可以处理下一个字。而 Transformer 的训练时并行的，即所有字是同时训练的，这样就大大增加了计算效率。<font color=green>Transformer 使用了位置嵌入 (Positional Encoding) 来理解语言的顺序</font>，使用自注意力机制（Self Attention Mechanism）和全连接层进行计算，这些后面会讲到</p>
<p>Transformer 模型主要分为两大部分，分别是 Encoder 和 Decoder。<font color=red>Encoder 负责把输入（语言序列）隐射成隐藏层（下图中第 2 步用九宫格代表的部分），然后解码器再把隐藏层映射为自然语言序列</font>。例如下图机器翻译的例子（Decoder 输出的时候，是通过 N 层 Decoder Layer 才输出一个 token，并不是通过一层 Decoder Layer 就输出一个 token）</p>
<p></p>
<p>本篇文章大部分内容在于解释 Encoder 部分，即把自然语言序列映射为隐藏层的数学表达的过程。理解了 Encoder 的结构，再理解 Decoder 就很简单了</p>
<p></p>
<p>上图为 Transformer Encoder Block 结构图，注意：下面的内容标题编号分别对应着图中 1,2,3,4 个方框的序号</p>
<h3 id="1-positional-encoding">1. Positional Encoding</h3>
<p>由于 Transformer 模型没有循环神经网络的迭代操作，所以我们必须提供每个字的位置信息给 Transformer，这样它才能识别出语言中的顺序关系。</p>
<p>现在定义一个<strong>位置嵌入</strong>的概念，也就是 Positional Encoding，位置嵌入的维度为 [max_sequence_length, embedding_dimension], 位置嵌入的维度与词向量的维度是相同的，都是 embedding_dimension。max_sequence_length 属于超参数，指的是限定每个句子最长由多少个词构成</p>
<p>注意，我们一般以字为单位训练 Transformer 模型。首先初始化字编码的大小为 [vocab_size, embedding_dimension]，vocab_size 为字库中所有字的数量，embedding_dimension 为字向量的维度，对应到 PyTorch 中，其实就是 nn.Embedding(vocab_size, embedding_dimension)</p>
<p>论文中使用了 sin 和 cos 函数的线性变换来提供给模型位置信息:</p>
<p>$$\left{\begin{aligned}
PE(pos, 2i) = \sin (pos/10000^{2i/d_{model}}) \
PE(pos, 2i + 1) = \cos (pos/10000^{2i/d_{model}}) \
\end{aligned}\right.$$</p>
<p>上式中 $pos$ 指的是一句话中某个字的位置，取值范围是 $[0, \text{max_sequence_length}]$ ， $i$ 指的是字向量的维度序号，取值范围是 $[0, \text{embedding_dimension} / 2]$ ， $d_{model}$ 指的是 embedding_dimension​的值</p>
<p>上面有 sin 和 cos 一组公式，也就是对应着 embedding_dimension 维度的一组奇数和偶数的序号的维度，例如 0,1 一组，2,3 一组，分别用上面的 sin 和 cos 函数做处理，从而产生不同的周期性变化，而位置嵌入在 embedding_dimension​维度上随着维度序号增大，周期变化会越来越慢，最终产生一种包含位置信息的纹理，就像论文原文中第六页讲的，位置嵌入函数的周期从 $ 2\pi $ 到 $10000 * 2 \pi$ 变化，而每一个位置在 embedding_dimension ​维度上都会得到不同周期的 $ \sin $ 和 $ \cos $ 函数的取值组合，从而产生独一的纹理位置信息，最终使得模型学到<strong>位置之间的依赖关系和自然语言的时序特性</strong>。</p>
<p>如果不理解这里为何这么设计，可以看这篇文章 <a href="https://wmathor.com/index.php/archives/1453/"target="_blank" rel="external nofollow noopener noreferrer">Transformer 中的 Positional Encoding<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<p>下面画一下位置嵌入，纵向观察，可见随着 embedding_dimension​序号增大，位置嵌入函数的周期变化越来越平缓</p>
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">    <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl">    <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</span></span><span class="line"><span class="cl">    <span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
</span></span><span class="line"><span class="cl">    <span class="kn">import</span> <span class="nn">math</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">get_positional_encoding</span><span class="p">(</span><span class="n">max_seq_len</span><span class="p">,</span> <span class="n">embed_dim</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 初始化一个positional encoding</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># embed_dim: 字嵌入的维度</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># max_seq_len: 最大的序列长度</span>
</span></span><span class="line"><span class="cl">        <span class="n">positional_encoding</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">            <span class="p">[</span><span class="n">pos</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="mi">10000</span><span class="p">,</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">i</span> <span class="o">/</span> <span class="n">embed_dim</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">pos</span> <span class="o">!=</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">)</span> <span class="k">for</span> <span class="n">pos</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_seq_len</span><span class="p">)])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">positional_encoding</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">positional_encoding</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">])</span>  <span class="c1"># dim 2i 偶数</span>
</span></span><span class="line"><span class="cl">        <span class="n">positional_encoding</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">positional_encoding</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">])</span>  <span class="c1"># dim 2i+1 奇数</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">positional_encoding</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">positional_encoding</span> <span class="o">=</span> <span class="n">get_positional_encoding</span><span class="p">(</span><span class="n">max_seq_len</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">embed_dim</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">positional_encoding</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&#34;Sinusoidal Function&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&#34;hidden dimension&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&#34;sequence length&#34;</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div><p></p>
<div class="highlight" id="id-2"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">positional_encoding</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&#34;dimension 1&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">positional_encoding</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&#34;dimension 2&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">positional_encoding</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s2">&#34;dimension 3&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&#34;Sequence length&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&#34;Period of Positional Encoding&#34;</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div><p></p>
<h3 id="2-self-attention-mechanism">2. Self Attention Mechanism</h3>
<p>对于输入的句子 $ X $，通过 WordEmbedding 得到该句子中每个字的字向量，同时通过 Positional Encoding 得到所有字的位置向量，将其相加（维度相同，可以直接相加），得到该字真正的向量表示。第 $ t $ 个字的向量记作 $ x_t $。</p>
<p>接着我们定义三个矩阵 $ W_Q $, $ W_K $, $ W_V $，使用这三个矩阵分别对所有的字向量进行三次线性变换，于是所有的字向量又衍生出三个新的向量 $ q_t $, $ k_t $, $ v_t $。我们将所有的 $ q_t $ 向量拼成一个大矩阵，记作查询矩阵 $ Q $ ，将所有的 $ k_t $ 向量拼成一个大矩阵，记作键矩阵 $ K $  ，将所有的 $ v_t $ 向量拼成一个大矩阵，记作值矩阵 $ V $ （见下图）</p>
<p></p>
<p>为了获得第一个字的注意力权重，我们需要用第一个字的查询向量 $ q_1 $ 乘以键矩阵 $ K $（见下图）</p>
<div class="highlight" id="id-3"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">                [0, 4, 2]
</span></span><span class="line"><span class="cl">    [1, 0, 2] x [1, 4, 3] = [2, 4, 4]
</span></span><span class="line"><span class="cl">                [1, 0, 1]</span></span></code></pre></td></tr></table>
</div>
</div><p></p>
<p>之后还需要将得到的值经过 softmax，使得它们的和为 1（见下图）</p>
<div class="highlight" id="id-4"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl"> softmax([2, 4, 4]) = [0.0, 0.5, 0.5]</span></span></code></pre></td></tr></table>
</div>
</div><p></p>
<p>有了权重之后，将权重其分别乘以对应字的值向量 $ v_t $（见下图）</p>
<div class="highlight" id="id-5"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">    0.0 * [1, 2, 3] = [0.0, 0.0, 0.0]
</span></span><span class="line"><span class="cl">    0.5 * [2, 8, 0] = [1.0, 4.0, 0.0]
</span></span><span class="line"><span class="cl">    0.5 * [2, 6, 3] = [1.0, 3.0, 1.5]</span></span></code></pre></td></tr></table>
</div>
</div><p></p>
<p>最后将这些<strong>权重化后的值向量求和</strong>，得到第一个字的输出（见下图）</p>
<div class="highlight" id="id-6"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">      [0.0, 0.0, 0.0]
</span></span><span class="line"><span class="cl">    + [1.0, 4.0, 0.0]
</span></span><span class="line"><span class="cl">    + [1.0, 3.0, 1.5]
</span></span><span class="line"><span class="cl">    -----------------
</span></span><span class="line"><span class="cl">    = [2.0, 7.0, 1.5]</span></span></code></pre></td></tr></table>
</div>
</div><p></p>
<p>对其它的输入向量也执行相同的操作，即可得到通过 self-attention 后的所有输出</p>
<p></p>
<p><strong>矩阵计算</strong></p>
<p>上面介绍的方法需要一个循环遍历所有的字$ x_t $，我们可以把上面的向量计算变成矩阵的形式，从而一次计算出所有时刻的输出</p>
<p>第一步就不是计算某个时刻的$ q_t $, $ k_t $, $ v_t $了，而是一次计算所有时刻的 $
Q $, $ K $, $ V $。计算过程如下图所示，这里的输入是一个矩阵 $ X $，矩阵第 $ t $ 行为第 $ t $ 个词的向量表示 $x_t$</p>
<p></p>
<p>接下来将 $ Q $ 和 $K_T$ 相乘，然后除以 $ \sqrt{d_k} $（这是论文中提到的一个 trick），经过 softmax 以后再乘以 $ V $ 得到输出</p>
<p></p>
<p><strong>Multi-Head Attention</strong></p>
<p>这篇论文还提出了 Multi-Head Attention 的概念。其实很简单，前面定义的一组 $Q $, $ K $, $ V $, 可以让一个词 attend to 相关的词，我们可以定义多组 $Q $, $ K $, $ V $，让它们分别关注不同的上下文。计算 $Q $, $ K $, $ V $ 的过程还是一样，只不过线性变换的矩阵从一组 $ W^Q $, $ W^K $, $ W^V $ 变成了多组$ W^Q_0 $, $ W^K_0 $, $ W^V_0 $  ，$ W^Q_1 $, $ W^K_1 $, $ W^V_1 $ ，… 如下图所示:</p>
<p></p>
<p>对于输入矩阵 $ X $ ，每一组 $ Q $ 、$ K $ 和 $ V $ 都可以得到一个输出矩阵 $ Z $ 。如下图所示</p>
<p></p>
<p><strong>Padding Mask</strong>
</p>
<p>上面 Self Attention 的计算过程中，我们通常使用 mini-batch 来计算，也就是一次计算多句话，即 $ X $ 的维度是 <code>[batch_size, sequence_length]</code>，sequence_length​是句长，而一个 mini-batch 是由多个不等长的句子组成的，我们需要按照这个 mini-batch 中最大的句长对剩余的句子进行补齐，一般用 0 进行填充，这个过程叫做 padding</p>
<p>但这时在进行 softmax 就会产生问题。回顾 softmax 函数 $\sigma(z_i) = \frac{e^{z_i}}{\sum_K^{j=i} e^{z_j}}$，$e^0$ 是 1，是有值的，这样的话 softmax 中被 padding 的部分就参与了运算，相当于让无效的部分参与了运算，这可能会产生很大的隐患。因此需要做一个 mask 操作，让这些无效的区域不参与运算，一般是给无效区域加一个很大的负数偏置，即</p>
<p>$$\left{\begin{aligned}
Z_{illegal} = Z_{illegal} + bias_{illegal} \
bias_{illegal}-&gt; -\infin \
\end{aligned}\right.$$</p>
<h3 id="3-残差连接和-layer-normalization">3. 残差连接和 Layer Normalization</h3>
<p><strong>残差连接</strong></p>
<p>我们在上一步得到了经过 self-attention 加权之后输出，也就是$\text{Self-Attention(Q, K, V)}$，然后把他们加起来做残差连接</p>
<p>$$X_{\text{embedding}} + \text{Self-Attention(Q, K, V)}$$</p>
<p><strong>Layer Normalization</strong></p>
<p>Layer Normalization 的作用是<strong>把神经网络中隐藏层归一为标准正态分布</strong>，也就是 $i.i.d$ 独立同分布，以起到<strong>加快训练速度，加速收敛</strong>的作用</p>
<p>$$\mu_j = \frac{1}{m} \sum^{i}<em>{i=1} x</em>{ij}$$</p>
<p>上式以矩阵的列（column）为单位求均值；</p>
<p>$$\sigma^2_{j} = \frac{1}{m}\sum^m_{i=1}(x_{ij} - \mu_j)^2$$</p>
<p>上式以矩阵的列（column）为单位求方差</p>
<p>$$LayerNorm(x) = \frac{x_{ij} - \mu_{j}}{\sqrt{\sigma^2 + \epsilon}}$$</p>
<p>然后用每一列的每一个元素减去这列的均值，再除以这列的标准差，从而得到归一化后的数值，加 $\epsilon$ 是为了防止分母为 0。</p>
<p></p>
<p>下图展示了更多细节：输入 $x_1, x_2$ 经 self-attention 层之后变成 $z_1, z_2$，然后和输入 $x_1, x_2$ 进行残差连接，经过 LayerNorm 后输出给全连接层。全连接层也有一个残差连接和一个 LayerNorm，最后再输出给下一个 Encoder（每个 Encoder Block 中的 FeedForward 层权重都是共享的）</p>
<p></p>
<h3 id="4-transformer-encoder-整体结构">4. Transformer Encoder 整体结构</h3>
<p>经过上面 3 个步骤，我们已经基本了解了 Encoder 的主要构成部分，下面我们用公式把一个 Encoder block 的计算过程整理一下：</p>
<p>(1). 字向量与位置编码</p>
<p>$$X = \text{Embedding-Lookup(X)} + \text{Positional-Encoding}$$</p>
<p>(2). 自注意力机制</p>
<p>$$Q = Linear_{q}(X) = XW_{Q}$$
$$K = Linear_{k}(X) = XW_{K}$$
$$V = Linear_{v}(X) = XW_{V}$$
$$X_{attention} = \text{Self-Attention(Q, K, V)}$$</p>
<p>(3). self-attention 残差连接与 Layer Normalization</p>
<p>$$X_{attention} = X + X_{attention}$$
$$X_{attention} = LayerNorm(attention)$$</p>
<p>(4). 下面进行 Encoder block 结构图中的第 4 部分，也就是 FeedForward，其实就是两层线性映射并用激活函数激活，比如说 $ReLU$</p>
<p>$$X_{hidden} = Linear(ReLU(Linear(X_{attention})))$$</p>
<p>(5). FeedForward 残差连接与 Layer Normalization</p>
<p>$$X_{hidden} = X_{attention} + X_{hidden}$$
$$X_{hidden} = LayerNorm(X_{hidden})$$</p>
<p>其中
$$X_{hidden} \in \mathbb{R}^{batch_size * seq_len * embed_dim}$$</p>
<h3 id="5-transformer-decoder-整体结构">5. Transformer Decoder 整体结构</h3>
<p>我们先从 HighLevel 的角度观察一下 Decoder 结构，从下到上依次是：</p>
<ul>
<li>Masked Multi-Head Self-Attention</li>
<li>Multi-Head Encoder-Decoder Attention</li>
<li>FeedForward Network</li>
</ul>
<p>和 Encoder 一样，上面三个部分的每一个部分，都有一个残差连接，后接一个 Layer Normalization。Decoder 的中间部件并不复杂，大部分在前面 Encoder 里我们已经介绍过了，但是 Decoder 由于其特殊的功能，因此在训练时会涉及到一些细节</p>
<p></p>
<p><strong>Masked Self-Attention</strong></p>
<p>具体来说，传统 Seq2Seq 中 Decoder 使用的是 RNN 模型，因此在训练过程中输入 $t$ 时刻的词，模型无论如何也看不到未来时刻的词，因为循环神经网络是时间驱动的，只有当 $t$ 时刻运算结束了，才能看到 $t + 1$ 时刻的词。而 Transformer Decoder 抛弃了 RNN，改为 Self-Attention，由此就产生了一个问题，<font color=red>在训练过程中，整个 ground truth 都暴露在 Decoder 中</font>，这显然是不对的，我们需要对 Decoder 的输入进行一些处理，该处理被称为 Mask
</br>
举个例子，Decoder 的 ground truth 为 &ldquo;<start> I am fine&rdquo;，我们将这个句子输入到 Decoder 中，经过 WordEmbedding 和 Positional Encoding 之后，将得到的矩阵做三次线性变换 $(W_Q, W_K, W_V)$。然后进行 self-attention 操作，首先通过得到 Scaled Scores，接下来非常关键，我们要<strong>对 Scaled Scores 进行 Mask</strong>，举个例子，当我们输入 &ldquo;I&rdquo; 时，模型目前仅知道包括 &ldquo;I&rdquo; 在内之前所有字的信息，即 &ldquo;<start>&rdquo; 和 &ldquo;I&rdquo; 的信息，不应该让其知道 &ldquo;I&rdquo; 之后词的信息。道理很简单，我们做预测的时候是按照顺序一个字一个字的预测，怎么能这个字都没预测完，就已经知道后面字的信息了呢？Mask 非常简单，首先生成一个下三角全 0，上三角全为负无穷的矩阵，然后将其与 Scaled Scores 相加即可</p>
<p></p>
<p>之后再做 softmax，就能将 - inf 变为 0，得到的这个矩阵即为每个字之间的权重</p>
<p></p>
<p>Multi-Head Self-Attention 无非就是并行的对上述步骤多做几次，前面 Encoder 也介绍了，这里就不多赘述了</p>
<p><strong>Masked Encoder-Decoder Attention</strong></p>
<p>其实这一部分的计算流程和前面 Masked Self-Attention 很相似，结构一模一样，唯一不同的是这里的 K, V为 Encoder 的输出，Q 为 Decoder 中 Masked Self-Attention 的输出</p>
<p></p>
<h3 id="6-总结">6. 总结</h3>
<p>到此为止，Transformer 中 95% 的内容已经介绍完了，我们用一张图展示其完整结构。不得不说，Transformer 设计的十分巧夺天工</p>
<p></p>
<p>下面有几个问题，是我从网上找的，感觉看完之后能对 Transformer 有一个更深的理解</p>
<p><font color=red>Transformer 为什么需要进行 Multi-head Attention？</font></p>
<ul>
<li>原论文中说到进行 Multi-head Attention 的原因是将模型分为多个头，形成多个子空间，可以让模型去关注不同方面的信息，最后再将各个方面的信息综合起来。其实直观上也可以想到，如果自己设计这样的一个模型，必然也不会只做一次 attention，多次 attention 综合的结果至少能够起到增强模型的作用，也可以类比 CNN 中同时使用多个卷积核的作用，直观上讲，多头的注意力有助于网络捕捉到更丰富的特征 / 信息</li>
</ul>
<p><font color=red>Transformer 相比于 RNN/LSTM，有什么优势？为什么？</font></p>
<ul>
<li>RNN 系列的模型，无法并行计算，因为 T 时刻的计算依赖 T-1 时刻的隐层计算结果，而 T-1 时刻的计算依赖 T-2 时刻的隐层计算结果</li>
<li>Transformer 的特征抽取能力比 RNN 系列的模型要好</li>
</ul>
<p><font color=red>为什么说 Transformer 可以代替 seq2seq？</font></p>
<ul>
<li>这里用代替这个词略显不妥当，seq2seq 虽已老，但始终还是有其用武之地，seq2seq 最大的问题在于<strong>将Encoder端的所有信息压缩到一个固定长度的向量中</strong>，并将其作为 Decoder 端首个隐藏状态的输入，来预测 Decoder 端第一个单词 (token) 的隐藏状态。在输入序列比较长的时候，这样做显然会损失 Encoder 端的很多信息，而且这样一股脑的把该固定向量送入 Decoder 端，Decoder 端不能够关注到其想要关注的信息。</li>
<li>Transformer 不但对 seq2seq 模型这两点缺点有了实质性的改进 (多头交互式 attention 模块)，而且还引入了 self-attention 模块，让源序列和目标序列首先 “自关联” 起来，这样的话，源序列和目标序列自身的 embedding 表示所蕴含的信息更加丰富，而且后续的 FFN 层也增强了模型的表达能力，并且 Transformer 并行计算的能力远远超过了 seq2seq 系列模型</li>
</ul>
<h3 id="7-参考文章">7. 参考文章</h3>
<ul>
<li><a href="http://mantchs.com/2019/09/26/NLP/Transformer/"target="_blank" rel="external nofollow noopener noreferrer">Transformer<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li><a href="http://jalammar.github.io/illustrated-transformer/"target="_blank" rel="external nofollow noopener noreferrer">The Illustrated Transformer<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li><a href="http://www.peterbloem.nl/blog/transformers"target="_blank" rel="external nofollow noopener noreferrer">TRANSFORMERS FROM SCRATCH<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
<li><a href="https://medium.com/@bgg/seq2seq-pay-attention-to-self-attention-part-2-%E4%B8%AD%E6%96%87%E7%89%88-ef2ddf8597a4"target="_blank" rel="external nofollow noopener noreferrer">Seq2seq pay Attention to Self Attention: Part 2<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></li>
</ul>]]></description></item><item><title>Effective STL [6] | 警惕C++最令人恼怒的解析</title><link>https://jianye0428.github.io/posts/clause_6/</link><pubDate>Mon, 24 Jul 2023 13:15:53 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/clause_6/</guid><description><![CDATA[<!-- <div class="details admonition quote">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-quote-right fa-fw" aria-hidden="true"></i>quote<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">note abstract info tip success question warning failure danger bug example quote</div>
    </div>
  </div> -->
<h2 id="函数声明的几种方式">函数声明的几种方式</h2>
<ol>
<li>声明一个函数f带有一个double而且返回一个int：</li>
</ol>
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">int</span> <span class="nf">f</span><span class="p">(</span><span class="kt">double</span> <span class="n">d</span><span class="p">);</span></span></span></code></pre></td></tr></table>
</div>
</div><ol start="2">
<li>名为d的参数左右的括号是多余的，被忽略：</li>
</ol>
<div class="highlight" id="id-2"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">int</span> <span class="nf">f</span><span class="p">(</span><span class="kt">double</span> <span class="p">(</span><span class="n">d</span><span class="p">));</span> <span class="c1">// 同上；d左右的括号被忽略
</span></span></span></code></pre></td></tr></table>
</div>
</div><ol start="3">
<li>省略了参数名：</li>
</ol>
<div class="highlight" id="id-3"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">int</span> <span class="nf">f</span><span class="p">(</span><span class="kt">double</span><span class="p">);</span> <span class="c1">// 同上；参数名被省略
</span></span></span></code></pre></td></tr></table>
</div>
</div><ol start="4">
<li>第一个声明了一个函数g，它带有一个参数，那个参数是指向一个没有参数、返回double的函数的指针：</li>
</ol>
<div class="highlight" id="id-4"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">int</span> <span class="nf">g</span><span class="p">(</span><span class="kt">double</span> <span class="p">(</span><span class="o">*</span><span class="n">pf</span><span class="p">)());</span> <span class="c1">// g带有一个指向函数的指针作为参数
</span></span></span></code></pre></td></tr></table>
</div>
</div><ol start="5">
<li>唯一的不同是pf使用非指针语法来声明(一个在C和C++中都有效的语法):</li>
</ol>
<div class="highlight" id="id-5"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">int</span> <span class="nf">g</span><span class="p">(</span><span class="kt">double</span> <span class="n">pf</span><span class="p">());</span> <span class="c1">// 同上；pf其实是一个指针
</span></span></span></code></pre></td></tr></table>
</div>
</div><ol start="6">
<li>照常，参数名可以省略，所以这是g的第三种声明，去掉了pf这个名字：</li>
</ol>
<div class="highlight" id="id-6"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">int</span> <span class="nf">g</span><span class="p">(</span><span class="kt">double</span> <span class="p">());</span> <span class="c1">// 同上；参数名省略
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>注意参数名左右的括号（就像f的第二种声明中的d）和单独的括号（正如本例）之间的区别。</p>
<p><strong>参数名左右的括号被忽略，但单独的括号指出存在一个参数列表：它们声明了存在指向函数的指针的参数。</strong></p>
<h2 id="问题探讨">问题探讨</h2>
<p>假设有一个int的文件，想要把那些int拷贝到一个list中，可能会使用下面代码：</p>
<div class="highlight" id="id-7"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">ifstream</span> <span class="nf">dataFile</span><span class="p">(</span><span class="s">&#34;ints.dat&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="c1">// 警告！这完成的并不是像你想象的那样
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">list</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">data</span><span class="p">(</span><span class="n">istream_iterator</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">dataFile</span><span class="p">),</span>
</span></span><span class="line"><span class="cl"><span class="n">istream_iterator</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">());</span></span></span></code></pre></td></tr></table>
</div>
</div><p>这里的想法是传一对<code>istream_iterator</code>给<code>list</code>的区间构造函数，因此把int从文件拷贝到list中。</p>
<p>这段代码可以编译，但是运行时什么都不会做，不会从文件中读出任何数据，甚至不会构建1个<code>list</code>。</p>
<p>第二句并不声明list，也不调用构造函数。</p>
<p>这声明了一个函数data，它的返回类型是<code>list&lt;int&gt;</code>。这个函数data带有两个参数：</p>
<p>● 第1个参数叫做dataFile。它的类型是<code>istream_iterator&lt;int&gt;</code>。dataFile左右的括号是多余的而且被忽略。</p>
<p>● 第2个参数没有名字。它的类型是指向一个没有参数而且返回<code>istream_iterator&lt;int&gt;</code>的函数的指针。</p>
<p>就像下面具有这条规则的代码：</p>
<div class="highlight" id="id-8"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Widget</span> <span class="p">{...};</span> <span class="c1">// 假设Widget有默认构造函数
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">Widget</span> <span class="nf">w</span><span class="p">();</span></span></span></code></pre></td></tr></table>
</div>
</div><p>这并没有声明一个叫做w的Widget，它声明了一个叫作w的没有参数且返回Widget的函数。</p>
<p>本来代码的初衷，是用一个文件的内容来初始化一个<code>list&lt;int&gt;</code>对象，现在并没有达到我们的期望。</p>
<h2 id="解决办法">解决办法</h2>
<ol>
<li>函数调用前后增加括号
用括号包围一个实参的声明是不合法的，但用括号包围一个函数调用的观点是合法的，所以通过增加一对括号，代码变为：</li>
</ol>
<div class="highlight" id="id-9"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">list</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">data</span><span class="p">((</span><span class="n">istream_iterator</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">dataFile</span><span class="p">)),</span> <span class="c1">// 注意在list构造函数的第一个实参左右的新括号
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">istream_iterator</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">());</span></span></span></code></pre></td></tr></table>
</div>
</div><p>这是可能的声明数据方法，给予<code>istream_iterators</code>的实用性和区间构造函数。</p>
<ol start="2">
<li>命名迭代器对象</li>
</ol>
<div class="highlight" id="id-10"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">ifstream</span> <span class="nf">dataFile</span><span class="p">(</span><span class="s">&#34;ints.dat&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">istream_iterator</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">dataBegin</span><span class="p">(</span><span class="n">dataFile</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">istream_iterator</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">dataEnd</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">list</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">data</span><span class="p">(</span><span class="n">dataBegin</span><span class="p">,</span> <span class="n">dataEnd</span><span class="p">);</span></span></span></code></pre></td></tr></table>
</div>
</div><p>命名迭代器对象的使用和普通的STL编程风格相反，但是你得判断这种方法对编译器和必须使用编译器的人都模棱两可的代码是一个值得付出的代价。</p>]]></description></item><item><title>Effective STL [5] | 尽量使用区间成员函数代替它们的单元素兄弟</title><link>https://jianye0428.github.io/posts/clause_5/</link><pubDate>Mon, 24 Jul 2023 13:15:50 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/clause_5/</guid><description><![CDATA[<!-- <div class="details admonition quote">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-quote-right fa-fw" aria-hidden="true"></i>quote<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">note abstract info tip success question warning failure danger bug example quote</div>
    </div>
  </div> -->
<p>ref:</br>
[1]. <a href="https://mp.weixin.qq.com/s?__biz=MzUyMDc2MDMxNg==&amp;mid=2247490705&amp;idx=1&amp;sn=830797e69b61fe9693bf4aaea72df4b3&amp;chksm=f9e42202ce93ab1437ad36c37e141b0794328495c0c584d808d0f4ad36251680dbfba257b060&amp;cur_album_id=3009999611861975043&amp;scene=189#wechat_redirect"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s?__biz=MzUyMDc2MDMxNg==&mid=2247490705&idx=1&sn=830797e69b61fe9693bf4aaea72df4b3&chksm=f9e42202ce93ab1437ad36c37e141b0794328495c0c584d808d0f4ad36251680dbfba257b060&cur_album_id=3009999611861975043&scene=189#wechat_redirect<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<h2 id="example">Example</h2>
<p>Q：给定两个vector，v1和v2，使v1的内容和v2的后半部分一样的最简单方式是什么？</p>
<p>A：</p>
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">v1</span><span class="p">.</span><span class="n">assign</span><span class="p">(</span><span class="n">v2</span><span class="p">.</span><span class="n">begin</span><span class="p">()</span> <span class="o">+</span> <span class="n">v2</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">v2</span><span class="p">.</span><span class="n">end</span><span class="p">());</span></span></span></code></pre></td></tr></table>
</div>
</div><p>这个测验设计为做两件事:</p>
<ol>
<li>它提供给我一个机会来提醒你assign成员函数的存在</li>
</ol>
<p>太多的程序员没注意到这是一个很方便的方法。<strong>它对于所有标准序列容器（vector，string，deque和list）都有效。</strong></p>
<p>无论何时你必须完全代替一个容器的内容，你就应该想到赋值。</p>
<p>如果你只是拷贝一个容器到另一个同类型的容器，<code>operator=</code>就是选择的赋值函数，但对于示范的那个例子，当你想要给一个容器完全的新数据集时，assign就可以利用，但<code>operator=</code>做不了。</p>
<ol start="2">
<li>演示为什么区间成员函数优先于它们的单元素替代品。</li>
</ol>
<p>区间成员函数是一个像STL算法的成员函数，使用两个迭代器参数来指定元素的一个区间来进行某个操作。</p>
<p>不用区间成员函数来解决这个条款开头的问题，你就必须写一个显式循环，可能就像这样:</p>
<div class="highlight" id="id-2"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">vector</span><span class="o">&lt;</span><span class="n">Randy</span><span class="o">&gt;</span> <span class="n">v1</span><span class="p">,</span> <span class="n">v2</span><span class="p">;</span> <span class="c1">// 假设v1和v2是Randy的vector
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">v1</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="p">(</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Randy</span><span class="o">&gt;::</span><span class="n">const_iterator</span> <span class="n">ci</span> <span class="o">=</span> <span class="n">v2</span><span class="p">.</span><span class="n">begin</span><span class="p">()</span> <span class="o">+</span> <span class="n">v2</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">/</span> <span class="mi">2</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">ci</span> <span class="o">!=</span> <span class="n">v2</span><span class="p">.</span><span class="n">end</span><span class="p">();</span> <span class="o">++</span><span class="n">ci</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">v1</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="o">*</span><span class="n">ci</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div><p>写这段代码比写assign的调用要做多得多的工作。</p>
<p><strong>copy 替代循环</strong></p>
<div class="highlight" id="id-3"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">v1</span><span class="p">.</span><span class="n">clear</span><span class="p">();</span>
</span></span><span class="line"><span class="cl"><span class="n">copy</span><span class="p">(</span><span class="n">v2</span><span class="p">.</span><span class="n">begin</span><span class="p">()</span> <span class="o">+</span> <span class="n">v2</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">v2</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span> <span class="n">back_inserter</span><span class="p">(</span><span class="n">v1</span><span class="p">))</span></span></span></code></pre></td></tr></table>
</div>
</div><p>虽然在这段代码中没有表现出循环，在copy中的确存在一个循环 。</p>
<p>效率损失仍然存在。</p>
<p>几乎所有目标区间是通过插入迭代器（比如，通过inserter，back_inserter或front_inserter）指定的copy的使用都可以——应该——通过调用区间 成员函数来代替。</p>
<p>比如这里，这个copy的调用可以用一个insert的区间版本代替：</p>
<div class="highlight" id="id-4"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">v1</span><span class="p">.</span><span class="n">insert</span><span class="p">(</span><span class="n">v1</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span> <span class="n">v2</span><span class="p">.</span><span class="n">begin</span><span class="p">()</span> <span class="o">+</span> <span class="n">v2</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">v2</span><span class="p">.</span><span class="n">end</span><span class="p">());</span></span></span></code></pre></td></tr></table>
</div>
</div><p>这个输入量稍微比调用copy少，但它发生的也比说的要直接：数据插入v1。</p>
<p>这里insert 也比 copy 好，因为字面上insert 表示有数据插入到了 v1中，而copy 的使用把它变得晦涩。</p>
<p><strong>关于东西被拷贝这个事实并没有什么好关注的，因为STL构建在东西会被拷贝的假定上。拷贝对STL来说很基本。</strong></p>
<p><strong>小结</strong></p>
<p>我们已经确定3个尽量使用区间成员函数代替它们的单元素兄弟的理由。 ● 一般来说使用区间成员函数可以输入更少的代码。 ● 区间成员函数会导致代码更清晰更直接了当。</p>
<h2 id="效率">效率</h2>
<p>当处理标准序列容器时，应用单元素成员函数比完成同样目的的区间成员函数需要更多地内存分配，更频繁地拷贝对象，而且/或者造成多余操作。</p>
<p>对此，我之前还做了个单元素兄弟插入和批量插入的效率比较的文章<a href="https://mp.weixin.qq.com/s?__biz=MzUyMDc2MDMxNg==&amp;mid=2247490268&amp;idx=1&amp;sn=fcf5b24ec09e544f1f0fea544e59bfd6&amp;chksm=f9e4244fce93ad5988926b2cba002426ada65b79d4672b7bad565fff633c52a29f9f451d6494&amp;token=855912511&amp;lang=zh_CN&amp;scene=21#wechat_redirect"target="_blank" rel="external nofollow noopener noreferrer">《vector 用 insert 批量插入效率高还是emplace_back效率高》<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>，也证实了这个观点。</p>
<p>标准要求区间<code>insert</code>函数直接把现有元素移动到它们最后的位置，也就是，开销是每个元素一次移动。总共开销是n次移动，numValues次容器中的对象类型的拷贝构造函数，剩下的是类型的赋值操作符。</p>
<p>相比单元素插入策略，区间insert少执行了n*(numValues-1)次移动。</p>
<p>花一分钟想想。这意味着如果numValues是100，insert的区间形式会比重复调用insert的单元素形式的代码少花费99%的移动！</p>
<p>仅当可以不用失去两个迭代器的位置就能决定它们之间的距离时，一个区间insert函数才能在一次移动中把一个元素移动到它的最终位置。</p>
<p>这几乎总是可能的，因为所有前向迭代器提供了这个功能，而且前向迭代器几乎到处都是。</p>
<p>所有用于标准容器的迭代器都提供了前向迭代器的功能。非标准的散列容器的迭代器也是。</p>
<p>在数组中表现为迭代器的指针也提供了这样的功能。事实上，唯一不提供前向迭代器能力的标准迭代器是输入和输出迭代器。</p>
<p><strong>单元素插入的问题</strong></p>
<ul>
<li>
<p>当你试图去把一个元素插入内存已经满了的vector时，这个vector会分配具有更多容量的新内存，从旧内存把它的元素拷贝到新内存，销毁旧内存里的元素，回收旧内存。然后它添加插入的元素。</p>
</li>
<li>
<p>每当用完内存时，大部分vector实现都使它们的容量翻倍，所以插入numValues个新元素会导致最多$\log_2{numValues}$次新内存的分配。</p>
</li>
<li>
<p>每次一个地插入1000个元素会导致10次新的分配（包括它们负责的元素拷贝）。</p>
</li>
</ul>
<p>与之对比的是，一个区间插入可以在开始插入东西前计算出需要多少新内存（假设给的是前向迭代器），所以它不用多于一次地重新分配vector的内在内存。</p>
<p>刚才进行分析是用于vector的，但同样的理由也作用于string。</p>
<p><strong>deque</strong></p>
<p>对于deque，理由也很相似，但deque管理它们内存的方式和vector和string不同，所以重复内存分配的论点不能应用。</p>
<p>但是，关于<strong>很多次不必要的元素移动</strong>的论点通常通过对函数调用次数的观察也应用到了（虽然细节不同）。</p>
<p><strong>list</strong></p>
<p>在这里使用insert区间形式代替单元素形式也有一个性能优势。</p>
<p>关于重复函数调用的论点当然继续有效，但因为链表的工作方式，拷贝和内存分配问题没有发生。</p>
<p>取而代之的是，这里有一个新问题：过多重复地对list中的一些节点的next和prev指针赋值。</p>
<p>每当一个元素添加到一个链表时，持有元素的链表节点必须有它的next和prev指针集，而且当然新节点前面的节点（我们叫它B，就是“before”）必须设置它的next指针，新节点后面的节点（我们叫它A，就是“after”）必须设置它的prev指针</p>
<p></p>
<p>当一系列新节点通过调用list的单元素insert一个接一个添加时，除了最后一个以外的其他新节点都会设置它的next指针两次，第一次指向A，第二次指向在它后面插入的元素。每次在A前面插入时，它都会设置它的prev指针指向一个新节点。</p>
<p>如果numValues个节点插入A前面，插入节点的next指针会发生次多余的赋值，而且A的prev指针会发生numValues-1次多余的赋值。合计次没有必要的指针赋值。当然，指针赋值很轻量，但如果不是必须，为什么要为它们花费呢？</p>
<p>**避免开销的关键是使用list的insert区间形式。**因为那个函数知道最后有多少节点会被插入，它可以避免多余的指针赋值，对每个指针只使用一次赋值就能设置它正确的插入后的值</p>
<h2 id="区间函数">区间函数</h2>
<p>参数类型iterator意思是容器的迭代器类型，也就是container::iterator。</p>
<p>参数类型InputIterator意思是可以接受任何输入迭代器。</p>
<ul>
<li><strong>区间构造</strong></li>
</ul>
<p>所有标准容器都提供这种形式的构造函数：</p>
<div class="highlight" id="id-5"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">container</span><span class="o">::</span><span class="n">container</span><span class="p">(</span><span class="n">InputIterator</span> <span class="n">begin</span><span class="p">,</span> <span class="c1">// 区间的起点
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">InputIterator</span> <span class="n">end</span><span class="p">);</span> <span class="c1">// 区间的终点
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>如果传给这个构造函数的迭代器是<code>istream_iterators</code>或<code>istreambuf_iterators</code>，你可能会遇到C++的最惊异的解析，原因之一是你的编译器可能会因为把这个构造看作一个函数声明而不是一个新容器对象的定义而中断。</p>
<ul>
<li><strong>区间插入</strong></li>
</ul>
<p>所有标准序列容器都提供这种形式的insert:</p>
<div class="highlight" id="id-6"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">void</span> <span class="n">container</span><span class="o">::</span><span class="n">insert</span><span class="p">(</span><span class="n">iterator</span> <span class="n">position</span><span class="p">,</span> <span class="c1">// 区间插入的位置
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">InputIterator</span> <span class="n">begin</span><span class="p">,</span> <span class="c1">// 插入区间的起点
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">InputIterator</span> <span class="n">end</span><span class="p">);</span> <span class="c1">// 插入区间的终点
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>关联容器使用它们的比较函数来决定元素要放在哪里，所以它们了省略position参数。</p>
<div class="highlight" id="id-7"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">void</span> <span class="n">container</span><span class="o">::</span><span class="n">insert</span><span class="p">(</span><span class="n">lnputIterator</span> <span class="n">begin</span><span class="p">,</span> <span class="n">InputIterator</span> <span class="n">end</span><span class="p">);</span></span></span></code></pre></td></tr></table>
</div>
</div><p>当寻找用区间版本代替单元素插入的方法时，不要忘记有些单元素变量用采用不同的函数名伪装它们自己。比如，<code>push_front</code>和<code>push_back</code>都把单元素插入容器，即使它们不叫<code>insert</code>。如果你看见一个循环调用<code>push_front</code>或<code>push_back</code>，或如果你看见一个算法——比如copy——的参数是<code>front_inserter</code>或者<code>back_inserter</code>，你就发现了一个<code>insert</code>的区间形式应该作为优先策略的地方。</p>
<ul>
<li><strong>区间删除</strong></li>
</ul>
<p>每个标准容器都提供了一个区间形式的<code>erase</code>，但是序列和关联容器的返回类型不同。</p>
<p><strong>序列容器</strong>提供了这个：</p>
<div class="highlight" id="id-8"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">iterator</span> <span class="n">container</span><span class="o">::</span><span class="n">erase</span><span class="p">(</span><span class="n">iterator</span> <span class="n">begin</span><span class="p">,</span> <span class="n">iterator</span> <span class="n">end</span><span class="p">);</span></span></span></code></pre></td></tr></table>
</div>
</div><p>关联容器提供这个:</p>
<div class="highlight" id="id-9"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">void</span> <span class="n">container</span><span class="o">::</span><span class="n">erase</span><span class="p">(</span><span class="n">iterator</span> <span class="n">begin</span><span class="p">,</span> <span class="n">iterator</span> <span class="n">end</span><span class="p">);</span></span></span></code></pre></td></tr></table>
</div>
</div><p>Q：为什么不同？</p>
<p>A：解释是，如果erase的关联容器版本返回一个迭代器（被删除的那个元素的下一个）会<strong>招致一个无法接受的性能下降</strong>。</p>
<p>这个条款的对insert的性能分析大部分也同样可以用于erase。单元素删除的函数调用次数仍然大于一次调用区间删除。当使用单元素删除时，每一次元素值仍然必须向它们的目的地移动一位，而区间删除可以在一个单独的移动中把它们移动到目标位置。</p>
<p>关于vector和string的插入和删除的一个论点是必须做很多重复的分配。（当然对于删除，会发生重复的回收。）那是因为用于vector和string的内存自动增长来适应于新元素，但当元素的数目减少时它不自动收缩。</p>
<ul>
<li><strong>区间赋值</strong></li>
</ul>
<p>所有标准列容器都提供了区间形式的assign:</p>
<div class="highlight" id="id-10"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">void</span> <span class="n">container</span><span class="o">::</span><span class="n">assign</span><span class="p">(</span><span class="n">InputIterator</span> <span class="n">begin</span><span class="p">,</span> <span class="n">InputIterator</span> <span class="n">end</span><span class="p">);</span></span></span></code></pre></td></tr></table>
</div>
</div><h2 id="结论">结论</h2>
<p>几乎所有目标区间被插入迭代器指定的copy的使用都可以用调用的区间成员函数的来代替 。</p>
<p>尽量使用区间成员函数来代替单元素兄弟的三个可靠的论点。区间成员函数更容易写，它们更清楚地表达你的意图，而且它们提供了更高的性能。那是很难打败的三驾马车。</p>]]></description></item><item><title>Effective STL [3] | 使容器里对象的拷贝操作轻量而正确</title><link>https://jianye0428.github.io/posts/clause_3/</link><pubDate>Mon, 24 Jul 2023 09:11:28 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/clause_3/</guid><description><![CDATA[<h2 id="拷贝对象是stl的方式">拷贝对象是STL的方式</h2>
<ul>
<li>
<p>当一个对象进入一个容器，它已经不是你添加（<code>insert</code>或<code>push_back</code>等）的那个对象了，进入容器的是你指定的对象的拷贝；</p>
</li>
<li>
<p>当从容器中取出一个对象时，所得到的也不是容器里的对象；</p>
</li>
<li>
<p>如果从<code>vector</code>、<code>string</code>或<code>deque</code>中插入或删除了什么，现有的容器元素会移动（拷贝）</p>
</li>
<li>
<p>如果使用了任何排序算法：<code>next_permutation</code>或者<code>previous_permutation</code>；</p>
</li>
<li>
<p><code>remove</code>、<code>unique</code>或它们的同类；</p>
</li>
<li>
<p><code>rotate</code>或<code>reverse</code>等，对象会移动（拷贝）</p>
</li>
</ul>
<p><strong>拷进去，拷出来</strong>。这就是STL的方式.</p>
<p>因为拷贝，还解决了一个 double free 的 bug<a href="https://mp.weixin.qq.com/s?__biz=MzUyMDc2MDMxNg==&amp;mid=2247490628&amp;idx=1&amp;sn=43650727bc93d8064fd2969733873fdc&amp;chksm=f9e422d7ce93abc1d2784bcb5772536f55aa79902bbb783003c3314df7ed6461a014ed3cce25&amp;token=235869638&amp;lang=zh_CN&amp;scene=21#wechat_redirect"target="_blank" rel="external nofollow noopener noreferrer">点击查看<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<h2 id="how-copy-如何完成拷贝">How Copy? 如何完成拷贝</h2>
<div class="details admonition info open">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-info-circle fa-fw" aria-hidden="true"></i>Notice<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">通过拷贝构造函数和拷贝复制操作符完成！</div>
    </div>
  </div>
<p>一个对象通过使用它的拷贝成员函数来拷贝，特别是它的拷贝构造函数和它的拷贝赋值操作符。</p>
<p>对于用户自定义类，比如Widget，这些函数传统上是这么声明的：</p>
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Widget</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl"><span class="p">...</span>
</span></span><span class="line"><span class="cl"><span class="n">Widget</span><span class="p">(</span><span class="k">const</span> <span class="n">Widget</span><span class="o">&amp;</span><span class="p">);</span> <span class="c1">// 拷贝构造函数
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">Widget</span><span class="o">&amp;</span> <span class="k">operator</span><span class="o">=</span><span class="p">(</span><span class="k">const</span> <span class="n">Widget</span><span class="o">&amp;</span><span class="p">);</span> <span class="c1">// 拷贝赋值操作符
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">...</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span></span></span></code></pre></td></tr></table>
</div>
</div><p><strong>如果你自己没有声明这些函数，你的编译器始终会为你声明它们。</strong></p>
<p>拷贝内建类型（比如int、指针等）也始终是通过简单地拷贝他们的内在比特来完成的。（请参考《Effective C++》中，条款11和27专注于这些函数的行为。）</p>
<h2 id="拷贝带来的问题">拷贝带来的问题</h2>
<p><strong>性能瓶颈</strong></p>
<p>拷贝会导致把对象放进容器也会被证明为是一个性能瓶颈。</p>
<p>容器中移动越多的东西，你就会在拷贝上浪费越多的内存和时钟周期。</p>
<p><strong>切片分割</strong></p>
<p>当然由于继承的存在，拷贝会导致分割。</p>
<p>如果以基类对象建立一个容器，而你试图插入派生类对象，那么当对象（通过基类的拷贝构造函数）拷入容器的时候对象的派生部分会被删除：</p>
<div class="highlight" id="id-2"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">vector</span><span class="o">&lt;</span><span class="n">Widget</span><span class="o">&gt;</span> <span class="n">randy</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">SpecialWidget</span><span class="o">:</span> <span class="k">public</span> <span class="n">Widget</span> <span class="p">{...};</span> <span class="c1">// SpecialWidget从上面的Widget派生
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">SpecialWidget</span> <span class="n">sw</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">randy</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">sw</span><span class="p">);</span> <span class="c1">// sw被当作基类对象拷入randy，当拷贝时它的特殊部分丢失了
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>分割问题暗示了把一个派生类对象插入基类对象的容器几乎总是错的。</p>
<p>如果你希望结果对象表现为派生类对象，比如，调用派生类的虚函数等，总是错的。</p>
<h2 id="解决">解决</h2>
<p>一个使拷贝更高效、正确而且对分割问题免疫的简单的方式是<strong>建立指针的容器而不是对象的容器</strong>。</p>
<p>也就是说，不是建立一个Widget的容器，建立一个Widget*的容器。</p>
<p><strong>拷贝指针很快，它总是严密地做你希望的（指针拷贝比特），而且当指针拷贝时没有分割，就是int类型的地址。</strong></p>
<p><font color=red>但是一定要记得在销毁容器的时候，使用delete 销毁里面保存的每个指针。而且一定要定义对象的深拷贝构造函数和深拷贝拷贝赋值操作符，否则delete 的时候会报错。</font></p>
<h2 id="和数组对比stl容器更文明">和数组对比，STL容器更文明</h2>
<p><strong>STL容器只建立（通过拷贝）你需要的个数的对象，而且它们只在你指定的时候做。</strong></p>
<p>STL进行了大量拷贝，但它通常设计为避免不必要的对象拷贝，实际上，它也被实现为避免不必要的对象拷贝。</p>
<ol>
<li>数组在声明的时候，会默认先构造好每个元素；STL容器可以实现动态扩展</li>
</ol>
<div class="highlight" id="id-3"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">Widget</span> <span class="n">randy</span><span class="p">[</span><span class="n">maxNumWidgets</span><span class="p">];</span> <span class="c1">// 建立一个大小为maxNumWidgets的Widgets数组
</span></span></span><span class="line"><span class="cl"><span class="c1">// 默认构造每个元素
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>即使只使用其中的一些或者我们立刻使用从某个地方获取（比如，一个文件）的值覆盖每个默认构造的值，这也得构造maxNumWidgets个Widget对象。</p>
<p>使用STL来代替数组，你可以使用一个可以在需要的时候增长的vector，就是动态数组的概念：</p>
<div class="highlight" id="id-4"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">vector</span><span class="o">&lt;</span><span class="n">Widget</span><span class="o">&gt;</span> <span class="n">randy</span><span class="p">;</span> <span class="c1">// 建立一个0个Widget对象的vector
</span></span></span><span class="line"><span class="cl"><span class="c1">// 需要的时候可以扩展
</span></span></span></code></pre></td></tr></table>
</div>
</div><ol start="2">
<li>建立一个可以足够包含maxNumWidgets个Widget的空vector，但不去构造Widget，需要时再构造：</li>
</ol>
<div class="highlight" id="id-5"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">vector</span><span class="o">&lt;</span><span class="n">Widget</span><span class="o">&gt;</span> <span class="n">randy</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">randy</span><span class="p">.</span><span class="n">reserve</span><span class="p">(</span><span class="n">maxNumWidgets</span><span class="p">);</span> <span class="c1">// reserve的详细信息请参见条款14
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>即便需要知道STL容器使用了拷贝，但是别忘了一个事实：比起数组它们仍然是一个进步。</p>
]]></description></item><item><title>Effective STL [2] | 小心对“容器无关代码”的幻想</title><link>https://jianye0428.github.io/posts/clause_2/</link><pubDate>Thu, 20 Jul 2023 15:58:12 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/clause_2/</guid><description><![CDATA[<h2 id="stl-容器特点">STL 容器特点</h2>
<p>STL是建立在<strong>泛化</strong>之上的</p>
<ul>
<li>数组泛化为容器，参数化了所包含的对象的类型</br></li>
<li>函数泛化为算法，参数化了所用的迭代器的类型</br></li>
<li>指针泛化为迭代器，参数化了所指向的对象的类型</br></li>
</ul>
<p><strong>独立的容器类型泛化为序列或关联容器，而且类似的容器拥有类似的功能。</strong></p>
<p>标准的内存相邻容器都提供随机访问迭代器，标准的基于节点的容器都提供双向迭代器。</p>
<p>序列容器支持<code>push_front</code>或<code>push_back</code>，但关联容器不支持。关联容器提供对数时间复杂度的<code>lower_bound</code>、<code>upper_bound</code>和<code>equal_range</code>成员函数，但序列容器却没有。</p>
<p>举例:</p>
<ul>
<li>标准序列容器: vector、string、deque 和 list</li>
<li>标准关联容器: set、multiset、map 和 multimap</li>
</ul>
<h2 id="推行自己的容器">推行自己的容器</h2>
<p>很多人会试图在他们的软件中泛化容器的不同，而不是针对容器的特殊性编程，他们会想在vector 中使用 deque 或者 list的特性，这往往会带来麻烦。</p>
<p>比如：</p>
<ul>
<li>
<p>只有序列容器支持push_front或push_back，只有关联容器支持count和lower_bound</p>
</li>
<li>
<p>即便是 insert和erase这样的操作在名称和语义上也有差别</p>
<ul>
<li>当把对象插入序列容器中，该对象会保留在你放置的位置上;</li>
<li>当你把对象插入到一个关联容器中，容器会按照排列顺序把对象移到它应该在的位置;</li>
</ul>
</li>
<li>
<p>在序列容器上用一个迭代器作为参数调用 erase，会返回一个新的迭代器；在关联容器上什么都不返回。</p>
</li>
</ul>
<p><strong>容器能力的交集</strong></p>
<p>如果你想写一个可以用在常用序列容器上的代码—— 包含vector, deque和list。你必须使用它们能力的交集来编写。</p>
<p>但要考虑几点：</p>
<ul>
<li><code>deque</code>和<code>list</code>不支持<code>reserve</code>或<code>capacity</code></li>
<li><code>list</code>不支持<code>operator[]</code>操作，且受限于双向迭代器的性能</li>
<li>不能使用需要随机访问迭代器的算法，包括<code>sort</code>，<code>stable_sort</code>，<code>partial_sort</code>和<code>nth_element</code></li>
<li>如果想支持<code>vector</code>的规则，则不能使用<code>push_front</code>和<code>pop_front</code></li>
<li><code>vector</code>和<code>deque</code>都会使<code>splice</code>和成员函数方式的<code>sort</code>失败</li>
<li>因为<code>deque::insert</code>会使所有迭代器失效，而且因为缺少<code>capacity</code>，<code>vector::insert</code>也必须假设使所有指针和引用失效，而deque是唯一一个在迭代器失效的情况下, 指针和引用仍然有效的东西</li>
<li><strong>不能把容器里的数据传递给C风格的界面</strong>，只有vector支持这么做</li>
<li><strong>不能用bool作为保存的对象来实例化你的容器</strong>，因为vector 并非总表现为一个vector，实际上它并没有真正保存bool值。</li>
<li>不能期望享受到list的常数时间复杂度的插入和删除，vector和deque的插入和删除操作是线性时间复杂度的</li>
</ul>
<p>所以，真正开发时，如果都考虑到上面几点，那想开发的容器只剩下一个&quot;泛化的序列容器&quot;，但是你不能调用<code>reserve</code>、<code>capacity</code>、<code>operator[]</code>、<code>push_front</code>、<code>pop_front</code>、<code>splice</code>或任何需要随机访问迭代器的算法；调用insert和erase会有线性时间复杂度而且会使所有迭代器、指针和引用失效；而且不能兼容C风格的界面，不能存储bool。</p>
<p>如果你放弃了序列容器，把代码改为只能和不同的关联容器配合，这情况并没有什么改善。</p>
<ul>
<li>要同时兼容set和map几乎是不可能的，因为set保存单个对象，而map保存对象对。</li>
<li>甚至要同时兼容set和multiset（或map和multimap）也是很难的。</li>
<li><code>set/map</code>的<code>insert</code>成员函数只返回一个值，和他们的multi兄弟的返回类型不同，而且你必须避免对一个保存在容器中的值的拷贝份数作出任何假设。</li>
<li>对于<code>map</code>和<code>multimap</code>，你必须避免使用<code>operator[]</code>，因为这个成员函数只存在于map中。</li>
</ul>
<h2 id="封装">封装</h2>
<p>如果想改变容器类型，就使用<strong>封装</strong>。</p>
<p><strong>Method 1: typedef</strong>
一种最简单的方法是通过自由地对容器和迭代器类型使用typedef</p>
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Widget</span> <span class="p">{...};</span>
</span></span><span class="line"><span class="cl"><span class="n">vector</span><span class="o">&lt;</span><span class="n">Widget</span><span class="o">&gt;</span> <span class="n">vw</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">Widget</span> <span class="n">bestWidget</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">...</span> <span class="c1">// 给bestWidget一个值
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">vector</span><span class="o">&lt;</span><span class="n">Widget</span><span class="o">&gt;::</span><span class="n">iterator</span> <span class="n">i</span> <span class="o">=</span>  <span class="c1">// 寻找和bestWidget相等的Widget
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">find</span><span class="p">(</span><span class="n">vw</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">vw</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span> <span class="n">bestWidget</span><span class="p">);</span></span></span></code></pre></td></tr></table>
</div>
</div><p>可以简化上述写法</p>
<div class="highlight" id="id-2"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Widget</span> <span class="p">{</span> <span class="p">...</span> <span class="p">};</span>
</span></span><span class="line"><span class="cl"><span class="k">typedef</span> <span class="n">vector</span><span class="o">&lt;</span><span class="n">Widget</span><span class="o">&gt;</span> <span class="n">WidgetContainer</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="k">typedef</span> <span class="n">WidgetContainer</span><span class="o">::</span><span class="n">iterator</span> <span class="n">WCIterator</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">WidgetContainer</span> <span class="n">cw</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">Widget</span> <span class="n">bestWidget</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">...</span>
</span></span><span class="line"><span class="cl"><span class="n">WCIterator</span> <span class="n">i</span> <span class="o">=</span> <span class="n">find</span><span class="p">(</span><span class="n">cw</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">cw</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span> <span class="n">bestWidg</span></span></span></code></pre></td></tr></table>
</div>
</div><p>如果需要加上用户的allocator，也特别方便。（一个不影响对迭代器/指针/参考的失效规则的改变）</p>
<div class="highlight" id="id-3"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Widget</span> <span class="p">{</span> <span class="p">...</span> <span class="p">};</span>
</span></span><span class="line"><span class="cl"><span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span> <span class="n">T</span><span class="o">&gt;</span> <span class="c1">// 关于为什么这里需要一个template
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">SpecialAllocator</span> <span class="p">{</span> <span class="p">...</span> <span class="p">};</span> <span class="c1">// 请参见条款10
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">typedef</span> <span class="n">vector</span><span class="o">&lt;</span><span class="n">Widget</span><span class="p">,</span> <span class="n">SpecialAllocator</span><span class="o">&lt;</span><span class="n">Widget</span><span class="o">&gt;</span> <span class="o">&gt;</span> <span class="n">WidgetContainer</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="k">typedef</span> <span class="n">WidgetContainer</span><span class="o">::</span><span class="n">iterator</span> <span class="n">WCIterator</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">WidgetContainer</span> <span class="n">cw</span><span class="p">;</span> <span class="c1">// 仍然能用
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">Widget</span> <span class="n">bestWidget</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">...</span>
</span></span><span class="line"><span class="cl"><span class="n">WCIterator</span> <span class="n">i</span> <span class="o">=</span> <span class="n">find</span><span class="p">(</span><span class="n">cw</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">cw</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span> <span class="n">bestWidget</span><span class="p">);</span> <span class="c1">// 仍然能用
</span></span></span></code></pre></td></tr></table>
</div>
</div><p><font color=red><code>typedef</code>只是其它类型的同义字，所以它提供的的封装是纯的词法（译注：不像#define是在预编译阶段替换的）。<code>typedef</code>并不能阻止用户使用（或依赖）任何他们不应该用的（或依赖的）。</font></p>
<p><strong>Method 2: class</strong></p>
<p>要限制如果用一个容器类型替换了另一个容器可能需要修改的代码，就需要在类中隐藏那个容器，而且要通过类的接口限制容器特殊信息可见性的数量。</p>
<p>比如需要隐藏 真实的容器 list 建立客户列表：</p>
<div class="highlight" id="id-4"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">CustomerList</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">private</span><span class="o">:</span>
</span></span><span class="line"><span class="cl"><span class="k">typedef</span> <span class="n">list</span><span class="o">&lt;</span><span class="n">Customer</span><span class="o">&gt;</span> <span class="n">CustomerContainer</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="k">typedef</span> <span class="n">CustomerContainer</span><span class="o">::</span><span class="n">iterator</span> <span class="n">CCIterator</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">CustomerContainer</span> <span class="n">customers</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span> <span class="c1">// 通过这个接口
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">...</span> <span class="c1">// 限制list特殊信息的可见性
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">};</span></span></span></code></pre></td></tr></table>
</div>
</div><p>如果使用过程中，你发现从列表的中部插入和删除客户并不像你想象的那么频繁，仅仅需要快速确定客户列表顶部的20%——一个为nth_element算法量身定做的任务。</p>
<p>但<code>nth_element</code>需要随机访问迭代器，不能兼容<code>list</code>。</p>
<p>在这种情况下，你的客户&quot;list&quot;可能更应该用&quot;vector&quot;或&quot;deque&quot;来实现</p>
<p>当你决定作这种更改的时候，你仍然<strong>必须检查每个CustomerList的成员函数和每个友元，看看他们受影响的程度（根据性能和迭代器/指针/引用失效的情况等等）</strong>。</p>
<p>但如果你做好了对CustomerList地实现细节做好封装的话，那对CustomerList的客户的影响将会很小。</p>
]]></description></item><item><title>Effective STL [1] | 仔细选择你的容器</title><link>https://jianye0428.github.io/posts/clause_1/</link><pubDate>Wed, 19 Jul 2023 08:51:49 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/clause_1/</guid><description><![CDATA[<div class="details admonition quote">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-quote-right fa-fw" aria-hidden="true"></i>quote<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">选择容器需要注意的几个方面</div>
    </div>
  </div>
<h2 id="迭代器">迭代器</h2>
<ol>
<li>输入迭代器</li>
</ol>
<ul>
<li>每个迭代位置<strong>只能被读1次</strong>的只读迭代器，通常表现为 istream_iterator</li>
</ul>
<ol start="2">
<li>输出迭代器</li>
</ol>
<ul>
<li>每个迭代位置<strong>只能被写1次</strong>的只写迭代器，通常表现为 ostream_iterator</li>
</ul>
<ol start="3">
<li>前向迭代器</li>
</ol>
<ul>
<li>
<p>有<strong>输入</strong>和<strong>输出</strong>迭代器的能力，可以反复读写1个位置，<u>不支持 operator&ndash;</u>，可以高效地向前移动任意次数</p>
</li>
<li>
<p>散列容器的一种设计可以产生前向迭代器；</p>
</li>
<li>
<p>单链表容器也提供前向迭代器</p>
</li>
</ul>
<ol start="4">
<li>双向迭代器</li>
</ol>
<ul>
<li>像前向迭代器一样，后退很容易。标准关联容器都提供双向迭代器，list也有</li>
</ul>
<ol start="5">
<li>随机访问迭代器</li>
</ol>
<ul>
<li>
<p>可以做双向迭代器一样的事情，但也提供“迭代器算术”，即迭代器有一步向前或向后跳的能力。</p>
</li>
<li>
<p>vector、string 和 deque 都提供随机访问迭代器。</p>
</li>
<li>
<p>指针数组的指针可以作为数组的随机访问迭代器。</p>
</li>
</ul>
<h2 id="容器">容器</h2>
<p>STL有<font color=red><strong>迭代器</strong></font>、<font color=red><strong>算法</strong></font>和<font color=red><strong>函数对象</strong></font>，但对于大多数C++程序员，容器是最突出的。</p>
<p>它们比数组更强大更灵活，可以动态增长（也常是缩减），可以管理属于它们自己的内存，可以跟踪它们拥有的对象数目，可以限制它们支持操作的算法复杂度等等。</p>
<p><strong>分类</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left">类别</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">标准STL序列容器</td>
<td style="text-align:left">vector、string、deque和list</td>
</tr>
<tr>
<td style="text-align:left">标准STL关联容器</td>
<td style="text-align:left">set、multiset、map和multimap</td>
</tr>
<tr>
<td style="text-align:left">非标准序列容器slist和rope</td>
<td style="text-align:left">slist是一个单向链表，rope本质上是一个重型字符串。(&ldquo;绳子(rope)&ldquo;是重型的&quot;线(string)&rdquo;)</td>
</tr>
<tr>
<td style="text-align:left">非标准关联容器</td>
<td style="text-align:left">hash_set、hash_multiset、hash_map和hash_multimap</td>
</tr>
<tr>
<td style="text-align:left">vector	可以作为string的替代品</td>
<td style="text-align:left">vector作为标准关联容器的替代品</br>	有时候vector可以在时间和空间上都表现得比标准关联容器好</td>
</tr>
<tr>
<td style="text-align:left">标准非STL容器</td>
<td style="text-align:left">包括数组、bitset、valarray、stack、queue和priority_queue 。</br>值得注意的是，数组可以和STL算法配合，因为指针可以当作数组的迭代器使用</td>
</tr>
</tbody>
</table>
<p><code>vector</code>、<code>list</code>和<code>deque</code>提供给程序员不同的复杂度，因此应该这么用：</p>
<ul>
<li>vector是一种可以默认使用的序列类型</br></li>
<li>当很频繁地对序列中部进行插入和删除时应该用list</br></li>
<li>当大部分插入和删除发生在序列的头或尾时可以选择deque这种数据结构</br></li>
</ul>
<p><strong>连续内存容器和基于节点的容器的区别</strong></p>
<ul>
<li><strong>连续内存容器（也叫做基于数组的容器）</strong>
<ul>
<li>
<p>在一个或多个（动态分配）的内存块中保存它们的元素。</p>
</li>
<li>
<p>如果一个新元素被查入或者已存元素被删除，其他在同一个内存块的元素就必须向上或者向下移动来为新元素提供空间或者填充原来被删除的元素所占的空间。</p>
</li>
<li>
<p>这种移动影响了效率和异常安全。</p>
</li>
<li>
<p>标准的连续内存容器是vector、string和deque。</p>
</li>
<li>
<p>非标准的rope也是连续内存容器。</p>
</li>
</ul>
</li>
<li><strong>基于节点的容器</strong>
<ul>
<li>
<p>在每个内存块（动态分配）中只保存一个元素。</p>
</li>
<li>
<p>容器元素的插入或删除只影响指向节点的指针，而不是节点自己的内容。</p>
</li>
<li>
<p>所以当有东西插入或删除时，元素值不需要移动。</p>
</li>
<li>
<p>表现为链表的容器——比如list和slist——是基于节点的，所有的标准关联容器也是（它们的典型实现是平衡树）。</p>
</li>
<li>
<p>非标准的散列容器使用不同的基于节点的实现。</p>
</li>
</ul>
</li>
</ul>
<h2 id="如何选择容器">如何选择容器?</h2>
<ol>
<li>你需要“可以在容器的任意位置插入一个新元素”的能力吗？
<ul>
<li>如果是，你需要<strong>序列容器</strong>，关联容器做不到。
</br></li>
</ul>
</li>
<li>你关心元素在容器中的顺序吗？
<ul>
<li><strong>如果不，散列容器就是可行的选择</strong>。否则，你要避免使用散列容器。
</br></li>
</ul>
</li>
<li>必须使用标准C++中的容器吗?
<ul>
<li>如果是，就可以除去散列容器、slist和rope。
</br></li>
</ul>
</li>
<li>你需要哪一类迭代器？
<ul>
<li>如果必须是<strong>随机访问迭代器</strong>，在技术上你就只能限于<code>vector</code>、<code>deque</code>和<code>string</code>，但你也可能会考虑<code>rope</code>。</li>
<li>如果需要<strong>双向迭代器</strong>，你就<strong>用不了</strong><code>slist </code>和<code>散列容器</code>的一般实现。
</br></li>
</ul>
</li>
<li>当插入或者删除数据时，是否非常在意容器内现有元素的移动？
<ul>
<li>如果是，你就必须<strong>放弃连续内存容器</strong>。
</br></li>
</ul>
</li>
<li>容器中的数据的内存布局需要兼容C吗？
<ul>
<li>如果是，你就只能用vector。
</br></li>
</ul>
</li>
<li>查找速度很重要吗？
<ul>
<li>如果是，你就应该看看散列容器，排序的vector和标准的关联容器——大概是这个顺序。
</br></li>
</ul>
</li>
<li>你介意如果容器的底层使用了引用计数吗？
<ul>
<li>如果是，你就得避开string，因为很多string的实现是用引用计数。</li>
<li>你也<strong>不能用rope</strong>，因为<strong>权威的rope实现是基于引用计数的</strong>。</li>
<li>于是你得重新审核你的string，你可以考虑使用vector<char>
</br></li>
</ul>
</li>
<li>你需要插入和删除的事务性语义吗？也就是说，你需要有可靠地回退插入和删除的能力吗？
<ul>
<li>如果是，你就需要使用<strong>基于节点的容器</strong>。</li>
<li>如果你需要<strong>多元素插入</strong>（比如，以范围的方式）的事务性语义，你就应该选择<code>list</code>，因为<strong>list是唯一提供多元素插入事务性语义的标准容器</strong>。</li>
<li>事务性语义对于有兴趣写异常安全代码的程序员来说非常重要。（事务性语义也可以在连续内存容器上实现，但会有一个性能开销，而且代码不那么直观）
</br></li>
</ul>
</li>
<li>你要把迭代器、指针和引用的失效次数减到最少吗？
<ul>
<li>如果是，你就应该<strong>使用基于节点的容器</strong>，因为在这些容器上进行插入和删除不会使迭代器、指针和引用失效（除非它们指向你删除的元素）。</li>
<li>一般来说，<strong>在连续内存容器上插入和删除会使所有指向容器的迭代器、指针和引用失效</strong>。
</br></li>
</ul>
</li>
<li>你需要具有以下特性的序列容器吗：1） 可以使用随机访问迭代器；2） 只要没有删除而且插入只发生在容器结尾，指针和引用的数据就不会失效？
<ul>
<li>这个一个非常特殊的情况，但如果你遇到这种情况，<strong>deque就是你梦想的容器</strong>。</li>
<li>有趣的是，<strong>当插入只在容器结尾时，deque的迭代器也可能会失效</strong>，<code>deque</code>是**唯一一个“在迭代器失效时不会使它的指针和引用失效”**的标准STL容器。</li>
</ul>
</li>
</ol>
<h2 id="结语">结语</h2>
<p><font color=green><strong>当面对容器时，STL给了你很多选项。如果你的视线超越了STL的范围，那就会有更多的选项。在选择一个容器前，要保证考虑了所有你的选项。</strong></font></p>]]></description></item><item><title>VectorNet 论文解读</title><link>https://jianye0428.github.io/posts/vectornet/</link><pubDate>Sun, 16 Jul 2023 17:13:44 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/vectornet/</guid><description><![CDATA[<p><code>ref link</code>:
[1] <a href="https://blog.csdn.net/qq_41897558/article/details/120087113"target="_blank" rel="external nofollow noopener noreferrer">https://blog.csdn.net/qq_41897558/article/details/120087113<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
[2] <a href="https://zhuanlan.zhihu.com/p/355131328"target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/355131328<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
<code>ref code</code>:
[1]https://github.com/xk-huang/yet-another-vectornet
[2]https://github.com/DQSSSSS/VectorNet</p>
<h2 id="novel-highlights">Novel Highlights</h2>
<p>(1) 使用矢量化的高精地图以及障碍物的历史轨迹，从而避免有损渲染以及ConvNet编码(计算开销比较大)。</p>
<p>(2) 设计子图网络以及全局图网络，建模低阶以及高阶交互</p>
<p>(3) auxiliary task 提高网络性能</p>
<p></p>
<h2 id="vecotornet-网络介绍">VecotorNet 网络介绍</h2>
<h3 id="轨迹和地图的向量表示-representing-trajectories-and-hd-maps">轨迹和地图的向量表示 Representing trajectories and HD maps</h3>
<p>lane可以表示为splines，人行道可以表示为一个很多个点组成的polygon，stop sign标记可以表示为单一个点。 对于agent来说，他们的轨迹也是一种splines。 这些元素都可以向量表示。</p>
<ul>
<li>对于地图的特征：选择一个start point和朝向，等间距均匀采样关键点，并于相邻的关键点相连为向量</li>
<li>对于agent轨迹，按照0.1s sample关键点，并将它们连接成向量。</li>
</ul>
<p>通过向量化的过程，可以得到折线polylines，这个polylines和轨迹、地图标注之间是一一对应的。如果给定的时空间隔足够小，得到的这些折线就与原始地图和轨迹十分接近。</p>
<p>我们将属于折线 $P_j$​ 的每一个向量$v_i$看出图中的一个节点，节点特征如下:</p>
<p>$$v_i = [d_i^s, d_i^e, a_i, j]$$</p>
<ul>
<li>其中前两个vector分别是vector的start point和end point的坐标，可以是(x,y)或者(x,y,z)三维的形式</li>
<li>第三个向量则是attribute属性的特征，比如object的类型，轨迹的时间戳，道路的特征，道路限速等</li>
<li>最后一个是障碍物id，表示 $v_i$ ​属于 $P_j$</li>
</ul>
<h3 id="polyline-子图构建">Polyline 子图构建</h3>
<p>对于一个Polyline P, 它的节点有 ${v_1,v_2,&hellip;,v_p}$， 可以定义一个子图网络：</p>
<p>$$v_i^{l+1} = \varphi_{rel}(g_{enc}(v_i^{(l)}), \varphi({g_{enc}(v_j^{(l)})}))$$</p>
<ul>
<li>
<p>$v_i^{(l)}$​ 代表第i个节点第L层的节点特征。</p>
</li>
<li>
<p>$g_{enc}(\cdot)$代表节点的变换，实践中采用MLP来实现。</p>
</li>
<li>
<p>$\varphi_{agg}(\cdot)$代表特征聚合，用来从相邻的节点来获取信息，实践中采用的是max_pooling。</p>
</li>
<li>
<p>$\varphi_{rel}(\cdot)$代表vi和周围节点的关系，实践中采用的是concate的操作。</p>
</li>
</ul>
<p></p>
<p>最后经过多层的堆叠，来获取整个Polyline级别的特征：</p>
<p>$$P = \varphi_{agg}(v_i^{L_p})$$</p>
<p>这里， $φ_{agg}(⋅)$也是max pooling操作.</p>
<h3 id="全局图的高阶交互-global-graph-for-high-order-interactions">全局图的高阶交互 Global graph for high-order interactions</h3>
<p>经过上面的子图进行低阶模型建模后，现在有了polyline级别节点的特征${p_1,p_2,&hellip;,p_P}$.</p>
<p>为了建立高阶的交互，需要建立一个global的交互图，详见论文图2的第3个子图。</p>
<p>$$P_i^{l+1} = GNN(p^l_i, A)$$</p>
<ul>
<li>
<p>$p_i^l$​代表polyline节点的集合</p>
</li>
<li>
<p>A代表邻接矩阵，实践中采用全链接</p>
</li>
<li>
<p>$GNN(⋅)$代表一层的GNN网络，实践中采用的是self attention layer：
$$GNN(P) = softmax(P_Q P_K^T)P_V$$</p>
<p>其中，P是node的feature matrix， $P_Q$,$P_k$,$P_v$ ​则是它的线性投影。</p>
</li>
</ul>
<p>经过了全局的网络之后，就生成了节点的特征$P^{L_t}_i$，其中Lt是全局GNN网络的层数。然后将$P^{(L_t)}_i$放入decoder进行轨迹的生成:</p>
<p>$$v_i^{future} = \varphi_{traj}(P_i^{L_t})$$</p>
<p>论文中，decoder $φ_{traj}(⋅)$ 使用的是MLP，当然也可以用MultiPath中anchor-based的方法或者variational RNNs 来进行多模态轨迹预测。</p>
<h3 id="辅助任务训练-auxiliary-graph-completion-task">辅助任务训练 auxiliary graph completion task</h3>
<p>为了让全局交互图能更好地捕捉不同轨迹和地图元素之间的交互信息，论文还提出了一个辅助的任务：在训练过程中，随机mask掉一些节点的特征，然后尝试去还原被掩盖的节点特征:</p>
<p>$$\hat{P}<em>i = \varphi</em>{node}(P_i^{L_t})$$</p>
<p>这里节点的decoder $φ_{node}(⋅)$ 也是一个MLP，只在训练的时候使用,在inference过程中不使用。</p>
<h3 id="损失函数-loss-function">损失函数 Loss Function</h3>
<p>多任务训练目标， multi-task training task:</p>
<p>$$\mathcal{L} = \mathcal{L_{traj}} + \alpha \mathcal{L_{node}}$$</p>
<ul>
<li>
<p>$L_{traj}​$: negative Gaussian log-likelihood loss</p>
</li>
<li>
<p>$L_{node}$​: 是预测的节点和被掩盖节点的huber损失函数</p>
</li>
</ul>
<p>其中，
negative Gaussian Log Likelihood 损失函数为:</p>
<p>$$L(x, y) = -\log P(y) = - \log P(y|\mu(x), \sum(x))$$</p>
<p>where,</p>
<p>$$p(y) = p(y∣μ,Σ)=1(2π)n/2∣Σ∣1/2exp−12(y−μ)⊤Σ−1(y−μ)$$</p>
<p>Huber 损失函数为:</p>
<p>$$ L(Y|f(x))= \begin{cases} \frac{1}{2} (Y-f(x))^2, &amp; |Y-f(x)|&lt;= \delta \\ \delta |Y-f(x)| - \frac{1}{2}\delta^2, &amp; |Y-f(x)| &gt; \delta \end{cases} $$</p>
<h2 id="整理">整理</h2>
<p><strong>VectorNet数据处理部分:</strong></p>
<ul>
<li>
<p>对actor的处理:</p>
<ul>
<li>输入: 取轨迹点，每两个轨迹点构建vector, 形式为(x1, x2, y1, y2), 其他特征(object type, timestamp, track_id)</li>
</ul>
</li>
<li>
<p>对lane node的处理:</p>
<ul>
<li>输入: 针对lane segment 的点，求polyline，原则上求lane segment的左右边界的点的向量(x_start, x_end, y_start, y_end, turn_direction, traffic_control, is_intersection, lane_id)</li>
</ul>
</li>
</ul>
<p><strong>网络部分:</strong></p>
<ul>
<li>
<p>构建subgraphnet: 针对每一个polyline，通过mlp和maxpool构构建subgraphnet</p>
</li>
<li>
<p>构建globalgraphnet: 以每个polyline作为graph node，构建全局图网络，采用全链接，通过自注意力机制$GNN(P) = softmax(P_Q, P_K)^T(P_V)$</p>
</li>
</ul>
<p><strong>轨迹生成:</strong></p>
<p>将全局网络的节点特征，通过mlp进行轨迹生成。</p>
]]></description></item><item><title>CRAT-Prediction</title><link>https://jianye0428.github.io/posts/crat_pred/</link><pubDate>Sun, 16 Jul 2023 15:54:26 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/crat_pred/</guid><description><![CDATA[<h2 id="overview">Overview</h2>
<p><code>paper link:</code><a href="https://arxiv.org/pdf/2202.04488.pdf"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/pdf/2202.04488.pdf<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<h2 id="论文概览">论文概览</h2>
<ul>
<li>
<p>文章提出了一种结合Crystal Graph Convolutional Neural Network和Multi-Head Self-Attention Mechanism对交通agent处理的方式</p>
</li>
<li>
<p>在argoverse数据集上进行验证，实现了map-free预测模型的SOTA效果; 相比较于其他模型，模型参数更少。</p>
</li>
<li>
<p>证明: 可以通过 Self-Attention Mechanism 学习到交通参与者之间的交互关系。</p>
</li>
</ul>
<h2 id="网络结构">网络结构</h2>
<p></p>
<ul>
<li>数据处理: 以argoverse2数据为例，取前50帧数据，两两作差值，取49组位移向量数据为输入</li>
<li>
<ul>
<li>首先用<code>EncoderLSTM</code>作为encoder</li>
</ul>
</li>
<li>
<ul>
<li>再将每一个agent作为node，通过<code>Crystal Graph Convolutional Neural Network</code>构建图神经网络</li>
</ul>
</li>
<li>
<ul>
<li>通过<code>Multi-Head Self-Attention</code>学习node之间的交互关系</li>
</ul>
</li>
</ul>
<h2 id="实现原理">实现原理</h2>
<h3 id="input-encoder-输入编码器">Input Encoder 输入编码器</h3>
<p>输入数据为过去5秒的离散位移:
$$s_i^t = (\Delta{\tau_i^t} || b_i^t)$$</p>
<p>其中， $\Delta \tau_i^t = \tau_i^{t-1}$.</p>
<h3 id="interaction-module-交互模块">Interaction Module 交互模块</h3>
<h3 id="output-decoder-输出编码器">Output Decoder 输出编码器</h3>
<h3 id="training-训练过程">Training 训练过程</h3>
<h2 id="代码实现结构">代码实现结构</h2>
<p><strong>数据处理结构</strong>
<code>input = dict()</code></br>
<code>input['argo_id'] = list()</code></br>
<code>input['city'] = list()</code></br>
<code>input['past_trajs'] = list()</code></br>
<code>input['fut_trajs'] = list()</code></br>
<code>input['gt'] = list()</code></br>
<code>input['displ'] = list()</code></br>
<code>input['centers'] = list()</code></br>
<code>input['origin'] = list()</code></br>
<code>input['rotation'] = list()</code></br></p>
<p>29 + 32 = 61</br>
<code>argo_id:</code></br>
[&lsquo;01d7deae-31e9-4657-843f-c30009b09f1c&rsquo;, &lsquo;01ca1736-ec51-41aa-8c73-3338c574a83a&rsquo;]</br>
<code>city:</code></br>
[&lsquo;austin&rsquo;, &lsquo;austin&rsquo;]</br>
<code>past_trajs:</code></br>
torch.Size([29, 50, 3])</br>
torch.Size([32, 50, 3])</br>
<code>fut_trajs:</code></br>
torch.Size([29, 60, 3])</br>
torch.Size([32, 60, 3])</br>
<code>gt:</code></br>
torch.Size([29, 60, 2])</br>
torch.Size([32, 60, 2])</br>
<code>displ:</code></br>
torch.Size([29, 49, 3])</br>
torch.Size([32, 49, 3])</br>
<code>centers:</code></br>
torch.Size([29, 2])</br>
torch.Size([32, 2])</br>
<code>origin:</code></br>
torch.Size([2])</br>
torch.Size([2])</br>
<code>rotation:</code></br>
torch.Size([2, 2])</br>
torch.Size([2, 2])</br></p>
<p><strong>网络输入输出结构详解</strong></br>
In Inference with two sample data:</br>
<code>displ_cat:</code> 61 x 49 x 3</br>
<code>centers_cat:</code> 61 x 2</br>
<code>agents_per_sample:</code> [32, 29]</br></p>
<h3 id="encoder_lstmbr">encoder_lstm</br></h3>
<p><strong>input:</strong> <code>displ_cat</code>(61 x 49 x 3), <code>agents_per_sample</code> [32,29]</br>
$\downarrow$  input_size = 3; hidden_size = 128; num_layers = 1</br>
$\downarrow$<code>lstm_hidden_state = torch.randn(num_layers, lstm_in.shape[0], hidden_size) = torch.randn(1, 61, 128)</code></br>
$\downarrow$<code>lstm_cell_state = torch.randn(num_layers, lstm_in.shape[0], hidden_size) = torch.randn(1, 61, 128)</code></br>
$\downarrow$<code>lstm_out, lstm_hidden = self.lstm(lstm_in, lstm_hidden)</code> =&gt; lstm((61, 49, 3), (torch((1, 61, 128)), torch(1, 61, 128)))</br>
$\downarrow$ <code>lstm_out</code>(61 x 49 x 128)</br>
<strong>output:</strong> <code>lstm_out[:,-1,:]</code>(61 x 128)</br></p>
<h3 id="agent_gnnbr">agent_gnn</br></h3>
<p><strong>input:</strong> <code>out_encoder_lstm</code>(61 x 128), <code>centers_cat</code> (61 x 2) <code>agents_per_sample</code> [32,29]</br>
$\downarrow$ x = gnn_in =&gt; (61 x 128)</br>
$\downarrow$ edge_index = build_fully_connected_edge_idx(agents_per_sample).to(gnn_in.device) =&gt; (2, 1804) 1804 = (29 x 29-1) + (32 x (32-1))</br>
$\downarrow$</br>
$\downarrow$ edge_attr = build_edge_attr(edge_index, centers).to(gnn_in.device) =&gt; (1804, 2)</br>
$\downarrow$ x = F.relu(self.gcn1(x, edge_index, edge_attr)) =&gt; (61 x 128)</br>
<strong>output:</strong> gnn_out = F.relu(self.gcn2(x, edge_index, edge_attr)) =&gt; (61 x 128)</br></p>
<p>$$\mathbf{x}^{\prime}<em>i = \mathbf{x}<em>i + \sum</em>{j \in \mathcal{N}(i)}
\sigma \left( \mathbf{z}</em>{i,j} \mathbf{W}_f + \mathbf{b}<em>f \right)
\odot g \left( \mathbf{z}</em>{i,j} \mathbf{W}_s + \mathbf{b}_s  \right)$$</p>
<h3 id="multihead_self_attention">multihead_self_attention</h3>
<p><strong>input:</strong> <code>out_agent_gnn</code> (61 x 128) <code>agents_per_sample</code>[32,29]
$\downarrow$ max_agents = max(agents_per_sample) =&gt; 32
$\downarrow$ padded_att_in = torch.zeros((len(agents_per_sample), max_agents, self.latent_size), device=att_in[0].device) =&gt; torch: (2 x 32 x 128)
$\downarrow$ mask = torch.arange(max_agents) &lt; torch.tensor(agents_per_sample)[:, None] &amp;&amp; padded_att_in[mask] = att_in =&gt; torch: (2 x 32 x 128)
$\downarrow$ padded_att_in_swapped = torch.swapaxes(padded_att_in, 0, 1) =&gt; torch: (32, 2, 128)
$\downarrow$ padded_att_in_swapped, _ = self.multihead_attention(padded_att_in_swapped, padded_att_in_swapped, padded_att_in_swapped, key_padding_mask=mask_inverted) =&gt; torch: (32, 2, 128)
$\downarrow$ padded_att_in_reswapped = torch.swapaxes(padded_att_in_swapped, 0, 1) =&gt; torch: (2, 32, 128)
$\downarrow$ att_out_batch = [x[0:agents_per_sample[i]] for i, x in enumerate(padded_att_in_reswapped)] =&gt; list: 2
<strong>output:</strong> <code>att_out_batch</code> =&gt; list: 2 for each with shape (29, 128) and (32, 128)</p>
<h3 id="torchstack">torch.stack()</h3>
<p><strong>input:</strong> <code>out_self_attention:</code> list: 2 for each with shape (29, 128) and (32, 128)</br>
$\downarrow$ out_self_attention = torch.stack([x[0] for x in out_self_attention])</br>
<strong>output:</strong> <code>out_self_attention:</code> torch: (2, 128)</br></p>
<h3 id="predictionnetout_self_attention">PredictionNet(out_self_attention)</h3>
<h3 id="decoder_residual">decoder_residual</h3>
<p><strong>input:</strong> <code>out_self_attention</code>(torch: (2, 128)) <code>frozen = False</code></br>
$\downarrow$ [condition: frozen = False] sample_wise_out.append(PredictionNet(out_self_attention)) =&gt; torch: (2, 120)</br>
$\downarrow$ decoder_out = torch.stack(sample_wise_out) =&gt; torch: (1, 2, 120)</br>
$\downarrow$ decoder_out = torch.swapaxes(decoder_out, 0, 1) =&gt; torch: (2, 1, 120)</br>
<strong>output:</strong> decoder_out =&gt; torch: (2, 1, 120)</br></p>
<h3 id="out--out_linearviewlendispl-1--1-selfconfignum_preds-2">out = out_linear.view(len(displ), 1, -1, self.config[&rsquo;num_preds&rsquo;], 2)</h3>
<p><strong>input:</strong> decoder_out: torch: (2, 1, 120)</br>
$\downarrow$ out = out_linear.view(len(displ), 1, -1, self.config[&rsquo;num_preds&rsquo;], 2) =&gt; torch: (2, 1, 1, 60, 2)</br>
<strong>output:</strong> out =&gt; torch: (2, 1, 1, 60, 2)</br></p>
<h3 id="将预测轨迹转换到全局坐标">将预测轨迹转换到全局坐标</h3>
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">for i in range(len(out)):
</span></span><span class="line"><span class="cl">	out[i] = torch.matmul(out[i], rotation[i]) + origin[i].view(
</span></span><span class="line"><span class="cl">                1, 1, 1, -1
</span></span><span class="line"><span class="cl">            )</span></span></code></pre></td></tr></table>
</div>
</div>]]></description></item><item><title>DenseTNT and TNT 论文解读</title><link>https://jianye0428.github.io/posts/densetnt_tnt/</link><pubDate>Sun, 16 Jul 2023 15:53:59 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/densetnt_tnt/</guid><description><![CDATA[<h2 id="tnt-target-driven-trajectory-prediction">TNT: Target-driveN Trajectory Prediction</h2>
<p><code>**ref link:**</code>
<a href="https://zhuanlan.zhihu.com/p/435953928"target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/435953928<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
<a href="https://blog.csdn.net/weixin_40633696/article/details/124542807?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-2-124542807-blog-122758833.pc_relevant_vip_default&amp;spm=1001.2101.3001.4242.2&amp;utm_relevant_index=5"target="_blank" rel="external nofollow noopener noreferrer">https://blog.csdn.net/weixin_40633696/article/details/124542807?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-2-124542807-blog-122758833.pc_relevant_vip_default&spm=1001.2101.3001.4242.2&utm_relevant_index=5<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<h3 id="概览">概览</h3>
<p>在预测车辆的轨迹时, 需要尽可能考虑到车辆不同的情况，即不同的模态，如前行或左转，并预测出对应的概率。</p>
<p>模态的定义是比较模糊的，例如，有不同的速度前行，左转可以以不同的转弯角度实现。为了能够更加通用且精确地定义每条轨迹的模态，我们直接将每条轨迹的模态定义在每条轨迹的终点上。这里的一个重要假设是，轨迹的模态基本由终点所决定，当终点确定后，轨迹的形状也大体确定了。这样我们就把轨迹预测变成了终点预测问题，极大地简化了问题的复杂度。</p>
<p>TNT的预测方式: <strong>首先预测轨迹的终点，然后基于这个终点补充完整条轨迹</strong>。</p>
<p>TNT 基于终点的轨迹预测流程图:
</p>
<p>TNT使用VectorNet对高精地图和车辆信息进行编码，得到要预测的车辆的全局特征，以用于接下来的解码，从而完成轨迹预测：</p>
<p>(1). <strong>终点预测:</strong> 为每个Anchor预测一个偏移，得到终点，这些Anchor从道路的中心线上采样得到;
(2). <strong>轨迹补全:</strong> 基于上一步预测的终点将整条轨迹补充完整;
(3). <strong>轨迹打分和筛选:</strong> 根据场景特征，为每条轨迹进行打分，并筛选出最有可能的若干条轨迹。</p>
<h3 id="tnt-实现">TNT 实现</h3>
<h4 id="原理">原理</h4>
<p>给定一个单个障碍物的观测状态序列 $S_P = [s_{-T^{&rsquo;}+1}, s_{-T^{&rsquo;}+2}, &hellip;, s_0]$。我们的目标是预测它的未来状态 $S_F = [s_1, s_2, &hellip;, s_T]$ 到某个固定时间步 T。自然地，障碍物与由其它障碍物和场景元素组成的环境交互作为背景: $C_P​=[c_{-T′+1}​,c_{-T′+2}​,&hellip;,c_0​]$。为简洁起见，我们记 $X = (s_P, c_P)$，因此我们想捕捉的整体概率分布是 $p(S_F|X)$ 。</p>
<p>实际上， $p(S_F|X)$ 可以是高度多模态的。例如，车辆驶近十字路口时可能左转、直行或改变车道。直观上，未来状态的不确定性可以被分解为两部分：<u>目标或者意图的不确定性</u>，比如左右转的决定；以及<u>控制的不确定性</u>，比如转弯时需要的细粒度运动。因此，我们可以通过对目标设定条件，然后将其边缘化，从而对概率分布进行分解：</p>
<p>$$p(S_F​∣X)=∫_{τ∈τ(C_P​)}​p(τ∣X)p(S_F​∣τ,X)d_τ​, \tag{1}$$</p>
<p>其中 $\tau(C_P)$ 表示取决于观察到的背景 $C_P$ ​的合理目标空间。</p>
<p>在这个公式下，我们的主要见解是，对于轨迹预测等应用，通过正确设计目标空间 $\tau τ ( C_P )$（如目标位置），目标分布 $ p(\tau|X)$ 可以很好地捕捉意图不确定性。一旦目标确定，我们会进一步证明控制不确定性（如轨迹）可以通过<strong>简单的单模态分布</strong>可靠地建模。我们用一组离散位置来模拟目标空间  $\tau{C_P}$，将 $p(\tau|X)$ 的估计主要转化为一个分类任务。与隐变分模型相比，我们的模型以明确的目标分布的形式提供了更好的可解释性，并且在设计目标空间 $\tau{C_P}$ 时可以自然地结合专家知识（如道路拓扑）。</p>
<p>我们的整体框架有三个概念阶段。第一阶段是<strong>障碍物意图预测</strong>，其目标是用基于观察背景 $X$ 的目标空间 $\tau$ 的离散集合<u>对意图不确定性进行建模</u>，并且输出目标分布 $p(\tau|X)$ 。第二个阶段是<strong>障碍物条件运动估计</strong>，它用单模态分布对从初始状态到目标可能的未来运动进行建模。前两个阶段产生了以下概率预测 $p(S_F|X) = \sum_{\tau\in\tau(C_P)}p(\tau|X)p(S_F|\tau, X)$。</p>
<p>许多下游应用，例如实时行为预测，需要一小组具有代表性的未来预测，而不是所有可能未来的完整分布。我们的最终阶段，<strong>评分和选择</strong>，就是为此目的量身定制的。我们从所有代表性预测上学习一个评分函数 $\phi(S_F)$，并选择一个最终的多样化预测集。</p>
<p></p>
<h4 id="场景编码vectornet">场景编码VectorNet</h4>
<p>建模场景背景是轨迹预测的第一步，以获取<u>车辆-道路</u>和<u>车辆-车辆</u>之间的交互。TNT可以使用任何合适的背景编码器：当高清地图可用时，我们使用最优秀的层次图神经网络 VectorNet 对背景进行编码。具体来说，使用多段线来抽象出高清地图元素 $C_P$(车道，交通标志) 和代理轨迹 $S_P$​；采用子图（subgraph）网络对多段线进行编码，多段线包含可变数量的向量；然后使用全局图（global graph）对多段线之间的交互进行建模。输出是每个建模代理的全局背景特征 $X$。如果场景背景只在自上而下的图像形式中可用，则使用卷积网络作为背景编码器。</p>
<h4 id="目标预测">目标预测</h4>
<p>在我们的公式中，目标 $\tau$ 被定义为一个预测目标可能在固定时间范围 $T$ 上的位置 $(x,y)$ 。在第一步目标预测阶段，我们的目的是提供一个预测目标的未来目标的分布 $p( \tau ∣ X )$ 。我们通过一组$N$个离散的、带有连续偏移的量化位置来建模潜在的未来目标： $\tau ={\tau^n}={(x^n,y^n)+(\Delta x^n,\Delta y^n)}^N_{n=1}$​。然后这个目标上分布可以通过一个离散-连续分解来建模：</p>
<p>$$p(τ^n∣X)=π(τ^n∣X)⋅N(Δx^n∣v^x_n​(X))⋅N(Δ_y^n∣v_y^n​(X)),\tag{2}$$</p>
<p>中 $\pi(\tau^n|X)=\frac{e^{f(\tau^n,X)}}{\sum_{\tau^{&rsquo;}}e^{f(\tau^{&rsquo;},X)}}$ 是在位置选择 $(x^n,y^n)$上的离散分布。术语 $N(·|v(·))$ 表示一个广义正态分布，其中我们选择Huber作为距离函数。我们将均值表示为 $v(·)$并假设单位方差。</p>
<p>可训练函数 $f(·)$ 和  $v(·)$ 由一个2层的多层感知机(MLP)实现，目标坐标 $(x^k,y^k)$ 和场景背景特征 $X$ 作为输入。它们预测目标位置上的离散分布及其最可能的偏移量。这一阶段的训练损失函数由以下公式给出：</p>
<p>$$L_{S1}​=L_{cls​}(π,u)+L_{offset}​(v_x​,v_y​,Δx^u,Δy^u),\tag{3}$$</p>
<p>其中 $L_{cls}$ 是交叉熵损失， $L_{offset}$​ 是 Huber 损失；$u$ 是离真实位置最近的目标，并且 $\Delta x^u,\Delta y^u$ 是 $u$ 相对于真值的空间偏移量。</p>
<p>离散目标空间的选择在不同应用中是灵活的，如图3所示。在车辆轨迹预测问题中，我们从高清地图里均匀地采样车道中心线上的点并且将他们作为目标候选点(标记为黄色菱形)，假设车辆从未远离车道线；对于行人，我们在代理周围生成了一个虚拟网格并将网格点作为目标候选点。对每个候选目标，TNT目标预测器生成了一个 $(\pi,\Delta x, \Delta y)$ 的元组；回归后的目标以橙色五角星标记。与直接回归相比，将未来建模成一组离散目标的最显著的优势在于，它不受模态平均的影响，模态平均是阻止多模态预测的主要因素。</p>
<p></p>
<h4 id="基于目标的运动估计">基于目标的运动估计</h4>
<p>在第二阶段，我们将给定目标轨迹的可能性建模为 $p(S_F|\tau,X)=\prod^T_{t=1}p(s_t|\tau,X)$，同样采用了广义正态分布。这里有两个假设。首先，未来时间步是条件独立的，这使得我们的模型通过避免顺序预测提高了计算效率。其次，我们正在作出有力但合理的假设，即给定目标的轨迹分布是单模态(正态)的。对于短的时间范围来说，这当然是正确的；对于更长的时间范围，可以在(中间)目标预测和运动估计之间迭代，以便假设仍然成立。</p>
<p>这一阶段使用2层的MLP实现。它将背景特征 X 和目标位置 $\tau$ 作为输入，并且每个目标输出一条最可能的轨迹 $[\hat{s_1},&hellip;,\hat{s_T}] [s1​^​,&hellip;,sT​^​]$。由于它以第一阶段的预测目标为条件，为了实现平滑的学习过程，我们在训练时采用teacher forcing Technique[36]，将真实位置 $(x^n,y^n)$ 作为目标。该阶段的损失项是预测状态 $\hat{s_t}$​ 和真值 $s_t$​ 之间的距离：</p>
<p>$$L_{S2}​ = \sum_{t=1}^{T}​L_{reg}​(\hat{s},s_t​),\tag{4}$$</p>
<p>其中， $L_{reg}$​ 作为每一步坐标偏移的 Huber 损失来实现。</p>
<h4 id="轨迹评分和选择">轨迹评分和选择</h4>
<p>我们的最终阶段估计未来完整轨迹 S F S_F SF​ 的可能性。这和第二阶段不同，第二阶段分解时间步和目标，也和第一阶段不同，第一阶段只知道目标，但没有完整的轨迹——例如，一个目标可能被估计有很高的可能性，但到达该目标完整轨迹的可能性可能不是。</p>
<p>我们使用最大熵模型对第二阶段的所有 M 条轨迹进行评分:</p>
<p>$$\phi (S_F | X) = \frac{e^{g(S_F, X)}}{{\sum}_{m=1}^{M} e^{g(S_F^m, X)}}​$$,</p>
<p>其中 $g(·)$ 被建模为一个2层的 MLP。这一阶段训练的损失项是预测分数和真值分数之间的交叉熵，</p>
<p>$$L_{S3} = L_{CE}(\phi (S_F | X), \psi(S_F))$$</p>
<p>其中每个预测轨迹的真值评分由预测轨迹到真值轨迹的距离 $\psi(S_F)=\frac{exp(-D(S,S_{GT})/\alpha)}{\sum_{s^{&rsquo;}}exp(-D(S^{&rsquo;},S_{GT})/\alpha)}$ 定义，其中 $D(·)$ 单位为米， $\alpha$ 是温度。距离度量定义为 $D(S^i,S^j)=max(||s^i_1-s^j_1||^2_2,&hellip;,||s^i_t-s^j_t||^2_2)$。</p>
<p>为了从已评分的 $M$ 个轨迹获得最终一小组 $K$ 个预测轨迹，我们实现了一个轨迹选择算法来排除近似重复的轨迹。我们首先根据他们的分数对轨迹进行降序排列，并且贪婪地选择轨迹； 如果一个轨迹距离所有的选择轨迹都足够远，我们也会选择它，否则排除它。这里使用的距离度量和评分过程相同。这个过程的灵感来源于通常应用于计算机视觉问题（如目标检测）的非极大值抑制算法。</p>
<h4 id="训练和推理细节">训练和推理细节</h4>
<p>上述的 TNT 公式产生全监督的端到端训练，具有损失函数
$$L = \lambda_1 L_{S1} + \lambda_2 L_{S2} + \lambda_3 L_{S3}$$</p>
<p>其中，选择 $\lambda_1,\lambda_2,\lambda_3$ 来平衡训练过程。</p>
<p>在推理时，TNT 的工作原理如下：
(1) 工作场景编码；
(2) 采样 N 个候选目标作为目标预测器的输入，取由 $\pi(\tau|X)$ 估计的前 M 个目标；
(3) 从运动估计模型 $p(S_F|\tau,X)$ 中获取 M 个目标中每个目标的 MAP 轨迹；
(4) 通过  $\phi(S_F|\tau,X)$  给 M 个轨迹评分，并且选择一组最终的 K 个轨迹。</p>
<h2 id="densetnt">DenseTNT:</h2>
<p><code>ref link:</code> <a href="https://blog.csdn.net/weixin_39397852/article/details/122764880"target="_blank" rel="external nofollow noopener noreferrer">https://blog.csdn.net/weixin_39397852/article/details/122764880<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<h3 id="comparison-between-densetnt-and-tnt">Comparison between DenseTNT and TNT</h3>
<p></p>
<p>TNT(左图)是根据lane定义一些anchor，再regress和classify获得最终的位置，之后还要通过NMS的筛选法选出最后的轨迹。
DenseTNT(右图)是通过密集地采点避免了定义anchor，同时也避免了使用NMS等规则来筛选轨迹。</p>
<p>意图预测中非常重要的一个问题是ground truth只有一个，而对于多意图的预测来说，多个方向的预测都是允许的，这导致了label中有很多都是无效的，因为gt只包含了一个意图下的结果。此处设计了一个offline的model来提供多个意图下的label。这个model使用了一个优化算法从goal的分布里取出了一个set作为online model的label。</p>
<h3 id="method-具体实现方法">Method 具体实现方法</h3>
<h4 id="sparse-context-encoding----vectornet">sparse context encoding &ndash; VectorNet</h4>
<p>本文使用VectorNet来提取地图的feature。(没有的高精地图的话也可使用CNN)</p>
<h4 id="dense-goal-probability-estimation">Dense goal probability estimation</h4>
<p>TNT对于一个goal只预测一条轨迹的概率是有问题的：一个goal只有一条预测(可能通向这个goal的别的预测概率很高)，一个goal获取的feature不够丰富(goal附近的点的信息也用上会更好)。</p>
<p>我们使用了<code>dense goal encoder</code>。它以一定的采样频率获取了地图上在道路上的所有点。然后预测了这些密集点的概率分布。</p>
<h5 id="lane-scoring">Lane Scoring</h5>
<blockquote>
<p>在论文实现中，可以用point scoring代替，效果更好。目的在与选出距离final pos(gt)更近的点。</p>
</blockquote>
<p>为了减少需要sample的点，我们先预测goal落在不同lane上的概率，这样能过滤掉明显不在candidate lane附近的点，提升运算速度。
这是一个二分类问题。因此使用了二分类的交叉熵计算loss。对于label，使用离gt的goal最近的lane作为1，别的lane为0。对于别的lane $l$，假设gt的goal是$y_{gt}$​，定义一个distance</p>
<p>$$d(l,y_{gt}) = min(||l_1 - y_{gt}||^2, ||l_2 - y_{gt}||^2, &hellip;, ||l_t - y_{gt}||^2,)$$</p>
<p>直觉上就是gt的goal到这条lane的最短距离的平方。</p>
<h5 id="probability-estimation">Probability Estimation</h5>
<p>获得概率分布的做法是self-attention。首先agent的feature经过两次MLP。然后把goal的feature $F$作为需要query的变量，从地图上所有元素 (lane，agent)的feature中去查找索引对应的键和值。<font color=red>目的就是建立goal的feature与地图上所有元素的联系。</font>直观上，这一步是把agent的未来状态(goal)表示成由历史的信息作为变量的函数，这个函数采用的是self-attention的做法。</p>
<p>轨迹目标点(goals)和道路的局部信息可以用以下注意力机制表示:</p>
<p>$$\mathbf{Q} = \mathbf{FW}^{\mathbf{Q}}, \mathbf{K} = \mathbf{LW}^{\mathbf{K}}, \mathbf{V}=\mathbf{LW}^{\mathbf{V}}$$</p>
<p>$$\mathbf{A}(\mathbf{Q},\mathbf{K},\mathbf{V}) = softmax(\frac{\mathbf{QK^\top}}{\sqrt{d_k}})\mathbf{V}$$</p>
<p>where $\mathbf{W}^Q, \mathbf{W}^{K}, \mathbf{W}^{V} \in \mathbb{R}^{d_h \times d_k}$ are the matrices for linear projection, $d_k$ is the dimension of query / key / value vectors, and $\mathbf{F}, \mathbf{F}$ are feature matrices of the dense goal candidates and all map elements (i.e., lanes or agents), respectively.</p>
<p>这一步之后的结果是goal新的feature $\mathbf{F}$。再通过两次MLP，即下图中的 $g(.)$.用softmax中的方法获得每个goal的概率。将所有goal在地图上表示出来的话就是一个概率分布heatmap。</p>
<p>$$\phi_i = \frac{\exp(g(\mathbf{F}<em>i))}{\sum</em>{n=1}^{N}\exp(g(\mathbf{F}_n))}$$</p>
<p>对于Loss的计算，离gt的goal最近的goal的label定为1，其余都为0.采取二分类交叉熵的算法。</p>
<p>$$\mathcal{L}<em>\text{goal} = \mathcal{L}</em>{\text{CE}}(\phi, \psi)$$</p>
<h4 id="goal-set-prediction">Goal Set Prediction</h4>
<p>对于多意图的预测，在TNT中，预先设定好target，采用NMS(non-maximum suppression)(靠的近或概率低的过滤掉)。而DenseTNT的上一步获得是heatmap，因此不能简单使用NMS，因为用于筛选的阈值比较难定。这是因为TNT中采用的是从高到低排序概率，而DenseTNT中的概率分布是针对于整个鸟瞰图的，一旦意图的可能性变多了，平均分布到每一个意图的概率就低了(对于概率分布，所有的点的概率加起来需要为1)。</p>
<p>heatmap，输出是goal set，这个有点像目标检测的框生成。但和目标检测不同，对于一个输入，我们的label只有一个，即gt。这样的话可能会有别的意图的结果在训练中被忽略。为此，设计了一个offline model来制造这些label。它和online model的区别就在这一步中。没有使用goal set predictor而是采用了优化算法。</p>
<p></p>
<h5 id="offline-optimization">Offline Optimization</h5>
<p>上一步heatmap的输出，实际上是对于地图上众多goal每个点的一个函数。设定 $C={c_1,c_2,&hellip;,c_m}$ 为所有dense goal的candidate，heatmap就把 $C$ 映射到一个0到1的集合，写成 $h(c_i)$ ，这也是每个goal的概率。
接下来定义一个目标函数:</p>
<p>$$E[d(\hat{y}, Y)] = \sum^m_{i=1}h(c_i)d(\hat{y}, c_i)$$</p>
<p>其中，$d(\hat{y}, c_i) = \mathop{\min}\limits_{y_i \in \hat{y}}||y_j - y_{c_i}||$</p>
<p>从直观上讲，目标是有M个goal（大池子），要从中选取K个靠谱的goal（小池子）。 $d$ 是针对于大池子的，对于大池子里所有candidate都有一个 $d$。这每个candidate都与小池子中的goal计算距离，取最近的作为 d d d，即寻找小池子中离candidate最近的点。对于所有的 $d$，用概率加权计算期望。总体的话在收敛情况，大池子中的所有goal到距离自己最近的小池子中的goal乘上概率加权应当达到最小。以下是这个优化算法的实现。</p>
<p></p>
<p>翻译成中文：</p>
<ul>
<li>初始化K个goal，从M个goal的大池子里随机选</li>
<li>小池子里的每个goal做随机扰动，变为别的goal</li>
<li>计算原来的和现在的小池子的d的期望e和e’</li>
<li>如果现在的小池子d的期望更小，则使用现在的小池子。否则以1%的概率采用现在的小池子。（避免局部最优）</li>
<li>不停循环2-4直到步数达到阈值（或时间太长）</li>
</ul>
<p>优化算法之后得到的就是全局最优的选中的小池子。这个小池子里的结果能作为训练online模型的伪label。</p>
<h5 id="goal-set-predictor-online">Goal Set Predictor (online)</h5>
<p>模型采用了encode+decode的办法。encoder部分是一层self-attention加上max pooling，decoder部分是2层MLP，输入是heatmap，输出是2K+1个值，分别对应K个2维坐标（goal set）和一个当前goal set的confidence。</p>
<p>考虑到heatmap的概率分布比较散，可以采用N头同时运算。即N个goal set predictor输出N个2K+1的值，从当中选取confidence最高的那个goal set预测。为了运算效率的提升，这N头使用相同的self-attention层，但是不同的2个MLP。</p>
<p>在训练过程中，采用了offline模型的伪label作为监督。上述offline中讲到的初始选定的小池子，在这里采用的是online模型的K个goal的set的预测。然后经过L次随机扰动（即不停随机选取邻居点，L=100），选取当中expected error（offline里的期望项）最小的那个set作为伪label。</p>
<p>标记 $\dot{y}$ ​为预测结果， $\hat{y}$ ​为伪label，则loss的计算如下。即一一对应后的L1距离之和。</p>
<p>$$\mathcal{L_{set}(\dot{y}, \hat{y})} = \sum_{i=1}^{k}\mathcal{L}_{\text{reg}}(\dot{y}, \hat{y})$$</p>
<p>再考虑到采用了N头预测，这部分的loss将采用二分类的交叉熵。其中 $\mu$ 为所有head的confidence，$\nu$ 为label，只有expected error最低的label为1，别的为0。</p>
<p>$$\mathcal{L}<em>\text{head} = \mathcal{L}</em>{\text{CE}}(\mu, \nu)$$</p>
<h4 id="trajectory-completion">Trajectory Completion</h4>
<p>这一步和TNT做法类似。类似于dense goal encoding（2层MLP后过self-attention）最后过2层MLP来decode得到整条预测轨迹的state。采用teacher forcing技巧（因为只有一条gt）训练时只用gt的goal来算这条预测轨迹。Loss的算法和TNT一样，用的是点点之间的Huber loss。</p>
<p>$$\mathcal{L}<em>{\text{completion}} = \sum</em>{t=1}^{T}\mathcal{L_{reg}}(\hat{s}_t, s_t)$$</p>
<h4 id="learning">Learning</h4>
<p>训练分为两个stage。第一个stage使用gt轨迹训练除了goal set predictor的部分。即把dense的goal输入。获得大量的轨迹。</p>
<p>$$\mathcal{L}<em>{s1} = \mathcal{L}</em>{lane} + \mathcal{L}<em>{goal}+ \mathcal{L}</em>{completion}$$</p>
<p>第二个stage主要负责goal set predictor的部分。</p>
<p>$$\mathcal{L}<em>{s2} = \mathcal{L}</em>{head} + \mathcal{L}_{set}$$</p>
]]></description></item><item><title>LaneGCN 论文解读</title><link>https://jianye0428.github.io/posts/lanegcn/</link><pubDate>Sun, 16 Jul 2023 15:53:35 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/lanegcn/</guid><description><![CDATA[<p><code>paper link:</code> <a href="https://arxiv.org/abs/2007.13732"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/abs/2007.13732<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
<code>PPT:</code> <a href="https://www.cs.toronto.edu/~byang/slides/LaneGCN.pdf"target="_blank" rel="external nofollow noopener noreferrer">https://www.cs.toronto.edu/~byang/slides/LaneGCN.pdf<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<h2 id="architechture">Architechture</h2>
<p><strong><font color=red>Lane Graph + Actor Map:</font></strong></p>
<ul>
<li>
<p>construct lane graph from vectorized map data to preserve the map structure and can avoid information loss 构建矢量化地图信息，避免地图信息丢失</p>
</li>
<li>
<p>LaneGCN:</p>
<ul>
<li>
<p>extends <strong>graph convolutions with multiple adjacency matrices</strong> and along-lane dilation</p>
<ul>
<li>to capture complex topology and long range dependencies of the lane graph.</li>
</ul>
</li>
<li>
<p>exploit a <strong>fusion network</strong> consisting of four types of interactions: <code>actor-to-lane</code>, <code>lane-to-actor</code>, <code>actor-to-actor</code>, <code>lane-to-lane</code>.</p>
<ul>
<li>present both actors and lanes as nodes in the graph and use a 1D CNN and LaneGCN to extract the features for the actor and lane nodes respectively, and then exploit spatial attention and another LaneGCN to model four types of interactions.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p></p>
<p><strong><font color=red>Difference between VectorNet and LaneGCN:</font></strong></p>
<ul>
<li><u>VecotrNet</u> uses vanilla graph networks with undirected full connections; <u>LaneGCN</u> uses connected lane graph folllowing the map topology and propose task specific multi-type and dilated graph operators.</li>
<li>VectorNet uses polyline-level nodes for interactions; LaneGCN uses polyline segments as map nodes to capture higher resolution.</li>
</ul>
<h2 id="lane-graph-representations-for-motion-forecasting">Lane Graph Representations for Motion Forecasting</h2>
<p></p>
<h3 id="font-colorredactornetfont-extracting-traffic-participant-representations"><font color=red>ActorNet</font>: Extracting Traffic Participant Representations</h3>
<p>Each Trajctory is represented as a sequence of displacement ${ \bigtriangleup{p_{-(T-1)},&hellip;,\bigtriangleup{p_{-1}}, \bigtriangleup{p_0}}}$, where $\bigtriangleup{p_t}$ is the 2D displacement from time step $t-1$ to t, and T is the trajectory size.</p>
<p>For trajectories with sizes smaller than $T$ , we pad them with zeros. We add a binary $1 × T$ mask to indicate if the element at each step is padded or not and concatenate it with the trajectory tensor, resulting in an input tensor of size $3 × T$.</p>
<p>1D CNN is used to process the trajectory input for its effectiveness in extracting multi-scale features
and efficiency in parallel computing. The output of ActorNet is a temporal feature map, whose element at $t = 0$ is used as the actor feature. The network has 3 groups/scales of 1D convolutions.</p>
<p>Each group consists of 2 residual blocks, with the stride of the first block as 2. We then use a Feature Pyramid Network (FPN) to fuse the
multi-scale features, and apply another residual block to obtain the output tensor. For all layers, the convolution kernel size is 3 and the number of output channels is 128. Layer normalization and the Rectified Linear Unit (ReLU) are used after each convolution.</p>
<p></p>
<h3 id="font-colorredmapnetfont-extracting-structured-map-representation"><font color=red>MapNet</font>: Extracting Structured Map Representation</h3>
<p>General Architecture:</p>
<ul>
<li>part 1: building a lane graph from vectorized map data;</li>
<li>part 2: applying our novel LaneGCN to the lane graph to output the map features.</li>
</ul>
<p><strong>Map Data:</strong></p>
<p>In this paper, we adopt a simple form of vectorized map data as our representation of HD maps. Specifically, the map data is represented as a set of lanes and their connectivity. Each lane contains a centerline, i.e., a sequence of 2D BEV points, which are arranged following the lane direction (see Fig. 3, top). For any two lanes which are directly reachable, 4 types of connections are given: <code>predecessor</code>, <code>successor</code>, <code>left neighbour</code> and <code>right neighbour</code>.</p>
<p><strong>Lane Graph Construction:</strong></p>
<p>first define a lane node as the straight line segment formed by any two consecutive points (grey circles in Fig. 3) of the centerline. The location of a lane node is the averaged coordinates of its two end points. Following the connections between lane centerlines, we also derive 4 connectivity types for the lane nodes, i.e., <code>predecessor</code>, <code>successor</code>, <code>left neighbour</code> and <code>right neighbour</code>.</p>
<p>We denote the lane nodes with $V ∈ \mathbb R^{N ×2}$ , where $N$ is the number of lane nodes and the $i$-th row of $V$ is the BEV coordinates of the $i$-th node. We represent the connectivity with 4 adjacency matrices ${\lbrace A_i \rbrace}_{i \in {pre,suc,left,right}}$ , with $A_i \in \mathbb R^{N ×N}$.</p>
<p>We denote $A_{i,jk}$, as the element in the $j$-th row and $k$-th column of $A_i$. Then $A_{i,jk} = 1$ if node $k$ is an $i$-type neighbor of node $j$.</p>
<p><strong>LaneConv Operator:</strong></p>
<p><font color=green><em>Node Feature:</em></font>
Each lane node corresponds to a straight line segment of a centerline. To encode all the lane node information, we need to take into account both the shape (size and orientation) and the location (the coordinates of the center) of the corresponding line segment. We parameterize the node feature as follows,</p>
<p>$$x_i = MLP_{shape} (v_{i}^{end} - v_{i}^{start}) + MLP_{loc}(v_i) $$</p>
<p>where $MLP$ indicates a multi-layer perceptron and the two subscripts refer to shape and location, respectively. $v_i$ is the location of the i-th lane node, i.e., the center between two end points, $v_i^{start}$ and $v_i^{end}$ are the BEV coordinates of the node $i’s$ starting and ending points, and $x_i$ is the $i$-th row of the node feature matrix $X$, denoting the input feature of the $i$-th lane node.</p>
<p><font color=green><em>LaneConv:</em> </font>
To aggregate the topology information of the lane graph at a larger scale, we design the following LaneConv operator:</p>
<p>$$Y = XW_0 + \sum_{i\in{pre, suc, left, right}}A_iXW_i,\tag{2}$$</p>
<p>where $A_i$ and $W_i$ are the adjacency and the weight matrices corresponding to the $i$-th connection type respectively. Since we order the lane nodes from the start to the end of the lane, $A_{suc}$ and $A_{pre}$ are matrices obtained by shifting the identity matrix (diagnal 1) one step towards upper right (non-zero superdiagonal) and lower left (non-zero subdiagonal). $A_{suc}$ and $A_{pre}$ can propagate information from the forward and backward neighbours whereas $A_{left}$ and $A_{right}$ allow information to flow from the cross-lane neighbours. It is not hard to see that our LaneConv builds on top of the general graph convolution and encodes more geometric (e.g., connection type/direction) information. As shown in our experiments this improves over the vanilla graph convolution.</p>
<p><font color=green><em>Dilated LaneConv:</em></font></p>
<p>Functionality: The model needs to capture the long range dependency along the lane direction for accurate prediction.</p>
<p>the k-dilation LaneConv operator is defined as follows:</p>
<p>$$Y = XW_0 + A_{pre}^k XW_{pre,k} + A_{suc}^k X W_{suc,k} \tag{3}$$</p>
<p>where $A_{pre}^k$ is the $k$-th matrix power of $A_{pre}$. This allows us to directly propagate information along the lane for $k$ steps, with $k$ a hyperparameter. Since $A_{pre}^k$ is highly sparse, one can efficiently compute it using sparse matrix multiplication. Note that the dilated LaneConv is only used for predecessor and successor, as the long range dependency is mostly along the lane direction.</p>
<p><font color=green><em>LaneGCN:</em></font></p>
<p>With Eq.(2) and Eq.(3), we get a multi-scale LaneConv operator with C dilation size as follows:</p>
<p>$$Y = XW_0 + \sum_{i\in \lbrace left, right \rbrace} A_i X W_i + \sum_{c=1}^C (A_{pre}^{k_c}XW_{pre, k_c} + A_{suc}^{k_c}XW_{suc, k_c})， \tag{4}$$</p>
<p>where $k_c$ is the $c$-th dilation size. We denote $LaneConv(k_1 , · · · , k_C)$ this multi-scale layer.</p>
<p></p>
<h3 id="font-colorredfusion-netfont"><font color=red>Fusion Net</font></h3>
<p>Four types fusion modules:</p>
<ul>
<li>A2L: introduces real-time traffic information to lane nodes, such as blockage or usage of the lanes.</li>
<li>L2L: updates lane node features by propagating the traffic information over the lane graph. -&gt; LaneGCN</li>
<li>L2A: fuses updated map features with real-time traffic information back to the actors.</li>
<li>A2A: handles the interactions between actors and produces the output actor features, which are then used by the prediction header for motion forecasting.</li>
</ul>
<p>We implement L2L using another LaneGCN, which has the same architecture as the one used in our MapNet (see Section 3.2). In the following we describe the other three modules in detail. We exploit a spatial attention layer for A2L, L2A and A2A. The attention layer applies to each of the three modules in the same way. Taking A2L as an example, given an actor node i, we aggregate the features from its context lane nodes j as follows:</p>
<p>$$y_i = x_i W_0 + \sum_j \phi (concat(x_i, \Delta_{i,j}, x_j)W_1)W_2, \tag{5}$$</p>
<p>with $x_i$ the feature of the $i$-th node, $W$ a weight matrix, $\phi$ the compositon of layer notmalization and RelU, and $\Delta_{ij} = MLP(v_j - v_i)$, where $v$ denotes the node location.</p>
<h3 id="font-colorredprediction-headerfont"><font color=red>Prediction Header</font></h3>
<p>Take after-fusion actor features as input, a multi-modal prediction header outputs the final motion forecasting. For each actor, it predicts $K$ possible future trajectories and their confidence scores.</p>
<p>The header has two branches, a regression branch to predict
the trajectory of each mode and a classification branch to predict the confidence score of each mode.</p>
<p>For the m-th actor, we apply a residual block and a linear layer in the
regression branch to regress the K sequences of BEV coordinates:</p>
<p>$$O_{m,reg} = \lbrace (p_{m,1}^k, p_{m,2}^k, &hellip;, p_{m,T}^k) \rbrace _{k\in[0,K-1]}$$</p>
<p>where $p_{m,i}^k$ is the predicted $m$-th actor&rsquo;s BEV coordinates of the $k$-th mode at the $i$-th time step. For the classification branch, we apply an MLP to $p^k_{m,T} − p_{m,0}$ to get $K$ distance embeddings. We then concatenate each distance embedding with the actor feature, apply a residual block and a linear layer to output $K$ confidence scores, $O_{m,cls} = (c_{m,0}, c_{m,1}, &hellip;, c_{m,K−1})$.</p>
<h3 id="font-colorredlearningfont"><font color=red>Learning</font></h3>
<p>use the sum of classification and regreesion losses to train the model:</p>
<p>$$ L = L_{cls} + \alpha L_{reg},$$</p>
<p>where $\alpha = 1.0$.</p>
<p>For classification, we use the max-margin loss:</p>
<p>$$L_{cls} = \frac{1}{M(K-1)}\sum_{m=1}^M \sum_{k \neq \hat{k}} \max(0, c_{m,k} + \epsilon - c_{m, \hat{k}}) \tag{6}$$</p>
<p>where $\epsilon$ is the margin and $M$ is the total number of actors. For regression, we apply the smooth $l1$ loss on all predicted time steps:</p>
<p>$$L_{reg} = \frac{1}{MT} \sum_{m=1}^M \sum_{t=1}^T reg(p_{m,y}^{\hat{k}} - p_{m,t}^*) \tag{7}$$</p>
<p>where $p_t^*$ is the ground truth BEV coordinates at time step $t$, $reg(x) = \sum\limits_i d(x_i)$, $x_i$ is the $i$-th element of $x$, and $d(x_i)$ is the smooth $\ell1$ loss defined as:</p>
<p>$$d(x_i) = \begin{cases}
0.5x_i^2 &amp;\text{if} ||x|| &lt; 1, \
||x_i|| - 0.5 &amp; \text{otherwise,}
\end{cases} \tag{8}$$</p>
<p>where $||x_i||$ denotes the $\ell1$ norm of $x_i$.</p>
<h3 id="font-colorred-neural-network-layoutfont"><font color=red> Neural Network Layout</font></h3>
<p></p>
<h3 id="font-colorreddata-process-and-network-constructionfont"><font color=red>Data Process And Network Construction</font></h3>
<blockquote>
<p>以官方的2645.csv数据集为例子</p>
</blockquote>
<p><strong>agent node:</strong></p>
<ul>
<li><code>data['city']:</code>城市名称</li>
<li><code>data['trajs'] = [agt_traj] + ctx_trajs:</code>轨迹点，(agent + context vehicles)</li>
<li><code>data['steps'] = [agt_step] + ctx_steps:</code>在原始数据中的位置</li>
<li><code>data['feats'] = feats:</code> (13 X 20 X 3) 前20预测轨迹 + 一维是否存在点</li>
<li><code>data['ctrs'] = ctrs:</code> (13 X 2) 中心点</li>
<li><code>data['orig'] = orig:</code> AGENT 当前点坐标</li>
<li><code>data['theta'] = theta:</code> AGENT 偏转角</li>
<li><code>data['rot'] = rot:</code> (2 X 2) 旋转矩阵</li>
<li><code>data['gt_preds'] = gt_preds:</code>(13 X 30 X 2) 后30帧真实轨迹</li>
<li><code>data['has_preds'] = has_preds:</code> (13 X 30) 标识后30帧轨迹是否存在</li>
</ul>
<p><strong>lane node:</strong></p>
<ul>
<li><code>graph['ctrs'] = np.concatenate(ctrs, 0):</code> lane node的中心点坐标</li>
<li><code>graph['num_nodes'] = num_nodes:</code> lane node的数量</li>
<li><code>graph['feats'] = np.concatenate(feats, 0):</code> lane node 方向向量</li>
<li><code>graph['turn'] = np.concatenate(turn, 0):</code> lane node 转向标识</li>
<li><code>graph['control'] = np.concatenate(control, 0):</code> lane node 的 has_traffic_control 标识</li>
<li><code>graph['intersect'] = np.concatenate(intersect, 0):</code> lane node 的 is_intersection 标识</li>
<li><code>graph['pre'] = [pre]:</code> pre[&lsquo;u&rsquo;] 和 pre[&lsquo;v&rsquo;], v 是 u 的pre， 这里表述的是lane node之间的关系</li>
<li><code>graph['suc'] = [suc]:</code> suc[&lsquo;u&rsquo;] 和 suc[&lsquo;v&rsquo;], v 是 u 的suc， 这里表述的是lane node之间的关系</li>
<li><code>graph['lane_idcs'] = lane_idcs:</code> lane node index
<ul>
<li>
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="mi">0</span> <span class="mi">0</span> <span class="mi">0</span> <span class="o">...</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl"><span class="mi">1</span> <span class="mi">1</span> <span class="mi">1</span> <span class="o">...</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">    <span class="o">...</span>
</span></span><span class="line"><span class="cl"><span class="mi">83</span> <span class="mi">83</span> <span class="mi">83</span> <span class="o">...</span> <span class="mi">83</span></span></span></code></pre></td></tr></table>
</div>
</div></li>
</ul>
</li>
<li><code>graph['pre_pairs'] = pre_pairs:</code> pair 表述的是lane之间的关系</li>
<li><code>graph['suc_pairs'] = suc_pairs:</code> pair 表述的是lane之间的关系</li>
<li><code>graph['left_pairs'] = left_pairs:</code> pair 表述的是lane之间的关系</li>
<li><code>graph['right_pairs'] = right_pairs:</code> pair 表述的是lane之间的关系
<ul>
<li>对于<code>pre['u']</code>和<code>pre['v']</code>, v 是 u 的 pre</li>
<li>对于<code>suc['u']</code>和<code>suc['v']</code>, v 是 u 的 suc</li>
<li>对于<code>left['u']</code>和<code>left['v']</code>, v 是 u 的 left</li>
<li>对于<code>right['u']</code>和<code>right['v']</code>, v 是 u 的 right</li>
</ul>
</li>
</ul>
<p><strong>Net结构</strong></p>
<ul>
<li><strong>ActorNet</strong>
<code>input:</code> M x 3 x 20
<code>output:</code> M x 128 x 20</li>
</ul>
<p>解释:</p>
<ul>
<li>
<p><strong>MapNet</strong>: 把 v 按照 u 加到center上
<code>input:</code> N x 4
<code>output:</code> N x 128</p>
</li>
<li>
<p><strong>A2M</strong>
<code>input:</code> N x 128
<code>output:</code> N x 128</p>
</li>
<li>
<p><strong>M2M</strong>
<code>input:</code> N x 128
<code>output:</code> N x 128</p>
</li>
<li>
<p><strong>M2A</strong>
<code>input:</code> N x 128
<code>output:</code> M x 128</p>
</li>
<li>
<p><strong>A2A</strong>
<code>input:</code> N x 128
<code>output:</code> N x 128</p>
</li>
<li>
<p><strong>Prediction Header:</strong>
<code>input</code> M x 128</p>
<ul>
<li>MLP Regression</li>
<li>MLP Classification</li>
</ul>
</li>
</ul>
<p>ref link: <a href="https://zhuanlan.zhihu.com/p/447129428"target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/447129428<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
]]></description></item><item><title>Social_NCE 论文解读</title><link>https://jianye0428.github.io/posts/social_nce/</link><pubDate>Sun, 16 Jul 2023 15:53:27 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/social_nce/</guid><description><![CDATA[<p><code>paper link:</code> <a href="https://arxiv.org/abs/2012.11717"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/abs/2012.11717<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
<code>论文解读参考:</code>
[1] <a href="https://zhuanlan.zhihu.com/p/434650863"target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/434650863<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
[2] <a href="https://www.gushiciku.cn/pl/amod"target="_blank" rel="external nofollow noopener noreferrer">https://www.gushiciku.cn/pl/amod<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<h2 id="issue-to-solve-and-its-solution">Issue to solve and its Solution</h2>
<p>Due to the ill-distributed training Data, it&rsquo;s <u><font color=red>difficult to capture the notion of the &ldquo;negative&rdquo; examples</font></u> like collision.</p>
<p><strong>Solution:</strong></p>
<p>Modeling the negative samples through self-supervision:</p>
<ul>
<li><font color=red>a social contrastive loss</font>: regularizes the extracted motion representation by discerning the ground-truth positive events from synthetic negative ones;</li>
<li><font color=red>Construct negative samples</font> based on prior knowledge of rare but dangerous circumstances.
<blockquote>
<p>a social sampling strategy (informed): construct the positive event from the ground-truth location of the primary agent and the negative events from the regions of other neighbors. given that one location cannot be occupied by multiple agents at the same time.</p>
</blockquote>
</li>
</ul>
<h2 id="method-font-colorredcontrastive-learning--social-ncefont">Method: <font color=red><em>Contrastive Learning + Social NCE</em></font></h2>
<h3 id="contrastive-representation-learning">Contrastive Representation Learning</h3>
<ul>
<li>
<p>Functionality:</p>
<ul>
<li>
<p><code>Representation Learning:</code> to learn a parametric function that maps the raw data into a feature space to extract abstract and useful information for downstream tasks.</p>
</li>
<li>
<p><code>NCE(Noise Contrastive Estimation):</code> to train encoder</p>
</li>
</ul>
<p>$$\mathcal{L_{NCE}} = -\log \frac{\exp(sim(q,k^+)/\tau)}{\sum_{n=0}^N  \exp(sim(q,k_n)/ \tau)}$$</p>
<p>where the encoded query $q$ is brought close to one positive key $k_0 = k^+$ and pushed apart from $N$ negative keys ${ k_1, k_2, &hellip; , k_N}$, $\tau$ is a temperature hyperparameter, and $sim(u,v) = u^{\mathsf{T}}v/(||u||||v||)$ is the cosine similarity between two feature vectors.</p>
</li>
</ul>
<h3 id="social-nce">Social NCE</h3>
<p><strong>Social NCE Description:</strong></p>
<p>智能体 $i$ 在时刻 $t$ 上的位置记为 $s^i_t=(x^i_t,y^i_t)$ 。那么 $M$ 个智能体的联合状态记为 $s_t = { s_t^1, &hellip;, s^M_t}$ 。给定一个历史观测序列 ${s_1, s_2, &hellip;, s_t}$ ，任务是预测所有智能体未来直至 $T$ 时刻的轨迹 ${s_{t+1}, &hellip;, s_T}$，许多最近的预测模型被设计为编码器 - 解码器神经网络，其中运动编码器 $f(\cdot)$ 首先提取与 $i$ 相关的紧密表示 $h_t^i$ ，然后解码器 $g(\cdot)$ 随后推测出其未来的轨迹 $\hat{s}^i_{t+1,T}$ :</p>
<p>$$h^i_t = f(s_{1:t}, i),  $$
$$\hat{s}^i_{t+1:T} = g(h^i_t)$$</p>
<p>为了多智能体之间的社交互动，$f(\cdot)$通常包含两个子模块：一个序列建模模块 $f_S(\cdot)$ 用于编码每个单独的序列，以及一个交互模块 $f_I(\cdot)$ 用于在多智能体之间共享信息：</p>
<p>$$z^i_t = f_S(h^i_{t-1}, s^i_t),$$
$$h^i_t = f_I(z_t, i)$$</p>
<p>其中， $z^i_t$ 是给定智能体 $i$ 在时间 $t$ 观察其自身状态的潜在表示， $z_t = {z^1_t,&hellip;,z^M_t}$ 。很多方法已经探索了各种架构，并验证了其准确性。尽管如此，它们的鲁棒性仍然是一个悬而未决的问题。 最近的几项工作表明，现有模型预测的轨迹通常会输出社会不可接受的解决方案（例如，碰撞），表明缺乏关于社会准则的常识。</p>
<p></p>
<ul>
<li>
<p><code>query</code>: embedding of history observations $q = \psi(h^i_t)$, where $\psi(\cdot)$ is an MLP projection head;</p>
</li>
<li>
<p><code>key</code>: embedding of a future event $k = \phi(s^i_{s+\delta t}, \delta t)$, where $\phi(\cdot)$ is an event encoder modeled by an MLP, $s_{t+\delta t}^i$ is a sampled spatial location and $\delta_t &gt; 0$ is the sampling horizon.</p>
<blockquote>
<p>tuning $\delta_t \in \Lambda$, e.g. $\Lambda = {1,&hellip;,4}$, then future events in the next few step can be taken in account simultaneously. Nevertheless, when $\delta_t$ is a fixed value, then $\phi(\cdot)$ can be simplified as a location encoder, i.e., $\phi(s^i_{t+\delta t})$.</p>
</blockquote>
</li>
</ul>
<p>给定一个场景，包括感兴趣的主智体（蓝色）和附近多个相邻智体（灰色），Social-NCE 损失鼓励在嵌入空间中提取的运动表示，接近未来的正样本事件，并远离可能导致碰撞或不适的合成负样本事件. Social NCE的损失函数如下:</p>
<p>$$\mathcal{L_{SocialNCE}} = -\log\frac{\exp(\psi(h^i_t)\cdot\phi(s^{i,+}<em>{t+\delta t}, \delta t)/\tau)}{\sum</em>{\delta t\in\Lambda}\sum_{n=0}^{N}\exp(\psi(h^i_t)\cdot\phi(s^{i,n}_{t+\delta t}, \delta t)/\tau))}$$</p>
<p>最终的训练损失函数为Social-NCE和传统任务损失项之和，即轨迹预测的mean squared error (MSE) 或者negative log-likelihood (NLL)：</p>
<p>$$\mathcal{L}(f,g,\psi, \phi) = \mathcal{L}<em>{task}(f,g) + \lambda \mathcal{L}</em>{SocialNCE}(f, \psi, \phi)$$</p>
<p>其中，$\lambda$ 为超参数，控制SocialNCE损失函数的重要程度。</p>
<h3 id="sampling-strategy-in-multi-agent-context-采样策略">sampling strategy in multi-agent context 采样策略</h3>
<p></p>
<p>在其他智能体附近寻求更多信息的负样本:</p>
<p>$$s^{i,n-}<em>{t+\delta t} = s^{j}</em>{t+\delta t} + \bigtriangleup{s_p} + \epsilon$$</p>
<p>其中， $j\in{1,2,&hellip;,M} \backslash i$ 是其他agent的index, $\bigtriangleup{s_p}$ 是适合社交距离的局部位移。</p>
<p>对于positive sample, 对该agent周围直接采样获得:</p>
<p>$$s^{i,n-}<em>{t+\delta t} = s^{i}</em>{t+\delta t} +  \epsilon$$</p>
]]></description></item><item><title>Social_STGCNN 论文解读</title><link>https://jianye0428.github.io/posts/social_stgcnn/</link><pubDate>Sun, 16 Jul 2023 15:53:17 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/social_stgcnn/</guid><description><![CDATA[<p><code>paper link:</code> <a href="https://arxiv.org/abs/2002.11927?from=leiphonecolumn_paperreview0323"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/abs/2002.11927?from=leiphonecolumn_paperreview0323<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<h2 id="网络结构">网络结构</h2>
<p>特点: Social STGCNN不同于其他方法只是聚合各种学习的行人状态，而是对行人交互做图建模。其中提出一种kernel function把行人社交交互嵌入一个adjacency matrix。</p>
<blockquote>
<p>代码显示，图建模一般在数据前处理完成。</p>
</blockquote>
<h3 id="model-description">Model Description</h3>
<p>两部分：时空图卷积神经网络ST-GCNN、时间外推器TXP-CNN。</p>
<p>ST-GCNN对行人轨迹的图表示进行时空卷积操作以提取特征。这些特征是观察到的行人轨迹历史的紧凑表示。
TXP-CNN将这些特征作为输入，并预测所有行人作为一个整体的未来轨迹。我们使用时间外推器的名字是因为TXP-CNN期望通过卷积运算外推未来的轨迹。</p>
<p></p>
<p>给定T帧，构造表示 $G=(V,A)$ 的时空图. 然后，$G$ 通过时空图卷积神经网络(ST-GCNNs)转发，创建一个时空嵌入。 之后，TXP-CNNs 预测了未来的轨迹。 $P$ 是行人位置的维数，$N$ 是行人的数目，$T$ 是时间步长, $\hat{P}$是来自ST-GCNN的嵌入的维数.</p>
<p>(1) <font color=red>Graph Representation of Pedestrian Trajectories</font></p>
<p>我们首先构造一组空间图 $G_t$，表示每个时间步长 $t$ 在场景中行人的相对位置，$G_t = (V_t, E_t)$ 。 $V_t$是图 $G_t$ 的顶点集，观察到的位置 $(x^i_t，y^i_t)$ 是顶点 $v^i_t$ 的属性; $E_t$ 是边集，如果顶点 $v^i_t$ 和顶点 $v^j_t$ 相连 $e^{ij}_t = 1$ ，否则 $=0$。</p>
<p>为了建模两个节点之间相互影响的强度，我们附加了一个值$a^{ij}_t$, 它是由每个$ e^{ij}_t$ 的某种核函数计算得到。$a^{ij}_t$ 被组织为带权邻接矩阵$A_t$。</p>
<p><strong>$a^{ij}_{sim,t}$是要在邻接矩阵$A_t$中使用的内核函数。</strong> 定义为:</p>
<p>$$\begin{equation}
a^{ij}_{sim,t}=
\left
{
\begin{aligned}
1/||v^i_t - v^j_t||_2 , ||v^i_t - v^j_t||_1\neq0 \
0, Otherwise
\end{aligned}
\right.
\end{equation}$$</p>
<p>(2) <font color=red>Graph Convolution Neural Network</font></p>
<p>对于在二维网格地图或特征地图上定义的卷积运算，定义如下:</p>
<p>$$z^{(l+1)} = \sigma(\sum_{h=1}^{k}\sum_{\omega=1}^{k}(p(z^{(l)},h, \omega) \cdot \boldsymbol{W}^{(l)}(h, \omega))$$</p>
<p>其中，$k$是内核大小，$p(.)$ 是采样函数，其聚集以$z$为中心的邻居的信息， $\sigma$ 是激活函数。${l}$表示神经网络层。</p>
<p>图卷积定义如下:</p>
<p>$$v^{i(l+1)} =\sigma (\frac{1}{\Omega}\sum_{v^{j(l)}\in B(v^{j(l)})}p(v^{i(l)}, v^{j(l)}) \cdot \boldsymbol{W}(v^{i(l)}, v^{j(l)}))$$</p>
<p>其中$\frac{1}{\Omega}$ 是正则化项，$B(v^i) =  { v^j|d(v^i,v^j)≤D }$是顶点的邻居集，而$d(v^i,v^j)$表示连接$v^i$和$v^j$的最短距离， $\Omega$是邻居集的基数。</p>
<p>(3) <font color=red>Spatio-Temporal Graph Convolution Neural Network(ST-GCNNs)</font></p>
<p>通过定义一个新的图G，其属性是$G_t$属性的集合，ST-GCNN将<strong>空间图卷积</strong>扩展到<strong>时空图卷积</strong>。 $G$结合了行人轨迹的时空信息。值得注意的是，$G_1，…，G_T$的拓扑结构是相同的，而当t变化时，不同的属性被分配给$v^i_t$。</p>
<p>因此，我们将$G$定义为$(V,E)$，其中$V={v_i|i\in { 1，…，N }}$ 和 $E={e_{ij}|i，j，{1，…，N}}$。 顶点$v_i$在G中的属性是$v^i_t$的集合，$∀t∈{0，…，T}$。 另外， 加权邻接矩阵A对应于$G$ 是${ A_1，…，A_T}$的集合。 我们将ST-GCNN产生的嵌入表示为 $\overline{V}$.</p>
<p>(4) <font color=red>Time-Extrapolator Convolution Neural Network (TXP-CNN)</font></p>
<p>ST-GCNN的功能是从输入图中<strong>提取时空节点嵌入</strong>。然而，我们的目标是预测行人未来的进一步位置。
TXP-CNN直接作用于图嵌入 $\overline{V}$ 的时间维度，并将其扩展为预测的必要条件。 由于TXP-CNN依赖于特征空间的卷积运算，因此与递归单元相比，它的参数较小。需要注意的一个特性是， TXP-CNN层不是置换不变的，因为在TXP-CNN之前，图嵌入的变化会导致不同的结果。Other than this, if the order of pedestrians is permutated starting from the input to Social-STGCNN then the predictions are invariant.</p>
<h3 id="modelsocial-stgcnn-implementation">model(Social STGCNN) Implementation</h3>
<ol>
<li>Adjacency Matrix Normalization</li>
</ol>
<p>$$ A_t = \Lambda_t^{-\frac{1}{2}}\hat{A}\Lambda_t^{-\frac{1}{2}}$$</p>
<p>where $\hat{A_t} = A_t + I$ and $\Lambda_t$ is the diagonal node degree matric of $\hat{A_t}$. We use $\hat{A}$ and $\Lambda$ to denote the stack of $\hat{A_t}$ and $\Lambda_t$ repectively.</p>
<p>The normalization of adjacency is essential for the graph CNN to work properly.</p>
<ol start="2">
<li>STGCNN Network Mechanism</li>
</ol>
<p>$$f(V^{l}, A) = \sigma(\Lambda_t^{-\frac{1}{2}}\hat{A}\Lambda_t^{-\frac{1}{2}}V^{(l)}W^{(l)})$$</p>
<p>where, $V^{(l)}$ denotes the stack of $V^{(l)}_t$, and $W^{(l)}$ denotes the trainable parameters.</p>
<h2 id="data-processing-数据处理以及图构建">Data Processing 数据处理以及图构建</h2>
<p>obs_traj - <font color=red><em>前8帧观察轨迹(绝对坐标)</em></font>
pred_traj_gt - <font color=red><em>后12帧预测轨迹(ground truth)(绝对坐标)</em></font>
obs_traj_rel - <em><font color=red>前8帧观察轨迹(相对坐标)</em></font>
pred_traj_gt_rel - <em><font color=red>后12帧预测轨迹(ground truth)(相对坐标)</em></font>
non_linear_ped - <em><font color=red>非线性轨迹 (剔除)</em></font>
loss_mask
V_obs - <em><font color=red>graph nodes</em></font>
A_obs - <em><font color=red>graph Adjacency Matrix</em></font>
V_tr - <em><font color=red>预测轨迹 graph nodes</em></font>
A_tr - <em><font color=red>预测轨迹 graph Adjacency Matrix</em></font></p>
]]></description></item><item><title>C++ STL Containers</title><link>https://jianye0428.github.io/posts/datastructrue/</link><pubDate>Sun, 16 Jul 2023 15:03:55 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/datastructrue/</guid><description><![CDATA[<h2 id="c-stl-standard-template-library-总结">C++ STL (Standard Template Library) 总结</h2>
<p>C++ STL 容器是使用频率超高的基础设施，只有了解各个容器的底层原理，才能得心应手地用好不同的容器，做到用最合适的容器干最合适的事情。</p>
<p>本文旨在对 C++ 标准模板库的 <em>array</em>, <em>vector</em>, <em>deque</em>, <em>list</em>, <em>forward_list</em>, <em>queue</em>, <em>priority_queue</em>, <em>stack</em>, <em>map</em>, <em>multimap</em>, <em>set</em>, <em>multi_set</em>, <em>unordered_map</em>, <em>unordered_multimap</em>, <em>unordered_set</em>, <em>unordered_multiset</em> 共十六类容器进行系统的对比分析，重点关注各个容器的底层原理与性能特点。本文唯一参考资料为C++官方文档，若有其它参考则会指明出处。</p>
<h3 id="1-array">1. array</h3>
<blockquote>
<p>Container properties: Sequence | Contiguous storage | Fixed-size aggregate
容器属性：顺序容器（支持随机访问），连续内存空间，固定大小；//连续内存
类模板头：template &lt; class T, size_t N &gt; class array;</p>
</blockquote>
<p>array 即数组，其大小固定，所有的元素严格按照内存地址线性排列，array 并不维护元素之外的任何多余数据，甚至也不会维护一个size这样的变量，这保证了它在存储性能上和C++语法中的数组符号[]无异。尽管其它大部分标准容器都可以通过 std::allocator 来动态的分配和回收内存空间，但 <strong>Array 并不支持这样做</strong>。</p>
<p>Array 和其它标准容器一个很重要的不同是：<u>对两个 array 执行 swap 操作意味着真的会对相应 range 内的元素一一置换</u>，因此其时间花销正比于置换规模；但同时，对两个 array 执行 swap 操作不会改变两个容器各自的迭代器的依附属性，这是由 array 的 swap 操作不交换内存地址决定的。</p>
<p>Array 的另一个特性是：不同于其它容器，<font color = red>array 可以被当作 std::tuple 使用</font>，因为 array 的头文件重载了get()以及tuple_size()和tuple_element()函数（注意这些函数非 array 的成员函数，而是外部函数）。</p>
<p>最后需要注意，虽然 array 和 C++语法中的[]符号无限接近，但两者是两个存在，array 毕竟是标准模板库的一员，是一个class，因此支持
<code>begin(), end(), front(), back(), at(), empty(), data(), fill(), swap(), ... </code> 等等标准接口，而[]是真正的最朴素的数组。</p>
<h3 id="2-vector">2. vector</h3>
<blockquote>
<p>Container properties: Sequence | Dynamic array | Allocator-aware
容器属性：<font color = red>顺序容器</font>（支持随机访问），动态调整大小，使用内存分配器动态管理内存；//连续内存
类模板头：template &lt; class T, class Alloc = allocator<T> &gt; class vector;</p>
</blockquote>
<p>一句话来说，<u>vector 就是能够动态调整大小的 array</u>。和 array 一样，vector 使用<font color=red>连续内存空间</font>来保存元素，这意味着其元素可以用普通指针的<code>++</code>和<code>--</code>操作来访问；不同于 array 的是，其<strong>存储空间可以自动调整</strong>。</p>
<p>在底层上，vector 使用动态分配的 array，当现有空间无法满足增长需求时，会重新分配（reallocate）一个更大的 array 并把所有元素移动过去，因此，<font color=red>vector 的 reallocate 是一个很耗时的处理</font>。所以，每次 reallocate 时都会预留多余的空间，以满足潜在的增长需求，也就是说，vector的capacity()通常会大于size()。vector 什么时候做 reallocate，reallocate 多少多余空间，是有具体策略的，按下不表。总体来说，<u>vector 比 array 多了一些内存消耗，以换取更灵活的内存管理</u>。</p>
<p>和其它的动态顺序容器（deque, list, forward_list）相比，<u>vector 在元素访问上效率最高，在尾部增删元素的效率也相对最高</u>。如果调用者有在尾部以外的地方增删元素的需求，vector 则不如其它容器，并且迭代器的一致性也较差（have less consistent iterators and references than lists and forward_lists）。</p>
<h3 id="3-queue">3. queue</h3>
<blockquote>
<p>容器属性：<font color=red>容器适配器(adapter)</font>，先进先出型容器（FIFO）；//C++设计模式之适配器模式
template &lt;class T, class Container = deque<T> &gt; class queue;</p>
</blockquote>
<p>queue（普通队列）是一个专为 FIFO 设计的容器适配器，也即只能从一端插入、从另一端删除；所谓容器适配器，是指它本身只是一个封装层，必须依赖指定的底层容器（通过模板参数中的class Container指定）才能实现具体功能。</p>
<p>**容器适配器(Adapter)**实际上是C++设计模式的一种 &ndash; 称为 Adapter 模式（适配器模式），Adapter 模式的目的是将第三方库提供的接口做一个封装和转化，使其适配自己工程中预留的接口，或者适应自己工程的调用风格。换句话说，Adapter 模式的目的是将被调用类（如第三方库）的接口转化为希望的接口。</p>
<p>回到正题，queue 可以接纳任何一个至少支持下列接口的容器作为底层容器：</p>
<blockquote>
<p>empty(); size(); front(); back(); push_back(); pop_front().</p>
</blockquote>
<p>在标准模板库容器中，deque 和 list 满足上述要求，当然用户也可以自定义一个满足上述要求的容器。通过模板参数可以看出，<font color=red>默认情况下，queue 使用 deque 作为底层容器</font>。</p>
<h3 id="4-deque">4. deque</h3>
<blockquote>
<p>Container properties: Sequence | Dynamic array | Allocator-aware
容器属性：<font color=red>顺序容器</font>（支持随机访问），动态调整大小，使用内存分配器动态管理内存；//分段连续内存
类模板头：template &lt; class T, class Alloc = allocator<T> &gt; class deque;</p>
</blockquote>
<p>deque（读作&quot;deck&quot;）是 double-ended queue 的缩写，是一个可以在首尾两端进行动态增删的顺序容器。</p>
<p>不同的库对 deque 的实现可能不同，但大体上都是<font color=green>某种形式的动态 array</font>，且都支持随机访问。deque 的功能和 vector 比较接近，但 deque 额外支持在头部动态增删元素。和 vector 不一样的是，<font color = red><u>deque 不保证存储区域一定是连续的!</u></font> 因此用指向元素的普通指针做<code>++</code>和<code>--</code>操作是非常危险的行为。</p>
<p>从底层机理上能更透彻地理解 deque 的特点：<font color = red>vector 使用的是单一的 array，deque 则会使用很多个离散的 array 来组织数据</font>「the elements of a deque can be scattered in different chunks of storage」！如果说 vector 是连续的，deque 则是分段连续。deque 会维护不同 array 之间的关联信息，使用户无需关心分段这个事实。这样做的好处是很明显的：deque 在 reallocate 时，只需新增/释放两端的 storage chunk 即可，无需移动已有数据（vector 的弊端），极大提升了效率，尤其在数据规模很大时，优势明显。</p>
<p>相比于 vector 和 list，deque 并不适合遍历！因为每次访问元素时，deque 底层都要检查是否触达了内存片段的边界，造成了额外的开销！deque 的核心优势是在双端都支持高效的增删操作，程序员选择使用 deque 时需要有双端操作的明确理由。</p>
<h3 id="5-priority_queue">5. priority_queue</h3>
<blockquote>
<p>容器属性：<font color=red>容器适配器</font>，严格弱序（Strict Weak Ordering），优先级队列；
template &lt;class T, class Container = vector<T>,
class Compare = less<typename Container::value_type> &gt; class priority_queue;</p>
</blockquote>
<p>和 queue 类似，priority_queue（术语叫作优先级队列）也只是一个容器适配器，需要指定底层容器才能实例化，参见模板参数中的class Container形参。priority_queue 的核心特点在于其严格弱序特性（strict weak ordering）：也即 priority_queue 保证容器中的第一个元素始终是所有元素中最大的！为此，用户在实例化一个 priority_queue 时，必须为元素类型（class T）重载&lt;运算符，以用于元素排序！</p>
<p>priority_queue 的原理可以用一个大顶堆来解释：priority_queue 在内部维护一个基于二叉树的大顶堆数据结构，在这个数据结构中，最大的元素始终位于堆顶部，且只有堆顶部的元素（max heap element）才能被访问和获取，大顶堆的具体原理可参见任何一本数据结构书籍。</p>
<p>为了支持这种工作原理，priority_queue 对底层容器也是有要求的，priority_queue 的底层容器必须支持随机访问和至少以下接口：</p>
<blockquote>
<p>empty(); size(); front(); push_back(); pop_back().</p>
</blockquote>
<p>标准模板库中的 vector 和 deque 能够满足上述需求，默认情况下，priority_queue 使用 vector 作为底层容器。</p>
<p>某种程度上来说，priority_queue 默认在 vector 上使用堆算法将 vector 中元素构造成大顶堆的结构，因此 priority_queue 就是堆 ，所有需要用到堆的位置，都可以考虑使用 priority_queue。priority_queue 默认是大顶堆，用户也可以通过自定义模板参数中的 class Compare 来实现一个小顶堆。</p>
<p>相比于 queue（普通队列）的先进先出FIFO，priority_queue 实现了最高优先级先出。</p>
<h3 id="6-list">6. list</h3>
<blockquote>
<p>Container properties: Sequence | Doubly-linked list | Allocator-aware
容器属性：<font color = red>顺序容器</font>（可顺序访问，但不支持随机访问），双链表，使用内存分配器动态管理内存；//离散内存
类模板头：template &lt; class T, class Alloc = allocator<T> &gt; class list;</p>
</blockquote>
<p>list 是一种支持在<strong>任意位置都可以快速地插入和删除</strong>元素的容器，且支持<strong>双向遍历</strong>。list 容器能够做到这些的原因在于<strong>其底层结构是双链表</strong>，双链表允许把各个元素都保存在彼此不相干的内存地址上，但每个元素都会与前后相邻元素关联。</p>
<p>和其它的顺序容器（array, vector, deque）相比，<u>list 的最大优势在于支持在任意位置插入、删除和移动元素</u>，对 list 来说，在哪个位置进行操作并没有区别。list 在部分算法（如 sorting）中的效率可能优于其它顺序容器。</p>
<p>list 的<strong>主要缺点</strong>是<u>不支持元素的随机访问</u>！如果我们想要访问某个元素，则必须从一个已知元素（如 begin 或 end）开始朝一个方向遍历，直至到达要访问的元素。此外，list 还要消耗更多的内存空间，用于保存各个元素的关联信息。</p>
<p>[另说] <strong>list 对内存空间的使用效率并不高，一方面元素内存地址是离散的而非连续，另一方面，list 需要保存额外的关联信息。</strong></p>
<h3 id="7-forward_list">7. forward_list</h3>
<blockquote>
<p>Container properties: Sequence | Linked list | Allocator-aware
容器属性：<font color = red>顺序容器</font>（可顺序访问，但不支持随机访问），单链表，使用内存分配器动态管理内存；
类模板头：template &lt; class T, class Alloc = allocator<T> &gt; class list;</p>
</blockquote>
<p>forward_list 也是一种支持在任意位置快速插入和删除元素的容器，forward_list 相比于 list 的核心区别是它是一个单链表，因此, 每个元素只会与相邻的下一个元素关联！由于关联信息少了一半，因此 forward_list 占用的内存空间更小，且插入和删除的效率稍稍高于 list。作为代价，forward_list 只能单向遍历。</p>
<p>相比于其它顺序容器（array, vector, deque），forward_list 的优缺点和 list 基本相同。</p>
<p>既然已经有了 list，为什么 C++ STL 又设计了 forward_list 这一容器呢？设计 forward_list 的目的是为了达到不输于任何一个C风格<strong>手写链表的极值效率</strong>！为此，forward_list 是一个最小链表设计，它甚至没有size()接口，因为内部维护一个size变量会降低增删元素的效率。如果想要获取 forward_list 的 size，一个通常的做法是，用 std::distance 计算 begin 到 end 的距离得出 size。一句话总结：list 兼顾了接口丰富性牺牲了效率，而 forward_list 舍弃了不必要的接口只为追求极致效率。</p>
<h3 id="8-stack">8. stack</h3>
<blockquote>
<p>容器属性：<font color = red>容器适配器</font>，后进先出型容器（LIFO）；
template &lt;class T, class Container = deque<T> &gt; class stack;</p>
</blockquote>
<p>stack（栈）是一个专为 LIFO 设计的容器适配器，也即只能从一端插入和删除；作为适配器，需要指定底层容器才能实例化，参见模板参数中的<code>class Container</code>形参。</p>
<p>stack 的特点是后进先出（一端进出），不允许遍历；任何时候外界只能访问 stack 顶部的元素；只有在移除 stack 顶部的元素后，才能访问下方的元素。stack 需要底层容器能够在一端增删元素，这一端也即 stack 的“栈顶”；stack 可以接纳任何一个至少支持下列接口的容器作为底层容器：</p>
<blockquote>
<p>empty(); size(); back(); push_back(); pop_back()</p>
</blockquote>
<p>在标准模板库容器中，vector、deque 和 list 满足上述要求，当然用户也可以自定义一个满足上述要求的容器。通过模板参数可以看出，默认情况下，<strong>stack 使用 deque 作为底层容器</strong>。</p>
<p>stack 容器应用广泛，例如，编辑器中的 undo （撤销操作）机制就是用栈来记录连续的操作。stack 的设计场景和自助餐馆中堆叠的盘子、摞起来的一堆书类似。</p>
<h3 id="9-map">9. map</h3>
<blockquote>
<p>Container properties: Associative | Ordered | Map | Unique keys | Allocator-aware
容器属性：<font color = red>关联容器</font>，有序，元素类型&lt;key, value&gt;，key是唯一的，使用内存分配器动态管理内存 ；
template &lt; class Key, // map::key_type
class T, // map::mapped_type
class Compare = less<Key>, // map::key_compare
class Alloc = allocator&lt;pair&lt;const Key,T&gt; &gt; // map::allocator_type
class map;</p>
</blockquote>
<p>map 是一个关联型容器，其元素类型是由 key 和 value 组成的 std::pair，实际上 map 中元素的数据类型正是 <code>typedef pair&lt;const Key, T&gt; value_type</code>;，这就看的很清楚了。</p>
<p>所谓关联容器，是指<strong>对所有元素的检索都是通过元素的 key 进行的（而非元素的内存地址）</strong>，map 通过底层的「红黑树」数据结构来将所有的元素按照 key 的相对大小进行排序，所实现的排序效果也是严格弱序特性（strict weak ordering），为此，开发者需要重载 key 的&lt;运算符或者模板参数中的 class Compare。所提到的红黑树是一种自平衡二叉搜索树，它衍生自B树，这里推荐两篇文章（<a href="https://zhuanlan.zhihu.com/p/72505589"target="_blank" rel="external nofollow noopener noreferrer">记一次腾讯面试：有了二叉查找树、平衡树（AVL）为啥还需要红黑树？<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>，<a href="https://zhuanlan.zhihu.com/p/273829162"target="_blank" rel="external nofollow noopener noreferrer">图解：什么是红黑树？<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>）作为更深入的参考。</p>
<p>大体来说，map 访问元素的速度要稍慢于下文的 unordered_map，这是因为虽然都叫“map”，但两者的底层机制完全不一样。但是，相比于后者，map 支持在一个子集合上进行直接迭代器访问，原因在于 map 中的元素是被有序组织的。</p>
<p>最后，map 也支持通过operator[]的方式来直接访问 value。</p>
<h3 id="10-multimap">10. multimap</h3>
<blockquote>
<p>Container properties: Associative | Ordered | Map | Multiple equivalent keys | Allocator-aware
容器属性: 关联容器，有序，元素类型&lt;key, value&gt;，允许不同元素key相同，使用内存分配器管理内存；
template &lt; class Key, // map::key_type
class T, // map::mapped_type
class Compare = less<Key>, // map::key_compare
class Alloc = allocator&lt;pair&lt;const Key,T&gt; &gt; // map::allocator_type
class map;</p>
</blockquote>
<p><strong>map 中不允许出现 key 相同的两个元素，但 multimap 则可以这样做！</strong></p>
<p>multimap 与 map 底层原理完全一样，都是使用「红黑树」对元素数据按 key 的比较关系，进行快速的插入、删除和检索操作；所不同的是 multimap 允许将具有相同 key 的不同元素插入容器（这个不同体现了 multimap 对红黑树的使用方式的差异）。在 multimap 容器中，元素的 key 与元素 value 的映射关系，是一对多的，因此，multimap 是多重映射容器。</p>
<p>注意，在向 multimap 中新增元素时，multimap 只会判断 key 是否相同，而完全不会判断 value 是否相同！<font color=red>这意味着如果相同的 &lt;key, value&gt; 插入了多次，multimap 会对它们悉数保存！</font></p>
<p>在使用中，我们可以通过迭代器配合 lower_bound() 和 upper_bound() 来访问一个 key 对应的所有 value，也可以使用equal_range()来访问一个 key 对应的所有 value，也可以通过find()配合count()来访问一个 key 对应的所有 value，个人认为前两种方法使用起来更方便一点。</p>
<p>下文中将要提到的 multiset 之于 set 类似于这里的 multimap 之于 map。</p>
<h3 id="11-set">11. set</h3>
<blockquote>
<p>Container properties: Associative | Ordered | Set | Unique keys | Allocator-aware
容器属性：<font color=red>关联容器</font>，有序，元素自身即key，元素有唯一性，使用内存分配器动态管理内存；
template &lt; class T, // set::key_type/value_type
class Compare = less<T>, // set::key_compare/value_compare
class Alloc = allocator<T> // set::allocator_type
class set;</p>
</blockquote>
<p>set 是一个关联型容器，和 map 一样，它的底层结构是「红黑树」，但和 map 不一样的是，<strong>set 是直接保存 value 的</strong>，或者说，set 中的 value 就是 key。</p>
<p><strong>set 中的元素必须是唯一的，不允许出现重复的元素</strong>，且元素不可更改，但可以自由插入或者删除。</p>
<p>由于底层是红黑树，所以 set 中的元素也是严格弱序（strict weak ordering）排序的，因此<u>支持用迭代器做范围访问</u>（迭代器自加自减）。</p>
<p>实际使用中，set 和 map 是近亲，性能相似，他们的差别是元素的 value 本身是否也作为 key 来标识自己。</p>
<h3 id="12-multi_set">12. multi_set</h3>
<blockquote>
<p>Container properties: Associative | Ordered | Set | Multiple equivalent keys | Allocator-aware
容器属性：<font color=red>关联容器</font>，有序，元素自身即key，允许不同元素值相同，使用内存分配器动态管理内存 ；
template &lt; class T, // multiset::key_type/value_type
class Compare = less<T>, // multiset::key_compare/value_compare
class Alloc = allocator<T> &gt; // multiset::allocator_type
class multiset;</p>
</blockquote>
<p>multiset 之于 set 就如同 multimap 之于 map：</p>
<p>multiset 和 set 底层都是红黑树，multiset 相比于 set 支持保存多个相同的元素；</p>
<p>multimap 和 map 底层都是红黑树，multimap 相比于 map 支持保存多个key相同的元素。</p>
<p>鉴于以上近亲关系，multiset 的性能特点与其它三者相似，不再赘述。</p>
<h3 id="13-unordered_map">13. unordered_map</h3>
<blockquote>
<p>Container properties: Associative | Unordered | Map | Unique keys | Allocator-aware
容器属性：<font color = red>关联容器</font>，无序，元素类型&lt;key, value&gt;，key是唯一的，使用内存分配器动态管理内存 ； template &lt; class Key, // unordered_map::key_type
class T, // unordered_map::mapped_type
class Hash = hash<Key>, // unordered_map::hasher
class Pred = equal_to<Key>, // unordered_map::key_equal
class Alloc = allocator&lt; pair&lt;const Key,T&gt; &gt; // unordered_map::allocator_type
class unordered_map;</p>
</blockquote>
<p>unordered_map 和 map 一样，都是关联容器，以键值对儿 &lt;key, value&gt; 作为元素进行存储；但是，除此之外，两者可以说是完全不一样！</p>
<p>这是由底层的数据结构决定的，map 以红黑树作为底层结构组织数据，而 <strong>unordered_map 以哈希表(hash table)作为底层数据结构</strong>来组织数据，这造成了两点重要影响：
1. unordered_map 不支持排序，<font color=red>在使用迭代器做范围访问时（迭代器自加自减）效率更低</font>；
2. 但 unordered_map 直接访问元素的速度更快（尤其在规模很大时），因为它通过直接计算 key 的哈希值来访问元素，是O(1)复杂度！</p>
<p>网络上有对 map VS unordered_map 效率对比的测试，通常 <strong>map 增删元素的效率更高，unordered_map 访问元素的效率更高</strong>，可以参见<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/uniqsa/article/details/62442383"target="_blank" rel="external nofollow noopener noreferrer">这篇文章<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>。另外，unordered_map 内存占用更高，因为底层的哈希表需要预分配足量的空间。</p>
<p>综上，unordered_map 更适用于增删操作不多，但需要频繁访问，且内存资源充足的场合。</p>
<blockquote>
<p>比如在机器人领域的SLAM技术中，可以选择 unordered_map 来维护体素形式的 local map？ 当然 deque 应该也是不错的选择。</p>
</blockquote>
<h3 id="14-unordered_multimap">14. unordered_multimap</h3>
<blockquote>
<p>Container properties: Associative | Unordered | Map | Multiple equivalent keys | Allocator-aware
容器属性：关联容器，无序，元素类型&lt;key, value&gt;，允许不同元素key相同，使用内存分配器管理内存 ；
template &lt; class Key, // unordered_multimap::key_type
class T, // unordered_multimap::mapped_type
class Hash = hash<Key>, // unordered_multimap::hasher
class Pred = equal_to<Key>, // unordered_multimap::key_equal
class Alloc = allocator&lt; pair&lt;const Key,T&gt; &gt; // unordered_multimap::allocator_type
class unordered_multimap;</p>
</blockquote>
<p>unordered_multimap 是对 unordered_map 的拓展，唯一区别在于 unordered_multimap 允许不同元素的 key 相同，但两者无论是在底层结构还是在容器特性上都是相通的，仅仅是对底层哈希表的使用方式稍有不同。</p>
<p>在 unordered_multimap 中想要访问同一个 key 下对应的所有元素的话，可以使用equal_range()轻松做到；当然，也可以使用find()和count()配合的方式来访问。</p>
<p>unordered_multimap 的容器特性参见 unordered_map，不再赘述。</p>
<h3 id="15-unordered_set">15. unordered_set</h3>
<blockquote>
<p>Container properties: Associative | Unordered | Set | Unique keys | Allocator-aware
容器属性：<font color=red>关联容器</font>，无序，元素自身即key，元素有唯一性，使用内存分配器动态管理内存 ；
template &lt; class Key, // unordered_set::key_type/value_type
class Hash = hash<Key>, // unordered_set::hasher
class Pred = equal_to<Key>, // unordered_set::key_equal
class Alloc = allocator<Key> // unordered_set::allocator_type
class unordered_set;</p>
</blockquote>
<p>所有unordered_XXX类容器的特点都是以哈希表作为底层结构；所有 XXX_set 类容器的特点都是「元素自身也作为key」来标识自己。我们在把两类特性叠加到一起，就得到了 unordered_set。</p>
<p>在 unordered_set 中，元素自身同时也作为 key 使用；既然是作为 key 使用，那么元素就不能被更改，也即 unordered_set 中的元素都是 constant 的，但我们可以自由的插入和删除元素，这也是所有XXX_set类容器的性质。既然底层结构是哈希表，意味着 unordered_set 中的元素是无序的，不能按照大小排序，这也是所有unordered_XXX类容器的性质。</p>
<p>和所有的unordered_XXX类容器一样：
1. unordered_set 直接用迭代器做范围访问时（迭代器自加自减）效率更低，低于 set；
2. 但 unordered_set 直接访问元素的速度更快（尤其在规模很大时），因为它通过直接计算 key 的哈希值来访问元素，是O(1)复杂度！</p>
<h3 id="16-unordered_multiset">16. unordered_multiset</h3>
<blockquote>
<p>Container properties: Associative | Unordered | Set | Multiple equivalent keys | Allocator-aware
容器属性：<font color=red>关联容器</font>，无序，元素自身即key，允许不同元素值相同，使用内存分配器动态管理内存 ；
template &lt; class Key, // unordered_multiset::key_type/value_type
class Hash = hash<Key>, // unordered_multiset::hasher
class Pred = equal_to<Key>, // unordered_multiset::key_equal
class Alloc = allocator<Key> // unordered_multiset::allocator_type
class unordered_multiset;</p>
</blockquote>
<p>unordered_multiset，顾名思义，就是集齐了“哈希表为底层结构”，“元素自身即key”，“允许不同元素值相同”这三个特性的容器，是对 unordered_set 的简单拓展。</p>
<p>unordered_multiset 的效率特性与所有基于哈希表的容器相似，参见 unordered_set，不再赘述。</p>
<h3 id="17-pair--tuple">17. pair &amp;&amp; tuple</h3>
<blockquote>
<p>template &lt;class&hellip; Types&gt; class tuple;
template &lt;class T1, class T2&gt; struct pair;</p>
</blockquote>
<p><code>std::pair</code> 和 <code>std::tuple</code> 并不是stl容器库中的容器，不过鉴于经常用到，就顺便整理一下。先从 tuple 说起，pair 相当于 tuple 的特例。</p>
<p>tuple 叫作元组，它可以把一组类型相同或不同的元素组合到一起，且元素的数量不限。tuple 的底层原理与 stl 中的容器完全不同，但在功能上，tuple 是对容器的有效补充，因为所有的容器都只能组合相同类型的元素，但tuple 可以组合任意不同类型的元素。在使用上，可以用std::make_tuple()来构造 tuple 对象，可以用std::get<index>()来获取 tuple 对象的某个元素，注意std::get<index>()返回的是 tuple 对象中某个元素的索引，因此是可以用作左值的！此外，也可以用std::tie()打包一组变量来作为左值接受 tuple 对象的赋值。</p>
<p>tuple 的底层原理大概是一个层层继承的类，详情可以参考<a href="https://zhuanlan.zhihu.com/p/356954012"target="_blank" rel="external nofollow noopener noreferrer">这篇文章<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>，写的非常透彻。</p>
<p>pair 可以看作是把 tuple 的 size 限制为 2 的一个特例，pair 只能把一对儿元素组合到一起。在使用上，可以用std::make_pair()来直接构建 pair 对象，可以用std::get&lt;0&gt;()和std::get&lt;1&gt;()来分别获取 pair 对象的两个元素，但更方便的做法是直接访问 pair 类型的两个数据成员pair对象.first和pair对象.second来访问元素</p>
<p>reference:
[1]. <a href="https://zhuanlan.zhihu.com/p/542115773"target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/542115773<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
]]></description></item></channel></rss>