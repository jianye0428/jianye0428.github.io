<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Draft - 标签 - yejian's blog</title><link>https://jianye0428.github.io/tags/draft/</link><description>Draft - 标签 - yejian's blog</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>18817571704@163.com (Jian YE)</managingEditor><webMaster>18817571704@163.com (Jian YE)</webMaster><lastBuildDate>Thu, 22 Feb 2024 17:25:21 +0800</lastBuildDate><atom:link href="https://jianye0428.github.io/tags/draft/" rel="self" type="application/rss+xml"/><item><title>RL学习笔记 [5] | 用时序差分法（TD）求解</title><link>https://jianye0428.github.io/posts/rl_learning_note_5/</link><pubDate>Thu, 22 Feb 2024 17:25:21 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/rl_learning_note_5/</guid><description><![CDATA[<h1 id="0-引言">0 引言</h1>
<p>在<a href="https://www.cnblogs.com/pinard/p/9492980.html"target="_blank" rel="external nofollow noopener noreferrer">强化学习（四）用蒙特卡罗法（MC）求解<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>中，我们讲到了使用蒙特卡罗法来求解强化学习问题的方法，虽然蒙特卡罗法很灵活，不需要环境的状态转化概率模型，但是它需要所有的采样序列都是经历完整的状态序列。如果我们没有完整的状态序列，那么就无法使用蒙特卡罗法求解了。本文我们就来讨论可以不使用完整状态序列求解强化学习问题的方法：时序差分(Temporal-Difference, TD)。</p>
<p>时序差分这一篇对应Sutton书的第六章部分和UCL强化学习课程的第四讲部分，第五讲部分。</p>
<h1 id="1-时序差分td简介">1. 时序差分TD简介</h1>
<p>时序差分法和蒙特卡罗法类似，都是<strong>不基于模型的强化学习问题</strong>求解方法。所以在上一篇定义的不基于模型的强化学习控制问题和预测问题的定义，在这里仍然适用。</p>
<p>预测问题：即给定强化学习的5个要素：状态集 $S$, 动作集 $A$, 即时奖励 $R$，衰减因子 $γ$, 给定策略 $π$， 求解该策略的状态价值函数 $v(π)$</p>
<p>控制问题：也就是求解最优的价值函数和策略。给定强化学习的5个要素：状态集 $S$, 动作集 $A$, 即时奖励 $R$，衰减因子 $γ$, 探索率 $ϵ$, 求解最优的动作价值函数 $q∗$ 和最优策略 $π∗$　</p>
<p>回顾蒙特卡罗法中计算状态收获的方法是：</p>
<p>$$G_t=R_{t+1}+\gamma R_{t+2}+\gamma^2R_{t+3}+\ldots\gamma^{T-t-1}R_T$$</p>
<p>而对于时序差分法来说，我们没有完整的状态序列，只有部分的状态序列，那么如何可以近似求出某个状态的收获呢？回顾<a href="https://www.cnblogs.com/pinard/p/9426283.html"target="_blank" rel="external nofollow noopener noreferrer">强化学习（二）马尔科夫决策过程(MDP)<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>中的贝尔曼方程：</p>
<p>$$v_\pi(s)=\mathbb{E}_\pi(R_{t+1}+\gamma v_\pi(S_{t+1})|S_t=s)$$</p>
<p>这启发我们可以用 $R_{t+1}+\gamma v(S_{t+1})$ 来近似的代替收获 $G_t$,一般我们把 $R_{t+1}+\gamma V(S_{t+1})$ 称为TD目标值。$R_{t+1}+\gamma V(S_{t+1})-V(S_t)$ 称为TD误差，将用TD目标值近似代替收获 $G(t)$ 的过程称为引导(bootstrapping)。这样我们只需要两个连续的状态与对应的奖励，就可以尝试求解强化学习问题了。</p>
<p>现在我们有了自己的近似收获 $G_t$ 的表达式，那么就可以去求解时序差分的预测问题和控制问题了。</p>
<h1 id="2-时序差分td的预测问题求解">2. 时序差分TD的预测问题求解</h1>
<p>时序差分的预测问题求解和蒙特卡罗法类似，但是主要有两个不同点。一是收获 $G_t$ 的表达式不同，时序差分 $G(t)$ 的表达式为：</p>
<p>$$G(t)=R_{t+1}+\gamma V(S_{t+1})$$</p>
<p>二是迭代的式子系数稍有不同，回顾蒙特卡罗法的迭代式子是：</p>
<p>$$V(S_t)=V(S_t)+\frac1{N(S_t)}(G_t-V(S_t))$$</p>
<p>由于在时序差分我们没有完整的序列，也就没有对应的次数 $N(S_t)$ ,一般就用一个[0,1]的系数 $α$ 代替。这样时序差分的价值函数迭代式子是：</p>
<p>$$V(S_t)=V(S_t)+\alpha(G_t-V(S_t)) \\\\
Q(S_t,A_t)=Q(S_t,A_t)+\alpha(G_t-Q(S_t,A_t)) $$</p>
<p>这里我们用一个简单的例子来看看蒙特卡罗法和时序差分法求解预测问题的不同。</p>
<p>假设我们的强化学习问题有A,B两个状态，模型未知，不涉及策略和行为。只涉及状态转化和即时奖励。一共有8个完整的状态序列如下：</p>
<p>　　① A,0,B,0 ②B,1 ③B,1 ④ B,1 ⑤ B,1 ⑥B,1 ⑦B,1 ⑧B,0</p>
<p>只有第一个状态序列是有状态转移的，其余7个只有一个状态。设置衰减因子 $γ=1$。</p>
<p>首先我们按蒙特卡罗法来求解预测问题。由于只有第一个序列中包含状态A，因此A的价值仅能通过第一个序列来计算，也就等同于计算该序列中状态A的收获：</p>
<p>$$V(A)=G(A)=R_A+\gamma R_B=0$$</p>
<p>对于B，则需要对其在8个序列中的收获值来平均，其结果是6/8。</p>
<p><strong>再来看看时序差分法求解的过程</strong>。其收获是在计算状态序列中某状态价值时是应用其后续状态的预估价值来计算的，对于B来说，它总是终止状态，没有后续状态，因此它的价值直接用其在8个序列中的收获值来平均，其结果是6/8。</p>
<p>对于A，只在第一个序列出现，它的价值为：</p>
<p>$$V(A)=R_A+\gamma V(B)=\frac68$$</p>
<p>从上面的例子我们也可以看到蒙特卡罗法和时序差分法求解预测问题的区别。</p>
<p>一是时序差分法在知道结果之前就可以学习，也可以在没有结果时学习，还可以在持续进行的环境中学习，而蒙特卡罗法则要等到最后结果才能学习，时序差分法可以更快速灵活的更新状态的价值估计，这在某些情况下有着非常重要的实际意义。</p>
<p>二是时序差分法在更新状态价值时使用的是TD 目标值，即基于即时奖励和下一状态的预估价值来替代当前状态在状态序列结束时可能得到的收获，是当前状态价值的有偏估计，而蒙特卡罗法则使用实际的收获来更新状态价值，是某一策略下状态价值的无偏估计，这一点蒙特卡罗法占优。</p>
<p>三是虽然时序差分法得到的价值是有偏估计，但是其方差却比蒙特卡罗法得到的方差要低，且对初始值敏感，通常比蒙特卡罗法更加高效。</p>
<p>从上面的描述可以看出时序差分法的优势比较大，因此现在主流的强化学习求解方法都是基于时序差分的。后面的文章也会主要基于时序差分法来扩展讨论。</p>
<h1 id="3-n步时序差分">3. n步时序差分</h1>
<p>在第二节的时序差分法中，我们使用了用 $R_{t+1}+\gamma v(S_{t+1})$ 来近似的代替收获 $G_t$。即向前一步来近似我们的收获 $G_{t}$,那么能不能向前两步呢？当然可以，这时我们的收获 $G_t$ 的近似表达式为：</p>
<p>$$G_t^{(2)}=R_{t+1}+\gamma R_{t+2}+\gamma^2V(S_{t+2})$$</p>
<p>从两步，到三步，再到n步，我们可以归纳出n步时序差分收获 $G^{(n)}_t$表达式为：$$G_t^{(n)}=R_{t+1}+\gamma R_{t+2}+\ldots+\gamma^{n-1}R_{t+n}+\gamma^nV(S_{t+n})$$</p>
<p>当n越来越大，趋于无穷，或者说趋于使用完整的状态序列时，n步时序差分就等价于蒙特卡罗法了。</p>
<p>对于n步时序差分来说，和普通的时序差分的区别就在于收获的计算方式的差异。那么既然有这个n步的说法，那么n到底是多少步好呢？如何衡量n的好坏呢？我们在下一节讨论。</p>
<h1 id="4-tdλ">4. TD(λ)</h1>
<p>n步时序差分选择多少步数作为一个较优的计算参数是需要尝试的超参数调优问题。为了能在不增加计算复杂度的情况下综合考虑所有步数的预测，我们引入了一个新[0,1]的参数 $\lambda$,定义入—收获是 $n$ 从 $1$ 到 $\infty$ 所有步的收获乘以权重的和。每一步的权重是 $(1-\lambda)\lambda^{n-1}$,这样 $\lambda-$收获的计算公式表示为:</p>
<p>$$G_t^\lambda=(1-\lambda)\sum_{n=1}^\infty\lambda^{n-1}G_t^{(n)}$$</p>
<p>进而我们可以得到 $TD(λ)$ 的价值函数的迭代公式：</p>
<p>$$V(S_t)=V(S_t)+\alpha(G_t^\lambda-V(S_t)) \\\\
Q(S_t,A_t)=Q(S_t,A_t)+\alpha(G_t^\lambda-Q(S_t,A_t)) $$</p>
<p>每一步收获的权重定义为 $(1−λ)λ^{n−1}$ 的原因是什么呢？其图像如下图所示，可以看到随着n的增大，其第n步收获的权重呈几何级数的衰减。当在T时刻到达终止状态时，未分配的权重全部给予终止状态的实际收获值。这样可以使一个完整的状态序列中所有的n步收获的权重加起来为1，离当前状态越远的收获其权重越小。</p>
<br>
<center>
  
  <br>
  <div style="color:orange; border-bottom: 1px solid #d9d9d9; display: inline-block; color: #999; padding: 2px;">TD(λ)</div>
</center>
<br>
<p>从前向来看 $TD(λ)$， 一个状态的价值 $V(St)$由 $G_t$得到，而Gt��又间接由所有后续状态价值计算得到，因此可以认为更新一个状态的价值需要知道所有后续状态的价值。也就是说，必须要经历完整的状态序列获得包括终止状态的每一个状态的即时奖励才能更新当前状态的价值。这和蒙特卡罗法的要求一样，因此TD(λ)��(�)有着和蒙特卡罗法一样的劣势。当 $λ=0$ 时,就是第二节讲到的普通的时序差分法，当 $λ=1$ 时,就是蒙特卡罗法。</p>
<p>从反向来看 $TD(λ)$，它可以分析我们状态对后续状态的影响。比如老鼠在依次连续接受了3 次响铃和1 次亮灯信号后遭到了电击，那么在分析遭电击的原因时，到底是响铃的因素较重要还是亮灯的因素更重要呢？如果把老鼠遭到电击的原因认为是之前接受了较多次数的响铃，则称这种归因为频率启发(frequency heuristic) 式；而把电击归因于最近少数几次状态的影响，则称为就近启发(recency heuristic) 式。</p>
<p>如果给每一个状态引入一个数值：效用(eligibility, E) 来表示该状态对后续状态的影响，就可以同时利用到上述两个启发。而所有状态的效用值总称为效用迹(eligibility traces,ES)。定义为：</p>
<p>$$ E_0(s)=0 \\\\ \left.E_t(s)=\gamma\lambda E_{t-1}(s)+1(S_t=s)=\left\\{\begin{array}{ll}0&amp;t&lt;k\\\\(\gamma\lambda)^{t-k}&amp;t\geq k\end{array}\right.\right.,\quad s.t.\quad\lambda,\gamma\in[0,1],s\textit{ is visited once at time k}$$</p>
<p>此时我们$TD(λ)$的价值函数更新式子可以表示为：</p>
<p>$$\delta_t=R_{t+1}+\gamma v(S_{t+1})-V(S_t)\\\\V(S_t)=V(S_t)+\alpha\delta_tE_t(s)$$</p>
<p>也许有人会问，这前向的式子和反向的式子看起来不同啊，是不是不同的逻辑呢？其实两者是等价的。现在我们从前向推导一下反向的更新式子。</p>
<p>$$\begin{aligned}
G_t^\lambda-V(S_t)&amp; =-V(S_t)+(1-\lambda)\lambda^0(R_{t+1}+\gamma V(S_{t+1})) &amp;&amp; \text{(1)}  \\\\
&amp;+(1-\lambda)\lambda^1(R_{t+1}+\gamma R_{t+2}+\gamma^2V(S_{t+2}))&amp;&amp; (2)  \\\\
&amp;+(1-\lambda)\lambda^2(R_{t+1}+\gamma R_{t+2}+\gamma^2R_{t+3}+\gamma^3V(S_{t+3}))&amp;&amp; (3)  \\\\
&amp;+\ldots &amp;&amp; \text{(4)}  \\\\
&amp;=-V(S_t)+(\gamma\lambda)^0(R_{t+1}+\gamma V(S_{t+1})-\gamma\lambda V(S_{t+1}))&amp;&amp; (5)  \\\\
&amp;+(\gamma\lambda)^1(R_{t+2}+\gamma V(S_{t+2})-\gamma\lambda V(S_{t+2}))&amp;&amp; \text{(6)}  \\\\
&amp;+(\gamma\lambda)^2(R_{t+3}+\gamma V(S_{t+3})-\gamma\lambda V(S_{t+3}))&amp;&amp; \text{(7)}  \\\\
&amp;\begin{array}{c}+\ldots\end{array}&amp;&amp; \text{(8)}  \\\\
&amp;=(\gamma\lambda)^0(R_{t+1}+\gamma V(S_{t+1})-V(S_t))&amp;&amp; \left(9\right)  \\\\
&amp;+(\gamma\lambda)^1(R_{t+2}+\gamma V(S_{t+2})-V(S_{t+1}))&amp;&amp; \text{(10)}  \\\\
&amp;+(\gamma\lambda)^2(R_{t+3}+\gamma V(S_{t+3})-V(S_{t+2}))&amp;&amp; (11)  \\\\
&amp;\begin{array}{c}+\ldots\end{array}&amp;&amp; (12)  \\\\
&amp;=\delta_t+\gamma\lambda\delta_{t+1}+(\gamma\lambda)^2\delta_{t+2}+\ldots &amp;&amp; (13)
\end{aligned}$$</p>
<p>可以看出前向TD误差和反向的TD误差实际上一致的。</p>
<h1 id="5-时序差分的控制问题求解">5. 时序差分的控制问题求解</h1>
<p>现在我们回到普通的时序差分，来看看它控制问题的求解方法。回想上一篇蒙特卡罗法在线控制的方法，我们使用的是$ϵ−$贪婪法来做价值迭代。对于时序差分，我们也可以用$ϵ−$贪婪法来价值迭代，和蒙特卡罗法在线控制的区别主要只是在于收获的计算方式不同。时序差分的在线控制(on-policy)算法最常见的是SARSA算法，我们在下一篇单独讲解。</p>
<p>而除了在线控制，我们还可以做离线控制(off-policy)，离线控制和在线控制的区别主要在于在线控制一般只有一个策略(最常见的是$ϵ−$贪婪法)。而离线控制一般有两个策略，其中一个策略(最常见的是$ϵ−$贪婪法)用于选择新的动作，另一个策略(最常见的是贪婪法)用于更新价值函数。时序差分的离线控制算法最常见的是Q-Learning算法，我们在下下篇单独讲解。</p>
<h1 id="6-时序差分小结">6. 时序差分小结</h1>
<p>时序差分和蒙特卡罗法比它更加灵活，学习能力更强，因此是目前主流的强化学习求解问题的方法，现在绝大部分强化学习乃至深度强化学习的求解都是以时序差分的思想为基础的。因此后面我们会重点讨论。</p>
<p>下一篇我们会讨论时序差分的在线控制算法SARSA。</p>
]]></description></item><item><title>Deformable DETR论文精读+代码详解</title><link>https://jianye0428.github.io/posts/deformabledetr/</link><pubDate>Fri, 27 Oct 2023 15:22:03 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/deformabledetr/</guid><description><![CDATA[<h2 id="abstract">Abstract</h2>
<p>DETR消除了目标检任务中的手工设计痕迹，但是存在<font color=red>收敛慢</font>以及<font color=red>Transformer的自注意力造成的特征图分辨率不能太高</font>的问题，这就导致了小目标检测性能很差。我们的Deformable DETR只在<mark>参考点附近采样少量的key来计算注意力</mark>，因此我们的方法收敛快并且可以用到多尺度特征。</p>
<p>相对于Transformer那种全局(global)&amp;密集(dense)的注意力机制，这里提出了一种新玩法: <strong>每个参考点仅关注邻域的一组采样点，这些采样点的位置并非固定，而是可学习的</strong>(和可变形卷积一样)，从而实现了一种局部(local)&amp;稀疏(sparse)的高效注意力机制。</p>
<h2 id="1introduction">1、Introduction</h2>
<p>传统目标检测任务有很多<strong>手工设计痕迹</strong>，所以不是端到端的网络。DETR运用到了Transformer强大的功能以及全局关系建模能力来取代目标检测中人工设计痕迹来达到端到端的目的。</p>
<p>DETR 的优势:
(i). 第一个端到端的目标检测器；
(ii). 不需要众多手工设计组件(如anchor、固定规则的标签分配策略、NMS后处理等)
(iii). DETR实质上相当于是给出了一个方法论，犹如“普度众生”，告诉大家Transformer可以拿到目标检测中来玩，并没有过多地追求其它方面的成就。</p>
<p>DETR的两大缺点:</p>
<ol>
<li><strong>收敛速度慢(slow convergence)</strong>: 因为全局像素之间计算注意力要收敛到几个稀疏的像素点需要消耗很长的时间。</li>
<li><strong>小目标检测差</strong>: 目标检测基本都是在大分辨率的特征图上进行小目标的检测，但是Transformer中的Self Attention的计算复杂度是平方级别的，所以只能利用到最后一层特征图。
<ul>
<li><strong>Transformer在初始化时，分配给所有特征像素的注意力权重几乎是均等的</strong>，这就造成了模型需要长时间去学习关注真正有意义的位置，这些位置应该是稀疏的；</li>
<li><strong>Transformer在计算注意力权重时，伴随着高计算量与空间复杂度</strong>。特别是在编码器部分，与特征像素点的数量成平方级关系，因此难以处理高分辨率的特征(这点也是DETR检测小目标效果差的原因)</li>
</ul>
</li>
</ol>
<p><code>可变形卷积DCN</code>是一种注意稀疏空间位置很好的机制，但是其<mark>缺乏元素之间关系的建模能力</mark>。</p>
<p>综上所述，<font color=red><code>Deformable Attention</code>模块结合了DCN稀疏采样能力和Transformer的全局关系建模能力。这个模块可以聚合多尺度特征，不需要FPN了，我们用这个模块替换了<code>Transformer Encoder</code>中的<code>Multi-Head Self-Attention</code>模块和<code>Transformer Decoder</code>中的<code>Cross Attention</code>模块</font>。</p>
<p>Deformable DETR的提出可以帮助探索更多端到端目标检测方案，提出了bbox迭代微调策略和两阶段方法，其中iterative bounding box refinement类似Cascade R-CNN方法，two stage类似RPN。</p>
<h2 id="2related-work">2、Related work</h2>
<p>Transformer中包含了<strong>多头自注意力</strong>和<strong>交叉注意力机制</strong>，其中多头自注意力机制对key的数量很敏感，平方级别的复杂度导致不能有太多的key，解决方法主要可以分为三类。</p>
<p>(1)第一类解决方法为在key上使用预定义稀疏注意力模式，例如将注意力限制在一个固定的局部窗口上，这将导致失去了全局信息。</p>
<p>(2)第二类是通过数据学习到相关的稀疏注意力。</p>
<p>(3)第三类是寻找自注意力中低等级的属性，类似限制关键元素的尺寸大小。</p>
<p>图像领域的注意力方法大多数都局限于第一种设计方法，但是因为内存模式原因速度要比传统卷积慢3倍(相同的FLOPs下)。DCN可以看作是一种自注意力机制，它比自注意力机制更加高效有效，但是其缺少元素关系建模的机制。我们的可变形注意力模块来源于DCN，并且属于第二类注意力方法。它只关注从q特征预测得到的一小部分固定数量的采样点。</p>
<p>目标检测任务一个难点就是高效的表征不同尺度下的物体。现在有的方法比如FPN，PA-FPN，NAS-FPN，Auto-FPN，BiFPN等。我们的多尺度可变形注意力模块可以自然的融合基于注意力机制的多尺度特征图，不需要FPN了。</p>
<h2 id="3revisiting-transformers-and-detr">3、Revisiting Transformers And DETR</h2>
<h3 id="31transformer中的multi-head-self-attention">3.1、Transformer中的Multi-Head Self-Attention</h3>
<p>该模块计算复杂度为: $O(N_qC^2+N_kC^2+N_qN_kC)$ ，其中 $C$ 代表特征图维度，$N_q$ 和 $N_k$ 均为图片中的像素(pixel)，因此有 $N_{q}=N_{k}\gg C$ 。所以计算复杂度可以简化为 $O(N_{q}N_{k}C)$ ，可以得出其与图片像素的数量成平方级别的计算复杂度。</p>
<h3 id="32detr">3.2、DETR</h3>
<p><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2005.12872v3"target="_blank" rel="external nofollow noopener noreferrer">DETR<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>在目标检测领域中引入了Transformer结构并且取得了不错的效果。这套范式摒弃了传统目标检测中的anchor和post processing 机制，而是先预先设定100个object queries然后进行二分图匹配计算loss。其具体流程图(pipeline)如下:</p>
<p></p>
<ol>
<li>
<p>输入图片<code>3×800×1066</code>的一张图片，经过卷积神经网络提取特征，长宽32倍下采样后得到<code>2048×25×34</code>，然后通过一个<code>1×1 Conv</code>进行降维最终得到输出shape为<code>256×25×34</code>.</p>
</li>
<li>
<p>positional encoding为绝对位置编码，为了和特征完全匹配形状也为<code>256×25×34</code>，然后和特征进行元素级别的相加后输入到Transformer Encoder中。</p>
</li>
<li>
<p>输入到Encoder的尺寸为<code>(25×34)×256=850×256</code>，代表有850个token，每个token的维度为256，<strong>Encoder不改变输入的Shape</strong>。</p>
</li>
<li>
<p><code>Encoder</code>的输出和<code>object queries</code>输入到Decoder中形成<code>cross attention</code>，<code>object queries</code>的维度设置为<code>anchor数量×token数量</code>。</p>
</li>
<li>
<p><code>Decoder</code>输出到<code>FFN</code>进行分类和框定位，其中<code>FFN</code>是共享参数的。</p>
</li>
</ol>
<p><strong>Tips</strong>: 虽然DETR没有anchor，但是object queries其实就是起到了anchor的作用。</p>
<h2 id="4method">4、Method</h2>
<h3 id="41deformable-attention-module">4.1、Deformable Attention Module</h3>
<p></p>
<p>Deformable Attention Module主要思想是结合了<strong>DCN</strong>和<strong>自注意力</strong>，目的就是<u>为了通过在输入特征图上的参考点(reference point)附近只采样少数点(deformable detr设置为3个点)来作为注意力的 $k$</u>。因此要解决的问题就是:
(1). 确定reference point。
(2). 确定每个reference point的偏移量(offset)。
(3). 确定注意力权重矩阵。</p>
<p>在Encoder和Decoder中实现方法不太一样，加下来详细叙述。</p>
<p><strong>Encoder部分</strong></p>
<p>在Encoder部分，输入的Query Feature $z_q$ 为加入了位置编码的特征图<code>(src+pos)</code>，$value(x)$ 的计算方法只使用了src而没有位置编码(<code>value_proj</code>函数)。</p>
<p>(1). <strong>reference point</strong>确定方法为用了<code>torch.meshgrid</code>方法，调用的函数如下(get_reference_points)，有一个细节就是参考点归一化到0和1之间，因此取值的时候要用到<strong>双线性插值</strong>的方法。
<strong>不同点:</strong> 在Decoder中，参考点的获取方法为<code>object queries</code>通过一个<code>nn.Linear</code>得到每个对应的<code>reference point</code>。</p>
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_reference_points</span><span class="p">(</span><span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">valid_ratios</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="n">reference_points_list</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="n">lvl</span><span class="p">,</span> <span class="p">(</span><span class="n">H_</span><span class="p">,</span> <span class="n">W_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">spatial_shapes</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># 从0.5到H-0.5采样H个点，W同理 这个操作的目的也就是为了特征图的对齐</span>
</span></span><span class="line"><span class="cl">      <span class="n">ref_y</span><span class="p">,</span> <span class="n">ref_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">H_</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">H_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                                      <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">W_</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">W_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">      <span class="n">ref_y</span> <span class="o">=</span> <span class="n">ref_y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="kc">None</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">valid_ratios</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">lvl</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">H_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">ref_x</span> <span class="o">=</span> <span class="n">ref_x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="kc">None</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">valid_ratios</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">lvl</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">W_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">ref</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">ref_x</span><span class="p">,</span> <span class="n">ref_y</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">reference_points_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ref</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">reference_points</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">reference_points_list</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">reference_points</span> <span class="o">=</span> <span class="n">reference_points</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">valid_ratios</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">reference_points</span></span></span></code></pre></td></tr></table>
</div>
</div><p>(2)计算offset的方法为对 $z_q$ 做一个<code>nn.Linear</code>，得到多组偏移量，每组偏移量的维度为参考点的个数，组数为注意力头的数量。</p>
<p>(3)计算注意力权重矩阵的方法为过一个<code>nn.Linear</code>和一个<code>F.softmax</code>，得到每个头的注意力权重。</p>
<p><strong>如图2所示</strong>，分头计算完的注意力最终会拼接到一起，然后最后过一个nn.Linear得到输入 $x$ 的最终输出。</p>
<h3 id="42multi-scale-deformable-attention-module">4.2、Multi-Scale Deformable Attention Module</h3>
<p></p>
<p><strong>Multi-Scale Features &amp; Scale-Level Embedding</strong></p>
<p>多尺度的<code>Deformable Attention</code>模块也是在多尺度特征图上计算的。多尺度的特征融合方法则是取了骨干网络(ResNet)最后三层的特征图C3，C4，C5，并且用了一个Conv3x3 Stride2的卷积得到了一个C6构成了四层特征图。下采样率对应为8、16、32， $C_6$ 由 $C_5$ 经过步长为2的3x3卷积得到。特别的是会通过卷积操作将通道数量统一为256(也就是token的数量)，然后在这四个特征图上运行<code>Deformable Attention Module</code>并且进行直接相加得到最终输出。其中<code>Deformable Attention Module</code>算子的pytorch实现如下:</p>
<div class="highlight" id="id-2"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">ms_deform_attn_core_pytorch</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">value_spatial_shapes</span><span class="p">,</span> <span class="n">sampling_locations</span><span class="p">,</span> <span class="n">attention_weights</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># for debug and test only,</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># need to use cuda version instead</span>
</span></span><span class="line"><span class="cl">    <span class="n">N_</span><span class="p">,</span> <span class="n">S_</span><span class="p">,</span> <span class="n">M_</span><span class="p">,</span> <span class="n">D_</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">shape</span> <span class="c1"># batch size, number token, number head, head dims</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Lq_: number query, L_: level number, P_: sampling number采样点数</span>
</span></span><span class="line"><span class="cl">    <span class="n">_</span><span class="p">,</span> <span class="n">Lq_</span><span class="p">,</span> <span class="n">M_</span><span class="p">,</span> <span class="n">L_</span><span class="p">,</span> <span class="n">P_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">sampling_locations</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 按照level划分value</span>
</span></span><span class="line"><span class="cl">    <span class="n">value_list</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">split</span><span class="p">([</span><span class="n">H_</span> <span class="o">*</span> <span class="n">W_</span> <span class="k">for</span> <span class="n">H_</span><span class="p">,</span> <span class="n">W_</span> <span class="ow">in</span> <span class="n">value_spatial_shapes</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># [0, 1] -&gt; [-1, 1] 因为要满足F.grid_sample的输入要求</span>
</span></span><span class="line"><span class="cl">    <span class="n">sampling_grids</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">sampling_locations</span> <span class="o">-</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">    <span class="n">sampling_value_list</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">lid_</span><span class="p">,</span> <span class="p">(</span><span class="n">H_</span><span class="p">,</span> <span class="n">W_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">value_spatial_shapes</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># N_, H_*W_, M_, D_ -&gt; N_, H_*W_, M_*D_ -&gt; N_, M_*D_, H_*W_ -&gt; N_*M_, D_, H_, W_</span>
</span></span><span class="line"><span class="cl">        <span class="n">value_l_</span> <span class="o">=</span> <span class="n">value_list</span><span class="p">[</span><span class="n">lid_</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N_</span><span class="o">*</span><span class="n">M_</span><span class="p">,</span> <span class="n">D_</span><span class="p">,</span> <span class="n">H_</span><span class="p">,</span> <span class="n">W_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># N_, Lq_, M_, P_, 2 -&gt; N_, M_, Lq_, P_, 2 -&gt; N_*M_, Lq_, P_, 2</span>
</span></span><span class="line"><span class="cl">        <span class="n">sampling_grid_l_</span> <span class="o">=</span> <span class="n">sampling_grids</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="n">lid_</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># N_*M_, D_, Lq_, P_</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 用双线性插值从feature map上获取value，因为mask的原因越界所以要zeros的方法进行填充</span>
</span></span><span class="line"><span class="cl">        <span class="n">sampling_value_l_</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">grid_sample</span><span class="p">(</span><span class="n">value_l_</span><span class="p">,</span> <span class="n">sampling_grid_l_</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                          <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;bilinear&#39;</span><span class="p">,</span> <span class="n">padding_mode</span><span class="o">=</span><span class="s1">&#39;zeros&#39;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">sampling_value_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sampling_value_l_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (N_, Lq_, M_, L_, P_) -&gt; (N_, M_, Lq_, L_, P_) -&gt; (N_, M_, 1, Lq_, L_*P_)</span>
</span></span><span class="line"><span class="cl">    <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">attention_weights</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N_</span><span class="o">*</span><span class="n">M_</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">Lq_</span><span class="p">,</span> <span class="n">L_</span><span class="o">*</span><span class="n">P_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 不同scale计算出的multi head attention 进行相加，返回output后还需要过一个Linear层</span>
</span></span><span class="line"><span class="cl">    <span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">sampling_value_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">attention_weights</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N_</span><span class="p">,</span> <span class="n">M_</span><span class="o">*</span><span class="n">D_</span><span class="p">,</span> <span class="n">Lq_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">output</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span></span></span></code></pre></td></tr></table>
</div>
</div><p>要知道，DETR仅用了单尺度特征，于是对于特征点位置信息的编码，使用的是三角函数，不同位置的特征点会对应不同的编码值，没问题。但是，注意了，这仅能区分位于单尺度特征点的位置！而在多尺度特征中，位于不同特征层的特征点可能拥有相同的(h,w)坐标，这样就无法区分它们的位置编码了。</p>
<p>针对这个问题，作者增加使用一个称之为<font color=red>scale-level embedding</font>的东东，它<strong>仅用于区分不同的特征层</strong>，也就是同一特征层中的所有特征点会对应相同的scale-level embedding，于是有几层特征就使用几个不同的scale-level embedding。</p>
<p>另外，不同于三角函数那种固定地利用公式计算出来的编码方式，这个scale-level embedding是随机初始化并且是随网络一起训练的、是可学习的:</p>
<div class="highlight" id="id-3"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># scale-level embedding</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 对4个特征层每层附加256-dim的embedding</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 目的是为了区分query对应到哪个特征层，它会与position embedding相加在一起</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 注意: 位于同一个特征的所有query都会对应到相同的scale-level embedding</span>
</span></span><span class="line"><span class="cl"><span class="bp">self</span><span class="o">.</span><span class="n">level_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">num_feature_levels</span><span class="p">,</span> <span class="n">d_model</span><span class="p">))</span></span></span></code></pre></td></tr></table>
</div>
</div><p>在实际使用时，这个 scale-level embedding 与基于三角函数公式计算的 position embedding 相加在一起作为位置信息的嵌入:</p>
<div class="highlight" id="id-4"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 由于 position embedding仅区分h, w的位置，因此对于不同特征层有相同坐标值的特征点来说，是无法区分的，于是这里附加上scale-level embedding作为特征层的区分信息，这样，所有特征点的位置信息就各不相同了</span>
</span></span><span class="line"><span class="cl"><span class="c1"># (bs, c, h, w) =&gt; (bs, h*w, c)</span>
</span></span><span class="line"><span class="cl"><span class="n">pos_embed</span> <span class="o">=</span> <span class="n">pos_embed</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># (bs, h*w, c) + (1, 1, 256)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># note that c = 256 here</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">lvl_pos_embed</span> <span class="o">=</span> <span class="n">pos_embed</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">level_embed</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div><p><strong>Deformable Attention(&amp;Multi-Scale)</strong></p>
<p>可变形注意力的道理用大白话来说很简单: query不是和全局每个位置的key都计算注意力权重，而是<strong>对于每个query，仅在全局位置中采样部分位置的key，并且value也是基于这些位置进行采样插值得到的</strong>，最后将这个<strong>局部&amp;稀疏</strong>的注意力权重施加在对应的value上。</p>
<p>Transformer中多头注意力的公式如下:</p>
<p>$$
\text{MultiHeadAttn}(z_q,x)=\sum_{m=1}^MW_m\big[\sum_{k\in\Omega_k}A_{mqk}\cdot W_m^{\prime}x_k\big],
$$</p>
<p>其中，$z_q$ 看作query，由 $x$ 经过线性变换生成，$q$ 是对应的索引，$k$ 是key的索引, $\Omega_k$ 即所有的 $k$ 集合，$m$ 代表是第几个注意力头部，$W_m$ 是对注意力施加在value后的结果进行线性变换从而得到不同头部的输出结果，$W_m^{&rsquo;}$用于将 $x_k$ 变换成value，$A_{mqk}$ 代表归一化的注意力权重。</p>
<p>Deformable Attetion公式:</p>
<p>$$
\text{DeformAttn}(z_q,p_q,x)=\sum_{m=1}^MW_m\big[\sum_{k=1}^KA_{mqk}\cdot W_m&rsquo;x(p_q+\Delta p_{mqk})\big],
$$</p>
<p>和Transformer的很像是不是？(老师我没有抄作业，别凶..)可以看到，这里多了 $p_q$ 和 $\Delta p_{mqk}$。其中，前者代表 $z_q$ 的位置(理解成坐标即可)，是2d向量，作者称其为参考点(reference points)；而后者是采样集合点相对于参考点的位置偏移(offsets)。</p>
<p>可以看到，<strong>每个query在每个头部中采样K个位置，只需和这些位置的特征交互</strong>($x(p_q+\Delta p_{mqk})$ 代表基于采样点位置插值出来的value)，并不需要像Transformer般一开始先从全局位置开始学习才能逐渐过渡到关注局部(&amp;稀疏的)的、真正有意义的位置。</p>
<p>需要注意的是，如可变形卷积一样，<strong>位置偏移 $\Delta p_{mqk}$ 是可学习的，由query经过全连接层得到。并且，注意力权重也一样，直接由query经过全连接层得到(因此，在可变形注意力机制下，其实没有真正所谓的key来与query交互计算，为何可以这样做，后文CW会谈自己的看法)</strong>！同时在K个采样点之间归一化，而非像Transformer般是由query与key交互计算得出的。</p>
<p>OK，顺着来，看看可变形注意力是如何应用到多尺度特征上的，依旧是公式走起:</p>
<p>$$
\text{MSDeformAttn}(z_{q},\hat{p}<em>{q},{x^{l}}</em>{l=1}^{L})=\sum_{m=1}^{M}W_{m}\big[\sum_{l=1}^{L}\sum_{k=1}^{K}A_{mlqk}\cdot W_{m}^{\prime}x^{l}(\phi_{l}(\hat{p}<em>{q})+\Delta p</em>{mlqk})\big]
$$</p>
<p>这个也和上面的非常想是不是！？(老师我真的没有抄作业啊..太难了~)相比于上面，这里多了 ${x^l}<em>{l=1}^{L}$, $\phi</em>{l}$。另外，$p_q$ 头上多了个小尖角，代表归一化到 $[0,1]$，而 $\phi_{l}$ 正是用于将归一化的坐标映射(re-scales)到各个特征层去，这样，每个参考点在所有特征层都会有一个对应的(归一化)坐标，从而方便计算在不同特征层进行采样的那些点的位置。至于 ${x^l}_{l=1}^{L}$ 嘛，当然就是代表多尺度特征咯，$x_l$ 代表第 $l$ 层的特征。</p>
<p>在这里，每个query在每个特征层都会采样K个点，共有L层特征，从而在每个头部内共采样LK个点，注意力权重也是在这LK个点之间进行归一化。</p>
<p>另外，作者还提到，当L=K=1且 $W_m^{&rsquo;}$ 是identity矩阵时，该模块就退化成可变形卷积；相对地，当采样所有可能的位置(即全局位置)时，该模块等效于Transfomer中的注意力。</p>
<p>道理说完，依旧如CW的风格，是时候上代码了:</p>
<div class="highlight" id="id-5"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">MSDeformAtten</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">n_levels</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">n_points</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">    Multi-Scale Deformable Attention Module
</span></span></span><span class="line"><span class="cl"><span class="s2">    :param d_model    hidden dimensions
</span></span></span><span class="line"><span class="cl"><span class="s2">    :param n_levels   number of feature levels
</span></span></span><span class="line"><span class="cl"><span class="s2">    :param n_heads    number of attention heads
</span></span></span><span class="line"><span class="cl"><span class="s2">    :param n_points   number of sampling points per attention head per feature level
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="nb">super</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">d_model</span> <span class="o">%</span> <span class="n">n_heads</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;d_model must be divisible by n_heads, but got </span><span class="si">{}</span><span class="s1"> and </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="n">_d_per_head</span> <span class="o">=</span> <span class="n">d_model</span> <span class="o">//</span> <span class="n">n_heads</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># you&#39;d better set _d_per_heads to a power of 2 which is more efficient in out CUDA implementation</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="ow">not</span> <span class="n">_is_power_of_2</span><span class="p">(</span><span class="n">_d_per_head</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">      <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&#34;You&#39;d better set d_model in MSDeformAttn to make the dimension of each attention head&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">      <span class="s2">&#34;power of 2&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">      <span class="s2">&#34;which is more efficient in out CUDA implementation.&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 用于cuda实现</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">im2col_step</span> <span class="o">=</span> <span class="mi">64</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">n_levels</span> <span class="o">=</span> <span class="n">n_levels</span> <span class="c1"># 4</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span> <span class="o">=</span> <span class="n">n_heads</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">n_points</span> <span class="o">=</span> <span class="n">n_points</span> <span class="c1"># 4</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># 采样点的坐标偏移， 每个query在每个注意力头和每个特征层都需要采样n_points个</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 由于x, y坐标都有对应的偏移量，因此还要*2</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">sampling_offsets</span> <span class="o">=</span>  <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_heads</span> <span class="o">*</span> <span class="n">n_levels</span> <span class="o">*</span> <span class="n">n_points</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 每个query对应的所有采样点的注意力权重</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_heads</span> <span class="o">*</span> <span class="n">n_levels</span> <span class="o">*</span> <span class="n">n_points</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 线性变换得到value</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">value_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 最后经过这个线性变换得到输出结果</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">output_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Liear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">__reset_parameters</span><span class="p">()</span></span></span></code></pre></td></tr></table>
</div>
</div><p>接下来有个亮点，在以上最后的 _reset_parameters() 中，是关于生成初始的采样点位置的:</p>
<div class="highlight" id="id-6"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">_reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="n">constant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sampling_offsets</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;&#34;&#34;初始化偏移量预测的偏置(bias), 使得初始偏移位置犹如不同大小的方形卷积核组合&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1"># (8,) [0, pi / 4, pi / 2, 3 * pi / 2, ..., 7 * pi / 4]</span>
</span></span><span class="line"><span class="cl">  <span class="n">thetas</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="p">(</span><span class="mf">2.0</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># (8, 2)</span>
</span></span><span class="line"><span class="cl">  <span class="n">grid_init</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">thetas</span><span class="o">.</span><span class="n">cos</span><span class="p">(),</span> <span class="n">thetas</span><span class="o">.</span><span class="n">sin</span><span class="p">()],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># grid_init / grid_init.abs().max(-1, keepdi=True)[0]这步计算得到8个头对应的坐标偏移:</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># (1, 0), (1, 1), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 从图形视觉上来看， 形成的偏移位置相当于是3x3， 5x5, 7x7, 9x9正方形卷积核(出去中心，中心是参考点本身)</span>
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_points</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">grid_init</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 注意这里取消了梯度，只是借助nn.Parameter把数值设置进去</span>
</span></span><span class="line"><span class="cl">  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="bp">self</span><span class="o">.</span><span class="n">sampling_offsets</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameters</span><span class="p">(</span><span class="n">grid_init</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span></span></span></code></pre></td></tr></table>
</div>
</div><p>具体实现以及道理看以上代码和CW的注释，最终效果就是，初始的采样点位置相当于会分布在参考点3x3、5x5、7x7、9x9方形邻域。在github上有朋友提过相关的issue，CW那时正好逛到，也给予了相应的互动:</p>
<p><a href="https://github.com/fundamentalvision/Deformable-DETR/issues/38"target="_blank" rel="external nofollow noopener noreferrer">github相关issue<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<p>另外，对于注意力权重的初始化，CW发现作者的源码实现和paper中描述得有出入:</p>
<div class="highlight" id="id-7"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">constant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># TODO: 这里与paper描述的有出入， paper中说bias初始化为1/LK, 其中L为特征层数=4， K为每层的采样点数量=4</span>
</span></span><span class="line"><span class="cl"><span class="c1"># paper中说的那样才是在多有采样点之间归一化</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 否则， 这里所示的， weight和bias都是0， 直接导致最终的输出全为0</span>
</span></span><span class="line"><span class="cl"><span class="n">cosntant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># constant_(self.attention_weights.bias.data, 1/(self.n_levels * self.n_points))</span></span></span></code></pre></td></tr></table>
</div>
</div><p>若按照以上的实现，感觉明显不合理，这样会导致注意力权重为全0，从而使得这个模块的输出结果也会变为全0。CW在github上提了issue，暂未有回复:</p>
<p><a href="https://link.zhihu.com/?target=https%3A//github.com/fundamentalvision/Deformable-DETR/issues/44"target="_blank" rel="external nofollow noopener noreferrer">issue<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<p>接下来看看最重要的前向过程:</p>
<div class="highlight" id="id-8"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">reference_points</span><span class="p">,</span> <span class="n">input_flatten</span><span class="p">,</span> <span class="n">input_spatial_shapes</span><span class="p">,</span> <span class="n">input_level_start_index</span><span class="p">,</span> <span class="n">input_padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">  :param query                    (N, Length_</span><span class="si">{query}</span><span class="s2">, c)
</span></span></span><span class="line"><span class="cl"><span class="s2">  :param reference_points         (N, Length_</span><span class="si">{query}</span><span class="s2">, n_levels, 2), range in
</span></span></span><span class="line"><span class="cl"><span class="s2">                                  [0, 1], top-left (0, 0), bottom-right (1, 1)
</span></span></span><span class="line"><span class="cl"><span class="s2">                                  including padding area or (N, Length_</span><span class="si">{query}</span><span class="s2">, n_levels, 4),
</span></span></span><span class="line"><span class="cl"><span class="s2">                                  add additional (w, h) to form reference boxes
</span></span></span><span class="line"><span class="cl"><span class="s2">  :param input_flatten            (N, \sum_{l=0}^{L-1} H_l \cdot W_l, C)
</span></span></span><span class="line"><span class="cl"><span class="s2">  :param input_spatial_shapes     (n_levels, 2), [(H_0, W_0), (H_1, W_1), ..., (H_{L-1}, W_{L-1})]
</span></span></span><span class="line"><span class="cl"><span class="s2">  :param input_level_start_index  (n_levels, ), [0, H_0*W_0, H_0*W_0+H_1*W_1, H_0*W_0+H_1*W_1+H_2*W_2, ..., H_0*W_0+H_1*W_1+...+H_{L-1}*W_{L-1}]
</span></span></span><span class="line"><span class="cl"><span class="s2">  :param input_padding_mask       (N, \sum_{l=0}^{L-1} H_l \cdot W_l), True for padding elements, False for non-padding elements
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">  :return output                  (N, Length_</span><span class="si">{query}</span><span class="s2">, C)
</span></span></span><span class="line"><span class="cl"><span class="s2">  &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">  <span class="n">N</span><span class="p">,</span> <span class="n">Len_q</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">  <span class="n">N</span><span class="p">,</span> <span class="n">Len_in</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">input_flatten</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">  <span class="k">assert</span> <span class="p">(</span><span class="n">input_spatial_shapes</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">input_spatial_shapes</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">==</span> <span class="n">Len_in</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_proj</span><span class="p">(</span><span class="n">input_flatten</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="k">if</span> <span class="n">input_padding_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">input_padding_mask</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="nb">float</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">  <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">Len_in</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1"># 以下主要是计算出采样点的位置。2-stage模式下，输入到Decoder的参考点是Encoder预测的top-k proposal boxes，也就是说是4d的(非2-stage情况下是2d)，于是需要分情况处理:</span>
</span></span><span class="line"><span class="cl">  <span class="n">sampling_offsets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampling_offsets</span><span class="p">(</span><span class="n">query</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">Len_q</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_levels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_points</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">attention_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span><span class="p">(</span><span class="n">query</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">Len_q</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_levels</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_points</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attention_weights</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">Len_q</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_levels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_points</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># N, Len_q, n_heads, n_levels, n_points, 2</span>
</span></span><span class="line"><span class="cl">  <span class="k">if</span> <span class="n">reference_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="n">offset_normalizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">input_spatial_shapes</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">input_spatial_shapes</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">sampling_locations</span> <span class="o">=</span> <span class="n">reference_points</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> \
</span></span><span class="line"><span class="cl">                            <span class="o">+</span> <span class="n">sampling_offsets</span> <span class="o">/</span> <span class="n">offset_normalizer</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
</span></span><span class="line"><span class="cl">  <span class="k">elif</span> <span class="n">reference_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># reference_points 最后一维中的前两个事中心坐标xy， 后两个是宽高wh</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 由于初始化时，offset的在-k~k(k = n_points)范围，因此这里除以n_points相当于归一化到0~1</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 然后乘以宽和高的一半， 加上参考点的中心坐标，这样就是的偏移后采样点位于proposal bbox内</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 相当于对采样范围进行了约束，减小了搜索空间</span>
</span></span><span class="line"><span class="cl">      <span class="n">sampling_locations</span> <span class="o">=</span> <span class="n">reference_points</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span> \
</span></span><span class="line"><span class="cl">                            <span class="o">+</span> <span class="n">sampling_offsets</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_points</span> <span class="o">*</span> <span class="n">reference_points</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">2</span><span class="p">:]</span> <span class="o">*</span> <span class="mf">0.5</span>
</span></span><span class="line"><span class="cl">  <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">          <span class="s1">&#39;Last dim of reference_points must be 2 or 4, but get </span><span class="si">{}</span><span class="s1"> instead.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">reference_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 根据采样点位置拿出对应的value，并且施加预测出来的注意力权重(和value进行weighted sum)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># (N, Len_in, 256)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 注意: 实质调用的是基于CUDA实现的版本，需要编译</span>
</span></span><span class="line"><span class="cl">  <span class="n">output</span> <span class="o">=</span> <span class="n">MSDeformAttnFunction</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">      <span class="n">value</span><span class="p">,</span> <span class="n">input_spatial_shapes</span><span class="p">,</span> <span class="n">input_level_start_index</span><span class="p">,</span> <span class="n">sampling_locations</span><span class="p">,</span> <span class="n">attention_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">im2col_step</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># (N， Len_in, 256)</span>
</span></span><span class="line"><span class="cl">  <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_proj</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">output</span></span></span></code></pre></td></tr></table>
</div>
</div><p>在这里，将注意力权重与value进行weighted sum的实现是调用了用CUDA来实现的版本，因为Pytorch版性能有点尴尬，不过我们也可以看看Pytorch的实现，了解其中的逻辑。</p>
<div class="highlight" id="id-9"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">ms_deform_attn_core_pytorch</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">value_spatial_shapes</span><span class="p">,</span> <span class="n">sampling_locations</span><span class="p">,</span> <span class="n">attention_weights</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;&#34;&#34;多尺度可变性注意力， 根据采样点的位置在多尺度value中插值采样出对应的特征图，最后和注意力权重进行weighted sum得到输出&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># for debug and test only,</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># need to use cuda version instead</span>
</span></span><span class="line"><span class="cl">  <span class="n">N_</span><span class="p">,</span> <span class="n">S_</span><span class="p">,</span> <span class="n">M_</span><span class="p">,</span> <span class="n">D_</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">  <span class="n">_</span><span class="p">,</span> <span class="n">Lq_</span><span class="p">,</span> <span class="n">M_</span><span class="p">,</span> <span class="n">L_</span><span class="p">,</span> <span class="n">P_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">sampling_locations</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 由于以下使用了F.grid_sample()，要求采样位置的坐标是归一化到[-1, 1] ((-1, -1)代表左上角， (1，1)代表右下角)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 因此， 这里是将[0, 1]映射到[-1, 1]</span>
</span></span><span class="line"><span class="cl">  <span class="n">value_list</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">split</span><span class="p">([</span><span class="n">H_</span> <span class="o">*</span> <span class="n">W_</span> <span class="k">for</span> <span class="n">H_</span><span class="p">,</span> <span class="n">W_</span> <span class="ow">in</span> <span class="n">value_spatial_shapes</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">sampling_grids</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">sampling_locations</span> <span class="o">-</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">  <span class="n">sampling_value_list</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="n">lid_</span><span class="p">,</span> <span class="p">(</span><span class="n">H_</span><span class="p">,</span> <span class="n">W_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">value_spatial_shapes</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># N_, H_*W_, M_, D_ -&gt; N_, H_*W_, M_*D_ -&gt; N_, M_*D_, H_*W_ -&gt; N_*M_, D_, H_, W_</span>
</span></span><span class="line"><span class="cl">      <span class="n">value_l_</span> <span class="o">=</span> <span class="n">value_list</span><span class="p">[</span><span class="n">lid_</span><span class="p">]</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N_</span><span class="o">*</span><span class="n">M_</span><span class="p">,</span> <span class="n">D_</span><span class="p">,</span> <span class="n">H_</span><span class="p">,</span> <span class="n">W_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># N_, Lq_, M_, P_, 2 -&gt; N_, M_, Lq_, P_, 2 -&gt; N_*M_, Lq_, P_, 2</span>
</span></span><span class="line"><span class="cl">      <span class="n">sampling_grid_l_</span> <span class="o">=</span> <span class="n">sampling_grids</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="n">lid_</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># 根据采样点坐标在value中插值出对应的特征</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># ps: grid_sample()用法</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># 这里value_l 充当被插值采样的特征图，是input， 维度需要时 4D/5D</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># sampling_grid_l则代表采样的位置，是grid，最后一维2对应input中的坐标(可能是小数)</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># 倒数第2，3维代表采样后输出特征图宽、高</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># input和grid的第一个维度必须一致，最终输出的通道数与input一致，是不变的</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># N_*M_, D_, Lq_, P_</span>
</span></span><span class="line"><span class="cl">      <span class="n">sampling_value_l_</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">grid_sample</span><span class="p">(</span><span class="n">value_l_</span><span class="p">,</span> <span class="n">sampling_grid_l_</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                        <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;bilinear&#39;</span><span class="p">,</span> <span class="n">padding_mode</span><span class="o">=</span><span class="s1">&#39;zeros&#39;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">sampling_value_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sampling_value_l_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># (N_, Lq_, M_, L_, P_) -&gt; (N_, M_, Lq_, L_, P_) -&gt; (N_, M_, 1, Lq_, L_*P_)</span>
</span></span><span class="line"><span class="cl">  <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">attention_weights</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N_</span><span class="o">*</span><span class="n">M_</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">Lq_</span><span class="p">,</span> <span class="n">L_</span><span class="o">*</span><span class="n">P_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 最后就是将注意力权重和采样特征进行weighted sum:</span>
</span></span><span class="line"><span class="cl">  <span class="n">output</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">sampling_value_list</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">attention_weights</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N_</span><span class="p">,</span> <span class="n">M_</span><span class="o">*</span><span class="n">D_</span><span class="p">,</span> <span class="n">Lq_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">output</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span></span></span></code></pre></td></tr></table>
</div>
</div><p>Deformable DETR有2-stage模式，后文会讲到。在2-stage模式下，输入到Decoder的参考点和object query&amp;query embedding会有所不同。</p>
<div class="details admonition quote">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-quote-right fa-fw" aria-hidden="true"></i>引用<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content"><p>Multi-Scale Deformable Attention 主要做以下事情:</p>
<ol>
<li>将输入input_flatten (对于Encoder就是由backbone输出的特征图变换而来；对于Decoder就是Encoder输出的memory)，通过变换矩阵得到value，同时将padding的部分用0填充；</li>
<li>将query(对于Encoder就是特征图本身加上position&amp;scale-level embedding);
对于Decoder就是self-attention的输出加上position embedding结果；
2-stage时这个position embedding是由Encoder预测的top-k proposal boxes进行position embedding得来，
而1-stage时是预设的embedding分别通过两个全连接层得到采样点对应的坐标偏移和注意力权重(注意力权重会进行归一化)；</li>
<li>根据参考点(reference points: 对于Decoder来说， 2-stage时是Encoder预测的top-k proposal boxes；1-stage时是由预设的query embedding经过全连接层得到。两种情况下最终都经过了sigmoid函数归一化；而对于Encoder来说，就是个特征点在所有的特征层对应的归一化中心坐标和预测坐标偏移采样点的坐标)；</li>
<li>由采样点坐标在value中插值采样处对应的特征向量，然后施加注意力权重，最后将结果经过全连接层得到输出结果。</li>
</ol></div>
    </div>
  </div>
<p>完整的<code>Multi-Scale Deformable Attention</code>模块代码如下:</p>
<div class="highlight" id="id-10"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span><span class="lnt">74
</span><span class="lnt">75
</span><span class="lnt">76
</span><span class="lnt">77
</span><span class="lnt">78
</span><span class="lnt">79
</span><span class="lnt">80
</span><span class="lnt">81
</span><span class="lnt">82
</span><span class="lnt">83
</span><span class="lnt">84
</span><span class="lnt">85
</span><span class="lnt">86
</span><span class="lnt">87
</span><span class="lnt">88
</span><span class="lnt">89
</span><span class="lnt">90
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">MSDeformAttn</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">n_levels</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">n_points</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">      <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">      Multi-Scale Deformable Attention Module
</span></span></span><span class="line"><span class="cl"><span class="s2">      :param d_model      hidden dimension
</span></span></span><span class="line"><span class="cl"><span class="s2">      :param n_levels     number of feature levels
</span></span></span><span class="line"><span class="cl"><span class="s2">      :param n_heads      number of attention heads
</span></span></span><span class="line"><span class="cl"><span class="s2">      :param n_points     number of sampling points per attention head per feature level
</span></span></span><span class="line"><span class="cl"><span class="s2">      &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">      <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">      <span class="k">if</span> <span class="n">d_model</span> <span class="o">%</span> <span class="n">n_heads</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">          <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;d_model must be divisible by n_heads, but got </span><span class="si">{}</span><span class="s1"> and </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">      <span class="n">_d_per_head</span> <span class="o">=</span> <span class="n">d_model</span> <span class="o">//</span> <span class="n">n_heads</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># you&#39;d better set _d_per_head to a power of 2 which is more efficient in our CUDA implementation</span>
</span></span><span class="line"><span class="cl">      <span class="k">if</span> <span class="ow">not</span> <span class="n">_is_power_of_2</span><span class="p">(</span><span class="n">_d_per_head</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">          <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&#34;You&#39;d better set d_model in MSDeformAttn to make the dimension of each attention head a power of 2 &#34;</span>
</span></span><span class="line"><span class="cl">                        <span class="s2">&#34;which is more efficient in our CUDA implementation.&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">im2col_step</span> <span class="o">=</span> <span class="mi">64</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">n_levels</span> <span class="o">=</span> <span class="n">n_levels</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span> <span class="o">=</span> <span class="n">n_heads</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">n_points</span> <span class="o">=</span> <span class="n">n_points</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">sampling_offsets</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_heads</span> <span class="o">*</span> <span class="n">n_levels</span> <span class="o">*</span> <span class="n">n_points</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_heads</span> <span class="o">*</span> <span class="n">n_levels</span> <span class="o">*</span> <span class="n">n_points</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">value_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">output_proj</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="bp">self</span><span class="o">.</span><span class="n">_reset_parameters</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="nf">_reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">      <span class="n">constant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sampling_offsets</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mf">0.</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">thetas</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mf">2.0</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">grid_init</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">thetas</span><span class="o">.</span><span class="n">cos</span><span class="p">(),</span> <span class="n">thetas</span><span class="o">.</span><span class="n">sin</span><span class="p">()],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">grid_init</span> <span class="o">=</span> <span class="p">(</span><span class="n">grid_init</span> <span class="o">/</span> <span class="n">grid_init</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_levels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_points</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_points</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">          <span class="n">grid_init</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">*=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">      <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">          <span class="bp">self</span><span class="o">.</span><span class="n">sampling_offsets</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">grid_init</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">      <span class="n">constant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mf">0.</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">constant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mf">0.</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">xavier_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value_proj</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">constant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">value_proj</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mf">0.</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">xavier_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_proj</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">constant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_proj</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mf">0.</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">query</span><span class="p">,</span> <span class="n">reference_points</span><span class="p">,</span> <span class="n">input_flatten</span><span class="p">,</span> <span class="n">input_spatial_shapes</span><span class="p">,</span> <span class="n">input_level_start_index</span><span class="p">,</span> <span class="n">input_padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">      <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">      :param query                       (N, Length_</span><span class="si">{query}</span><span class="s2">, C)
</span></span></span><span class="line"><span class="cl"><span class="s2">      :param reference_points            (N, Length_</span><span class="si">{query}</span><span class="s2">, n_levels, 2), range in [0, 1], top-left (0,0), bottom-right (1, 1), including padding area
</span></span></span><span class="line"><span class="cl"><span class="s2">                                      or (N, Length_</span><span class="si">{query}</span><span class="s2">, n_levels, 4), add additional (w, h) to form reference boxes
</span></span></span><span class="line"><span class="cl"><span class="s2">      :param input_flatten               (N, \sum_{l=0}^{L-1} H_l \cdot W_l, C)
</span></span></span><span class="line"><span class="cl"><span class="s2">      :param input_spatial_shapes        (n_levels, 2), [(H_0, W_0), (H_1, W_1), ..., (H_{L-1}, W_{L-1})]
</span></span></span><span class="line"><span class="cl"><span class="s2">      :param input_level_start_index     (n_levels, ), [0, H_0*W_0, H_0*W_0+H_1*W_1, H_0*W_0+H_1*W_1+H_2*W_2, ..., H_0*W_0+H_1*W_1+...+H_{L-1}*W_{L-1}]
</span></span></span><span class="line"><span class="cl"><span class="s2">      :param input_padding_mask          (N, \sum_{l=0}^{L-1} H_l \cdot W_l), True for padding elements, False for non-padding elements
</span></span></span><span class="line"><span class="cl"><span class="s2">
</span></span></span><span class="line"><span class="cl"><span class="s2">      :return output                     (N, Length_</span><span class="si">{query}</span><span class="s2">, C)
</span></span></span><span class="line"><span class="cl"><span class="s2">      &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># query是 src + positional encoding</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># input_flatten是src，没有位置编码</span>
</span></span><span class="line"><span class="cl">      <span class="n">N</span><span class="p">,</span> <span class="n">Len_q</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">      <span class="n">N</span><span class="p">,</span> <span class="n">Len_in</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">input_flatten</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">      <span class="k">assert</span> <span class="p">(</span><span class="n">input_spatial_shapes</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">input_spatial_shapes</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">==</span> <span class="n">Len_in</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># 根据input_flatten得到v</span>
</span></span><span class="line"><span class="cl">      <span class="n">value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">value_proj</span><span class="p">(</span><span class="n">input_flatten</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="k">if</span> <span class="n">input_padding_mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">          <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">input_padding_mask</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="nb">float</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># 多头注意力 根据头的个数将v等分</span>
</span></span><span class="line"><span class="cl">      <span class="n">value</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">Len_in</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># 根据query得到offset偏移量和attention weights注意力权重</span>
</span></span><span class="line"><span class="cl">      <span class="n">sampling_offsets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampling_offsets</span><span class="p">(</span><span class="n">query</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">Len_q</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_levels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_points</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">attention_weights</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span><span class="p">(</span><span class="n">query</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">Len_q</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_levels</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_points</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">attention_weights</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">attention_weights</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">Len_q</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_heads</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_levels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_points</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># N, Len_q, n_heads, n_levels, n_points, 2</span>
</span></span><span class="line"><span class="cl">      <span class="k">if</span> <span class="n">reference_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">          <span class="n">offset_normalizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">input_spatial_shapes</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">input_spatial_shapes</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">          <span class="n">sampling_locations</span> <span class="o">=</span> <span class="n">reference_points</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> \
</span></span><span class="line"><span class="cl">                                <span class="o">+</span> <span class="n">sampling_offsets</span> <span class="o">/</span> <span class="n">offset_normalizer</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
</span></span><span class="line"><span class="cl">      <span class="k">elif</span> <span class="n">reference_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">          <span class="n">sampling_locations</span> <span class="o">=</span> <span class="n">reference_points</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span> \
</span></span><span class="line"><span class="cl">                                <span class="o">+</span> <span class="n">sampling_offsets</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_points</span> <span class="o">*</span> <span class="n">reference_points</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">2</span><span class="p">:]</span> <span class="o">*</span> <span class="mf">0.5</span>
</span></span><span class="line"><span class="cl">      <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">          <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">              <span class="s1">&#39;Last dim of reference_points must be 2 or 4, but get </span><span class="si">{}</span><span class="s1"> instead.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">reference_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl">      <span class="n">output</span> <span class="o">=</span> <span class="n">MSDeformAttnFunction</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">          <span class="n">value</span><span class="p">,</span> <span class="n">input_spatial_shapes</span><span class="p">,</span> <span class="n">input_level_start_index</span><span class="p">,</span> <span class="n">sampling_locations</span><span class="p">,</span> <span class="n">attention_weights</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">im2col_step</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_proj</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="k">return</span> <span class="n">output</span></span></span></code></pre></td></tr></table>
</div>
</div><h3 id="43-deformable-transformer">4.3 Deformable Transformer</h3>
<p>这里的Transformer和DETR中的大体过程一致，最主要的区别在于用<strong>可变形注意力</strong>替代了Encoder中的自注意力(self-attention)以及Decoder中的交叉注意力(cross-attention)。在分别解析Encoder和Decoder前，CW先向大家梳理下这里Transformer的整个pipeline(有源码解析哦！)。</p>
<p><strong>1). 为Encoder的输入做准备</strong></p>
<p>主要是将一些输入元素的维度展平(flatten)，这些输入元素包括: 多尺度特征图、各尺度特征图对应的mask(指示哪些部分属于padding)、各尺度特征图对应的位置信息(position embedding + scale-level embedding)，另外还有些辅助信息，比如: 各尺度特征图的宽高、不同尺度特征对应于被flatten的那个维度的起始索引、各尺度特征图中非padding部分的边长占其边长的比例。</p>
<div class="highlight" id="id-11"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># deformable transformer forward函数</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">srcs</span><span class="p">,</span> <span class="n">masks</span><span class="p">,</span> <span class="n">pos_embeds</span><span class="p">,</span> <span class="n">query_embed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">two_stage</span> <span class="ow">or</span> <span class="n">query_embed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;为Encoder的输入作准备:
</span></span></span><span class="line"><span class="cl"><span class="s2">    (i). 将各层特征图(已映射到c=256维度)flatten并concat到一起: (bs, h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 +..., 256);
</span></span></span><span class="line"><span class="cl"><span class="s2">    (ii). 将各层特征图对应的mask(指示了哪些位置是padding)flatten并concat: (bs, h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 + ...,)
</span></span></span><span class="line"><span class="cl"><span class="s2">    (iii). 将各层特征图对应的position embedding加上scale level embedding(用于表明query属于哪个特征层)， 然后flatten并concat: (bs, h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 + ..., 256);
</span></span></span><span class="line"><span class="cl"><span class="s2">    (iv). 将各层特征图的宽高由list变为tensor: (n_lvl, 2);
</span></span></span><span class="line"><span class="cl"><span class="s2">    (v). 由于将所有特征图的特征点concat在了一起 (h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 + ...), 因此为了区分各层，需要计算对应于被flatten那个维度的起始index(第一层当然是0，后面就是累加...)
</span></span></span><span class="line"><span class="cl"><span class="s2">    (vi). 计算各层特征层中非padding的部分边长(高&amp;宽)占特征图边长的比例(bs, n_lvl, 2)
</span></span></span><span class="line"><span class="cl"><span class="s2">    &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># prepare input for encoder</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 以下的flatten指的是将h，w两个维度展平为h * w</span>
</span></span><span class="line"><span class="cl">    <span class="n">src_flatten</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">    <span class="n">mask_flatten</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 各层特征图对应的position embedding + scale-level embedding</span>
</span></span><span class="line"><span class="cl">    <span class="n">lvl_pos_embed_flatten</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 各层特征图的尺寸(h, w)</span>
</span></span><span class="line"><span class="cl">    <span class="n">spatial_shapes</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">lvl</span><span class="p">,</span> <span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">pos_embed</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">srcs</span><span class="p">,</span> <span class="n">masks</span><span class="p">,</span> <span class="n">pos_embeds</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">        <span class="n">bs</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">src</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">        <span class="n">spatial_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">spatial_shapes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">spatial_shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># (bs, c, h, w) =&gt; (bs, h*w, c)</span>
</span></span><span class="line"><span class="cl">        <span class="n">src</span> <span class="o">=</span> <span class="n">src</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># (bs, h, w) =&gt; (bs, h*w)</span>
</span></span><span class="line"><span class="cl">        <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">        由于position embedding仅区分h，w的位置
</span></span></span><span class="line"><span class="cl"><span class="s2">        因此对于不同特征层有相同坐标值的特征点来说，是无法区分的，于是这里附加上scale-level embedding作为特征层的区分信息
</span></span></span><span class="line"><span class="cl"><span class="s2">        这样，所有特征点的位置信息就各不相同了
</span></span></span><span class="line"><span class="cl"><span class="s2">        &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># (bs, c, h, w) =&gt; (bs, h * w, c)</span>
</span></span><span class="line"><span class="cl">        <span class="n">pos_embed</span> <span class="o">=</span> <span class="n">pos_embed</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># (bs, h*w, c) + (1, 1, 256)\</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># note that c = 256 here</span>
</span></span><span class="line"><span class="cl">        <span class="n">lvl_pos_embed</span> <span class="o">=</span> <span class="n">pos_embed</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">level_embed</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">lvl_pos_embed_flatten</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lvl_pos_embed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">src_flatten</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">mask_flatten</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (bs, h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 + ..., c)</span>
</span></span><span class="line"><span class="cl">    <span class="n">src_flatten</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">src_flatten</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (bs, h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 + ...)</span>
</span></span><span class="line"><span class="cl">    <span class="n">mask_flatten</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">mask_flatten</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (bs, h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 + ..., c)</span>
</span></span><span class="line"><span class="cl">    <span class="n">lvl_pos_embed_flatten</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">lvl_pos_embed_flatten</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (n_lvl,2)</span>
</span></span><span class="line"><span class="cl">    <span class="n">spatial_shapes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">src_flatten</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># .prod(dim=1)是将dim1的各个元素相乘，在这里就会得到各特征层点数量: h * w</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># .cumsum(0)代表在dim=0进行累加，在这里就会得到h_lvl1 * w_lvl1, h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2, ...</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 因此这里得到的level_start_index是各特征层起始的index(这个索引对应到被flatten的维度)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (n_lvl,)</span>
</span></span><span class="line"><span class="cl">    <span class="n">level_start_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">spatial_shapes</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="p">)),</span> <span class="n">spatial_shapes</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="mi">0</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (bs, n_lvl, 2) 各特征层中非padding部分的边长(高&amp;宽)占特征图边长的比例</span>
</span></span><span class="line"><span class="cl">    <span class="n">valid_ratios</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">get_valid_ratio</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">masks</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># encoder</span>
</span></span><span class="line"><span class="cl">    <span class="n">memory</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">src_flatten</span><span class="p">,</span> <span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">level_start_index</span><span class="p">,</span> <span class="n">valid_ratios</span><span class="p">,</span> <span class="n">lvl_pos_embed_flatten</span><span class="p">,</span> <span class="n">mask_flatten</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div><p>2). Encoder编码特征</p>
<p>源码对应上图最后一句。</p>
<p>encoder部分，输出memory(编码后的特征表示)，shape是 (bs, h_lvl1<em>w_lvl1+h_lvl2</em>w_lvl2+.., c=256)，其中h_lvli和w_lvli分别代表第i层特征图的高和宽，于是第二个维度就是所有特征点的数量。编码后，特征的最后一个维度(hidden_dim)为256。</p>
<p>3). 处理Encoder的输出，为Decoder的输入做准备</p>
<p>这一步<strong>主要是得到参考点(reference points)</strong>。需要说明下，在2-stage模式下，参考点和输入到Decoder的object query及query embedding的生成方式和形式会有所不同:</p>
<p>&ndash;如果是2-stage模式，那么参考点就是由Encoder预测的top-k得分最高的proposal boxes(注意，这时参考点是4d的，是bbox形式)。然后通过对参考点进行位置嵌入(position embedding)来生成Decoder的object query(target) 和对应的 query embedding；</p>
<p>&ndash;否则，Decoder的 object query(target )和 query embedding 就是预设的embedding，然后将query embedding经过全连接层输出2d参考点，这时的参考点是归一化的中心坐标形式。</p>
<p>另外，两种情况下生成的参考点数量可能不同: 2-stage时是有top-k(作者设置为300)个，而1-stage时是num_queries(作者也设置为300)个，也就是和object query的数量一致(可以理解为，此时参考点就是object query本身的位置)。</p>
<div class="highlight" id="id-12"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">    <span class="c1"># prepare input for decoder</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># c = 256 中间那一维等于(所有层)特征点的数量</span>
</span></span><span class="line"><span class="cl">    <span class="n">bs</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">memory</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 根据是否2-stage分情况进行处理，因为生成的reference points不同</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">two_stage</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># 生成proposals， 并且对Encoder的输出(memory)进行处理(全连接层 + 归一化)</span>
</span></span><span class="line"><span class="cl">      <span class="c1">#(bs, h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 + ..., 256), (bs, h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 + ..., 4)</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># 其中proposals每个都是xywh形式， 并且是经过inverse-sigmoid函数后的结果</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># (其实这里的output_proposals对应的就是各层特征图各个特征点的位置(相当于anchor的形式，是固定的)，</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># 因此还需要借助Decoder最后一层的bbox head来预测一个偏移(offset)来得到一个更加灵活的结果，</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># 这才是第一阶段预测的proposal boxes)</span>
</span></span><span class="line"><span class="cl">      <span class="n">output_memory</span><span class="p">,</span> <span class="n">output_proposals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gen_encoder_output_proposals</span><span class="p">(</span><span class="n">memory</span><span class="p">,</span> <span class="n">mask_flatten</span><span class="p">,</span> <span class="n">spatial_shapes</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="c1"># hack implementation for two-stage Deformable DETR</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># 注意: 这里维度对应的是多分类，并非二分类</span>
</span></span><span class="line"><span class="cl">      <span class="n">enc_outputs_class</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">class_embed</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">num_layers</span><span class="p">](</span><span class="n">output_memory</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># bbox head预测的是相对proposals的偏移，因此这里要相加， 后续还要经过sigmoid函数才得到真正的bbox预测结果(归一化形式)</span>
</span></span><span class="line"><span class="cl">      <span class="c1">#(bs， h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 + .., 4)</span>
</span></span><span class="line"><span class="cl">      <span class="n">enc_outputs_coord_unact</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">bbox_embed</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">num_layers</span><span class="p">](</span><span class="n">output_memory</span><span class="p">)</span> <span class="o">+</span> <span class="n">output_proposals</span></span></span></code></pre></td></tr></table>
</div>
</div><p>在阅读源码的过程中，发现这里有个小问题，貌似不妥。由于分类预测头部的输出维度是多分类的，而proposals仅需二分类就足够了，作者在取top-k得分时直接用第一个类别预测的结果来计算:</p>
<div class="highlight" id="id-13"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">      <span class="c1"># 300</span>
</span></span><span class="line"><span class="cl">      <span class="n">topk</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">two_stage_num_proposals</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># 选取得分最高的top分类预测，最后的[1]代表取得返回top对应的索引</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># (bs， k = 300)</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># TODO: 取第一个类别的预测结果算top-k，代表二分类</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># 当不适用iterative bbox refine时， 所有class_embed参数共享，这样会使得在第二阶段对解码输出进行分类时都偏向于第一个类别</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># 这样貌似不妥</span>
</span></span><span class="line"><span class="cl">      <span class="n">topk_proposals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">enc_outputs_class</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">topk</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># 拿出top-k得分最高的对应的预测bbox:  (bs, k = 300, 4)</span>
</span></span><span class="line"><span class="cl">      <span class="n">topk_coords_unact</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">enc_outputs_coord_unact</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">topk_proposals</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># 注意: 这里取消了梯度</span>
</span></span><span class="line"><span class="cl">      <span class="n">topk_coords_unact</span> <span class="o">=</span> <span class="n">topk_coords_unact</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># 经过sigmoid，变成了归一化形式，这个结果会送到decoder中作为初始的bboxes估计</span>
</span></span><span class="line"><span class="cl">      <span class="n">reference_points</span> <span class="o">=</span> <span class="n">topk_coords_unact</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># init_reference_out = reference_points</span>
</span></span><span class="line"><span class="cl">      <span class="n">init_reference_out</span> <span class="o">=</span> <span class="n">reference_points</span></span></span></code></pre></td></tr></table>
</div>
</div><p>同时，在不使用iterative bbox refine策略的情况下，会使得在第二阶段对解码输出进行分类时都倾向于预测第一个类别(使用iterative bbox refine时，对Decoder每层都有不同的分类预测头部实例，参数不共享，并且在这里会额外使用一个独立的分类预测头部，与应用到Decoder中的不相关)。关于检测头部的设置，代码如下:</p>
<div class="highlight" id="id-14"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 如果使用2-stage， 那么在Decoder 中多加一层(变为7层)，用于第一阶段中proposal的预测输出</span>
</span></span><span class="line"><span class="cl"><span class="c1"># (预测输出实际上由Encoder输出，只不过这里借用一层Decoder来解码形成预测结果，也就是借用了分类和回归预测的头部)</span>
</span></span><span class="line"><span class="cl"><span class="n">num_pred</span> <span class="o">=</span> <span class="p">(</span><span class="n">transformer</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">two_stage</span> <span class="k">else</span> <span class="n">transformer</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">num_layers</span>
</span></span><span class="line"><span class="cl"><span class="s2">&#34;&#34;&#34;在iterative box refine策略下，_get_clones得到的每个模块都是不同的实例，参数不共享；
</span></span></span><span class="line"><span class="cl"><span class="s2">  而不使用该策略时， nn.ModuleList中每个都是相同的实例，即参数共享&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl"><span class="c1"># TODO: 以下bbox head的bias的后两个初始化为-2.0是为何？</span>
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="n">with_box_refine</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 如果使用迭代的bbox校正策略，则Decoder各层参数不共享，因此这里用_get_clones(deepcopy)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="bp">self</span><span class="o">.</span><span class="n">class_embed</span> <span class="o">=</span> <span class="n">_get_clones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">class_embed</span><span class="p">,</span> <span class="n">num_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="bp">self</span><span class="o">.</span><span class="n">bbox_embed</span> <span class="o">=</span> <span class="n">_get_clones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bbox_embed</span><span class="p">,</span> <span class="n">num_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bbox_embed</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">2</span><span class="p">:],</span> <span class="o">-</span><span class="mf">2.0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># hack implementation for iterative bounding box refinement</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 默认情况下， Decoder的bbox_embed设置为None，因此只有使用iterative bbox refinement策略时，</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 其bbox_embed才不是None； 在使用iterative bbox refine时，Decoder每层都会预测bbox偏移量，</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 使用这个偏移量对上一层的预测输出进行校正</span>
</span></span><span class="line"><span class="cl">  <span class="bp">self</span><span class="o">.</span><span class="n">transformer</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">bbox_embed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bbox_embed</span>
</span></span><span class="line"><span class="cl"><span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">  <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">contant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bbox_embed</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">2</span><span class="p">:],</span> <span class="o">-</span><span class="mf">2.0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 不使用iterative bbox refine 策略，则各层参数共享</span>
</span></span><span class="line"><span class="cl">  <span class="bp">self</span><span class="o">.</span><span class="n">class_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">class_embed</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_pred</span><span class="p">)])</span>
</span></span><span class="line"><span class="cl">  <span class="bp">self</span><span class="o">.</span><span class="n">bbox_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">bbox_embed</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_pred</span><span class="p">)])</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 不用iterative bbox refine策略， 则Decoder的bbox_embed设置为None</span>
</span></span><span class="line"><span class="cl">  <span class="bp">self</span><span class="o">.</span><span class="n">transofmer</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">bbox_embed</span> <span class="o">=</span> <span class="kc">None</span></span></span></code></pre></td></tr></table>
</div>
</div><p>紧接着pipeline:</p>
<div class="highlight" id="id-15"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">  <span class="n">reference_points</span> <span class="o">=</span> <span class="n">topk_coords_unact</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># init_reference_out = reference_points</span>
</span></span><span class="line"><span class="cl">  <span class="n">init_reference_out</span> <span class="o">=</span> <span class="n">reference_points</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;&#34;&#34;
</span></span></span><span class="line"><span class="cl"><span class="s2">  生成的Decoder的query(target)和query embedding:
</span></span></span><span class="line"><span class="cl"><span class="s2">    - 对于top-k proposal boxes进行位置编码，编码方式是给xywh每个都赋予128维，
</span></span></span><span class="line"><span class="cl"><span class="s2">    其中每128维中，偶数维度用sin函数，奇数维度用cos函数编码；
</span></span></span><span class="line"><span class="cl"><span class="s2">    然后经过全连接层和归一化处理；
</span></span></span><span class="line"><span class="cl"><span class="s2">    最终， 前256维结果对应xy作为Decoder 的query embedding(因为xy代表的是位置信息)
</span></span></span><span class="line"><span class="cl"><span class="s2">  &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">  <span class="c1">#(bs, k = 300, 4 x 128 = 512)</span>
</span></span><span class="line"><span class="cl">  <span class="n">pos_trans_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_trans_norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pos_trans</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_proposal_pos_embed</span><span class="p">(</span><span class="n">topk_coords_unact</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># (bs, k = 300, 256), (bs, k = 300, 256)</span>
</span></span><span class="line"><span class="cl">  <span class="n">query_embed</span><span class="p">,</span> <span class="n">tgt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">pos_trans_out</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 仅为了与2-stage的情况兼容</span>
</span></span><span class="line"><span class="cl">  <span class="n">enc_output_class</span> <span class="o">=</span> <span class="n">enc_outputs_coord_unact</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># (n_query = 300, 256) (n_query = 300, 256)</span>
</span></span><span class="line"><span class="cl">  <span class="n">query_embed</span><span class="p">,</span> <span class="n">tgt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">query_embed</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># (bs, n_query = 300, 256)</span>
</span></span><span class="line"><span class="cl">  <span class="n">query_embed</span> <span class="o">=</span> <span class="n">query_embed</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># (bs, n_query = 300, 256)</span>
</span></span><span class="line"><span class="cl">  <span class="n">tgt</span> <span class="o">=</span> <span class="n">tgt</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 通过全连接层生成proposal参考点的归一化坐标(cx, cy) : (bs, n_query = 300, 2)</span>
</span></span><span class="line"><span class="cl">  <span class="n">reference_points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference_points</span><span class="p">(</span><span class="n">query_embed</span><span class="p">)</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">  <span class="n">init_reference_out</span> <span class="o">=</span> <span class="n">reference_points</span></span></span></code></pre></td></tr></table>
</div>
</div><p><strong>4). Decoder解码特征并输出参考点</strong></p>
<p>若使用了iterative bbox refine策略，则Decoder每层都会预测bbox，这些bbox就会作为新一轮的参考点供下一层使用，相当于coarse-to-fine的过程，不断地对参考点进行校正，最终会返回最后一层的校正结果。</p>
<p>由此可知，即便不是2-stage模式，只要使用了iterative bbox refine策略，这里返回的参考点也会变为4d的形式。因为检测头部的回归分支预测出来的结果是4d(xywh)形式的，而且是相对于参考点的偏移量(并非绝对坐标位置)。如果初始进来的参考点是2d的，那么wh就仅由检测头部的预测结果决定。</p>
<p>相对地，如果没有使用iterative bbox refine策略，那么这里返回的参考点和初始输进来的一样，保持不变。</p>
<div class="highlight" id="id-16"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">  <span class="c1"># decoder</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># hs: (n_dec_layers, bs, n_query=300, d_model=256);</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># itner_references: with iterative bbox refine - (n_dec_layers, bs, k = 300, 4)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># otherwise - (n_dec_layers, bs, k = 300, 2)</span>
</span></span><span class="line"><span class="cl">  <span class="n">hs</span><span class="p">,</span> <span class="n">inter_references</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">tgt</span><span class="p">,</span> <span class="n">reference_points</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                      <span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">level_start_index</span><span class="p">,</span> <span class="n">valid_ratios</span><span class="p">,</span> <span class="n">query_embed</span><span class="p">,</span> <span class="n">mask_flatten</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="n">inter_references_out</span> <span class="o">=</span> <span class="n">inter_references</span>
</span></span><span class="line"><span class="cl">  <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">two_stage</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="k">return</span> <span class="n">hs</span><span class="p">,</span> <span class="n">init_reference_out</span><span class="p">,</span> <span class="n">inter_references_out</span><span class="p">,</span> <span class="n">enc_outputs_class</span><span class="p">,</span> <span class="n">enc_outputs_coord_unact</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 1-stage情况下:  enc_outputs_class 和 enc_outputs_coord_unact 都是None</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">hs</span><span class="p">,</span> <span class="n">init_reference_out</span><span class="p">,</span> <span class="n">inter_references_out</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span></span></span></code></pre></td></tr></table>
</div>
</div><p><strong>5). 输出解码特征和参考点</strong></p>
<p>这里输出的参考点有两个，包括初始进入Decoder前的和Decoder返回的。在上一步也说过，如果没有使用iterative bbox refine策略，则两者是一样的。</p>
<h3 id="44encoder">4.4、Encoder</h3>
<p>这里的Encoder与Transformer中最主要的区别在于使用<strong>可变形注意力</strong>替代了原生的自注意力。类似地，在每层编码时会将上一层输出的编码特征作为下一层的输入，这个输入与position emebdding结合作为query、而经过线性变换则作为value。</p>
<div class="highlight" id="id-17"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">level_start_index</span><span class="p">,</span> <span class="n">valid_ratios</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 这里的pos是position embedding + scale-level embedding</span>
</span></span><span class="line"><span class="cl">  <span class="n">output</span> <span class="o">=</span> <span class="n">src</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 将各特征点在其所在特征层的归一化坐标映射到所有特征层，使得每个特征点在所有特征层上都会得到一个归一化的坐标</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 这个reference_points 相当于key的角色， 从而每个query都会和其在所有特征层的位置(也就是以下计算出来的坐标)进行交互</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 实现了跨尺度融合的效果，因此不需要FPN</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># (bs, H_lvl1 * W_lvl1 + H_lvl2 * W_lvl2 + ..., n_lvl, 2)</span>
</span></span><span class="line"><span class="cl">  <span class="n">reference_points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_reference_points</span><span class="p">(</span><span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">valid_ratios</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">src</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">      <span class="n">output</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">reference_points</span><span class="p">,</span> <span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">level_start_index</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">output</span></span></span></code></pre></td></tr></table>
</div>
</div><p>现在具体来看看主要有哪些过程:</p>
<p><strong>i). 计算参考点的位置</strong></p>
<p>这里的参考点实质就是多尺度特征点的归一化坐标。注意，每个特征点在所有特征层都会计算出一个对应的归一化坐标(后文会谈到为何这样做)。</p>
<div class="highlight" id="id-18"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">get_reference_points</span><span class="p">(</span><span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">valid_ratios</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="n">reference_points_list</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="n">lvl</span><span class="p">,</span> <span class="p">(</span><span class="n">H_</span><span class="p">,</span> <span class="n">W_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">spatial_shapes</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (H_, W_), (H_, W_)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 0.5 是为对应到特征点中心</span>
</span></span><span class="line"><span class="cl">    <span class="n">ref_y</span><span class="p">,</span> <span class="n">ref_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">H_</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">H_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                                  <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">W_</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">W_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;将各层特征图每个特征点中心坐标根据特征图非padding的边长进行归一化(可能大于1)&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (1, H_*W_) / (bs, 1) 后一项是特征图有效(非padding)部分的高</span>
</span></span><span class="line"><span class="cl">    <span class="n">ref_y</span> <span class="o">=</span> <span class="n">ref_y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="kc">None</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">valid_ratios</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">lvl</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">H_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (1, H_*W_) / (bs, 1) 后一项是特征图有效(非padding)部分的宽</span>
</span></span><span class="line"><span class="cl">    <span class="n">ref_x</span> <span class="o">=</span> <span class="n">ref_x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="kc">None</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">valid_ratios</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">lvl</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">W_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (bs, H_*W_, 2) 每一项是xy</span>
</span></span><span class="line"><span class="cl">    <span class="n">ref</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">ref_x</span><span class="p">,</span> <span class="n">ref_y</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">reference_points_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ref</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># (bs, H_lvl1 * W_lvl1 + H_lvl2 * W_lvl2 + ..., 2)</span>
</span></span><span class="line"><span class="cl">  <span class="n">reference_points</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">reference_points_list</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;&#34;&#34;将各特征点在其所在特征层的归一化坐标映射(扩散)到所有特征层， 这样每个特征点在所有特征层上都会得到一个归一化坐标&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># TODO: 以下这样貌似不妥， 如果各特征层对应的valid_ratio不一致，</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># TODO: 则坐标值有可能大于1， 而后续没有再对这里的reference_points进行归一化到 0~1</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># (bs, H_lvl1 * W_lvl1 + H_lvl2 * W_lvl2 + ..., 1, 2) * (bs, 1, n_lvl, 2)</span>
</span></span><span class="line"><span class="cl">  <span class="n">reference_points</span> <span class="o">=</span> <span class="n">reference_points</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">valid_ratios</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># (bs, H_lvl1 * W_lvl1 + H_lvl2 * W_lvl2 + ..., n_lvl, 2)</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">reference_points</span></span></span></code></pre></td></tr></table>
</div>
</div><p>通过源码发现有个小问题: <strong>这里在对坐标归一化时使用的是非padding部分的特征图边长</strong>，而不同层非padding部分的边长比例有可能由于计算时的舍入误差而不一致，从而导致最终归一化后的坐标值大于1。</p>
<p>ii). self-attention</p>
<p>使用(多尺度)可变形注意力模块替代原生的Transformer自注意力，query和value均来自特征图，只不过query要结合position embedding，注意，<strong>这里的position embedding实质是position emebedding + scale-level emebedding</strong>。</p>
<p>iii). feed-forward network</p>
<p>前向反馈网络，和Transformer中的一致: 由全连接层、激活函数、Dropout、残差连接以及层归一化(LayerNorm)组成。</p>
<div class="highlight" id="id-19"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">reference_points</span><span class="p">,</span> <span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">level_start_index</span><span class="p">,</span> <span class="n">padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="s2">&#34;&#34;&#34;Deformable DETR的Encoder也是由self-attention + FNN组成
</span></span></span><span class="line"><span class="cl"><span class="s2">    只不过这里self-attention使用Multi-Scale Deformable Attention， 并且位置编码加入了scale-level embedding
</span></span></span><span class="line"><span class="cl"><span class="s2">  &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># self attention</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 这里的pos是position embedding + scale-level embedding</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># padding_mask 就是指示各特征图哪些位置是原图padding的</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># reference_points 就是每个特征点本身中心的位置(归一化坐标): (bs, H_lvl1 * W_lvl1 + H_lvl2 * W_lvl2 + ..., n_lvl, 2)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 注意一个特征点不仅在其所有特征层有个坐标， 而且还在其他特征层也都分别映射了一个坐标</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># self attention</span>
</span></span><span class="line"><span class="cl">  <span class="n">src2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">with_pos_embed</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">pos</span><span class="p">),</span> <span class="n">reference_points</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">level_start_index</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">src</span> <span class="o">=</span> <span class="n">src</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">src2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">src</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1"># ffn</span>
</span></span><span class="line"><span class="cl">  <span class="n">src</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_ffn</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">src</span></span></span></code></pre></td></tr></table>
</div>
</div><p><strong>DECODER</strong>详细代码注释如下，iterative bounding box refinement和two stage改进方法的Encoder不变。</p>
<div class="highlight" id="id-20"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">DeformableTransformerEncoderLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">d_model</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">d_ffn</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&#34;relu&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">n_levels</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">n_points</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># self attention</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span> <span class="o">=</span> <span class="n">MSDeformAttn</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_levels</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span> <span class="n">n_points</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># ffn</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_ffn</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">_get_activation_fn</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_ffn</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">dropout3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nd">@staticmethod</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">with_pos_embed</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">pos</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">tensor</span> <span class="k">if</span> <span class="n">pos</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">tensor</span> <span class="o">+</span> <span class="n">pos</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward_ffn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">src2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear1</span><span class="p">(</span><span class="n">src</span><span class="p">))))</span>
</span></span><span class="line"><span class="cl">        <span class="n">src</span> <span class="o">=</span> <span class="n">src</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout3</span><span class="p">(</span><span class="n">src2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">src</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">src</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">reference_points</span><span class="p">,</span> <span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">level_start_index</span><span class="p">,</span> <span class="n">padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># self attention</span>
</span></span><span class="line"><span class="cl">        <span class="n">src2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">with_pos_embed</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">pos</span><span class="p">),</span> <span class="n">reference_points</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">level_start_index</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">src</span> <span class="o">=</span> <span class="n">src</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">src2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">src</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># ffn</span>
</span></span><span class="line"><span class="cl">        <span class="n">src</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_ffn</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">src</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">DeformableTransformerEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder_layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">_get_clones</span><span class="p">(</span><span class="n">encoder_layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nd">@staticmethod</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">get_reference_points</span><span class="p">(</span><span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">valid_ratios</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">reference_points_list</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">lvl</span><span class="p">,</span> <span class="p">(</span><span class="n">H_</span><span class="p">,</span> <span class="n">W_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">spatial_shapes</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 从0.5到H-0.5采样H个点，W同理 这个操作的目的也就是为了特征图的对齐</span>
</span></span><span class="line"><span class="cl">            <span class="n">ref_y</span><span class="p">,</span> <span class="n">ref_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">H_</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">H_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                                          <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">W_</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">W_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">            <span class="n">ref_y</span> <span class="o">=</span> <span class="n">ref_y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="kc">None</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">valid_ratios</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">lvl</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">H_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">ref_x</span> <span class="o">=</span> <span class="n">ref_x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="kc">None</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">valid_ratios</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">lvl</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">W_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">ref</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">ref_x</span><span class="p">,</span> <span class="n">ref_y</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">reference_points_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ref</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">reference_points</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">reference_points_list</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">reference_points</span> <span class="o">=</span> <span class="n">reference_points</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">valid_ratios</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">reference_points</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">level_start_index</span><span class="p">,</span> <span class="n">valid_ratios</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span> <span class="o">=</span> <span class="n">src</span>
</span></span><span class="line"><span class="cl">        <span class="n">reference_points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_reference_points</span><span class="p">(</span><span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">valid_ratios</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">src</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">output</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">pos</span><span class="p">,</span> <span class="n">reference_points</span><span class="p">,</span> <span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">level_start_index</span><span class="p">,</span> <span class="n">padding_mask</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">output</span></span></span></code></pre></td></tr></table>
</div>
</div><h3 id="44decoder">4.4、Decoder</h3>
<p>这里与Transformer中主要的区别在于使用可变形注意力替代了原生的交叉注意力。类似地，每层的解码过程是self-attention+cross-attention+ffn，下一层输入的object query是上一层输出的解码特征。</p>
<div class="highlight" id="id-21"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 每一层输入的output是上一层输出的结果，而reference_points_input在使用iterative bbox refine策略时，</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 每层都会对齐进行校正， 因此下一层用到的也是上一层的输出结果</span>
</span></span><span class="line"><span class="cl"><span class="c1"># (bs， n_query=300，hidden_dim=256)</span>
</span></span><span class="line"><span class="cl"><span class="n">output</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">query_pos</span><span class="p">,</span> <span class="n">reference_points_input</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">src_spatial_shapes</span><span class="p">,</span> <span class="n">src_level_start_index</span><span class="p">,</span> <span class="n">src_padding_mask</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div><p>一起具体来看看每层的主要过程:</p>
<p>i). 将参考点坐标映射(re-scales)到各尺度特征层</p>
<p>将每个参考点的坐标分别都乘以各特征层非padding部分边长的比例，使得一个参考点在所有尺度特征层上都有相应的归一化坐标值(后文会谈到为何这样做)。</p>
<div class="highlight" id="id-22"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">reference_points</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">src_spatial_shapes</span><span class="p">,</span> <span class="n">src_level_start_index</span><span class="p">,</span> <span class="n">src_valid_ratios</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">query_pos</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">src_padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 说明一下Decoder一开始得到的tgt, query_pos和reference_points, 分为两种情况:</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 1. 2-stage 模式下，reference_points 是Encoder输出的top-k proposal boxes(并归一化)，最后一维为4</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 而tgt和query_pos由其经过position embedding得到；</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 2. 1-stage 模式下， tgt和query_pos是预设的embedding， reference_points通过这个query_pos经全连接层得到，</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 最后一维为2</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 另外，src是Encoder最终编码输出的特征图，即 memory</span>
</span></span><span class="line"><span class="cl">  <span class="n">output</span> <span class="o">=</span> <span class="n">tgt</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1"># 中间各层(包括头尾)的解码输出</span>
</span></span><span class="line"><span class="cl">  <span class="n">intermediate</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 中间各层(包括头尾)校正的参考点</span>
</span></span><span class="line"><span class="cl">  <span class="n">intermediate_reference_points</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">  <span class="k">for</span> <span class="n">lid</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 2-stage 模式下， 参考点是proposal boxes， 因此最后一维是4</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">reference_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># (bs, k = 300, n_lvl, 4)</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># (bs, k = 300, 1, 4) * (bs, 1, n_lvl, 4)</span>
</span></span><span class="line"><span class="cl">      <span class="n">reference_points_input</span> <span class="o">=</span> <span class="n">reference_points</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span> \
</span></span><span class="line"><span class="cl">                                <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">src_valid_ratios</span><span class="p">,</span> <span class="n">src_valid_ratios</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># 1-stage 模式下 参考点就是通过query embedding 变换而来的中心坐标形式，因此最后一维是2</span>
</span></span><span class="line"><span class="cl">      <span class="k">assert</span> <span class="n">reference_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># (bs, k=300, n_lvl, 2)</span>
</span></span><span class="line"><span class="cl">      <span class="c1"># (bs, k=300, 1, 2) * (bs, 1, n_lvl, 2)</span>
</span></span><span class="line"><span class="cl">      <span class="n">reference_points_input</span> <span class="o">=</span> <span class="n">reference_points</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">src_valid_ratios</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">output</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">query_pos</span><span class="p">,</span> <span class="n">reference_points_input</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">src_spatial_shapes</span><span class="p">,</span> <span class="n">src_level_start_index</span><span class="p">,</span> <span class="n">src_padding_mask</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># hack implementation for iterative bounding box refinement</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bbox_embed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">tmp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bbox_embed</span><span class="p">[</span><span class="n">lid</span><span class="p">](</span><span class="n">output</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">reference_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">new_reference_points</span> <span class="o">=</span> <span class="n">tmp</span> <span class="o">+</span> <span class="n">inverse_sigmoid</span><span class="p">(</span><span class="n">reference_points</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">new_reference_points</span> <span class="o">=</span> <span class="n">new_reference_points</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">assert</span> <span class="n">reference_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl">            <span class="n">new_reference_points</span> <span class="o">=</span> <span class="n">tmp</span>
</span></span><span class="line"><span class="cl">            <span class="n">new_reference_points</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">inverse_sigmoid</span><span class="p">(</span><span class="n">reference_points</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">new_reference_points</span> <span class="o">=</span> <span class="n">new_reference_points</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">reference_points</span> <span class="o">=</span> <span class="n">new_reference_points</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_intermediate</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">intermediate</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">intermediate_reference_points</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reference_points</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_intermediate</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">      <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">intermediate</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">intermediate_reference_points</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">reference_points</span></span></span></code></pre></td></tr></table>
</div>
</div><p>ii). self-attention</p>
<p>这一步是为了学习各个目标之间的关系，query和key都是object query+query embedding，value就是object query(注意不需要位置嵌入哦)。</p>
<div class="highlight" id="id-23"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">query_pos</span><span class="p">,</span> <span class="n">reference_points</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">src_spatial_shapes</span><span class="p">,</span> <span class="n">level_start_index</span><span class="p">,</span> <span class="n">src_padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 若是2-stage， 则tgt 和 query_pos来自Encoder输出的top-k proposal boxes(经过位置嵌入)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 而reference_points 就是这个top-k proposal boxes(归一化)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 否则， tgt和query_pos由预设的embedding产生， 而reference_points由query_pos经过全连接层生成</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="c1"># self attention</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># (bs, k = 300, d_model=256)</span>
</span></span><span class="line"><span class="cl">  <span class="n">q</span> <span class="o">=</span> <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_pos_embed</span><span class="p">(</span><span class="n">tgt</span><span class="p">,</span> <span class="n">query_pos</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># (bs, k = 300, d_model=256) 注意: value就是target本身不需要， 不需要位置编码</span>
</span></span><span class="line"><span class="cl">  <span class="n">tgt2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tgt</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">tgt</span> <span class="o">=</span> <span class="n">tgt</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">tgt2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">tgt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">tgt</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div><p>iii). cross-attention</p>
<p>使用(多尺度)可变形注意力模块替代原生的Transformer交叉注意力，object query来自self-attention层的输出，同时也要加上query embedding；value由Encoder编码的特征经过线性变换得到。</p>
<div class="highlight" id="id-24"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 上续 decoder的 decoder layer forward</span>
</span></span><span class="line"><span class="cl"><span class="c1"># cross attention</span>
</span></span><span class="line"><span class="cl"><span class="c1"># src是Encoder输出的memory， 即编码后的特征(bs, n_feat_points, d_model=256), 其会经过线性变换得到value,</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 这里的tgt来自self-attention的输出，而query_pos依旧如刚传进来Decoder时一样，不变</span>
</span></span><span class="line"><span class="cl"><span class="c1"># reference_points: (bs, k=300, n_feat_lvl, 4 or 2) 在cross-attention中代表key的位置信息</span>
</span></span><span class="line"><span class="cl"><span class="n">tgt2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_attn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">with_pos_embed</span><span class="p">(</span><span class="n">tgt</span><span class="p">,</span> <span class="n">query_pos</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                        <span class="n">reference_points</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                        <span class="n">src</span><span class="p">,</span> <span class="n">src_spatial_shapes</span><span class="p">,</span> <span class="n">level_start_index</span><span class="p">,</span> <span class="n">src_padding_mask</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">tgt</span> <span class="o">=</span> <span class="n">tgt</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">tgt2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">tgt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">tgt</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div><p>iv). feed-forward network
输入来自cross-attention的输出，详细过程就不再阐述了，都是老朋友了~</p>
<div class="highlight" id="id-25"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># ffn</span>
</span></span><span class="line"><span class="cl"><span class="n">tgt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_ffn</span><span class="p">(</span><span class="n">tgt</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">return</span> <span class="n">tgt</span></span></span></code></pre></td></tr></table>
</div>
</div><p>v). iterative bounding box refinement</p>
<p>仅当使用了iterative bbox refine策略时有这一步: 使用bbox检测头部对解码特征进行预测，得到相对于参考点(boxes or points)的偏移量，然后加上参考点坐标(先经过反sigmoid处理，即先从归一化的空间从还原出来)，最后这个结果再经过sigmoid(归一化)得到校正的参考点，供下一层使用(在输入下一层之前会取消梯度，因为这个参考点在各层相当于作为先验的角色)。</p>
<div class="highlight" id="id-26"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># hack implementation for iterative bounding box refinement</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 当使用了iterative bbox refine策略，则这里的bbox_embed就不是None</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 并且会对reference points进行refine， 之后每层的reference points都是前一层校正后的结果(取消了梯度)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 否则，即没有使用iterative bbox refine的话， 那么reference points将永远是一样的</span>
</span></span><span class="line"><span class="cl"><span class="c1"># (来自Encoder输出的proposal boxes或由预设的embedding通过位置编码，需要根据是2-stage还是1-stage的情况而定)</span>
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bbox_embed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># (bs， n_query=300, 4)</span>
</span></span><span class="line"><span class="cl">  <span class="n">tmp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bbox_embed</span><span class="p">[</span><span class="n">lid</span><span class="p">](</span><span class="n">output</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 2-stage 模式</span>
</span></span><span class="line"><span class="cl">  <span class="k">if</span> <span class="n">reference_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># tmp是bbox head输出的(相对参考点也就是proposal boxes)预测偏移量</span>
</span></span><span class="line"><span class="cl">    <span class="n">new_reference_points</span> <span class="o">=</span> <span class="n">tmp</span> <span class="o">+</span> <span class="n">inverse_sigmoid</span><span class="p">(</span><span class="n">reference_points</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (bs，k=300， 4)</span>
</span></span><span class="line"><span class="cl">    <span class="n">new_reference_points</span> <span class="o">=</span> <span class="n">new_reference_points</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">  <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">assert</span> <span class="n">reference_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 注意: 即使是1-stage， 在iterative bbox refine策略下，这里</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 也将reference points最后一维变成4</span>
</span></span><span class="line"><span class="cl">    <span class="n">new_reference_points</span> <span class="o">=</span> <span class="n">tmp</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 1-stage模式下，参考点是特征点中心坐标(最后一维是2)， 因此这里预测的偏移量只需要去前面两维做加法</span>
</span></span><span class="line"><span class="cl">    <span class="n">new_reference_points</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">inverse_sigmoid</span><span class="p">(</span><span class="n">reference_points</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (bs， k=300, 4)</span>
</span></span><span class="line"><span class="cl">    <span class="n">new_reference_points</span> <span class="o">=</span> <span class="n">new_reference_points</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># (bs, k=300, 4)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># 注意:  这里取消了梯度！</span>
</span></span><span class="line"><span class="cl">  <span class="n">reference_points</span> <span class="o">=</span> <span class="n">new_reference_points</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span></span></span></code></pre></td></tr></table>
</div>
</div><p>vi). 输出各层的解码特征和参考点</p>
<div class="highlight" id="id-27"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># DECODER forward()</span>
</span></span><span class="line"><span class="cl">  <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_intermediate</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">intermediate</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">intermediate_reference_points</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reference_points</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_intermediate</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># (n_layers, bs, n_query=300, d_model), (n_layers, bs, k=300, 4 or 2)</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">intermediate</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">intermediate_reference_points</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 这里应该是[output] [reference_points] 这样才兼容return_intermediate的情况，第一个维度对应Decoder的层数</span>
</span></span><span class="line"><span class="cl"><span class="c1"># return output, reference_points</span>
</span></span><span class="line"><span class="cl"><span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">reference_points</span></span></span></code></pre></td></tr></table>
</div>
</div><p><strong>DECODER</strong>详细代码注释如下，这里要控制是否使用iterative bounding box refinement和two stage技巧。iterative bounding box refinement其实就是对参考点的位置进行微调。two stage方法其实就是通过参考点直接生成anchor但是只取最高置信度的前几个，然后再送入decoder进行调整。intermediate数组是一个trick，每层Decoder都是可以输出bbox和分类信息的，如果都利用起来算损失则成为auxiliary loss。</p>
<div class="highlight" id="id-28"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">DeformableTransformerDecoderLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">d_ffn</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&#34;relu&#34;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">n_levels</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_heads</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">n_points</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># cross attention</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">cross_attn</span> <span class="o">=</span> <span class="n">MSDeformAttn</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_levels</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span> <span class="n">n_points</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># self attention</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">n_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># ffn</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_ffn</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">_get_activation_fn</span><span class="p">(</span><span class="n">activation</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">dropout3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_ffn</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">dropout4</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">norm3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nd">@staticmethod</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">with_pos_embed</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">pos</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">tensor</span> <span class="k">if</span> <span class="n">pos</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">tensor</span> <span class="o">+</span> <span class="n">pos</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward_ffn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tgt</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">tgt2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout3</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear1</span><span class="p">(</span><span class="n">tgt</span><span class="p">))))</span>
</span></span><span class="line"><span class="cl">        <span class="n">tgt</span> <span class="o">=</span> <span class="n">tgt</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout4</span><span class="p">(</span><span class="n">tgt2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">tgt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm3</span><span class="p">(</span><span class="n">tgt</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">tgt</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">query_pos</span><span class="p">,</span> <span class="n">reference_points</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">src_spatial_shapes</span><span class="p">,</span> <span class="n">level_start_index</span><span class="p">,</span> <span class="n">src_padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># self attention</span>
</span></span><span class="line"><span class="cl">        <span class="n">q</span> <span class="o">=</span> <span class="n">k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">with_pos_embed</span><span class="p">(</span><span class="n">tgt</span><span class="p">,</span> <span class="n">query_pos</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">tgt2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">self_attn</span><span class="p">(</span><span class="n">q</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">k</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">tgt</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">tgt</span> <span class="o">=</span> <span class="n">tgt</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout2</span><span class="p">(</span><span class="n">tgt2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">tgt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm2</span><span class="p">(</span><span class="n">tgt</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># cross attention</span>
</span></span><span class="line"><span class="cl">        <span class="n">tgt2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_attn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">with_pos_embed</span><span class="p">(</span><span class="n">tgt</span><span class="p">,</span> <span class="n">query_pos</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                               <span class="n">reference_points</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                               <span class="n">src</span><span class="p">,</span> <span class="n">src_spatial_shapes</span><span class="p">,</span> <span class="n">level_start_index</span><span class="p">,</span> <span class="n">src_padding_mask</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">tgt</span> <span class="o">=</span> <span class="n">tgt</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout1</span><span class="p">(</span><span class="n">tgt2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">tgt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm1</span><span class="p">(</span><span class="n">tgt</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># ffn</span>
</span></span><span class="line"><span class="cl">        <span class="n">tgt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_ffn</span><span class="p">(</span><span class="n">tgt</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">tgt</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">DeformableTransformerDecoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">decoder_layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">return_intermediate</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">_get_clones</span><span class="p">(</span><span class="n">decoder_layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">return_intermediate</span> <span class="o">=</span> <span class="n">return_intermediate</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># hack implementation for iterative bounding box refinement and two-stage Deformable DETR</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">bbox_embed</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">class_embed</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">reference_points</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">src_spatial_shapes</span><span class="p">,</span> <span class="n">src_level_start_index</span><span class="p">,</span> <span class="n">src_valid_ratios</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">query_pos</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">src_padding_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span> <span class="o">=</span> <span class="n">tgt</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># 用来存储中间decoder输出的 可以考虑是否用auxiliary loss</span>
</span></span><span class="line"><span class="cl">        <span class="n">intermediate</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="n">intermediate_reference_points</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">lid</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">reference_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">reference_points_input</span> <span class="o">=</span> <span class="n">reference_points</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span> \
</span></span><span class="line"><span class="cl">                                         <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">src_valid_ratios</span><span class="p">,</span> <span class="n">src_valid_ratios</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">assert</span> <span class="n">reference_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl">                <span class="n">reference_points_input</span> <span class="o">=</span> <span class="n">reference_points</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">src_valid_ratios</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="n">output</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">query_pos</span><span class="p">,</span> <span class="n">reference_points_input</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">src_spatial_shapes</span><span class="p">,</span> <span class="n">src_level_start_index</span><span class="p">,</span> <span class="n">src_padding_mask</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="c1"># hack implementation for iterative bounding box refinement</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># iterative refinement是对decoder中的参考点进行微调，类似cascade rcnn思想</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">bbox_embed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">tmp</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bbox_embed</span><span class="p">[</span><span class="n">lid</span><span class="p">](</span><span class="n">output</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="n">reference_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                    <span class="n">new_reference_points</span> <span class="o">=</span> <span class="n">tmp</span> <span class="o">+</span> <span class="n">inverse_sigmoid</span><span class="p">(</span><span class="n">reference_points</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                    <span class="n">new_reference_points</span> <span class="o">=</span> <span class="n">new_reference_points</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">                <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                    <span class="k">assert</span> <span class="n">reference_points</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl">                    <span class="n">new_reference_points</span> <span class="o">=</span> <span class="n">tmp</span>
</span></span><span class="line"><span class="cl">                    <span class="n">new_reference_points</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">inverse_sigmoid</span><span class="p">(</span><span class="n">reference_points</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                    <span class="n">new_reference_points</span> <span class="o">=</span> <span class="n">new_reference_points</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">                <span class="n">reference_points</span> <span class="o">=</span> <span class="n">new_reference_points</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_intermediate</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">intermediate</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">intermediate_reference_points</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reference_points</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">return_intermediate</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">intermediate</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">intermediate_reference_points</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">reference_points</span></span></span></code></pre></td></tr></table>
</div>
</div><h3 id="45deformable-transformer">4.5、Deformable Transformer</h3>
<p>综合模块代码如下</p>
<div class="highlight" id="id-29"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span><span class="lnt">118
</span><span class="lnt">119
</span><span class="lnt">120
</span><span class="lnt">121
</span><span class="lnt">122
</span><span class="lnt">123
</span><span class="lnt">124
</span><span class="lnt">125
</span><span class="lnt">126
</span><span class="lnt">127
</span><span class="lnt">128
</span><span class="lnt">129
</span><span class="lnt">130
</span><span class="lnt">131
</span><span class="lnt">132
</span><span class="lnt">133
</span><span class="lnt">134
</span><span class="lnt">135
</span><span class="lnt">136
</span><span class="lnt">137
</span><span class="lnt">138
</span><span class="lnt">139
</span><span class="lnt">140
</span><span class="lnt">141
</span><span class="lnt">142
</span><span class="lnt">143
</span><span class="lnt">144
</span><span class="lnt">145
</span><span class="lnt">146
</span><span class="lnt">147
</span><span class="lnt">148
</span><span class="lnt">149
</span><span class="lnt">150
</span><span class="lnt">151
</span><span class="lnt">152
</span><span class="lnt">153
</span><span class="lnt">154
</span><span class="lnt">155
</span><span class="lnt">156
</span><span class="lnt">157
</span><span class="lnt">158
</span><span class="lnt">159
</span><span class="lnt">160
</span><span class="lnt">161
</span><span class="lnt">162
</span><span class="lnt">163
</span><span class="lnt">164
</span><span class="lnt">165
</span><span class="lnt">166
</span><span class="lnt">167
</span><span class="lnt">168
</span><span class="lnt">169
</span><span class="lnt">170
</span><span class="lnt">171
</span><span class="lnt">172
</span><span class="lnt">173
</span><span class="lnt">174
</span><span class="lnt">175
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">DeformableTransformer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">nhead</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">num_encoder_layers</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">num_decoder_layers</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">dim_feedforward</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">activation</span><span class="o">=</span><span class="s2">&#34;relu&#34;</span><span class="p">,</span> <span class="n">return_intermediate_dec</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">num_feature_levels</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">dec_n_points</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>  <span class="n">enc_n_points</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">two_stage</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">two_stage_num_proposals</span><span class="o">=</span><span class="mi">300</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">nhead</span> <span class="o">=</span> <span class="n">nhead</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">two_stage</span> <span class="o">=</span> <span class="n">two_stage</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">two_stage_num_proposals</span> <span class="o">=</span> <span class="n">two_stage_num_proposals</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">encoder_layer</span> <span class="o">=</span> <span class="n">DeformableTransformerEncoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">dim_feedforward</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                          <span class="n">dropout</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                          <span class="n">num_feature_levels</span><span class="p">,</span> <span class="n">nhead</span><span class="p">,</span> <span class="n">enc_n_points</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">DeformableTransformerEncoder</span><span class="p">(</span><span class="n">encoder_layer</span><span class="p">,</span> <span class="n">num_encoder_layers</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">decoder_layer</span> <span class="o">=</span> <span class="n">DeformableTransformerDecoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">dim_feedforward</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                          <span class="n">dropout</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                          <span class="n">num_feature_levels</span><span class="p">,</span> <span class="n">nhead</span><span class="p">,</span> <span class="n">dec_n_points</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">DeformableTransformerDecoder</span><span class="p">(</span><span class="n">decoder_layer</span><span class="p">,</span> <span class="n">num_decoder_layers</span><span class="p">,</span> <span class="n">return_intermediate_dec</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">level_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">num_feature_levels</span><span class="p">,</span> <span class="n">d_model</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">two_stage</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">enc_output</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">enc_output_norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">pos_trans</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">d_model</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">pos_trans_norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">d_model</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">reference_points</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">_reset_parameters</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">_reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_uniform_</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">MSDeformAttn</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                <span class="n">m</span><span class="o">.</span><span class="n">_reset_parameters</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">two_stage</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">xavier_uniform_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reference_points</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">gain</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">constant_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reference_points</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="mf">0.</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">normal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">level_embed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">get_proposal_pos_embed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">proposals</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">num_pos_feats</span> <span class="o">=</span> <span class="mi">128</span>
</span></span><span class="line"><span class="cl">        <span class="n">temperature</span> <span class="o">=</span> <span class="mi">10000</span>
</span></span><span class="line"><span class="cl">        <span class="n">scale</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">pi</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">dim_t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">num_pos_feats</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">proposals</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">dim_t</span> <span class="o">=</span> <span class="n">temperature</span> <span class="o">**</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">dim_t</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_pos_feats</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># N, L, 4</span>
</span></span><span class="line"><span class="cl">        <span class="n">proposals</span> <span class="o">=</span> <span class="n">proposals</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span> <span class="o">*</span> <span class="n">scale</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># N, L, 4, 128</span>
</span></span><span class="line"><span class="cl">        <span class="n">pos</span> <span class="o">=</span> <span class="n">proposals</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">/</span> <span class="n">dim_t</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># N, L, 4, 64, 2</span>
</span></span><span class="line"><span class="cl">        <span class="n">pos</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">pos</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">sin</span><span class="p">(),</span> <span class="n">pos</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">cos</span><span class="p">()),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">pos</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">gen_encoder_output_proposals</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span> <span class="n">memory_padding_mask</span><span class="p">,</span> <span class="n">spatial_shapes</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">N_</span><span class="p">,</span> <span class="n">S_</span><span class="p">,</span> <span class="n">C_</span> <span class="o">=</span> <span class="n">memory</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">        <span class="n">base_scale</span> <span class="o">=</span> <span class="mf">4.0</span>
</span></span><span class="line"><span class="cl">        <span class="n">proposals</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="n">_cur</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">lvl</span><span class="p">,</span> <span class="p">(</span><span class="n">H_</span><span class="p">,</span> <span class="n">W_</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">spatial_shapes</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">mask_flatten_</span> <span class="o">=</span> <span class="n">memory_padding_mask</span><span class="p">[:,</span> <span class="n">_cur</span><span class="p">:(</span><span class="n">_cur</span> <span class="o">+</span> <span class="n">H_</span> <span class="o">*</span> <span class="n">W_</span><span class="p">)]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N_</span><span class="p">,</span> <span class="n">H_</span><span class="p">,</span> <span class="n">W_</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">valid_H</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">~</span><span class="n">mask_flatten_</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">valid_W</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">~</span><span class="n">mask_flatten_</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">grid_y</span><span class="p">,</span> <span class="n">grid_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">H_</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">H_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">memory</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                                            <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">W_</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">W_</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">memory</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">            <span class="n">grid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">grid_x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">grid_y</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">scale</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">valid_W</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">valid_H</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)],</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N_</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">grid</span> <span class="o">=</span> <span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">N_</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">/</span> <span class="n">scale</span>
</span></span><span class="line"><span class="cl">            <span class="n">wh</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">grid</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.05</span> <span class="o">*</span> <span class="p">(</span><span class="mf">2.0</span> <span class="o">**</span> <span class="n">lvl</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">proposal</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">grid</span><span class="p">,</span> <span class="n">wh</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">N_</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">proposals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">proposal</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">_cur</span> <span class="o">+=</span> <span class="p">(</span><span class="n">H_</span> <span class="o">*</span> <span class="n">W_</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">output_proposals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">proposals</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">output_proposals_valid</span> <span class="o">=</span> <span class="p">((</span><span class="n">output_proposals</span> <span class="o">&gt;</span> <span class="mf">0.01</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">output_proposals</span> <span class="o">&lt;</span> <span class="mf">0.99</span><span class="p">))</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">output_proposals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">output_proposals</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">output_proposals</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">output_proposals</span> <span class="o">=</span> <span class="n">output_proposals</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">memory_padding_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">output_proposals</span> <span class="o">=</span> <span class="n">output_proposals</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="o">~</span><span class="n">output_proposals_valid</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">output_memory</span> <span class="o">=</span> <span class="n">memory</span>
</span></span><span class="line"><span class="cl">        <span class="n">output_memory</span> <span class="o">=</span> <span class="n">output_memory</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">memory_padding_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="nb">float</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">output_memory</span> <span class="o">=</span> <span class="n">output_memory</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="o">~</span><span class="n">output_proposals_valid</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">output_memory</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_output_norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_output</span><span class="p">(</span><span class="n">output_memory</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">output_memory</span><span class="p">,</span> <span class="n">output_proposals</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">get_valid_ratio</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">_</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">        <span class="n">valid_H</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">~</span><span class="n">mask</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">valid_W</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">~</span><span class="n">mask</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">valid_ratio_h</span> <span class="o">=</span> <span class="n">valid_H</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">/</span> <span class="n">H</span>
</span></span><span class="line"><span class="cl">        <span class="n">valid_ratio_w</span> <span class="o">=</span> <span class="n">valid_W</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">/</span> <span class="n">W</span>
</span></span><span class="line"><span class="cl">        <span class="n">valid_ratio</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">valid_ratio_w</span><span class="p">,</span> <span class="n">valid_ratio_h</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">valid_ratio</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">srcs</span><span class="p">,</span> <span class="n">masks</span><span class="p">,</span> <span class="n">pos_embeds</span><span class="p">,</span> <span class="n">query_embed</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">two_stage</span> <span class="ow">or</span> <span class="n">query_embed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># prepare input for encoder</span>
</span></span><span class="line"><span class="cl">        <span class="n">src_flatten</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="n">mask_flatten</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="n">lvl_pos_embed_flatten</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="n">spatial_shapes</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">lvl</span><span class="p">,</span> <span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">pos_embed</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">srcs</span><span class="p">,</span> <span class="n">masks</span><span class="p">,</span> <span class="n">pos_embeds</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 得到每一层feature map的batch size 通道数量 高宽</span>
</span></span><span class="line"><span class="cl">            <span class="n">bs</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">src</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">            <span class="n">spatial_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">spatial_shapes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">spatial_shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 将每层的feature map、mask、位置编码拉平，并且加入到相关数组中</span>
</span></span><span class="line"><span class="cl">            <span class="n">src</span> <span class="o">=</span> <span class="n">src</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">pos_embed</span> <span class="o">=</span> <span class="n">pos_embed</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 位置编码和可学习的每层编码相加，表征类似 3D position</span>
</span></span><span class="line"><span class="cl">            <span class="n">lvl_pos_embed</span> <span class="o">=</span> <span class="n">pos_embed</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">level_embed</span><span class="p">[</span><span class="n">lvl</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">lvl_pos_embed_flatten</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lvl_pos_embed</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">src_flatten</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">mask_flatten</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 在hidden_dim维度上进行拼接，也就是number token数量一样的那个维度</span>
</span></span><span class="line"><span class="cl">        <span class="n">src_flatten</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">src_flatten</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">mask_flatten</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">mask_flatten</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">lvl_pos_embed_flatten</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">lvl_pos_embed_flatten</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">spatial_shapes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">src_flatten</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 记录每个level开始的索引以及有效的长宽(因为有mask存在，raw image的分辨率可能不统一) 具体查看get_valid_ratio函数</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># prod(1)计算h*w，cumsum(0)计算前缀和</span>
</span></span><span class="line"><span class="cl">        <span class="n">level_start_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">spatial_shapes</span><span class="o">.</span><span class="n">new_zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="p">)),</span> <span class="n">spatial_shapes</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="mi">0</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl">        <span class="n">valid_ratios</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">get_valid_ratio</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">masks</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># encoder</span>
</span></span><span class="line"><span class="cl">        <span class="n">memory</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">src_flatten</span><span class="p">,</span> <span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">level_start_index</span><span class="p">,</span> <span class="n">valid_ratios</span><span class="p">,</span> <span class="n">lvl_pos_embed_flatten</span><span class="p">,</span> <span class="n">mask_flatten</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># prepare input for decoder</span>
</span></span><span class="line"><span class="cl">        <span class="n">bs</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">memory</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 是否使用两阶段模式</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">two_stage</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">output_memory</span><span class="p">,</span> <span class="n">output_proposals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gen_encoder_output_proposals</span><span class="p">(</span><span class="n">memory</span><span class="p">,</span> <span class="n">mask_flatten</span><span class="p">,</span> <span class="n">spatial_shapes</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="c1"># hack implementation for two-stage Deformable DETR</span>
</span></span><span class="line"><span class="cl">            <span class="n">enc_outputs_class</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">class_embed</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">num_layers</span><span class="p">](</span><span class="n">output_memory</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">enc_outputs_coord_unact</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">bbox_embed</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">num_layers</span><span class="p">](</span><span class="n">output_memory</span><span class="p">)</span> <span class="o">+</span> <span class="n">output_proposals</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">topk</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">two_stage_num_proposals</span>
</span></span><span class="line"><span class="cl">            <span class="n">topk_proposals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">enc_outputs_class</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">topk</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="n">topk_coords_unact</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">enc_outputs_coord_unact</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">topk_proposals</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">            <span class="n">topk_coords_unact</span> <span class="o">=</span> <span class="n">topk_coords_unact</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">reference_points</span> <span class="o">=</span> <span class="n">topk_coords_unact</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">init_reference_out</span> <span class="o">=</span> <span class="n">reference_points</span>
</span></span><span class="line"><span class="cl">            <span class="n">pos_trans_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_trans_norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pos_trans</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">get_proposal_pos_embed</span><span class="p">(</span><span class="n">topk_coords_unact</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">            <span class="n">query_embed</span><span class="p">,</span> <span class="n">tgt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">pos_trans_out</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 这是非双阶段版本的Deformable DETR</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 将query_embed划分为query_embed和tgt两部分</span>
</span></span><span class="line"><span class="cl">            <span class="n">query_embed</span><span class="p">,</span> <span class="n">tgt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">query_embed</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 复制bs份</span>
</span></span><span class="line"><span class="cl">            <span class="n">query_embed</span> <span class="o">=</span> <span class="n">query_embed</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">tgt</span> <span class="o">=</span> <span class="n">tgt</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># nn.Linear得到每个object queries对应的reference point, 这是decoder参考点的方法!!!</span>
</span></span><span class="line"><span class="cl">            <span class="n">reference_points</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reference_points</span><span class="p">(</span><span class="n">query_embed</span><span class="p">)</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">init_reference_out</span> <span class="o">=</span> <span class="n">reference_points</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># decoder</span>
</span></span><span class="line"><span class="cl">        <span class="n">hs</span><span class="p">,</span> <span class="n">inter_references</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">tgt</span><span class="p">,</span> <span class="n">reference_points</span><span class="p">,</span> <span class="n">memory</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                            <span class="n">spatial_shapes</span><span class="p">,</span> <span class="n">level_start_index</span><span class="p">,</span> <span class="n">valid_ratios</span><span class="p">,</span> <span class="n">query_embed</span><span class="p">,</span> <span class="n">mask_flatten</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">inter_references_out</span> <span class="o">=</span> <span class="n">inter_references</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">two_stage</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">hs</span><span class="p">,</span> <span class="n">init_reference_out</span><span class="p">,</span> <span class="n">inter_references_out</span><span class="p">,</span> <span class="n">enc_outputs_class</span><span class="p">,</span> <span class="n">enc_outputs_coord_unact</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">hs</span><span class="p">,</span> <span class="n">init_reference_out</span><span class="p">,</span> <span class="n">inter_references_out</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span></span></span></code></pre></td></tr></table>
</div>
</div><h2 id="5experiment">5、Experiment</h2>
<p></p>
<p>由图4可知，Deformable DETR不仅收敛速率比DETR快并且小目标精度也高了许多。</p>
<h2 id="6改进策略">6、改进策略</h2>
<p>Deformable DETR是怎么让DCN和Transformer一起玩的，CW在上述已基本解析完毕。无奈作者还研究了“高配版”的Deformable DETR，涉及两个提升性能的策略: iterative bounding box refinement &amp; two-stage。</p>
<p><strong>a. Iterative Bounding Box Refinement</strong></p>
<p>字面意思就是迭代地对bbox进行校正，类似于cascaded head，实质上也是coarse-to-fine不断校正的一个过程。第d层Decoder校正后归一化的bbox用公式表示如下:</p>
<p>$$\hat{b}<em>q^d={\sigma(\Delta b</em>{qx}^d+\sigma^{-1}(\hat{b}<em>{qx}^{d-1})),\sigma(\Delta b</em>{qy}^d+\sigma^{-1}(\hat{b}<em>{qy}^{d-1})),\sigma(\Delta b</em>{qw}^d+\sigma^{-1}(\hat{b}<em>{qw}^{d-1})),\sigma(\Delta b</em>{qh}^d+\sigma^{-1}(\hat{b}_{qh}^{d-1}))}$$</p>
<p>其中 $\Delta b_{q{x,y,w,h}}^d$ 是第d层Decoder利用检测头部的回归分支预测的结果(偏移量)，$\sigma$，$\sigma^{-1}$分别代表sigmoid和反sigmoid函数。</p>
<p>在这里需要注意两点:</p>
<ol>
<li>各层的检测头部是不共享参数的；</li>
<li>校正后的bbox梯度会被阻断(detach)，不会跨层传播</li>
</ol>
<p>具体实现和解析在上一节讲Decoder的时候已详细说明。</p>
<p><strong>Two-Stage Deformable DETR</strong></p>
<p>2-stage模式下，Encoder会输出一批proposals(<strong>并不是基于网络预测，而是像anchor一样计算出来的</strong>)，boxes中心就是各特征点的中心，而宽、高的设置则与所在的特征层相关，base值设置为0.05。<strong>这时的proposals相对于anchors的角色。</strong></p>
<p>然后，使用检测头部的分类分支对Encoder编码的特征(memory)进行预测，对应各个proposals的分类结果；同时使用回归分支也对编码特征也进行预测，得到相对于proposals(xywh)的偏移量，接着将偏移量加在proposals的中心坐标和宽、高上得到第一阶段预测的proposals。</p>
<p>最后，<strong>取top-k分数最高的那批预测proposals作为Decoder的参考点</strong>。并且，<strong>Decoder的object query和query embedding都由参考点通过位置嵌入(position embedding)来生成。</strong></p>
<h2 id="7conclusion">7、Conclusion</h2>
<p>Deformable DETR效率高并且收敛快，核心是Multi-Scale Deformable Attention Module。解决了DETR中收敛慢以及小目标性能低的问题。</p>
<h2 id="8qa">8、Q&amp;A</h2>
<p>如果认真思考，会发现Deformable DETR中有许多值得考量的地方。</p>
<p><strong>1. 为何不需要FPN也能达到跨层融合的效果？</strong></p>
<p>作者在paper中说到，多尺度可变形注意力可以在不同尺度的特征之间交换信息，因此不需要FPN:</p>
<blockquote>
<p>Note that the top-down structure in FPN (Lin et al., 2017a) is not used, because our proposed multi-scale deformable attention in itself can exchange information among multi-scale feature maps.</p>
</blockquote>
<p>那么到底是为何？具体是怎么做到的呢？</p>
<p>其实前文也提到了，每个参考点在各尺度特征层都会进行采样。而且在上述处理参考点坐标的过程中，我们也可以看到，无论在Encoder还是Decoder，都会对参考点进行处理，使得一个参考点在所有尺度特征层上都有相应的归一化坐标值。为什么这样做呢？这样做其实就是为了计算出每个参考点在各尺度特征层对应的采样点位置。</p>
<p>那么你可能又会奇怪了，一个参考点明明是只处于某个特定的特征层，怎么能够把它放到另一个特征层去呢？这样合理吗？</p>
<p>合理不合理由网络去进行学习，基于最终的匹配效果来证明。但是可不可行我们倒是可分析的，可以这么看: 我们知道，由于特征图是经过原图下采样得到，因此一个像素点无论是处于原图还是各层特征图中，其坐标的归一化值应该是一致的(忽略细微的计算误差)。那么，既然这里参考点坐标是归一化的，它就能够映射(re-scales)到各尺度特征中去，这部分对应以下公式中的 $\phi_l$ 函数:</p>
<p>$$\text{MSDeformAttn}(z_{q},\hat{p}<em>{q},{x^{l}}</em>{l=1}^{L})=\sum_{m=1}^{M}W_{m}\bigl[\sum_{l=1}^{L}\sum_{k=1}^{K}A_{mlqk}\cdot W_{m}^{\prime}x^{l}\bigl[\phi_{l}(\hat{p}<em>{q})\bigr]+\Delta p</em>{mlqk}\bigr)\bigr],$$</p>
<p>作者在paper中是这么描述的:</p>
<blockquote>
<p>Function $\phi_l$ re-scales the normalized coordinates $\hat{p}_{q}$ to the input feature map of the l-th level.</p>
</blockquote>
<p><strong>2. 为何注意力权重可由query直接通过全连接层预测得到？</strong></p>
<p>我们知道，<strong>在Transformer中，注意力权重是由query和key交互计算得到的。然而，在这里却像开挂般直接通过query经全连接层输出得到</strong>(好家伙~！)，这节奏是不是不对劲呢？要分析这个问题，不妨先来看看Deformable DETR中参考点(reference points)和query之间的关系。</p>
<p>在Encoder中: 参考点是特征点本身的位置，query embedding是特征图对应的position emebdding(其实还加上了scale-level embedding)，object query则来自于特征图，最终注意力机制中的query就是object query + query embedding。</p>
<p>在Decoder中: 2-stage时，由参考点经过位置嵌入生成query embedding和object query；而1-stage时，object query和query embedding都是预设的embedding，参考点则由query embedding经全连接层生成，最终注意力机制中的query也是object query + query embedding。</p>
<p>综上可知，<strong>参考点(reference points)和query之间是存在着对应关系的</strong>(就有点“你生我、我生你”的feel~)。</p>
<p>OK，既然这样，那么基于参考点位置采样插值出来的特征(value)自然就能够和通过query经过线性变换得到的注意力权重对应起来了，这就是为什么可变形注意力模块中不需要key与query来交互计算注意力权重了。</p>
<p>打个比方: A与B已建立起了对应关系，之后A再通过某种映射关系得到C，B也通过某种映射关系得到D，那么C与D之间必然会有某种程度的耦合与对应关系。这里A、B、C、D就分别指代query、reference points、attention weights以及value。</p>
<p>还有个问题值得思考，为何在Decoder中，2-stage时由reference points生成query embedding是通过position embedding，而1-stage时由query embedding生成reference points时却用全连接层呢？</p>
<p>对此，CW是这么想的: 2-stage时，参考点是由Encoder预测出来的proposals，本身一定程度上代表着物体的位置信息了(虽然这个位置可能并不精确)，因此有必要用位置嵌入将这“宝贵&quot;的信息给记录下来；而1-stage时，预设的query embedding本身就是一个抽象体，盲猜的东西，因此用线性变换来做维度映射得到参考点比较合理，因为毕竟其本身并没有实际意义的位置信息。</p>
<p><strong>3. 为何检测头部的回归分支预测的是偏移量而非绝对坐标值？</strong></p>
<p>这个问题估计很多人会提出，<strong>为何这里不像DETR一样直接预测bbox的坐标而是预测偏移量呢？</strong> 请你想想，Deformable DETR相比于DETR多了一个很显眼的东西是什么？是参考点 <strong>(reference points)</strong> 啊！(感觉通篇它都在秀存在感..)</p>
<p>采样点的位置是基于参考点和对应的坐标偏移量计算出来的，也就是说采样特征是分布在参考点附近的，既然这里需要由采样特征回归出bbox的位置，那么<strong>预测相对于参考点的偏移量就会比直接预测绝对坐标更易优化，更有利于模型学习</strong>。</p>
<blockquote>
<p>Because the multi-scale deformable attention module extracts image features around the reference point, we let the detection head predict the bounding box as relative offsets w.r.t. the reference point to further reduce the optimization difficulty.</p>
</blockquote>
<p>另外，由于采样特征中注入了注意力，而预测框是基于采样特征回归得到的，loss是基于回归结果计算的，梯度是通过loss反向传播的，因此最终学习到的注意力权重就会和预测框有相对较强的联系，这也起到了加速收敛的效果。</p>
<blockquote>
<p>In this way, the learned decoder attention will have strong correlation with the predicted bounding boxes, which also accelerates the training convergence.</p>
</blockquote>
<h2 id="9与其它方法比较">9、与其它方法比较</h2>
<p>Deformable DETR是在DETR基础上提出的，因此，在这最后一部分CW打算将其与DETR作个比较；另外，CW觉得其与Sparse R-CNN也有值得比较的地方，之前CW也写过一篇文章(目前还在简书，后续会同步到知乎这边来)分析过说Sparse R-CNN像是DETR的小弟哈哈哈。</p>
<p>以下列出的点都是仅出现在 Deformable DETR 中而在 DETR / Sparse R-CNN 中是没有的。</p>
<p><strong>i). vs DETR</strong></p>
<ol>
<li>多尺度特征；</li>
<li>新增scale-level embedding，用于区分不同特征层(由于第1点)；</li>
<li>使用了多尺度可变形注意力替代Encoder中的自注意力和Decoder中的交叉注意力；</li>
<li>引入了参考点，某种程度上起到先验的作用；</li>
<li>为自己开发了“高配”版: 迭代的框校正策略 和 两阶段模式；</li>
<li>检测头部的回归分支预测的是bbox偏移量而非绝对坐标值</li>
</ol>
<p><strong>ii). vs Sparse R-CNN</strong></p>
<ol>
<li>没有使用FPN；</li>
<li>使用了位置嵌入；</li>
<li>2-stage时，proposals是predicted的(而非Sparse R-CNN直接使用learnable embedding)；</li>
<li>使用了Transformer；</li>
<li>注意力机制是one-to-many iteraction(Sparse R-CNN由于‘Sparse’偶像包袱太重，是彻底的sparse，是one-to-one实例级别的交互)；</li>
<li>检测头部的回归分支预测的是bbox偏移量而非绝对坐标值</li>
</ol>
<p><strong>最后:</strong></p>
<p>DETR收敛慢和小目标检测效果差的原因在于Transformer的注意力计算模块——它对全局密集的关系进行建模，这使得模型需要长时间去学习(关注)真正有意义的稀疏位置，同时还带来了高复杂度的计算与空间资源消耗。</p>
<p>联想到稀疏空间位置的学习是DCN的强项，但其又缺乏关系建模能力，于是作者机智地将DCN与Transformer结合在一起，最终提出 Deformable DETR。</p>
<p>ref:
[1]. <a href="https://zhuanlan.zhihu.com/p/372116181"target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/372116181<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
[2]. <a href="https://blog.csdn.net/qq_38253797/article/details/127668593"target="_blank" rel="external nofollow noopener noreferrer">https://blog.csdn.net/qq_38253797/article/details/127668593<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
[3]. <a href="https://zhuanlan.zhihu.com/p/596303361"target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/596303361<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
]]></description></item><item><title>Diffusion 扩散模型（DDPM）</title><link>https://jianye0428.github.io/posts/ddpm/</link><pubDate>Mon, 31 Jul 2023 15:57:07 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/ddpm/</guid><description><![CDATA[<h2 id="一引入">一、引入</h2>
<p></p>
<p>近年AIGC的爆火离不开人工智能在图像生成、文本生成以及多模态等领域的不断累积，其中<strong>生成模型</strong>的发展占据了很大功劳，如：<mark>生成对抗网络 GAN</mark> 及其一系列变体、<mark>变分自编码器 VAE</mark> 及其一系列变体、<mark>自回归模型 AR</mark>、<mark>流模型 flow</mark> ，以及近年大火的<strong>扩散模型 Diffusion Model</strong> 等。</p>
<p>扩散模型的大火并非横空出世，早在2015年就有人提出了类似的想法，直到2020年才提出了经典的 <strong>Denoising Diffusion Probabilistic Models（DDPM）</strong>，像OpenAI、NovelAI、NVIDIA和Google成功的训练了大规模模型之后，它们吸引了很多人注意，后续有了很多基于扩散模型的变体，比如有：GLIDE、DALLE-2、Imagen和年底爆火的完全开源的稳定扩散模型（Stable Diffusion）。</p>
<p>扩散模型与之前所有的生成方法有着本质的区别：</p>
<p></p>
<p>直观的说它是<mark>将图像生成过程（采样）分解为许多小的去噪步骤</mark>，其实 Diffusion 的含义本质上就是一个迭代过程，实线箭头用于扩散步骤中添加随机噪声，虚线箭头代表的是通过学习逆向扩散过程<mark>从噪声中重构所需的数据样本</mark>。<strong>引入噪声导致了信息的衰减，再通过噪声尝试还原原始数据，多次迭代最小化损失后，能够使模型在给定噪声输入的情况下学习生成新图像。</strong></p>
<p>所以Diffusion模型和其它生成模型的区别是，它不是直接的<strong>图像-&gt;潜变量、潜变量-&gt;图像</strong>的一步到位，它是一步一步的<mark><font color=red><strong>逐渐分解、逐渐去噪</strong></font></mark>的过程。</p>
<p>当然有关Diffusion的理解和变体有很多，但是扩散模型从本质上讲就是DDPM，所以本文主要对DDPM的原理进行讲解，并给出DDPM的扩散过程、去噪过程、训练损失的详细推导，对于掌握Diffusion算法原理只需要抓住以下四点即可：</p>
<ul>
<li>前向过程（扩散）；</li>
<li>反向过程（去噪、采样）；</li>
<li>如何训练；</li>
<li>如何推断。</li>
</ul>
<h2 id="二扩散原理阐述">二、扩散原理阐述</h2>
<p>扩散模型包括 <strong>前向扩散过程</strong> 和 <strong>反向去噪过程(采样)</strong>，前向阶段对图像逐步施加噪声，直至图像被破坏变成完全的高斯噪声，然后在反向阶段学习从高斯噪声还原为原始图像的过程。</p>
<h3 id="21直观理解">2.1、直观理解</h3>
<ul>
<li>扩散模型的目的是什么？
<ul>
<li>学习从纯噪声生成图片的方法。</li>
</ul>
</li>
<li>扩散模型是怎么做的？
<ul>
<li>训练一个UNet，接受一系列加了噪声的图片，学习预测所加的噪声。</li>
</ul>
</li>
<li>前向过程在干什么？
<ul>
<li>逐步向真实图片添加噪声最终得到一个纯噪声；</li>
<li>对于训练集中的每张图片，都能生成一系列的噪声程度不同的加噪图片；</li>
<li>在训练时，这些 【不同程度的噪声图片 + 生成它们所用的噪声】 是实际的训练样本。</li>
</ul>
</li>
<li>反向过程在干什么？
<ul>
<li>训练好模型后，采样、生成图片。</li>
</ul>
</li>
</ul>
<h3 id="22前向过程扩散">2.2、前向过程（扩散）</h3>
<p></p>
<p>前向过程在原始输入图像$x_0$上逐步添加随机噪声，这个噪声服从高斯分布$N(0, 1)$，每一步得到的图像$x_t$只和上一步的加噪结果$x_{t-1}$相关，逐步添加噪声至$T$步，可以得到趋向于纯粹噪声的图像，如下图所示：
</p>
<blockquote>
<p>后面有详细的推导，公式比较多，这里先提前把主要的列一下方便阐述。</p>
</blockquote>
<p>对于将一张图片，从$x_{t-1}\rightarrow x_{t}$的逐步加噪破坏的公式为：</p>
<p>$$x_t=\sqrt{\alpha_t}\left.x_{t-1}+\sqrt{1-\alpha_t}\right.\varepsilon_t\quad\quad\quad\quad\quad\quad(1)$$</p>
<p>其中:</p>
<ul>
<li>$x_t$表示第$t$步的图像；</li>
<li>$\varepsilon$ 是一个满足正态分布的随机噪声，$\varepsilon \sim N(0, 1)$；</li>
<li>$\sqrt{\alpha_{t}}$ 是图片的权重，$\sqrt{1 - \alpha_{t}}$ 是噪声的权重；</li>
</ul>
<p>定义：</p>
<ul>
<li>$\alpha_t=1-\beta_t$</li>
<li>$\overline{\alpha}=\prod_{s=1}^t\alpha_s$</li>
</ul>
<p>随着$t$的增加，<strong>噪声的占比会越来越大</strong>，所以添加的<strong>噪声强度也会越来越大</strong>，也就是说图片的权重要越来越小，噪声的权重要越来越大。因为随着扩散过程的增加，图像中噪声的占比也会越来越大，我们想要进一步破坏它的结构，就需要添加更多的噪声。</p>
<blockquote>
<p>换句话说，一开始图像比较清晰，这个时候添加的噪声小一些，随着图像的噪声越来越多，这个时候再加一点噪声的话，对原来的图像就没什么影响了，因为它本身就有好多噪声了，所以随着图像的噪声越来越多，后面的步骤就要加更多的噪声。</p>
</blockquote>
<p>实际训练过程中会比较大（DDPM原文中为1000），所以会有从$x_0$递推到$x_t$的公式：</p>
<p>$$x_t=\sqrt{\overline{\alpha}_t}\left.x_0+\sqrt{1-\overline{\alpha}_t}\right.\varepsilon\quad\quad\quad\quad(2)$$</p>
<p>其中：</p>
<ul>
<li>$\alpha_t$、$\beta_t$ 有一个固定的已知函数，是可以直接进行计算的；</li>
<li>$\varepsilon$ 为随机产生的噪声；</li>
</ul>
<p>所以整个式子是已知的，式 $(1)$、$(2)$ 就可以描述前向过程了，$(1)$ 用于将一张图片的逐步破坏，$(2)$ 用于一步到位的破坏。</p>
<h3 id="23反向过程去噪">2.3、反向过程（去噪）</h3>
<p>反向过程则是不断去除噪声的过程，给定一个噪声图片 $x_T$，对它一步步的去噪还原，直至最终将原始图像 $x_0$ 给恢复出来，如下图所示：</p>
<p></p>
<p>去噪的过程，$x_t$、$\alpha_t$、$\beta_t$ 都是已知的，只有公式 $(2)$ 中的真实噪声是未知的，因为它是随机采样的。所以需要一个神经网络把 $\varepsilon$ 给学出来，也就是说训练一个由 $x_t$ 和 $t$ 估测噪声的模型:</p>
<p>$$x_{t-1}=\frac{1}{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\overline{\alpha}<em>t}}\varepsilon</em>\theta(x_t,t))$$</p>
<p>其中 $\theta$ 就是模型的参数，通常使用UNet作为预估噪声的模型。</p>
<h3 id="24模型训练">2.4、模型训练</h3>
<p>所以说反向过程其实就是<strong>训练网络去学习分解过程每一步的噪声</strong>，当网络训练好之后，输入一张噪声图片，通过网络就能把加的噪声给求出来，噪声有了代入公式，就能把 $x_{t-1}$ 步的比较清晰的图给求出来了，一步步往前迭代就行了。</p>
<p>采用L2距离刻画相近程度就可以，DDPM的关键是训练 $\varepsilon_{\theta}(x_t, t)$，目的就是使预测的噪声与真实用于破坏的噪声相近：</p>
<p>$$Loss=\mid\mid\varepsilon-\varepsilon_\theta(x_t,t)\mid\mid^2=\mid\mid\varepsilon-\varepsilon_\theta(\sqrt{\overline{\alpha}_t}~x_0+\sqrt{1-\overline{\alpha}_t}~\varepsilon_t,t)\mid\mid^2$$</p>
<p></p>
<p>模型训练完后，只要给定随机高斯噪声，就可以生成一张从未见过的图像。</p>
<p>UNet本文不做介绍，结构图为：</p>
<p></p>
<blockquote>
<p>额外强调的是：Unet里有一个位置编码，是关于时间步的，每个时间步是有一个线性调度器的，每个时间添加的噪声的方差是不一样的，所以将时间步作为编码嵌入的话，可以将模型预测的噪声更加的准确。</p>
</blockquote>
<h2 id="三算法流程概述">三、算法流程概述</h2>
<p></p>
<p>再次总结，扩散模型两个步骤如下：</p>
<ul>
<li>一个固定的（预先定义好的）前向扩散过程 $q(x_t | x_{t-1})$：逐步向图片增加噪声直到最终得到一张纯粹的噪声图；</li>
<li>一个学习得到的去噪过程 $p_{\theta}(x_{t-1} | x_t)$：训练一个神经网络去逐渐的从一张纯噪声中消除噪声，直到得到一张真正的图片。</li>
</ul>
<p></p>
<p>算法1 为训练流程：</p>
<ul>
<li>line2：从数据中采样 $x_0$，$q(x_0)$ 的意思是给 $x_0$ 加上噪声；</li>
<li>line3：随机选取 time step $t$；
<ul>
<li>真实训练过程中我们不可能一步步的从 $t$ 到 $T$，因为会很大，这就意味着每输入一张图片 $x$，就会产生张噪声图像，也就是一张图像的网络要训练 $T$ 个噪声样本，非常耗时。</li>
<li>所以对 $T$ 进行了采样，$t$ 就是从 $T$ 里采集若干个的意思。</li>
<li>举个例子：假设采集 $t$ 的分别为100、20、3，对应的 $x$ 为 $x_{100}$、$x_{20}$、$x_{3}$，对应噪声为 $\varepsilon_{100}$、$\varepsilon_{20}$、$\varepsilon_{3}$，对于的预测噪声为 $\hat{\varepsilon}<em>{100}$、$\hat{\varepsilon}</em>{20}$、$\hat{\varepsilon}_{3}$, 只需要将 $\varepsilon$ 和 $\hat{\varepsilon}$ 代入MSE公式即可（相减、平方、最小化）。</li>
</ul>
</li>
<li>line 4：生成随机高斯噪声；</li>
<li>line 5：调用模型估计 $\varepsilon_{\theta}(\sqrt{\overline{\alpha}_t}~x_0+\sqrt{1-\overline{\alpha}_t}~\varepsilon_t,t)$ ，计算真实噪声与估计噪声之间的MSE Loss，反向传播更新模型。
<ul>
<li>网络的作用是预测噪声，随着的增加，噪声强度会越来越大，因此预测的噪声是和迭代是直接相关的，所以要把作为参数送入到网络当中。</li>
</ul>
</li>
<li>直到收敛。</li>
</ul>
<p>算法2 为采样流程：</p>
<ul>
<li>line 1：从高斯分布采样 $x_T$；</li>
<li>line 2：按照 $T, &hellip;, 1$ 的顺序进行迭代；</li>
<li>line 3：如果 $t = 1$ 令 $z = 0$；如果 $t &gt; 1$ ，从高斯分布中采样；</li>
<li>line 4：利用公式求出均值和方差，进而求得 $x_{t-1}$；</li>
<li>经过上述迭代，恢复 $x_0$。</li>
</ul>
<h2 id="四数学描述">四、数学描述</h2>
<p>我们来推导如何从原始图像直接到第t时刻的图像 $(X_0 - X_t)$。</p>
<p>首先回顾 2.1小节 的两个定义：</p>
<ul>
<li>$\alpha_t = 1 - \beta_{t}$, $\beta_t$ 要越大越好，论文中从0.0001到0.02;</li>
<li>$\overline{\alpha}=\prod_{s=1}^t\alpha_s$累乘，下面会用到；</li>
<li>$x_t=\sqrt{\alpha_t}x_{t-1}+\sqrt{1-\alpha_t}\varepsilon_t\text{,}\varepsilon_t\sim N(0,1)$ 每一时刻添加的噪声均独立；</li>
</ul>
<p>我们要求$x_t$时刻的图像，它需要一步步的加噪迭代，这样太慢了。因为每一步添加的噪声独立且服从正太分布，我们可以做如下推导：</p>
<blockquote>
<p>为了不混淆，只需要记住：<strong>下标越小，噪声越小</strong>，即 $x_{t-1}$ 的噪声是小于 $x_t$ 的。</p>
</blockquote>
<p>$$
\begin{aligned}
q(x_{t}\mid x_{t-1})&amp; =N(x_t;\sqrt{\alpha_t}x_{t-1},(1-\alpha_t)I)  \cr
&amp;=\underbrace{\sqrt{\alpha_t}x_{t-1}}<em>{x</em>{t-2}\text{来表示}x_{t-1}}+\sqrt{1-\alpha_t}\varepsilon_t \cr
&amp;=\sqrt{\alpha_t}\left(\sqrt{\alpha_{t-1}}\right.x_{t-2}+\sqrt{1-\alpha_{t-1}}\left.\varepsilon_{t-1}\right)+\sqrt{1-\alpha_t}\left.\varepsilon_t\right. \cr
&amp;=\sqrt{\alpha_t\alpha_{t-1}}x_{t-2}+\underbrace{\sqrt{\alpha_t-\alpha_t\alpha_{t-1}}\varepsilon_{t-1}+\sqrt{1-\alpha_t}\varepsilon_t}<em>{\text{两个独立正太分布相加}} \cr
&amp;=\sqrt{\alpha_t\alpha</em>{t-1}}\left.x_{t-2}+\sqrt{1-\alpha_t\alpha_{t-1}}\right.\varepsilon  \cr
&amp;\text{&hellip;} \
&amp;=\sqrt{\overline{\alpha}_t}\left.x_0+\sqrt{1-\overline{\alpha}_t}\right.\varepsilon  \cr
&amp;\therefore q(x_t\mid x_0)=N(x_t;\sqrt{\overline{\alpha}_t}x_0,\sqrt{1-\overline{\alpha}_t}I)
\end{aligned}
$$</p>
<blockquote>
<p>上述用的就是重参数化技巧。</p>
</blockquote>
<p>方差参数 $\beta_{t}$ 可以固定为一个常数，也可以选择作为 $T$ 时间段的一个时间表。事实上，人们可以定义一个方差表，它可以是线性的、二次的、余弦的等等。最初的DDPM作者利用了一个从 $\beta_1 = 10^{-4}$ 到$\beta_T = 0.02$增加的线性时间表。Nichol等人2021年的研究表明，采用余弦时间表效果更好。</p>
<p></p>
<h3 id="42反向过程去噪">4.2、反向过程（去噪）</h3>
<p>接下来是反向过程的推导：
$$p(x_{t-1}\mid x_t)=N(x_{t-1};\underbrace{\mu_\theta(x_t,t)}<em>\text{要反预测这个},\overbrace{\Sigma</em>\theta(x_t,t)}^{fixed})$$</p>
<p>给定$x_t$要预测 $x_{t-1}$，它是一个高斯分布，$x_t$和$t$的方差是固定的，论文作者使用原始的噪声调度器作为方差，也就是说噪声调度器一旦确立，方差的大小也就固定了。所以我们只需要预测这个均值就好了，下面给出具体的推导过程：</p>
<p>我们先看整个损失函数，是个<strong>负对数似然</strong>：</p>
<p>$$-\log{p_{\theta}(x_0)}$$</p>
<p>希望神经网络的参数 $\theta$，可以使得生成 $x_0$的概率越大越好。</p>
<p>但问题在于 $x_0$ 的概率不好计算，因为它依赖于 $x_0$ 之前的所有步长，从 $x_T$ 开始。作为一种解决方案，我们可以计算这个目标的<strong>变分下界</strong>，并得到一个更易于计算的公式：</p>
<p>$$-log(p_\theta(x_0))\leq-log(p_\theta(x_0))+D_{KL}(q(x_{1:T}\mid x_0)\parallel p_\theta(x_{1:T}\mid x_0))$$</p>
<p>其中：</p>
<ul>
<li>$x_{1:T}$ 指的是 $x_1, &hellip;, x_T$ 整个序列。</li>
</ul>
<p>现在依然无法计算，我们继续推导：</p>
<p>$$
\begin{gathered}
-log(p_\theta(x_0)) \leq-log(p_\theta(x_0))+D_{KL}(q(x_{1:T}\mid x_0)\mid\mid p_\theta(x_{1:T}\mid x_0)) \cr
\leq-log(p_\theta(x_0))+log(\frac{q(x_{1:T}\mid x_0)}{p_\theta(x_{1:T}\mid x_0)})
\end{gathered}
$$</p>
<p>我们将 KL divergence 改写后，再利用贝叶斯公式进行变形，即分母可以改写为：</p>
<p>$$
\begin{aligned}
p_\theta(x_{1:T}\mid x_0) &amp;=\frac{p_\theta(x_0\mid x_{1:T})\mathrm{~}p_\theta(x_{1:T})}{p_\theta(x_0)} \cr
&amp;=\frac{p_\theta(x_0,x_{1:T})}{p_\theta(x_0)} \cr
&amp;=\frac{p_\theta(x_{0:T})}{p_\theta(x_0)}
\end{aligned}
$$</p>
<p>将其代回原式：</p>
<p>$$
\begin{aligned}
log(\frac{q(x_{1:T}\mid x_0)}{p_\theta(x_{1:T}\mid x_0)})&amp; =log(\frac{q(x_{1:T}\mid x_0)}{\frac{p_\theta(x_{0:T})}{p_\theta(x_0)}})  \cr
&amp;=log(\frac{q(x_{1:T}\mid x_0)}{p_\theta(x_{0:T})})+log(p_\theta(x_0))
\end{aligned}
$$</p>
<p>所以原式可简化为：</p>
<p>$$-log(p_\theta(x_0))\leq\underbrace{log(\frac{q(x_{1:T}\mid x_0)}{p_\theta(x_{0:T})})}_{\text{变分下界,可以优化它}}$$</p>
<ul>
<li>
<p>分子，就是前向过程，它是固定的，从 $x_0$ 到 $x_{1:T}$ 的采样，换句话说就是从我们数据中的一些图像开始；</p>
</li>
<li>
<p>分母，$p_\theta(x_{0:T})=p(x_T)\prod_{t=1}^Tp_\theta(x_{t-1}\mid x_t)$；</p>
<ul>
<li>将 $p(x_T)$ 提出来，是因为 $p(x_T)$ 是指当前图像，它是不依赖于网络参数 $\theta$ 的.</li>
</ul>
<p>$$
\begin{aligned}
log(\frac{q(x_{1:T}\mid x_0)}{p_{\theta}(x_{0:T})})&amp; =log(\frac{\prod_{t=1}^Tq(x_t\mid x_{t-1})}{p(x_T)\prod_{t=1}^Tp_\theta(x_{t-1}\mid x_t)})  \cr
&amp;=-log(p(x_T))+log(\frac{\prod_{t=1}^Tq(x_t\mid x_{t-1})}{\prod_{t=1}^Tp_\theta(x_{t-1}\mid x_t)}) \cr
&amp;=-log(p(x_T))+\sum_{t=1}^Tlog(\frac{q(x_t\mid x_{t-1})}{p_\theta(x_{t-1}\mid x_t)}) \cr
&amp;=-log(p(x_T))+\sum_{t=2}^Tlog(\frac{q(x_t\mid x_{t-1})}{p_\theta(x_{t-1}\mid x_t)})+\underbrace{log(\frac{q(x_1\mid x_0)}{p_\theta(x_0\mid x_1)})}_{t=1}
\end{aligned}
$$</p>
</li>
</ul>
<p></p>
<p>$q(x_t|x_{t-1})$ 根据贝叶斯公式可以变换如下：</p>
<p>$$q(x_t\mid x_{t-1})=\frac{q(x_{t-1}\mid x_t)q(x_t)}{q(x_{t-1})}$$</p>
<p>$q(x_{t-1}|x_{t})$具有比较高的方差，因为根据这张照片，我们无法确定它来自哪里，但是引入 $x_0$，我们就可以容易的预测出 $x_{t-1}$，</p>
<p></p>
<p>因此我们使用：</p>
<p>$$\frac{q(x_{t-1}\mid x_t,x_0)\mathrm{~}q(x_t\mid x_0)}{q(x_{t-1}\mid x_0)}$$</p>
<p>替换贝叶斯重写后的式子，我们得到：</p>
<p>$$
\begin{aligned}
log(\frac{q(x_{1:T}\mid x_0)}{p_{\theta}(x_{0:T})})&amp; =-log(p(x_T))+\sum_{t=2}^Tlog(\frac{q(x_{t-1}\mid x_t,x_0)q(x_t\mid x_0)}{p_\theta(x_{t-1}\mid x_t)q(x_{t-1}\mid x_0)})+log(\frac{q(x_1\mid x_0)}{p_\theta(x_0\mid x_1)})  \cr
&amp;=-log(p(x_T))+\sum_{t=2}^Tlog(\frac{q(x_{t-1}\mid x_t,x_0)}{p_\theta(x_{t-1}\mid x_t)})+\underbrace{\sum_{t=2}^Tlog(\frac{q(x_t\mid x_0)}{q(x_{t-1}\mid x_0)})}+log(\frac{q(x_1\mid x_0)}{p_\theta(x_0\mid x_1)})
\end{aligned}
$$</p>
<p>上述标记的式子，也可以简化，我们假设 $t=4$：</p>
<p>$$
\begin{gathered}
\begin{aligned}\sum_{t=2}^{T=4}log(\frac{q(x_t\mid x_0)}{q(x_{t-1}\mid x_0)})\end{aligned} =log(\frac{q(x_2\mid x_0)}{q(x_1\mid x_0)}\cdot\frac{q(x_3\mid x_0)}{q(x_2\mid x_0)}\cdot\frac{q(x_4\mid x_0)}{q(x_3\mid x_0)}) \
=log(\frac{q(x_4\mid x_0)}{q(x_1\mid x_0)})
\end{gathered}
$$</p>
<p>因此我们可以简化为：</p>
<p>$$
\begin{aligned}
&amp;=-log(p(x_T))+\sum_{t=2}^Tlog(\frac{q(x_{t-1}\mid x_t,x_0)}{p_\theta(x_{t-1}\mid x_t)})+log(\frac{q(x_t\mid x_0)}{q(x_1\mid x_0)})+log(\frac{q(x_1\mid x_0)}{p_\theta(x_0\mid x_1)}) \cr
&amp;=-log(p(x_T))+\sum_{t=2}^Tlog(\frac{q(x_{t-1}\mid x_t,x_0)}{p_\theta(x_{t-1}\mid x_t)})+log(q(x_t\mid x_0))-log(p_\theta(x_0\mid x_1)) \cr
&amp;=log(\frac{q(x_t\mid x_0)}{p(x_T)})+\sum_{t=2}^Tlog(\frac{q(x_{t-1}\mid x_t,x_0)}{p_\theta(x_{t-1}\mid x_t)})-log(p_\theta(x_0\mid x_1))\cr
&amp;=\overbrace{\underbrace{D_{KL}(q(x_t\mid x_0)\mid\mid p(x_T))}<em>{q\text{只是个正向过程没有可学习参数}}}^{\text{可以忽略}} + \sum</em>{t=2}^TD_{KL}(q(x_{t-1}\mid x_t,x_0)\mid\mid p_\theta(x_{t-1}\mid x_t))-log(p_\theta(x_0\mid x_1))
\end{aligned}
$$</p>
<ul>
<li>第一项KL散度可以忽略，因为$q$只是个正向过程，没有可学习参数，换句话说就是它是固定的。</li>
<li>第二项KL散度，左边和右边都是正太分布，分别服从 $N(x_{t-1};\tilde{\mu_t}(x_t,x_0),\tilde{\mathsf{\beta}<em>t}I)$ 、$N(x</em>{t-1};\mu_\theta(x_t,t),\text{β}I)$：</li>
</ul>
<p>$$
\sum_{t=2}^TD_{KL}(\underbrace{q(x_{t-1}\mid x_t,x_0)}<em>{N(x</em>{t-1};\tilde{\mu}<em>t(x_t,x_0),\tilde{\mathsf{\beta}}<em>tI)}\mid\mid\overbrace{p</em>\theta(x</em>{t-1}\mid x_t)}^{N(x_{t-1};\mu_\theta(x_t,t),\mathsf{\beta}I})
$$</p>
<p>第一项的 $\tilde{\mu_{t}}(x_{t},x_{0})$、$\tilde{\beta_{t}}$ 就是我们要求的值，这里省略了这部分的推导，不影响算法的理解，</p>
<p>$$
\begin{gathered}\tilde{\mu}<em>t(x_t,x_0)=\frac{\sqrt{\alpha_t}(1-\overline{\alpha}</em>{t-1})}{1-\overline{\alpha}<em>t}x_t+\frac{\sqrt{\alpha}</em>{t-1}\beta_t}{1-\overline{\alpha}_t}x_0\\tilde{\mathsf{\beta}}<em>t=\frac{1-\overline{\alpha}</em>{t-1}}{1-\overline{\alpha}_t}\beta_t\end{gathered}
$$</p>
<blockquote>
<p>凡是涉及到 $\alpha_t$ 的，就是学习调度器的，我们不需要关注它</p>
</blockquote>
<p>我们可以化简 $\tilde{\mu}_{t}$，我们知道 $x_t=\sqrt{\overline{\alpha}_t}x_0+\sqrt{1-\overline{\alpha}_t}\varepsilon $, 即:</p>
<p>$$
x_0=\frac1{\sqrt{\overline{\alpha}_t}}(x_t-\sqrt{1-\overline{\alpha}_t}\left.\varepsilon\right)
$$</p>
<p>还知道: $\overline{\alpha}=\prod_{s=1}^t\alpha_s$、$\alpha_t=1-\beta_t$:</p>
<p>代入 $\tilde{\mu}_{t}$ 得到：</p>
<p>$$
\begin{aligned}
\underbrace{\tilde{\mu}<em>t(x_t,x_0)}</em>{\text{不再依赖}x_0}&amp; =\frac{\sqrt{\alpha_{t}}(1-\overline{\alpha}<em>{t-1})}{1-\overline{\alpha}</em>{t}}x_{t}+\frac{\sqrt{\overline{\alpha}<em>{t-1}}\beta</em>{t}}{1-\overline{\alpha}<em>{t}}\frac{1}{\sqrt{\overline{\alpha}</em>{t}}}(x_{t}-\sqrt{1-\overline{\alpha}<em>{t}}\varepsilon)  \cr
&amp;=\frac{\alpha_t(1-\overline{\alpha}</em>{t-1})x_t}{\sqrt{\alpha_t}(1-\overline{\alpha}_t)}+\frac{\beta_t}{\sqrt{\alpha_t}(1-\overline{\alpha}_t)}(x_t-\sqrt{1-\overline{\alpha}_t}\left.\varepsilon\right) \cr
&amp;=\frac{\alpha_tx_t-\overline{\alpha}_tx_t+(1-\alpha_t)x_t-(1-\alpha_t)\sqrt{1-\overline{\alpha}_t}\varepsilon}{\sqrt{\alpha_t}(1-\overline{\alpha}_t)} \cr
&amp;=\frac{x_t(1-\overline{\alpha}_t)-(1-\alpha_t)\sqrt{1-\overline{\alpha}_t}\varepsilon}{\sqrt{\alpha_t}(1-\overline{\alpha}_t)} \cr
&amp;=\frac{x_t}{\sqrt{\alpha_t}}-\frac{(1-\alpha_t)\varepsilon}{\sqrt{\alpha_t}\sqrt{(1-\overline{\alpha}_t)}} \cr
&amp;=\frac1{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\overline{\alpha}_t}}\left.\varepsilon\right)
\end{aligned}
$$</p>
<p>代入之后我们发现它就不再依赖于 $x_0$ 了，它就是和 $x_t$ 的一个关系式，式中的 $\alpha_t$、$\beta_t$、$\varepsilon$都是已知的，最后的本质就是我们只是从中减去缩放的随机噪声。</p>
<p>$$\therefore x_{t-1}=N(x_{t-1};\frac1{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\overline{\alpha}<em>t}}\left.\varepsilon</em>\theta(x_t,t)\right),\Sigma_\theta(x_t,t))$$</p>
<p>这样一来，DDPM的每一步推断可以总结为：</p>
<ul>
<li>每个时间步通过 $x_t$ 和 $t$ 来预测高斯噪声，图中用 $z$ 表示，根据上述公式计算得到均值 $\mu$；</li>
<li>得到方差 $\Sigma_\theta(x_t,t)$</li>
<li>入公式得到 $q(x_{t-1}\mid x_t)$ ，利用重参数化得到 $x_{t-1}$ 。</li>
</ul>
<p></p>
<h3 id="43训练损">4.3、训练损</h3>
<p>下面我们来看损失的推导，我们来回顾第二项：</p>
<p></p>
<p>我们需要减小KL散度，由于<mark>方差是固定的，我们无法优化，所以需要将它们的均值之差减小</mark>，原论文中使用的是简单的均方误差：</p>
<p>将$\mu$表达式代入：</p>
<p>$$
\begin{aligned}
L_{t}&amp; =\frac1{2\sigma_t^2}\mid|\tilde{\mu}<em>t(x_t,x_0)-\mu</em>\theta(x_t,t)||^2  \cr
&amp;=\frac1{2\sigma_t^2}\mid\mid\frac1{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\overline{\alpha}<em>t}}\left.\varepsilon\right)-\frac1{\sqrt{\alpha_t}}(x_t-\frac{\beta_t}{\sqrt{1-\overline{\alpha}<em>t}}\left.\varepsilon</em>\theta(x_t,t)\right)\mid\mid^2 \cr
&amp;=\frac{\beta_t^2}{2\sigma_t^2\alpha_t(1-\overline{\alpha}<em>t)}\underbrace{\mid\mid\varepsilon-\varepsilon</em>\theta(x_t,t)\mid\mid^2}</em>{mse} \cr
&amp;-&gt;\mid\mid\varepsilon-\varepsilon_\theta(x_t,t)\mid\mid^2=\mid\mid\varepsilon-\varepsilon_\theta(\sqrt{\overline{\alpha}_t}\left.x_0+\sqrt{1-\overline{\alpha}_t}\left.\varepsilon_t,t\right)\mid\mid^2\right.
\end{aligned}
$$</p>
<p>研究人员发现，忽略前面的系数项会变得更简单，采样质量也会得到提高，所以前面这个系数项我们直接忽略，它是和噪声调度器有关的，我们加噪的话也会使计算复杂。</p>
<p>我们最小化 $\mid\mid\varepsilon-\varepsilon_\theta(x_t, t)\mid\mid^2$ 也就是<strong>最小化了KL散度</strong>，KL散度变小了也就是变分上限优化到最小，所以那个负对数似然也会变小。</p>
<p>上面还剩了最后一项 $-log(p_\theta(x_0\mid x_1))$ ，这个作者决定去掉它，即在 $t=1$ 时，我们不添加噪声。也就是下面横线的地方，只有 $t&gt;1$ 的时候才服从高斯分布，如果 $t\leq {1}$，直接让 $z=0$，即噪声设置为0。</p>
<p></p>
<p>回顾上面整个推导过程：我们从<strong>负对数似然 -&gt; 优化下界 -&gt; 简化下界 -&gt; 预测噪声</strong>。</p>
<h2 id="五torch复现">五、torch复现</h2>
<p><a href="https://wangguisen.blog.csdn.net/article/details/128821008"target="_blank" rel="external nofollow noopener noreferrer">https://wangguisen.blog.csdn.net/article/details/128821008<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<p>ref:
[1]. <a href="https://arxiv.org/abs/2006.11239"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/abs/2006.11239<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[2]. <a href="https://kexue.fm/archives/9119"target="_blank" rel="external nofollow noopener noreferrer">https://kexue.fm/archives/9119<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[3]. <a href="https://zhuanlan.zhihu.com/p/576475987"target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/576475987<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[4]. <a href="https://zhuanlan.zhihu.com/p/525106459"target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/525106459<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[5]. <a href="https://www.bilibili.com/video/BV1b541197HX"target="_blank" rel="external nofollow noopener noreferrer">https://www.bilibili.com/video/BV1b541197HX<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[6]. <a href="https://www.bilibili.com/video/BV1WD4y1E7X5"target="_blank" rel="external nofollow noopener noreferrer">https://www.bilibili.com/video/BV1WD4y1E7X5<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[7]. <a href="https://huggingface.co/blog/annotated-diffusion"target="_blank" rel="external nofollow noopener noreferrer">https://huggingface.co/blog/annotated-diffusion<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[8]. <a href="https://www.datalearner.com/blog/1051664857725795"target="_blank" rel="external nofollow noopener noreferrer">https://www.datalearner.com/blog/1051664857725795<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[9]. <a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models"target="_blank" rel="external nofollow noopener noreferrer">https://lilianweng.github.io/posts/2021-07-11-diffusion-models<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[10]. <a href="https://mp.weixin.qq.com/s?__biz=Mzk0MzIzODM5MA==&amp;mid=2247486128&amp;idx=1&amp;sn=7ffef5d8c1bbf24565d0597eb5eaeb16&amp;chksm=c337b729f4403e3f4ca4fcc1bc04704f72c1dc02876a2bf83c330e7857eba567864da6a64e18&amp;scene=21#wechat_redirect"target="_blank" rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s?__biz=Mzk0MzIzODM5MA==&mid=2247486128&idx=1&sn=7ffef5d8c1bbf24565d0597eb5eaeb16&chksm=c337b729f4403e3f4ca4fcc1bc04704f72c1dc02876a2bf83c330e7857eba567864da6a64e18&scene=21#wechat_redirect<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
[11]. <a href="https://arxiv.org/pdf/2006.11239.pdf"target="_blank" rel="external nofollow noopener noreferrer">paper link<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
]]></description></item><item><title>Effective STL [10] | 注意分配器的协定和约束</title><link>https://jianye0428.github.io/posts/clause_10/</link><pubDate>Sat, 29 Jul 2023 15:38:00 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/clause_10/</guid><description><![CDATA[<h2 id="分配器">分配器</h2>
<p>分配器最初是为抽象内存模型而开发的，允许库开发者忽略在某些16位操作系统上near和far指针的区别，也被设计成促进全功能内存管理器的发展，但事实表明那种方法在STL的一些部分会<font color=red>导致效率损失</font>。</p>
<p>分配器最初被设想为抽象内存模型，在那种情况下，分配器在它们定义的内存模型中提供指针和引用的<code>typedef</code>才有意义。在C++标准里，类型T的对象的默认分配器（巧妙地称为<code>allocator&lt;T&gt;</code>）提供<code>typedef allocator&lt;T&gt;::pointer</code>和<code>allocator&lt;T&gt;::reference</code>，而且也希望用户定义的分配器也提供这些typedef。</p>
<p>建立行为像引用的对象是使用代理对象的例子，而代理对象会导致很多问题。</p>
<p>实际上标准明确地允许库实现假设每个分配器的pointer typedef是T*的同义词，每个分配器的reference typedef与T&amp;相同。对，库实现可以忽视typedef并直接使用原始指针和引用！</p>
<p>分配器是对象，那表明它们可能有成员功能，内嵌的类型和typedef（例如pointer和reference）等等，但标准允许STL实现认为所有相同类型的分配器对象都是等价的而且比较起来总是相等。</p>
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span> <span class="n">T</span><span class="o">&gt;</span> <span class="c1">// 一个用户定义的分配器
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">class</span> <span class="nc">SpecialAllocator</span> <span class="p">{...};</span> <span class="c1">// 模板
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">typedef</span> <span class="n">SpecialAllocator</span><span class="o">&lt;</span><span class="n">Widget</span><span class="o">&gt;</span> <span class="n">SAW</span><span class="p">;</span> <span class="c1">// SAW = “SpecialAllocator for Widgets”
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">list</span><span class="o">&lt;</span><span class="n">Widget</span><span class="p">,</span> <span class="n">SAW</span><span class="o">&gt;</span> <span class="n">L1</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">list</span><span class="o">&lt;</span><span class="n">Widget</span><span class="p">,</span> <span class="n">SAW</span><span class="o">&gt;</span> <span class="n">L2</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">...</span>
</span></span><span class="line"><span class="cl"><span class="n">L1</span><span class="p">.</span><span class="n">splice</span><span class="p">(</span><span class="n">L1</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">L2</span><span class="p">);</span> <span class="c1">// 把L2的节点移到 L1前端
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>记住当list元素从一个list被接合到另一个时，没有拷贝什么。取而代之的是，调整了一些指针，曾经在一个list中的节点发现他们自己现在在另一个list中。这使接合操作既迅速又异常安全。</p>
<p>当L1被销毁时，当然，它必须销毁它的所有节点（以及回收它们的内存），而因为它现在包含最初是L2一部分的节点，L1的分配器必须回收最初由L2的分配器分配的节点。</p>
<p>现在清楚为什么<font color=blue><strong>标准允许STL实现认为相同类型的分配器等价</strong></font>。所以由一个分配器对象（比如L2）分配的内存可以安全地被另一个分配器对象（比如L1）回收。</p>
<p>STL实现可以认为相同类型的分配器等价是多严厉的约束。那意味着可移植的分配器对象——<font color=blue><strong>不能有状态</strong></font>。让我们明确这一点：它意味着可移植的分配器不能有任何非静态数据成员，至少没有会影响它们行为的。</p>
<h2 id="分配原始内存">分配原始内存</h2>
<p>分配器在分配原始内存方面类似operator new，但它们的接口不同。如果你看看operator new和allocator::allocate最普通形式的声明，就会很清楚。</p>
<div class="highlight" id="id-2"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">void</span><span class="o">*</span> <span class="k">operator</span> <span class="nf">new</span><span class="p">(</span><span class="n">size_t</span> <span class="n">bytes</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">pointer</span> <span class="n">allocator</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;::</span><span class="n">allocate</span><span class="p">(</span><span class="n">size_type</span> <span class="n">numObjects</span><span class="p">);</span> <span class="c1">// 记住事实上“pointer”总是 T*的typedef
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>两者都带有一个指定要分配多少内存的参数，但对于<code>operator new</code>，这个参数指定的是字节数，而对于<code>allocator::allocate</code>，它指定的是内存里要能容纳多少个T对象。</p>
<p>通常<code>allocator::size_type</code>是一个<code>size_t</code>的<code>typedef</code>。</p>
<p><code>operator new</code>和<code>allocator::allocate</code>的返回类型也不同。<code>operator new</code>返回<code>void</code>，那是C++传统的表示一个到未初始化内存的指针的方式。<code>allocator::allocate</code>返回一个T（通过<code>pointer typedef</code>），不仅不传统，而且是有预谋的欺诈。从<code>allocator::allocate</code>返回的指针并不指向一个T对象，因为T还没有被构造！</p>
<h2 id="大多数标准容器从未调用它们例示的分配器">大多数标准容器从未调用它们例示的分配器</h2>
<div class="highlight" id="id-3"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">list</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">L</span><span class="p">;</span> <span class="c1">// 和list&lt;int, allocator&lt;int&gt; &gt;一样； allocator&lt;int&gt;从未用来分配内存！
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">set</span><span class="o">&lt;</span><span class="n">Widget</span><span class="p">,</span> <span class="n">SAW</span><span class="o">&gt;</span> <span class="n">s</span><span class="p">;</span> <span class="c1">// 记住SAW是一个 SpecialAllocator&lt;Widget&gt;的typedef； SAW从未分配内存！
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>因为<code>set</code>、<code>multiset</code>、<code>map</code>和<code>multimap</code>是基于节点的容器，即，这些容器所基于的数据结构是每当值被储存就动态分配一个新节点。对于list，节点是列表节点。</p>
<p><strong><font color=lightseagreen>对于标准关联容器，节点通常是树节点，因为标准关联容器通常用平衡二叉搜索树实现。</font></strong></p>
<p><code>list</code>本身由节点组成，每个节点容纳一个T对象和到list中后一个和前一个节点的指针：</p>
<div class="highlight" id="id-4"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span> <span class="n">T</span><span class="p">,</span> <span class="c1">// list的可能
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">typename</span> <span class="n">Allocator</span> <span class="o">=</span> <span class="n">allocator</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span> <span class="o">&gt;</span> <span class="c1">// 实现
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">class</span> <span class="nc">list</span><span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">private</span><span class="o">:</span>
</span></span><span class="line"><span class="cl"><span class="n">Allocator</span> <span class="n">alloc</span><span class="p">;</span> <span class="c1">// 用于T类型对象的分配器
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">struct</span> <span class="nc">ListNode</span><span class="p">{</span> <span class="c1">// 链表里的节点
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="n">T</span> <span class="nl">data</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">ListNode</span> <span class="o">*</span><span class="n">prev</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">ListNode</span> <span class="o">*</span><span class="n">next</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">};</span>
</span></span><span class="line"><span class="cl"><span class="p">...</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span></span></span></code></pre></td></tr></table>
</div>
</div><p>当添加一个新节点到<code>list</code>时，我们需要从分配器为它获取内存，我们要的不是<code>T</code>的内存，我们要的是包含了一个<code>T</code>的<code>ListNode</code>的内存。那使我们的<code>Allocator</code>对象没用了，因为它不为<code>ListNode</code>分配内存，它为T分配内存。现在你理解list为什么从未让它的<code>Allocator</code>做任何分配了：分配器不能提供list需要的。</p>
<p>list需要的是从它的分配器类型那里获得用于ListNode的对应分配器的方法。</p>
<div class="highlight" id="id-5"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span> <span class="n">T</span><span class="o">&gt;</span> <span class="c1">// 标准分配器像这样声明，
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">class</span> <span class="nc">allocator</span> <span class="p">{</span> <span class="c1">// 但也可以是用户写的分配器模板
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">template</span><span class="o">&lt;</span><span class="k">typename</span> <span class="n">U</span><span class="o">&gt;</span>
</span></span><span class="line"><span class="cl">    <span class="k">struct</span> <span class="nc">rebind</span><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">typedef</span> <span class="n">allocator</span><span class="o">&lt;</span><span class="n">U</span><span class="o">&gt;</span> <span class="n">other</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">...</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span></span></span></code></pre></td></tr></table>
</div>
</div><p>在list的实现代码里，需要确定我们持有的T的分配器所对应的<code>ListNode</code>的分配器类型。我们持有的T的分配器类型是模板参数<code>Allocator</code>。</p>
<p>在本例中，<code>ListNodes</code>的对应分配器类型是：</p>
<div class="highlight" id="id-6"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">Allocator</span><span class="o">::</span><span class="n">rebind</span><span class="o">&lt;</span><span class="n">ListNode</span><span class="o">&gt;::</span><span class="n">other</span></span></span></code></pre></td></tr></table>
</div>
</div><p>每个分配器模板A（例如，<code>std::allocator</code>，<code>SpecialAllocator</code>等）都被认为有一个叫做<code>rebind</code>的内嵌结构体模板。<code>rebind</code>带有一个类型参数<code>U</code>, 并且只定义一个<code>typedef A&lt;U&gt; other</code>. other是<code>A&lt;U&gt;</code>的一个简单名字。</p>
<p>结果，List<T>可以通过<code>Allocator::rebind&lt;ListNode&gt;::other</code>从它用于T对象的分配器（叫做Allocator）获取对应的<code>ListNode</code>对象分配器。</p>
<h2 id="结论">结论</h2>
<p>如果你想要写自定义分配器，让我们总结你需要记得的事情。</p>
<ul>
<li>把你的分配器做成一个模板，带有模板参数T，代表你要分配内存的对象类型。</li>
<li>提供pointer和reference的typedef，但是总是让pointer是T*，reference是T&amp;。</li>
<li>决不要给你的分配器每对象状态。通常，分配器不能有非静态的数据成员。- 记得应该传给分配器的allocate成员函数需要分配的对象个数而不是字节数。也应该记得这些函数返回T*指针（通过pointer typedef），即使还没有T对象被构造。</li>
<li>一定要提供标准容器依赖的内嵌rebind模板。</li>
</ul>
]]></description></item><item><title>Effective STL [9] | 在删除选项中仔细选择</title><link>https://jianye0428.github.io/posts/clause_9/</link><pubDate>Fri, 28 Jul 2023 07:59:27 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/clause_9/</guid><description><![CDATA[<!-- <div class="details admonition quote">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-quote-right fa-fw" aria-hidden="true"></i>quote<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content">note abstract info tip success question warning failure danger bug example quote</div>
    </div>
  </div> -->
<h2 id="删除指定值对象">删除指定值对象</h2>
<p>假定你有一个容纳<code>int</code>标准STL容器:</p>
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">Container</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">c</span><span class="p">;</span></span></span></code></pre></td></tr></table>
</div>
</div><p>而你想把c中所有值为2023的对象都去掉。</p>
<p>令人吃惊的是，完成这项任务的方法因不同的容器类型而不同：没有一种方法是通用的。</p>
<ul>
<li>当c是连续内存容器（vector、deque或string），最好的方法是erase-remove惯用法</li>
</ul>
<div class="highlight" id="id-2"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">c</span><span class="p">.</span><span class="n">erase</span><span class="p">(</span><span class="n">remove</span><span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">c</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span> <span class="mi">2023</span><span class="p">),</span> <span class="n">c</span><span class="p">.</span><span class="n">end</span><span class="p">());</span>
</span></span><span class="line"><span class="cl"><span class="c1">// 当c是vector、string或deque时，
</span></span></span><span class="line"><span class="cl"><span class="c1">// erase-remove惯用法是去除特定值的元素的最佳方法
</span></span></span></code></pre></td></tr></table>
</div>
</div><div class="details admonition Note">
    <div class="details-summary admonition-title">
      <i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden="true"></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden="true"></i>
    </div>
    <div class="details-content">
      <div class="admonition-content"><ul>
<li>STL 和 vector中的remove的作用是<strong>将等于value的元素放到vector的尾部</strong>，但并不减少vector的size；</li>
<li>vector中erase的作用是删除掉某个位置position或一段区域(begin, end)中的元素，减少其size，返回被删除元素下一个元素的位置。</li>
</ul>
</div>
    </div>
  </div>
<ul>
<li>这方法也适合于<code>list</code>，但是<code>list</code>的成员函数<code>remove</code>更高效：</li>
</ul>
<div class="highlight" id="id-3"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="c1">// 当c是list时，remove成员函数是去除特定值的元素的最佳方法
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">c</span><span class="p">.</span><span class="n">remove</span><span class="p">(</span><span class="mi">1963</span><span class="p">);</span></span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>当c是标准关联容器（即<code>set</code>、<code>multiset</code>、<code>map</code>或<code>multimap</code>）时，使用任何叫做<code>remove</code>的东西都是完全错误的。这样的容器没有叫做remove的成员函数，而且使用remove算法可能覆盖容器值，潜在地破坏容器。对于关联容器，解决问题的适当方法是调用erase：</li>
</ul>
<div class="highlight" id="id-4"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="c1">// 当c是标准关联容器时,erase成员函数是去除特定值的元素的最佳方法
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">c</span><span class="p">.</span><span class="n">erase</span><span class="p">(</span><span class="mi">2023</span><span class="p">);</span></span></span></code></pre></td></tr></table>
</div>
</div><p>这很高效，只花费对数时间，<strong>序列容器的基于删除的技术需要线性时间</strong>。并且，关联容器的<code>erase</code>成员函数有基于等价而不是相等的优势。</p>
<h2 id="消除判断式">消除判断式</h2>
<p>消除下面判断式，返回真的每个对象:</p>
<div class="highlight" id="id-5"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">bool</span> <span class="nf">badValue</span><span class="p">(</span><span class="kt">int</span> <span class="n">x</span><span class="p">);</span> <span class="c1">// 返回x是否是“bad”
</span></span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>对于序列容器（<code>vector</code>、<code>string</code>、<code>deque</code>和<code>list</code>），把每个<code>remove</code>替换为<code>remove_if</code>：</li>
</ul>
<div class="highlight" id="id-6"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">c</span><span class="p">.</span><span class="n">erase</span><span class="p">(</span><span class="n">remove_if</span><span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">c</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span> <span class="n">badValue</span><span class="p">),</span> <span class="c1">// 当c是vector、string或deque时
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">c</span><span class="p">.</span><span class="n">end</span><span class="p">());</span> <span class="c1">// 这是去掉badValue返回真的对象的最佳方法
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl"><span class="n">c</span><span class="p">.</span><span class="n">remove_if</span><span class="p">(</span><span class="n">badValue</span><span class="p">);</span> <span class="c1">// 当c是list时这是去掉badValue返回真的对象的最佳方法
</span></span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>对于标准关联容器，有两种方法处理该问题，一个更容易编码，另一个更高效。</li>
</ul>
<div class="highlight" id="id-7"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">AssocContainer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">c</span><span class="p">;</span> <span class="c1">// c现在是一种标准关联容器
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl"><span class="n">AssocContainer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">goodValues</span><span class="p">;</span> <span class="c1">// 用于容纳不删除的值的临时容器
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl"><span class="n">remove_copy_if</span><span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">c</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span><span class="n">inserter</span><span class="p">(</span><span class="n">goodValues</span><span class="p">,</span> <span class="n">goodValues</span><span class="p">.</span><span class="n">end</span><span class="p">()),</span> <span class="n">badValue</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">c</span><span class="p">.</span><span class="n">swap</span><span class="p">(</span><span class="n">goodValues</span><span class="p">);</span> <span class="c1">// 交换c和goodValues的内容
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>对这种方法的<strong>缺点</strong>是它拷贝了所有不删除的元素。</p>
<p>因为关联容器没有提供类似<code>remove_if</code>的成员函数，所以必须写一个循环来迭代c中的元素，和原来一样删除元素。不幸的是，那些正确工作的代码很少是跃出脑海的代码。例如，这是很多程序员首先想到的：</p>
<div class="highlight" id="id-8"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">AssocContainer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">c</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">...</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="p">(</span><span class="n">AssocContainer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;::</span><span class="n">iterator</span> <span class="n">i</span> <span class="o">=</span> <span class="n">c</span><span class="p">.</span><span class="n">begin</span><span class="p">();</span> <span class="n">i</span><span class="o">!=</span> <span class="n">c</span><span class="p">.</span><span class="n">end</span><span class="p">();</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>  <span class="c1">// 清晰，直截了当而漏洞百出的,用于删除c中badValue返回真的每个元素的代码
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">if</span> <span class="p">(</span><span class="n">badValue</span><span class="p">(</span><span class="o">*</span><span class="n">i</span><span class="p">))</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">c</span><span class="p">.</span><span class="n">erase</span><span class="p">(</span><span class="n">i</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span> <span class="c1">// 不要这么做！
</span></span></span></code></pre></td></tr></table>
</div>
</div><p>这有未定义的行为。当容器的一个元素被删时，<strong>指向那个元素的所有迭代器都失效了</strong>。</p>
<p>当<code>c.erase(i)</code>返回时，<code>i</code>已经失效。那对于这个循环是个坏消息，因为在<code>erase</code>返回后，<code>i</code>通过for循环的<code>++i</code>部分自增。为了避免这个问题，我们必须保证在调用<code>erase</code>之前就得到了c中下一元素的迭代器。最容易的方法是当我们调用时在i上使用后置递增：</p>
<div class="highlight" id="id-9"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">AssocContainer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">c</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">...</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="p">(</span><span class="n">AssocContainer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;::</span><span class="n">iterator</span> <span class="n">i</span> <span class="o">=</span> <span class="n">c</span><span class="p">.</span><span class="n">begin</span><span class="p">();</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">c</span><span class="p">.</span><span class="n">end</span><span class="p">();</span><span class="cm">/*nothing*/</span> <span class="p">){</span><span class="c1">// for循环的第三部分是空的；i现在在下面自增
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">if</span> <span class="p">(</span><span class="n">badValue</span><span class="p">(</span><span class="o">*</span><span class="n">i</span><span class="p">))</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">c</span><span class="p">.</span><span class="n">erase</span><span class="p">(</span><span class="n">i</span><span class="o">++</span><span class="p">);</span> <span class="c1">// 对于坏的值，把当前的i传给erase，然后作为副作用增加i；
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="o">++</span><span class="n">i</span><span class="p">;</span> <span class="c1">// 对于好的值，只增加i
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div><p>精髓的地方在于：这种调用<code>erase</code>的解决方法可以工作，因为表达式i++的值是i的旧值，但作为副作用，i增加了。</p>
<p>因此，我们把i的旧值（没增加的）传给<code>erase</code>，但在<code>erase</code>开始执行前i已经自增了。</p>
<p>现在不仅删除<code>badValue</code>返回真的每个元素，而且每当一个元素被删掉时，我们也想把一条消息写到日志文件中。</p>
<ul>
<li>可以通过<strong>直接从原容器删除元素来避开拷贝</strong>。</li>
<li>“更容易但效率较低”的解决方案用<code>remove_copy_if</code><strong>把需要的值拷贝到一个新容器中，然后把原容器的内容和新的交换</strong>：</li>
</ul>
<p>对于<strong>关联容器</strong>，这说多容易就有多容易，因为只需要对刚才开发的循环做一个微不足道的修改就行了：</p>
<div class="highlight" id="id-10"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">ofstream</span> <span class="n">logFile</span><span class="p">;</span> <span class="c1">// 要写入的日志文件
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">AssocContainer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">c</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">...</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="p">(</span><span class="n">AssocContainer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;::</span><span class="n">iterator</span> <span class="n">i</span> <span class="o">=</span> <span class="n">c</span><span class="p">.</span><span class="n">begin</span><span class="p">();</span> <span class="n">i</span> <span class="o">!=</span><span class="n">c</span><span class="p">.</span><span class="n">end</span><span class="p">();){</span><span class="c1">// 循环条件和前面一样
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">if</span> <span class="p">(</span><span class="n">badValue</span><span class="p">(</span><span class="o">*</span><span class="n">i</span><span class="p">)){</span>
</span></span><span class="line"><span class="cl">        <span class="n">logFile</span> <span class="o">&lt;&lt;</span> <span class="s">&#34;Erasing &#34;</span> <span class="o">&lt;&lt;</span> <span class="o">*</span><span class="n">i</span> <span class="o">&lt;&lt;</span><span class="sc">&#39;\n&#39;</span><span class="p">;</span> <span class="c1">// 写日志文件
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>        <span class="n">c</span><span class="p">.</span><span class="n">erase</span><span class="p">(</span><span class="n">i</span><span class="o">++</span><span class="p">);</span> <span class="c1">// 删除元素
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="o">++</span><span class="n">i</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div><p>现在是<code>vector</code>、<code>string</code>和<code>deque</code>不能再使用<code>erase-remove</code>惯用法，因为没有办法让<code>erase</code>或<code>remove</code>写日志文件。</p>
<p>而且，我们不能使用刚刚为关联容器开发的循环，因为它为<code>vector</code>、<code>string</code>和<code>deque</code>产生未定义的行为！</p>
<p>要记得对于那样的容器，<strong>调用<code>erase</code>不仅使所有指向被删元素的迭代器失效，也使被删元素之后的所有迭代器失效</strong>。</p>
<p>包括所有i之后的迭代器。我们写<code>i++</code>，<code>++i</code>或你能想起的其它任何东西都没有用，因为没有能导致迭代器有效的。必须利用erase的返回值。那个返回值正是我们需要的：<strong>一旦删除完成，它就是指向紧接在被删元素之后的元素的有效迭代器。</strong></p>
<p>我们这么写：</p>
<div class="highlight" id="id-11"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">for</span> <span class="p">(</span><span class="n">SeqContainer</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;::</span><span class="n">iterator</span> <span class="n">i</span> <span class="o">=</span> <span class="n">c</span><span class="p">.</span><span class="n">begin</span><span class="p">();</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">c</span><span class="p">.</span><span class="n">end</span><span class="p">();){</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">badValue</span><span class="p">(</span><span class="o">*</span><span class="n">i</span><span class="p">)){</span>
</span></span><span class="line"><span class="cl">        <span class="n">logFile</span> <span class="o">&lt;&lt;</span> <span class="s">&#34;Erasing &#34;</span> <span class="o">&lt;&lt;</span> <span class="o">*</span><span class="n">i</span> <span class="o">&lt;&lt;</span> <span class="sc">&#39;\n&#39;</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">i</span> <span class="o">=</span> <span class="n">c</span><span class="p">.</span><span class="n">erase</span><span class="p">(</span><span class="n">i</span><span class="p">);</span> <span class="c1">// 通过把erase的返回值
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="p">}</span> <span class="c1">// 赋给i来保持i有效
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">       <span class="o">++</span><span class="n">i</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div><p><strong><font color=blue>这可以很好地工作，但只用于标准序列容器</font></strong>。</p>
<p>标准关联容器的<code>erase</code>的返回类型是<code>void</code>。对于那些容器，你必须使用“<strong>后置递增你要传给erase的迭代器</strong>”技术。为了避免你奇怪<code>list</code>的适当方法是什么，事实表明对于迭代和删除，你可以像<code>vector/string/deque</code>一样或像关联容器一样对待list；两种方法都可以为list工作。</p>
<h2 id="结论">结论</h2>
<ol>
<li><strong>去除一个容器中有特定值的所有对象</strong>：</li>
</ol>
<ul>
<li>如果容器是<code>vector</code>、<code>string</code>或<code>deque</code>，使用<code>erase-remove</code>惯用法</li>
<li>如果容器是<code>list</code>，使用<code>list::remove</code></li>
<li>如果容器是标准关联容器，使用它的<code>erase</code>成员函数</li>
</ul>
<ol start="2">
<li><strong>去除一个容器中满足一个特定判定式的所有对象</strong>：</li>
</ol>
<ul>
<li>如果容器是<code>vector</code>、<code>string</code>或<code>deque</code>，使用<code>erase-remove_if</code>惯用法</li>
<li>如果容器是<code>list</code>，使用<code>list::remove_if</code></li>
<li>如果容器是标准关联容器，使用<code>remove_copy_if</code>和<code>swap</code>，或写一个循环来遍历容器元素，当你把迭代器传给<code>erase</code>时记得后置递增它</li>
</ul>
<ol start="3">
<li><strong>在循环内做某些事情（除了删除对象之外）</strong>：</li>
</ol>
<ul>
<li>如果容器是标准<strong>序列容器</strong>，写一个循环来遍历容器元素，<strong>每当调用<code>erase</code>时记得都用它的返回值更新你的迭代器</strong>。</li>
<li>如果容器是标准<strong>关联容器</strong>，写一个循环来遍历容器元素，当<strong>你把迭代器传给<code>erase</code>时记得后置递增它</strong>。</li>
</ul>
<p>如你所见，与仅仅调用erase相比，有效地删除容器元素有更多的东西。</p>
<p><strong>解决问题的最好方法取决于你是怎样鉴别出哪个对象是要被去掉的，储存它们的容器的类型，和当你删除它们的时候你还想要做什么（如果有的话）。</strong></p>
<p>这仅对带有迭代器实参的<code>erase</code>形式是正确的。关联容器也提供一个带有一个值的实参的<code>erase</code>形式，而那种形式返回被删掉的元素个数。但这里，我们只关心通过迭代器删除东西。</p>]]></description></item><item><title>Effective STL [4] | 用empty来代替检查size()是否为0</title><link>https://jianye0428.github.io/posts/clause_4/</link><pubDate>Mon, 24 Jul 2023 13:15:46 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/clause_4/</guid><description><![CDATA[<h2 id="判断容器是否为空">判断容器是否为空</h2>
<p>对于任意容器 randy, 当判断是否为空的时候，会使用到以下判断语句：</p>
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">if</span><span class="p">(</span><span class="n">randy</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="p">...</span> <span class="c1">// work
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// or
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl"><span class="k">if</span><span class="p">(</span><span class="n">randy</span><span class="p">.</span><span class="n">empty</span><span class="p">())</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="p">...</span> <span class="c1">// work
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div><p>应该首选empty的构造，而且理由很简单：<strong>对于所有的标准容器，empty是一个常数时间的操作，但对于一些<code>list</code>实现，<code>size</code>花费线性时间</strong></p>
<h2 id="list-size耗时">list size耗时</h2>
<p><strong>Q</strong>：但是什么造成list这么麻烦？为什么不能也提供一个常数时间的size？</p>
<p><strong>A</strong>：对于list特有的splice有很多要处理的东西。</p>
<p>考虑这段代码：</p>
<div class="highlight" id="id-2"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="n">list</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">list1</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="n">list</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">list2</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">...</span>
</span></span><span class="line"><span class="cl"><span class="n">list1</span><span class="p">.</span><span class="n">splice</span><span class="p">(</span> <span class="c1">// 把list2中
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">list1</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span> <span class="n">list2</span><span class="p">,</span> <span class="c1">// 从第一次出现5到
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">find</span><span class="p">(</span><span class="n">list2</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">list2</span><span class="p">.</span><span class="n">end</span><span class="p">(),</span> <span class="mi">5</span><span class="p">),</span> <span class="c1">// 最后一次出现10
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="n">find</span><span class="p">(</span><span class="n">list2</span><span class="p">.</span><span class="n">rbegin</span><span class="p">(),</span> <span class="n">list2</span><span class="p">.</span><span class="n">rend</span><span class="p">(),</span> <span class="mi">10</span><span class="p">).</span><span class="n">base</span><span class="p">()</span> <span class="c1">// 的所有节点移到list1的结尾。
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">);</span></span></span></code></pre></td></tr></table>
</div>
</div><p>除非<code>list2</code>在5的后面有一个10，否则这段代码无法工作，但是咱们假设这不是问题。</p>
<p><strong>Q</strong>：假设上述代码可以正常运行，那么接合后<code>list1</code>有多少元素？</p>
<p><strong>A</strong>：结合后<code>list1</code>的元素个数=接合之后前<code>list1</code>的元素个数 + 接合进去的元素个数</p>
<p><strong>Q</strong>：有多少元素接合进去了？</p>
<p><strong>A</strong>：元素个数为<code>find(list2.rbegin(), list2.rend(), 10).base()</code>所定义的区间的元素个数。</p>
<p>到底有多少？</p>
<p>在没有遍历这个区间并计数之前无法知道。</p>
<p><strong>问题剖析</strong></p>
<p>如果size是一个常数时间操作，当操作时每个list成员函数必须更新list的大小。也包括了splice。</p>
<p>让区间版本的splice更新它所更改的list大小的<strong>唯一的方法</strong>是算出接合进来的元素的个数，但<strong>那么做就会使它不可能有你所希望的常数时间的性能。</strong></p>
<p>如果你去掉了splice的区间形式要更新它所修改的list的大小的需求，splice就可以是常数时间，但<strong>size就变成线性时间的操作</strong>。</p>
<p>一般来说，<strong>必须遍历它的整个数据结构来才知道包含多少元素</strong>。</p>
<p>不同的list实现用不同的方式解决这个矛盾，依赖于他们的作者选择的是让size或splice的区间形式达到最高效率。</p>
<p>如果你碰巧使用了一个常数时间的splice的区间形式比常数时间的size优先级更高的list实现，<strong>调用empty比调用size更好，因为empty总是常数时间操作。</strong></p>
<h2 id="结论">结论</h2>
<p>不同的list实现用不同的方式解决这个矛盾，依赖于它们的作者选择的是让size或splice的区间形式达到最高效率。</p>
<p>如果你碰巧使用了一个常数时间的splice的区间形式比常数时间的size优先级更高的list实现，<font color=blue>调用empty比调用size更好，因为empty总是常数时间操作。</font></p>
<h2 id="stl-vector-和-list的empty-及-size--实现源码">STL vector 和 list的empty 及 size  实现源码</h2>
<p><strong>vector</strong></p>
<div class="highlight" id="id-3"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="c1">// vector
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>  <span class="n">size_type</span>
</span></span><span class="line"><span class="cl">  <span class="nf">size</span><span class="p">()</span> <span class="k">const</span> <span class="n">_GLIBCXX_NOEXCEPT</span>
</span></span><span class="line"><span class="cl">  <span class="p">{</span> <span class="k">return</span> <span class="n">size_type</span><span class="p">(</span><span class="n">end</span><span class="p">()</span> <span class="o">-</span> <span class="n">begin</span><span class="p">());</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">  <span class="kt">bool</span>
</span></span><span class="line"><span class="cl">  <span class="nf">empty</span><span class="p">()</span> <span class="k">const</span> <span class="n">_GLIBCXX_NOEXCEPT</span>
</span></span><span class="line"><span class="cl">  <span class="p">{</span> <span class="k">return</span> <span class="n">begin</span><span class="p">()</span> <span class="o">==</span> <span class="n">end</span><span class="p">();</span> <span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div><p><strong>list</strong></p>
<div class="highlight" id="id-4"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="c1">// list
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl"><span class="cm">/**  Returns the number of elements in the %list.  */</span>
</span></span><span class="line"><span class="cl"><span class="n">size_type</span>
</span></span><span class="line"><span class="cl"><span class="nf">size</span><span class="p">()</span> <span class="k">const</span> <span class="n">_GLIBCXX_NOEXCEPT</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span> <span class="k">return</span> <span class="n">_M_node_count</span><span class="p">();</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">      <span class="c1">// return the stored size
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>      <span class="n">size_t</span>
</span></span><span class="line"><span class="cl">      <span class="nf">_M_node_count</span><span class="p">()</span> <span class="k">const</span>
</span></span><span class="line"><span class="cl">      <span class="p">{</span> <span class="k">return</span> <span class="k">this</span><span class="o">-&gt;</span><span class="n">_M_get_size</span><span class="p">();</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// size() 调用 _M_get_size
</span></span></span><span class="line"><span class="cl"><span class="c1"></span> <span class="n">size_t</span> <span class="nf">_M_get_size</span><span class="p">()</span> <span class="k">const</span> <span class="p">{</span> <span class="k">return</span> <span class="n">_M_impl</span><span class="p">.</span><span class="n">_M_node</span><span class="p">.</span><span class="n">_M_size</span><span class="p">;</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// [23.2.2.2] capacity
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="cm">/**
</span></span></span><span class="line"><span class="cl"><span class="cm">*  Returns true if the %list is empty.  (Thus begin() would equal
</span></span></span><span class="line"><span class="cl"><span class="cm">*  end().)
</span></span></span><span class="line"><span class="cl"><span class="cm">*/</span>
</span></span><span class="line"><span class="cl"><span class="n">_GLIBCXX_NODISCARD</span> <span class="kt">bool</span>
</span></span><span class="line"><span class="cl"><span class="nf">empty</span><span class="p">()</span> <span class="k">const</span> <span class="n">_GLIBCXX_NOEXCEPT</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span> <span class="k">return</span> <span class="k">this</span><span class="o">-&gt;</span><span class="n">_M_impl</span><span class="p">.</span><span class="n">_M_node</span><span class="p">.</span><span class="n">_M_next</span> <span class="o">==</span> <span class="o">&amp;</span><span class="k">this</span><span class="o">-&gt;</span><span class="n">_M_impl</span><span class="p">.</span><span class="n">_M_node</span><span class="p">;</span> <span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div>]]></description></item><item><title>VectorNet 论文解读</title><link>https://jianye0428.github.io/posts/vectornet/</link><pubDate>Sun, 16 Jul 2023 17:13:44 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/vectornet/</guid><description><![CDATA[<h2 id="novel-highlights">Novel Highlights</h2>
<p>(1) 使用矢量化的高精地图以及障碍物的历史轨迹，从而避免有损渲染以及ConvNet编码(计算开销比较大)。</p>
<p>(2) 设计子图网络以及全局图网络，建模低阶以及高阶交互</p>
<p>(3) auxiliary task 提高网络性能</p>
<p></p>
<h2 id="vecotornet-网络介绍">VecotorNet 网络介绍</h2>
<h3 id="轨迹和地图的向量表示-representing-trajectories-and-hd-maps">轨迹和地图的向量表示 Representing trajectories and HD maps</h3>
<p>lane可以表示为splines，人行道可以表示为一个很多个点组成的polygon，stop sign标记可以表示为单一个点。 对于agent来说，他们的轨迹也是一种splines。 这些元素都可以向量表示。</p>
<ul>
<li>对于地图的特征：选择一个start point和朝向，等间距均匀采样关键点，并于相邻的关键点相连为向量</li>
<li>对于agent轨迹，按照0.1s sample关键点，并将它们连接成向量。</li>
</ul>
<p>通过向量化的过程，可以得到折线polylines，这个polylines和轨迹、地图标注之间是一一对应的。如果给定的时空间隔足够小，得到的这些折线就与原始地图和轨迹十分接近。</p>
<p>我们将属于折线 $P_j$​ 的每一个向量$v_i$看作图中的一个节点，节点特征如下:</p>
<p>$$v_i = [d_i^s, d_i^e, a_i, j]$$</p>
<ul>
<li>其中前两个vector分别是vector的start point和end point的坐标，可以是(x,y)或者(x,y,z)三维的形式</li>
<li>第三个向量则是attribute属性的特征，比如object的类型，轨迹的时间戳，道路的特征，道路限速等</li>
<li>最后一个是障碍物id，表示 $v_i$ ​属于 $P_j$</li>
</ul>
<h3 id="polyline-子图构建">Polyline 子图构建</h3>
<p>对于一个Polyline P, 它的节点有 ${v_1,v_2,&hellip;,v_p}$， 可以定义一个子图网络：</p>
<p>$$v_i^{l+1} = \varphi_{rel}(g_{enc}(v_i^{(l)}), \varphi({g_{enc}(v_j^{(l)})}))$$</p>
<ul>
<li>
<p>$v_i^{(l)}$​ 代表第i个节点第L层的节点特征。</p>
</li>
<li>
<p>$g_{enc}(\cdot)$代表节点的变换，实践中采用MLP来实现。</p>
</li>
<li>
<p>$\varphi_{agg}(\cdot)$代表特征聚合，用来从相邻的节点来获取信息，实践中采用的是max_pooling。</p>
</li>
<li>
<p>$\varphi_{rel}(\cdot)$代表vi和周围节点的关系，实践中采用的是concate的操作。</p>
</li>
</ul>
<p></p>
<p>最后经过多层的堆叠，来获取整个Polyline级别的特征：</p>
<p>$$P = \varphi_{agg}(v_i^{L_p})$$</p>
<p>这里， $φ_{agg}(⋅)$也是max pooling操作.</p>
<h3 id="全局图的高阶交互-global-graph-for-high-order-interactions">全局图的高阶交互 Global graph for high-order interactions</h3>
<p>经过上面的子图进行低阶模型建模后，现在有了polyline级别节点的特征${p_1,p_2,&hellip;,p_P}$.</p>
<p>为了建立高阶的交互，需要建立一个global的交互图，详见论文图2的第3个子图。</p>
<p>$$P_i^{l+1} = GNN(p^l_i, A)$$</p>
<ul>
<li>
<p>$p_i^l$​代表polyline节点的集合</p>
</li>
<li>
<p>A代表邻接矩阵，实践中采用全链接</p>
</li>
<li>
<p>$GNN(⋅)$代表一层的GNN网络，实践中采用的是self attention layer：
$$GNN(P) = softmax(P_Q P_K^T)P_V$$</p>
<p>其中，P是node的feature matrix， $P_Q$,$P_k$,$P_v$ ​则是它的线性投影。</p>
</li>
</ul>
<p>经过了全局的网络之后，就生成了节点的特征$P^{L_t}_i$，其中Lt是全局GNN网络的层数。然后将$P^{(L_t)}_i$放入decoder进行轨迹的生成:</p>
<p>$$v_i^{future} = \varphi_{traj}(P_i^{L_t})$$</p>
<p>论文中，decoder $φ_{traj}(⋅)$ 使用的是MLP，当然也可以用MultiPath中anchor-based的方法或者variational RNNs 来进行多模态轨迹预测。</p>
<h3 id="辅助任务训练-auxiliary-graph-completion-task">辅助任务训练 auxiliary graph completion task</h3>
<p>为了让全局交互图能更好地捕捉不同轨迹和地图元素之间的交互信息，论文还提出了一个辅助的任务：在训练过程中，随机mask掉一些节点的特征，然后尝试去还原被掩盖的节点特征:</p>
<p>$$\hat{P}<em>_i = \varphi</em>_{node}(P_i^{L_t})$$</p>
<p>这里节点的decoder $φ_{node}(⋅)$ 也是一个MLP，只在训练的时候使用,在inference过程中不使用。</p>
<h3 id="损失函数-loss-function">损失函数 Loss Function</h3>
<p>多任务训练目标， multi-task training task:</p>
<p>$$\mathcal{L} = \mathcal{L_{traj}} + \alpha \mathcal{L_{node}}$$</p>
<ul>
<li>
<p>$L_{traj}​$: negative Gaussian log-likelihood loss</p>
</li>
<li>
<p>$L_{node}$​: 是预测的节点和被掩盖节点的huber损失函数</p>
</li>
</ul>
<p>其中，
negative Gaussian Log Likelihood 损失函数为:</p>
<p>$$L(x, y) = -\log P(y) = - \log P(y|\mu(x), \sum(x))$$</p>
<p>where,</p>
<p>$$p(y) = p(y∣μ,Σ)=1(2π)n/2∣Σ∣1/2exp−12(y−μ)⊤Σ−1(y−μ)$$</p>
<p>Huber 损失函数为:</p>
<p>$$ L(Y|f(x))= \begin{cases} \frac{1}{2} (Y-f(x))^2, &amp; |Y-f(x)|&lt;= \delta \\ \delta |Y-f(x)| - \frac{1}{2}\delta^2, &amp; |Y-f(x)| &gt; \delta \end{cases} $$</p>
<h2 id="整理">整理</h2>
<p><strong>VectorNet数据处理部分:</strong></p>
<ul>
<li>
<p>对actor的处理:</p>
<ul>
<li>输入: 取轨迹点，每两个轨迹点构建vector, 形式为(x1, x2, y1, y2), 其他特征(object type, timestamp, track_id)</li>
</ul>
</li>
<li>
<p>对lane node的处理:</p>
<ul>
<li>输入: 针对lane segment 的点，求polyline，原则上求lane segment的左右边界的点的向量(x_start, x_end, y_start, y_end, turn_direction, traffic_control, is_intersection, lane_id)</li>
</ul>
</li>
</ul>
<p><strong>网络部分:</strong></p>
<ul>
<li>
<p>构建subgraphnet: 针对每一个polyline，通过mlp和maxpool构建subgraphnet</p>
</li>
<li>
<p>构建globalgraphnet: 以每个polyline作为graph node，构建全局图网络，采用全链接，通过自注意力机制$GNN(P) = softmax(P_Q, P_K)^T(P_V)$</p>
</li>
</ul>
<p><strong>轨迹生成:</strong></p>
<p>将全局网络的节点特征，通过mlp进行轨迹生成。</p>
<p><code>ref link</code>:
[1] <a href="https://blog.csdn.net/qq_41897558/article/details/120087113"target="_blank" rel="external nofollow noopener noreferrer">https://blog.csdn.net/qq_41897558/article/details/120087113<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[2] <a href="https://zhuanlan.zhihu.com/p/355131328"target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/355131328<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
<code>ref code</code>:
[1]https://github.com/xk-huang/yet-another-vectornet</br>
[2]https://github.com/DQSSSSS/VectorNet</br></p>
]]></description></item><item><title>CRAT-Prediction</title><link>https://jianye0428.github.io/posts/crat_pred/</link><pubDate>Sun, 16 Jul 2023 15:54:26 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/crat_pred/</guid><description><![CDATA[<h2 id="overview">Overview</h2>
<p><code>paper link:</code><a href="https://arxiv.org/pdf/2202.04488.pdf"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/pdf/2202.04488.pdf<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<h2 id="论文概览">论文概览</h2>
<ul>
<li>
<p>文章提出了一种结合Crystal Graph Convolutional Neural Network和Multi-Head Self-Attention Mechanism对交通agent处理的方式</p>
</li>
<li>
<p>在argoverse数据集上进行验证，实现了map-free预测模型的SOTA效果; 相比较于其他模型，模型参数更少。</p>
</li>
<li>
<p>证明: 可以通过 Self-Attention Mechanism 学习到交通参与者之间的交互关系。</p>
</li>
</ul>
<h2 id="网络结构">网络结构</h2>
<p></p>
<ul>
<li>数据处理: 以argoverse2数据为例，取前50帧数据，两两作差值，取49组位移向量数据为输入</li>
<li>
<ul>
<li>首先用<code>EncoderLSTM</code>作为encoder</li>
</ul>
</li>
<li>
<ul>
<li>再将每一个agent作为node，通过<code>Crystal Graph Convolutional Neural Network</code>构建图神经网络</li>
</ul>
</li>
<li>
<ul>
<li>通过<code>Multi-Head Self-Attention</code>学习node之间的交互关系</li>
</ul>
</li>
</ul>
<h2 id="实现原理">实现原理</h2>
<h3 id="input-encoder-输入编码器">Input Encoder 输入编码器</h3>
<p>输入数据为过去5秒的离散位移:
$$s_i^t = (\Delta{\tau_i^t} || b_i^t)$$</p>
<p>其中， $\Delta \tau_i^t = \tau_i^{t-1}$.</p>
<h3 id="interaction-module-交互模块">Interaction Module 交互模块</h3>
<h3 id="output-decoder-输出编码器">Output Decoder 输出编码器</h3>
<h3 id="training-训练过程">Training 训练过程</h3>
<h2 id="代码实现结构">代码实现结构</h2>
<p><strong>数据处理结构</strong>
<code>input = dict()</code></br>
<code>input['argo_id'] = list()</code></br>
<code>input['city'] = list()</code></br>
<code>input['past_trajs'] = list()</code></br>
<code>input['fut_trajs'] = list()</code></br>
<code>input['gt'] = list()</code></br>
<code>input['displ'] = list()</code></br>
<code>input['centers'] = list()</code></br>
<code>input['origin'] = list()</code></br>
<code>input['rotation'] = list()</code></br></p>
<p>29 + 32 = 61</br>
<code>argo_id:</code></br>
[&lsquo;01d7deae-31e9-4657-843f-c30009b09f1c&rsquo;, &lsquo;01ca1736-ec51-41aa-8c73-3338c574a83a&rsquo;]</br>
<code>city:</code></br>
[&lsquo;austin&rsquo;, &lsquo;austin&rsquo;]</br>
<code>past_trajs:</code></br>
torch.Size([29, 50, 3])</br>
torch.Size([32, 50, 3])</br>
<code>fut_trajs:</code></br>
torch.Size([29, 60, 3])</br>
torch.Size([32, 60, 3])</br>
<code>gt:</code></br>
torch.Size([29, 60, 2])</br>
torch.Size([32, 60, 2])</br>
<code>displ:</code></br>
torch.Size([29, 49, 3])</br>
torch.Size([32, 49, 3])</br>
<code>centers:</code></br>
torch.Size([29, 2])</br>
torch.Size([32, 2])</br>
<code>origin:</code></br>
torch.Size([2])</br>
torch.Size([2])</br>
<code>rotation:</code></br>
torch.Size([2, 2])</br>
torch.Size([2, 2])</br></p>
<p><strong>网络输入输出结构详解</strong></br>
In Inference with two sample data:</br>
<code>displ_cat:</code> 61 x 49 x 3</br>
<code>centers_cat:</code> 61 x 2</br>
<code>agents_per_sample:</code> [32, 29]</br></p>
<h3 id="encoder_lstmbr">encoder_lstm</br></h3>
<p><strong>input:</strong> <code>displ_cat</code>(61 x 49 x 3), <code>agents_per_sample</code> [32,29]</br>
$\downarrow$  input_size = 3; hidden_size = 128; num_layers = 1</br>
$\downarrow$<code>lstm_hidden_state = torch.randn(num_layers, lstm_in.shape[0], hidden_size) = torch.randn(1, 61, 128)</code></br>
$\downarrow$<code>lstm_cell_state = torch.randn(num_layers, lstm_in.shape[0], hidden_size) = torch.randn(1, 61, 128)</code></br>
$\downarrow$<code>lstm_out, lstm_hidden = self.lstm(lstm_in, lstm_hidden)</code> =&gt; lstm((61, 49, 3), (torch((1, 61, 128)), torch(1, 61, 128)))</br>
$\downarrow$ <code>lstm_out</code>(61 x 49 x 128)</br>
<strong>output:</strong> <code>lstm_out[:,-1,:]</code>(61 x 128)</br></p>
<h3 id="agent_gnnbr">agent_gnn</br></h3>
<p><strong>input:</strong> <code>out_encoder_lstm</code>(61 x 128), <code>centers_cat</code> (61 x 2) <code>agents_per_sample</code> [32,29]</br>
$\downarrow$ x = gnn_in =&gt; (61 x 128)</br>
$\downarrow$ edge_index = build_fully_connected_edge_idx(agents_per_sample).to(gnn_in.device) =&gt; (2, 1804) 1804 = (29 x 29-1) + (32 x (32-1))</br>
$\downarrow$</br>
$\downarrow$ edge_attr = build_edge_attr(edge_index, centers).to(gnn_in.device) =&gt; (1804, 2)</br>
$\downarrow$ x = F.relu(self.gcn1(x, edge_index, edge_attr)) =&gt; (61 x 128)</br>
<strong>output:</strong> gnn_out = F.relu(self.gcn2(x, edge_index, edge_attr)) =&gt; (61 x 128)</br></p>
<p>$$\mathbf{x}^{\prime}<em>i = \mathbf{x}<em>i + \sum</em>{j \in \mathcal{N}(i)}
\sigma \left( \mathbf{z}</em>{i,j} \mathbf{W}_f + \mathbf{b}<em>f \right)
\odot g \left( \mathbf{z}</em>{i,j} \mathbf{W}_s + \mathbf{b}_s  \right)$$</p>
<h3 id="multihead_self_attention">multihead_self_attention</h3>
<p><strong>input:</strong> <code>out_agent_gnn</code> (61 x 128) <code>agents_per_sample</code>[32,29]
$\downarrow$ max_agents = max(agents_per_sample) =&gt; 32
$\downarrow$ padded_att_in = torch.zeros((len(agents_per_sample), max_agents, self.latent_size), device=att_in[0].device) =&gt; torch: (2 x 32 x 128)
$\downarrow$ mask = torch.arange(max_agents) &lt; torch.tensor(agents_per_sample)[:, None] &amp;&amp; padded_att_in[mask] = att_in =&gt; torch: (2 x 32 x 128)
$\downarrow$ padded_att_in_swapped = torch.swapaxes(padded_att_in, 0, 1) =&gt; torch: (32, 2, 128)
$\downarrow$ padded_att_in_swapped, _ = self.multihead_attention(padded_att_in_swapped, padded_att_in_swapped, padded_att_in_swapped, key_padding_mask=mask_inverted) =&gt; torch: (32, 2, 128)
$\downarrow$ padded_att_in_reswapped = torch.swapaxes(padded_att_in_swapped, 0, 1) =&gt; torch: (2, 32, 128)
$\downarrow$ att_out_batch = [x[0:agents_per_sample[i]] for i, x in enumerate(padded_att_in_reswapped)] =&gt; list: 2
<strong>output:</strong> <code>att_out_batch</code> =&gt; list: 2 for each with shape (29, 128) and (32, 128)</p>
<h3 id="torchstack">torch.stack()</h3>
<p><strong>input:</strong> <code>out_self_attention:</code> list: 2 for each with shape (29, 128) and (32, 128)</br>
$\downarrow$ out_self_attention = torch.stack([x[0] for x in out_self_attention])</br>
<strong>output:</strong> <code>out_self_attention:</code> torch: (2, 128)</br></p>
<h3 id="predictionnetout_self_attention">PredictionNet(out_self_attention)</h3>
<h3 id="decoder_residual">decoder_residual</h3>
<p><strong>input:</strong> <code>out_self_attention</code>(torch: (2, 128)) <code>frozen = False</code></br>
$\downarrow$ [condition: frozen = False] sample_wise_out.append(PredictionNet(out_self_attention)) =&gt; torch: (2, 120)</br>
$\downarrow$ decoder_out = torch.stack(sample_wise_out) =&gt; torch: (1, 2, 120)</br>
$\downarrow$ decoder_out = torch.swapaxes(decoder_out, 0, 1) =&gt; torch: (2, 1, 120)</br>
<strong>output:</strong> decoder_out =&gt; torch: (2, 1, 120)</br></p>
<h3 id="out--out_linearviewlendispl-1--1-selfconfignum_preds-2">out = out_linear.view(len(displ), 1, -1, self.config[&rsquo;num_preds&rsquo;], 2)</h3>
<p><strong>input:</strong> decoder_out: torch: (2, 1, 120)</br>
$\downarrow$ out = out_linear.view(len(displ), 1, -1, self.config[&rsquo;num_preds&rsquo;], 2) =&gt; torch: (2, 1, 1, 60, 2)</br>
<strong>output:</strong> out =&gt; torch: (2, 1, 1, 60, 2)</br></p>
<h3 id="将预测轨迹转换到全局坐标">将预测轨迹转换到全局坐标</h3>
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">for i in range(len(out)):
</span></span><span class="line"><span class="cl">	out[i] = torch.matmul(out[i], rotation[i]) + origin[i].view(
</span></span><span class="line"><span class="cl">                1, 1, 1, -1
</span></span><span class="line"><span class="cl">            )</span></span></code></pre></td></tr></table>
</div>
</div>]]></description></item><item><title>DenseTNT and TNT 论文解读</title><link>https://jianye0428.github.io/posts/densetnt_tnt/</link><pubDate>Sun, 16 Jul 2023 15:53:59 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/densetnt_tnt/</guid><description><![CDATA[<h2 id="tnt-target-driven-trajectory-prediction">TNT: Target-driveN Trajectory Prediction</h2>
<p><code>**ref link:**</code>
<a href="https://zhuanlan.zhihu.com/p/435953928"target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/435953928<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
<a href="https://blog.csdn.net/weixin_40633696/article/details/124542807?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-2-124542807-blog-122758833.pc_relevant_vip_default&amp;spm=1001.2101.3001.4242.2&amp;utm_relevant_index=5"target="_blank" rel="external nofollow noopener noreferrer">https://blog.csdn.net/weixin_40633696/article/details/124542807?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_title~default-2-124542807-blog-122758833.pc_relevant_vip_default&spm=1001.2101.3001.4242.2&utm_relevant_index=5<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<h3 id="概览">概览</h3>
<p>在预测车辆的轨迹时, 需要尽可能考虑到车辆不同的情况，即不同的模态，如前行或左转，并预测出对应的概率。</p>
<p>模态的定义是比较模糊的，例如，有不同的速度前行，左转可以以不同的转弯角度实现。为了能够更加通用且精确地定义每条轨迹的模态，我们直接将每条轨迹的模态定义在每条轨迹的终点上。这里的一个重要假设是，轨迹的模态基本由终点所决定，当终点确定后，轨迹的形状也大体确定了。这样我们就把轨迹预测变成了终点预测问题，极大地简化了问题的复杂度。</p>
<p>TNT的预测方式: <strong>首先预测轨迹的终点，然后基于这个终点补充完整条轨迹</strong>。</p>
<p>TNT 基于终点的轨迹预测流程图:
</p>
<p>TNT使用VectorNet对高精地图和车辆信息进行编码，得到要预测的车辆的全局特征，以用于接下来的解码，从而完成轨迹预测：</p>
<p>(1). <strong>终点预测:</strong> 为每个Anchor预测一个偏移，得到终点，这些Anchor从道路的中心线上采样得到;
(2). <strong>轨迹补全:</strong> 基于上一步预测的终点将整条轨迹补充完整;
(3). <strong>轨迹打分和筛选:</strong> 根据场景特征，为每条轨迹进行打分，并筛选出最有可能的若干条轨迹。</p>
<h3 id="tnt-实现">TNT 实现</h3>
<h4 id="原理">原理</h4>
<p>给定一个单个障碍物的观测状态序列 $S_P = [s_{-T^{&rsquo;}+1}, s_{-T^{&rsquo;}+2}, &hellip;, s_0]$。我们的目标是预测它的未来状态 $S_F = [s_1, s_2, &hellip;, s_T]$ 到某个固定时间步 T。自然地，障碍物与由其它障碍物和场景元素组成的环境交互作为背景: $C_P​=[c_{-T′+1}​,c_{-T′+2}​,&hellip;,c_0​]$。为简洁起见，我们记 $X = (s_P, c_P)$，因此我们想捕捉的整体概率分布是 $p(S_F|X)$ 。</p>
<p>实际上， $p(S_F|X)$ 可以是高度多模态的。例如，车辆驶近十字路口时可能左转、直行或改变车道。直观上，未来状态的不确定性可以被分解为两部分：<u>目标或者意图的不确定性</u>，比如左右转的决定；以及<u>控制的不确定性</u>，比如转弯时需要的细粒度运动。因此，我们可以通过对目标设定条件，然后将其边缘化，从而对概率分布进行分解：</p>
<p>$$p(S_F​∣X)=∫_{τ∈τ(C_P​)}​p(τ∣X)p(S_F​∣τ,X)d_τ​, \tag{1}$$</p>
<p>其中 $\tau(C_P)$ 表示取决于观察到的背景 $C_P$ ​的合理目标空间。</p>
<p>在这个公式下，我们的主要见解是，对于轨迹预测等应用，通过正确设计目标空间 $\tau τ ( C_P )$（如目标位置），目标分布 $ p(\tau|X)$ 可以很好地捕捉意图不确定性。一旦目标确定，我们会进一步证明控制不确定性（如轨迹）可以通过<strong>简单的单模态分布</strong>可靠地建模。我们用一组离散位置来模拟目标空间  $\tau{C_P}$，将 $p(\tau|X)$ 的估计主要转化为一个分类任务。与隐变分模型相比，我们的模型以明确的目标分布的形式提供了更好的可解释性，并且在设计目标空间 $\tau{C_P}$ 时可以自然地结合专家知识（如道路拓扑）。</p>
<p>我们的整体框架有三个概念阶段。第一阶段是<strong>障碍物意图预测</strong>，其目标是用基于观察背景 $X$ 的目标空间 $\tau$ 的离散集合<u>对意图不确定性进行建模</u>，并且输出目标分布 $p(\tau|X)$ 。第二个阶段是<strong>障碍物条件运动估计</strong>，它用单模态分布对从初始状态到目标可能的未来运动进行建模。前两个阶段产生了以下概率预测 $p(S_F|X) = \sum_{\tau\in\tau(C_P)}p(\tau|X)p(S_F|\tau, X)$。</p>
<p>许多下游应用，例如实时行为预测，需要一小组具有代表性的未来预测，而不是所有可能未来的完整分布。我们的最终阶段，<strong>评分和选择</strong>，就是为此目的量身定制的。我们从所有代表性预测上学习一个评分函数 $\phi(S_F)$，并选择一个最终的多样化预测集。</p>
<p></p>
<h4 id="场景编码vectornet">场景编码VectorNet</h4>
<p>建模场景背景是轨迹预测的第一步，以获取<u>车辆-道路</u>和<u>车辆-车辆</u>之间的交互。TNT可以使用任何合适的背景编码器：当高清地图可用时，我们使用最优秀的层次图神经网络 VectorNet 对背景进行编码。具体来说，使用多段线来抽象出高清地图元素 $C_P$(车道，交通标志) 和代理轨迹 $S_P$​；采用子图（subgraph）网络对多段线进行编码，多段线包含可变数量的向量；然后使用全局图（global graph）对多段线之间的交互进行建模。输出是每个建模代理的全局背景特征 $X$。如果场景背景只在自上而下的图像形式中可用，则使用卷积网络作为背景编码器。</p>
<h4 id="目标预测">目标预测</h4>
<p>在我们的公式中，目标 $\tau$ 被定义为一个预测目标可能在固定时间范围 $T$ 上的位置 $(x,y)$ 。在第一步目标预测阶段，我们的目的是提供一个预测目标的未来目标的分布 $p( \tau ∣ X )$ 。我们通过一组$N$个离散的、带有连续偏移的量化位置来建模潜在的未来目标： $\tau ={\tau^n}={(x^n,y^n)+(\Delta x^n,\Delta y^n)}^N_{n=1}$​。然后这个目标上分布可以通过一个离散-连续分解来建模：</p>
<p>$$p(τ^n∣X)=π(τ^n∣X)⋅N(Δx^n∣v^x_n​(X))⋅N(Δ_y^n∣v_y^n​(X)),\tag{2}$$</p>
<p>中 $\pi(\tau^n|X)=\frac{e^{f(\tau^n,X)}}{\sum_{\tau^{&rsquo;}}e^{f(\tau^{&rsquo;},X)}}$ 是在位置选择 $(x^n,y^n)$上的离散分布。术语 $N(·|v(·))$ 表示一个广义正态分布，其中我们选择Huber作为距离函数。我们将均值表示为 $v(·)$并假设单位方差。</p>
<p>可训练函数 $f(·)$ 和  $v(·)$ 由一个2层的多层感知机(MLP)实现，目标坐标 $(x^k,y^k)$ 和场景背景特征 $X$ 作为输入。它们预测目标位置上的离散分布及其最可能的偏移量。这一阶段的训练损失函数由以下公式给出：</p>
<p>$$L_{S1}​=L_{cls​}(π,u)+L_{offset}​(v_x​,v_y​,Δx^u,Δy^u),\tag{3}$$</p>
<p>其中 $L_{cls}$ 是交叉熵损失， $L_{offset}$​ 是 Huber 损失；$u$ 是离真实位置最近的目标，并且 $\Delta x^u,\Delta y^u$ 是 $u$ 相对于真值的空间偏移量。</p>
<p>离散目标空间的选择在不同应用中是灵活的，如图3所示。在车辆轨迹预测问题中，我们从高清地图里均匀地采样车道中心线上的点并且将他们作为目标候选点(标记为黄色菱形)，假设车辆从未远离车道线；对于行人，我们在代理周围生成了一个虚拟网格并将网格点作为目标候选点。对每个候选目标，TNT目标预测器生成了一个 $(\pi,\Delta x, \Delta y)$ 的元组；回归后的目标以橙色五角星标记。与直接回归相比，将未来建模成一组离散目标的最显著的优势在于，它不受模态平均的影响，模态平均是阻止多模态预测的主要因素。</p>
<p></p>
<h4 id="基于目标的运动估计">基于目标的运动估计</h4>
<p>在第二阶段，我们将给定目标轨迹的可能性建模为 $p(S_F|\tau,X)=\prod^T_{t=1}p(s_t|\tau,X)$，同样采用了广义正态分布。这里有两个假设。首先，未来时间步是条件独立的，这使得我们的模型通过避免顺序预测提高了计算效率。其次，我们正在作出有力但合理的假设，即给定目标的轨迹分布是单模态(正态)的。对于短的时间范围来说，这当然是正确的；对于更长的时间范围，可以在(中间)目标预测和运动估计之间迭代，以便假设仍然成立。</p>
<p>这一阶段使用2层的MLP实现。它将背景特征 X 和目标位置 $\tau$ 作为输入，并且每个目标输出一条最可能的轨迹 $[\hat{s_1},&hellip;,\hat{s_T}] [s1​^​,&hellip;,sT​^​]$。由于它以第一阶段的预测目标为条件，为了实现平滑的学习过程，我们在训练时采用teacher forcing Technique[36]，将真实位置 $(x^n,y^n)$ 作为目标。该阶段的损失项是预测状态 $\hat{s_t}$​ 和真值 $s_t$​ 之间的距离：</p>
<p>$$L_{S2}​ = \sum_{t=1}^{T}​L_{reg}​(\hat{s},s_t​),\tag{4}$$</p>
<p>其中， $L_{reg}$​ 作为每一步坐标偏移的 Huber 损失来实现。</p>
<h4 id="轨迹评分和选择">轨迹评分和选择</h4>
<p>我们的最终阶段估计未来完整轨迹 S F S_F SF​ 的可能性。这和第二阶段不同，第二阶段分解时间步和目标，也和第一阶段不同，第一阶段只知道目标，但没有完整的轨迹——例如，一个目标可能被估计有很高的可能性，但到达该目标完整轨迹的可能性可能不是。</p>
<p>我们使用最大熵模型对第二阶段的所有 M 条轨迹进行评分:</p>
<p>$$\phi (S_F | X) = \frac{e^{g(S_F, X)}}{{\sum}_{m=1}^{M} e^{g(S_F^m, X)}}​$$,</p>
<p>其中 $g(·)$ 被建模为一个2层的 MLP。这一阶段训练的损失项是预测分数和真值分数之间的交叉熵，</p>
<p>$$L_{S3} = L_{CE}(\phi (S_F | X), \psi(S_F))$$</p>
<p>其中每个预测轨迹的真值评分由预测轨迹到真值轨迹的距离 $\psi(S_F)=\frac{exp(-D(S,S_{GT})/\alpha)}{\sum_{s^{&rsquo;}}exp(-D(S^{&rsquo;},S_{GT})/\alpha)}$ 定义，其中 $D(·)$ 单位为米， $\alpha$ 是温度。距离度量定义为 $D(S^i,S^j)=max(||s^i_1-s^j_1||^2_2,&hellip;,||s^i_t-s^j_t||^2_2)$。</p>
<p>为了从已评分的 $M$ 个轨迹获得最终一小组 $K$ 个预测轨迹，我们实现了一个轨迹选择算法来排除近似重复的轨迹。我们首先根据他们的分数对轨迹进行降序排列，并且贪婪地选择轨迹； 如果一个轨迹距离所有的选择轨迹都足够远，我们也会选择它，否则排除它。这里使用的距离度量和评分过程相同。这个过程的灵感来源于通常应用于计算机视觉问题（如目标检测）的非极大值抑制算法。</p>
<h4 id="训练和推理细节">训练和推理细节</h4>
<p>上述的 TNT 公式产生全监督的端到端训练，具有损失函数
$$L = \lambda_1 L_{S1} + \lambda_2 L_{S2} + \lambda_3 L_{S3}$$</p>
<p>其中，选择 $\lambda_1,\lambda_2,\lambda_3$ 来平衡训练过程。</p>
<p>在推理时，TNT 的工作原理如下：
(1) 工作场景编码；
(2) 采样 N 个候选目标作为目标预测器的输入，取由 $\pi(\tau|X)$ 估计的前 M 个目标；
(3) 从运动估计模型 $p(S_F|\tau,X)$ 中获取 M 个目标中每个目标的 MAP 轨迹；
(4) 通过  $\phi(S_F|\tau,X)$  给 M 个轨迹评分，并且选择一组最终的 K 个轨迹。</p>
<h2 id="densetnt">DenseTNT:</h2>
<p><code>ref link:</code> <a href="https://blog.csdn.net/weixin_39397852/article/details/122764880"target="_blank" rel="external nofollow noopener noreferrer">https://blog.csdn.net/weixin_39397852/article/details/122764880<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<h3 id="comparison-between-densetnt-and-tnt">Comparison between DenseTNT and TNT</h3>
<p></p>
<p>TNT(左图)是根据lane定义一些anchor，再regress和classify获得最终的位置，之后还要通过NMS的筛选法选出最后的轨迹。
DenseTNT(右图)是通过密集地采点避免了定义anchor，同时也避免了使用NMS等规则来筛选轨迹。</p>
<p>意图预测中非常重要的一个问题是ground truth只有一个，而对于多意图的预测来说，多个方向的预测都是允许的，这导致了label中有很多都是无效的，因为gt只包含了一个意图下的结果。此处设计了一个offline的model来提供多个意图下的label。这个model使用了一个优化算法从goal的分布里取出了一个set作为online model的label。</p>
<h3 id="method-具体实现方法">Method 具体实现方法</h3>
<h4 id="sparse-context-encoding----vectornet">sparse context encoding &ndash; VectorNet</h4>
<p>本文使用VectorNet来提取地图的feature。(没有的高精地图的话也可使用CNN)</p>
<h4 id="dense-goal-probability-estimation">Dense goal probability estimation</h4>
<p>TNT对于一个goal只预测一条轨迹的概率是有问题的：一个goal只有一条预测(可能通向这个goal的别的预测概率很高)，一个goal获取的feature不够丰富(goal附近的点的信息也用上会更好)。</p>
<p>我们使用了<code>dense goal encoder</code>。它以一定的采样频率获取了地图上在道路上的所有点。然后预测了这些密集点的概率分布。</p>
<h5 id="lane-scoring">Lane Scoring</h5>
<blockquote>
<p>在论文实现中，可以用point scoring代替，效果更好。目的在与选出距离final pos(gt)更近的点。</p>
</blockquote>
<p>为了减少需要sample的点，我们先预测goal落在不同lane上的概率，这样能过滤掉明显不在candidate lane附近的点，提升运算速度。
这是一个二分类问题。因此使用了二分类的交叉熵计算loss。对于label，使用离gt的goal最近的lane作为1，别的lane为0。对于别的lane $l$，假设gt的goal是$y_{gt}$​，定义一个distance</p>
<p>$$d(l,y_{gt}) = min(||l_1 - y_{gt}||^2, ||l_2 - y_{gt}||^2, &hellip;, ||l_t - y_{gt}||^2,)$$</p>
<p>直觉上就是gt的goal到这条lane的最短距离的平方。</p>
<h5 id="probability-estimation">Probability Estimation</h5>
<p>获得概率分布的做法是self-attention。首先agent的feature经过两次MLP。然后把goal的feature $F$作为需要query的变量，从地图上所有元素 (lane，agent)的feature中去查找索引对应的键和值。<font color=red>目的就是建立goal的feature与地图上所有元素的联系。</font>直观上，这一步是把agent的未来状态(goal)表示成由历史的信息作为变量的函数，这个函数采用的是self-attention的做法。</p>
<p>轨迹目标点(goals)和道路的局部信息可以用以下注意力机制表示:</p>
<p>$$\mathbf{Q} = \mathbf{FW}^{\mathbf{Q}}, \mathbf{K} = \mathbf{LW}^{\mathbf{K}}, \mathbf{V}=\mathbf{LW}^{\mathbf{V}}$$</p>
<p>$$\mathbf{A}(\mathbf{Q},\mathbf{K},\mathbf{V}) = softmax(\frac{\mathbf{QK^\top}}{\sqrt{d_k}})\mathbf{V}$$</p>
<p>where $\mathbf{W}^Q, \mathbf{W}^{K}, \mathbf{W}^{V} \in \mathbb{R}^{d_h \times d_k}$ are the matrices for linear projection, $d_k$ is the dimension of query / key / value vectors, and $\mathbf{F}, \mathbf{F}$ are feature matrices of the dense goal candidates and all map elements (i.e., lanes or agents), respectively.</p>
<p>这一步之后的结果是goal新的feature $\mathbf{F}$。再通过两次MLP，即下图中的 $g(.)$.用softmax中的方法获得每个goal的概率。将所有goal在地图上表示出来的话就是一个概率分布heatmap。</p>
<p>$$\phi_i = \frac{\exp(g(\mathbf{F}<em>i))}{\sum</em>{n=1}^{N}\exp(g(\mathbf{F}_n))}$$</p>
<p>对于Loss的计算，离gt的goal最近的goal的label定为1，其余都为0.采取二分类交叉熵的算法。</p>
<p>$$\mathcal{L}<em>\text{goal} = \mathcal{L}</em>{\text{CE}}(\phi, \psi)$$</p>
<h4 id="goal-set-prediction">Goal Set Prediction</h4>
<p>对于多意图的预测，在TNT中，预先设定好target，采用NMS(non-maximum suppression)(靠的近或概率低的过滤掉)。而DenseTNT的上一步获得是heatmap，因此不能简单使用NMS，因为用于筛选的阈值比较难定。这是因为TNT中采用的是从高到低排序概率，而DenseTNT中的概率分布是针对于整个鸟瞰图的，一旦意图的可能性变多了，平均分布到每一个意图的概率就低了(对于概率分布，所有的点的概率加起来需要为1)。</p>
<p>heatmap，输出是goal set，这个有点像目标检测的框生成。但和目标检测不同，对于一个输入，我们的label只有一个，即gt。这样的话可能会有别的意图的结果在训练中被忽略。为此，设计了一个offline model来制造这些label。它和online model的区别就在这一步中。没有使用goal set predictor而是采用了优化算法。</p>
<p></p>
<h5 id="offline-optimization">Offline Optimization</h5>
<p>上一步heatmap的输出，实际上是对于地图上众多goal每个点的一个函数。设定 $C={c_1,c_2,&hellip;,c_m}$ 为所有dense goal的candidate，heatmap就把 $C$ 映射到一个0到1的集合，写成 $h(c_i)$ ，这也是每个goal的概率。
接下来定义一个目标函数:</p>
<p>$$E[d(\hat{y}, Y)] = \sum^m_{i=1}h(c_i)d(\hat{y}, c_i)$$</p>
<p>其中，$d(\hat{y}, c_i) = \mathop{\min}\limits_{y_i \in \hat{y}}||y_j - y_{c_i}||$</p>
<p>从直观上讲，目标是有M个goal（大池子），要从中选取K个靠谱的goal（小池子）。 $d$ 是针对于大池子的，对于大池子里所有candidate都有一个 $d$。这每个candidate都与小池子中的goal计算距离，取最近的作为 d d d，即寻找小池子中离candidate最近的点。对于所有的 $d$，用概率加权计算期望。总体的话在收敛情况，大池子中的所有goal到距离自己最近的小池子中的goal乘上概率加权应当达到最小。以下是这个优化算法的实现。</p>
<p></p>
<p>翻译成中文：</p>
<ul>
<li>初始化K个goal，从M个goal的大池子里随机选</li>
<li>小池子里的每个goal做随机扰动，变为别的goal</li>
<li>计算原来的和现在的小池子的d的期望e和e’</li>
<li>如果现在的小池子d的期望更小，则使用现在的小池子。否则以1%的概率采用现在的小池子。（避免局部最优）</li>
<li>不停循环2-4直到步数达到阈值（或时间太长）</li>
</ul>
<p>优化算法之后得到的就是全局最优的选中的小池子。这个小池子里的结果能作为训练online模型的伪label。</p>
<h5 id="goal-set-predictor-online">Goal Set Predictor (online)</h5>
<p>模型采用了encode+decode的办法。encoder部分是一层self-attention加上max pooling，decoder部分是2层MLP，输入是heatmap，输出是2K+1个值，分别对应K个2维坐标（goal set）和一个当前goal set的confidence。</p>
<p>考虑到heatmap的概率分布比较散，可以采用N头同时运算。即N个goal set predictor输出N个2K+1的值，从当中选取confidence最高的那个goal set预测。为了运算效率的提升，这N头使用相同的self-attention层，但是不同的2个MLP。</p>
<p>在训练过程中，采用了offline模型的伪label作为监督。上述offline中讲到的初始选定的小池子，在这里采用的是online模型的K个goal的set的预测。然后经过L次随机扰动（即不停随机选取邻居点，L=100），选取当中expected error（offline里的期望项）最小的那个set作为伪label。</p>
<p>标记 $\dot{y}$ ​为预测结果， $\hat{y}$ ​为伪label，则loss的计算如下。即一一对应后的L1距离之和。</p>
<p>$$\mathcal{L_{set}(\dot{y}, \hat{y})} = \sum_{i=1}^{k}\mathcal{L}_{\text{reg}}(\dot{y}, \hat{y})$$</p>
<p>再考虑到采用了N头预测，这部分的loss将采用二分类的交叉熵。其中 $\mu$ 为所有head的confidence，$\nu$ 为label，只有expected error最低的label为1，别的为0。</p>
<p>$$\mathcal{L}<em>\text{head} = \mathcal{L}</em>{\text{CE}}(\mu, \nu)$$</p>
<h4 id="trajectory-completion">Trajectory Completion</h4>
<p>这一步和TNT做法类似。类似于dense goal encoding（2层MLP后过self-attention）最后过2层MLP来decode得到整条预测轨迹的state。采用teacher forcing技巧（因为只有一条gt）训练时只用gt的goal来算这条预测轨迹。Loss的算法和TNT一样，用的是点点之间的Huber loss。</p>
<p>$$\mathcal{L}<em>{\text{completion}} = \sum</em>{t=1}^{T}\mathcal{L_{reg}}(\hat{s}_t, s_t)$$</p>
<h4 id="learning">Learning</h4>
<p>训练分为两个stage。第一个stage使用gt轨迹训练除了goal set predictor的部分。即把dense的goal输入。获得大量的轨迹。</p>
<p>$$\mathcal{L}<em>{s1} = \mathcal{L}</em>{lane} + \mathcal{L}<em>{goal}+ \mathcal{L}</em>{completion}$$</p>
<p>第二个stage主要负责goal set predictor的部分。</p>
<p>$$\mathcal{L}<em>{s2} = \mathcal{L}</em>{head} + \mathcal{L}_{set}$$</p>
]]></description></item><item><title>Social_NCE 论文解读</title><link>https://jianye0428.github.io/posts/social_nce/</link><pubDate>Sun, 16 Jul 2023 15:53:27 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/social_nce/</guid><description><![CDATA[<p><code>paper link:</code> <a href="https://arxiv.org/abs/2012.11717"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/abs/2012.11717<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
<code>论文解读参考:</code>
[1] <a href="https://zhuanlan.zhihu.com/p/434650863"target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/434650863<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
[2] <a href="https://www.gushiciku.cn/pl/amod"target="_blank" rel="external nofollow noopener noreferrer">https://www.gushiciku.cn/pl/amod<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<h2 id="issue-to-solve-and-its-solution">Issue to solve and its Solution</h2>
<p>Due to the ill-distributed training Data, it&rsquo;s <u><font color=red>difficult to capture the notion of the &ldquo;negative&rdquo; examples</font></u> like collision.</p>
<p><strong>Solution:</strong></p>
<p>Modeling the negative samples through self-supervision:</p>
<ul>
<li><font color=red>a social contrastive loss</font>: regularizes the extracted motion representation by discerning the ground-truth positive events from synthetic negative ones;</li>
<li><font color=red>Construct negative samples</font> based on prior knowledge of rare but dangerous circumstances.
<blockquote>
<p>a social sampling strategy (informed): construct the positive event from the ground-truth location of the primary agent and the negative events from the regions of other neighbors. given that one location cannot be occupied by multiple agents at the same time.</p>
</blockquote>
</li>
</ul>
<h2 id="method-font-colorredcontrastive-learning--social-ncefont">Method: <font color=red><em>Contrastive Learning + Social NCE</em></font></h2>
<h3 id="contrastive-representation-learning">Contrastive Representation Learning</h3>
<ul>
<li>
<p>Functionality:</p>
<ul>
<li>
<p><code>Representation Learning:</code> to learn a parametric function that maps the raw data into a feature space to extract abstract and useful information for downstream tasks.</p>
</li>
<li>
<p><code>NCE(Noise Contrastive Estimation):</code> to train encoder</p>
</li>
</ul>
<p>$$\mathcal{L_{NCE}} = -\log \frac{\exp(sim(q,k^+)/\tau)}{\sum_{n=0}^N  \exp(sim(q,k_n)/ \tau)}$$</p>
<p>where the encoded query $q$ is brought close to one positive key $k_0 = k^+$ and pushed apart from $N$ negative keys ${ k_1, k_2, &hellip; , k_N}$, $\tau$ is a temperature hyperparameter, and $sim(u,v) = u^{\mathsf{T}}v/(||u||||v||)$ is the cosine similarity between two feature vectors.</p>
</li>
</ul>
<h3 id="social-nce">Social NCE</h3>
<p><strong>Social NCE Description:</strong></p>
<p>智能体 $i$ 在时刻 $t$ 上的位置记为 $s^i_t=(x^i_t,y^i_t)$ 。那么 $M$ 个智能体的联合状态记为 $s_t = { s_t^1, &hellip;, s^M_t}$ 。给定一个历史观测序列 ${s_1, s_2, &hellip;, s_t}$ ，任务是预测所有智能体未来直至 $T$ 时刻的轨迹 ${s_{t+1}, &hellip;, s_T}$，许多最近的预测模型被设计为编码器 - 解码器神经网络，其中运动编码器 $f(\cdot)$ 首先提取与 $i$ 相关的紧密表示 $h_t^i$ ，然后解码器 $g(\cdot)$ 随后推测出其未来的轨迹 $\hat{s}^i_{t+1,T}$ :</p>
<p>$$h^i_t = f(s_{1:t}, i),  $$
$$\hat{s}^i_{t+1:T} = g(h^i_t)$$</p>
<p>为了多智能体之间的社交互动，$f(\cdot)$通常包含两个子模块：一个序列建模模块 $f_S(\cdot)$ 用于编码每个单独的序列，以及一个交互模块 $f_I(\cdot)$ 用于在多智能体之间共享信息：</p>
<p>$$z^i_t = f_S(h^i_{t-1}, s^i_t),$$
$$h^i_t = f_I(z_t, i)$$</p>
<p>其中， $z^i_t$ 是给定智能体 $i$ 在时间 $t$ 观察其自身状态的潜在表示， $z_t = {z^1_t,&hellip;,z^M_t}$ 。很多方法已经探索了各种架构，并验证了其准确性。尽管如此，它们的鲁棒性仍然是一个悬而未决的问题。 最近的几项工作表明，现有模型预测的轨迹通常会输出社会不可接受的解决方案（例如，碰撞），表明缺乏关于社会准则的常识。</p>
<p></p>
<ul>
<li>
<p><code>query</code>: embedding of history observations $q = \psi(h^i_t)$, where $\psi(\cdot)$ is an MLP projection head;</p>
</li>
<li>
<p><code>key</code>: embedding of a future event $k = \phi(s^i_{s+\delta t}, \delta t)$, where $\phi(\cdot)$ is an event encoder modeled by an MLP, $s_{t+\delta t}^i$ is a sampled spatial location and $\delta_t &gt; 0$ is the sampling horizon.</p>
<blockquote>
<p>tuning $\delta_t \in \Lambda$, e.g. $\Lambda = {1,&hellip;,4}$, then future events in the next few step can be taken in account simultaneously. Nevertheless, when $\delta_t$ is a fixed value, then $\phi(\cdot)$ can be simplified as a location encoder, i.e., $\phi(s^i_{t+\delta t})$.</p>
</blockquote>
</li>
</ul>
<p>给定一个场景，包括感兴趣的主智体（蓝色）和附近多个相邻智体（灰色），Social-NCE 损失鼓励在嵌入空间中提取的运动表示，接近未来的正样本事件，并远离可能导致碰撞或不适的合成负样本事件. Social NCE的损失函数如下:</p>
<p>$$\mathcal{L_{SocialNCE}} = -\log\frac{\exp(\psi(h^i_t)\cdot\phi(s^{i,+}<em>{t+\delta t}, \delta t)/\tau)}{\sum</em>{\delta t\in\Lambda}\sum_{n=0}^{N}\exp(\psi(h^i_t)\cdot\phi(s^{i,n}_{t+\delta t}, \delta t)/\tau))}$$</p>
<p>最终的训练损失函数为Social-NCE和传统任务损失项之和，即轨迹预测的mean squared error (MSE) 或者negative log-likelihood (NLL)：</p>
<p>$$\mathcal{L}(f,g,\psi, \phi) = \mathcal{L}<em>{task}(f,g) + \lambda \mathcal{L}</em>{SocialNCE}(f, \psi, \phi)$$</p>
<p>其中，$\lambda$ 为超参数，控制SocialNCE损失函数的重要程度。</p>
<h3 id="sampling-strategy-in-multi-agent-context-采样策略">sampling strategy in multi-agent context 采样策略</h3>
<p></p>
<p>在其他智能体附近寻求更多信息的负样本:</p>
<p>$$s^{i,n-}<em>{t+\delta t} = s^{j}</em>{t+\delta t} + \bigtriangleup{s_p} + \epsilon$$</p>
<p>其中， $j\in{1,2,&hellip;,M} \backslash i$ 是其他agent的index, $\bigtriangleup{s_p}$ 是适合社交距离的局部位移。</p>
<p>对于positive sample, 对该agent周围直接采样获得:</p>
<p>$$s^{i,n-}<em>{t+\delta t} = s^{i}</em>{t+\delta t} +  \epsilon$$</p>
]]></description></item><item><title>Social_STGCNN 论文解读</title><link>https://jianye0428.github.io/posts/social_stgcnn/</link><pubDate>Sun, 16 Jul 2023 15:53:17 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/social_stgcnn/</guid><description><![CDATA[<p><code>paper link:</code> <a href="https://arxiv.org/abs/2002.11927?from=leiphonecolumn_paperreview0323"target="_blank" rel="external nofollow noopener noreferrer">https://arxiv.org/abs/2002.11927?from=leiphonecolumn_paperreview0323<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<h2 id="网络结构">网络结构</h2>
<p>特点: Social STGCNN不同于其他方法只是聚合各种学习的行人状态，而是对行人交互做图建模。其中提出一种kernel function把行人社交交互嵌入一个adjacency matrix。</p>
<blockquote>
<p>代码显示，图建模一般在数据前处理完成。</p>
</blockquote>
<h3 id="model-description">Model Description</h3>
<p>两部分：时空图卷积神经网络ST-GCNN、时间外推器TXP-CNN。</p>
<p>ST-GCNN对行人轨迹的图表示进行时空卷积操作以提取特征。这些特征是观察到的行人轨迹历史的紧凑表示。
TXP-CNN将这些特征作为输入，并预测所有行人作为一个整体的未来轨迹。我们使用时间外推器的名字是因为TXP-CNN期望通过卷积运算外推未来的轨迹。</p>
<p></p>
<p>给定T帧，构造表示 $G=(V,A)$ 的时空图. 然后，$G$ 通过时空图卷积神经网络(ST-GCNNs)转发，创建一个时空嵌入。 之后，TXP-CNNs 预测了未来的轨迹。 $P$ 是行人位置的维数，$N$ 是行人的数目，$T$ 是时间步长, $\hat{P}$是来自ST-GCNN的嵌入的维数.</p>
<p>(1) <font color=red>Graph Representation of Pedestrian Trajectories</font></p>
<p>我们首先构造一组空间图 $G_t$，表示每个时间步长 $t$ 在场景中行人的相对位置，$G_t = (V_t, E_t)$ 。 $V_t$是图 $G_t$ 的顶点集，观察到的位置 $(x^i_t，y^i_t)$ 是顶点 $v^i_t$ 的属性; $E_t$ 是边集，如果顶点 $v^i_t$ 和顶点 $v^j_t$ 相连 $e^{ij}_t = 1$ ，否则 $=0$。</p>
<p>为了建模两个节点之间相互影响的强度，我们附加了一个值$a^{ij}_t$, 它是由每个$ e^{ij}_t$ 的某种核函数计算得到。$a^{ij}_t$ 被组织为带权邻接矩阵$A_t$。</p>
<p><strong>$a^{ij}_{sim,t}$是要在邻接矩阵$A_t$中使用的内核函数。</strong> 定义为:</p>
<p>$$\begin{equation}
a^{ij}_{sim,t}=
\left
{
\begin{aligned}
1/||v^i_t - v^j_t||_2 , ||v^i_t - v^j_t||_1\neq0 \
0, Otherwise
\end{aligned}
\right.
\end{equation}$$</p>
<p>(2) <font color=red>Graph Convolution Neural Network</font></p>
<p>对于在二维网格地图或特征地图上定义的卷积运算，定义如下:</p>
<p>$$z^{(l+1)} = \sigma(\sum_{h=1}^{k}\sum_{\omega=1}^{k}(p(z^{(l)},h, \omega) \cdot \boldsymbol{W}^{(l)}(h, \omega))$$</p>
<p>其中，$k$是内核大小，$p(.)$ 是采样函数，其聚集以$z$为中心的邻居的信息， $\sigma$ 是激活函数。${l}$表示神经网络层。</p>
<p>图卷积定义如下:</p>
<p>$$v^{i(l+1)} =\sigma (\frac{1}{\Omega}\sum_{v^{j(l)}\in B(v^{j(l)})}p(v^{i(l)}, v^{j(l)}) \cdot \boldsymbol{W}(v^{i(l)}, v^{j(l)}))$$</p>
<p>其中$\frac{1}{\Omega}$ 是正则化项，$B(v^i) =  { v^j|d(v^i,v^j)≤D }$是顶点的邻居集，而$d(v^i,v^j)$表示连接$v^i$和$v^j$的最短距离， $\Omega$是邻居集的基数。</p>
<p>(3) <font color=red>Spatio-Temporal Graph Convolution Neural Network(ST-GCNNs)</font></p>
<p>通过定义一个新的图G，其属性是$G_t$属性的集合，ST-GCNN将<strong>空间图卷积</strong>扩展到<strong>时空图卷积</strong>。 $G$结合了行人轨迹的时空信息。值得注意的是，$G_1，…，G_T$的拓扑结构是相同的，而当t变化时，不同的属性被分配给$v^i_t$。</p>
<p>因此，我们将$G$定义为$(V,E)$，其中$V={v_i|i\in { 1，…，N }}$ 和 $E={e_{ij}|i，j，{1，…，N}}$。 顶点$v_i$在G中的属性是$v^i_t$的集合，$∀t∈{0，…，T}$。 另外， 加权邻接矩阵A对应于$G$ 是${ A_1，…，A_T}$的集合。 我们将ST-GCNN产生的嵌入表示为 $\overline{V}$.</p>
<p>(4) <font color=red>Time-Extrapolator Convolution Neural Network (TXP-CNN)</font></p>
<p>ST-GCNN的功能是从输入图中<strong>提取时空节点嵌入</strong>。然而，我们的目标是预测行人未来的进一步位置。
TXP-CNN直接作用于图嵌入 $\overline{V}$ 的时间维度，并将其扩展为预测的必要条件。 由于TXP-CNN依赖于特征空间的卷积运算，因此与递归单元相比，它的参数较小。需要注意的一个特性是， TXP-CNN层不是置换不变的，因为在TXP-CNN之前，图嵌入的变化会导致不同的结果。Other than this, if the order of pedestrians is permutated starting from the input to Social-STGCNN then the predictions are invariant.</p>
<h3 id="modelsocial-stgcnn-implementation">model(Social STGCNN) Implementation</h3>
<ol>
<li>Adjacency Matrix Normalization</li>
</ol>
<p>$$ A_t = \Lambda_t^{-\frac{1}{2}}\hat{A}\Lambda_t^{-\frac{1}{2}}$$</p>
<p>where $\hat{A_t} = A_t + I$ and $\Lambda_t$ is the diagonal node degree matric of $\hat{A_t}$. We use $\hat{A}$ and $\Lambda$ to denote the stack of $\hat{A_t}$ and $\Lambda_t$ repectively.</p>
<p>The normalization of adjacency is essential for the graph CNN to work properly.</p>
<ol start="2">
<li>STGCNN Network Mechanism</li>
</ol>
<p>$$f(V^{l}, A) = \sigma(\Lambda_t^{-\frac{1}{2}}\hat{A}\Lambda_t^{-\frac{1}{2}}V^{(l)}W^{(l)})$$</p>
<p>where, $V^{(l)}$ denotes the stack of $V^{(l)}_t$, and $W^{(l)}$ denotes the trainable parameters.</p>
<h2 id="data-processing-数据处理以及图构建">Data Processing 数据处理以及图构建</h2>
<p>obs_traj - <font color=red><em>前8帧观察轨迹(绝对坐标)</em></font>
pred_traj_gt - <font color=red><em>后12帧预测轨迹(ground truth)(绝对坐标)</em></font>
obs_traj_rel - <em><font color=red>前8帧观察轨迹(相对坐标)</em></font>
pred_traj_gt_rel - <em><font color=red>后12帧预测轨迹(ground truth)(相对坐标)</em></font>
non_linear_ped - <em><font color=red>非线性轨迹 (剔除)</em></font>
loss_mask
V_obs - <em><font color=red>graph nodes</em></font>
A_obs - <em><font color=red>graph Adjacency Matrix</em></font>
V_tr - <em><font color=red>预测轨迹 graph nodes</em></font>
A_tr - <em><font color=red>预测轨迹 graph Adjacency Matrix</em></font></p>
]]></description></item><item><title>Line Fitting</title><link>https://jianye0428.github.io/posts/linefitting/</link><pubDate>Sun, 16 Jul 2023 15:41:48 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/linefitting/</guid><description><![CDATA[<h2 id="曲线拟合合集">曲线拟合合集</h2>
<p><a href="https://durant35.github.io/2017/07/21/Algorithms_LeastSquaresLineFitting/"target="_blank" rel="external nofollow noopener noreferrer">https://durant35.github.io/2017/07/21/Algorithms_LeastSquaresLineFitting/<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<h3 id="一-最小二乘法拟合直线">一、 最小二乘法拟合直线</h3>
<h3 id="二-三次样条曲线">二、 三次样条曲线</h3>
<ul>
<li>
<ol>
<li>根据起始点和终点求三次样条曲线的系数</li>
</ol>
<p>已知三次样条曲线的方程为 $y = a_0 + a_1 \cdot x + a_2 \cdot x ^ 2 + a_3 \cdot x ^ 3$ ， 并且已知起始点坐标 $(x_0, y_0)$, 起始点导数k_1, 终点坐标(x_1, y_1), 终点导数k_2, 求三次样条曲线的系数</p>
<p>解: 通过平移变换可知， 将起始点置于零点，则终点为$(x_1 - x_0, y_1 - y_0)$，那么根据点和相关点之间的导数可以求相应的系数。方程如下:</p>
<p>$a_0 = y_0$
$a_1 = k_0$
$(y_1 - y_1) = a_1 * (x_1 - x_0) + a_2 * (x_1 - x_0) ^ 2 + a_3 * (x_1 - x_0) ^ 3$
$k_1 = a_1 + 2 * a_2 * (x_1 - x_0) + 3 * a_3 * (x_1 - x_0) ^ 2$</p>
<p>或者也可以设三次样条曲线方程为:$y = a_0 + a_1 * (x - x_0) + a_2 * (x - x_1) ^ 2 + a_3 * (x - x_2) ^ 3$</p>
<p>代码参考:</p>
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">void</span> <span class="n">PredictorManager</span><span class="o">::</span><span class="n">GetCubicPolynomialCofficients</span><span class="p">(</span><span class="kt">double</span> <span class="n">start_s</span><span class="p">,</span> <span class="kt">double</span> <span class="n">start_ds</span><span class="p">,</span> <span class="kt">double</span> <span class="n">end_s</span><span class="p">,</span> <span class="kt">double</span> <span class="n">end_ds</span><span class="p">,</span> <span class="kt">double</span> <span class="n">start_t</span><span class="p">,</span> <span class="kt">double</span> <span class="n">end_t</span><span class="p">,</span> <span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">double</span><span class="p">,</span> <span class="mi">4</span><span class="o">&gt;*</span> <span class="n">coeffs</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="n">coeffs</span><span class="o">-&gt;</span><span class="k">operator</span><span class="p">[](</span><span class="mi">0</span><span class="p">)</span> <span class="o">=</span> <span class="n">start_s</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="n">coeffs</span><span class="o">-&gt;</span><span class="k">operator</span><span class="p">[](</span><span class="mi">1</span><span class="p">)</span> <span class="o">=</span> <span class="n">start_ds</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="kt">double</span> <span class="n">p</span> <span class="o">=</span> <span class="n">end_t</span> <span class="o">-</span> <span class="n">start_t</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="kt">double</span> <span class="n">p2</span> <span class="o">=</span> <span class="n">p</span> <span class="o">*</span> <span class="n">p</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="kt">double</span> <span class="n">p3</span> <span class="o">=</span> <span class="n">p2</span> <span class="o">*</span> <span class="n">p</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="kt">double</span> <span class="n">tmp_var1</span> <span class="o">=</span> <span class="p">(</span><span class="n">end_ds</span> <span class="o">-</span> <span class="n">start_ds</span><span class="p">)</span> <span class="o">*</span> <span class="n">p</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="kt">double</span> <span class="n">tmp_var2</span> <span class="o">=</span> <span class="n">end_s</span> <span class="o">-</span> <span class="n">start_s</span> <span class="o">-</span>  <span class="n">start_ds</span> <span class="o">*</span> <span class="n">p</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="n">coeffs</span><span class="o">-&gt;</span><span class="k">operator</span><span class="p">[](</span><span class="mi">2</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="mf">3.0</span> <span class="o">*</span> <span class="n">tmp_var2</span> <span class="o">-</span> <span class="n">tmp_var1</span><span class="p">)</span> <span class="o">/</span> <span class="n">p2</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="n">coeffs</span><span class="o">-&gt;</span><span class="k">operator</span><span class="p">[](</span><span class="mi">3</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span><span class="n">tmp_var1</span> <span class="o">-</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">tmp_var2</span><span class="p">)</span> <span class="o">/</span> <span class="n">p3</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">double</span> <span class="nf">EvaluateQuarticPolynomial</span><span class="p">(</span><span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">array</span><span class="o">&lt;</span><span class="kt">double</span><span class="p">,</span> <span class="mi">5</span><span class="o">&gt;&amp;</span> <span class="n">coeffs</span><span class="p">,</span> <span class="k">const</span> <span class="kt">double</span> <span class="n">t</span><span class="p">,</span> <span class="k">const</span> <span class="kt">uint32_t</span> <span class="n">order</span><span class="p">,</span> <span class="k">const</span> <span class="kt">double</span> <span class="n">end_t</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                             <span class="k">const</span> <span class="kt">double</span> <span class="n">end_v</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="k">if</span> <span class="p">(</span><span class="n">t</span> <span class="o">&gt;=</span> <span class="n">end_t</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">switch</span> <span class="p">(</span><span class="n">order</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">      <span class="k">case</span> <span class="mi">0</span><span class="o">:</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="kt">double</span> <span class="n">end_value</span> <span class="o">=</span> <span class="p">(((</span><span class="n">coeffs</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="o">*</span> <span class="n">end_t</span> <span class="o">+</span> <span class="n">coeffs</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span> <span class="o">*</span> <span class="n">end_t</span> <span class="o">+</span> <span class="n">coeffs</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span> <span class="o">*</span> <span class="n">end_t</span> <span class="o">+</span> <span class="n">coeffs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="n">end_t</span> <span class="o">+</span> <span class="n">coeffs</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">end_value</span> <span class="o">+</span> <span class="p">(</span><span class="n">t</span> <span class="o">-</span> <span class="n">end_t</span><span class="p">)</span> <span class="o">*</span> <span class="n">end_v</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">      <span class="p">}</span>
</span></span><span class="line"><span class="cl">      <span class="k">case</span> <span class="mi">1</span><span class="o">:</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">end_v</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">      <span class="p">}</span>
</span></span><span class="line"><span class="cl">      <span class="k">default</span><span class="o">:</span> <span class="p">{</span> <span class="k">return</span> <span class="mf">0.0</span><span class="p">;</span> <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">  <span class="p">}</span>
</span></span><span class="line"><span class="cl">  <span class="k">switch</span> <span class="p">(</span><span class="n">order</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">case</span> <span class="mi">0</span><span class="o">:</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">      <span class="k">return</span> <span class="p">(((</span><span class="n">coeffs</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="o">*</span> <span class="n">t</span> <span class="o">+</span> <span class="n">coeffs</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span> <span class="o">*</span> <span class="n">t</span> <span class="o">+</span> <span class="n">coeffs</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span> <span class="o">*</span> <span class="n">t</span> <span class="o">+</span> <span class="n">coeffs</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="n">t</span> <span class="o">+</span> <span class="n">coeffs</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">case</span> <span class="mi">1</span><span class="o">:</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">      <span class="k">return</span> <span class="p">((</span><span class="mf">4.0</span> <span class="o">*</span> <span class="n">coeffs</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="o">*</span> <span class="n">t</span> <span class="o">+</span> <span class="mf">3.0</span> <span class="o">*</span> <span class="n">coeffs</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span> <span class="o">*</span> <span class="n">t</span> <span class="o">+</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">coeffs</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span> <span class="o">*</span> <span class="n">t</span> <span class="o">+</span> <span class="n">coeffs</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">case</span> <span class="mi">2</span><span class="o">:</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">      <span class="k">return</span> <span class="p">(</span><span class="mf">12.0</span> <span class="o">*</span> <span class="n">coeffs</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="o">*</span> <span class="n">t</span> <span class="o">+</span> <span class="mf">6.0</span> <span class="o">*</span> <span class="n">coeffs</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span> <span class="o">*</span> <span class="n">t</span> <span class="o">+</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="n">coeffs</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">case</span> <span class="mi">3</span><span class="o">:</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">      <span class="k">return</span> <span class="mf">24.0</span> <span class="o">*</span> <span class="n">coeffs</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span> <span class="o">*</span> <span class="n">t</span> <span class="o">+</span> <span class="mf">6.0</span> <span class="o">*</span> <span class="n">coeffs</span><span class="p">[</span><span class="mi">3</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">case</span> <span class="mi">4</span><span class="o">:</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">      <span class="k">return</span> <span class="mf">24.0</span> <span class="o">*</span> <span class="n">coeffs</span><span class="p">[</span><span class="mi">4</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">default</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">      <span class="k">return</span> <span class="mf">0.0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">  <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div></li>
</ul>
<h3 id="三bezier曲线">三、Bezier曲线</h3>
<pre><code>参考文献:
[1]. [三次样条曲线求系数1](https://huaweicloud.csdn.net/63a571ddb878a5454594788c.html?spm=1001.2101.3001.6650.2&amp;utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Eactivity-2-90477388-blog-118017126.pc_relevant_vip_default&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7Eactivity-2-90477388-blog-118017126.pc_relevant_vip_default&amp;utm_relevant_index=3#devmenu7)

[2]. [三次样条曲线求系数2](https://blog.csdn.net/ymj7150697/article/details/105713587)

[3]. [三次样条曲线求系数3](https://blog.csdn.net/weixin_37722026/article/details/103778202)</code></pre>
]]></description></item><item><title>C++ STL Containers</title><link>https://jianye0428.github.io/posts/datastructrue/</link><pubDate>Sun, 16 Jul 2023 15:03:55 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/datastructrue/</guid><description><![CDATA[<h2 id="c-stl-standard-template-library-总结">C++ STL (Standard Template Library) 总结</h2>
<p>C++ STL 容器是使用频率超高的基础设施，只有了解各个容器的底层原理，才能得心应手地用好不同的容器，做到用最合适的容器干最合适的事情。</p>
<p>本文旨在对 C++ 标准模板库的 <em>array</em>, <em>vector</em>, <em>deque</em>, <em>list</em>, <em>forward_list</em>, <em>queue</em>, <em>priority_queue</em>, <em>stack</em>, <em>map</em>, <em>multimap</em>, <em>set</em>, <em>multi_set</em>, <em>unordered_map</em>, <em>unordered_multimap</em>, <em>unordered_set</em>, <em>unordered_multiset</em> 共十六类容器进行系统的对比分析，重点关注各个容器的底层原理与性能特点。本文唯一参考资料为C++官方文档，若有其它参考则会指明出处。</p>
<h3 id="1-array">1. array</h3>
<blockquote>
<p>Container properties: Sequence | Contiguous storage | Fixed-size aggregate
容器属性：顺序容器（支持随机访问），连续内存空间，固定大小；//连续内存
类模板头：template &lt; class T, size_t N &gt; class array;</p>
</blockquote>
<p>array 即数组，其大小固定，所有的元素严格按照内存地址线性排列，array 并不维护元素之外的任何多余数据，甚至也不会维护一个size这样的变量，这保证了它在存储性能上和C++语法中的数组符号[]无异。尽管其它大部分标准容器都可以通过 std::allocator 来动态的分配和回收内存空间，但 <strong>Array 并不支持这样做</strong>。</p>
<p>Array 和其它标准容器一个很重要的不同是：<u>对两个 array 执行 swap 操作意味着真的会对相应 range 内的元素一一置换</u>，因此其时间花销正比于置换规模；但同时，对两个 array 执行 swap 操作不会改变两个容器各自的迭代器的依附属性，这是由 array 的 swap 操作不交换内存地址决定的。</p>
<p>Array 的另一个特性是：不同于其它容器，<font color = red>array 可以被当作 std::tuple 使用</font>，因为 array 的头文件重载了get()以及tuple_size()和tuple_element()函数（注意这些函数非 array 的成员函数，而是外部函数）。</p>
<p>最后需要注意，虽然 array 和 C++语法中的[]符号无限接近，但两者是两个存在，array 毕竟是标准模板库的一员，是一个class，因此支持
<code>begin(), end(), front(), back(), at(), empty(), data(), fill(), swap(), ... </code> 等等标准接口，而[]是真正的最朴素的数组。</p>
<h3 id="2-vector">2. vector</h3>
<blockquote>
<p>Container properties: Sequence | Dynamic array | Allocator-aware
容器属性：<font color = red>顺序容器</font>（支持随机访问），动态调整大小，使用内存分配器动态管理内存；//连续内存
类模板头：template &lt; class T, class Alloc = allocator<T> &gt; class vector;</p>
</blockquote>
<p>一句话来说，<u>vector 就是能够动态调整大小的 array</u>。和 array 一样，vector 使用<font color=red>连续内存空间</font>来保存元素，这意味着其元素可以用普通指针的<code>++</code>和<code>--</code>操作来访问；不同于 array 的是，其<strong>存储空间可以自动调整</strong>。</p>
<p>在底层上，vector 使用动态分配的 array，当现有空间无法满足增长需求时，会重新分配（reallocate）一个更大的 array 并把所有元素移动过去，因此，<font color=red>vector 的 reallocate 是一个很耗时的处理</font>。所以，每次 reallocate 时都会预留多余的空间，以满足潜在的增长需求，也就是说，vector的capacity()通常会大于size()。vector 什么时候做 reallocate，reallocate 多少多余空间，是有具体策略的，按下不表。总体来说，<u>vector 比 array 多了一些内存消耗，以换取更灵活的内存管理</u>。</p>
<p>和其它的动态顺序容器（deque, list, forward_list）相比，<u>vector 在元素访问上效率最高，在尾部增删元素的效率也相对最高</u>。如果调用者有在尾部以外的地方增删元素的需求，vector 则不如其它容器，并且迭代器的一致性也较差（have less consistent iterators and references than lists and forward_lists）。</p>
<h3 id="3-queue">3. queue</h3>
<blockquote>
<p>容器属性：<font color=red>容器适配器(adapter)</font>，先进先出型容器（FIFO）；//C++设计模式之适配器模式
template &lt;class T, class Container = deque<T> &gt; class queue;</p>
</blockquote>
<p>queue（普通队列）是一个专为 FIFO 设计的容器适配器，也即只能从一端插入、从另一端删除；所谓容器适配器，是指它本身只是一个封装层，必须依赖指定的底层容器（通过模板参数中的class Container指定）才能实现具体功能。</p>
<p>**容器适配器(Adapter)**实际上是C++设计模式的一种 &ndash; 称为 Adapter 模式（适配器模式），Adapter 模式的目的是将第三方库提供的接口做一个封装和转化，使其适配自己工程中预留的接口，或者适应自己工程的调用风格。换句话说，Adapter 模式的目的是将被调用类（如第三方库）的接口转化为希望的接口。</p>
<p>回到正题，queue 可以接纳任何一个至少支持下列接口的容器作为底层容器：</p>
<blockquote>
<p>empty(); size(); front(); back(); push_back(); pop_front().</p>
</blockquote>
<p>在标准模板库容器中，deque 和 list 满足上述要求，当然用户也可以自定义一个满足上述要求的容器。通过模板参数可以看出，<font color=red>默认情况下，queue 使用 deque 作为底层容器</font>。</p>
<h3 id="4-deque">4. deque</h3>
<blockquote>
<p>Container properties: Sequence | Dynamic array | Allocator-aware
容器属性：<font color=red>顺序容器</font>（支持随机访问），动态调整大小，使用内存分配器动态管理内存；//分段连续内存
类模板头：template &lt; class T, class Alloc = allocator<T> &gt; class deque;</p>
</blockquote>
<p>deque（读作&quot;deck&quot;）是 double-ended queue 的缩写，是一个可以在首尾两端进行动态增删的顺序容器。</p>
<p>不同的库对 deque 的实现可能不同，但大体上都是<font color=green>某种形式的动态 array</font>，且都支持随机访问。deque 的功能和 vector 比较接近，但 deque 额外支持在头部动态增删元素。和 vector 不一样的是，<font color = red><u>deque 不保证存储区域一定是连续的!</u></font> 因此用指向元素的普通指针做<code>++</code>和<code>--</code>操作是非常危险的行为。</p>
<p>从底层机理上能更透彻地理解 deque 的特点：<font color = red>vector 使用的是单一的 array，deque 则会使用很多个离散的 array 来组织数据</font>「the elements of a deque can be scattered in different chunks of storage」！如果说 vector 是连续的，deque 则是分段连续。deque 会维护不同 array 之间的关联信息，使用户无需关心分段这个事实。这样做的好处是很明显的：deque 在 reallocate 时，只需新增/释放两端的 storage chunk 即可，无需移动已有数据（vector 的弊端），极大提升了效率，尤其在数据规模很大时，优势明显。</p>
<p>相比于 vector 和 list，deque 并不适合遍历！因为每次访问元素时，deque 底层都要检查是否触达了内存片段的边界，造成了额外的开销！deque 的核心优势是在双端都支持高效的增删操作，程序员选择使用 deque 时需要有双端操作的明确理由。</p>
<h3 id="5-priority_queue">5. priority_queue</h3>
<blockquote>
<p>容器属性：<font color=red>容器适配器</font>，严格弱序（Strict Weak Ordering），优先级队列；
template &lt;class T, class Container = vector<T>,
class Compare = less<typename Container::value_type> &gt; class priority_queue;</p>
</blockquote>
<p>和 queue 类似，priority_queue（术语叫作优先级队列）也只是一个容器适配器，需要指定底层容器才能实例化，参见模板参数中的class Container形参。priority_queue 的核心特点在于其严格弱序特性（strict weak ordering）：也即 priority_queue 保证容器中的第一个元素始终是所有元素中最大的！为此，用户在实例化一个 priority_queue 时，必须为元素类型（class T）重载&lt;运算符，以用于元素排序！</p>
<p>priority_queue 的原理可以用一个大顶堆来解释：priority_queue 在内部维护一个基于二叉树的大顶堆数据结构，在这个数据结构中，最大的元素始终位于堆顶部，且只有堆顶部的元素（max heap element）才能被访问和获取，大顶堆的具体原理可参见任何一本数据结构书籍。</p>
<p>为了支持这种工作原理，priority_queue 对底层容器也是有要求的，priority_queue 的底层容器必须支持随机访问和至少以下接口：</p>
<blockquote>
<p>empty(); size(); front(); push_back(); pop_back().</p>
</blockquote>
<p>标准模板库中的 vector 和 deque 能够满足上述需求，默认情况下，priority_queue 使用 vector 作为底层容器。</p>
<p>某种程度上来说，priority_queue 默认在 vector 上使用堆算法将 vector 中元素构造成大顶堆的结构，因此 priority_queue 就是堆 ，所有需要用到堆的位置，都可以考虑使用 priority_queue。priority_queue 默认是大顶堆，用户也可以通过自定义模板参数中的 class Compare 来实现一个小顶堆。</p>
<p>相比于 queue（普通队列）的先进先出FIFO，priority_queue 实现了最高优先级先出。</p>
<h3 id="6-list">6. list</h3>
<blockquote>
<p>Container properties: Sequence | Doubly-linked list | Allocator-aware
容器属性：<font color = red>顺序容器</font>（可顺序访问，但不支持随机访问），双链表，使用内存分配器动态管理内存；//离散内存
类模板头：template &lt; class T, class Alloc = allocator<T> &gt; class list;</p>
</blockquote>
<p>list 是一种支持在<strong>任意位置都可以快速地插入和删除</strong>元素的容器，且支持<strong>双向遍历</strong>。list 容器能够做到这些的原因在于<strong>其底层结构是双链表</strong>，双链表允许把各个元素都保存在彼此不相干的内存地址上，但每个元素都会与前后相邻元素关联。</p>
<p>和其它的顺序容器（array, vector, deque）相比，<u>list 的最大优势在于支持在任意位置插入、删除和移动元素</u>，对 list 来说，在哪个位置进行操作并没有区别。list 在部分算法（如 sorting）中的效率可能优于其它顺序容器。</p>
<p>list 的<strong>主要缺点</strong>是<u>不支持元素的随机访问</u>！如果我们想要访问某个元素，则必须从一个已知元素（如 begin 或 end）开始朝一个方向遍历，直至到达要访问的元素。此外，list 还要消耗更多的内存空间，用于保存各个元素的关联信息。</p>
<p>[另说] <strong>list 对内存空间的使用效率并不高，一方面元素内存地址是离散的而非连续，另一方面，list 需要保存额外的关联信息。</strong></p>
<h3 id="7-forward_list">7. forward_list</h3>
<blockquote>
<p>Container properties: Sequence | Linked list | Allocator-aware
容器属性：<font color = red>顺序容器</font>（可顺序访问，但不支持随机访问），单链表，使用内存分配器动态管理内存；
类模板头：template &lt; class T, class Alloc = allocator<T> &gt; class list;</p>
</blockquote>
<p>forward_list 也是一种支持在任意位置快速插入和删除元素的容器，forward_list 相比于 list 的核心区别是它是一个单链表，因此, 每个元素只会与相邻的下一个元素关联！由于关联信息少了一半，因此 forward_list 占用的内存空间更小，且插入和删除的效率稍稍高于 list。作为代价，forward_list 只能单向遍历。</p>
<p>相比于其它顺序容器（array, vector, deque），forward_list 的优缺点和 list 基本相同。</p>
<p>既然已经有了 list，为什么 C++ STL 又设计了 forward_list 这一容器呢？设计 forward_list 的目的是为了达到不输于任何一个C风格<strong>手写链表的极值效率</strong>！为此，forward_list 是一个最小链表设计，它甚至没有size()接口，因为内部维护一个size变量会降低增删元素的效率。如果想要获取 forward_list 的 size，一个通常的做法是，用 std::distance 计算 begin 到 end 的距离得出 size。一句话总结：list 兼顾了接口丰富性牺牲了效率，而 forward_list 舍弃了不必要的接口只为追求极致效率。</p>
<h3 id="8-stack">8. stack</h3>
<blockquote>
<p>容器属性：<font color = red>容器适配器</font>，后进先出型容器（LIFO）；
template &lt;class T, class Container = deque<T> &gt; class stack;</p>
</blockquote>
<p>stack（栈）是一个专为 LIFO 设计的容器适配器，也即只能从一端插入和删除；作为适配器，需要指定底层容器才能实例化，参见模板参数中的<code>class Container</code>形参。</p>
<p>stack 的特点是后进先出（一端进出），不允许遍历；任何时候外界只能访问 stack 顶部的元素；只有在移除 stack 顶部的元素后，才能访问下方的元素。stack 需要底层容器能够在一端增删元素，这一端也即 stack 的“栈顶”；stack 可以接纳任何一个至少支持下列接口的容器作为底层容器：</p>
<blockquote>
<p>empty(); size(); back(); push_back(); pop_back()</p>
</blockquote>
<p>在标准模板库容器中，vector、deque 和 list 满足上述要求，当然用户也可以自定义一个满足上述要求的容器。通过模板参数可以看出，默认情况下，<strong>stack 使用 deque 作为底层容器</strong>。</p>
<p>stack 容器应用广泛，例如，编辑器中的 undo （撤销操作）机制就是用栈来记录连续的操作。stack 的设计场景和自助餐馆中堆叠的盘子、摞起来的一堆书类似。</p>
<h3 id="9-map">9. map</h3>
<blockquote>
<p>Container properties: Associative | Ordered | Map | Unique keys | Allocator-aware
容器属性：<font color = red>关联容器</font>，有序，元素类型&lt;key, value&gt;，key是唯一的，使用内存分配器动态管理内存 ；
template &lt; class Key, // map::key_type
class T, // map::mapped_type
class Compare = less<Key>, // map::key_compare
class Alloc = allocator&lt;pair&lt;const Key,T&gt; &gt; // map::allocator_type
class map;</p>
</blockquote>
<p>map 是一个关联型容器，其元素类型是由 key 和 value 组成的 std::pair，实际上 map 中元素的数据类型正是 <code>typedef pair&lt;const Key, T&gt; value_type</code>;，这就看的很清楚了。</p>
<p>所谓关联容器，是指<strong>对所有元素的检索都是通过元素的 key 进行的（而非元素的内存地址）</strong>，map 通过底层的「红黑树」数据结构来将所有的元素按照 key 的相对大小进行排序，所实现的排序效果也是严格弱序特性（strict weak ordering），为此，开发者需要重载 key 的&lt;运算符或者模板参数中的 class Compare。所提到的红黑树是一种自平衡二叉搜索树，它衍生自B树，这里推荐两篇文章（<a href="https://zhuanlan.zhihu.com/p/72505589"target="_blank" rel="external nofollow noopener noreferrer">记一次腾讯面试：有了二叉查找树、平衡树（AVL）为啥还需要红黑树？<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>，<a href="https://zhuanlan.zhihu.com/p/273829162"target="_blank" rel="external nofollow noopener noreferrer">图解：什么是红黑树？<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>）作为更深入的参考。</p>
<p>大体来说，map 访问元素的速度要稍慢于下文的 unordered_map，这是因为虽然都叫“map”，但两者的底层机制完全不一样。但是，相比于后者，map 支持在一个子集合上进行直接迭代器访问，原因在于 map 中的元素是被有序组织的。</p>
<p>最后，map 也支持通过operator[]的方式来直接访问 value。</p>
<h3 id="10-multimap">10. multimap</h3>
<blockquote>
<p>Container properties: Associative | Ordered | Map | Multiple equivalent keys | Allocator-aware
容器属性: 关联容器，有序，元素类型&lt;key, value&gt;，允许不同元素key相同，使用内存分配器管理内存；
template &lt; class Key, // map::key_type
class T, // map::mapped_type
class Compare = less<Key>, // map::key_compare
class Alloc = allocator&lt;pair&lt;const Key,T&gt; &gt; // map::allocator_type
class map;</p>
</blockquote>
<p><strong>map 中不允许出现 key 相同的两个元素，但 multimap 则可以这样做！</strong></p>
<p>multimap 与 map 底层原理完全一样，都是使用「红黑树」对元素数据按 key 的比较关系，进行快速的插入、删除和检索操作；所不同的是 multimap 允许将具有相同 key 的不同元素插入容器（这个不同体现了 multimap 对红黑树的使用方式的差异）。在 multimap 容器中，元素的 key 与元素 value 的映射关系，是一对多的，因此，multimap 是多重映射容器。</p>
<p>注意，在向 multimap 中新增元素时，multimap 只会判断 key 是否相同，而完全不会判断 value 是否相同！<font color=red>这意味着如果相同的 &lt;key, value&gt; 插入了多次，multimap 会对它们悉数保存！</font></p>
<p>在使用中，我们可以通过迭代器配合 lower_bound() 和 upper_bound() 来访问一个 key 对应的所有 value，也可以使用equal_range()来访问一个 key 对应的所有 value，也可以通过find()配合count()来访问一个 key 对应的所有 value，个人认为前两种方法使用起来更方便一点。</p>
<p>下文中将要提到的 multiset 之于 set 类似于这里的 multimap 之于 map。</p>
<h3 id="11-set">11. set</h3>
<blockquote>
<p>Container properties: Associative | Ordered | Set | Unique keys | Allocator-aware
容器属性：<font color=red>关联容器</font>，有序，元素自身即key，元素有唯一性，使用内存分配器动态管理内存；
template &lt; class T, // set::key_type/value_type
class Compare = less<T>, // set::key_compare/value_compare
class Alloc = allocator<T> // set::allocator_type
class set;</p>
</blockquote>
<p>set 是一个关联型容器，和 map 一样，它的底层结构是「红黑树」，但和 map 不一样的是，<strong>set 是直接保存 value 的</strong>，或者说，set 中的 value 就是 key。</p>
<p><strong>set 中的元素必须是唯一的，不允许出现重复的元素</strong>，且元素不可更改，但可以自由插入或者删除。</p>
<p>由于底层是红黑树，所以 set 中的元素也是严格弱序（strict weak ordering）排序的，因此<u>支持用迭代器做范围访问</u>（迭代器自加自减）。</p>
<p>实际使用中，set 和 map 是近亲，性能相似，他们的差别是元素的 value 本身是否也作为 key 来标识自己。</p>
<h3 id="12-multi_set">12. multi_set</h3>
<blockquote>
<p>Container properties: Associative | Ordered | Set | Multiple equivalent keys | Allocator-aware
容器属性：<font color=red>关联容器</font>，有序，元素自身即key，允许不同元素值相同，使用内存分配器动态管理内存 ；
template &lt; class T, // multiset::key_type/value_type
class Compare = less<T>, // multiset::key_compare/value_compare
class Alloc = allocator<T> &gt; // multiset::allocator_type
class multiset;</p>
</blockquote>
<p>multiset 之于 set 就如同 multimap 之于 map：</p>
<p>multiset 和 set 底层都是红黑树，multiset 相比于 set 支持保存多个相同的元素；</p>
<p>multimap 和 map 底层都是红黑树，multimap 相比于 map 支持保存多个key相同的元素。</p>
<p>鉴于以上近亲关系，multiset 的性能特点与其它三者相似，不再赘述。</p>
<h3 id="13-unordered_map">13. unordered_map</h3>
<blockquote>
<p>Container properties: Associative | Unordered | Map | Unique keys | Allocator-aware
容器属性：<font color = red>关联容器</font>，无序，元素类型&lt;key, value&gt;，key是唯一的，使用内存分配器动态管理内存 ； template &lt; class Key, // unordered_map::key_type
class T, // unordered_map::mapped_type
class Hash = hash<Key>, // unordered_map::hasher
class Pred = equal_to<Key>, // unordered_map::key_equal
class Alloc = allocator&lt; pair&lt;const Key,T&gt; &gt; // unordered_map::allocator_type
class unordered_map;</p>
</blockquote>
<p>unordered_map 和 map 一样，都是关联容器，以键值对儿 &lt;key, value&gt; 作为元素进行存储；但是，除此之外，两者可以说是完全不一样！</p>
<p>这是由底层的数据结构决定的，map 以红黑树作为底层结构组织数据，而 <strong>unordered_map 以哈希表(hash table)作为底层数据结构</strong>来组织数据，这造成了两点重要影响：
1. unordered_map 不支持排序，<font color=red>在使用迭代器做范围访问时（迭代器自加自减）效率更低</font>；
2. 但 unordered_map 直接访问元素的速度更快（尤其在规模很大时），因为它通过直接计算 key 的哈希值来访问元素，是O(1)复杂度！</p>
<p>网络上有对 map VS unordered_map 效率对比的测试，通常 <strong>map 增删元素的效率更高，unordered_map 访问元素的效率更高</strong>，可以参见<a href="https://link.zhihu.com/?target=https%3A//blog.csdn.net/uniqsa/article/details/62442383"target="_blank" rel="external nofollow noopener noreferrer">这篇文章<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>。另外，unordered_map 内存占用更高，因为底层的哈希表需要预分配足量的空间。</p>
<p>综上，unordered_map 更适用于增删操作不多，但需要频繁访问，且内存资源充足的场合。</p>
<blockquote>
<p>比如在机器人领域的SLAM技术中，可以选择 unordered_map 来维护体素形式的 local map？ 当然 deque 应该也是不错的选择。</p>
</blockquote>
<h3 id="14-unordered_multimap">14. unordered_multimap</h3>
<blockquote>
<p>Container properties: Associative | Unordered | Map | Multiple equivalent keys | Allocator-aware
容器属性：关联容器，无序，元素类型&lt;key, value&gt;，允许不同元素key相同，使用内存分配器管理内存 ；
template &lt; class Key, // unordered_multimap::key_type
class T, // unordered_multimap::mapped_type
class Hash = hash<Key>, // unordered_multimap::hasher
class Pred = equal_to<Key>, // unordered_multimap::key_equal
class Alloc = allocator&lt; pair&lt;const Key,T&gt; &gt; // unordered_multimap::allocator_type
class unordered_multimap;</p>
</blockquote>
<p>unordered_multimap 是对 unordered_map 的拓展，唯一区别在于 unordered_multimap 允许不同元素的 key 相同，但两者无论是在底层结构还是在容器特性上都是相通的，仅仅是对底层哈希表的使用方式稍有不同。</p>
<p>在 unordered_multimap 中想要访问同一个 key 下对应的所有元素的话，可以使用equal_range()轻松做到；当然，也可以使用find()和count()配合的方式来访问。</p>
<p>unordered_multimap 的容器特性参见 unordered_map，不再赘述。</p>
<h3 id="15-unordered_set">15. unordered_set</h3>
<blockquote>
<p>Container properties: Associative | Unordered | Set | Unique keys | Allocator-aware
容器属性：<font color=red>关联容器</font>，无序，元素自身即key，元素有唯一性，使用内存分配器动态管理内存 ；
template &lt; class Key, // unordered_set::key_type/value_type
class Hash = hash<Key>, // unordered_set::hasher
class Pred = equal_to<Key>, // unordered_set::key_equal
class Alloc = allocator<Key> // unordered_set::allocator_type
class unordered_set;</p>
</blockquote>
<p>所有unordered_XXX类容器的特点都是以哈希表作为底层结构；所有 XXX_set 类容器的特点都是「元素自身也作为key」来标识自己。我们在把两类特性叠加到一起，就得到了 unordered_set。</p>
<p>在 unordered_set 中，元素自身同时也作为 key 使用；既然是作为 key 使用，那么元素就不能被更改，也即 unordered_set 中的元素都是 constant 的，但我们可以自由的插入和删除元素，这也是所有XXX_set类容器的性质。既然底层结构是哈希表，意味着 unordered_set 中的元素是无序的，不能按照大小排序，这也是所有unordered_XXX类容器的性质。</p>
<p>和所有的unordered_XXX类容器一样：
1. unordered_set 直接用迭代器做范围访问时（迭代器自加自减）效率更低，低于 set；
2. 但 unordered_set 直接访问元素的速度更快（尤其在规模很大时），因为它通过直接计算 key 的哈希值来访问元素，是O(1)复杂度！</p>
<h3 id="16-unordered_multiset">16. unordered_multiset</h3>
<blockquote>
<p>Container properties: Associative | Unordered | Set | Multiple equivalent keys | Allocator-aware
容器属性：<font color=red>关联容器</font>，无序，元素自身即key，允许不同元素值相同，使用内存分配器动态管理内存 ；
template &lt; class Key, // unordered_multiset::key_type/value_type
class Hash = hash<Key>, // unordered_multiset::hasher
class Pred = equal_to<Key>, // unordered_multiset::key_equal
class Alloc = allocator<Key> // unordered_multiset::allocator_type
class unordered_multiset;</p>
</blockquote>
<p>unordered_multiset，顾名思义，就是集齐了“哈希表为底层结构”，“元素自身即key”，“允许不同元素值相同”这三个特性的容器，是对 unordered_set 的简单拓展。</p>
<p>unordered_multiset 的效率特性与所有基于哈希表的容器相似，参见 unordered_set，不再赘述。</p>
<h3 id="17-pair--tuple">17. pair &amp;&amp; tuple</h3>
<blockquote>
<p>template &lt;class&hellip; Types&gt; class tuple;
template &lt;class T1, class T2&gt; struct pair;</p>
</blockquote>
<p><code>std::pair</code> 和 <code>std::tuple</code> 并不是stl容器库中的容器，不过鉴于经常用到，就顺便整理一下。先从 tuple 说起，pair 相当于 tuple 的特例。</p>
<p>tuple 叫作元组，它可以把一组类型相同或不同的元素组合到一起，且元素的数量不限。tuple 的底层原理与 stl 中的容器完全不同，但在功能上，tuple 是对容器的有效补充，因为所有的容器都只能组合相同类型的元素，但tuple 可以组合任意不同类型的元素。在使用上，可以用std::make_tuple()来构造 tuple 对象，可以用std::get<index>()来获取 tuple 对象的某个元素，注意std::get<index>()返回的是 tuple 对象中某个元素的索引，因此是可以用作左值的！此外，也可以用std::tie()打包一组变量来作为左值接受 tuple 对象的赋值。</p>
<p>tuple 的底层原理大概是一个层层继承的类，详情可以参考<a href="https://zhuanlan.zhihu.com/p/356954012"target="_blank" rel="external nofollow noopener noreferrer">这篇文章<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>，写的非常透彻。</p>
<p>pair 可以看作是把 tuple 的 size 限制为 2 的一个特例，pair 只能把一对儿元素组合到一起。在使用上，可以用std::make_pair()来直接构建 pair 对象，可以用std::get&lt;0&gt;()和std::get&lt;1&gt;()来分别获取 pair 对象的两个元素，但更方便的做法是直接访问 pair 类型的两个数据成员pair对象.first和pair对象.second来访问元素</p>
<p>reference:
[1]. <a href="https://zhuanlan.zhihu.com/p/542115773"target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/542115773<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
]]></description></item><item><title>TreeNode 二叉树</title><link>https://jianye0428.github.io/posts/treenode/</link><pubDate>Sun, 16 Jul 2023 14:49:58 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/treenode/</guid><description><![CDATA[<p>Runebook
<a href="https://www.doc4dev.com"target="_blank" rel="external nofollow noopener noreferrer">www.doc4dev.com<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<h2 id="深度优先遍历">深度优先遍历</h2>
<p></p>
<ul>
<li>前序遍历：中左右 <code>5 4 1 2 6 7 8</code></li>
<li>中序遍历：左中右 <code>1 4 2 5 7 6 8</code></li>
<li>后序遍历：左右中 <code>1 2 4 7 8 6 5</code></li>
</ul>
<p><strong>二叉树的定义</strong></p>
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">struct</span> <span class="nc">TreeNode</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">val</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">TreeNode</span> <span class="o">*</span><span class="n">left</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">TreeNode</span> <span class="o">*</span><span class="n">right</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">TreeNode</span><span class="p">(</span><span class="kt">int</span> <span class="n">x</span><span class="p">)</span> <span class="o">:</span> <span class="n">val</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">left</span><span class="p">(</span><span class="nb">NULL</span><span class="p">),</span> <span class="n">right</span><span class="p">(</span><span class="nb">NULL</span><span class="p">)</span> <span class="p">{}</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span></span></span></code></pre></td></tr></table>
</div>
</div><h3 id="前序遍历">前序遍历</h3>
<p><strong>递归法</strong></p>
<div class="highlight" id="id-2"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Solution</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="kt">void</span> <span class="n">traversal</span><span class="p">(</span><span class="n">TreeNode</span><span class="o">*</span> <span class="n">cur</span><span class="p">,</span> <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">vec</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">cur</span> <span class="o">==</span> <span class="k">nullptr</span><span class="p">)</span> <span class="k">return</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">vec</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">cur</span><span class="o">-&gt;</span><span class="n">val</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">traversal</span><span class="p">(</span><span class="n">root</span><span class="o">-&gt;</span><span class="n">left</span><span class="p">,</span> <span class="n">vec</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">traversal</span><span class="p">(</span><span class="n">root</span><span class="o">-&gt;</span><span class="n">right</span><span class="p">,</span> <span class="n">vec</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">preorderTraversal</span><span class="p">(</span><span class="n">TreeNode</span><span class="o">*</span> <span class="n">root</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">res</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">traversal</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">vec</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">res</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span></span></span></code></pre></td></tr></table>
</div>
</div><p><strong>迭代法</strong></p>
<div class="highlight" id="id-3"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Solution</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">preorderTraversal</span><span class="p">(</span><span class="n">TreeNode</span><span class="o">*</span> <span class="n">root</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">stack</span><span class="o">&lt;</span><span class="n">TreeNode</span><span class="o">*&gt;</span> <span class="n">st</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">res</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">root</span> <span class="o">==</span> <span class="k">nullptr</span><span class="p">)</span> <span class="k">return</span> <span class="n">res</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">st</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">root</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">while</span> <span class="p">(</span><span class="o">!</span><span class="n">st</span><span class="p">.</span><span class="n">empty</span><span class="p">())</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">TreeNode</span><span class="o">*</span> <span class="n">node</span> <span class="o">=</span> <span class="n">st</span><span class="p">.</span><span class="n">top</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">            <span class="n">st</span><span class="p">.</span><span class="n">pop</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">            <span class="n">res</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">val</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">right</span><span class="p">)</span>  <span class="n">st</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">right</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">left</span><span class="p">)</span> <span class="n">st</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">left</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">res</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span></span></span></code></pre></td></tr></table>
</div>
</div><h3 id="中序遍历">中序遍历</h3>
<p><strong>递归法</strong></p>
<div class="highlight" id="id-4"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Solution</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="kt">void</span> <span class="n">traversal</span><span class="p">(</span><span class="n">TreeNode</span><span class="o">*</span> <span class="n">cur</span><span class="p">,</span> <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">vec</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">cur</span> <span class="o">==</span> <span class="k">nullptr</span><span class="p">)</span> <span class="k">return</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">traversal</span><span class="p">(</span><span class="n">root</span><span class="o">-&gt;</span><span class="n">left</span><span class="p">,</span> <span class="n">vec</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">vec</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">cur</span><span class="o">-&gt;</span><span class="n">val</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">traversal</span><span class="p">(</span><span class="n">root</span><span class="o">-&gt;</span><span class="n">right</span><span class="p">,</span> <span class="n">vec</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">inorderTraversal</span><span class="p">(</span><span class="n">TreeNode</span><span class="o">*</span> <span class="n">root</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">res</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">traversal</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">vec</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">res</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span></span></span></code></pre></td></tr></table>
</div>
</div><p><strong>迭代法</strong></p>
<div class="highlight" id="id-5"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="c1">// 中序遍历
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">class</span> <span class="nc">Solution</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">inorderTraversal</span><span class="p">(</span><span class="n">TreeNode</span><span class="o">*</span> <span class="n">root</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">stack</span><span class="o">&lt;</span><span class="n">TreeNode</span><span class="o">*&gt;</span> <span class="n">st</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">res</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">root</span> <span class="o">==</span> <span class="k">nullptr</span><span class="p">)</span> <span class="k">return</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">TreeNode</span><span class="o">*</span> <span class="n">cur</span> <span class="o">=</span> <span class="n">root</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">while</span> <span class="p">(</span><span class="o">!</span><span class="n">cur</span> <span class="o">||</span> <span class="o">!</span><span class="n">st</span><span class="p">.</span><span class="n">empty</span><span class="p">())</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="p">(</span><span class="n">cur</span> <span class="o">!=</span> <span class="k">nullptr</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">                <span class="n">st</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">cur</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">                <span class="n">cur</span> <span class="o">=</span> <span class="n">cur</span><span class="o">-&gt;</span><span class="n">left</span><span class="p">;</span> <span class="c1">// 左
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>            <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">                <span class="n">cur</span> <span class="o">=</span> <span class="n">st</span><span class="p">.</span><span class="n">top</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">                <span class="n">st</span><span class="p">.</span><span class="n">pop</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">                <span class="n">res</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">cur</span><span class="o">-&gt;</span><span class="n">val</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">                <span class="n">cur</span> <span class="o">=</span> <span class="n">cur</span><span class="o">-&gt;</span><span class="n">right</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">            <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">res</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span></span></span></code></pre></td></tr></table>
</div>
</div><h3 id="后序遍历">后序遍历</h3>
<p><strong>递归法</strong></p>
<div class="highlight" id="id-6"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Solution</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="kt">void</span> <span class="n">traversal</span><span class="p">(</span><span class="n">TreeNode</span><span class="o">*</span> <span class="n">cur</span><span class="p">,</span> <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">vec</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">cur</span> <span class="o">==</span> <span class="k">nullptr</span><span class="p">)</span> <span class="k">return</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">traversal</span><span class="p">(</span><span class="n">root</span><span class="o">-&gt;</span><span class="n">left</span><span class="p">,</span> <span class="n">vec</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">traversal</span><span class="p">(</span><span class="n">root</span><span class="o">-&gt;</span><span class="n">right</span><span class="p">,</span> <span class="n">vec</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">vec</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">cur</span><span class="o">-&gt;</span><span class="n">val</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">postorderTraversal</span><span class="p">(</span><span class="n">TreeNode</span><span class="o">*</span> <span class="n">root</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">res</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">traversal</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">vec</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">res</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span></span></span></code></pre></td></tr></table>
</div>
</div><p><strong>迭代法</strong></p>
<div class="highlight" id="id-7"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Solution</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">postorderTraversal</span><span class="p">(</span><span class="n">TreeNode</span><span class="o">*</span> <span class="n">root</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">res</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">root</span><span class="p">)</span> <span class="k">return</span> <span class="n">res</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">stack</span><span class="o">&lt;</span><span class="n">TreeNode</span><span class="o">*&gt;</span> <span class="n">st</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">st</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">root</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">while</span> <span class="p">(</span><span class="o">!</span><span class="n">st</span><span class="p">.</span><span class="n">empty</span><span class="p">())</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">TreeNode</span><span class="o">*</span> <span class="n">node</span> <span class="o">=</span> <span class="n">st</span><span class="p">.</span><span class="n">top</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">            <span class="n">st</span><span class="p">.</span><span class="n">pop</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">            <span class="n">res</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">val</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">left</span><span class="p">)</span> <span class="n">st</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">left</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">right</span><span class="p">)</span> <span class="n">st</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">right</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="n">reverse</span><span class="p">(</span><span class="n">res</span><span class="p">.</span><span class="n">begin</span><span class="p">(),</span> <span class="n">res</span><span class="p">.</span><span class="n">end</span><span class="p">());</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">res</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span></span></span></code></pre></td></tr></table>
</div>
</div><h2 id="二叉树的统一迭代法">二叉树的统一迭代法</h2>
<p><strong>迭代法前序遍历</strong></p>
<div class="highlight" id="id-8"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="c1">// 中左右
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">class</span> <span class="nc">Solution</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">preorderTraversal</span><span class="p">(</span><span class="n">TreeNode</span><span class="o">*</span> <span class="n">root</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">res</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">stack</span><span class="o">&lt;</span><span class="n">TreeNode</span><span class="o">*&gt;</span> <span class="n">st</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">root</span><span class="p">)</span> <span class="n">st</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">root</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">while</span> <span class="p">(</span><span class="o">!</span><span class="n">st</span><span class="p">.</span><span class="n">empty</span><span class="p">())</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">TreeNode</span><span class="o">*</span> <span class="n">node</span> <span class="o">=</span> <span class="n">st</span><span class="p">.</span><span class="n">top</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="p">(</span><span class="n">node</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">                <span class="n">st</span><span class="p">.</span><span class="n">pop</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">right</span><span class="p">)</span> <span class="n">st</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">right</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">left</span><span class="p">)</span> <span class="n">st</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">left</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">                <span class="n">st</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">node</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">                <span class="n">st</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="k">nullptr</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">                <span class="n">st</span><span class="p">.</span><span class="n">pop</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">                <span class="n">node</span> <span class="o">=</span> <span class="n">st</span><span class="p">.</span><span class="n">top</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">                <span class="n">st</span><span class="p">.</span><span class="n">pop</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">                <span class="n">res</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">val</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">res</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span></span></span></code></pre></td></tr></table>
</div>
</div><p><strong>迭代法中序遍历</strong></p>
<div class="highlight" id="id-9"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="c1">//左中右
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">class</span> <span class="nc">Solution</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">inorderTraversal</span><span class="p">(</span><span class="n">TreeNode</span><span class="o">*</span> <span class="n">root</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">res</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">stack</span><span class="o">&lt;</span><span class="n">TreeNode</span><span class="o">*&gt;</span> <span class="n">st</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">root</span> <span class="o">!=</span> <span class="k">nullptr</span><span class="p">)</span> <span class="n">st</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">root</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">while</span><span class="p">(</span><span class="o">!</span><span class="n">st</span><span class="p">.</span><span class="n">empty</span><span class="p">())</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">TreeNode</span><span class="o">*</span> <span class="n">node</span> <span class="o">=</span> <span class="n">st</span><span class="p">.</span><span class="n">top</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="p">(</span><span class="n">node</span> <span class="o">!=</span> <span class="k">nullptr</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">                <span class="n">st</span><span class="p">.</span><span class="n">pop</span><span class="p">();</span> <span class="c1">//将该节点弹出，避免重复操作
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>                <span class="k">if</span> <span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">right</span><span class="p">)</span> <span class="n">st</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">right</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">                <span class="n">st</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">node</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">                <span class="n">st</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="k">nullptr</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">left</span><span class="p">)</span> <span class="n">st</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">left</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">                <span class="n">st</span><span class="p">.</span><span class="n">pop</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">                <span class="n">node</span> <span class="o">=</span> <span class="n">st</span><span class="p">.</span><span class="n">top</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">                <span class="n">st</span><span class="p">.</span><span class="n">pop</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">                <span class="n">res</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">val</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">res</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span></span></span></code></pre></td></tr></table>
</div>
</div><p><strong>迭代法后序遍历</strong></p>
<div class="highlight" id="id-10"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="c1">// 左右中
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">class</span> <span class="nc">Solution</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">postorderTraversal</span><span class="p">(</span><span class="n">TreeNode</span><span class="o">*</span> <span class="n">root</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">res</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">stack</span><span class="o">&lt;</span><span class="n">TreeNode</span><span class="o">*&gt;</span> <span class="n">st</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">root</span><span class="p">)</span> <span class="n">st</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">root</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">while</span> <span class="p">(</span><span class="o">!</span><span class="n">st</span><span class="p">.</span><span class="n">empty</span><span class="p">())</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">TreeNode</span><span class="o">*</span> <span class="n">node</span> <span class="o">=</span> <span class="n">st</span><span class="p">.</span><span class="n">top</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="p">(</span><span class="n">node</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">                <span class="n">st</span><span class="p">.</span><span class="n">pop</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">                <span class="n">st</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">node</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">                <span class="n">st</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="k">nullptr</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">right</span><span class="p">)</span> <span class="n">st</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">right</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">left</span><span class="p">)</span> <span class="n">st</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">left</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">                <span class="n">st</span><span class="p">.</span><span class="n">pop</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">                <span class="n">node</span> <span class="o">=</span> <span class="n">st</span><span class="p">.</span><span class="n">top</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">                <span class="n">st</span><span class="p">.</span><span class="n">pop</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">                <span class="n">res</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">val</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">res</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span></span></span></code></pre></td></tr></table>
</div>
</div><h2 id="广度优先遍历-层序遍历">广度优先遍历 (层序遍历)</h2>
<p><strong>递归法</strong></p>
<div class="highlight" id="id-11"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Solution</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">vector</span><span class="o">&lt;</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&gt;</span> <span class="n">levelOrder</span><span class="p">(</span><span class="n">TreeNode</span><span class="o">*</span> <span class="n">root</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">queue</span><span class="o">&lt;</span><span class="n">TreeNode</span><span class="o">*&gt;</span> <span class="n">que</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">root</span><span class="p">)</span> <span class="n">que</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">root</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">vector</span><span class="o">&lt;</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&gt;</span> <span class="n">ans</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">while</span> <span class="p">(</span><span class="o">!</span><span class="n">que</span><span class="p">.</span><span class="n">empty</span><span class="p">())</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="kt">int</span> <span class="n">size</span> <span class="o">=</span> <span class="n">que</span><span class="p">.</span><span class="n">size</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">            <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">vec</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">            <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">size</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">                <span class="n">TreeNode</span><span class="o">*</span> <span class="n">node</span> <span class="o">=</span> <span class="n">que</span><span class="p">.</span><span class="n">front</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">                <span class="n">que</span><span class="p">.</span><span class="n">pop</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">                <span class="n">vec</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">val</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">left</span><span class="p">)</span> <span class="n">que</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">left</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">right</span><span class="p">)</span> <span class="n">que</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">right</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="p">}</span>
</span></span><span class="line"><span class="cl">            <span class="n">ans</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">vec</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">ans</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span></span></span></code></pre></td></tr></table>
</div>
</div><p><strong>迭代法</strong></p>
<div class="highlight" id="id-12"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Solution</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl"><span class="k">public</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="kt">void</span> <span class="n">order</span><span class="p">(</span><span class="n">TreeNode</span><span class="o">*</span> <span class="n">cur</span><span class="p">,</span> <span class="n">vector</span><span class="o">&lt;</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&gt;&amp;</span> <span class="n">res</span><span class="p">,</span> <span class="kt">int</span> <span class="n">depth</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">cur</span> <span class="o">==</span> <span class="k">nullptr</span><span class="p">)</span> <span class="k">return</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">res</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">==</span> <span class="n">depth</span><span class="p">)</span> <span class="n">res</span><span class="p">.</span><span class="n">push_back</span><span class="p">(</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">());</span>
</span></span><span class="line"><span class="cl">        <span class="n">res</span><span class="p">[</span><span class="n">depth</span><span class="p">].</span><span class="n">push_back</span><span class="p">(</span><span class="n">cur</span><span class="o">-&gt;</span><span class="n">val</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">order</span><span class="p">(</span><span class="n">cur</span><span class="o">-&gt;</span><span class="n">left</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="n">order</span><span class="p">(</span><span class="n">cur</span><span class="o">-&gt;</span><span class="n">right</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="n">vector</span><span class="o">&lt;</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&gt;</span> <span class="n">levelOrder</span><span class="p">(</span><span class="n">TreeNode</span><span class="o">*</span> <span class="n">root</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">vector</span><span class="o">&lt;</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&gt;</span> <span class="n">res</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="kt">int</span> <span class="n">depth</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="n">order</span><span class="p">(</span><span class="n">root</span><span class="p">,</span> <span class="n">res</span><span class="p">,</span> <span class="n">depth</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">res</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">};</span></span></span></code></pre></td></tr></table>
</div>
</div>]]></description></item><item><title>Sorting Algorithms</title><link>https://jianye0428.github.io/posts/sortingalgo/</link><pubDate>Sun, 16 Jul 2023 13:54:12 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/sortingalgo/</guid><description><![CDATA[<h3 id="sorting-algotithms-collection">Sorting Algotithms Collection</h3>
<h4 id="quick-sort-快速排序">Quick Sort 快速排序</h4>
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">quick_sort</span><span class="p">(</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">nums</span><span class="p">,</span> <span class="kt">int</span> <span class="n">l</span><span class="p">,</span> <span class="kt">int</span> <span class="n">r</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">l</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">&gt;=</span> <span class="n">r</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">first</span> <span class="o">=</span> <span class="n">l</span><span class="p">,</span> <span class="n">last</span> <span class="o">=</span> <span class="n">r</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">key</span> <span class="o">=</span> <span class="n">nums</span><span class="p">[</span><span class="n">first</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">    <span class="k">while</span> <span class="p">(</span><span class="n">first</span> <span class="o">&lt;</span> <span class="n">last</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">while</span> <span class="p">(</span><span class="n">first</span> <span class="o">&lt;</span> <span class="n">last</span> <span class="o">&amp;&amp;</span> <span class="n">nums</span><span class="p">[</span><span class="n">last</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">key</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="o">--</span><span class="n">last</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="n">nums</span><span class="p">[</span><span class="n">first</span><span class="p">]</span> <span class="o">=</span> <span class="n">nums</span><span class="p">[</span><span class="n">last</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">        <span class="k">while</span> <span class="p">(</span><span class="n">first</span> <span class="o">&lt;</span> <span class="n">last</span> <span class="o">&amp;&amp;</span> <span class="n">nums</span><span class="p">[</span><span class="n">first</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">key</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="o">++</span><span class="n">first</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="n">nums</span><span class="p">[</span><span class="n">last</span><span class="p">]</span> <span class="o">=</span> <span class="n">nums</span><span class="p">[</span><span class="n">first</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="n">nums</span><span class="p">[</span><span class="n">first</span><span class="p">]</span> <span class="o">=</span> <span class="n">key</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">quick_sort</span><span class="p">(</span><span class="n">nums</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">first</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">quick_sort</span><span class="p">(</span><span class="n">nums</span><span class="p">,</span> <span class="n">first</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">r</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div><h4 id="merge-sort-归并排序">Merge Sort 归并排序</h4>
<div class="highlight" id="id-2"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">merge_sort</span><span class="p">(</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">nums</span><span class="p">,</span> <span class="kt">int</span> <span class="n">l</span><span class="p">,</span> <span class="kt">int</span> <span class="n">r</span><span class="p">,</span> <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">temp</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">l</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">&gt;=</span> <span class="n">r</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// divide
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">int</span> <span class="n">m</span> <span class="o">=</span> <span class="n">l</span> <span class="o">+</span> <span class="p">(</span><span class="n">r</span> <span class="o">-</span> <span class="n">l</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">merge_sort</span><span class="p">(</span><span class="n">nums</span><span class="p">,</span> <span class="n">l</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">temp</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">merge_sort</span><span class="p">(</span><span class="n">nums</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">temp</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1">// conquer
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="kt">int</span> <span class="n">p</span> <span class="o">=</span> <span class="n">l</span><span class="p">,</span> <span class="n">q</span> <span class="o">=</span> <span class="n">m</span><span class="p">,</span> <span class="n">i</span> <span class="o">=</span> <span class="n">l</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">while</span> <span class="p">(</span><span class="n">q</span> <span class="o">&lt;</span> <span class="n">m</span> <span class="o">||</span> <span class="n">q</span> <span class="o">&lt;</span> <span class="n">r</span><span class="o">&gt;</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">q</span> <span class="o">&gt;=</span> <span class="n">r</span> <span class="o">||</span> <span class="n">q</span> <span class="o">&lt;</span> <span class="n">r</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="p">(</span><span class="n">q</span> <span class="o">&gt;=</span> <span class="n">r</span> <span class="o">||</span> <span class="p">(</span><span class="n">p</span> <span class="o">&lt;</span> <span class="n">m</span> <span class="o">&amp;&amp;</span> <span class="n">nums</span><span class="p">[</span><span class="n">p</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">nums</span><span class="p">[</span><span class="n">q</span><span class="p">]))</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">                <span class="n">temp</span><span class="p">[</span><span class="n">i</span><span class="o">++</span><span class="p">]</span> <span class="o">=</span> <span class="n">nums</span><span class="p">[</span><span class="n">p</span><span class="o">++</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">            <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">                <span class="n">temp</span><span class="p">[</span><span class="n">i</span><span class="o">++</span><span class="p">]</span> <span class="o">=</span> <span class="n">nums</span><span class="p">[</span><span class="n">q</span><span class="o">++</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">            <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">l</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">r</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">nums</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">temp</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div><h4 id="insertion-sort-插入排序">Insertion Sort 插入排序</h4>
<div class="highlight" id="id-3"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">insertion_sort</span><span class="p">(</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">nums</span><span class="p">,</span> <span class="kt">int</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="n">i</span><span class="p">;</span> <span class="n">j</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="o">&amp;&amp;</span> <span class="n">nums</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">nums</span><span class="p">[</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">];</span> <span class="o">--</span><span class="n">j</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">swap</span><span class="p">(</span><span class="n">nums</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">nums</span><span class="p">[</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div><h4 id="bubble-sort-冒泡排序">Bubble Sort 冒泡排序</h4>
<div class="highlight" id="id-4"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">bubble_sort</span><span class="p">(</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">nums</span><span class="p">,</span> <span class="kt">int</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">bool</span> <span class="n">swapped</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">swapped</span> <span class="o">=</span> <span class="nb">false</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">n</span> <span class="o">-</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span> <span class="o">++</span><span class="n">j</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="p">(</span><span class="n">nums</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">nums</span><span class="p">[</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">                <span class="n">swap</span><span class="p">(</span><span class="n">nums</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">nums</span><span class="p">[</span><span class="n">j</span><span class="o">-</span><span class="mi">1</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl">                <span class="n">swapped</span> <span class="o">=</span> <span class="nb">true</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">            <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="o">!</span><span class="n">swapped</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="k">break</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div><h4 id="selection-sort-选择排序">Selection Sort 选择排序</h4>
<div class="highlight" id="id-5"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">selection_sort</span><span class="p">(</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">nums</span><span class="p">,</span> <span class="kt">int</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">mid</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="n">mid</span> <span class="o">=</span> <span class="n">i</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="o">++</span><span class="n">j</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">mid</span> <span class="o">=</span> <span class="n">j</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="n">swap</span><span class="p">(</span><span class="n">nums</span><span class="p">[</span><span class="n">mid</span><span class="p">],</span> <span class="n">nums</span><span class="p">[</span><span class="n">i</span><span class="p">]);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div>]]></description></item><item><title>KnapSack Problem 背包问题</title><link>https://jianye0428.github.io/posts/knapsack/</link><pubDate>Sun, 16 Jul 2023 13:42:09 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/knapsack/</guid><description><![CDATA[<h3 id="knapsack-背包问题">KnapSack 背包问题</h3>
<h4 id="definiton-定义">Definiton 定义</h4>
<p><u>背包问题</u>是一种组合优化的NP完全问题:有N个物品和容量为W的背包，每个物品都有自己的体积w和价值v，求拿哪些物品可以使得背包所装下的物品的总价值最大。如果限定每种物品只能选择0个或者1个，则称问题为<u>0-1背包问题</u>;如果不限定每种物品的数量，则问题称为<u>无界背包问题和或者完全背包问题</u>。</p>
<h4 id="0-1-背包问题">0-1 背包问题</h4>
<p>以 0-1 背包问题为例。我们可以定义一个二维数组 <code>dp</code> 存储最大价值，其中<u> <code>dp[i][j]</code> 表示前 <code>i</code> 件物品体积不超过 <code>j</code> 的情况下能达到的最大价值</u>。在我们遍历到第 <code>i</code> 件物品时，在当前背包总容量为 <code>j</code> 的情况下，如果我们不将物品 <code>i</code> 放入背包，那么 <code>dp[i][j] = dp[i-1][j]</code>，即前 <code>i</code> 个物品的最大价值等于只取前 <code>i-1</code> 个物品时的最大价值；如果我们将物品 <code>i</code> 放入背包，假设第 <code>i</code> 件物品体积为 <code>w</code>，价值为 <code>v</code>，那么我们得到 <code>dp[i][j] = dp[i-1][j-w] + v</code>。我们只需在遍历过程中对这两种情况取最大值即可，总时间复杂度和空间复杂度都为 <code>O(NW)</code>。</p>
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">int</span> <span class="nf">knapsack</span><span class="p">(</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">weights</span><span class="p">,</span> <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="kt">int</span> <span class="n">N</span><span class="p">,</span> <span class="kt">int</span> <span class="n">W</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">vector</span><span class="o">&lt;</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&gt;</span> <span class="n">dp</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="p">(</span><span class="n">W</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;=</span><span class="n">N</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="kt">int</span> <span class="n">w</span> <span class="o">=</span> <span class="n">weight</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">v</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;=</span> <span class="n">W</span><span class="p">;</span> <span class="o">++</span><span class="n">j</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="p">(</span><span class="n">j</span> <span class="o">&gt;=</span> <span class="n">w</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">                <span class="n">dp</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">max</span><span class="p">(</span><span class="n">dp</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="n">j</span><span class="p">],</span> <span class="n">dp</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="n">j</span><span class="o">-</span><span class="n">w</span><span class="p">]</span> <span class="o">+</span> <span class="n">v</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">                <span class="n">dp</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">dp</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="n">j</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">            <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">dp</span><span class="p">[</span><span class="n">N</span><span class="p">][</span><span class="n">W</span><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div><p><strong>空间压缩:</strong></p>
<div class="highlight" id="id-2"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">int</span> <span class="nf">knapsack</span><span class="p">(</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">weights</span><span class="p">,</span> <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="kt">int</span> <span class="n">N</span><span class="p">,</span> <span class="kt">int</span> <span class="n">W</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">dp</span><span class="p">(</span><span class="n">W</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">N</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="kt">int</span> <span class="n">w</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">v</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="p">(</span><span class="n">j</span> <span class="o">=</span> <span class="n">W</span><span class="p">;</span> <span class="n">j</span> <span class="o">&gt;=</span> <span class="n">w</span><span class="p">;</span> <span class="o">++</span><span class="n">j</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">dp</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">max</span><span class="p">(</span><span class="n">dp</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">dp</span><span class="p">[</span><span class="n">j</span><span class="o">-</span><span class="n">w</span><span class="p">]</span> <span class="o">+</span> <span class="n">v</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">dp</span><span class="p">[</span><span class="n">W</span><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div><h4 id="完全背包问题">完全背包问题</h4>
<p><u>完全背包问题</u>中，一个物品可以拿多次。对于拿多个物品的情况，我们只需考虑 <code>dp[2][3]</code> 即可，即 <code>dp[2][5] = max(dp[1][5], dp[2][3] + 3)</code>。这样，我们
就得到了完全背包问题的状态转移方程：<code>dp[i][j] = max(dp[i-1][j], dp[i][j-w] + v)</code>，其与 <code>0-1背包问题</code>的差别仅仅是把状态转移方程中的第二个 <code>i-1</code> 变成了 <code>i</code>。</p>
<div class="highlight" id="id-3"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">int</span> <span class="nf">knapsack</span><span class="p">(</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">weights</span><span class="p">,</span> <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="kt">int</span> <span class="n">N</span><span class="p">,</span> <span class="kt">int</span> <span class="n">W</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">vector</span><span class="o">&lt;</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&gt;</span> <span class="n">dp</span><span class="p">(</span><span class="n">N</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span><span class="p">(</span><span class="n">W</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">));</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">N</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="kt">int</span> <span class="n">w</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">v</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;=</span> <span class="n">W</span><span class="p">;</span> <span class="o">++</span><span class="n">j</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="p">(</span><span class="n">j</span> <span class="o">&gt;=</span> <span class="n">w</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">                <span class="n">dp</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">max</span><span class="p">(</span><span class="n">dp</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="n">j</span><span class="p">],</span> <span class="n">dp</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="o">-</span><span class="n">w</span><span class="p">]</span> <span class="o">+</span> <span class="n">v</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">            <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">                <span class="n">dp</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">dp</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="n">j</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">            <span class="p">}</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">dp</span><span class="p">[</span><span class="n">N</span><span class="p">][</span><span class="n">W</span><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div><p><strong>空间压缩:</strong></p>
<div class="highlight" id="id-4"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c++" data-lang="c++"><span class="line"><span class="cl"><span class="kt">int</span> <span class="nf">knapsack</span><span class="p">(</span><span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">weights</span><span class="p">,</span> <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;&amp;</span> <span class="n">values</span><span class="p">,</span> <span class="kt">int</span> <span class="n">N</span><span class="p">,</span> <span class="kt">int</span> <span class="n">W</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="n">vector</span><span class="o">&lt;</span><span class="kt">int</span><span class="o">&gt;</span> <span class="n">dp</span><span class="p">(</span><span class="n">W</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">N</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="kt">int</span> <span class="n">w</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">v</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">];</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="n">w</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;=</span> <span class="n">W</span><span class="p">;</span> <span class="o">++</span><span class="n">j</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">            <span class="n">dp</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">max</span><span class="p">(</span><span class="n">dp</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">dp</span><span class="p">[</span><span class="n">j</span><span class="o">-</span><span class="n">w</span><span class="p">]</span> <span class="o">+</span> <span class="n">v</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">dp</span><span class="p">[</span><span class="n">W</span><span class="p">];</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span></span></span></code></pre></td></tr></table>
</div>
</div><p>ref:</br>
<code>dp:</code> <a href="https://juejin.cn/post/6844903993429196813"target="_blank" rel="external nofollow noopener noreferrer">https://juejin.cn/post/6844903993429196813<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
<code>knapsack problem:</code> <a href="https://blog.csdn.net/qq_38410730/article/details/81667885"target="_blank" rel="external nofollow noopener noreferrer">https://blog.csdn.net/qq_38410730/article/details/81667885<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
<code>完全背包问题:</code> <a href="https://www.cnblogs.com/darkerg/p/15464987.html"target="_blank" rel="external nofollow noopener noreferrer">https://www.cnblogs.com/darkerg/p/15464987.html<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br></p>
]]></description></item><item><title>Pandas Notes 1</title><link>https://jianye0428.github.io/posts/pandasnotes1/</link><pubDate>Sat, 15 Jul 2023 19:09:21 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/pandasnotes1/</guid><description><![CDATA[<h1 id="pandas-notes">Pandas Notes</h1>
<h2 id="inputoutput">Input/Output</h2>
<ol>
<li>
<p><strong><code>pd.read_csv(filepath)</code>: 读取csv文件</strong>
ref: <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html?highlight=read_csv"target="_blank" rel="external nofollow noopener noreferrer">https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html?highlight=read_csv<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</li>
<li>
<p><strong><code>pd.read_pickle()</code>:读取pickle数据</strong></p>
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pandas</span>
</span></span><span class="line"><span class="cl"><span class="n">pandas</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="n">filepath_or_buffer</span><span class="p">,</span> <span class="n">compression</span><span class="o">=</span><span class="s1">&#39;infer&#39;</span><span class="p">,</span> <span class="n">storage_options</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div><p>ref: <a href="https://pandas.pydata.org/docs/reference/api/pandas.read_pickle.html"target="_blank" rel="external nofollow noopener noreferrer">https://pandas.pydata.org/docs/reference/api/pandas.read_pickle.html<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
Parameters:</p>
<ul>
<li><strong><code>filepath_or_buffer:</code></strong> 文件名或者文件路径
字符串、路径对象(实现 os.PathLike[str] )或 file-like 对象实现二进制 readlines() 函数。</li>
<li><strong><code>compression:</code></strong> <code>str or dict, default ‘infer’</code>
用于on-disk 数据的即时解压缩。如果 ‘infer’ 和 ‘filepath_or_buffer’ 是 path-like，则从以下扩展名检测压缩：“.gz”、“.bz2”、“.zip”、“.xz”或“.zst”(否则不压缩)。如果使用‘zip’，ZIP 文件必须只包含一个要读入的数据文件。设置为None 不解压缩。也可以是键 &lsquo;method&rsquo; 设置为 {<code>'zip'</code> , <code>'gzip'</code> , <code>'bz2'</code> , <code>'zstd'</code> } 之一的字典，其他键值对分别转发到 zipfile.ZipFile , gzip.GzipFile , bz2.BZ2File 或 zstandard.ZstdDecompressor 。例如，可以使用自定义压缩字典为 Zstandard 解压缩传递以下内容：<u>compression={&lsquo;method&rsquo;: &lsquo;zstd&rsquo;, &lsquo;dict_data&rsquo;: my_compression_dict}</u>。</li>
<li><strong><code>storage_options:</code></strong> <code>dict, optional</code>
对特定存储连接有意义的额外选项，例如主机、端口、用户名、密码等。对于 HTTP(S) URL，键值对作为标头选项转发到 urllib。对于其他 URL(例如以 “s3://” 和 “gcs://” 开头)，键值对被转发到fsspec 。有关详细信息，请参阅fsspec和urllib。</li>
</ul>
</li>
</ol>
<h2 id="general-functions-通用函数">General functions 通用函数</h2>
<h2 id="series">Series</h2>
<h2 id="dataframe">DataFrame</h2>
<p>DataFrame是一个【表格型】的数据结构，可以看做是【由Series组成的字典】（共用同一个索引）。DataFrame由按一定顺序排列的多列数据组成。设计初衷是将Series的使用场景从一维拓展到多维。</p>
<h3 id="constructor">Constructor</h3>
<ol>
<li><strong><code>DataFrame[data, index, columns, dtype, copy]</code>: 构造一个DataFrame对象</strong></li>
</ol>
<h3 id="attributes-and-underlying-data">Attributes and underlying data</h3>
<ol>
<li><strong><code>DataFrame.index</code>: 行标签(行信息)-&gt;第0列的信息</strong></li>
<li><strong><code>DataFrame.columns</code>: 列标签(列信息)-&gt; 第0行的信息</strong></li>
<li><strong><code>DataFrame.dtypes</code>: 返回DataFrame的数据类型</strong></li>
<li><strong><code>DataFrame.info([verbose, buf, max_cols, ...])</code>: 返回df的信息</strong></li>
<li><strong><code>DataFrame.select_dtypes([include, exclude])</code>: 返回DataFrame中根据columns筛选的部分数据</strong></li>
<li><strong><code>DataFrame.values</code>: 以numpy数组的形式返回数据</strong></li>
<li><strong><code>DataFrame.axes</code>: 返回一个list，其中是df的axes</strong></li>
<li><strong><code>DataFrame.ndim</code>: 返回int，代表axes/array的数量</strong></li>
<li><strong><code>DataFrame.shape</code>: 返回tuple, 代表df维度</strong></li>
<li><strong><code>DataFrame.memory_usage([index, deep])</code>: 返回数据内存使用情况</strong></li>
<li><strong><code>DataFrame.empty</code>: 判断df是否为空</strong></li>
<li><strong><code>DataFrame.set_flags(*[, copy, ...])</code>: 返回带有更新标记的df</strong>
DataFrame.set_flags(*, copy=False, allows_duplicate_labels=None)
<ul>
<li>参数：<code>allows_duplicate_labels</code>：布尔型，可选。返回的对象是否允许重复标签。</li>
<li>返回：Series或DataFrame, 与调用者相同的类型。</li>
<li>注意：此方法返回一个新对象，该对象是与输入数据相同的视图。改变输入或输出值将反映在另一个中。此方法旨在用于方法链中。“Flags” 与 “metadata” 不同。标志反映了 pandas 对象(Series 或 DataFrame)的属性。元数据是 index 据集的属性，应存储在 DataFrame.attrs 中。</li>
<li>demo:
<div class="highlight" id="id-2"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="o">&gt;&gt;&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s2">&#34;A&#34;</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]})</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;&gt;&gt;</span> <span class="n">df</span><span class="o">.</span><span class="n">flags</span><span class="o">.</span><span class="n">allows_duplicate_labels</span>
</span></span><span class="line"><span class="cl"><span class="kc">True</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;&gt;&gt;</span> <span class="n">df2</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">set_flags</span><span class="p">(</span><span class="n">allows_duplicate_labels</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;&gt;&gt;</span> <span class="n">df2</span><span class="o">.</span><span class="n">flags</span><span class="o">.</span><span class="n">allows_duplicate_labels</span>
</span></span><span class="line"><span class="cl"><span class="kc">False</span></span></span></code></pre></td></tr></table>
</div>
</div></li>
</ul>
</li>
<li><strong><code>DataFrame.groupby()</code>:</strong></li>
</ol>
<h3 id="conversion">Conversion</h3>
<ol>
<li><strong><code>DataFrame.astype(dtype[,copy, errors])</code>:数据类型转换</strong></li>
<li><strong><code>DataFrame.convert_dtypes([infer_objects, ...])</code>:根据现存数据推断pd.NA数据类型</strong></li>
<li><strong><code>DataFrame.infer_objects()</code>:根据现有数据大部分数据推断类型</strong></li>
<li><strong><code>DataFrame.copy([deep])</code>:深度拷贝</strong>
<ul>
<li>demo</li>
</ul>
<div class="highlight" id="id-3"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">s</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s2">&#34;a&#34;</span><span class="p">,</span><span class="s2">&#34;b&#34;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">deep</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="c1"># 深拷贝</span>
</span></span><span class="line"><span class="cl"><span class="n">shallow</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="c1"># 浅拷贝</span></span></span></code></pre></td></tr></table>
</div>
</div></li>
<li><strong><code>DataFrame.bool()</code>:判断数据是ture还是false，只针对单个元素对象</strong></li>
</ol>
<h3 id="indexingiteration">Indexing，iteration</h3>
<ol>
<li><strong><code>DataFrame.head([n])</code>: return the first n rows</strong></li>
<li><strong><code>DataFrame.at[4,'B']</code>: 用标签取值(行名为4，列名为B的值)</strong></li>
<li><strong><code>DataFrame.iat[1,2]</code>: 用行列的整数取值(第1行,第二列的值)</strong></li>
<li><strong><code>DataFrame.loc['cobra':'viper', 'max_speed']</code>: 取行名为&rsquo;cobra&rsquo;至&rsquo;viper&rsquo;, 列名为&rsquo;max_speed&rsquo;的值</strong></li>
<li><strong><code>DataFrame.iloc</code>: 通过行列的值取值</strong>
<ul>
<li><code>df.iloc[0]:取第0行，所有列的值，返回series类型</code></li>
<li><code>df.iloc[[0]]:取得第0行，所有列的值，返回df类型</code></li>
<li><code>df.iloc[[0,1]]:取得第0行和第1行的所有列的值</code></li>
<li><code>df.iloc[:3]:取得第0，1，2行的值</code></li>
<li><code>df.iloc[[True, False, True]]: 用True/False标记要取的行</code></li>
<li><code>df.iloc[lambda x:x.index % 2 == 0]: 用lambda标记要取的行</code></li>
<li><code>df.iloc[0,1]:取得第0行，第1列的值</code></li>
<li><code>df.iloc[[0,2],[1,3]]: 取得第0行，第2行，第1列，第3列的值</code></li>
<li><code>df.iloc[1:3, 0:3]: 取得第1行，第2行，第0列，第1列，第2列的值</code></li>
<li><code>df.iloc[:, [True,False,True,False]]:取所有的行，用True/False取相应的列</code></li>
<li><code>df.iloc[:,lambda df:[0,2]]: 取所有的行，取第0列，第2列</code></li>
</ul>
</li>
<li><strong><code>df.insert(loc, column, value, allow_duplicates=False):插入相应的列</code></strong>
<ul>
<li>loc:(int), 列的位置</li>
<li>column: 列的名字，一般类型为string</li>
<li>value: 列数据的值</li>
</ul>
</li>
<li><strong><code>df.drop()</code>:删除固定的行或者列</strong></li>
<li><strong><code>df.drop_duplicates(subset, keep, inplace=False,ignore_index=False):删除重复的行或者列</code></strong>
<ul>
<li>
<div class="highlight" id="id-4"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"></code></pre></td></tr></table>
</div>
</div></li>
<li><code>subset: 根据某一列的值，删除行数据</code></li>
<li><code>keep: 设置保留第一次出现的数据或者最后一次出现的数据</code></li>
</ul>
</li>
<li></li>
<li></li>
</ol>
<h2 id="heading"></h2>
]]></description></item><item><title>Python Notes 1</title><link>https://jianye0428.github.io/posts/pythonnotes1/</link><pubDate>Sat, 15 Jul 2023 19:09:09 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/pythonnotes1/</guid><description><![CDATA[<h2 id="python文件相关">python文件相关</h2>
<h3 id="ospath模块">os.path模块</h3>
<ol>
<li>
<p><strong><code>os.path.exists()</code>: 判断当前目录以及文件是否存在</strong>
<strong><code>os.path.mkdir()</code>:  若目录或文件不存在，则创建</strong></p>
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">os</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 目录</span>
</span></span><span class="line"><span class="cl"><span class="n">dirs</span> <span class="o">=</span> <span class="s1">&#39;/Users/joseph/work/python/&#39;</span>
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">dirs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">dirs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 文件</span>
</span></span><span class="line"><span class="cl"><span class="n">filename</span> <span class="o">=</span> <span class="s1">&#39;/Users/joseph/work/python/poem.txt&#39;</span>
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">filename</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="sa">r</span><span class="s2">&#34;touch </span><span class="si">{}</span><span class="s2">&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">path</span><span class="p">))</span><span class="c1">#调用系统命令行来创建文件</span></span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p><strong><code>os.listdir()</code>： 用于返回指定的文件夹包含的文件或文件夹的名字的列表</strong></p>
<div class="highlight" id="id-2"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 打开文件</span>
</span></span><span class="line"><span class="cl"><span class="n">path</span> <span class="o">=</span> <span class="s2">&#34;/var/www/html/&#34;</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 如果目录名字为中文 需要转码处理</span>
</span></span><span class="line"><span class="cl"><span class="n">path</span> <span class="o">=</span> <span class="n">unicode</span><span class="p">(</span><span class="n">path</span><span class="p">,</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">dirs</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 输出所有文件和文件夹</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">dirs</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="n">file</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p><strong><code>os.path.join()</code>: 路径拼接</strong></p>
<div class="highlight" id="id-3"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl">import os
</span></span><span class="line"><span class="cl"><span class="nv">path</span> <span class="o">=</span> <span class="s2">&#34;/home&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Join various path components</span>
</span></span><span class="line"><span class="cl">print<span class="o">(</span>os.path.join<span class="o">(</span>path, <span class="s2">&#34;User/Desktop&#34;</span>, <span class="s2">&#34;file.txt&#34;</span><span class="o">))</span>
</span></span><span class="line"><span class="cl"><span class="c1"># /home/User/Desktop/file.txt</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nv">path</span> <span class="o">=</span> <span class="s2">&#34;User/Documents&#34;</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Join various path components</span>
</span></span><span class="line"><span class="cl">print<span class="o">(</span>os.path.join<span class="o">(</span>path, <span class="s2">&#34;/home&#34;</span>, <span class="s2">&#34;file.txt&#34;</span><span class="o">))</span>
</span></span><span class="line"><span class="cl"><span class="c1"># /home/file.txt</span>
</span></span><span class="line"><span class="cl"><span class="c1"># In above example &#39;/home&#39;</span>
</span></span><span class="line"><span class="cl"><span class="c1"># represents an absolute path</span>
</span></span><span class="line"><span class="cl"><span class="c1"># so all previous components i.e User / Documents</span>
</span></span><span class="line"><span class="cl"><span class="c1"># are thrown away and joining continues</span>
</span></span><span class="line"><span class="cl"><span class="c1"># from the absolute path component i.e / home.</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">print<span class="o">(</span>os.path.join<span class="o">(</span>path, <span class="s2">&#34;Downloads&#34;</span>, <span class="s2">&#34;file.txt&#34;</span>, <span class="s2">&#34;/home&#34;</span><span class="o">))</span>
</span></span><span class="line"><span class="cl"><span class="c1"># /home</span>
</span></span><span class="line"><span class="cl"><span class="c1"># In above example &#39;/User&#39; and &#39;/home&#39;</span>
</span></span><span class="line"><span class="cl"><span class="c1"># both represents an absolute path</span>
</span></span><span class="line"><span class="cl"><span class="c1"># but &#39;/home&#39; is the last value</span>
</span></span><span class="line"><span class="cl"><span class="c1"># so all previous components before &#39;/home&#39;</span>
</span></span><span class="line"><span class="cl"><span class="c1"># will be discarded and joining will</span>
</span></span><span class="line"><span class="cl"><span class="c1"># continue from &#39;/home&#39;</span></span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p><strong><code>os.path.abspath(path)</code>: 返回绝对路径</strong></p>
</li>
<li>
<p><strong><code>os.path.basename(path)</code>: 返回文件名</strong></p>
</li>
<li>
<p><strong><code>os.path.commonprefix(list)</code>: 返回list(多个路径)中，所有path共有的最长的路径</strong></p>
</li>
<li>
<p><strong><code>os.path.dirname(path)</code>: 返回文件路径</strong></p>
</li>
<li>
<p><strong><code>os.path.expanduser(path)</code>: 把path中包含的&quot;~&ldquo;和&rdquo;~user&quot;转换成用户目录</strong></p>
</li>
<li>
<p><strong><code>os.path.expandvars(path)</code>: 根据环境变量的值替换path中包含的 &ldquo;$name&rdquo; 和 &ldquo;${name}&rdquo;</strong></p>
</li>
<li>
<p><strong><code>os.path.getatime(path)</code>: 返回最近访问时间(浮点型秒数)</strong></p>
</li>
<li>
<p><strong><code>os.path.getmtime(path)</code>: 返回最近文件修改时间</strong></p>
</li>
<li>
<p><strong><code>os.path.getctime(path)</code>: 返回文件 path 创建时间</strong></p>
</li>
<li>
<p><strong><code>os.path.getsize(path)</code>: 返回文件大小，如果文件不存在就返回错误</strong></p>
</li>
<li>
<p><strong><code>os.path.isfile(path)</code>: 判断路径是否为文件</strong></p>
</li>
<li>
<p><strong><code>os.path.isdir(path)</code>: 判断路径是否为目录</strong></p>
</li>
<li>
<p><strong><code>os.path.islink(path)</code>: 判断路径是否为链接</strong></p>
</li>
<li>
<p><strong><code>os.path.ismount(path)</code>: 判断路径是否为挂载点</strong></p>
</li>
<li>
<p><strong><code>os.path.normcase(path)</code>: 转换path的大小写和斜杠</strong></p>
</li>
<li>
<p><strong><code>os.path.normpath(path)</code>: 规范path字符串形式</strong></p>
</li>
<li>
<p><strong><code>os.path.realpath(path)</code>: 返回path的真实路径</strong></p>
</li>
<li>
<p><strong><code>os.path.relpath(path[, start])</code>: 从start开始计算相对路径</strong></p>
</li>
<li>
<p><strong><code>os.path.samefile(path1, path2)</code>: 判断目录或文件是否相同</strong></p>
</li>
<li>
<p><strong><code>os.path.sameopenfile(fp1, fp2)</code>: 判断fp1和fp2是否指向同一文件</strong></p>
</li>
<li>
<p><strong><code>os.path.samestat(stat1, stat2)</code>: 判断stat tuple stat1和stat2是否指向同一个文件</strong></p>
</li>
<li>
<p><strong><code>os.path.split(path)</code>: 把路径分割成 dirname 和 basename，返回一个元组</strong></p>
</li>
<li>
<p><strong><code>os.path.splitdrive(path)</code>: 一般用在 windows 下，返回驱动器名和路径组成的元组</strong></p>
</li>
<li>
<p><strong><code>os.path.splitext(path)</code>: 分割路径，返回路径名和文件扩展名的元组</strong></p>
</li>
<li>
<p><strong><code>os.path.splitunc(path)</code>: 把路径分割为加载点与文件</strong></p>
</li>
<li>
<p><strong><code>os.path.walk(path, visit, arg)</code>: 遍历path，进入每个目录都调用visit函数，visit函数必须有3个参数(arg, dirname, names)，dirname表示当前目录的目录名，names代表当前目录下的所有文件名，args则为walk的第三个参数</strong>
<strong><code>os.walk(path,topdown=True,onerror=None)</code>: 函数返回一个元组，含有三个元素。这三个元素分别是：每次遍历的路径名、路径下子目录列表、目录下文件列表。</strong></p>
<div class="highlight" id="id-4"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;xxx/xxx&#39;</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">root</span><span class="p">,</span> <span class="n">dirs</span><span class="p">,</span> <span class="n">files</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">walk</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="n">root</span><span class="p">)</span> <span class="c1"># path以及path下的目录</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="n">dirs</span><span class="p">)</span> <span class="c1"># path下的文件夹</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="n">files</span><span class="p">)</span> <span class="c1"># path下每个文件夹中的文件</span></span></span></code></pre></td></tr></table>
</div>
</div><blockquote>
<p>区别：<code>os.path.walk()</code>与<code>os.walk()</code>产生的文件名列表并不相同.os.walk()产生目录树下的目录路径和文件路径，而os.path.walk()只产生文件路径（是子目录与文件的混合列表）。
ref: <a href="https://www.cnblogs.com/zmlctt/p/4222621.html"target="_blank" rel="external nofollow noopener noreferrer">https://www.cnblogs.com/zmlctt/p/4222621.html<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</blockquote>
</li>
<li>
<p><strong><code>os.path.supports_unicode_filenames</code>: 设置是否支持unicode路径名</strong></p>
</li>
</ol>
]]></description></item><item><title>PyTorch Dataset And DataLoader</title><link>https://jianye0428.github.io/posts/datasetanddataloader/</link><pubDate>Sat, 15 Jul 2023 18:16:08 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/datasetanddataloader/</guid><description><![CDATA[<p>ref: </br>
[1] <a href="https://chenllliang.github.io/2020/02/04/dataloader/"target="_blank" rel="external nofollow noopener noreferrer">https://chenllliang.github.io/2020/02/04/dataloader/<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[2] <a href="https://blog.csdn.net/zyq12345678/article/details/90268668"target="_blank" rel="external nofollow noopener noreferrer">https://blog.csdn.net/zyq12345678/article/details/90268668<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
[3] <a href="https://cloud.tencent.com/developer/article/1877393"target="_blank" rel="external nofollow noopener noreferrer">https://cloud.tencent.com/developer/article/1877393<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></br>
</br></p>
<h2 id="dataset">Dataset</h2>
<p>PyTorch为我们提供的两个<code>Dataset</code>和<code>DataLoader</code>类分别负责可被Pytorch使用的数据集的创建以及向训练传递数据的任务。如果想个性化自己的数据集或者数据传递方式，也可以自己重写子类。</p>
<p>Dataset是DataLoader实例化的一个参数，所以这篇文章会先从Dataset的源代码讲起，然后讲到DataLoader，关注主要函数，少细枝末节，目的是使大家学会自定义自己的数据集。</p>
<h3 id="什么时候使用dataset">什么时候使用Dataset</h3>
<p>CIFAR10是CV训练中经常使用到的一个数据集，在PyTorch中CIFAR10是一个写好的Dataset，我们使用时只需以下代码：</p>
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="s2">&#34;./data/&#34;</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div><p>datasets.CIFAR10就是一个Datasets子类，data是这个类的一个实例。</p>
<p>我们有的时候需要用自己在一个文件夹中的数据作为数据集，这个时候，我们可以使用ImageFolder这个方便的API。</p>
<div class="highlight" id="id-2"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">FaceDataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">img_transform</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div><h3 id="如何定义一个自己的数据集合">如何定义一个自己的数据集合</h3>
<p><code>torch.utils.data.dataset</code> 是一个表示数据集的抽象类。任何自定义的数据集都需要继承这个类并覆写相关方法。</p>
<p>所谓数据集，其实就是一个负责处理索引(index)到样本(sample)映射的一个类(class)。</p>
<p>Pytorch提供两种数据集：</p>
<ul>
<li>Map式数据集</li>
<li>Iterable式数据集</li>
</ul>
<h4 id="map式数据集">Map式数据集</h4>
<p>一个Map式的数据集必须要重写<code>__getitem__(self, index)</code>, <code>len(self)</code> 两个内建方法，用来表示从索引到样本的映射(Map).</p>
<p>这样一个数据集dataset，举个例子，当使用dataset[idx]命令时，可以在你的硬盘中读取你的数据集中第idx张图片以及其标签（如果有的话）;len(dataset)则会返回这个数据集的容量。</p>
<p>例子-1： 自己实验中写的一个例子：这里我们的图片文件储存在“./data/faces/”文件夹下，图片的名字并不是从1开始，而是从final_train_tag_dict.txt这个文件保存的字典中读取，label信息也是用这个文件中读取。大家可以照着上面的注释阅读这段代码。</p>
<div class="highlight" id="id-3"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.utils</span> <span class="kn">import</span> <span class="n">data</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">face_dataset</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">	<span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">		<span class="bp">self</span><span class="o">.</span><span class="n">file_path</span> <span class="o">=</span> <span class="s1">&#39;./data/faces/&#39;</span>
</span></span><span class="line"><span class="cl">		<span class="n">f</span><span class="o">=</span><span class="nb">open</span><span class="p">(</span><span class="s2">&#34;final_train_tag_dict.txt&#34;</span><span class="p">,</span><span class="s2">&#34;r&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">		<span class="bp">self</span><span class="o">.</span><span class="n">label_dict</span><span class="o">=</span><span class="nb">eval</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">		<span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">index</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">		<span class="n">label</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_dict</span><span class="o">.</span><span class="n">values</span><span class="p">())[</span><span class="n">index</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">		<span class="n">img_id</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="n">index</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">		<span class="n">img_path</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">file_path</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">img_id</span><span class="p">)</span><span class="o">+</span><span class="s2">&#34;.jpg&#34;</span>
</span></span><span class="line"><span class="cl">		<span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">img_path</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">		<span class="k">return</span> <span class="n">img</span><span class="p">,</span><span class="n">label</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">	<span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">		<span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">label_dict</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div><p>下面我们看一下官方MNIST数据集的例子</p>
<div class="highlight" id="id-4"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span><span class="lnt">118
</span><span class="lnt">119
</span><span class="lnt">120
</span><span class="lnt">121
</span><span class="lnt">122
</span><span class="lnt">123
</span><span class="lnt">124
</span><span class="lnt">125
</span><span class="lnt">126
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">MNIST</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;`MNIST &lt;http://yann.lecun.com/exdb/mnist/&gt;`_ Dataset. Args: root (string): Root directory of dataset where ``processed/training.pt`` and ``processed/test.pt`` exist. train (bool, optional): If True, creates dataset from ``training.pt``, otherwise from ``test.pt``. download (bool, optional): If true, downloads the dataset from the internet and puts it in root directory. If dataset is already downloaded, it is not downloaded again. transform (callable, optional): A function/transform that takes in an PIL image and returns a transformed version. E.g, ``transforms.RandomCrop`` target_transform (callable, optional): A function/transform that takes in the target and transforms it. &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">urls</span> <span class="o">=</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">        <span class="s1">&#39;http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="s1">&#39;http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="s1">&#39;http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="s1">&#39;http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">raw_folder</span> <span class="o">=</span> <span class="s1">&#39;raw&#39;</span>
</span></span><span class="line"><span class="cl">    <span class="n">processed_folder</span> <span class="o">=</span> <span class="s1">&#39;processed&#39;</span>
</span></span><span class="line"><span class="cl">    <span class="n">training_file</span> <span class="o">=</span> <span class="s1">&#39;training.pt&#39;</span>
</span></span><span class="line"><span class="cl">    <span class="n">test_file</span> <span class="o">=</span> <span class="s1">&#39;test.pt&#39;</span>
</span></span><span class="line"><span class="cl">    <span class="n">classes</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;0 - zero&#39;</span><span class="p">,</span> <span class="s1">&#39;1 - one&#39;</span><span class="p">,</span> <span class="s1">&#39;2 - two&#39;</span><span class="p">,</span> <span class="s1">&#39;3 - three&#39;</span><span class="p">,</span> <span class="s1">&#39;4 - four&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">               <span class="s1">&#39;5 - five&#39;</span><span class="p">,</span> <span class="s1">&#39;6 - six&#39;</span><span class="p">,</span> <span class="s1">&#39;7 - seven&#39;</span><span class="p">,</span> <span class="s1">&#39;8 - eight&#39;</span><span class="p">,</span> <span class="s1">&#39;9 - nine&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">class_to_idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">_class</span><span class="p">:</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_class</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">classes</span><span class="p">)}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nd">@property</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">targets</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_labels</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_labels</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">root</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">target_transform</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">root</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="n">root</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">target_transform</span> <span class="o">=</span> <span class="n">target_transform</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="n">train</span>  <span class="c1"># training set or test set</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">download</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">download</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_exists</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;Dataset not found.&#39;</span> <span class="o">+</span>
</span></span><span class="line"><span class="cl">                               <span class="s1">&#39; You can use download=True to download it&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">processed_folder</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_file</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">test_data</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_labels</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">processed_folder</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_file</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;&#34;&#34; Args: index (int): Index Returns: tuple: (image, target) where target is index of the target class. &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">img</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_labels</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">img</span><span class="p">,</span> <span class="n">target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_data</span><span class="p">[</span><span class="n">index</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_labels</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># doing this so that it is consistent with all other datasets         # to return a PIL Image         img = Image.fromarray(img.numpy(), mode=&#39;L&#39;)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_transform</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">img</span><span class="p">,</span> <span class="n">target</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train_data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test_data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">_check_exists</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">processed_folder</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_file</span><span class="p">))</span> <span class="ow">and</span> \
</span></span><span class="line"><span class="cl">            <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">processed_folder</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_file</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">download</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;&#34;&#34;Download the MNIST data if it doesn&#39;t exist in processed_folder already.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="kn">from</span> <span class="nn">six.moves</span> <span class="kn">import</span> <span class="n">urllib</span>
</span></span><span class="line"><span class="cl">        <span class="kn">import</span> <span class="nn">gzip</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_exists</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># download files         try:</span>
</span></span><span class="line"><span class="cl">            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_folder</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">processed_folder</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="k">except</span> <span class="ne">OSError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">e</span><span class="o">.</span><span class="n">errno</span> <span class="o">==</span> <span class="n">errno</span><span class="o">.</span><span class="n">EEXIST</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">pass</span>
</span></span><span class="line"><span class="cl">            <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">raise</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">urls</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Downloading &#39;</span> <span class="o">+</span> <span class="n">url</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">data</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">filename</span> <span class="o">=</span> <span class="n">url</span><span class="o">.</span><span class="n">rpartition</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="mi">2</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_folder</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.gz&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">),</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">out_f</span><span class="p">,</span> \
</span></span><span class="line"><span class="cl">                    <span class="n">gzip</span><span class="o">.</span><span class="n">GzipFile</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span> <span class="k">as</span> <span class="n">zip_f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">out_f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">zip_f</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">            <span class="n">os</span><span class="o">.</span><span class="n">unlink</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># process and save as torch files         print(&#39;Processing...&#39;)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">training_set</span> <span class="o">=</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">read_image_file</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_folder</span><span class="p">,</span> <span class="s1">&#39;train-images-idx3-ubyte&#39;</span><span class="p">)),</span>
</span></span><span class="line"><span class="cl">            <span class="n">read_label_file</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_folder</span><span class="p">,</span> <span class="s1">&#39;train-labels-idx1-ubyte&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">test_set</span> <span class="o">=</span> <span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">read_image_file</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_folder</span><span class="p">,</span> <span class="s1">&#39;t10k-images-idx3-ubyte&#39;</span><span class="p">)),</span>
</span></span><span class="line"><span class="cl">            <span class="n">read_label_file</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">raw_folder</span><span class="p">,</span> <span class="s1">&#39;t10k-labels-idx1-ubyte&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">processed_folder</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_file</span><span class="p">),</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">training_set</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">processed_folder</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test_file</span><span class="p">),</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">test_set</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Done!&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">fmt_str</span> <span class="o">=</span> <span class="s1">&#39;Dataset &#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span>
</span></span><span class="line"><span class="cl">        <span class="n">fmt_str</span> <span class="o">+=</span> <span class="s1">&#39; Number of datapoints: </span><span class="si">{}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="fm">__len__</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">        <span class="n">tmp</span> <span class="o">=</span> <span class="s1">&#39;train&#39;</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="ow">is</span> <span class="kc">True</span> <span class="k">else</span> <span class="s1">&#39;test&#39;</span>
</span></span><span class="line"><span class="cl">        <span class="n">fmt_str</span> <span class="o">+=</span> <span class="s1">&#39; Split: </span><span class="si">{}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">fmt_str</span> <span class="o">+=</span> <span class="s1">&#39; Root Location: </span><span class="si">{}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">root</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">tmp</span> <span class="o">=</span> <span class="s1">&#39; Transforms (if any): &#39;</span>
</span></span><span class="line"><span class="cl">        <span class="n">fmt_str</span> <span class="o">+=</span> <span class="s1">&#39;</span><span class="si">{0}{1}</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tmp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="o">.</span><span class="fm">__repr__</span><span class="p">()</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39; &#39;</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">tmp</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">        <span class="n">tmp</span> <span class="o">=</span> <span class="s1">&#39; Target Transforms (if any): &#39;</span>
</span></span><span class="line"><span class="cl">        <span class="n">fmt_str</span> <span class="o">+=</span> <span class="s1">&#39;</span><span class="si">{0}{1}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tmp</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_transform</span><span class="o">.</span><span class="fm">__repr__</span><span class="p">()</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">+</span> <span class="s1">&#39; &#39;</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">tmp</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">fmt_str</span></span></span></code></pre></td></tr></table>
</div>
</div><h3 id="iterable数据集">Iterable数据集</h3>
<p>一个Iterable（迭代）式数据集是抽象类data.IterableDataset的子类，并且覆写了__iter__方法成为一个迭代器。这种数据集主要用于数据大小未知，或者以流的形式的输入，本地文件不固定的情况，需要以迭代的方式来获取样本索引。</p>
<p>关于迭代器与生成器的知识可以参见博主的另一篇文章Python迭代器与生成器介绍及在Pytorch源码中应用[https://chenllliang.github.io/2020/02/06/PyIter/]。</p>
<h2 id="dataloader">DataLoader</h2>
<blockquote>
<p>Data loader. Combines a dataset and a sampler, and provides an iterable over the given dataset. –PyTorch Documents</p>
</blockquote>
<p>一般来说PyTorch中深度学习训练的流程是这样的：</p>
<ol>
<li>创建Dateset</li>
<li>Dataset传递给DataLoader</li>
<li>DataLoader迭代产生训练数据提供给模型</li>
</ol>
<p>对应的一般都会有这三部分代码</p>
<div class="highlight" id="id-5"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 创建Dateset(可以自定义)</span>
</span></span><span class="line"><span class="cl"><span class="n">dataset</span> <span class="o">=</span> <span class="n">face_dataset</span> <span class="c1"># Dataset部分自定义过的face_dataset</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Dataset传递给DataLoader</span>
</span></span><span class="line"><span class="cl"><span class="n">dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span><span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># DataLoader迭代产生训练数据提供给模型</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epoch</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">index</span><span class="p">,(</span><span class="n">img</span><span class="p">,</span><span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">pass</span></span></span></code></pre></td></tr></table>
</div>
</div><p>到这里应该就PyTorch的数据集和数据传递机制应该就比较清晰明了了。Dataset负责建立索引到样本的映射，DataLoader负责以特定的方式从数据集中迭代的产生 一个个batch的样本集合。在enumerate过程中实际上是dataloader按照其参数sampler规定的策略调用了其dataset的getitem方法。</p>
<h2 id="参数介绍">参数介绍</h2>
<p>先看一下实例化一个DataLoader所需的参数，我们只关注几个重点即可。</p>
<div class="highlight" id="id-6"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">           <span class="n">batch_sampler</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">           <span class="n">pin_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">           <span class="n">worker_init_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div><p>参数介绍:</p>
<ul>
<li><code>dataset</code> (Dataset) – 定义好的Map式或者Iterable式数据集。</li>
<li><code>batch_size</code> (python:int, optional) – 一个batch含有多少样本 (default: 1)。</li>
<li><code>shuffle</code> (bool, optional) – 每一个epoch的batch样本是相同还是随机 (default: False)。</li>
<li><code>sampler</code> (Sampler, optional) – 决定数据集中采样的方法. 如果有，则shuffle参数必须为False。</li>
<li><code>batch_sampler</code> (Sampler, optional) – 和 sampler 类似，但是一次返回的是一个batch内所有样本的index。和 batch_size, shuffle, sampler, and drop_last 三个参数互斥。</li>
<li><code>num_workers</code> (python:int, optional) – 多少个子程序同时工作来获取数据，多线程。 (default: 0)</li>
<li><code>collate_fn</code> (callable, optional) – 合并样本列表以形成小批量。</li>
<li><code>pin_memory</code> (bool, optional) – 如果为True，数据加载器在返回前将张量复制到CUDA固定内存中。</li>
<li><code>drop_last</code> (bool, optional) – 如果数据集大小不能被batch_size整除，设置为True可删除最后一个不完整的批处理。如果设为False并且数据集的大小不能被batch_size整除，则最后一个batch将更小。(default: False)</li>
<li><code>timeout</code> (numeric, optional) – 如果是正数，表明等待从worker进程中收集一个batch等待的时间，若超出设定的时间还没有收集到，那就不收集这个内容了。这个numeric应总是大于等于0。 (default: 0)</li>
<li><code>worker_init_fn</code> (callable, optional) – 每个worker初始化函数 (default: None)</li>
</ul>
<p>dataset 没什么好说的，很重要，需要按照前面所说的两种dataset定义好，完成相关函数的重写。</p>
<p>batch_size 也没啥好说的，就是训练的一个批次的样本数。</p>
<p>shuffle 表示每一个epoch中训练样本的顺序是否相同，一般True。</p>
<h3 id="采样器">采样器</h3>
<p><code>sampler</code> 重点参数，采样器，是一个迭代器。PyTorch提供了多种采样器，用户也可以自定义采样器。</p>
<p>所有sampler都是继承 <code>torch.utils.data.sampler.Sampler</code>这个抽象类。</p>
<p>关于迭代器的基础知识在博主这篇文章中可以找到Python迭代器与生成器介绍及在Pytorch源码中应用。[]</p>
<div class="highlight" id="id-7"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Sampler</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># &#34;&#34;&#34;Base class for all Samplers.     # Every Sampler subclass has to provide an __iter__ method, providing a way     # to iterate over indices of dataset elements, and a __len__ method that     # returns the length of the returned iterators.     # &#34;&#34;&#34;     # 一个 迭代器 基类     def __init__(self, data_source):</span>
</span></span><span class="line"><span class="cl">        <span class="k">pass</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">raise</span> <span class="ne">NotImplementedError</span></span></span></code></pre></td></tr></table>
</div>
</div><h4 id="pytorch自带的sampler">PyTorch自带的Sampler</h4>
<ul>
<li>SequentialSampler</li>
<li>RandomSampler</li>
<li>SubsetRandomSampler</li>
<li>WeightedRandomSampler</li>
</ul>
<p><strong>SequentialSampler</strong> 很好理解就是顺序采样器。</p>
<p>其原理是首先在初始化的时候拿到数据集<code>data_source</code>，之后在<code>__iter__</code>方法中首先得到一个和data_source一样长度的<code>range</code>可迭代器。每次只会返回一个索引值。</p>
<div class="highlight" id="id-8"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span><span class="lnt">9
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">SequentialSampler</span><span class="p">(</span><span class="n">Sampler</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># r&#34;&#34;&#34;Samples elements sequentially, always in the same order.     # Arguments:     # data_source (Dataset): dataset to sample from     # &#34;&#34;&#34;    # 产生顺序 迭代器     def __init__(self, data_source):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">data_source</span> <span class="o">=</span> <span class="n">data_source</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_source</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_source</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div><p>参数作用:</p>
<ul>
<li><code>data_source</code>: 同上</li>
<li><code>num_sampler</code>: 指定采样的数量，默认是所有。</li>
<li><code>replacement</code>: 若为True，则表示可以重复采样，即同一个样本可以重复采样，这样可能导致有的样本采样不到。所以此时我们可以设置num_samples来增加采样数量使得每个样本都可能被采样到。</li>
</ul>
<div class="highlight" id="id-9"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">RandomSampler</span><span class="p">(</span><span class="n">Sampler</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># r&#34;&#34;&#34;Samples elements randomly. If without replacement, then sample from a shuffled dataset.     # If with replacement, then user can specify ``num_samples`` to draw.     # Arguments:     # data_source (Dataset): dataset to sample from     # num_samples (int): number of samples to draw, default=len(dataset)     # replacement (bool): samples are drawn with replacement if ``True``, default=False     # &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_source</span><span class="p">,</span> <span class="n">replacement</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">data_source</span> <span class="o">=</span> <span class="n">data_source</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">replacement</span> <span class="o">=</span> <span class="n">replacement</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="o">=</span> <span class="n">num_samples</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">replacement</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&#34;With replacement=False, num_samples should not be specified, &#34;</span>
</span></span><span class="line"><span class="cl">                             <span class="s2">&#34;since a random permute will be performed.&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_source</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&#34;num_samples should be a positive integeral &#34;</span>
</span></span><span class="line"><span class="cl">                             <span class="s2">&#34;value, but got num_samples=</span><span class="si">{}</span><span class="s2">&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">replacement</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&#34;replacement should be a boolean value, but got &#34;</span>
</span></span><span class="line"><span class="cl">                             <span class="s2">&#34;replacement=</span><span class="si">{}</span><span class="s2">&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">replacement</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_source</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">replacement</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">high</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_samples</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">iter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_source</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div><p>这个采样器常见的使用场景是将训练集划分成训练集和验证集:</p>
<div class="highlight" id="id-10"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">SubsetRandomSampler</span><span class="p">(</span><span class="n">Sampler</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># r&#34;&#34;&#34;Samples elements randomly from a given list of indices, without replacement.     # Arguments:     # indices (sequence): a sequence of indices     # &#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">indices</span> <span class="o">=</span> <span class="n">indices</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">indices</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">indices</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div><p><strong>batch_sampler</strong>
前面的采样器每次都只返回一个索引，但是我们在训练时是对批量的数据进行训练，而这个工作就需要<code>BatchSampler</code>来做。也就是说<code>BatchSampler</code>的作用就是将前面的Sampler采样得到的索引值进行合并，当数量等于一个batch大小后就将这一批的索引值返回。</p>
<div class="highlight" id="id-11"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">BatchSampler</span><span class="p">(</span><span class="n">Sampler</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># Wraps another sampler to yield a mini-batch of indices.     # Args:     # sampler (Sampler): Base sampler.     # batch_size (int): Size of mini-batch.     # drop_last (bool): If ``True``, the sampler will drop the last batch if     # its size would be less than ``batch_size``     # Example:     # &gt;&gt;&gt; list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=False))     # [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]     # &gt;&gt;&gt; list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=True))     # [[0, 1, 2], [3, 4, 5], [6, 7, 8]]</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 批次采样     def __init__(self, sampler, batch_size, drop_last):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sampler</span><span class="p">,</span> <span class="n">Sampler</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&#34;sampler should be an instance of &#34;</span>
</span></span><span class="line"><span class="cl">                             <span class="s2">&#34;torch.utils.data.Sampler, but got sampler=</span><span class="si">{}</span><span class="s2">&#34;</span>
</span></span><span class="line"><span class="cl">                             <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">sampler</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">_int_classes</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="nb">bool</span><span class="p">)</span> <span class="ow">or</span> \
</span></span><span class="line"><span class="cl">                <span class="n">batch_size</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&#34;batch_size should be a positive integeral value, &#34;</span>
</span></span><span class="line"><span class="cl">                             <span class="s2">&#34;but got batch_size=</span><span class="si">{}</span><span class="s2">&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">batch_size</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">drop_last</span><span class="p">,</span> <span class="nb">bool</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&#34;drop_last should be a boolean value, but got &#34;</span>
</span></span><span class="line"><span class="cl">                             <span class="s2">&#34;drop_last=</span><span class="si">{}</span><span class="s2">&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">drop_last</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span> <span class="o">=</span> <span class="n">sampler</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">drop_last</span> <span class="o">=</span> <span class="n">drop_last</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">batch</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">yield</span> <span class="n">batch</span>
</span></span><span class="line"><span class="cl">                <span class="n">batch</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_last</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">yield</span> <span class="n">batch</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">drop_last</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sampler</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span></span></span></code></pre></td></tr></table>
</div>
</div><h3 id="多线程">多线程</h3>
<p><code>num_workers</code> 参数表示同时参与数据读取的线程数量，多线程技术可以加快数据读取，提供GPU/CPU利用率。</p>
<p>未来会出一篇文章讲一讲PyTorch多线程实现的原理。</p>
<h3 id="dataloader-和-dataset-简单举例">DataLoader 和 Dataset 简单举例</h3>
<div class="highlight" id="id-12"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># construct dataset</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span><span class="n">DataLoader</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">MyDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span><span class="n">index</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">index</span><span class="p">],</span><span class="bp">self</span><span class="o">.</span><span class="n">label</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># dataloader</span>
</span></span><span class="line"><span class="cl"><span class="n">mydataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">mydataset</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                          <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mydataloader</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div><h2 id="demo1---mlps-dataset-and-dataloader">DEMO1 - MLP&rsquo;s Dataset and DataLoader</h2>
<div class="highlight" id="id-13"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">dim_output</span> <span class="o">=</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">TrainValidDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s1">&#39;&#39;&#39;
</span></span></span><span class="line"><span class="cl"><span class="s1">    Args:
</span></span></span><span class="line"><span class="cl"><span class="s1">      - root_dir (string): Directory containing all folders with different
</span></span></span><span class="line"><span class="cl"><span class="s1">        dates, each folder containing .cruise.h5 data files.
</span></span></span><span class="line"><span class="cl"><span class="s1">    &#39;&#39;&#39;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">list_of_files</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">list_of_files_</span> <span class="o">=</span> <span class="n">list_of_files</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">data_size_until_this_file_</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">dataset_size</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">list_of_files_</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">with</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">file</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">h5_file</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">data_size</span> <span class="o">=</span> <span class="n">h5_file</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">h5_file</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">dataset_size</span> <span class="o">+=</span> <span class="n">data_size</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">data_size_until_this_file_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dataset_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;Total size of dataset: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_size_until_this_file_</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dataset_size</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">bin_idx</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">FindBin</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">data_size_until_this_file_</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">with</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">list_of_files_</span><span class="p">[</span><span class="n">bin_idx</span><span class="p">],</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">h5_file</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">idx_offset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_size_until_this_file_</span><span class="p">[</span><span class="n">bin_idx</span><span class="p">]</span> <span class="o">-</span> \
</span></span><span class="line"><span class="cl">                <span class="n">h5_file</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">h5_file</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">]]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="n">data</span> <span class="o">=</span> <span class="n">h5_file</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">h5_file</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">]][</span><span class="n">index</span><span class="o">-</span><span class="n">idx_offset</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">label</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="o">-</span><span class="n">dim_output</span><span class="p">:]</span>
</span></span><span class="line"><span class="cl">        <span class="n">label</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">label</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">data</span><span class="p">[:</span><span class="o">-</span><span class="n">dim_output</span><span class="p">],</span> <span class="n">label</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Binary search to expedite the data-loading process.</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">FindBin</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">start</span> <span class="o">==</span> <span class="n">end</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">start</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">mid</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">start</span><span class="o">+</span><span class="n">end</span><span class="p">)</span><span class="o">/</span><span class="mf">2.0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_size_until_this_file_</span><span class="p">[</span><span class="n">mid</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">index</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">FindBin</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">mid</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">end</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">FindBin</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">mid</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># search all the files in the directory</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">getListOfFiles</span><span class="p">(</span><span class="n">dirName</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">listOfFiles</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">dirName</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">allFiles</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">entry</span> <span class="ow">in</span> <span class="n">listOfFiles</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">fullPath</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">dirName</span><span class="p">,</span> <span class="n">entry</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">fullPath</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">allFiles</span> <span class="o">=</span> <span class="n">allFiles</span> <span class="o">+</span> <span class="n">getListOfFiles</span><span class="p">(</span><span class="n">fullPath</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">allFiles</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fullPath</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">allFiles</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">list_of_training_files</span> <span class="o">=</span> <span class="n">getListOfFiles</span><span class="p">(</span><span class="s1">&#39;data&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_dataset</span> <span class="o">=</span> <span class="n">TrainValidDataset</span><span class="p">(</span><span class="n">list_of_training_files</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">myDataLoader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">myDataLoader</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div><h2 id="demo2---lanegcns-dataset-and-dataloader">DEMO2 - LaneGCN&rsquo;s Dataset and DataLoader</h2>
<p><strong>dataset description:</strong></p>
<div class="highlight" id="id-14"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">  1
</span><span class="lnt">  2
</span><span class="lnt">  3
</span><span class="lnt">  4
</span><span class="lnt">  5
</span><span class="lnt">  6
</span><span class="lnt">  7
</span><span class="lnt">  8
</span><span class="lnt">  9
</span><span class="lnt"> 10
</span><span class="lnt"> 11
</span><span class="lnt"> 12
</span><span class="lnt"> 13
</span><span class="lnt"> 14
</span><span class="lnt"> 15
</span><span class="lnt"> 16
</span><span class="lnt"> 17
</span><span class="lnt"> 18
</span><span class="lnt"> 19
</span><span class="lnt"> 20
</span><span class="lnt"> 21
</span><span class="lnt"> 22
</span><span class="lnt"> 23
</span><span class="lnt"> 24
</span><span class="lnt"> 25
</span><span class="lnt"> 26
</span><span class="lnt"> 27
</span><span class="lnt"> 28
</span><span class="lnt"> 29
</span><span class="lnt"> 30
</span><span class="lnt"> 31
</span><span class="lnt"> 32
</span><span class="lnt"> 33
</span><span class="lnt"> 34
</span><span class="lnt"> 35
</span><span class="lnt"> 36
</span><span class="lnt"> 37
</span><span class="lnt"> 38
</span><span class="lnt"> 39
</span><span class="lnt"> 40
</span><span class="lnt"> 41
</span><span class="lnt"> 42
</span><span class="lnt"> 43
</span><span class="lnt"> 44
</span><span class="lnt"> 45
</span><span class="lnt"> 46
</span><span class="lnt"> 47
</span><span class="lnt"> 48
</span><span class="lnt"> 49
</span><span class="lnt"> 50
</span><span class="lnt"> 51
</span><span class="lnt"> 52
</span><span class="lnt"> 53
</span><span class="lnt"> 54
</span><span class="lnt"> 55
</span><span class="lnt"> 56
</span><span class="lnt"> 57
</span><span class="lnt"> 58
</span><span class="lnt"> 59
</span><span class="lnt"> 60
</span><span class="lnt"> 61
</span><span class="lnt"> 62
</span><span class="lnt"> 63
</span><span class="lnt"> 64
</span><span class="lnt"> 65
</span><span class="lnt"> 66
</span><span class="lnt"> 67
</span><span class="lnt"> 68
</span><span class="lnt"> 69
</span><span class="lnt"> 70
</span><span class="lnt"> 71
</span><span class="lnt"> 72
</span><span class="lnt"> 73
</span><span class="lnt"> 74
</span><span class="lnt"> 75
</span><span class="lnt"> 76
</span><span class="lnt"> 77
</span><span class="lnt"> 78
</span><span class="lnt"> 79
</span><span class="lnt"> 80
</span><span class="lnt"> 81
</span><span class="lnt"> 82
</span><span class="lnt"> 83
</span><span class="lnt"> 84
</span><span class="lnt"> 85
</span><span class="lnt"> 86
</span><span class="lnt"> 87
</span><span class="lnt"> 88
</span><span class="lnt"> 89
</span><span class="lnt"> 90
</span><span class="lnt"> 91
</span><span class="lnt"> 92
</span><span class="lnt"> 93
</span><span class="lnt"> 94
</span><span class="lnt"> 95
</span><span class="lnt"> 96
</span><span class="lnt"> 97
</span><span class="lnt"> 98
</span><span class="lnt"> 99
</span><span class="lnt">100
</span><span class="lnt">101
</span><span class="lnt">102
</span><span class="lnt">103
</span><span class="lnt">104
</span><span class="lnt">105
</span><span class="lnt">106
</span><span class="lnt">107
</span><span class="lnt">108
</span><span class="lnt">109
</span><span class="lnt">110
</span><span class="lnt">111
</span><span class="lnt">112
</span><span class="lnt">113
</span><span class="lnt">114
</span><span class="lnt">115
</span><span class="lnt">116
</span><span class="lnt">117
</span><span class="lnt">118
</span><span class="lnt">119
</span><span class="lnt">120
</span><span class="lnt">121
</span><span class="lnt">122
</span><span class="lnt">123
</span><span class="lnt">124
</span><span class="lnt">125
</span><span class="lnt">126
</span><span class="lnt">127
</span><span class="lnt">128
</span><span class="lnt">129
</span><span class="lnt">130
</span><span class="lnt">131
</span><span class="lnt">132
</span><span class="lnt">133
</span><span class="lnt">134
</span><span class="lnt">135
</span><span class="lnt">136
</span><span class="lnt">137
</span><span class="lnt">138
</span><span class="lnt">139
</span><span class="lnt">140
</span><span class="lnt">141
</span><span class="lnt">142
</span><span class="lnt">143
</span><span class="lnt">144
</span><span class="lnt">145
</span><span class="lnt">146
</span><span class="lnt">147
</span><span class="lnt">148
</span><span class="lnt">149
</span><span class="lnt">150
</span><span class="lnt">151
</span><span class="lnt">152
</span><span class="lnt">153
</span><span class="lnt">154
</span><span class="lnt">155
</span><span class="lnt">156
</span><span class="lnt">157
</span><span class="lnt">158
</span><span class="lnt">159
</span><span class="lnt">160
</span><span class="lnt">161
</span><span class="lnt">162
</span><span class="lnt">163
</span><span class="lnt">164
</span><span class="lnt">165
</span><span class="lnt">166
</span><span class="lnt">167
</span><span class="lnt">168
</span><span class="lnt">169
</span><span class="lnt">170
</span><span class="lnt">171
</span><span class="lnt">172
</span><span class="lnt">173
</span><span class="lnt">174
</span><span class="lnt">175
</span><span class="lnt">176
</span><span class="lnt">177
</span><span class="lnt">178
</span><span class="lnt">179
</span><span class="lnt">180
</span><span class="lnt">181
</span><span class="lnt">182
</span><span class="lnt">183
</span><span class="lnt">184
</span><span class="lnt">185
</span><span class="lnt">186
</span><span class="lnt">187
</span><span class="lnt">188
</span><span class="lnt">189
</span><span class="lnt">190
</span><span class="lnt">191
</span><span class="lnt">192
</span><span class="lnt">193
</span><span class="lnt">194
</span><span class="lnt">195
</span><span class="lnt">196
</span><span class="lnt">197
</span><span class="lnt">198
</span><span class="lnt">199
</span><span class="lnt">200
</span><span class="lnt">201
</span><span class="lnt">202
</span><span class="lnt">203
</span><span class="lnt">204
</span><span class="lnt">205
</span><span class="lnt">206
</span><span class="lnt">207
</span><span class="lnt">208
</span><span class="lnt">209
</span><span class="lnt">210
</span><span class="lnt">211
</span><span class="lnt">212
</span><span class="lnt">213
</span><span class="lnt">214
</span><span class="lnt">215
</span><span class="lnt">216
</span><span class="lnt">217
</span><span class="lnt">218
</span><span class="lnt">219
</span><span class="lnt">220
</span><span class="lnt">221
</span><span class="lnt">222
</span><span class="lnt">223
</span><span class="lnt">224
</span><span class="lnt">225
</span><span class="lnt">226
</span><span class="lnt">227
</span><span class="lnt">228
</span><span class="lnt">229
</span><span class="lnt">230
</span><span class="lnt">231
</span><span class="lnt">232
</span><span class="lnt">233
</span><span class="lnt">234
</span><span class="lnt">235
</span><span class="lnt">236
</span><span class="lnt">237
</span><span class="lnt">238
</span><span class="lnt">239
</span><span class="lnt">240
</span><span class="lnt">241
</span><span class="lnt">242
</span><span class="lnt">243
</span><span class="lnt">244
</span><span class="lnt">245
</span><span class="lnt">246
</span><span class="lnt">247
</span><span class="lnt">248
</span><span class="lnt">249
</span><span class="lnt">250
</span><span class="lnt">251
</span><span class="lnt">252
</span><span class="lnt">253
</span><span class="lnt">254
</span><span class="lnt">255
</span><span class="lnt">256
</span><span class="lnt">257
</span><span class="lnt">258
</span><span class="lnt">259
</span><span class="lnt">260
</span><span class="lnt">261
</span><span class="lnt">262
</span><span class="lnt">263
</span><span class="lnt">264
</span><span class="lnt">265
</span><span class="lnt">266
</span><span class="lnt">267
</span><span class="lnt">268
</span><span class="lnt">269
</span><span class="lnt">270
</span><span class="lnt">271
</span><span class="lnt">272
</span><span class="lnt">273
</span><span class="lnt">274
</span><span class="lnt">275
</span><span class="lnt">276
</span><span class="lnt">277
</span><span class="lnt">278
</span><span class="lnt">279
</span><span class="lnt">280
</span><span class="lnt">281
</span><span class="lnt">282
</span><span class="lnt">283
</span><span class="lnt">284
</span><span class="lnt">285
</span><span class="lnt">286
</span><span class="lnt">287
</span><span class="lnt">288
</span><span class="lnt">289
</span><span class="lnt">290
</span><span class="lnt">291
</span><span class="lnt">292
</span><span class="lnt">293
</span><span class="lnt">294
</span><span class="lnt">295
</span><span class="lnt">296
</span><span class="lnt">297
</span><span class="lnt">298
</span><span class="lnt">299
</span><span class="lnt">300
</span><span class="lnt">301
</span><span class="lnt">302
</span><span class="lnt">303
</span><span class="lnt">304
</span><span class="lnt">305
</span><span class="lnt">306
</span><span class="lnt">307
</span><span class="lnt">308
</span><span class="lnt">309
</span><span class="lnt">310
</span><span class="lnt">311
</span><span class="lnt">312
</span><span class="lnt">313
</span><span class="lnt">314
</span><span class="lnt">315
</span><span class="lnt">316
</span><span class="lnt">317
</span><span class="lnt">318
</span><span class="lnt">319
</span><span class="lnt">320
</span><span class="lnt">321
</span><span class="lnt">322
</span><span class="lnt">323
</span><span class="lnt">324
</span><span class="lnt">325
</span><span class="lnt">326
</span><span class="lnt">327
</span><span class="lnt">328
</span><span class="lnt">329
</span><span class="lnt">330
</span><span class="lnt">331
</span><span class="lnt">332
</span><span class="lnt">333
</span><span class="lnt">334
</span><span class="lnt">335
</span><span class="lnt">336
</span><span class="lnt">337
</span><span class="lnt">338
</span><span class="lnt">339
</span><span class="lnt">340
</span><span class="lnt">341
</span><span class="lnt">342
</span><span class="lnt">343
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">ArgoDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">split</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="n">config</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="n">train</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="s1">&#39;preprocess&#39;</span> <span class="ow">in</span> <span class="n">config</span> <span class="ow">and</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;preprocess&#39;</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">train</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;preprocess_train&#39;</span><span class="p">],</span> <span class="n">allow_pickle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">split</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;preprocess_val&#39;</span><span class="p">],</span> <span class="n">allow_pickle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">avl</span> <span class="o">=</span> <span class="n">ArgoverseForecastingLoader</span><span class="p">(</span><span class="n">split</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">avl</span><span class="o">.</span><span class="n">seq_list</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">avl</span><span class="o">.</span><span class="n">seq_list</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">am</span> <span class="o">=</span> <span class="n">ArgoverseMap</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="s1">&#39;raster&#39;</span> <span class="ow">in</span> <span class="n">config</span> <span class="ow">and</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;raster&#39;</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">            <span class="c1">#TODO: DELETE</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">map_query</span> <span class="o">=</span> <span class="n">MapQuery</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;map_scale&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="s1">&#39;preprocess&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;preprocess&#39;</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">            <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">split</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;rot_aug&#39;</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">                <span class="n">new_data</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;city&#39;</span><span class="p">,</span> <span class="s1">&#39;orig&#39;</span><span class="p">,</span> <span class="s1">&#39;gt_preds&#39;</span><span class="p">,</span> <span class="s1">&#39;has_preds&#39;</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">                    <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                        <span class="n">new_data</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">ref_copy</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">key</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">                <span class="n">dt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;rot_size&#39;</span><span class="p">]</span><span class="c1">#np.pi * 2.0</span>
</span></span><span class="line"><span class="cl">                <span class="n">theta</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">dt</span>
</span></span><span class="line"><span class="cl">                <span class="n">new_data</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">theta</span>
</span></span><span class="line"><span class="cl">                <span class="n">new_data</span><span class="p">[</span><span class="s1">&#39;rot&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">                    <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">),</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">)],</span>
</span></span><span class="line"><span class="cl">                    <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">)]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">                <span class="n">rot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">                    <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="o">-</span><span class="n">dt</span><span class="p">),</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="o">-</span><span class="n">dt</span><span class="p">)],</span>
</span></span><span class="line"><span class="cl">                    <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="o">-</span><span class="n">dt</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="o">-</span><span class="n">dt</span><span class="p">)]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">new_data</span><span class="p">[</span><span class="s1">&#39;feats&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;feats&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">                <span class="n">new_data</span><span class="p">[</span><span class="s1">&#39;feats&#39;</span><span class="p">][:,</span> <span class="p">:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">new_data</span><span class="p">[</span><span class="s1">&#39;feats&#39;</span><span class="p">][:,</span> <span class="p">:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">],</span> <span class="n">rot</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">new_data</span><span class="p">[</span><span class="s1">&#39;ctrs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;ctrs&#39;</span><span class="p">],</span> <span class="n">rot</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">                <span class="n">graph</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;num_nodes&#39;</span><span class="p">,</span> <span class="s1">&#39;turn&#39;</span><span class="p">,</span> <span class="s1">&#39;control&#39;</span><span class="p">,</span> <span class="s1">&#39;intersect&#39;</span><span class="p">,</span> <span class="s1">&#39;pre&#39;</span><span class="p">,</span> <span class="s1">&#39;suc&#39;</span><span class="p">,</span> <span class="s1">&#39;lane_idcs&#39;</span><span class="p">,</span> <span class="s1">&#39;left_pairs&#39;</span><span class="p">,</span> <span class="s1">&#39;right_pairs&#39;</span><span class="p">,</span> <span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="s1">&#39;right&#39;</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">                    <span class="n">graph</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">ref_copy</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;graph&#39;</span><span class="p">][</span><span class="n">key</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">graph</span><span class="p">[</span><span class="s1">&#39;ctrs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;graph&#39;</span><span class="p">][</span><span class="s1">&#39;ctrs&#39;</span><span class="p">],</span> <span class="n">rot</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">graph</span><span class="p">[</span><span class="s1">&#39;feats&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;graph&#39;</span><span class="p">][</span><span class="s1">&#39;feats&#39;</span><span class="p">],</span> <span class="n">rot</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">new_data</span><span class="p">[</span><span class="s1">&#39;graph&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">graph</span>
</span></span><span class="line"><span class="cl">                <span class="n">data</span> <span class="o">=</span> <span class="n">new_data</span>
</span></span><span class="line"><span class="cl">            <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">new_data</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;city&#39;</span><span class="p">,</span> <span class="s1">&#39;orig&#39;</span><span class="p">,</span> <span class="s1">&#39;gt_preds&#39;</span><span class="p">,</span> <span class="s1">&#39;has_preds&#39;</span><span class="p">,</span> <span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="s1">&#39;rot&#39;</span><span class="p">,</span> <span class="s1">&#39;feats&#39;</span><span class="p">,</span> <span class="s1">&#39;ctrs&#39;</span><span class="p">,</span> <span class="s1">&#39;graph&#39;</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">                    <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                        <span class="n">new_data</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">ref_copy</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">key</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">data</span> <span class="o">=</span> <span class="n">new_data</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="s1">&#39;raster&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;raster&#39;</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">                <span class="n">data</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">&#39;graph&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;pred_range&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">                <span class="n">cx</span><span class="p">,</span> <span class="n">cy</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;orig&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">                <span class="n">region</span> <span class="o">=</span> <span class="p">[</span><span class="n">cx</span> <span class="o">+</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">cx</span> <span class="o">+</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">cy</span> <span class="o">+</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">cy</span> <span class="o">+</span> <span class="n">y_max</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">                <span class="n">raster</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_query</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">region</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;city&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">                <span class="n">data</span><span class="p">[</span><span class="s1">&#39;raster&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">raster</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">data</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">read_argo_data</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_obj_feats</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;idx&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">idx</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="s1">&#39;raster&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;raster&#39;</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">            <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;pred_range&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="n">cx</span><span class="p">,</span> <span class="n">cy</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;orig&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">region</span> <span class="o">=</span> <span class="p">[</span><span class="n">cx</span> <span class="o">+</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">cx</span> <span class="o">+</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">cy</span> <span class="o">+</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">cy</span> <span class="o">+</span> <span class="n">y_max</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="n">raster</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_query</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="n">region</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;city&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">data</span><span class="p">[</span><span class="s1">&#39;raster&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">raster</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="n">data</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;graph&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_lane_graph</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">data</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="s1">&#39;preprocess&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;preprocess&#39;</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">split</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">avl</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">read_argo_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">city</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">avl</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">city</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;&#34;&#34;TIMESTAMP,TRACK_ID,OBJECT_TYPE,X,Y,CITY_NAME&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="n">df</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">avl</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">seq_df</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">agt_ts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;TIMESTAMP&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">mapping</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ts</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">agt_ts</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">mapping</span><span class="p">[</span><span class="n">ts</span><span class="p">]</span> <span class="o">=</span> <span class="n">i</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">trajs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span>
</span></span><span class="line"><span class="cl">            <span class="n">df</span><span class="o">.</span><span class="n">X</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">            <span class="n">df</span><span class="o">.</span><span class="n">Y</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">steps</span> <span class="o">=</span> <span class="p">[</span><span class="n">mapping</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;TIMESTAMP&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">steps</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">objs</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">([</span><span class="s1">&#39;TRACK_ID&#39;</span><span class="p">,</span> <span class="s1">&#39;OBJECT_TYPE&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">groups</span>
</span></span><span class="line"><span class="cl">        <span class="n">keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">objs</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">        <span class="n">obj_type</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">agt_idx</span> <span class="o">=</span> <span class="n">obj_type</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s1">&#39;AGENT&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">idcs</span> <span class="o">=</span> <span class="n">objs</span><span class="p">[</span><span class="n">keys</span><span class="p">[</span><span class="n">agt_idx</span><span class="p">]]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">agt_traj</span> <span class="o">=</span> <span class="n">trajs</span><span class="p">[</span><span class="n">idcs</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">agt_step</span> <span class="o">=</span> <span class="n">steps</span><span class="p">[</span><span class="n">idcs</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">del</span> <span class="n">keys</span><span class="p">[</span><span class="n">agt_idx</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">ctx_trajs</span><span class="p">,</span> <span class="n">ctx_steps</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">idcs</span> <span class="o">=</span> <span class="n">objs</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="n">ctx_trajs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">trajs</span><span class="p">[</span><span class="n">idcs</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">            <span class="n">ctx_steps</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">steps</span><span class="p">[</span><span class="n">idcs</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">data</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;city&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">city</span>
</span></span><span class="line"><span class="cl">        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;trajs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">agt_traj</span><span class="p">]</span> <span class="o">+</span> <span class="n">ctx_trajs</span>
</span></span><span class="line"><span class="cl">        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;steps&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">agt_step</span><span class="p">]</span> <span class="o">+</span> <span class="n">ctx_steps</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">data</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">get_obj_feats</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">orig</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;trajs&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">19</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;rot_aug&#39;</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">            <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="mf">2.0</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">pre</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;trajs&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">18</span><span class="p">]</span> <span class="o">-</span> <span class="n">orig</span>
</span></span><span class="line"><span class="cl">            <span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">arctan2</span><span class="p">(</span><span class="n">pre</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">pre</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">rot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">            <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">),</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">)],</span>
</span></span><span class="line"><span class="cl">            <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">)]],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">feats</span><span class="p">,</span> <span class="n">ctrs</span><span class="p">,</span> <span class="n">gt_preds</span><span class="p">,</span> <span class="n">has_preds</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">traj</span><span class="p">,</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;trajs&#39;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;steps&#39;</span><span class="p">]):</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="mi">19</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">step</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">continue</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">gt_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">30</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">has_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">future_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">step</span> <span class="o">&gt;=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">step</span> <span class="o">&lt;</span> <span class="mi">50</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">post_step</span> <span class="o">=</span> <span class="n">step</span><span class="p">[</span><span class="n">future_mask</span><span class="p">]</span> <span class="o">-</span> <span class="mi">20</span>
</span></span><span class="line"><span class="cl">            <span class="n">post_traj</span> <span class="o">=</span> <span class="n">traj</span><span class="p">[</span><span class="n">future_mask</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="n">gt_pred</span><span class="p">[</span><span class="n">post_step</span><span class="p">]</span> <span class="o">=</span> <span class="n">post_traj</span>
</span></span><span class="line"><span class="cl">            <span class="n">has_pred</span><span class="p">[</span><span class="n">post_step</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">obs_mask</span> <span class="o">=</span> <span class="n">step</span> <span class="o">&lt;</span> <span class="mi">20</span>
</span></span><span class="line"><span class="cl">            <span class="n">step</span> <span class="o">=</span> <span class="n">step</span><span class="p">[</span><span class="n">obs_mask</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="n">traj</span> <span class="o">=</span> <span class="n">traj</span><span class="p">[</span><span class="n">obs_mask</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="n">idcs</span> <span class="o">=</span> <span class="n">step</span><span class="o">.</span><span class="n">argsort</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">step</span> <span class="o">=</span> <span class="n">step</span><span class="p">[</span><span class="n">idcs</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="n">traj</span> <span class="o">=</span> <span class="n">traj</span><span class="p">[</span><span class="n">idcs</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">step</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="n">step</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">19</span> <span class="o">-</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">step</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">i</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                    <span class="k">break</span>
</span></span><span class="line"><span class="cl">            <span class="n">step</span> <span class="o">=</span> <span class="n">step</span><span class="p">[</span><span class="n">i</span><span class="p">:]</span>
</span></span><span class="line"><span class="cl">            <span class="n">traj</span> <span class="o">=</span> <span class="n">traj</span><span class="p">[</span><span class="n">i</span><span class="p">:]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">feat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">20</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">feat</span><span class="p">[</span><span class="n">step</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">rot</span><span class="p">,</span> <span class="p">(</span><span class="n">traj</span> <span class="o">-</span> <span class="n">orig</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
</span></span><span class="line"><span class="cl">            <span class="n">feat</span><span class="p">[</span><span class="n">step</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;pred_range&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">feat</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">x_min</span> <span class="ow">or</span> <span class="n">feat</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">x_max</span> <span class="ow">or</span> <span class="n">feat</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">y_min</span> <span class="ow">or</span> <span class="n">feat</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">y_max</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">continue</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">ctrs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">feat</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">            <span class="n">feat</span><span class="p">[</span><span class="mi">1</span><span class="p">:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">-=</span> <span class="n">feat</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="n">feat</span><span class="p">[</span><span class="n">step</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">            <span class="n">feats</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">feat</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">gt_preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gt_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">has_preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">has_pred</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">feats</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">feats</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">ctrs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">ctrs</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">gt_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">gt_preds</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">has_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">has_preds</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;feats&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">feats</span>
</span></span><span class="line"><span class="cl">        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;ctrs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">ctrs</span>
</span></span><span class="line"><span class="cl">        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;orig&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">orig</span>
</span></span><span class="line"><span class="cl">        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">theta</span>
</span></span><span class="line"><span class="cl">        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;rot&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rot</span>
</span></span><span class="line"><span class="cl">        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;gt_preds&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">gt_preds</span>
</span></span><span class="line"><span class="cl">        <span class="n">data</span><span class="p">[</span><span class="s1">&#39;has_preds&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">has_preds</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">data</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">get_lane_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="s2">&#34;&#34;&#34;Get a rectangle area defined by pred_range.&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">        <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;pred_range&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">radius</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">x_min</span><span class="p">),</span> <span class="nb">abs</span><span class="p">(</span><span class="n">x_max</span><span class="p">))</span> <span class="o">+</span> <span class="nb">max</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">y_min</span><span class="p">),</span> <span class="nb">abs</span><span class="p">(</span><span class="n">y_max</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">lane_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">am</span><span class="o">.</span><span class="n">get_lane_ids_in_xy_bbox</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;orig&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;orig&#39;</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;city&#39;</span><span class="p">],</span> <span class="n">radius</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">lane_ids</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">lane_ids</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">lanes</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">lane_id</span> <span class="ow">in</span> <span class="n">lane_ids</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">lane</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">am</span><span class="o">.</span><span class="n">city_lane_centerlines_dict</span><span class="p">[</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;city&#39;</span><span class="p">]][</span><span class="n">lane_id</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="n">lane</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">lane</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">centerline</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;rot&#39;</span><span class="p">],</span> <span class="p">(</span><span class="n">lane</span><span class="o">.</span><span class="n">centerline</span> <span class="o">-</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;orig&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
</span></span><span class="line"><span class="cl">            <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">centerline</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">centerline</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">x_min</span> <span class="ow">or</span> <span class="n">x</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">x_max</span> <span class="ow">or</span> <span class="n">y</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&lt;</span> <span class="n">y_min</span> <span class="ow">or</span> <span class="n">y</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">y_max</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">continue</span>
</span></span><span class="line"><span class="cl">            <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="s2">&#34;&#34;&#34;Getting polygons requires original centerline&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">                <span class="n">polygon</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">am</span><span class="o">.</span><span class="n">get_lane_segment_polygon</span><span class="p">(</span><span class="n">lane_id</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;city&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                <span class="n">polygon</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">polygon</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="n">lane</span><span class="o">.</span><span class="n">centerline</span> <span class="o">=</span> <span class="n">centerline</span>
</span></span><span class="line"><span class="cl">                <span class="n">lane</span><span class="o">.</span><span class="n">polygon</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;rot&#39;</span><span class="p">],</span> <span class="p">(</span><span class="n">polygon</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;orig&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
</span></span><span class="line"><span class="cl">                <span class="n">lanes</span><span class="p">[</span><span class="n">lane_id</span><span class="p">]</span> <span class="o">=</span> <span class="n">lane</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">lane_ids</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">lanes</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">        <span class="n">ctrs</span><span class="p">,</span> <span class="n">feats</span><span class="p">,</span> <span class="n">turn</span><span class="p">,</span> <span class="n">control</span><span class="p">,</span> <span class="n">intersect</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">lane_id</span> <span class="ow">in</span> <span class="n">lane_ids</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">lane</span> <span class="o">=</span> <span class="n">lanes</span><span class="p">[</span><span class="n">lane_id</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="n">ctrln</span> <span class="o">=</span> <span class="n">lane</span><span class="o">.</span><span class="n">centerline</span>
</span></span><span class="line"><span class="cl">            <span class="n">num_segs</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ctrln</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">ctrs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">((</span><span class="n">ctrln</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">ctrln</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span> <span class="o">/</span> <span class="mf">2.0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">            <span class="n">feats</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">ctrln</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">ctrln</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">num_segs</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">lane</span><span class="o">.</span><span class="n">turn_direction</span> <span class="o">==</span> <span class="s1">&#39;LEFT&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">x</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">            <span class="k">elif</span> <span class="n">lane</span><span class="o">.</span><span class="n">turn_direction</span> <span class="o">==</span> <span class="s1">&#39;RIGHT&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">x</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">            <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">pass</span>
</span></span><span class="line"><span class="cl">            <span class="n">turn</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">control</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lane</span><span class="o">.</span><span class="n">has_traffic_control</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_segs</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">            <span class="n">intersect</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lane</span><span class="o">.</span><span class="n">is_intersection</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_segs</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">node_idcs</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ctr</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">ctrs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">node_idcs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">count</span><span class="p">,</span> <span class="n">count</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">ctr</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">            <span class="n">count</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">ctr</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">num_nodes</span> <span class="o">=</span> <span class="n">count</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">pre</span><span class="p">,</span> <span class="n">suc</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(),</span> <span class="nb">dict</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;u&#39;</span><span class="p">,</span> <span class="s1">&#39;v&#39;</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">            <span class="n">pre</span><span class="p">[</span><span class="n">key</span><span class="p">],</span> <span class="n">suc</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">lane_id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">lane_ids</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">lane</span> <span class="o">=</span> <span class="n">lanes</span><span class="p">[</span><span class="n">lane_id</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="n">idcs</span> <span class="o">=</span> <span class="n">node_idcs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">pre</span><span class="p">[</span><span class="s1">&#39;u&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idcs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</span></span><span class="line"><span class="cl">            <span class="n">pre</span><span class="p">[</span><span class="s1">&#39;v&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idcs</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">lane</span><span class="o">.</span><span class="n">predecessors</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">for</span> <span class="n">nbr_id</span> <span class="ow">in</span> <span class="n">lane</span><span class="o">.</span><span class="n">predecessors</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                    <span class="k">if</span> <span class="n">nbr_id</span> <span class="ow">in</span> <span class="n">lane_ids</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                        <span class="n">j</span> <span class="o">=</span> <span class="n">lane_ids</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">nbr_id</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                        <span class="n">pre</span><span class="p">[</span><span class="s1">&#39;u&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">idcs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                        <span class="n">pre</span><span class="p">[</span><span class="s1">&#39;v&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node_idcs</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">suc</span><span class="p">[</span><span class="s1">&#39;u&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idcs</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">            <span class="n">suc</span><span class="p">[</span><span class="s1">&#39;v&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idcs</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">lane</span><span class="o">.</span><span class="n">successors</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">for</span> <span class="n">nbr_id</span> <span class="ow">in</span> <span class="n">lane</span><span class="o">.</span><span class="n">successors</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                    <span class="k">if</span> <span class="n">nbr_id</span> <span class="ow">in</span> <span class="n">lane_ids</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                        <span class="n">j</span> <span class="o">=</span> <span class="n">lane_ids</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">nbr_id</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                        <span class="n">suc</span><span class="p">[</span><span class="s1">&#39;u&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">idcs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                        <span class="n">suc</span><span class="p">[</span><span class="s1">&#39;v&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node_idcs</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">lane_idcs</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">idcs</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">node_idcs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">lane_idcs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">idcs</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="n">lane_idcs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">lane_idcs</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">pre_pairs</span><span class="p">,</span> <span class="n">suc_pairs</span><span class="p">,</span> <span class="n">left_pairs</span><span class="p">,</span> <span class="n">right_pairs</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">lane_id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">lane_ids</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">lane</span> <span class="o">=</span> <span class="n">lanes</span><span class="p">[</span><span class="n">lane_id</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">nbr_ids</span> <span class="o">=</span> <span class="n">lane</span><span class="o">.</span><span class="n">predecessors</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">nbr_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">for</span> <span class="n">nbr_id</span> <span class="ow">in</span> <span class="n">nbr_ids</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                    <span class="k">if</span> <span class="n">nbr_id</span> <span class="ow">in</span> <span class="n">lane_ids</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                        <span class="n">j</span> <span class="o">=</span> <span class="n">lane_ids</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">nbr_id</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                        <span class="n">pre_pairs</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">nbr_ids</span> <span class="o">=</span> <span class="n">lane</span><span class="o">.</span><span class="n">successors</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">nbr_ids</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">for</span> <span class="n">nbr_id</span> <span class="ow">in</span> <span class="n">nbr_ids</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                    <span class="k">if</span> <span class="n">nbr_id</span> <span class="ow">in</span> <span class="n">lane_ids</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                        <span class="n">j</span> <span class="o">=</span> <span class="n">lane_ids</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">nbr_id</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                        <span class="n">suc_pairs</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">nbr_id</span> <span class="o">=</span> <span class="n">lane</span><span class="o">.</span><span class="n">l_neighbor_id</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">nbr_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="n">nbr_id</span> <span class="ow">in</span> <span class="n">lane_ids</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                    <span class="n">j</span> <span class="o">=</span> <span class="n">lane_ids</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">nbr_id</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                    <span class="n">left_pairs</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">            <span class="n">nbr_id</span> <span class="o">=</span> <span class="n">lane</span><span class="o">.</span><span class="n">r_neighbor_id</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">nbr_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">if</span> <span class="n">nbr_id</span> <span class="ow">in</span> <span class="n">lane_ids</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                    <span class="n">j</span> <span class="o">=</span> <span class="n">lane_ids</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">nbr_id</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                    <span class="n">right_pairs</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="n">pre_pairs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">pre_pairs</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">suc_pairs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">suc_pairs</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">left_pairs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">left_pairs</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">right_pairs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">right_pairs</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="n">graph</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">graph</span><span class="p">[</span><span class="s1">&#39;ctrs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">ctrs</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">graph</span><span class="p">[</span><span class="s1">&#39;num_nodes&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">num_nodes</span>
</span></span><span class="line"><span class="cl">        <span class="n">graph</span><span class="p">[</span><span class="s1">&#39;feats&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">feats</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">graph</span><span class="p">[</span><span class="s1">&#39;turn&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">turn</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">graph</span><span class="p">[</span><span class="s1">&#39;control&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">control</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">graph</span><span class="p">[</span><span class="s1">&#39;intersect&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">intersect</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">graph</span><span class="p">[</span><span class="s1">&#39;pre&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">pre</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">graph</span><span class="p">[</span><span class="s1">&#39;suc&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">suc</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">graph</span><span class="p">[</span><span class="s1">&#39;lane_idcs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lane_idcs</span>
</span></span><span class="line"><span class="cl">        <span class="n">graph</span><span class="p">[</span><span class="s1">&#39;pre_pairs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pre_pairs</span>
</span></span><span class="line"><span class="cl">        <span class="n">graph</span><span class="p">[</span><span class="s1">&#39;suc_pairs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">suc_pairs</span>
</span></span><span class="line"><span class="cl">        <span class="n">graph</span><span class="p">[</span><span class="s1">&#39;left_pairs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">left_pairs</span>
</span></span><span class="line"><span class="cl">        <span class="n">graph</span><span class="p">[</span><span class="s1">&#39;right_pairs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">right_pairs</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">k1</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;pre&#39;</span><span class="p">,</span> <span class="s1">&#39;suc&#39;</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">            <span class="k">for</span> <span class="n">k2</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;u&#39;</span><span class="p">,</span> <span class="s1">&#39;v&#39;</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">                <span class="n">graph</span><span class="p">[</span><span class="n">k1</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="n">k2</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">graph</span><span class="p">[</span><span class="n">k1</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="n">k2</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;pre&#39;</span><span class="p">,</span> <span class="s1">&#39;suc&#39;</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="s1">&#39;scales&#39;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;scales&#39;</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">                <span class="c1">#TODO: delete here</span>
</span></span><span class="line"><span class="cl">                <span class="n">graph</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+=</span> <span class="n">dilated_nbrs2</span><span class="p">(</span><span class="n">graph</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">graph</span><span class="p">[</span><span class="s1">&#39;num_nodes&#39;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;scales&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">            <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="n">graph</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+=</span> <span class="n">dilated_nbrs</span><span class="p">(</span><span class="n">graph</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">graph</span><span class="p">[</span><span class="s1">&#39;num_nodes&#39;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;num_scales&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">graph</span></span></span></code></pre></td></tr></table>
</div>
</div><p><strong>DataLoader:</strong></p>
<div class="highlight" id="id-15"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"> <span class="c1"># Data loader for training</span>
</span></span><span class="line"><span class="cl">    <span class="n">dataset</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;train_split&#34;</span><span class="p">],</span> <span class="n">config</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_sampler</span> <span class="o">=</span> <span class="n">DistributedSampler</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">dataset</span><span class="p">,</span> <span class="n">num_replicas</span><span class="o">=</span><span class="n">hvd</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">rank</span><span class="o">=</span><span class="n">hvd</span><span class="o">.</span><span class="n">rank</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">dataset</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;batch_size&#34;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="n">num_workers</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;workers&#34;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="n">sampler</span><span class="o">=</span><span class="n">train_sampler</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">worker_init_fn</span><span class="o">=</span><span class="n">worker_init_fn</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Data loader for evaluation</span>
</span></span><span class="line"><span class="cl">    <span class="n">dataset</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;val_split&#34;</span><span class="p">],</span> <span class="n">config</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">val_sampler</span> <span class="o">=</span> <span class="n">DistributedSampler</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">num_replicas</span><span class="o">=</span><span class="n">hvd</span><span class="o">.</span><span class="n">size</span><span class="p">(),</span> <span class="n">rank</span><span class="o">=</span><span class="n">hvd</span><span class="o">.</span><span class="n">rank</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">    <span class="n">val_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">dataset</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">batch_size</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;val_batch_size&#34;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="n">num_workers</span><span class="o">=</span><span class="n">config</span><span class="p">[</span><span class="s2">&#34;val_workers&#34;</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="n">sampler</span><span class="o">=</span><span class="n">val_sampler</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div>]]></description></item><item><title>PyTorch Notes</title><link>https://jianye0428.github.io/posts/pytorchnotes/</link><pubDate>Sat, 15 Jul 2023 18:15:53 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/pytorchnotes/</guid><description><![CDATA[<h2 id="torch-基本函数">Torch 基本函数</h2>
<h3 id="1-torcheinsum">1. <strong><code>torch.einsum()</code></strong></h3>
<p><code>torch.einsum(equation, *operands)-&gt;Tensor</code>:爱因斯坦求和
ref1: 算子部署: <a href="https://blog.csdn.net/HW140701/article/details/120654252"target="_blank" rel="external nofollow noopener noreferrer">https://blog.csdn.net/HW140701/article/details/120654252<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
ref2: 例子: <a href="https://zhuanlan.zhihu.com/p/361209187"target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/361209187<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<p><strong>三条基本规则:</strong></p>
<ul>
<li><strong>规则一:</strong> equation 箭头左边，在不同输入之间<font color=red>重复出现的索引</font>表示，把输入张量沿着该维度做乘法操作，比如还是以上面矩阵乘法为例， &ldquo;ik,kj-&gt;ij&rdquo;，k 在输入中重复出现，所以就是把 a 和 b 沿着 k 这个维度作相乘操作；</li>
<li><strong>规则二:</strong> 只出现在 equation 箭头左边的索引，表示中间计算结果需要在这个维度上求和，也就是上面提到的求和索引；</li>
<li><strong>规则三:</strong> equation 箭头右边的索引顺序可以是任意的，比如上面的 &ldquo;ik,kj-&gt;ij&rdquo; 如果写成 &ldquo;ik,kj-&gt;ji&rdquo;，那么就是返回输出结果的转置，用户只需要定义好索引的顺序，转置操作会在 einsum 内部完成</li>
</ul>
<p><strong>特殊规则:</strong></p>
<ul>
<li>equation 可以不写包括箭头在内的右边部分，那么在这种情况下，输出张量的维度会根据默认规则推导。就是把输入中只出现一次的索引取出来，然后按字母表顺序排列，比如上面的矩阵乘法 &ldquo;ik,kj-&gt;ij&rdquo; 也可以简化为 &ldquo;ik,kj&rdquo;，根据默认规则，输出就是 &ldquo;ij&rdquo; 与原来一样；</li>
<li>equation 中支持 &ldquo;&hellip;&rdquo; 省略号，用于表示用户并不关心的索引。比如只对一个高维张量的最后两维做转置可以这么写：
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-shell" data-lang="shell"><span class="line"><span class="cl"><span class="nv">a</span> <span class="o">=</span> torch.randn<span class="o">(</span>2,3,5,7,9<span class="o">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># i = 7, j = 9</span>
</span></span><span class="line"><span class="cl"><span class="nv">b</span> <span class="o">=</span> torch.einsum<span class="o">(</span><span class="s1">&#39;...ij-&gt;...ji&#39;</span>, <span class="o">[</span>a<span class="o">])</span></span></span></code></pre></td></tr></table>
</div>
</div></li>
</ul>
<h3 id="2-torchpermutetorchtranspose">2. <strong><code>torch.permute()/torch.transpose()</code></strong></h3>
<p><code>torch.permute(dim0, dim1, dim2)</code>:用于调换不同维度的顺序
<code>torch.transpose(input, dim0, dim1)</code>:交换矩阵的两个维度</p>
<h3 id="3-torchrand">3. <strong><code>torch.rand()</code></strong></h3>
<p><code>torch.rand(dim0, dim1)</code>:生成dim0 x dim1的tensor</p>
<h3 id="4-torchsizetorchshape">4. <strong><code>torch.size()/torch.shape</code></strong></h3>
<p><code>torch.size()</code>:返回tensor的size
<code>torch.shape</code>:返回tensor的size</p>
<h3 id="5-torchtensordot">5. <strong><code>torch.tensordot()</code></strong></h3>
<p>ref: tensordot()和einsum()的区别: <a href="https://blog.csdn.net/Eric_1993/article/details/105670381"target="_blank" rel="external nofollow noopener noreferrer">https://blog.csdn.net/Eric_1993/article/details/105670381<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
<code>torch.tensordot(tensor1， tensor2， axes=([dim1,dim2],[dim0, dim1]))</code>: 将axes指定的子数组进行点乘, axes 指定具体的维度.</p>
<h3 id="6-torchtranspose">6. <strong><code>torch.transpose()</code></strong></h3>
<p><code>torch.transpose(tensor, dim0, dim2) —&gt; Tensor</code>:在dim0和dim1方向上转置</p>
<p>###7. <strong><code>torch.index_add_()</code></strong></p>
<p><code> Tensor.index_add_(dim, index, source, *, alpha=1) → Tensor</code></p>
<p>demo:</p>
<div class="highlight" id="id-2"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;&gt;&gt;</span> <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;&gt;&gt;</span> <span class="n">index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">index_add_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">tensor</span><span class="p">([[</span>  <span class="mf">2.</span><span class="p">,</span>   <span class="mf">3.</span><span class="p">,</span>   <span class="mf">4.</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="p">[</span>  <span class="mf">1.</span><span class="p">,</span>   <span class="mf">1.</span><span class="p">,</span>   <span class="mf">1.</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="p">[</span>  <span class="mf">8.</span><span class="p">,</span>   <span class="mf">9.</span><span class="p">,</span>  <span class="mf">10.</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="p">[</span>  <span class="mf">1.</span><span class="p">,</span>   <span class="mf">1.</span><span class="p">,</span>   <span class="mf">1.</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="p">[</span>  <span class="mf">5.</span><span class="p">,</span>   <span class="mf">6.</span><span class="p">,</span>   <span class="mf">7.</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;&gt;&gt;</span> <span class="n">x</span><span class="o">.</span><span class="n">index_add_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">tensor</span><span class="p">([[</span>  <span class="mf">1.</span><span class="p">,</span>   <span class="mf">1.</span><span class="p">,</span>   <span class="mf">1.</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="p">[</span>  <span class="mf">1.</span><span class="p">,</span>   <span class="mf">1.</span><span class="p">,</span>   <span class="mf">1.</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="p">[</span>  <span class="mf">1.</span><span class="p">,</span>   <span class="mf">1.</span><span class="p">,</span>   <span class="mf">1.</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="p">[</span>  <span class="mf">1.</span><span class="p">,</span>   <span class="mf">1.</span><span class="p">,</span>   <span class="mf">1.</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">        <span class="p">[</span>  <span class="mf">1.</span><span class="p">,</span>   <span class="mf">1.</span><span class="p">,</span>   <span class="mf">1.</span><span class="p">]])</span></span></span></code></pre></td></tr></table>
</div>
</div><h2 id="torch-nn-module">Torch NN Module</h2>
<div class="highlight" id="id-3"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">torch</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span></span></span></code></pre></td></tr></table>
</div>
</div><h3 id="1-nnconv1d">1. <strong><code>nn.Conv1d()</code></strong></h3>
<p><code>torch.nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)</code></p>
<p><strong>Shape:</strong>
- Input: $(N, C_{in}, L_{in})$ or $(C_{in}, L_{in})$
- Output: $(N, C_{in}, L_{in})$ or $(C_{in}, L_{in})$, where
$$L_{out} = \frac{L_{in} + 2 \cdot \text{padding} - \text{dilation} \cdot (\text{kernel_size} - 1) - 1}{stride}$$</p>
<p><strong>Demo:</strong></p>
<div class="highlight" id="id-4"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span> <span class="c1"># B x C x H or N x C x L</span>
</span></span><span class="line"><span class="cl"><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="c1"># torch.Size([20, 33, 24])</span></span></span></code></pre></td></tr></table>
</div>
</div><h3 id="2-nnconv2d">2. <strong><code>nn.Conv2d()</code></strong></h3>
<p><code>torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)</code></p>
<p><strong>Shape:</strong></p>
<ul>
<li>Input: $(N, C_{\text in}, H_{\text in}, W_{\text in})$ or $(C_{\text in}, H_{\text in}, W_{\text in})$
- Output: $(N, C_{\text out}, H_{\text out}, W_{\text out})$ or $(C_{\text out}, H_{\text out}, W_{\text out})$, where
$$
H_{out} = \frac{H_{in} + 2 \cdot \text{padding[0]} - \text{dilation[0]} \cdot (\text{kernel_size[0]} - 1) - 1}{stride[0]} + 1
$$
$$
W_{out} = \frac{W_{in} + 2 \cdot \text{padding[1]} - \text{dilation[1]} \cdot (\text{kernel_size[1]} - 1) - 1}{stride[1]} + 1
$$</li>
</ul>
<p><strong>Demo:</strong></p>
<div class="highlight" id="id-5"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl">  <span class="c1"># With square kernels and equal stride</span>
</span></span><span class="line"><span class="cl">  <span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># non-square kernels and unequal stride and with padding</span>
</span></span><span class="line"><span class="cl">  <span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="c1"># output.shape: 20 x 33 x 28 x 100</span>
</span></span><span class="line"><span class="cl">  <span class="c1"># non-square kernels and unequal stride and with padding and dilation</span>
</span></span><span class="line"><span class="cl">  <span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dilation</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="c1"># output.shape: 20 x 33 x 26 x 100</span>
</span></span><span class="line"><span class="cl">  <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="c1">#</span></span></span></code></pre></td></tr></table>
</div>
</div><h3 id="3-nnfunctionalinterpolate">3. <strong><code>nn.functional.interpolate()</code></strong></h3>
<p><code>torch.nn.functional.interpolate(input, size=None, scale_factor=None, mode='nearest', align_corners=None, recompute_scale_factor=None, antialias=False)</code></p>
<h3 id="4-nnfunctionalrelu">4. <strong><code>nn.functional.ReLU()</code></strong></h3>
<p>$$ \text{ReLU} = (x)^+ = \max {(0,x)}$$</p>
<p><code>torch.nn.ReLU(inplace=False)</code></p>
<p><strong>作用:</strong></p>
<ul>
<li>
<p>Sigmoid的导数只有在0附近的时候有比较好的激活性，在正负饱和区的梯度都接近于0，所以这会造成梯度弥散，而ReLU函数在大于0的部分梯度为常数，所以不会产生梯度弥散现象。</p>
</li>
<li>
<p>ReLU函数在负半区的导数为0 ，所以一旦神经元激活值进入负半区，那么梯度就会为0，而正值不变，这种操作被成为单侧抑制。（也就是说：<strong>在输入是负值的情况下，它会输出0，那么神经元就不会被激活。这意味着同一时间只有部分神经元会被激活，从而使得网络很稀疏，进而对计算来说是非常有效率的。</strong>）<u>正因为有了这单侧抑制，才使得神经网络中的神经元也具有了稀疏激活性。</u>尤其体现在深度神经网络模型(如CNN)中，当模型增加N层之后，理论上ReLU神经元的激活率将降低2的N次方倍。</p>
</li>
<li>
<p>relu函数的导数<strong>计算更快</strong>，程序实现就是一个if-else语句，而sigmoid函数要进行浮点四则运算。</p>
</li>
</ul>
<p><strong>Shape:</strong></p>
<ul>
<li>Input: $(∗)$, where $*$ means any number of dimensions.</li>
<li>Output: $(∗)$, same shape as the input.</li>
</ul>
<p></p>
<p><strong>Demo:</strong></p>
<div class="highlight" id="id-6"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># An implementation of CReLU - https://arxiv.org/abs/1603.05201</span>
</span></span><span class="line"><span class="cl"><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">),</span><span class="n">m</span><span class="p">(</span><span class="o">-</span><span class="nb">input</span><span class="p">)))</span></span></span></code></pre></td></tr></table>
</div>
</div><h3 id="5-nnmaxpool2d">5. <strong><code>nn.MaxPool2d()</code></strong></h3>
<p><code>torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)</code></p>
<p><strong>Shape:</strong></p>
<ul>
<li>Input: $(N, C, H_{in}, W_{in})$ or $(C, H_{in}, W_{in})$</li>
<li>Output: $(N, C, H_{out}, W_{out})$ or $(C, H_{out}, W_{out})$</li>
</ul>
<p>where,</p>
<p>$$ H_{out} = \frac{H_{in} + 2 * \text{padding}[0] - \text{dilation}[0] * (\text{kernel_size}[0]-1) - 1}{\text{stride}[0]} + 1$$</p>
<p>$$ W_{out} = \frac{W_{in} + 2 * \text{padding}[1] - \text{dilation}[1] * (\text{kernel_size}[1]-1) - 1}{\text{stride}[1]} + 1$$</p>
<p><strong>demo:</strong></p>
<div class="highlight" id="id-7"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># pool of square window of size=3, stride=2</span>
</span></span><span class="line"><span class="cl"><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># pool of non-square window</span>
</span></span><span class="line"><span class="cl"><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="c1"># 20 16 24 31</span></span></span></code></pre></td></tr></table>
</div>
</div><h3 id="6-nnavgpool2d">6. <strong><code>nn.AvgPool2d()</code></strong></h3>
<div class="highlight" id="id-8"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">torch.nn.AvgPool2d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None)</span></span></code></pre></td></tr></table>
</div>
</div><p><strong>Shape:</strong></p>
<ul>
<li>Input: $(N, C, H_{in}, W_{in})$ or $(C, H_{in}, W_{in})$</li>
<li>Output: $(N, C, H_{out}, W_{out})$ or $(C, H_{out}, W_{out})$</li>
</ul>
<p>where,</p>
<p>$$ H_{out} = \frac{H_{in} + 2 * \text{padding}[0] -  (\text{kernel_size}[0])}{\text{stride}[0]} + 1$$</p>
<p>$$ W_{out} = \frac{W_{in} + 2 * \text{padding}[1] - (\text{kernel_size}[1])}{\text{stride}[1]} + 1$$</p>
<p><strong>demo:</strong></p>
<div class="highlight" id="id-9"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># pool of square window of size=3, stride=2</span>
</span></span><span class="line"><span class="cl"><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># pool of non-square window</span>
</span></span><span class="line"><span class="cl"><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="c1"># 20 16, 24 31</span></span></span></code></pre></td></tr></table>
</div>
</div><h2 id="torchcuda">torch.cuda</h2>
<p>ref link: <a href="https://zhuanlan.zhihu.com/p/76908135"target="_blank" rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/76908135<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
<ol>
<li>
<p><a href="https://pytorch.org/docs/stable/_modules/torch/cuda.html#current_device"target="_blank" rel="external nofollow noopener noreferrer"><code>torch.cuda.current_device()</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>: 返回当前选择的设备的索引</p>
</li>
<li>
<p><a href="https://pytorch.org/docs/stable/_modules/torch/cuda.html#current_stream"target="_blank" rel="external nofollow noopener noreferrer"><code>torch.cuda.current_stream()</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>: 返回参数设备的当前的<a href="https://pytorch.org/docs/stable/cuda.html#torch.cuda.Stream"target="_blank" rel="external nofollow noopener noreferrer">Stream<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</li>
<li>
<p><a href="https://pytorch.org/docs/stable/_modules/torch/cuda.html#current_stream"target="_blank" rel="external nofollow noopener noreferrer"><code>torch.cuda.default_stream()</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>: 返回当前参数设备的<a href="https://pytorch.org/docs/stable/cuda.html#torch.cuda.Stream"target="_blank" rel="external nofollow noopener noreferrer">Stream<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</li>
<li>
<p><em>CLASS</em> <a href="https://pytorch.org/docs/stable/_modules/torch/cuda.html#device"target="_blank" rel="external nofollow noopener noreferrer"><code>torch.cuda.device</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>: 可以改变选择的设备的上下文管理器
Parameters：device (torch.device or int) – device index to select. It’s a no-op if this argument is a negative integer or None.</p>
</li>
<li>
<p><a href="https://pytorch.org/docs/stable/_modules/torch/cuda.html#device_count"target="_blank" rel="external nofollow noopener noreferrer"><code>torch.cuda.device_count()</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>: 返回可使用GPU的数量</p>
</li>
<li>
<p><em>CLASS</em> <a href="https://pytorch.org/docs/stable/_modules/torch/cuda.html#device_of"target="_blank" rel="external nofollow noopener noreferrer"><code>torch.cuda.device_of(obj)</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
Context-manager 将参数对象的设备改成当前的设备。你可以使用张量或者存储作为参数。如果传入的对象没有分配在GPU上，这个操作是无效的。</p>
</li>
<li>
<p><a href="https://pytorch.org/docs/stable/_modules/torch/cuda.html#empty_cache"target="_blank" rel="external nofollow noopener noreferrer"><code>torch.cuda.empty_cache()</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
释放caching allocator当前持有的所有未占用的cached memory，使其可以用在其他GPU应用且可以在 nvidia-smi可视化。</p>
<blockquote>
<blockquote>
<p>注意：<a href="https://pytorch.org/docs/stable/cuda.html#torch.cuda.empty_cache"target="_blank" rel="external nofollow noopener noreferrer">empty_cache()<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> 并不会增加PyTorch可以使用的GPU显存的大小。 查看 <a href="https://pytorch.org/docs/stable/notes/cuda.html#cuda-memory-management"target="_blank" rel="external nofollow noopener noreferrer">Memory management<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a> 来获取更多的GPU显存管理的信息。</p>
</blockquote>
</blockquote>
</li>
<li>
<p><a href="https://pytorch.org/docs/stable/_modules/torch/cuda.html#get_device_capability"target="_blank" rel="external nofollow noopener noreferrer"><code>torch.cuda.get_device_capability(device=None)</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
Gets the cuda capability of a device.</p>
<p>Parameters：device (torch.device or int, optional) – device for which to return the device capability. This function is a no-op if this argument is a negative integer. It uses the current device, given bycurrent_device(), if device is None (default).</p>
<p>Returns：the major and minor cuda capability of the device</p>
<p>Return type ： tuple(int, int)</p>
</li>
<li>
<p><a href="https://pytorch.org/docs/stable/_modules/torch/cuda.html#get_device_name"target="_blank" rel="external nofollow noopener noreferrer"><code>torch.cuda.get_device_name(device=None)</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</li>
<li>
<p><a href="https://pytorch.org/docs/stable/_modules/torch/cuda.html#init"target="_blank" rel="external nofollow noopener noreferrer"><code>torch.cuda.init()</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
初始化PyTorch的CUDA状态。如果你通过C API与PyTorch进行交互，你可能需要显式调用这个方法。只有CUDA的初始化完成，CUDA的功能才会绑定到Python。用户一般不应该需要这个，因为所有PyTorch的CUDA方法都会自动在需要的时候初始化CUDA。如果CUDA的状态已经初始化了，将不起任何作用。</p>
</li>
<li>
<p>[<code>torch.cuda.is_available()</code>]</p>
</li>
<li>
<p><a href="https://pytorch.org/docs/stable/_modules/torch/cuda.html#max_memory_allocated"target="_blank" rel="external nofollow noopener noreferrer"><code>torch.cuda.max_memory_allocated(device=None)</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
Returns the maximum GPU memory occupied by tensors in bytes for a given device.</p>
</li>
<li>
<p><a href="https://pytorch.org/docs/stable/_modules/torch/cuda.html#max_memory_cached"target="_blank" rel="external nofollow noopener noreferrer"><code>torch.cuda.max_memory_cached(device=None)</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</li>
<li>
<p><a href="https://pytorch.org/docs/stable/_modules/torch/cuda.html#memory_allocated"target="_blank" rel="external nofollow noopener noreferrer"><code>torch.cuda.memory_allocated(device=None)</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a>
Parameters：device (torch.device or int, optional) – selected device. Returns statistic for the current device, given by current_device(), if device is None (default).</p>
</li>
<li>
<p><a href="https://pytorch.org/docs/stable/_modules/torch/cuda.html#memory_cached"target="_blank" rel="external nofollow noopener noreferrer"><code>torch.cuda.memory_cached(devide=None)</code><i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a></p>
</li>
<li>
<p>[``]</p>
</li>
</ol>
]]></description></item></channel></rss>