<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Dataset - 标签 - yejian's blog</title><link>https://jianye0428.github.io/tags/dataset/</link><description>Dataset - 标签 - yejian's blog</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>18817571704@163.com (Jian YE)</managingEditor><webMaster>18817571704@163.com (Jian YE)</webMaster><lastBuildDate>Fri, 05 Jan 2024 17:34:44 +0800</lastBuildDate><atom:link href="https://jianye0428.github.io/tags/dataset/" rel="self" type="application/rss+xml"/><item><title>Argoverse 2 数据集</title><link>https://jianye0428.github.io/posts/argoverse2/</link><pubDate>Fri, 05 Jan 2024 17:34:44 +0800</pubDate><author>Jian YE</author><guid>https://jianye0428.github.io/posts/argoverse2/</guid><description><![CDATA[<h2 id="一简介">一、简介</h2>
<p>Argoverse数据集是由Argo AI、卡内基梅隆大学、佐治亚理工学院发布的用于支持自动驾驶汽车3D Tracking和Motion Forecasting研究的数据集。
数据集包括:</p>
<ul>
<li><strong>带标注的传感器数据集:</strong> 含1000个多模态数据序列，包括来自七个环视摄像机和两个双目摄像机的高分辨率图像，以及激光雷达点云和6自由度地图配准位姿。序列包含26个目标类别的三维长方体标注，所有这些标注都是充分采样的，以支持训练和三维感知模型的评估。</li>
<li><strong>激光雷达数据集:</strong> 包含20,000个未标记的激光雷达点云序列和地图配准位姿。该数据集是有史以来最大的激光雷达传感器数据集合，支持自监督学习和新兴的点云预测任务。</li>
<li><strong>运动预测数据集:</strong> 包含250,000个场景，挖掘每个场景中自车与其他参与者之间有趣和具有挑战性的交互。模型的任务是预测每个场景中scored actors的未来运动，并提供跟踪历史，捕捉目标的位置、航向、速度和类别。</li>
</ul>
<p>在所有三个数据集中，每个场景都包含自己的高精地图，带有3D车道和人行横道几何形状&ndash;来自六个不同城市的数据。所有数据集都是在CC BY-NC-SA 4.0许可下发布的。</p>
<h2 id="二argoverse-2-datasets">二、Argoverse 2 Datasets</h2>
<h3 id="21-sensor-dataset-传感器数据集">2.1 Sensor Dataset 传感器数据集</h3>
<p>Argoverse 2传感器数据集是Argoverse 1 3D跟踪数据集的后续。AV2更大，有1000个场景，高于Argoverse 1中的113个，但每个AV2场景也更丰富&ndash;AV2中有23倍的非车辆、非行人长方体。作者手工选择Argoverse 2传感器数据集中的30s组成场景，以包含拥挤的场景，其中包含未被表示的对象、值得注意的天气和有趣的行为，如插队和乱穿马路。每个场景的持续时间为15秒。表1将AV2传感器数据集与自动驾驶数据集进行了比较。图1、2和3显示了AV2的场景在标注范围、目标多样性、目标密度和场景动态性方面如何优于其他数据集。</p>
<p>与本文最相似的传感器数据集是非常有影响力的nuScenes[4]&ndash;这两个数据集都有1000个场景和高清地图，尽管Argoverse在拥有地面高度地图方面是独一无二的。nuScenes包含毫米波雷达数据，而AV2包含双目图像。nuScenes有一个很大的分类学&ndash;23个目标类别，其中10个有适合训练和评估（evaluation）的数据。本文的数据集包含30个目标类别，其中26个被很好地采样，足以用于训练和评估。nuScenes横跨两个城市，而本文的提出的数据集横跨六个城市。</p>
<p><strong>传感器套件。</strong> 激光雷达扫描收集在10赫兹，以及20 fps图像从7个摄像头定位，以提供一个完整的全景视野。此外，还提供了全局坐标系下的摄像机内参、外参和6自由度 ego-vehicle 姿态。激光雷达回波由两个32波束激光雷达捕获，激光雷达在同一方向以10赫兹旋转，但在方向上相隔180°。摄像机触发与两个激光雷达同步，导致20赫兹的帧率。七个全局快门摄像机与激光雷达同步，使它们的曝光集中在激光雷达上，扫描它们的视野。在附录中，本文提供了一个示意图，说明了汽车传感器套件及其坐标框架。</p>
<p><strong>激光雷达同步精度。</strong> 在AV2中，本文改进了摄像机和激光雷达的同步比Argoverse 1明显。本文的同步精度在[-1.39,1.39]ms，与Waymo开放数据集[-6,7]ms[45]相比较。</p>
<p><strong>标注。</strong> AV2传感器数据集包含本文30个类分类法中的对象的10 Hz 3D长方体标注（图1）。长方体的轨道标识符随着时间的推移对于相同的目标实例是一致的。如果对象在“感兴趣区域”(ROI)内&ndash;在映射的“可驾驶”区域的五米内，则对其进行标注。</p>
<p><strong>隐私。</strong> 为了保护隐私，所有的脸和车牌，无论是在车辆内还是在可驾驶区域外，都被广泛模糊。</p>
<p>传感器数据集分割。 本文随机地将数据集划分为700、150和150个场景的训练、验证和测试拆分。</p>
<h3 id="22-lidar-dataset-激光雷达数据集">2.2 Lidar Dataset 激光雷达数据集</h3>
<p>Argoverse 2 激光雷达数据集旨在支持激光雷达域中的自监督学习研究以及点云预测[48,49]。由于激光雷达数据比完整的传感器套件更紧凑，本文可以包括两倍长度的场景（30秒而不是15秒），和更多 （20,000 而不是 1,000），相当于大约40倍的驾驶小时，空间预算是5倍。AV2激光雷达数据集的挖掘标准与预测数据集（第3.3.2节）相同，以确保每个场景都是有趣的。虽然激光雷达数据集没有3D目标标注，但每个场景都带有一张高清地图，其中包含关于场景的丰富的3D信息。</p>
<p>本文的数据集是迄今为止最大的此类集合，有20,000个30秒序列。唯一一个类似的数据集，是同时发布的ONCE[36]，包含1M激光雷达帧，而本文的是6M激光雷达帧。本文的数据集以10 Hz采样，而不是像ONCE[36]中那样以2 Hz采样，使本文的数据集更适合于点云预测或自监督任务，这些任务点云随时间的演变是重要的。</p>
<p><strong>激光雷达数据集分割。</strong> 本文用分别为16,000个、2000个和2000个场景的train、validation和test拆分 随机划分数据集。</p>
<h3 id="23-motion-forecasting-dataset-运动预测数据集">2.3 Motion Forecasting Dataset 运动预测数据集</h3>
<p>运动预测解决了预测局部环境中动态行为者的未来状态（或占用图）的问题。自动驾驶相关行为者的一些例子包括：车辆（停车和移动）、行人、骑自行车的人、滑板车和宠物。由预测系统生成的预测未来被用作运动规划的主要输入，运动规划根据这种预测条件进行轨迹选择。生成这些预测提出了一个复杂的、多模态的问题，涉及许多不同的、部分观察的和社会交互的主体。然而，通过利用观察到的ground truth futures 来“自我标记”数据的能力，运动预测成为机器学习应用的理想领域（ideal domain）。</p>
<p>在Argoverse 1成功的基础上，Argoverse 2运动预测数据集提供了从自动驾驶车队收集的一组更新的预测场景。下面列举的设计决策总结了本文从内部研究/开发中吸取的集体经验教训，以及来自3个竞赛中近260个独特团队提交的2700多份submissions的反馈意见[43]:</p>
<ol>
<li>
<p>运动预测是长尾域中的一个安全关键系统。 因此，本文的数据集偏向于包含不同类型focal agent的不同和有趣的场景（见第3.3.2节）。本文的目标是鼓励开发确保尾部事件（tail events）期间安全的方法，而不是优化“轻松里程”上的预期性能。</p>
</li>
<li>
<p>There is a “Goldilocks zone” of task difficulty. Argoverse1测试集的性能已经开始稳定下来，如附录的图10所示。Argoverse 2的设计是为了增加预测的难度，在未来几年刺激富有成效的重点研究。这些变化旨在激励在扩展预测范围(3s→6s)上表现良好的方法，处理多种类型的动态对象(1→5)，并确保长尾场景的安全性。未来的Argoverse releases可能会通过减少观测窗口和增加预测层位来继续增加问题的难度。</p>
</li>
<li>
<p>可用性很重要。 Argoverse 1受益于一个庞大而活跃的研究社区&ndash;在很大程度上是由于设置和使用的简单性。因此，本文注意确保现有的Argoverse模型可以很容易地移植到Argoverse 2上运行。特别是，本文优先考虑对地图元素的直观访问，鼓励使用车道图作为强优先级的方法。为了提高训练和泛化，所有姿态也被插值和重新采样在精确的10赫兹（Argoverse 1是近似的）。新的数据集包括更少，但更长和更复杂的场景；这确保总的数据集大小保持足够大，可以训练复杂的模型，但足够小，可以方便地访问。</p>
</li>
</ol>
<h3 id="24-hd-maps-高精地图">2.4 HD Maps 高精地图</h3>
<p>上述三个数据集中的每个场景共享相同的HD地图表示。每个场景都带有自己的本地地图区域，类似于Waymo Open Motion[12]数据集。这与最初的Argoverse数据集不同，在最初的数据集中，所有场景都被本地化到两张城市地图上&ndash;一张是匹兹堡的，一张是迈阿密的。在附录中，本文提供了例子。每个场景映射的优点包括更高效的查询和处理映射更改的能力。在本文的数据集中，一个特定的十字路口可能会被观察多次，在此期间车道、人行横道甚至地面高度都可能发生变化。</p>
<p><strong>车道图。</strong> HD地图的核心特征是车道图，由图组成，其中是单个车道段。在附录中，本文列举并定义了本文为每个车道段提供的属性。与Argoverse 1不同，本文提供了实际的3D车道边界，而不仅仅是中心线。但是，本文的API提供了代码，可以在任何期望的采样分辨率下快速推断中心线。折线被量化到1cm分辨率。本文的表示比nuScenes更丰富，它只在2D中提供车道几何，而不是3D。</p>
<p><strong>可驾驶区域。</strong> 而不是像在Argoverse 1中所做的那样，以光栅化格式提供可驾驶区域分割，本文以矢量格式释放它，即作为3D多边形。这提供了多种优势，主要是在压缩方面，允许本文为成千上万的场景存储单独的地图，然而光栅格式仍然很容易衍生。将多边形顶点量化到1cm分辨率。</p>
<p>**地表高度。**只有传感器数据集包括密集的地表高度图（尽管其他数据集仍然有关于折线的稀疏的三维高度信息）。地地面高度为可行驶区域边界5m等值线内的区域提供，本文将其定义为感兴趣区域(ROI)[6]。本文这样做是因为对于建筑物内部和建筑密集的城市街区内部，地面车辆由于遮挡而无法观察的区域，地表高度的概念定义不清(ill-defined)。光栅栅格被量化到30cm分辨率，比Argoverse 1中的1m分辨率更高。</p>
<p>**本地地图的面积。**每个场景的局部地图都包括在ego-vehicle轨迹的l2范数中100米膨胀范围内找到的所有实体。</p>
<h2 id="三argoverse-2-api-简介">三、Argoverse 2 API 简介</h2>
<p>轨迹预测常用的有场景数据<code>ArgoverseScenario</code>和地图<code>ArgoverseStaticMap</code></p>
<p>轨迹序列读取的API为<code>scenario_serialization</code></p>
<p>可视化的API为<code>visualize_scenario</code></p>
<p>argoverse2和argoverse1不一样的地方是，每一段轨迹序列（Scenario）内有自己的json地图文件（虽然说都是同一幅HD map，但是对应HD map中的不同的位置），而argoverse1是所有轨迹序列共享一个地图文件</p>
<div class="highlight" id="id-1"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span><span class="lnt">8
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># 存放轨迹序列的类</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">av2.datasets.motion_forecasting.data_schema</span> <span class="kn">import</span> <span class="n">ArgoverseScenario</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 用于读取轨迹序列的API</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">av2.datasets.motion_forecasting</span> <span class="kn">import</span> <span class="n">scenario_serialization</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 用于可视化的API</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">av2.datasets.motion_forecasting.viz.scenario_visualization</span> <span class="kn">import</span> <span class="n">visualize_scenario</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 用于读取地图的API</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">av2.map.map_api</span> <span class="kn">import</span> <span class="n">ArgoverseStaticMap</span></span></span></code></pre></td></tr></table>
</div>
</div><p><strong>ArgoverseScenario</strong>
每个scenario有11s长的序列，包含actor的历史轨迹集合，就是这里面的tracks，对于每一个scenario，提供了以下的顶层属性:</p>
<ul>
<li><code>scenario_id</code>: 该scenario的特有ID</li>
<li><code>timestamps_ns</code>: 该scenario的所有时间戳</li>
<li><code>tracks</code>: 该scenario的所有轨迹序列</li>
<li><code>focal_track_id</code>: 该scenario的焦点agent(focal agent)的track ID</li>
<li><code>city_name</code>: 该scenario对应的城市名</li>
</ul>
<p>每个<code>track</code>包含以下属性:</p>
<ul>
<li><code>track_id</code>: 该track的特有ID</li>
<li><code>object_states</code>: 该轨迹序列对应的object在这11s内的有效观测的状态，以timestep表示时间步，一般来说最多有110步，因为采样频率为10Hz，一步对应0.1s</li>
<li><code>object_type</code>: 该轨迹序列对应的object的类型，如vehicle等</li>
<li><code>category</code>: 给轨迹序列分配种类，用于给轨迹预测的数据质量提供参考，一般来说，有四种：SCORED_TRACK，UNSCORED_TRACK，FOCAL_TRACK，TRACK_FRAGMENT。其中FOCAL_TRACK和SCORED_TRACK数据质量较好，UNSCORED_TRACK用于当作上下文输入，数据质量一般，而TRACK_FRAGMENT的时间长度不定，数据质量较差
<ul>
<li><code>TRACK_FRAGMENT</code>: Lower quality track that may only contain a few timestamps of observations. 在数据中以整数0表示</li>
<li><code>UNSCORED_TRACK</code>: Unscored track used for contextual input. 在数据中以整数1表示</li>
<li><code>SCORED_TRACK</code>: High-quality tracks relevant to the AV - scored in the multi-agent prediction challenge. 在数据中以整数2表示</li>
<li><code>FOCAL_TRACK</code>: The primary track of interest in a given scenario - scored in the single-agent prediction challenge. 在数据中以整数3表示</li>
</ul>
</li>
</ul>
<p>每个<code>object_states</code>包含以下属性，对应某一actor在某一时间点的所有信息：</p>
<ul>
<li><code>observed</code>: Boolean 指示这个object state是否在该scenario的观测区间内(observed segment)</li>
<li><code>timestep</code>: 时间步，范围是[0, num_scenario_timesteps) Time step corresponding to this object state [0, num_scenario_timesteps).</li>
<li><code>position</code>: (x, y) Coordinates of center of object bounding box. object bounding box的xy坐标</li>
<li><code>heading</code>: Heading associated with object bounding box (in radians, defined w.r.t the map coordinate frame). object bounding box的航向角，单位是弧度，是在地图坐标系下的</li>
<li><code>velocity</code>: (x, y) Instantaneous velocity associated with the object (in m/s). object的xy方向的速度</li>
</ul>
<p>每个track有以下10种label:</p>
<ul>
<li><code>Dynamic</code>
<ul>
<li><code>VEHICLE</code></li>
<li><code>PEDESTRIAN</code></li>
<li><code>MOTORCYCLIST</code></li>
<li><code>CYCLIST</code></li>
<li><code>BUS</code></li>
</ul>
</li>
<li><code>Static</code>
<ul>
<li><code>STATIC</code></li>
<li><code>BACKGROUND</code></li>
<li><code>CONSTRUCTION</code></li>
<li><code>RIDERLESS_BICYCLE</code></li>
</ul>
</li>
<li><code>UNKNOWN</code></li>
</ul>
<p><strong>ArgoverseStaticMap</strong></p>
<ul>
<li>
<p>Vector Map: Lane Graph and Lane Segments</p>
<blockquote>
<p>The core feature of the HD map is the lane graph, consisting of a graph G = (V, E), where V are individual lane segments.</p>
</blockquote>
<p>Argoverse2 提供了3D的道路边界线，而不是仅仅有centerlines，也提供了快速获取特定采样分辨率的centerlines的API，在release中多边形的分辨率被设置为1cm</p>
<p>地图以json文件的形式提供, 可以通过以下方式读取：</p>
<div class="highlight" id="id-2"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">av2.map.map_api</span> <span class="kn">import</span> <span class="n">ArgoverseStaticMap</span>
</span></span><span class="line"><span class="cl"><span class="n">log_map_dirpath</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="s2">&#34;av2&#34;</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&#34;00a6ffc1-6ce9-3bc3-a060-6006e9893a1a&#34;</span> <span class="o">/</span> <span class="s2">&#34;map&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">avm</span> <span class="o">=</span> <span class="n">ArgoverseStaticMap</span><span class="o">.</span><span class="n">from_map_dir</span><span class="p">(</span><span class="n">log_map_dirpath</span><span class="o">=</span><span class="n">log_map_dirpath</span><span class="p">,</span> <span class="n">build_raster</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>
<p>LaneSegment
LaneSegment中包含以下属性：</p>
<ul>
<li><code>id:</code> unique identifier for this lane segment (guaranteed to be unique only within this local map). 该lane segment的特有ID（仅在局部地图中保证是特有的ID）</li>
<li><code>is_intersection:</code> boolean value representing whether or not this lane segment lies within an intersection. boolean value，用来表示该lane segment是否位于一个路口内</li>
<li><code>lane_type:</code> designation of which vehicle types may legally utilize this lane for travel. 表示车道线类型</li>
<li><code>right_lane_boundary:</code> 3d polyline representing the right lane boundary. 3D线条，表示右车道边界线</li>
<li><code>left_lane_boundary:</code> 3d polyline representing the left lane boundary. 3D线条，表示左车道边界线</li>
<li><code>right_mark_type:</code> type of painted marking found along the right lane boundary . 右车道边界线的线型</li>
<li><code>left_mark_type:</code> type of painted marking found along the left lane boundary. 左车道边界线的线型</li>
<li><code>predecessors:</code> unique identifiers of lane segments that are predecessors of this object. 该lane segment的前继lane segment的unique ID</li>
<li><code>successors:</code> unique identifiers of lane segments that represent successor of this object. Note: this list will be empty if no successors exist. 该lane segment的后继lane segment的unique ID</li>
<li><code>right_neighbor_id:</code> unique identifier of the lane segment representing this object’s right neighbor. 该lane segment的右邻lane segment的unique ID</li>
<li><code>left_neighbor_id:</code> unique identifier of the lane segment representing this object’s left neighbor. 该lane segment的左邻lane segment的unique ID</li>
</ul>
</li>
<li>
<p>Vector Map: Drivable Area
多边形向量的分辨率也是1cm, 包含以下属性：</p>
<ul>
<li><code>id:</code> unique identifier. 特有ID</li>
<li><code>area_boundary:</code> 3d vertices of polygon, representing the drivable area’s boundary. 3D多边形，用来表示可行驶区域的边</li>
</ul>
</li>
<li>
<p>Vector Map: Pedestrian Crossings
代表人行道，由两条沿同一主轴的edge构成</p>
<ul>
<li><code>id:</code> unique identifier of pedestrian crossing. 人行道的特有ID</li>
<li><code>edge1:</code> 3d polyline representing one edge of the crosswalk, with 2 waypoints. 3D多边形，代表人行道的其中一边，由2个waypoints组成</li>
<li><code>edge2:</code> 3d polyline representing the other edge of the crosswalk, with 2 - waypoints. 3D多边形，代表人行道的其中一边，由2个waypoints组成</li>
</ul>
</li>
<li>
<p>Area of Local Maps
Each scenario’s local map includes all entities found within a 100 m dilation in l2-norm from the ego-vehicle trajectory.
每个scenario的局部地图包含距离ego-vehicle的轨迹100m l2距离内的所有实体</p>
</li>
</ul>
<p>常用API汇总:</p>
<div class="highlight" id="id-3"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">av2.datasets.motion_forecasting.data_schema</span> <span class="kn">import</span> <span class="n">ArgoverseScenario</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">av2.datasets.motion_forecasting</span> <span class="kn">import</span> <span class="n">scenario_serialization</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">av2.datasets.motion_forecasting.viz.scenario_visualization</span> <span class="kn">import</span> <span class="n">visualize_scenario</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">av2.map.map_api</span> <span class="kn">import</span> <span class="n">ArgoverseStaticMap</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">av2.map.map_primitives</span> <span class="kn">import</span> <span class="n">Polyline</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">av2.utils.io</span> <span class="kn">import</span> <span class="n">read_json_file</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 利用pandas读取轨迹序列parquet文件</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_parquet文件</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_dir</span><span class="p">,</span> <span class="n">raw_file_name</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;scenario_</span><span class="si">{</span><span class="n">raw_file_name</span><span class="si">}</span><span class="s1">.parquet&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 加载地图json文件</span>
</span></span><span class="line"><span class="cl"><span class="n">map_data</span> <span class="o">=</span> <span class="n">read_json_file</span><span class="p">(</span><span class="n">map_path</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 从地图的json文件读取车道中心线</span>
</span></span><span class="line"><span class="cl"><span class="n">centerlines</span> <span class="o">=</span> <span class="p">{</span><span class="n">lane_segment</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]:</span> <span class="n">Polyline</span><span class="o">.</span><span class="n">from_json_data</span><span class="p">(</span><span class="n">lane_segment</span><span class="p">[</span><span class="s1">&#39;centerline&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">                           <span class="k">for</span> <span class="n">lane_segment</span> <span class="ow">in</span> <span class="n">map_data</span><span class="p">[</span><span class="s1">&#39;lane_segments&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">()}</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 加载地图API</span>
</span></span><span class="line"><span class="cl"><span class="n">map_api</span> <span class="o">=</span> <span class="n">ArgoverseStaticMap</span><span class="o">.</span><span class="n">from_json</span><span class="p">(</span><span class="n">map_path</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 以某个query中心搜索附近一定半径的的lane_segments</span>
</span></span><span class="line"><span class="cl"><span class="n">query_center</span> <span class="o">=</span> <span class="n">scenario_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;position_x&#39;</span><span class="p">,</span> <span class="s1">&#39;position_y&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>
</span></span><span class="line"><span class="cl"><span class="n">search_radius_m</span> <span class="o">=</span> <span class="mi">30</span>
</span></span><span class="line"><span class="cl"><span class="n">nearby_lane_segments</span> <span class="o">=</span> <span class="n">map_api</span><span class="o">.</span><span class="n">get_nearby_lane_segments</span><span class="p">(</span><span class="n">query_center</span><span class="p">,</span> <span class="n">search_radius_m</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 通过map_api获取lane_segments的车道中心线</span>
</span></span><span class="line"><span class="cl"><span class="n">nearby_lane_centerlines</span> <span class="o">=</span> <span class="n">get_lane_centerlines</span><span class="p">(</span><span class="n">map_api</span><span class="p">,</span> <span class="n">nearby_lane_segments</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 获取地图内的所有pedestrian crossings（目前av2 API没有提供获取附近pedestrian crossings的API）</span>
</span></span><span class="line"><span class="cl"><span class="n">crosswalks</span> <span class="o">=</span> <span class="n">map_api</span><span class="o">.</span><span class="n">get_scenario_ped_crossings</span><span class="p">()</span></span></span></code></pre></td></tr></table>
</div>
</div><h2 id="四argoverse-2-数据提取">四、Argoverse 2 数据提取</h2>
<p>raw_dir 文件夹内包含<code>.parquet</code>和<code>.json</code>文件，其中文件组织形式为<code>log_map_archive_{$scenario_name}.parquet</code>和<code>scenario_{$scenario_name}.json</code>，分别代表<strong>障碍物时序信息</strong>和<strong>地图信息</strong>。</p>
<ul>
<li>设置原始数据路径:
<div class="highlight" id="id-4"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">raw_dir</span> <span class="o">=</span> <span class="s2">&#34;/home/yejian/yejian_personal/QCNet/train/&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">raw_file_name</span> <span class="o">=</span> <span class="s2">&#34;ffffe3df-8d26-42c3-9e7a-59de044736a0&#34;</span></span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>读取障碍物信息和地图信息
<div class="highlight" id="id-5"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">parquet_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">raw_dir</span><span class="p">,</span> <span class="n">raw_file_name</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;scenario_</span><span class="si">{</span><span class="n">raw_file_name</span><span class="si">}</span><span class="s1">.parquet&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;parquet_file: </span><span class="si">{</span><span class="n">parquet_file</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span> <span class="c1"># 障碍物信息</span>
</span></span><span class="line"><span class="cl"><span class="n">map_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">raw_dir</span><span class="p">,</span> <span class="n">raw_file_name</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;log_map_archive_</span><span class="si">{</span><span class="n">raw_file_name</span><span class="si">}</span><span class="s1">.json&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&#34;map_file: </span><span class="si">{</span><span class="n">map_file</span><span class="si">}</span><span class="s2">&#34;</span><span class="p">)</span><span class="c1"># 地图信息</span>
</span></span><span class="line"><span class="cl"><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_from_parquet</span><span class="p">(</span><span class="n">parquet_file</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">map_file</span> <span class="o">=</span> <span class="n">read_json_file</span><span class="p">(</span><span class="n">map_file</span><span class="p">)</span></span></span></code></pre></td></tr></table>
</div>
</div></li>
<li>查看障碍物信息文件内容
<div class="highlight" id="id-6"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span></span></span></code></pre></td></tr></table>
</div>
</div><code>['observed', 'track_id', 'object_type', 'object_category', 'timestep', 'position_x', 'position_y', 'heading', 'velocity_x', 'velocity_y', 'scenario_id', 'start_timestamp', 'end_timestamp', 'num_timestamps', 'focal_track_id', 'city']</code></li>
</ul>
<h2 id="reference">Reference</h2>
<p>[1]. <a href="https://blog.csdn.net/Yong_Qi2015/article/details/128731798"target="_blank" rel="external nofollow noopener noreferrer">https://blog.csdn.net/Yong_Qi2015/article/details/128731798<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a><br>
[2]. <a href="https://blog.csdn.net/m0_56423263/article/details/134593815"target="_blank" rel="external nofollow noopener noreferrer">https://blog.csdn.net/m0_56423263/article/details/134593815<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden="true"></i></a><br></p>
]]></description></item></channel></rss>