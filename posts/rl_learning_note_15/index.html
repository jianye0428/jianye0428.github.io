<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=2"><meta name=robots content="noodp"><title>强化学习笔记 [15] | A3C - yejian's blog</title><meta name=author content="Jian YE">
<meta name=author-link content="https://github.com/jianye0428"><meta name=description content="0. 引言 在强化学习(十四) Actor-Critic中，我们讨论了Actor-Critic的算法流程，但是由于普通的Actor-Critic算法难以收敛，需要一些其他的优化。而Asynchronous Advantage Actor-critic(以下简称A3C)就是其中比较好的优化算法。本文我们讨论A3C的算法原理和算法"><meta name=keywords content='RL'><meta itemprop=name content="强化学习笔记 [15] | A3C"><meta itemprop=description content="0. 引言 在强化学习(十四) Actor-Critic中，我们讨论了Actor-Critic的算法流程，但是由于普通的Actor-Critic算法难以收敛，需要一些其他的优化。而Asynchronous Advantage Actor-critic(以下简称A3C)就是其中比较好的优化算法。本文我们讨论A3C的算法原理和算法"><meta itemprop=datePublished content="2024-02-25T15:36:01+08:00"><meta itemprop=dateModified content="2024-02-25T21:12:29+08:00"><meta itemprop=wordCount content="3439"><meta itemprop=image content="https://jianye0428.github.io/images/favicon/jian_icon.png"><meta itemprop=keywords content="RL,"><meta property="og:title" content="强化学习笔记 [15] | A3C"><meta property="og:description" content="0. 引言 在强化学习(十四) Actor-Critic中，我们讨论了Actor-Critic的算法流程，但是由于普通的Actor-Critic算法难以收敛，需要一些其他的优化。而Asynchronous Advantage Actor-critic(以下简称A3C)就是其中比较好的优化算法。本文我们讨论A3C的算法原理和算法"><meta property="og:type" content="article"><meta property="og:url" content="https://jianye0428.github.io/posts/rl_learning_note_15/"><meta property="og:image" content="https://jianye0428.github.io/images/favicon/jian_icon.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-02-25T15:36:01+08:00"><meta property="article:modified_time" content="2024-02-25T21:12:29+08:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jianye0428.github.io/images/favicon/jian_icon.png"><meta name=twitter:title content="强化学习笔记 [15] | A3C"><meta name=twitter:description content="0. 引言 在强化学习(十四) Actor-Critic中，我们讨论了Actor-Critic的算法流程，但是由于普通的Actor-Critic算法难以收敛，需要一些其他的优化。而Asynchronous Advantage Actor-critic(以下简称A3C)就是其中比较好的优化算法。本文我们讨论A3C的算法原理和算法"><meta name=application-name content="菠菜阿九时代峰峻啊；数量可根据；"><meta name=apple-mobile-web-app-title content="菠菜阿九时代峰峻啊；数量可根据；"><meta name=theme-color data-light=#ffffff data-dark=#252627 content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/png href=/jian_icon.png><link rel=icon type=image/png sizes=32x32 href=/jian_icon.png><link rel=icon type=image/png sizes=16x16 href=/jian_icon.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://jianye0428.github.io/posts/rl_learning_note_15/><link rel=prev href=https://jianye0428.github.io/posts/rl_learning_note_14/><link rel=next href=https://jianye0428.github.io/posts/rl_learning_note_16/><link rel=stylesheet href=/css/style.min.css><link rel=stylesheet href=/lib/fontawesome-free/all.min.css><link rel=stylesheet href=/lib/animate/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"强化学习笔记 [15] | A3C","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/jianye0428.github.io\/posts\/rl_learning_note_15\/"},"image":["https:\/\/jianye0428.github.io\/images\/favicon\/jian_icon.png"],"genre":"posts","keywords":"RL","wordcount":3439,"url":"https:\/\/jianye0428.github.io\/posts\/rl_learning_note_15\/","datePublished":"2024-02-25T15:36:01+08:00","dateModified":"2024-02-25T21:12:29+08:00","publisher":{"@type":"Organization","name":"Jian YE","logo":"https:\/\/jianye0428.github.io\/images\/favicon\/jian_icon.png"},"author":{"@type":"Person","name":"Jian YE"},"description":""}</script></head><body data-header-desktop=sticky data-header-mobile=auto><script>(window.localStorage?.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("data-theme","dark")</script><div class=wrapper data-page-style=wide><header class="desktop animate__faster" id=header-desktop><div class=header-wrapper data-github-corner=right><div class=header-title><a href=/ title="yejian's blog"><img loading=lazy src=/images/favicon/jian_icon.png srcset="/images/favicon/jian_icon.png, /images/favicon/jian_icon.png 1.5x, /images/favicon/jian_icon.png 2x" sizes=auto data-title="yejian's blog" data-alt="yejian's blog" class=logo style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span class=header-title-text>Jian's Blog</span></a><span class=header-subtitle></span></div><nav><ul class=menu><li class=menu-item><a class=menu-link href=/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> 所有文章</a></li><li class=menu-item><a class=menu-link href=/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> 分类</a></li><li class=menu-item><a class=menu-link href=/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> 标签</a></li><li class=menu-item><a class=menu-link href=/friends/ title=友情链接><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden=true></i> 友链</a></li><li class=menu-item><a class=menu-link href=/guestbook/><i class="fa-solid fa-comments fa-fw fa-sm" aria-hidden=true></i> 留言</a></li><li class="menu-item has-children"><a class=menu-link href=/about/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 关于</a><i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden=true></i><ul class=sub-menu><li class=menu-item><a class=menu-link href=/projects/_index.zh-tw/ title=項目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的項目</a></li><li class=menu-item><a class=menu-link href=/projects/ title=项目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的项目</a></li></ul></li><li class=menu-item><a class=menu-link href=/pilot/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 导航</a></li><li class="menu-item delimiter"></li><li class="menu-item search" id=search-desktop><input type=text placeholder=搜索文章标题或内容…… id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></li><li class="menu-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></li></ul></nav></div></header><header class="mobile animate__faster" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="yejian's blog"><img loading=lazy src=/images/favicon/jian_icon.png srcset="/images/favicon/jian_icon.png, /images/favicon/jian_icon.png 1.5x, /images/favicon/jian_icon.png 2x" sizes=auto data-title=/images/favicon/jian_icon.png data-alt=/images/favicon/jian_icon.png class=logo style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span class=header-title-text>Jian's Blog</span></a><span class=header-subtitle></span></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><nav><ul class=menu id=menu-mobile><li class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索文章标题或内容…… id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></li><li class=menu-item><a class=menu-link href=/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> 所有文章</a></li><li class=menu-item><a class=menu-link href=/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> 分类</a></li><li class=menu-item><a class=menu-link href=/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> 标签</a></li><li class=menu-item><a class=menu-link href=/friends/ title=友情链接><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden=true></i> 友链</a></li><li class=menu-item><a class=menu-link href=/guestbook/><i class="fa-solid fa-comments fa-fw fa-sm" aria-hidden=true></i> 留言</a></li><li class=menu-item><span class=nested-item><a class=menu-link href=/about/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 关于</a>
<i class="dropdown-icon fa-solid fa-chevron-right" aria-hidden=true></i></span><ul class=sub-menu><li class=menu-item><a class=menu-link href=/projects/_index.zh-tw/ title=項目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的項目</a></li><li class=menu-item><a class=menu-link href=/projects/ title=项目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的项目</a></li></ul></li><li class=menu-item><a class=menu-link href=/pilot/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 导航</a></li><li class="menu-item text-center"><a class=menu-link href=https://github.com/jianye0428/ title=GitHub rel="noopener noreferrer" target=_blank><i class='fa-brands fa-github fa-fw' aria-hidden=true></i></a></li><li class="menu-item menu-system"><span class="menu-system-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></span></li></ul></nav></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class="container container-reverse"><aside class=toc id=toc-auto></aside><aside class=aside-custom></aside><article class="page single"><div class=header><h1 class="single-title animate__animated animate__flipInX"><span>强化学习笔记 [15] | A3C</span></h1></div><div class=post-meta><div class=post-meta-line><span class=post-author><a href=https://github.com/jianye0428 title=作者 target=_blank rel="external nofollow noopener noreferrer author" class=author><img loading=lazy src="https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp" srcset="https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp, https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp 1.5x, https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp 2x" sizes=auto data-title="Jian YE" data-alt="Jian YE" class=avatar style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'>&nbsp;Jian YE</a></span>
<span class=post-category>收录于 <a href=/categories/rl/><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> RL</a></span></div><div class=post-meta-line><span title="发布于 2024-02-25 15:36:01"><i class="fa-regular fa-calendar-alt fa-fw me-1" aria-hidden=true></i><time datetime=2024-02-25>2024-02-25</time></span>&nbsp;<span title="更新于 2024-02-25 21:12:29"><i class="fa-regular fa-edit fa-fw me-1" aria-hidden=true></i><time datetime=2024-02-25>2024-02-25</time></span>&nbsp;<span><i class="fa-solid fa-pencil-alt fa-fw me-1" aria-hidden=true></i>约 3439 字</span>&nbsp;<span><i class="fa-regular fa-clock fa-fw me-1" aria-hidden=true></i>预计阅读 7 分钟</span>&nbsp;<span id=busuanzi_container_page_pv class="busuanzi_visitors comment-visitors" data-flag-title="强化学习笔记 [15] | A3C">
<i class="fa-regular fa-eye fa-fw me-1" aria-hidden=true></i><span id=busuanzi_value_page_pv>-</span>&nbsp;次阅读
</span>&nbsp;</div></div><div class=content id=content data-end-flag=（完）><h1 id=0-引言>0. 引言</h1><p>在<a href=https://www.cnblogs.com/pinard/p/10272023.html target=_blank rel="external nofollow noopener noreferrer">强化学习(十四) Actor-Critic<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>中，我们讨论了Actor-Critic的算法流程，但是由于普通的Actor-Critic算法难以收敛，需要一些其他的优化。而Asynchronous Advantage Actor-critic(以下简称A3C)就是其中比较好的优化算法。本文我们讨论A3C的算法原理和算法流程。</p><p>本文主要参考了A3C的<a href=http://proceedings.mlr.press/v48/mniha16.pdf target=_blank rel="external nofollow noopener noreferrer">论文<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>，以及ICML 2016的<a href=https://icml.cc/2016/tutorials/deep_rl_tutorial.pdf target=_blank rel="external nofollow noopener noreferrer">deep RL tutorial<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>。</p><h1 id=1-a3c的引入>1. A3C的引入</h1><p>上一篇Actor-Critic算法的代码，其实很难收敛，无论怎么调参，最后的CartPole都很难稳定在200分，这是Actor-Critic算法的问题。但是我们还是有办法去有优化这个难以收敛的问题的。</p><p>回忆下之前的DQN算法，为了方便收敛使用了经验回放的技巧。那么我们的Actor-Critic是不是也可以使用经验回放的技巧呢？当然可以！不过A3C更进一步，还克服了一些经验回放的问题。经验回放有什么问题呢？ 回放池经验数据相关性太强，用于训练的时候效果很可能不佳。举个例子，我们学习下棋，总是和同一个人下，期望能提高棋艺。这当然没有问题，但是到一定程度就再难提高了，此时最好的方法是另寻高手切磋。</p><p>A3C的思路也是如此，它<font color=green>利用多线程的方法，同时在多个线程里面分别和环境进行交互学习，每个线程都把学习的成果汇总起来，整理保存在一个公共的地方</font>。并且，定期从公共的地方把大家的齐心学习的成果拿回来，指导自己和环境后面的学习交互。</p><p>通过这种方法，A3C避免了经验回放相关性过强的问题，同时做到了异步并发的学习模型。</p><h1 id=2-a3c的算法优化>2. A3C的算法优化</h1><p>现在我们来看看相比Actor-Critic，A3C到底做了哪些具体的优化。</p><p>相比Actor-Critic，A3C的优化主要有3点，分别是异步训练框架，网络结构优化，Critic评估点的优化。其中异步训练框架是最大的优化。</p><p>我们首先来看这个异步训练框架，如下图所示：</p><br><center><img src=images/2_01.jpg width=640 height=320 align=center style="border-radius:.3125em;box-shadow:0 2px 4px rgba(34,36,38,.12),0 2px 10px rgba(34,36,38,8%)"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">异步训练框架</div></center><br><p>图中上面的Global Network就是上一节说的共享的公共部分，主要是一个公共的神经网络模型，这个神经网络包括Actor网络和Critic网络两部分的功能。下面有n个worker线程，每个线程里有和公共的神经网络一样的网络结构，每个线程会独立的和环境进行交互得到经验数据，这些线程之间互不干扰，独立运行。</p><p>每个线程和环境交互到一定量的数据后，就计算在自己线程里的神经网络损失函数的梯度，但是这些梯度却并不更新自己线程里的神经网络，而是去更新公共的神经网络。也就是n个线程会独立的使用累积的梯度分别更新公共部分的神经网络模型参数。每隔一段时间，线程会将自己的神经网络的参数更新为公共神经网络的参数，进而指导后面的环境交互。</p><p>可见，公共部分的网络模型就是我们要学习的模型，而线程里的网络模型主要是用于和环境交互使用的，这些线程里的模型可以帮助线程更好的和环境交互，拿到高质量的数据帮助模型更快收敛。</p><p>现在我们来看看第二个优化，网络结构的优化。之前在<a href=https://www.cnblogs.com/pinard/p/10272023.html target=_blank rel="external nofollow noopener noreferrer">强化学习(十四) Actor-Critic<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>中，我们使用了两个不同的网络Actor和Critic。在A3C这里，我们把两个网络放到了一起，即输入状态 $S$,可以输出状态价值 $V$,和对应的策略 $π$, 当然，我们仍然可以把Actor和Critic看做独立的两块，分别处理，如下图所示：</p><br><center><img src=images/2_02.jpg width=640 height=180 align=center style="border-radius:.3125em;box-shadow:0 2px 4px rgba(34,36,38,.12),0 2px 10px rgba(34,36,38,8%)"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">把Actor和Critic看做独立的两块，分别处理</div></center><br><p>第三个优化点是Critic评估点的优化，在<a href=https://www.cnblogs.com/pinard/p/10272023.html target=_blank rel="external nofollow noopener noreferrer">强化学习(十四) Actor-Critic<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>第2节中，我们讨论了不同的Critic评估点的选择，其中d部分讲到了使用优势函数 $A$ 来做Critic评估点，优势函数 $A$ 在时刻t不考虑参数的默认表达式为：</p><p>$$A(S,A,t)=Q(S,A)-V(S)$$</p><p>$Q(S,A)$的值一般可以通过单步采样近似估计，即：</p><p>$$Q(S,A)=R+\gamma V(S^{\prime})$$</p><p>这样优势函数去掉动作可以表达为：</p><p>$$A(S,t)=R+\gamma V(S^{\prime})-V(S)$$</p><p>其中 $V(S)$的值需要通过Critic网络来学习得到。</p><p>在A3C中，采样更进一步，使用了N步采样，以加速收敛。这样A3C中使用的优势函数表达为：</p><p>$$A(S,t)=R_t++\gamma R_{t+1}+\ldots\gamma^{n-1}R_{t+n-1}+\gamma^nV(S^{\prime})-V(S)$$</p><p>对于Actor和Critic的损失函数部分，和Actor-Critic基本相同。有一个小的优化点就是在Actor-Critic策略函数的损失函数中，加入了策略 $π$ 的熵项,系数为 $c$, 即策略参数的梯度更新和Actor-Critic相比变成了这样：</p><p>$$\theta=\theta+\alpha\nabla_\theta log\pi_\theta(s_t,a_t)A(S,t)+c\nabla_\theta H(\pi(S_t,\theta))$$</p><p>以上就是A3C和Actor-Critic相比有优化的部分。下面我们来总价下A3C的算法流程。</p><h1 id=3-a3c算法流程>3. A3C算法流程</h1><p>这里我们对A3C算法流程做一个总结，由于A3C是异步多线程的，我们这里给出任意一个线程的算法流程。</p><ul><li><p>输入：公共部分的A3C神经网络结构，对应参数位 $θ$ , $w$，本线程的A3C神经网络结构，对应参数 $θ&rsquo;$, $w&rsquo;$, 全局共享的迭代轮数 $T$，全局最大迭代次数 $T_{max}$, 线程内单次迭代时间序列最大长度 $T_{local}$,状态特征维度 $n$, 动作集 $A$, 步长 $α$, $β$，熵系数 $c$, 衰减因子 $γ$</p></li><li><p>输出：公共部分的A3C神经网络参数 $θ$, $w$</p><ul><li>(1). 更新时间序列 $t=1$</li><li>(2). 重置Actor和Critic的梯度更新量: $dθ←0$,$dw←0$</li><li>(3). 从公共部分的A3C神经网络同步参数到本线程的神经网络：$θ&rsquo;=θ,w&rsquo;=w$</li><li>(4). $t_{start}=t$，初始化状态 $s_t$</li><li>(5). 基于策略 $π(at|st;θ)$ 选择出动作 $a_t$</li><li>(6). 执行动作 $a_t$得到奖励 $r_t$ 和新状态 $s_{t+1}$</li><li>(7). $t←t+1$, $T←T+1$</li><li>(8). 如果 $s_t$是终止状态，或 $t − t_{start}==t_{local}$,则进入步骤(9)，否则回到步骤(5)</li><li>(9). 计算最后一个时间序列位置 $s_t$的 $Q(s,t)$:<ul><li>$$\left.Q(s,t)=\left\{\begin{array}{ll}0&amp;terminal~state\\V(s_t,w^{\prime})&amp;none~terminal~state,bootstrapping\end{array}\right.\right.$$</li></ul></li><li>(10). for $i∈(t−1,t−2,&mldr;t_{start})$:<ul><li>1). 计算每个时刻的$Q(s,i)$： $Q(s,i)=r_i+\gamma Q(s,i+1)$</li><li>2). 累计Actor的本地梯度更新：<ul><li>$$d\theta\leftarrow d\theta+\nabla_{\theta^{\prime}}log\pi_{\theta^{\prime}}(s_i,a_i)(Q(s,i)-V(S_i,w^{\prime}))+c\nabla_{\theta^{\prime}}H(\pi(s_i,\theta^{\prime}))$$</li></ul></li><li>3). 累计Critic的本地梯度更新：<ul><li>$$\begin{aligned}dw&\leftarrow dw+\frac{\partial(Q(s,i)-V(S_i,w^{\prime}))^2}{\partial w^{\prime}}\end{aligned}$$</li></ul></li></ul></li><li>(11). 更新全局神经网络的模型参数：<ul><li>$$\theta=\theta+\alpha d\theta,~w=w-\beta dw$$</li></ul></li><li>(12). 如果 $T>T_{max}$,则算法结束，输出公共部分的A3C神经网络参数 $θ$, $w$,否则进入步骤(3)</li></ul></li></ul><p>以上就是A3C算法单个线程的算法流程。</p><h1 id=4-a3c算法实例>4. A3C算法实例</h1><p>下面我们基于上述算法流程给出A3C算法实例。仍然使用了OpenAI Gym中的CartPole-v0游戏来作为我们算法应用。CartPole-v0游戏的介绍参见<a href=https://github.com/openai/gym/wiki/CartPole-v0 target=_blank rel="external nofollow noopener noreferrer">这里<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>。它比较简单，基本要求就是控制下面的cart移动使连接在上面的pole保持垂直不倒。这个任务只有两个离散动作，要么向左用力，要么向右用力。而state状态就是这个cart的位置和速度， pole的角度和角速度，4维的特征。坚持到200分的奖励则为过关。</p><p>算法代码大部分参考了莫烦的<a href=https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/blob/master/contents/10_A3C/A3C_discrete_action.py target=_blank rel="external nofollow noopener noreferrer">A3C代码<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>，增加了模型测试部分的代码并调整了部分模型参数。完整的代码参见我的Github：https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/a3c.py</p><p>整个算法的Actor和Critic的网络结构都定义在这里， 所有的线程中的网络结构，公共部分的网络结构都在这里定义。</p><div class=highlight id=id-1><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>_build_net</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>scope</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=n>w_init</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>random_normal_initializer</span><span class=p>(</span><span class=mf>0.</span><span class=p>,</span> <span class=mf>.1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=k>with</span> <span class=n>tf</span><span class=o>.</span><span class=n>variable_scope</span><span class=p>(</span><span class=s1>&#39;actor&#39;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>l_a</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>dense</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>s</span><span class=p>,</span> <span class=mi>200</span><span class=p>,</span> <span class=n>tf</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>relu6</span><span class=p>,</span> <span class=n>kernel_initializer</span><span class=o>=</span><span class=n>w_init</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=s1>&#39;la&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>a_prob</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>dense</span><span class=p>(</span><span class=n>l_a</span><span class=p>,</span> <span class=n>N_A</span><span class=p>,</span> <span class=n>tf</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>softmax</span><span class=p>,</span> <span class=n>kernel_initializer</span><span class=o>=</span><span class=n>w_init</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=s1>&#39;ap&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=k>with</span> <span class=n>tf</span><span class=o>.</span><span class=n>variable_scope</span><span class=p>(</span><span class=s1>&#39;critic&#39;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>l_c</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>dense</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>s</span><span class=p>,</span> <span class=mi>100</span><span class=p>,</span> <span class=n>tf</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>relu6</span><span class=p>,</span> <span class=n>kernel_initializer</span><span class=o>=</span><span class=n>w_init</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=s1>&#39;lc&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>v</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>layers</span><span class=o>.</span><span class=n>dense</span><span class=p>(</span><span class=n>l_c</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>kernel_initializer</span><span class=o>=</span><span class=n>w_init</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=s1>&#39;v&#39;</span><span class=p>)</span>  <span class=c1># state value</span>
</span></span><span class=line><span class=cl>  <span class=n>a_params</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>get_collection</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>GraphKeys</span><span class=o>.</span><span class=n>TRAINABLE_VARIABLES</span><span class=p>,</span> <span class=n>scope</span><span class=o>=</span><span class=n>scope</span> <span class=o>+</span> <span class=s1>&#39;/actor&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>c_params</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>get_collection</span><span class=p>(</span><span class=n>tf</span><span class=o>.</span><span class=n>GraphKeys</span><span class=o>.</span><span class=n>TRAINABLE_VARIABLES</span><span class=p>,</span> <span class=n>scope</span><span class=o>=</span><span class=n>scope</span> <span class=o>+</span> <span class=s1>&#39;/critic&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>a_prob</span><span class=p>,</span> <span class=n>v</span><span class=p>,</span> <span class=n>a_params</span><span class=p>,</span> <span class=n>c_params</span></span></span></code></pre></td></tr></table></div></div><p>所有线程初始化部分，以及本线程和公共的网络结构初始化部分如下：</p><div class=highlight id=id-2><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>with</span> <span class=n>tf</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s2>&#34;/cpu:0&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=n>OPT_A</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>train</span><span class=o>.</span><span class=n>RMSPropOptimizer</span><span class=p>(</span><span class=n>LR_A</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=s1>&#39;RMSPropA&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>OPT_C</span> <span class=o>=</span> <span class=n>tf</span><span class=o>.</span><span class=n>train</span><span class=o>.</span><span class=n>RMSPropOptimizer</span><span class=p>(</span><span class=n>LR_C</span><span class=p>,</span> <span class=n>name</span><span class=o>=</span><span class=s1>&#39;RMSPropC&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>GLOBAL_AC</span> <span class=o>=</span> <span class=n>ACNet</span><span class=p>(</span><span class=n>GLOBAL_NET_SCOPE</span><span class=p>)</span>  <span class=c1># we only need its params</span>
</span></span><span class=line><span class=cl>  <span class=n>workers</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>  <span class=c1># Create worker</span>
</span></span><span class=line><span class=cl>  <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>N_WORKERS</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>i_name</span> <span class=o>=</span> <span class=s1>&#39;W_</span><span class=si>%i</span><span class=s1>&#39;</span> <span class=o>%</span> <span class=n>i</span>   <span class=c1># worker name</span>
</span></span><span class=line><span class=cl>    <span class=n>workers</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>Worker</span><span class=p>(</span><span class=n>i_name</span><span class=p>,</span> <span class=n>GLOBAL_AC</span><span class=p>))</span></span></span></code></pre></td></tr></table></div></div><p>本线程神经网络将本地的梯度更新量用于更新公共网络参数的逻辑在update_global函数中，而从公共网络把参数拉回到本线程神经网络的逻辑在pull_global中。</p><div class=highlight id=id-3><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>update_global</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>feed_dict</span><span class=p>):</span>  <span class=c1># run by a local</span>
</span></span><span class=line><span class=cl>  <span class=n>SESS</span><span class=o>.</span><span class=n>run</span><span class=p>([</span><span class=bp>self</span><span class=o>.</span><span class=n>update_a_op</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>update_c_op</span><span class=p>],</span> <span class=n>feed_dict</span><span class=p>)</span>  <span class=c1># local grads applies to global net</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>pull_global</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>  <span class=c1># run by a local</span>
</span></span><span class=line><span class=cl>  <span class=n>SESS</span><span class=o>.</span><span class=n>run</span><span class=p>([</span><span class=bp>self</span><span class=o>.</span><span class=n>pull_a_params_op</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>pull_c_params_op</span><span class=p>])</span></span></span></code></pre></td></tr></table></div></div><p>详细的内容大家可以对照代码和算法流程一起看。在主函数里我新加了一个测试模型效果的过程，大家可以试试看看最后的模型效果如何。</p><h1 id=5-a3c小结>5. A3C小结</h1><p>A3C解决了Actor-Critic难以收敛的问题，同时更重要的是，提供了一种通用的异步的并发的强化学习框架，也就是说，这个并发框架不光可以用于A3C，还可以用于其他的强化学习算法。这是A3C最大的贡献。目前，已经有基于GPU的A3C框架，这样A3C的框架训练速度就更快了。</p><p>除了A3C, DDPG算法也可以改善Actor-Critic难收敛的问题。它使用了Nature DQN，DDQN类似的思想，用两个Actor网络，两个Critic网络，一共4个神经网络来迭代更新模型参数。在下一篇我们讨论DDPG算法。</p></div><div class=post-reward><div class=comment>Buy me a coffee~</div><input type=checkbox class=reward-input name=reward id=fi-reward hidden>
<label class=reward-button for=fi-reward>赞赏</label><div class=reward-ways data-mode=fixed><div><img loading=lazy src=/images/alipay.png srcset="/images/alipay.png, /images/alipay.png 1.5x, /images/alipay.png 2x" sizes=auto data-title="Jian YE 支付宝" data-alt="Jian YE 支付宝" style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span data-animation>支付宝</span></div><div><img loading=lazy src=/images/wechatpay.png srcset="/images/wechatpay.png, /images/wechatpay.png 1.5x, /images/wechatpay.png 2x" sizes=auto data-title="Jian YE 微信" data-alt="Jian YE 微信" style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span data-animation>微信</span></div></div></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span title="更新于 2024-02-25 21:12:29">更新于 2024-02-25&nbsp;<a class=git-hash href=https://github.com/jianye0428/JianBlog/commit/23cd7c478708235ece71456fee411313e37ef46b rel="external nofollow noopener noreferrer" target=_blank title="commit by yejian(18817571704@163.com) 23cd7c478708235ece71456fee411313e37ef46b: feat: add rl learning note to 19"><i class="fa-solid fa-hashtag fa-fw" aria-hidden=true></i>23cd7c4</a></span></div></div><div class=post-info-line><div class=post-info-md><span><a href=/posts/rl_learning_note_15/index.md title=阅读原始文档 class=link-to-markdown>阅读原始文档</a></span><span><a href=https://github.com/jianye0428/JianBlog/edit/docs/content/posts/RL/RL_Learning_Notes/rl_learning_note_15/index.md title=编辑此页 target=_blank rel="external nofollow noopener noreferrer" class=link-to-edit>编辑此页</a></span></div><div class=post-info-share><span><a href=javascript:void(0); title="分享到 Twitter" data-sharer=twitter data-url=https://jianye0428.github.io/posts/rl_learning_note_15/ data-title="强化学习笔记 [15] | A3C" data-hashtags=RL><i class="fa-brands fa-twitter fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 Facebook" data-sharer=facebook data-url=https://jianye0428.github.io/posts/rl_learning_note_15/ data-hashtag=RL><i class="fa-brands fa-facebook-square fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 Linkedin" data-sharer=linkedin data-url=https://jianye0428.github.io/posts/rl_learning_note_15/><i class="fa-brands fa-linkedin fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 微博" data-sharer=weibo data-url=https://jianye0428.github.io/posts/rl_learning_note_15/ data-title="强化学习笔记 [15] | A3C"><i class="fa-brands fa-weibo fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 百度" data-sharer=baidu data-url=https://jianye0428.github.io/posts/rl_learning_note_15/ data-title="强化学习笔记 [15] | A3C"><i data-svg-src=/lib/simple-icons/icons/baidu.min.svg aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fa-solid fa-tags fa-fw me-1" aria-hidden=true></i><a href=/tags/rl/ class=post-tag>RL</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class=post-nav><a href=/posts/rl_learning_note_14/ class=post-nav-item rel=prev title="强化学习笔记 [14] | Actor-Critic"><i class="fa-solid fa-angle-left fa-fw" aria-hidden=true></i>强化学习笔记 [14] | Actor-Critic</a>
<a href=/posts/rl_learning_note_16/ class=post-nav-item rel=next title="强化学习笔记 [16] | 深度确定性策略梯度(DDPG)">强化学习笔记 [16] | 深度确定性策略梯度(DDPG)<i class="fa-solid fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article></main><footer class=footer><div class=footer-container><div class="footer-line powered">由 <a href=https://gohugo.io/ target=_blank rel="external nofollow noopener noreferrer" title="Hugo 0.123.6">Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/hugo-fixit/FixIt target=_blank rel=external title="FixIt v0.2.18"><img class=fixit-icon src=/fixit.min.svg alt="FixIt logo">&nbsp;FixIt</a></div><div class="footer-line copyright" itemscope itemtype=http://schema.org/CreativeWork><i class="fa-regular fa-copyright fa-fw" aria-hidden=true></i>
<span itemprop=copyrightYear>2018 - 2024</span><span class=author itemprop=copyrightHolder>
<a href=https://github.com/jianye0428 target=_blank rel="external nofollow noopener noreferrer">Jian YE</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div><div class="footer-line statistics order-first"><span class=site-time title=网站运行中……><i class="fa-solid fa-heartbeat fa-fw animate-icon" aria-hidden=true></i><span class="ms-1 d-none">博客已运行</span><span class="run-times ms-1">网站运行中……</span></span></div><div class="footer-line visitor"><span id=busuanzi_container_site_uv title=总访客数><i class="fa-regular fa-user fa-fw" aria-hidden=true></i>&nbsp;<span id=busuanzi_value_site_uv><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden=true></i></span></span><span id=busuanzi_container_site_pv class=footer-divider title=总访问量><i class="fa-regular fa-eye fa-fw" aria-hidden=true></i>&nbsp;<span id=busuanzi_value_site_pv><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden=true></i></span></span></div></div></footer></div><div class=widgets><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role=button aria-label=回到顶部><i class="fa-solid fa-arrow-up fa-fw" aria-hidden=true></i><span class=variant-numeric>0%</span></div></div><a href=https://github.com/jianye0428/JianBlog title="在 GitHub 上查看程式碼，訂閱請點 Watch" target=_blank rel="external nofollow" class="github-corner right d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115h15l12 27L250 250V0z"/><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentcolor" style="transform-origin:130px 106px" class="octo-arm"/><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4l13.9-13.8C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8z" fill="currentcolor" class="octo-body"/></svg></a><div id=mask></div><div class=reading-progress-bar style=left:0;top:0;--bg-progress:#000;--bg-progress-dark:#fff></div><noscript><div class=noscript-warning>FixIt 主题在启用 JavaScript 的情况下效果最佳。</div></noscript></div><link rel=stylesheet href=/lib/katex/katex.min.css><link rel=stylesheet href=/lib/cookieconsent/cookieconsent.min.css><link rel=stylesheet href=/lib/pace/themes/blue/pace-theme-minimal.css><script src=/lib/autocomplete/autocomplete.min.js defer></script><script src=/lib/algoliasearch/algoliasearch-lite.umd.min.js defer></script><script src=/lib/instant-page/instantpage.min.js async defer type=module></script><script src=/lib/twemoji/twemoji.min.js defer></script><script src=/lib/sharer/sharer.min.js async defer></script><script src=/lib/katex/katex.min.js defer></script><script src=/lib/katex/auto-render.min.js defer></script><script src=/lib/katex/mhchem.min.js defer></script><script src=/lib/cookieconsent/cookieconsent.min.js defer></script><script src=/lib/pangu/pangu.min.js defer></script><script src=/lib/cell-watermark/watermark.min.js defer></script><script src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js async defer></script><script src=/lib/pace/pace.min.js async defer></script><script>window.config={autoBookmark:!0,code:{copyTitle:"复制到剪贴板",editLockTitle:"锁定可编辑代码块",editUnLockTitle:"解锁可编辑代码块",editable:!0,maxShownLines:50},comment:{enable:!1},cookieconsent:{content:{dismiss:"同意",link:"了解更多",message:"本网站使用 Cookies 来改善您的浏览体验。"},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},enablePWA:!0,math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},pangu:{enable:!0,selector:"article"},search:{algoliaAppID:"MTJNHU0JVB",algoliaIndex:"index",algoliaSearchKey:"5486225134d99f43826da401ee9bad57",highlightTag:"em",maxResultLength:10,noResultsFound:"没有找到结果",snippetLength:50,type:"algolia"},siteTime:"2018-05-28T20:01:01+08:00",twemoji:!0,watermark:{appendto:".wrapper>main",colspacing:30,content:'<img style="height: 0.85rem;" src="/images/favicon/jian_icon.png" alt="logo" /> jianye',enable:!0,fontfamily:"MMT_LRH,沐目体",fontsize:1.1,height:20,opacity:.0125,rotate:15,rowspacing:60,width:150}}</script><script src=/js/theme.min.js defer></script><script src=/js/custom.min.js defer></script></body></html>