<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=2"><meta name=robots content="noodp"><title>生成对抗网络GAN - yejian's blog</title><meta name=author content="Jian YE">
<meta name=author-link content="https://github.com/jianye0428"><meta name=description content><meta name=keywords content='GAN'><meta itemprop=name content="生成对抗网络GAN"><meta itemprop=description content><meta itemprop=datePublished content="2023-07-26T10:03:45+08:00"><meta itemprop=dateModified content="2023-07-27T20:06:28+08:00"><meta itemprop=wordCount content="8437"><meta itemprop=image content="https://jianye0428.github.io/images/favicon/jian_icon.png"><meta itemprop=keywords content="GAN"><meta property="og:url" content="https://jianye0428.github.io/posts/gan_1/"><meta property="og:site_name" content="yejian's blog"><meta property="og:title" content="生成对抗网络GAN"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-07-26T10:03:45+08:00"><meta property="article:modified_time" content="2023-07-27T20:06:28+08:00"><meta property="article:tag" content="GAN"><meta property="og:image" content="https://jianye0428.github.io/images/favicon/jian_icon.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jianye0428.github.io/images/favicon/jian_icon.png"><meta name=twitter:title content="生成对抗网络GAN"><meta name=twitter:description content><meta name=application-name content="菠菜阿九时代峰峻啊；数量可根据；"><meta name=apple-mobile-web-app-title content="菠菜阿九时代峰峻啊；数量可根据；"><meta name=theme-color data-light=#ffffff data-dark=#252627 content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/png href=/jian_icon.png><link rel=icon type=image/png sizes=32x32 href=/jian_icon.png><link rel=icon type=image/png sizes=16x16 href=/jian_icon.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://jianye0428.github.io/posts/gan_1/><link rel=prev href=https://jianye0428.github.io/posts/transformerdetailedexplanation/><link rel=next href=https://jianye0428.github.io/posts/clause_7/><link rel=stylesheet href=/css/style.min.css><link rel=stylesheet href=/lib/fontawesome-free/all.min.css><link rel=stylesheet href=/lib/animate/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"生成对抗网络GAN","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/jianye0428.github.io\/posts\/gan_1\/"},"image":["https:\/\/jianye0428.github.io\/images\/favicon\/jian_icon.png"],"genre":"posts","keywords":"GAN","wordcount":8437,"url":"https:\/\/jianye0428.github.io\/posts\/gan_1\/","datePublished":"2023-07-26T10:03:45+08:00","dateModified":"2023-07-27T20:06:28+08:00","publisher":{"@type":"Organization","name":"Jian YE","logo":"https:\/\/jianye0428.github.io\/images\/favicon\/jian_icon.png"},"author":{"@type":"Person","name":"Jian YE"},"description":""}</script></head><body data-header-desktop=sticky data-header-mobile=auto><script>(window.localStorage?.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("data-theme","dark")</script><div class=wrapper data-page-style=normal><header class="desktop animate__faster" id=header-desktop><div class=header-wrapper data-github-corner=right><div class=header-title><a href=/ title="yejian's blog"><img loading=lazy src=/images/favicon/jian_icon.png srcset="/images/favicon/jian_icon.png, /images/favicon/jian_icon.png 1.5x, /images/favicon/jian_icon.png 2x" sizes=auto data-title="yejian's blog" data-alt="yejian's blog" class=logo style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span class=header-title-text>Jian's Blog</span></a><span class=header-subtitle></span></div><nav><ul class=menu><li class=menu-item><a class=menu-link href=/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> 所有文章</a></li><li class=menu-item><a class=menu-link href=/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> 分类</a></li><li class=menu-item><a class=menu-link href=/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> 标签</a></li><li class=menu-item><a class=menu-link href=/friends/ title=友情链接><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden=true></i> 友链</a></li><li class=menu-item><a class=menu-link href=/guestbook/><i class="fa-solid fa-comments fa-fw fa-sm" aria-hidden=true></i> 留言</a></li><li class="menu-item has-children"><a class=menu-link href=/about/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 关于</a><i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden=true></i><ul class=sub-menu><li class=menu-item><a class=menu-link href=/projects/_index.zh-tw/ title=項目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的項目</a></li><li class=menu-item><a class=menu-link href=/projects/ title=项目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的项目</a></li></ul></li><li class=menu-item><a class=menu-link href=/pilot/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 导航</a></li><li class="menu-item delimiter"></li><li class="menu-item search" id=search-desktop><input type=text placeholder=搜索文章标题或内容…… id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></li><li class="menu-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></li></ul></nav></div></header><header class="mobile animate__faster" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="yejian's blog"><img loading=lazy src=/images/favicon/jian_icon.png srcset="/images/favicon/jian_icon.png, /images/favicon/jian_icon.png 1.5x, /images/favicon/jian_icon.png 2x" sizes=auto data-title=/images/favicon/jian_icon.png data-alt=/images/favicon/jian_icon.png class=logo style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span class=header-title-text>Jian's Blog</span></a><span class=header-subtitle></span></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><nav><ul class=menu id=menu-mobile><li class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索文章标题或内容…… id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></li><li class=menu-item><a class=menu-link href=/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> 所有文章</a></li><li class=menu-item><a class=menu-link href=/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> 分类</a></li><li class=menu-item><a class=menu-link href=/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> 标签</a></li><li class=menu-item><a class=menu-link href=/friends/ title=友情链接><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden=true></i> 友链</a></li><li class=menu-item><a class=menu-link href=/guestbook/><i class="fa-solid fa-comments fa-fw fa-sm" aria-hidden=true></i> 留言</a></li><li class=menu-item><span class=nested-item><a class=menu-link href=/about/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 关于</a>
<i class="dropdown-icon fa-solid fa-chevron-right" aria-hidden=true></i></span><ul class=sub-menu><li class=menu-item><a class=menu-link href=/projects/_index.zh-tw/ title=項目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的項目</a></li><li class=menu-item><a class=menu-link href=/projects/ title=项目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的项目</a></li></ul></li><li class=menu-item><a class=menu-link href=/pilot/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 导航</a></li><li class="menu-item text-center"><a class=menu-link href=https://github.com/jianye0428/ title=GitHub rel="noopener noreferrer" target=_blank><i class='fa-brands fa-github fa-fw' aria-hidden=true></i></a></li><li class="menu-item menu-system"><span class="menu-system-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></span></li></ul></nav></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class="container container-reverse"><aside class=toc id=toc-auto><h2 class=toc-title>目录&nbsp;<i class="toc-icon fa-solid fa-angle-down fa-fw" aria-hidden=true></i></h2><div class=toc-content id=toc-content-auto></div></aside><aside class=aside-custom></aside><article class="page single"><div class=header><h1 class="single-title animate__animated animate__flipInX"><span>生成对抗网络GAN</span></h1></div><div class=post-meta><div class=post-meta-line><span class=post-author><a href=https://github.com/jianye0428 title=作者 target=_blank rel="external nofollow noopener noreferrer author" class=author><img loading=lazy src="https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp" srcset="https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp, https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp 1.5x, https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp 2x" sizes=auto data-title="Jian YE" data-alt="Jian YE" class=avatar style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'>&nbsp;Jian YE</a></span>
<span class=post-category>收录于 <a href=/categories/ml/><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> ML</a></span></div><div class=post-meta-line><span title="发布于 2023-07-26 10:03:45"><i class="fa-regular fa-calendar-alt fa-fw me-1" aria-hidden=true></i><time datetime=2023-07-26>2023-07-26</time></span>&nbsp;<span title="更新于 2023-07-27 20:06:28"><i class="fa-regular fa-edit fa-fw me-1" aria-hidden=true></i><time datetime=2023-07-27>2023-07-27</time></span>&nbsp;<span><i class="fa-solid fa-pencil-alt fa-fw me-1" aria-hidden=true></i>约 8437 字</span>&nbsp;<span><i class="fa-regular fa-clock fa-fw me-1" aria-hidden=true></i>预计阅读 17 分钟</span>&nbsp;<span id=busuanzi_container_page_pv class="busuanzi_visitors comment-visitors" data-flag-title=生成对抗网络GAN>
<i class="fa-regular fa-eye fa-fw me-1" aria-hidden=true></i><span id=busuanzi_value_page_pv>-</span>&nbsp;次阅读
</span>&nbsp;</div></div><div class="details toc" id=toc-static data-kept=false><div class="details-summary toc-title"><span>目录</span>
<span><i class="details-icon fa-solid fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#一gan的引入>一、GAN的引入</a></li><li><a href=#二gan的应用举例>二、GAN的应用举例</a></li><li><a href=#三gan的快速概述>三、GAN的快速概述</a></li><li><a href=#四原文的摘要>四、原文的摘要</a></li><li><a href=#五原文的例子>五、原文的例子</a></li><li><a href=#六gan模型结构--训练gan的目的>六、GAN模型结构 & 训练GAN的目的</a></li><li><a href=#七举例理解gan的原理>七、举例理解GAN的原理</a></li><li><a href=#八数学描述>八、数学描述</a><ul><li><a href=#81-相关符号>8.1 相关符号</a></li><li><a href=#82高专家的目标函数>8.2、“高专家”的目标函数</a></li><li><a href=#83高大师的目标函数>8.3、“高大师”的目标函数</a></li><li><a href=#84总目标函数>8.4、总目标函数</a></li></ul></li><li><a href=#九全局最优解推导>九、全局最优解推导</a><ul><li><a href=#91关于-d-的最大值>9.1、关于 D 的最大值</a></li><li><a href=#92-关于-g-的最小值>9.2 关于 G 的最小值</a></li></ul></li><li><a href=#十原文给出的训练步骤>十、原文给出的训练步骤</a></li><li><a href=#十一gan原理及训练过程总结>十一、GAN原理及训练过程总结</a><ul><li><a href=#111gan原理总结>11.1、GAN原理总结</a></li><li><a href=#112gan算法流程总结>11.2、GAN算法流程总结</a></li></ul></li><li><a href=#十二torch复现>十二、torch复现</a></li></ul></nav></div></div><div class=content id=content data-end-flag=（完）><div class="details admonition warning open"><div class="details-summary admonition-title"><i class="icon fa-solid fa-exclamation-triangle fa-fw" aria-hidden=true></i>警告<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class=details-content><div class=admonition-content>本文最后更新于 2023-07-27，文中内容可能已过时。</div></div></div><h2 id=一gan的引入>一、GAN的引入</h2><p><img loading=lazy src=images/GAN_1.png srcset="/posts/gan_1/images/GAN_1.png, images/GAN_1.png 1.5x, /posts/gan_1/images/GAN_1.png 2x" sizes=auto data-title=init data-alt=init width=1080 height=353 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>GAN（Generative Adversarial Networks）是一种无监督的深度学习模型，提出于2014年，被誉为“近年来复杂分布上无监督学习最具前景的方法之一”。</p><div class="details admonition quote"><div class="details-summary admonition-title"><i class="icon fa-solid fa-quote-right fa-fw" aria-hidden=true></i>quote<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class=details-content><div class=admonition-content><p>Yann Lecun对其的评价是：对抗式训练是迄今为止最酷的一件事情。</p><p>Adversarial training is the coolest thing since sliced bread.</p></div></div></div><p>我们来看下原文的标题：</p><ul><li>Generative：我们知道机器学习模型有两大类，第一个是分辨模型：对于一个数据去分辨它的类别，或者是预测一个实数值；另一类是生成模型，意思是怎么样生成这个数据本身。显然GAN是属于生成模型。</li><li>Adversarial：对抗的，这里指的是GAN提出的这种 framework 采用对抗训练的方式来work。</li><li>Nets：Network的简写。</li></ul><h2 id=二gan的应用举例>二、GAN的应用举例</h2><ul><li>数据生成：生成一些假的图像数据，比如海报中的人脸、文本生成图像等；</br></li><li>数据增强：从分割图生成假的真实街景，比如可以方便训练无人汽车等；</br></li><li>风格化和艺术的图像创造：比如转换图像风格、AI换脸、修补图像等；</br></li><li>声音的转换：比如一个人的声音转为另一个的声音、去除噪声等；</br></li><li>&mldr;&mldr;</br></li></ul><h2 id=三gan的快速概述>三、GAN的快速概述</h2><p>比如人脸检测、图像识别、语音识别等，<strong>机器总是在现有事物的基础上，做出描述和判断</strong>。能不能创造这个世界不存在的东西？</p><p>GAN就是为此而来，它包含三个部分：<strong>生成</strong>、<strong>判别</strong>、<strong>对抗</strong>。其中 <u>生成</u> 和 <u>判别</u> 是它的结构组成，<u>对抗</u>则是它的训练过程。</p><ul><li>生成：<strong>生成</strong> 和 <strong>判别</strong> 指的是两个独立的模型，生成器会根据随机向量产生假数据，这些假数据既可以是图片、也可以是文本，并<strong>试图</strong><font color=red>欺骗判别网络</font>；</li><li>判别：<strong>判别器</strong>负责判断接受到的数据是否是真实的，即对生成数据进行<font color=red>真伪鉴别</font>，试图正确识别所有假数据，它其实是一个二分类问题，会给出一个概率，代表着内容的真实程度；两者使用哪种网络并没有明确的规定，所以原文中作者称其为framework。比如可以使用擅长处理图片的CNN、常见的全连接等等，只要能够完成相应的功能就可以了。</li><li>对抗：这指的是 GAN 的交替训练过程。以图片生成为例，先让<font color=green><strong>生成器</strong></font>产生一些假图片，和收集到的真图片一起交给辨别器，让它学习区分两者，给真的高分，给假的低分，当判别器能够熟练判断现有数据后；再让 <font color=green><strong>生成器</strong></font> 以从 <font color=green><strong>判别器</strong></font> 处获得高分为目标，不断生成更好的假图片，直到能骗过判别器，重复进行这个过程，直到辨别器对任何图片的预测概率都接近0.5，也就是无法分辨图片的真假，就停止训练。</li></ul><p>也就是说在训练迭代的过程中，两个网络持续地进化和对抗，直到到达一个平衡状态，即判别网络无法识别真假。虽说是对抗，但是生成器和辨别器的关系更像是朋友，最初大家都是“无名之辈”，随着不断的训练“切磋”，共同成为“一代高手”。</p><p>我们<font color=red><strong>训练GAN的最终目标</strong></font>是获得好用的生成器，也就是生成足够以假乱真的内容，能完成类似功能的还有波尔斯曼机、变分自编码器等，它们被称为生成模型。</p><h2 id=四原文的摘要>四、原文的摘要</h2><p><img loading=lazy src=images/GAN_2.png srcset="/posts/gan_1/images/GAN_2.png, images/GAN_2.png 1.5x, /posts/gan_1/images/GAN_2.png 2x" sizes=auto data-title=abstract data-alt=abstract width=1080 height=567 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><div class="details admonition quote"><div class="details-summary admonition-title"><i class="icon fa-solid fa-quote-right fa-fw" aria-hidden=true></i>quote<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class=details-content><div class=admonition-content>到底什么是GAN？</div></div></div><p>首先作者提出一个新的framework，通过一个<strong>对抗过程</strong>来估计一个生成模型。</p><p>同时会训练两个模型：</p><ul><li>第一个模型叫做 <mark><strong>生成模型G</strong></mark>，用来捕获整个数据的分布，其实就是通过 <font color=red>生成器</font> 去拟合和逼近真实的数据分布；</li><li>第二个是 <mark><strong>辨别模型D</strong></mark>，它是用来估计一个样本是来自真正的数据、还是来自于<strong>G</strong>生成的。</li></ul><div class="details admonition Note open"><div class="details-summary admonition-title"><i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden=true></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class=details-content><div class=admonition-content>这里稍微解释一下：<strong>生成模型</strong> 它就是对整个数据的分布进行建模，使得能够生成各种分布。这里“分布”是一个很一般化的词，比如生成图片、生成文本、生成视频等。在统计学眼里，整个世界是通过采样不同的分布来得到的，所以想要生成东西，目的就是要抓住整个数据的一个分布。</div></div></div><p>生成模型的任务是尽量的想<strong>让辨别模型犯错</strong>，这个过程是一个<strong>最大最小的博弈</strong>。在任何函数空间的<strong>G</strong>和<strong>D</strong>里面，存在一个独一无二的解，这个解是代表：<strong>G</strong>能够找出训练数据的真实分布（生成的数据分布趋向于真实数据分布），此时辨别器就判别不出来了，所以概率值为$\frac{1}{2}$。</p><p>如果<strong>G</strong>和<strong>D</strong>是一个MLP的话，那么整个系统就可以通过误差反向传播来进行训练。作者说这里不需要使用任何的马尔科夫链，或者说是对一个近似的推理过程展开（说白了意思好像就是和别人的方法比比较简单一点），最后就是说实验的效果非常好。</p><h2 id=五原文的例子>五、原文的例子</h2><p><img loading=lazy src=images/GAN_3.png srcset="/posts/gan_1/images/GAN_3.png, images/GAN_3.png 1.5x, /posts/gan_1/images/GAN_3.png 2x" sizes=auto data-title=example data-alt=example width=1080 height=213 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>在对抗网络的框架里有两类模型：一个是<mark><strong>生成模型</strong></mark>、一个是<mark><strong>判别模型</strong></mark>：</p><ul><li>生成模型比喻成造假的人，它要去产生假币；</li><li>判别模型比喻成警察，警察的任务就是很好的鉴别假币和真币；</li></ul><p>造假者和警察会不断的学习，造假者会提升自己的造假技能，警察也会提升自己判别真币和假币的性能。最后希望造假者能够赢，就是说造的假钱和真钱一模一样，然后警察没有能力去区分真币和假币，那么这个时候就可以使用生成器生成和真实数据一样的数据了。</p><h2 id=六gan模型结构--训练gan的目的>六、GAN模型结构 & 训练GAN的目的</h2><p>摘要说的已经很清楚了，GAN由两部分组成：</p><ul><li>生成器G（Generator）；</li><li>判别器D（Discriminator）；</li></ul><p>我们的最终目的是希望生成器<strong>G</strong>，能够<font color=purple>学习到样本的真实分布$P_{\text{data}}(x)$</font>，那么就能生成之前不存在的、但是却又很真实的样本。</p><p>那再啰嗦的说明白一点就是：</p><ul><li>我们把随机向量（随机噪声）定义为 $z$，$z \in F$，可以是任意分布，比如正态分布、均匀分布。</li><li>将随机噪声输入到 <strong>生成器G</strong> 中，<strong>G</strong>其实看成一个函数就可以，它可以是任意的一个神经网络，因为神经网络可以逼近任何形式的函数。</li><li>随机噪声 $z$ 经过<strong>生成器G</strong>后会产生一个 $G(z)$，生成的这个新的向量 $G(z)$，它可以记为服从$P_G(x)$。但是$P_G(x)$这个分布不是我们想要的，我们想要的是<strong>生成器G</strong>生成一个满足于真实分布$P_{\text{data}}(x)$的数据。</li><li>通过不断的训练迭代，更新调整生成器G的参数，使得$P_G(x)$近似于 $P_{\text{data}}(x)$。</li></ul><p>通过调整 <strong>生成器G</strong> 的参数，使得<font color=violet>它生成的分布和真实的分布尽可能的像</font>，这个就是最终要达到的目的，可以通过 生成器G 生成一些满足真实分布，但又不是真实存在的数据。</p><p>我们以手写数字识别为例，图例如下：</p><p><img loading=lazy src=images/GAN_4.png srcset="/posts/gan_1/images/GAN_4.png, images/GAN_4.png 1.5x, /posts/gan_1/images/GAN_4.png 2x" sizes=auto data-title=/posts/gan_1/images/GAN_4.png data-alt=/posts/gan_1/images/GAN_4.png width=1080 height=742 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>GAN模型结构图如下示例：</p><p><img loading=lazy src=images/GAN_5.png srcset="/posts/gan_1/images/GAN_5.png, images/GAN_5.png 1.5x, /posts/gan_1/images/GAN_5.png 2x" sizes=auto data-title=/posts/gan_1/images/GAN_5.png data-alt=/posts/gan_1/images/GAN_5.png width=1080 height=300 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><ul><li>我们将随机噪声输入到<strong>生成器G</strong>中，产生 $G(z)$，我们把它叫做$x_{\text{fake}}$，$x_{\text{fake}}$为生成的图片，就是假的图片；</li><li>我们还有满足于真实分布$P_{\text{data}}(x)$的数据，记为$x_{\text{real}}$；</li><li>我们把 $x_{\text{real}}$ 和 $x_{\text{fake}}$ 同时送到<strong>判别器D</strong>中去训练，做一个二分类任务，判断是真还是假；</li></ul><h2 id=七举例理解gan的原理>七、举例理解GAN的原理</h2><div class="details admonition Note open"><div class="details-summary admonition-title"><i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden=true></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class=details-content><div class=admonition-content>因为原文举的例子比较敏感，我们以李宏毅老师的例子（中央电视台鉴宝节目：一槌定音）来进行GAN原理的阐述。</div></div></div><p><img loading=lazy src=images/GAN_6.png srcset="/posts/gan_1/images/GAN_6.png, images/GAN_6.png 1.5x, /posts/gan_1/images/GAN_6.png 2x" sizes=auto data-title=/posts/gan_1/images/GAN_6.png data-alt=/posts/gan_1/images/GAN_6.png width=1080 height=515 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>假设现在有一个人，我们称它为小王，小王是一个收藏家，它的收藏室里收藏了很多“国宝”。但是小王不想只做一个收藏家，他还想高仿这些“国宝”，我们这里将高仿的赝品定义为“工艺品”。</p><p>基于GAN的目标，我们知道：</p><ul><li>小王最终想成为一个水平很高的“工艺品大师”；</li></ul><p>但是如果想成为一个“工艺品”方面的专家，小王自己在家闭门造车肯定是行不通的，因为我们的总目标是想让小王成为一个高水平的、可以以假乱真的工艺品大师。为了达到这个目标，首先需要一个高水平的鉴赏专家（高水平的对手），其次小王本身就要是个高水平的工艺品大师。所以小王还需要找一个水平很高的国宝鉴赏专家。鉴赏专家负责辨别出真的“国宝”和小王的“工艺品”，小王负责高仿生产“工艺品”。</p><p><img loading=lazy src=images/GAN_7.png srcset="/posts/gan_1/images/GAN_7.png, images/GAN_7.png 1.5x, /posts/gan_1/images/GAN_7.png 2x" sizes=auto data-title=/posts/gan_1/images/GAN_7.png data-alt=/posts/gan_1/images/GAN_7.png width=1080 height=503 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>概述来说：<strong>小王需要先有一个高水平的专家，然后才可能成为一个高水平的大师。高水平的专家可以看成一种手段，成为高水平的大师才是我们的目标。</strong></p><h2 id=八数学描述>八、数学描述</h2><h3 id=81-相关符号>8.1 相关符号</h3><p>基于上述鉴宝例子，我们来看一下GAN的数学描述，首先需要强调的是：</p><ul><li>工艺品经过鉴赏专家判断后，是会受到一个 feedback 的；</li><li>对于鉴赏专家而言，它也会从工艺品受到一个 feedback ，当然这是潜在的；</li></ul><p>我们就来看一下，这个例子如何用数学符号去表示：</p><ul><li><p>&ldquo;国宝"是静态的，它相当于我们的真实样本 ${x_{\text{real}<em>i}}^N</em>{i=1}$ ，这里我们以 $P_{data}$ 表示；</p></li><li><p>工艺品也是从一个概率分布里抽样出来的，我们将工艺品记作 ${x_{\text{fake}<em>i}}^N</em>{i=1}$ ，我们把这个概率分布称作 $P_g(x;\theta_{g})$，g就代表Generator的意思；</p><div class="details admonition Note open"><div class="details-summary admonition-title"><i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden=true></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class=details-content><div class=admonition-content>注意我们并不直接对 $P_g$ 建模，即不直接对生成模型本身进行建模，我们用一个神经网络去逼近这个分布，纯粹的神经网络它是不具备随机性的，所以我们会假设它有一个 $z$，就是前面提到的随机噪声，是来自于一个简单的分布，比如高斯分布： $z \sim P_Z(z)$ ；</div></div></div></li><li><p>原始的GAN里，神经网络就用NN表示，它本身就是一个确定性变换，即是一个复杂函数，表示为 $G(z;\theta_{g})$；</p><div class="details admonition Note open"><div class="details-summary admonition-title"><i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden=true></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class=details-content><div class=admonition-content>$\theta_g$ 在NN里就是表示权重参数，在 $P_g$ 里就是代表概率分布参数。</div></div></div></li><li><p>鉴赏专家也可以看成一个概率分布，我们也用一个NN来描述它：$D(x; \theta_{d})$，代表 $x$ 是国宝的概率</p></li></ul><p><img loading=lazy src=images/GAN_8.png srcset="/posts/gan_1/images/GAN_8.png, images/GAN_8.png 1.5x, /posts/gan_1/images/GAN_8.png 2x" sizes=auto data-title=/posts/gan_1/images/GAN_8.png data-alt=/posts/gan_1/images/GAN_8.png width=1080 height=398 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>对于鉴赏专家 <strong>(判别器D)</strong> 接收到的来说：</p><ul><li>可以是来自国宝、也可以是来自于工艺品，是无所谓的，重要的是本身是代表是国宝的概率。</li></ul><p>对于判别器D的输出来说：</p><ul><li>$D(x)$ 的值越趋近于1，说明它是国宝的概率就越大；越趋近于0，说明它是工艺品的概率就越大。</li></ul><p>上图又可简化为：</p><p><img loading=lazy src=images/GAN_9.png srcset="/posts/gan_1/images/GAN_9.png, images/GAN_9.png 1.5x, /posts/gan_1/images/GAN_9.png 2x" sizes=auto data-title=/posts/gan_1/images/GAN_9.png data-alt=/posts/gan_1/images/GAN_9.png width=1080 height=333 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>一方面是从 $P_{data}$ 里来的 $x_{real}$，一方面是 $z$ 输入到生成器后的输出 $x_{fake}$，$z$ 为噪声。</p><div class="details admonition Note open"><div class="details-summary admonition-title"><i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden=true></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class=details-content><div class=admonition-content>换句话说, $z$ 是从简单分布中采样，经过生成器后变成 $x$，此时生成的由的先验分布和生成器共同决定。</div></div></div><h3 id=82高专家的目标函数>8.2、“高专家”的目标函数</h3><p>符号描述表述清楚后，我们看一下GAN的目标函数，首先回顾一下GAN的目标：<u><strong>成为一个高水平的、可以以假乱真的大师</strong></u>。为了达到这个目标，我们又可以分为一个手段和一个目标：</p><ul><li>手段：<strong>需要一个高水平的鉴别专家</strong>；</li><li>目标：<strong>成为高水平的工艺品大师</strong>。</li></ul><p>也就是说我们需要<u><strong>先成就一个高水平的专家，才有可能成就一个高水平的大师</strong></u>，所以它们的关系是：(高大师(高专家))。</p><p>首先看高专家，高专家水平高体现在：国宝判别为真、工艺品判别为假：</p><p>$$
高专家：
\begin{equation}
\left{
\begin{aligned}
%\nonumber
if \ x \ is \ from \ P_{data}, \ then D(x) \uparrow\
if \ x \ is \ from \ P_{g}, \ then D(x) \downarrow\
(z \ is \ from \ P_{z}) \
\end{aligned}
\right.
\end{equation}
$$</p><p>为了将式子统一起来，我们改写为：</p><p>$$
高专家：
\begin{equation}
\left{
\begin{aligned}
%\nonumber
if \ x \ is \ from \ P_{data}, \ then D(x) \uparrow\
if \ x \ is \ from \ P_{g}, \ then \ 1-D(x) \uparrow\
(z \ is \ from \ P_{z}) \
\end{aligned}
\right.
\end{equation}
$$</p><div class="details admonition Note open"><div class="details-summary admonition-title"><i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden=true></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class=details-content><div class=admonition-content>因为 $D(x)$ 是一个概率值分布，范围是0~1， $D(x)$ 偏小， $1-D(x)$ 则相应的就偏大。</div></div></div><p>对于工艺品，$x$ 是从<strong>生成器G</strong>来的，所以可以表示成 $G(z)$：</p><p>$$
高专家：
\begin{equation}
\left{
\begin{aligned}
%\nonumber
if \ x \ is \ from \ P_{data}, \ then D(x) \uparrow\
if \ x \ is \ from \ P_{g}, \ then \ 1 - D(G(z)) \uparrow\
(z \ is \ from \ P_{z}) \
\end{aligned}
\right.
\end{equation}
$$</p><p>为了使目标函数更容易表达，或者说计算更加方便，我们加上，所以进一步表达为：
$$
高专家：
\begin{equation}
\left{
\begin{aligned}
%\nonumber
if \ x \ is \ from \ P_{data}, \ then \ \log{D(x)} \uparrow\
if \ x \ is \ from \ P_{g}, \ then \ \log{(1 - D(G(z)))} \uparrow\
(z \ is \ from \ P_{z}) \
\end{aligned}
\right.
\end{equation}
$$</p><div class="details admonition Note open"><div class="details-summary admonition-title"><i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden=true></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class=details-content><div class=admonition-content>$\log$ 为增函数，$\log(x)$ 与 $x$ 的增减性保持一致，在极大化参数的时候，与原始求解是一样的。</div></div></div><p>所以对于成就一个高专家来说，目标函数如下：</p><p>$$\max_{D} E_{x \sim P_{data}}[\log{D(x)}] + E_{z \sim P_{z}}[\log (1 - D(G(z)))]$$</p><div class="details admonition Note open"><div class="details-summary admonition-title"><i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden=true></i>note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class=details-content><div class=admonition-content><p>可能有同学不明白为什么原文这里用期望，其实很简单，我们假设数据分布总共有个样本，那么它的期望可以表示为：</p><p>$$E_{x \sim P_{data}}[\log(D(x))] = \frac{1}{N} \sum_{i=1}^{N} \log(D(x_i)), x_i \sim P_{data}$$</p></div></div></div><h3 id=83高大师的目标函数>8.3、“高大师”的目标函数</h3><p>我们再来看高大师的目标函数，<strong>高大师是建立在高专家的水平之上</strong>，对于高大师来讲，希望高专家将所有的工艺品都判断为真：</p><p>$$高大师: if \ x \ from \ P_g,\ then \ D(G(z)) \uparrow $$</p><p>为了统一起来，我们改写为:</p><p>$$高大师: if \ x \ from \ P_g,\ then \ (1 - D(G(z))) \downarrow $$</p><p>所以对于高大师来讲，目标函数为:</p><p>$$\min_{G} E_{z \sim P_z}[\log (1 - D(G(z)))]$$</p><h3 id=84总目标函数>8.4、总目标函数</h3><p>本着<strong>先成就 高专家, 再成就 高大师</strong>的原则，GAN的目标函数为：</p><p>$$\min_{G} \max_{D} V(D, G) = \mathbb{E_{x\sim p_{data}(x)}}[\log(D(x))] + \mathbb{E_{z\sim p_{z}(z)}}[\log(1 - D(G(z)))]$$</p><div class="details admonition Note open"><div class="details-summary admonition-title"><i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden=true></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class=details-content><div class=admonition-content>通过目标函数我们也能看出，GAN模型的复杂度，不在于模型的定义，而在于模型的traning，也就是D和G的学习。</div></div></div><div class="details admonition Note open"><div class="details-summary admonition-title"><i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden=true></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class=details-content><div class=admonition-content>还有一点需要强调的是，自始至终我们都没有去直接面对 $P_g$，我们实际上使用一个可微神经网络 $G(z)$ 去逼近这个 $P_g$ ，而且是从采样的角度去逼近，换句话说，对于生成网络 $P_g$，GAN是绕过了它，并没有直接去解决 $P_g$，而是从采样的角度去逼近它。所以GAN又被称做：Implicit Density Model.</div></div></div><p>公式比较多，所以对目标函数再啰嗦的介绍下：</p><p>我们可以得出，它实际上就要对价值函数 $V(D, G)$ 进行min、max的博弈，还有需要注意的是：$D(x)$ 是判别器的输出，它要做二分类，所以经过sigmoid之后 $D(x) \in [0, 1]$；</p><p>我们来看一下它是怎么工作的：</p><ul><li>首先固定住G不动，通过调整D的参数，来最大化价值函数 $V(D, G)$：<ul><li>要想最大化 $V$ ，左边的 $D(x)$ 要趋近于1（这样才能保证log的值尽可能大），同时要让右边的 $D(G(z))$ 趋近于0（这样才能保证 $log(1-D(G(z)))$ 尽可能大）；</li><li>$\max V(D, G)$ 其实就是把真实数据和假数据区分的一个过程.
$$\min_{G} \max_{D} V(D, G) = \mathbb{E_{x\sim p_{data}(x)}}[\log(D(x))] + \mathbb{E_{z\sim p_{z}(z)}}[\log(1 - D(G(z)))]$$</li></ul></li><li>然后固定住D不动，此时公式的左部分已经是个定值了，我们<strong>调整G的参数</strong>，来最小化价值函数 $V(D, G)$：<ul><li>要让 $V(D, G)$ 最小，那么就要让 $D(G(z))$ 趋近于1，只有 $V(G(z))$ 趋近于1的时候，定义域里的值才能趋近于0，也就是log会变得越来越小，达到最小化 $V$ 的过程；</li><li>这个过程就是想让 $D(G(z))$ 趋近于1，z满足生成数据的分布，它是假的，那么 $min_G$ 的过程就是想要调整生成器，来骗过判别器，从而<strong>使得假数据被判别为真</strong>。
$$\min_{G} \max_{D} V(D, G) = \mathbb{E_{x\sim p_{data}(x)}}[\log(D(x))] + \mathbb{E_{z\sim p_{z}(z)}}[\log(1 - D(G(z)))]$$</li></ul></li></ul><p>总结如下：</p><ul><li>固定G, 调整D, 最大化 $V(D, G)$, 导致 $D(x) \rightarrow 1, D(G(z)) \rightarrow 0$</li><li>固定D, 调整G, 最小化 $\max_{D}V(D, G)$, 导致 $D(G(z)) \rightarrow 1$</li></ul><p>想必肯定有同学会发现这里出现的一个矛盾：上面的趋近于0，下面的趋近于1，这个矛盾、冲突，就理解为GAN中的<strong>对抗</strong>的意思。</p><h2 id=九全局最优解推导>九、全局最优解推导</h2><p>因为公式多、篇幅长，所以在推导最优解之前，我们先回顾一下GAN里的三个角色：</p><ul><li>真实样本分布$P_{data}$；</li><li><strong>生成器 Generator</strong> 对应概率分布为:$P_g$，即代表生成器生成数据的概率分布；</li><li><strong>判别器 Discriminator</strong> 对应的条件概率分布是离散的，就是0-1分布（伯努利分布），给定x的情况下，1代表正品、0代表工艺品（赝品）；</li></ul><p>我们的最终目标，就<strong>是想让生成器生成的样本的概率分布$P_g$无限的接近于$P_{data}$</strong>，即：$P_g \rightarrow P_{data}$；</p><div class="details admonition Note open"><div class="details-summary admonition-title"><i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden=true></i>note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class=details-content><div class=admonition-content><p>我们常规的生成模型（不是GAN），是直接对$P_g$进行建模: $P_g \rightarrow \theta_{g}$, 极大似然估计表示如下：</p><p>$$\theta_g = \argmax_{\theta_g} \sum_{i=1}^N \log{P_g}(x_i) = \argmin KL(P_{data} || P_g)$$</p><p>从距离的角度讲，是最小化KL散度，最终想让$P_{data} = P_g$，这就是原先如何把参数求出来的策略。</p></div></div></div><h3 id=91关于-d-的最大值>9.1、关于 D 的最大值</h3><p>GAN从<strong>对抗学习</strong>的角度去构造目标函数，我们上面构造的目标函数，只是从逻辑上觉得它没有问题，那么我们可能会考虑：</p><ul><li>这个最大最小问题，它的最优解存在不存在？</li><li>如果最优解 $P_g$（就是G）存在，那么全局最优的情况下，$P_g$是否等于$P_{data}$？</li></ul><p>如果这个不成立的话，那么其实这个目标函数是没有意义的，我们来看一下，方便记作，直接用论文中的符号来描述：</p><p><img loading=lazy src=images/GAN_10.png#center srcset="/posts/gan_1/images/GAN_10.png, images/GAN_10.png#center 1.5x, /posts/gan_1/images/GAN_10.png 2x" sizes=auto data-title=/posts/gan_1/images/GAN_10.png data-alt=/posts/gan_1/images/GAN_10.png width=1080 height=251 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>我们记：</p><p>$$V(D, G) = \mathbb{E}<em>{x\sim p</em>{data}(x)}[\log{D(x)}] + \mathbb{E}<em>{z\sim p</em>{z}}[\log{1 - D(G(z))}]$$</p><p>我们先求max，根据期望的定义：$E_{x \sim P(x)} = \int_x p(x)f(x)dx$，将其展为积分的形式：</p><p>$\quad For \quad fixed \quad G, 求： \max_D(V(D, G))$
$$
\begin{align}
\max_D V(D, G) &= \int P_{data} \cdot \log D dx + \int P_g \cdot \log (1 - D) dx \
&= \int {[P_{data} \cdot \log D + P_g \cdot \log(1 - D)]} dx
\end{align}
$$</p><div class="details admonition Note open"><div class="details-summary admonition-title"><i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden=true></i>note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class=details-content><div class=admonition-content>这里两个积分中的x确实是不同的变量，但是积分微元的符号可以做任意变换，不用纠结这里。</div></div></div><p>我们要求里面函数关于x积分的最大值，那么就看一下它的导数：</p><p>$$
\begin{align}
\frac{\partial}{\partial{D}}(\max V(D, G)) &= \frac{\partial}{\partial D}\int {[P_{data} \cdot \log D + P_g \cdot \log(1 - D)]} \
&= \int \frac{\partial}{\partial D} {[P_{data} \cdot \log D + P_g \cdot \log(1 - D)]} \
&= \int {[P_{data} \cdot \frac{1}{D} + P_g \cdot \frac{-1}{\log(1 - D)}]} \Longleftrightarrow 0\
\end{align}
$$</p><div class="details admonition Note open"><div class="details-summary admonition-title"><i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden=true></i>note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class=details-content><div class=admonition-content><p>因为积分是对x积的，求导是对D求的，两者互不干扰可以交换词序。</p><p>最优的时候导数为0。</p></div></div></div><p>$$\therefore P_{data} \cdot \frac{1}{D} = P_g \cdot \frac{1}{1-D}$$</p><p>所以当固定G时，最优的D为:</p><p>$$D^*<em>G = \frac{P</em>{data}}{P_{data} + P_g}$$</p><h3 id=92-关于-g-的最小值>9.2 关于 G 的最小值</h3><p>最大值求出来之后，我们再来看关于G的最小值，我们将$D^*$带进去：</p><p>$$
\begin{align}
\min_G \max_D V(D, G) &= \min_G V(D^*<em>G, G) \
&= \min_G E</em>{x \sim P_{data}}[\log(\frac{P_{data}}{P_{data} + P_g})] + E_{x \sim P_{g}}[\log(1 - \frac{P_{data}}{P_{data} + P_g})] \
&= \min_G E_{x \sim P_{data}}[\log(\frac{P_{data}}{P_{data} + P_g})] + E_{x \sim P_{g}}[\log(\frac{P_{g}}{P_{data} + P_g})]\
\end{align}
$$</p><p>这里 $P_{data}$ 和 $P_g$，和KL散度的定义非常类似，KL divergence定义：</p><p>$$KL(P||Q) = E_{x \sim P}[\log(\frac{P(x)}{Q(x)})]$$</p><p>但是我们不能直接这么写，我们需要保证分子和分母必须同时为两个概率分布，但是分母是$P_{data} + P_g$，是两个概率分布相加，那它的取值就变成[0, 2]了。</p><p>所以我们给它再除以个2就可以了，取值范围就又变成[0, 1]了。换句话说，可以把它看成概率密度函数，具体什么样子无所谓，它的取值在[0, 1]之间，并且是连续的。</p><p>$$
\begin{align}
\min_G \max_D V(D, G) &= \min_G V(D^*<em>G, G) \
&= \min_G E</em>{x \sim P_{data}}[\log(\frac{P_{data}}{P_{data} + P_g})] + E_{x \sim P_{g}}[\log(1 - \frac{P_{data}}{P_{data} + P_g})] \
&= \min_G E_{x \sim P_{data}}[\log(\frac{P_{data}}{P_{data} + P_g})] + E_{x \sim P_{g}}[\log(\frac{P_{g}}{P_{data} + P_g})]\
&= \min_G E_{x \sim P_{data}}[\log(\frac{P_{data}}{(P_{data} + P_g)/2} \cdot\frac{1}{2})] + E_{x \sim P_{g}}[\log(\frac{P_{g}}{(P_{data} + P_g)/2}\cdot\frac{1}{2})]\
&= \min_{G} KL (P_{data} || \frac{P_{data} + P_g}{2}) + KL (P_{g} || \frac{P_{data} + P_g}{2}) - \log4\
\end{align}
$$</p><div class="details admonition Note open"><div class="details-summary admonition-title"><i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden=true></i>tips<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class=details-content><div class=admonition-content>将两个$\log(\frac{1}{2})$拿出去，$\log(\frac{1}{2}) = \log1 - \log2 = -\log2,$，$-\log2$的期望就是它自己，两个就是$-\log2-\log2 = -\log4$</div></div></div><p>我们得出上式，发现它又满足 JS divergence 的定义：</p><p>$$JSD(P||Q) = \frac{1}{2} KL(P || M) + \frac{1}{2} KL (Q||M), 其中 M = \frac{P + Q}{2}$$</p><p>所以上式又可写成：</p><p>$$\min_G - \log 4 + 2 JSP(P_{data}||P_g)$$</p><p>JS divergence是衡量两个分布之间的距离，所以只有当这两个分布越来越相等的时候，就找到这个式子的最小值了，故：</p><p>当$P_g(x) = P_{data}(x)$时，上式可得最小值。</p><p>所以我们只需要优化：</p><p>$$\min_G\max_D V(D, G) = \mathbb{E}<em>{x\sim{p</em>{data}(x)}}[\log D(x)] + \mathbb{E}<em>{z\sim{p</em>{z}(z)}}[1 - \log D(G(z))]$$</p><p>就可以得到$P_g(x) = P_{data}(x)$.</p><div class="details admonition Note open"><div class="details-summary admonition-title"><i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden=true></i>tips<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class=details-content><div class=admonition-content>另外，当 $P_g(x) = P_{data}(x)$ 时，又因为 $D^<em><em>G = \frac{P</em>{data}}{P_{data} + P_g}$， 所以此时 $D^</em> = \frac{1}{2}$ 。意思是，在最优的情况下，鉴赏专家已经没有分辨真假的能力了，概率都0.5，这个时候判别器对于生成器而言，已经没有继续学习的必要了。</div></div></div><h2 id=十原文给出的训练步骤>十、原文给出的训练步骤</h2><p><img loading=lazy src=images/GAN_11.png srcset="/posts/gan_1/images/GAN_11.png, images/GAN_11.png 1.5x, /posts/gan_1/images/GAN_11.png 2x" sizes=auto data-title=/posts/gan_1/images/GAN_11.png data-alt=/posts/gan_1/images/GAN_11.png width=1080 height=690 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><ul><li>在每一个step里先采样m个噪音样本；</li><li>再采样m个来自于真实数据的样本；这样就组成了一个大小为2m的小批量；</li><li>将样本分别放到 <strong>生成器</strong> 和 <strong>辨别器</strong> 去求梯度，更新 <strong>辨别器</strong> 参数；</li></ul><p>做完之后：</p><ul><li>再采样m个噪音样本，放到公式的第二项里面（因为我们要<strong>更新生成器</strong>，生成器与第一项无关），算出它的梯度；</li><li>然后对生成器进行参数更新。</li></ul><p>这样就完成了一次迭代，可以看到每次迭代里，我们是<strong>先更新辨别器，再更新生成器</strong>。</p><div class="details admonition Note open"><div class="details-summary admonition-title"><i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden=true></i>tips<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class=details-content><div class=admonition-content><p>k是一个超参数，不能太小也不能太大，要保证辨别器有足够的更新，但也不要更新太好了。如果没有足够好的更新，就是生成器变换了之后，没有把辨别器更新的足够好，</p><p><img loading=lazy src=images/GAN_12.png srcset="/posts/gan_1/images/GAN_12.png, images/GAN_12.png 1.5x, /posts/gan_1/images/GAN_12.png 2x" sizes=auto data-title=/posts/gan_1/images/GAN_12.png data-alt=/posts/gan_1/images/GAN_12.png width=768 height=212 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'>
G已经做了变化，但是D没有做什么改变，再更新G来糊弄D，其实意义不大。</p><p>反过来讲，如果一更新就把D训练到完美，那么1-D就会变成0，对一个0的东西求导，那么就会在生成模型上更新有困难。</p><p>回到原文的例子，辨别器是警察，生成器就是造假者，假设警察特别厉害，造假者产一点假钞出来就被连锅端了，那造假者就没能力改进和提升自己了，但反过来讲，如果警察无力，造假者随便造点东西，警察也看不出来，那造假者就不会有动力去改进和提升自己。</p><p>所以最好是两者实力相当、相爱相杀，大家一起进步。所以k的调参，要使得D的更新和G的更新进度都差不多。</p></div></div></div><h2 id=十一gan原理及训练过程总结>十一、GAN原理及训练过程总结</h2><h3 id=111gan原理总结>11.1、GAN原理总结</h3><p>GAN主要包括了两部分：</p><ul><li><mark>生成器（Generator）</mark>：生成器主要用来学习真实数据的分布，从而让自身生成的数据更加真实，骗过判别器；</li><li><mark>判别器（Discriminator）</mark>：判别器则需要对接受的数据进行真假判断。</li></ul><p>在训练过程中，生成器努力地让生成的数据更加真实，而判别器则努力地去识别出数据的真假，这个过程相当于一个二人博弈，随着时间的推移，生成器和判别器在不断的进行对抗，这就是它对抗的含义。</p><p>最终两个网络达到了一个动态均衡：生成器生成的数据接近于真实数据分布，而判别器识别不出真假数据，对于给定数据的预测为真的概率基本接近0.5（相当于随机猜测类别）。</p><p>GAN设计的关键在于损失函数的处理：</p><ul><li>对于判别模型，损失函数是容易定义的，判断一张图片是真实的还是生成的，显然是一个二分类问题。</li><li>对于生成模型，损失函数的定义就不是那么容易，我们希望生成器可以生成接近于真实的图片，对于生成的图片是否像真实的，我们人类肉眼容易判断，但具体到代码中，是一个抽象的，难以数学公里化定义的范式。</li></ul><p>针对这个问题，我们不妨把生成模型的输出，交给判别模型处理，让判别器判断这是一个真实的图像还是假的图像，因为深度学习模型很适合做分类，这样就将生成器和判别器紧密地联合在了一起。</p><div class="details admonition Note open"><div class="details-summary admonition-title"><i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden=true></i>tips<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class=details-content><div class=admonition-content>假如我们直接用生成器训练，它的训练结果并不会得到一个真实的图像，而会得到一个比较模糊的图像，因为我们无法构建一个合适的损失去判断它是否像真实图片，所以它会将所有训练样本做平均，产生一个比较糊的图片。这就是为什么要将生成器的样本交给判别器来构建损失。</div></div></div><h3 id=112gan算法流程总结>11.2、GAN算法流程总结</h3><ul><li>$G$ 是一个生成图片的网络，它接收一个随机的噪声z，通过这个噪声生成图片$G(z)$，记作；</li><li>$D$ 是一个判别网络，判别一张图片是不是“真实的”，它的输入参数是x，x代表一张图片，输出$D(x)$，代表x为真实图片的概率，如果为1，就代表100%是真实的图片，输出为0，就代表不是真实图片。</li></ul><p>在训练过程中，将随机噪声输入生成网络G，得到生成的图片；判别器接受生成的图片和真实的图片，并尽量将两者区分开来。在这个计算过程中，能否正确区分生成的图片和真实的图片将作为判别器的损失；而能否生成近似真实的图片、并使得判别器将生成的图片判定为真，将作为生成器的损失。</p><p>生成器的损失是通过判别器的输出来计算的，而判别器的输出是一个概率值，我们可以通过交叉熵来计算。</p><h2 id=十二torch复现>十二、torch复现</h2><p><a href=https://wangguisen.blog.csdn.net/article/details/127820071 target=_blank rel="external nofollow noopener noreferrer">https://wangguisen.blog.csdn.net/article/details/127820071<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>
ref:</br>[1]. <a href=https://arxiv.org/abs/1406.2661 target=_blank rel="external nofollow noopener noreferrer">https://arxiv.org/abs/1406.2661<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></br>[2]. <a href=https://www.bilibili.com/video/BV1eE411g7xc target=_blank rel="external nofollow noopener noreferrer">https://www.bilibili.com/video/BV1eE411g7xc<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></br>[3]. <a href=https://www.bilibili.com/video/BV1rb4y187vD target=_blank rel="external nofollow noopener noreferrer">https://www.bilibili.com/video/BV1rb4y187vD<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></br>[4]. <a href=https://www.bilibili.com/video/BV1HD4y1S7Pe target=_blank rel="external nofollow noopener noreferrer">https://www.bilibili.com/video/BV1HD4y1S7Pe<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></br></p></div><div class=post-reward><div class=comment>Buy me a coffee~</div><input type=checkbox class=reward-input name=reward id=fi-reward hidden>
<label class=reward-button for=fi-reward>赞赏</label><div class=reward-ways data-mode=fixed><div><img loading=lazy src=/images/alipay.png srcset="/images/alipay.png, /images/alipay.png 1.5x, /images/alipay.png 2x" sizes=auto data-title="Jian YE 支付宝" data-alt="Jian YE 支付宝" style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span data-animation>支付宝</span></div><div><img loading=lazy src=/images/wechatpay.png srcset="/images/wechatpay.png, /images/wechatpay.png 1.5x, /images/wechatpay.png 2x" sizes=auto data-title="Jian YE 微信" data-alt="Jian YE 微信" style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span data-animation>微信</span></div></div></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span title="更新于 2023-07-27 20:06:28">更新于 2023-07-27&nbsp;<a class=git-hash href=https://github.com/jianye0428/JianBlog/commit/201c2ba519ab7792870fc823af3e475181b4fc0c rel="external nofollow noopener noreferrer" target=_blank title="commit by yejian(18817571704@163.com) 201c2ba519ab7792870fc823af3e475181b4fc0c: feat: add VAE PART ONE"><i class="fa-solid fa-hashtag fa-fw" aria-hidden=true></i>201c2ba</a></span></div></div><div class=post-info-line><div class=post-info-md><span><a href=/posts/gan_1/index.md title=阅读原始文档 class=link-to-markdown>阅读原始文档</a></span><span><a href=https://github.com/jianye0428/JianBlog/edit/docs/content/posts/ML/GAN/GAN_1/index.md title=编辑此页 target=_blank rel="external nofollow noopener noreferrer" class=link-to-edit>编辑此页</a></span></div><div class=post-info-share><span><a href=javascript:void(0); title="分享到 Twitter" data-sharer=twitter data-url=https://jianye0428.github.io/posts/gan_1/ data-title=生成对抗网络GAN data-hashtags=GAN><i class="fa-brands fa-twitter fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 Facebook" data-sharer=facebook data-url=https://jianye0428.github.io/posts/gan_1/ data-hashtag=GAN><i class="fa-brands fa-facebook-square fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 Linkedin" data-sharer=linkedin data-url=https://jianye0428.github.io/posts/gan_1/><i class="fa-brands fa-linkedin fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 微博" data-sharer=weibo data-url=https://jianye0428.github.io/posts/gan_1/ data-title=生成对抗网络GAN><i class="fa-brands fa-weibo fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 百度" data-sharer=baidu data-url=https://jianye0428.github.io/posts/gan_1/ data-title=生成对抗网络GAN><i data-svg-src=/lib/simple-icons/icons/baidu.min.svg aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fa-solid fa-tags fa-fw me-1" aria-hidden=true></i><a href=/tags/gan/ class=post-tag>GAN</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class=post-nav><a href=/posts/transformerdetailedexplanation/ class=post-nav-item rel=prev title="Transformer 详解"><i class="fa-solid fa-angle-left fa-fw" aria-hidden=true></i>Transformer 详解</a>
<a href=/posts/clause_7/ class=post-nav-item rel=next title="Effective STL [7] | 当使用new得指针的容器时，记得在销毁容器前delete那些指针">Effective STL [7] | 当使用new得指针的容器时，记得在销毁容器前delete那些指针<i class="fa-solid fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article></main><footer class=footer><div class=footer-container><div class="footer-line powered">由 <a href=https://gohugo.io/ target=_blank rel="external nofollow noopener noreferrer" title="Hugo 0.125.7">Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/hugo-fixit/FixIt target=_blank rel=external title="FixIt v0.2.18"><img class=fixit-icon src=/fixit.min.svg alt="FixIt logo">&nbsp;FixIt</a></div><div class="footer-line copyright" itemscope itemtype=http://schema.org/CreativeWork><i class="fa-regular fa-copyright fa-fw" aria-hidden=true></i>
<span itemprop=copyrightYear>2018 - 2024</span><span class=author itemprop=copyrightHolder>
<a href=https://github.com/jianye0428 target=_blank rel="external nofollow noopener noreferrer">Jian YE</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div><div class="footer-line statistics order-first"><span class=site-time title=网站运行中……><i class="fa-solid fa-heartbeat fa-fw animate-icon" aria-hidden=true></i><span class="ms-1 d-none">博客已运行</span><span class="run-times ms-1">网站运行中……</span></span></div><div class="footer-line visitor"><span id=busuanzi_container_site_uv title=总访客数><i class="fa-regular fa-user fa-fw" aria-hidden=true></i>&nbsp;<span id=busuanzi_value_site_uv><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden=true></i></span></span><span id=busuanzi_container_site_pv class=footer-divider title=总访问量><i class="fa-regular fa-eye fa-fw" aria-hidden=true></i>&nbsp;<span id=busuanzi_value_site_pv><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden=true></i></span></span></div></div></footer></div><div class=widgets><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role=button aria-label=回到顶部><i class="fa-solid fa-arrow-up fa-fw" aria-hidden=true></i><span class=variant-numeric>0%</span></div></div><a href=https://github.com/jianye0428/JianBlog title="在 GitHub 上查看程式碼，訂閱請點 Watch" target=_blank rel="external nofollow" class="github-corner right d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115h15l12 27L250 250V0z"/><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentcolor" style="transform-origin:130px 106px" class="octo-arm"/><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4l13.9-13.8C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8z" fill="currentcolor" class="octo-body"/></svg></a><div id=mask></div><div class=reading-progress-bar style=left:0;top:0;--bg-progress:#000;--bg-progress-dark:#fff></div><noscript><div class=noscript-warning>FixIt 主题在启用 JavaScript 的情况下效果最佳。</div></noscript></div><link rel=stylesheet href=/lib/katex/katex.min.css><link rel=stylesheet href=/lib/cookieconsent/cookieconsent.min.css><link rel=stylesheet href=/lib/pace/themes/blue/pace-theme-minimal.css><script src=/lib/autocomplete/autocomplete.min.js defer></script><script src=/lib/algoliasearch/algoliasearch-lite.umd.min.js defer></script><script src=/lib/instant-page/instantpage.min.js async defer type=module></script><script src=/lib/twemoji/twemoji.min.js defer></script><script src=/lib/sharer/sharer.min.js async defer></script><script src=/lib/katex/katex.min.js defer></script><script src=/lib/katex/auto-render.min.js defer></script><script src=/lib/katex/mhchem.min.js defer></script><script src=/lib/cookieconsent/cookieconsent.min.js defer></script><script src=/lib/pangu/pangu.min.js defer></script><script src=/lib/cell-watermark/watermark.min.js defer></script><script src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js async defer></script><script src=/lib/pace/pace.min.js async defer></script><script>window.config={autoBookmark:!0,code:{copyTitle:"复制到剪贴板",editLockTitle:"锁定可编辑代码块",editUnLockTitle:"解锁可编辑代码块",editable:!0,maxShownLines:50},comment:{enable:!1},cookieconsent:{content:{dismiss:"同意",link:"了解更多",message:"本网站使用 Cookies 来改善您的浏览体验。"},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},enablePWA:!0,math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},pangu:{enable:!0,selector:"article"},search:{algoliaAppID:"MTJNHU0JVB",algoliaIndex:"index",algoliaSearchKey:"5486225134d99f43826da401ee9bad57",highlightTag:"em",maxResultLength:10,noResultsFound:"没有找到结果",snippetLength:50,type:"algolia"},siteTime:"2018-05-28T20:01:01+08:00",twemoji:!0,watermark:{appendto:".wrapper>main",colspacing:30,content:'<img style="height: 0.85rem;" src="/images/favicon/jian_icon.png" alt="logo" /> jianye',enable:!0,fontfamily:"MMT_LRH,沐目体",fontsize:1.1,height:20,opacity:.0125,rotate:15,rowspacing:60,width:150}}</script><script src=/js/theme.min.js defer></script><script src=/js/custom.min.js defer></script></body></html>