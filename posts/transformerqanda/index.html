<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=2"><meta name=robots content="noodp"><title>Transformer Q & A - yejian's blog</title><meta name=author content="Jian YE">
<meta name=author-link content="https://github.com/jianye0428"><meta name=description content="1. 2017年深度学习领域的重大突破是什么？ Transformer。有两方面的原因: 1.1 一方面，Transformer是深度学习领域继MLP、RNN、CNN之后的第4大特征提取器(也被称为基础模型)。 什么是特征提取器？ 特征提取器是计算机模仿大脑，与外部世界(图像、文字、语音等)交互的方式，如图1所示。举"><meta name=keywords content='Transformer'><meta itemprop=name content="Transformer Q & A"><meta itemprop=description content="1. 2017年深度学习领域的重大突破是什么？ Transformer。有两方面的原因: 1.1 一方面，Transformer是深度学习领域继MLP、RNN、CNN之后的第4大特征提取器(也被称为基础模型)。 什么是特征提取器？ 特征提取器是计算机模仿大脑，与外部世界(图像、文字、语音等)交互的方式，如图1所示。举"><meta itemprop=datePublished content="2023-08-21T07:59:36+08:00"><meta itemprop=dateModified content="2023-08-26T13:40:05+08:00"><meta itemprop=wordCount content="6984"><meta itemprop=image content="https://jianye0428.github.io/images/favicon/jian_icon.png"><meta itemprop=keywords content="Transformer,"><meta property="og:title" content="Transformer Q & A"><meta property="og:description" content="1. 2017年深度学习领域的重大突破是什么？ Transformer。有两方面的原因: 1.1 一方面，Transformer是深度学习领域继MLP、RNN、CNN之后的第4大特征提取器(也被称为基础模型)。 什么是特征提取器？ 特征提取器是计算机模仿大脑，与外部世界(图像、文字、语音等)交互的方式，如图1所示。举"><meta property="og:type" content="article"><meta property="og:url" content="https://jianye0428.github.io/posts/transformerqanda/"><meta property="og:image" content="https://jianye0428.github.io/images/favicon/jian_icon.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-08-21T07:59:36+08:00"><meta property="article:modified_time" content="2023-08-26T13:40:05+08:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jianye0428.github.io/images/favicon/jian_icon.png"><meta name=twitter:title content="Transformer Q & A"><meta name=twitter:description content="1. 2017年深度学习领域的重大突破是什么？ Transformer。有两方面的原因: 1.1 一方面，Transformer是深度学习领域继MLP、RNN、CNN之后的第4大特征提取器(也被称为基础模型)。 什么是特征提取器？ 特征提取器是计算机模仿大脑，与外部世界(图像、文字、语音等)交互的方式，如图1所示。举"><meta name=application-name content="菠菜阿九时代峰峻啊；数量可根据；"><meta name=apple-mobile-web-app-title content="菠菜阿九时代峰峻啊；数量可根据；"><meta name=theme-color data-light=#ffffff data-dark=#252627 content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/png href=/jian_icon.png><link rel=icon type=image/png sizes=32x32 href=/jian_icon.png><link rel=icon type=image/png sizes=16x16 href=/jian_icon.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://jianye0428.github.io/posts/transformerqanda/><link rel=prev href=https://jianye0428.github.io/posts/attentionaqkv/><link rel=next href=https://jianye0428.github.io/posts/effective_stl_part_six/><link rel=stylesheet href=/css/style.min.css><link rel=stylesheet href=/lib/fontawesome-free/all.min.css><link rel=stylesheet href=/lib/animate/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Transformer Q \u0026 A","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/jianye0428.github.io\/posts\/transformerqanda\/"},"image":["https:\/\/jianye0428.github.io\/images\/favicon\/jian_icon.png"],"genre":"posts","keywords":"Transformer","wordcount":6984,"url":"https:\/\/jianye0428.github.io\/posts\/transformerqanda\/","datePublished":"2023-08-21T07:59:36+08:00","dateModified":"2023-08-26T13:40:05+08:00","publisher":{"@type":"Organization","name":"Jian YE","logo":"https:\/\/jianye0428.github.io\/images\/favicon\/jian_icon.png"},"author":{"@type":"Person","name":"Jian YE"},"description":""}</script></head><body data-header-desktop=sticky data-header-mobile=auto><script>(window.localStorage?.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("data-theme","dark")</script><div class=wrapper data-page-style=normal><header class="desktop animate__faster" id=header-desktop><div class=header-wrapper data-github-corner=right><div class=header-title><a href=/ title="yejian's blog"><img loading=lazy src=/images/favicon/jian_icon.png srcset="/images/favicon/jian_icon.png, /images/favicon/jian_icon.png 1.5x, /images/favicon/jian_icon.png 2x" sizes=auto data-title="yejian's blog" data-alt="yejian's blog" class=logo style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span class=header-title-text>Jian's Blog</span></a><span class=header-subtitle></span></div><nav><ul class=menu><li class=menu-item><a class=menu-link href=/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> 所有文章</a></li><li class=menu-item><a class=menu-link href=/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> 分类</a></li><li class=menu-item><a class=menu-link href=/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> 标签</a></li><li class=menu-item><a class=menu-link href=/friends/ title=友情链接><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden=true></i> 友链</a></li><li class=menu-item><a class=menu-link href=/guestbook/><i class="fa-solid fa-comments fa-fw fa-sm" aria-hidden=true></i> 留言</a></li><li class="menu-item has-children"><a class=menu-link href=/about/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 关于</a><i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden=true></i><ul class=sub-menu><li class=menu-item><a class=menu-link href=/projects/_index.zh-tw/ title=項目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的項目</a></li><li class=menu-item><a class=menu-link href=/projects/ title=项目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的项目</a></li></ul></li><li class=menu-item><a class=menu-link href=/pilot/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 导航</a></li><li class="menu-item delimiter"></li><li class="menu-item search" id=search-desktop><input type=text placeholder=搜索文章标题或内容…… id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></li><li class="menu-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></li></ul></nav></div></header><header class="mobile animate__faster" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="yejian's blog"><img loading=lazy src=/images/favicon/jian_icon.png srcset="/images/favicon/jian_icon.png, /images/favicon/jian_icon.png 1.5x, /images/favicon/jian_icon.png 2x" sizes=auto data-title=/images/favicon/jian_icon.png data-alt=/images/favicon/jian_icon.png class=logo style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span class=header-title-text>Jian's Blog</span></a><span class=header-subtitle></span></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><nav><ul class=menu id=menu-mobile><li class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索文章标题或内容…… id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></li><li class=menu-item><a class=menu-link href=/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> 所有文章</a></li><li class=menu-item><a class=menu-link href=/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> 分类</a></li><li class=menu-item><a class=menu-link href=/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> 标签</a></li><li class=menu-item><a class=menu-link href=/friends/ title=友情链接><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden=true></i> 友链</a></li><li class=menu-item><a class=menu-link href=/guestbook/><i class="fa-solid fa-comments fa-fw fa-sm" aria-hidden=true></i> 留言</a></li><li class=menu-item><span class=nested-item><a class=menu-link href=/about/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 关于</a>
<i class="dropdown-icon fa-solid fa-chevron-right" aria-hidden=true></i></span><ul class=sub-menu><li class=menu-item><a class=menu-link href=/projects/_index.zh-tw/ title=項目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的項目</a></li><li class=menu-item><a class=menu-link href=/projects/ title=项目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的项目</a></li></ul></li><li class=menu-item><a class=menu-link href=/pilot/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 导航</a></li><li class="menu-item text-center"><a class=menu-link href=https://github.com/jianye0428/ title=GitHub rel="noopener noreferrer" target=_blank><i class='fa-brands fa-github fa-fw' aria-hidden=true></i></a></li><li class="menu-item menu-system"><span class="menu-system-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></span></li></ul></nav></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class="container container-reverse"><aside class=toc id=toc-auto><h2 class=toc-title>目录&nbsp;<i class="toc-icon fa-solid fa-angle-down fa-fw" aria-hidden=true></i></h2><div class=toc-content id=toc-content-auto></div></aside><aside class=aside-custom></aside><article class="page single"><div class=header><h1 class="single-title animate__animated animate__flipInX"><span>Transformer Q & A</span></h1></div><div class=post-meta><div class=post-meta-line><span class=post-author><a href=https://github.com/jianye0428 title=作者 target=_blank rel="external nofollow noopener noreferrer author" class=author><img loading=lazy src="https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp" srcset="https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp, https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp 1.5x, https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp 2x" sizes=auto data-title="Jian YE" data-alt="Jian YE" class=avatar style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'>&nbsp;Jian YE</a></span>
<span class=post-category>收录于 <a href=/categories/ml/><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> ML</a></span></div><div class=post-meta-line><span title="发布于 2023-08-21 07:59:36"><i class="fa-regular fa-calendar-alt fa-fw me-1" aria-hidden=true></i><time datetime=2023-08-21>2023-08-21</time></span>&nbsp;<span title="更新于 2023-08-26 13:40:05"><i class="fa-regular fa-edit fa-fw me-1" aria-hidden=true></i><time datetime=2023-08-26>2023-08-26</time></span>&nbsp;<span><i class="fa-solid fa-pencil-alt fa-fw me-1" aria-hidden=true></i>约 6984 字</span>&nbsp;<span><i class="fa-regular fa-clock fa-fw me-1" aria-hidden=true></i>预计阅读 14 分钟</span>&nbsp;<span id=busuanzi_container_page_pv class="busuanzi_visitors comment-visitors" data-flag-title="Transformer Q & A">
<i class="fa-regular fa-eye fa-fw me-1" aria-hidden=true></i><span id=busuanzi_value_page_pv>-</span>&nbsp;次阅读
</span>&nbsp;</div></div><div class="details toc" id=toc-static data-kept=false><div class="details-summary toc-title"><span>目录</span>
<span><i class="details-icon fa-solid fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#1-2017年深度学习领域的重大突破是什么>1. 2017年深度学习领域的重大突破是什么？</a></li><li><a href=#2-transformer的提出背景是什么>2. Transformer的提出背景是什么？</a></li><li><a href=#3-transformer到底是什么>3. Transformer到底是什么？</a></li><li><a href=#4-什么是transformer-encoder>4. 什么是Transformer Encoder？</a></li><li><a href=#5-什么是transformer-decoder>5. 什么是Transformer Decoder？</a></li><li><a href=#6-transformer-encoder和transformer-decoder有哪些不同>6. Transformer Encoder和Transformer Decoder有哪些不同？</a></li><li><a href=#7-什么是embedding>7. 什么是Embedding？</a></li><li><a href=#8-什么是positional-embedding>8. 什么是Positional Embedding？</a></li><li><a href=#9-什么是attention>9. 什么是Attention？</a></li><li><a href=#10-什么是self-attention>10. 什么是Self Attention？</a></li><li><a href=#11-什么是scaled-dot-product-attention>11. 什么是Scaled dot product attention？</a></li><li><a href=#12-什么是multi-head-attention>12. 什么是Multi head attention？</a></li><li><a href=#13-什么是mask-multi-head-attention>13. 什么是Mask Multi head attention？</a></li><li><a href=#14-什么是add>14. 什么是ADD？</a></li><li><a href=#15-什么是norm>15. 什么是Norm？</a></li><li><a href=#17-transformer是如何训练出来的>17. Transformer是如何训练出来的？</a></li><li><a href=#18-transformer为什么效果好>18. Transformer为什么效果好？</a></li></ul></nav></div></div><div class=content id=content data-end-flag=（完）><div class="details admonition note open"><div class="details-summary admonition-title"><i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden=true></i>注意<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class=details-content><div class=admonition-content>本文最后更新于 2023-08-26，文中内容可能已过时。</div></div></div><h2 id=1-2017年深度学习领域的重大突破是什么>1. 2017年深度学习领域的重大突破是什么？</h2><p>Transformer。有两方面的原因:</p><p>1.1 一方面，Transformer是深度学习领域继MLP、RNN、CNN之后的第4大特征提取器(也被称为基础模型)。</br><strong>什么是特征提取器？</strong></br>特征提取器是计算机模仿大脑，与外部世界(图像、文字、语音等)交互的方式，如图1所示。举例而言: Imagenet数据集中包含1000类图像，人们已经根据自己的经验把这一百万张图像分好1000类，每一类图像(如美洲豹)都有独特的特征。这时，神经网络(如ResNet18)也是想通过这种分类的方式，把每一类图像的特征尽可能提取或识别出来。分类不是最终目的，而是一种提取图像特征的手段，掩码补全图像也是一种提取特征的方式，图像块顺序打乱也是一种提取特征的方式。</p><p><img loading=lazy src=images/1.jpeg srcset="/posts/transformerqanda/images/1.jpeg, images/1.jpeg 1.5x, /posts/transformerqanda/images/1.jpeg 2x" sizes=auto data-title=/posts/transformerqanda/images/1.jpeg data-alt=/posts/transformerqanda/images/1.jpeg width=716 height=218 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>1.2 另一方面，Transformer在深度学习领域扮演的角色: 第3次和第4次热潮的基石，如下图2所示。</p><p><img loading=lazy src=images/2.jpeg srcset="/posts/transformerqanda/images/2.jpeg, images/2.jpeg 1.5x, /posts/transformerqanda/images/2.jpeg 2x" sizes=auto data-title=/posts/transformerqanda/images/2.jpeg data-alt=/posts/transformerqanda/images/2.jpeg width=1080 height=545 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><h2 id=2-transformer的提出背景是什么>2. Transformer的提出背景是什么？</h2><p><strong>2.1 在领域发展背景层面</strong>: 当时时处2017年，深度学习在计算机视觉领域已经火了几年。从Alexnet、VGG、GoogleNet、ResNet、DenseNet;从图像分类、目标检测再到语义分割;但在自然语言处理领域并没有引起很大反响。</p><p><strong>2.2 技术背景层面</strong>:
(1)当时主流的序列转录任务(如机器翻译)的解决方案如下图3所示，在Sequence to Sequence架构下(Encoder-Decoder的一种)，RNN来提取特征，Attention机制将Encoder提取到的特征高效传递给Decoder。
(2)这种做法有两个不足之处，一方面是在提取特征时的RNN天生<strong>从前向后时序传递</strong>的结构决定了其无法并行运算，其次是当序列长度过长时，最前面序列的信息有可能被遗忘掉。因此可以看到，在这个框架下，RNN是相对薄弱急需改进的地方。</p><p><img loading=lazy src=images/3.jpeg srcset="/posts/transformerqanda/images/3.jpeg, images/3.jpeg 1.5x, /posts/transformerqanda/images/3.jpeg 2x" sizes=auto data-title=/posts/transformerqanda/images/3.jpeg data-alt=/posts/transformerqanda/images/3.jpeg width=720 height=204 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><h2 id=3-transformer到底是什么>3. Transformer到底是什么？</h2><p>3.1 Transformer是一种由Encoder和Decoder组成的架构。那么什么是架构呢？最简单的架构就是A + B + C。</p><p>3.2 Transformer也可以理解为一个函数，输入是“我爱学习”，输出是“I love study”。</p><p>3.3 如果把Transformer的架构进行分拆，如图4所示。</p><p><img loading=lazy src=images/4.jpeg srcset="/posts/transformerqanda/images/4.jpeg, images/4.jpeg 1.5x, /posts/transformerqanda/images/4.jpeg 2x" sizes=auto data-title=/posts/transformerqanda/images/4.jpeg data-alt=/posts/transformerqanda/images/4.jpeg width=720 height=459 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><h2 id=4-什么是transformer-encoder>4. 什么是Transformer Encoder？</h2><p>4.1 从<font color=red>功能角度</font>，Transformer Encoder的核心作用是<strong>提取特征</strong>，也有使用Transformer Decoder来提取特征。例如，一个人学习跳舞，Encoder是看别人是如何跳舞的，Decoder是将学习到的经验和记忆(key和value的匹配程度)，展现出来</p><p>4.2 从<font color=red>结构角度</font>，如图5所示，Transformer Encoder = Embedding + Positional Embedding + N * (子Encoder block1 + 子Encoder block2);</p><p>子Encoder block1 = Multi head attention + ADD + Norm;</p><p>子Encoder block2 = Feed Forward + ADD + Norm;</p><p>4.3 从<font color=red>输入输出角度</font>，N个Transformer Encoder block中的第一个Encoder block的输入为一组向量 X = (Embedding + Positional Embedding)，向量维度通常为512*512，其他N个TransformerEncoder block的输入为上一个 Transformer Encoder block的输出，输出向量的维度也为<code>512*512</code>(输入输出大小相同)。</p><p>4.4 为什么是<code>512*512</code>？<font color=red>前者是指token的个数</font>，如“我爱学习”是4个token，这里设置为512是为了囊括不同的序列长度，不够时padding。<font color=red>后者是指每一个token生成的向量维度</font>，也就是每一个token使用一个序列长度为512的向量表示。人们常说，Transformer不能超过512，否则硬件很难支撑;其实512是指前者，也就是token的个数，因为每一个token要做self attention操作;但是后者的512不宜过大，否则计算起来也很慢。</p><p><img loading=lazy src=images/5.jpeg srcset="/posts/transformerqanda/images/5.jpeg, images/5.jpeg 1.5x, /posts/transformerqanda/images/5.jpeg 2x" sizes=auto data-title=/posts/transformerqanda/images/5.jpeg data-alt=/posts/transformerqanda/images/5.jpeg width=720 height=467 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><h2 id=5-什么是transformer-decoder>5. 什么是Transformer Decoder？</h2><p>5.1 从功能角度，相比于Transformer Encoder，Transformer Decoder更擅长做<strong>生成式任务</strong>，尤其对于自然语言处理问题。</p><p>5.2 从结构角度，如图6所示，Transformer Decoder = Embedding + Positional Embedding + N*(子Decoder block1 + 子Decoder block2 + 子Decoder block3)+ Linear + Softmax;</p><p>子Decoder block1 = Mask Multi head attention + ADD + Norm;</p><p>子Decoder block2 = Multi head attention + ADD + Norm;</p><p>子Decoder block3 = Feed Forward + ADD + Norm;</p><p><img loading=lazy src=images/6.jpeg srcset="/posts/transformerqanda/images/6.jpeg, images/6.jpeg 1.5x, /posts/transformerqanda/images/6.jpeg 2x" sizes=auto data-title=/posts/transformerqanda/images/6.jpeg data-alt=/posts/transformerqanda/images/6.jpeg width=720 height=792 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>5.3 从(Embedding+Positional Embedding)(N个Decoder block)(Linear + softmax) 这三个每一个单独作用角度:</p><p>Embedding + Positional Embedding: 以机器翻译为例，输入“Machine Learning”，输出“机器学习”; 这里的Embedding是把“机器学习”也转化成向量的形式。</p><p>N个Decoder block: 特征处理和传递过程。</p><p>Linear + softmax: softmax是预测下一个词出现的概率，如图7所示，前面的Linear层类似于分类网络(ResNet18)最后分类层前接的MLP层。</p><p><img loading=lazy src=images/7.jpeg srcset="/posts/transformerqanda/images/7.jpeg, images/7.jpeg 1.5x, /posts/transformerqanda/images/7.jpeg 2x" sizes=auto data-title=/posts/transformerqanda/images/7.jpeg data-alt=/posts/transformerqanda/images/7.jpeg width=720 height=475 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>5.4 Transformer Decoder的输入、输出是什么？在Train和Test时是不同的。</p><p>在Train阶段，如图8所示。这时是知道label的，decoder的第一个输入是begin字符，输出第一个向量与label中第一个字符使用cross entropy loss。Decoder的第二个输入是第一个向量的label，Decoder的第N个输入对应的输出是End字符，到此结束。这里也可以看到，在Train阶段是可以进行<strong>并行训练</strong>的。</p><p><img loading=lazy src=images/8.jpeg srcset="/posts/transformerqanda/images/8.jpeg, images/8.jpeg 1.5x, /posts/transformerqanda/images/8.jpeg 2x" sizes=auto data-title=/posts/transformerqanda/images/8.jpeg data-alt=/posts/transformerqanda/images/8.jpeg width=720 height=541 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>在Test阶段，下一个时刻的输入是前一个时刻的输出，如图9所示。因此，Train和Test时候，Decoder的输入会出现Mismatch，在Test时候确实有可能会出现一步错，步步错的情况。有两种解决方案: 一种是train时偶尔给一些错误，另一种是Scheduled sampling。</p><p><img loading=lazy src=images/9.jpeg srcset="/posts/transformerqanda/images/9.jpeg, images/9.jpeg 1.5x, /posts/transformerqanda/images/9.jpeg 2x" sizes=auto data-title="Image 图9 Transformer Decoder在Test阶段的输入和输出" data-alt="Image 图9 Transformer Decoder在Test阶段的输入和输出" width=720 height=569 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>5.5 Transformer Decoder block内部的输入和输出是什么？</p><p>前面提到的是在整体train和test阶段，Decoder的输入和输出，那么Transformer Decoder内部的Transformer Decoder block，如图10所示，的输入输出又是什么呢？</p><p><img loading=lazy src=images/10.jpeg srcset="/posts/transformerqanda/images/10.jpeg, images/10.jpeg 1.5x, /posts/transformerqanda/images/10.jpeg 2x" sizes=auto data-title="Image 图10 Transformer Decoder block的架构图" data-alt="Image 图10 Transformer Decoder block的架构图" width=622 height=722 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>对于N=6中的第1次循环(N=1时): 子Decoder block1 的输入是 embedding +Positional Embedding，子Decoder block2 的输入的Q来自子Decoder block1的输出，KV来自Transformer Encoder最后一层的输出。</p><p>对于N=6的第2次循环: 子Decoder block1的输入是N=1时，子Decoder block3的输出，KV同样来自Transformer Encoder的最后一层的输出。</p><p>总的来说，可以看到，无论在Train还是Test时，Transformer Decoder的输入不仅来自(ground truth或者上一个时刻Decoder的输出)，还来自Transformer Encoder的最后一层。</p><p>训练时: 第i个decoder的输入 = encoder输出 + ground truth embedding。</p><p>预测时: 第i个decoder的输入 = encoder输出 + 第(i-1)个decoder输出.</p><h2 id=6-transformer-encoder和transformer-decoder有哪些不同>6. Transformer Encoder和Transformer Decoder有哪些不同？</h2><p>6.1 作用上，Transformer Encoder常用来<strong>提取特征</strong>，Transformer Decoder常用于<strong>生成式任务</strong>。Transformer Encoder和Transformer Decoder是两条不同的技术路线，<strong>Bert采用的前者，GPT系列模型采用的是后者</strong>。</p><p>6.2 结构上，Transformer Decoder block包括了3个子Decoder block，而Transformer Encoder block 包括2个子Encoder block，且Transformer Decoder中使用了Mask multi-head Attention。</p><p>6.3 从二者的输入输出角度，N个Transformer Encoder运算完成之后，它的输出才正式输入进Transformer Decoder，作为QKV中的K和V，给Transformer Decoder使用。那么TransformerEncoder最后层的输出是如何送给Decoder呢？如图11所示。</p><p><img loading=lazy src=images/11.jpeg srcset="/posts/transformerqanda/images/11.jpeg, images/11.jpeg 1.5x, /posts/transformerqanda/images/11.jpeg 2x" sizes=auto data-title="图11 Transformer Encoder和Transformer Decoder交互的方式" data-alt="图11 Transformer Encoder和Transformer Decoder交互的方式" width=720 height=316 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>那么，为什么Encoder和Decoder必须要用这种交互的方式呢？其实也并不一定，后续有不同交互方式的提出，如图12。</p><p><img loading=lazy src=images/12.jpeg srcset="/posts/transformerqanda/images/12.jpeg, images/12.jpeg 1.5x, /posts/transformerqanda/images/12.jpeg 2x" sizes=auto data-title="图12 Transformer Encoder和Transformer Decoder交互的方式" data-alt="图12 Transformer Encoder和Transformer Decoder交互的方式" width=720 height=442 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><h2 id=7-什么是embedding>7. 什么是Embedding？</h2><p>7.1 Embedding在Transformer架构中的位置如图13所示。</p><p>7.2 提出背景: 计算机无法直接处理一个单词或者一个汉字，需要把一个token转化成计算机可以识别的向量，这也就是embedding过程。</p><p>7.3 实现方式: 最简单的embedding操作就是one hot vector，但one hot vector有一个弊端就是没有考虑词语前后之间的关系，后来也就产生了WordEmbedding，如图13。</p><div class="details admonition Note open"><div class="details-summary admonition-title"><i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden=true></i>Note<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class=details-content><div class=admonition-content>wordembedding将单词token向量化，并且考虑的单词与单词之间的相关性。</div></div></div><p><img loading=lazy src=images/13.jpeg srcset="/posts/transformerqanda/images/13.jpeg, images/13.jpeg 1.5x, /posts/transformerqanda/images/13.jpeg 2x" sizes=auto data-title="图13 Embedding的一些说明，从左往右依次为: embedding在Transformer中的位置，one hot vector，Word embedding。" data-alt="图13 Embedding的一些说明，从左往右依次为: embedding在Transformer中的位置，one hot vector，Word embedding。" width=720 height=258 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><h2 id=8-什么是positional-embedding>8. 什么是Positional Embedding？</h2><p>8.1 Positional Embedding在Transformer架构中的位置如图14所示。</p><p>8.2 提出背景: RNN作为特征提取器，是自带词的前后顺序信息的;而Attention机制并没有考虑先后顺序信息，但前后顺序信息对语义影响很大，因此需要通过Positional Embedding这种方式把前后位置信息加在输入的Embedding上。</p><p>8.3 实现方式: 传统位置编码和神经网络自动训练得到。</p><p><img loading=lazy src=images/14.jpeg srcset="/posts/transformerqanda/images/14.jpeg, images/14.jpeg 1.5x, /posts/transformerqanda/images/14.jpeg 2x" sizes=auto data-title="图14 Positional Embedding的一些说明，从左往右依次为: positional embedding在Transformer中的位置，传统位置编码的实现方式，传统位置编码ei得到的图像，每一列为一个token的位置编码。" data-alt="图14 Positional Embedding的一些说明，从左往右依次为: positional embedding在Transformer中的位置，传统位置编码的实现方式，传统位置编码ei得到的图像，每一列为一个token的位置编码。" width=720 height=245 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><h2 id=9-什么是attention>9. 什么是Attention？</h2><p>9.1 介绍Transformer，为什么要介绍Attention呢？因为在Transformer中最多的multi head attention和Mask multi head attention来自Scaled dot product attention，而scaled dot product attention来自self attention，而self attention是attention的一种，因此首先需要了解Attention，如图15所示。</p><p><img loading=lazy src=images/15.jpeg srcset="/posts/transformerqanda/images/15.jpeg, images/15.jpeg 1.5x, /posts/transformerqanda/images/15.jpeg 2x" sizes=auto data-title="图15 Attention与Transformer的关系" data-alt="图15 Attention与Transformer的关系" width=720 height=486 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>9.2 Attention到底是什么意思呢？</p><p>对于图像而言，attention就是人们看到图像中的核心关注的区域，是图像中的重点，如图16所示。对于序列而言，Attention机制本质上是为了找到<strong>输入中不同token之间的相互关系</strong>，通过权重矩阵来自发地找到词与词之间的关系。</p><p><img loading=lazy src=images/16.jpeg srcset="/posts/transformerqanda/images/16.jpeg, images/16.jpeg 1.5x, /posts/transformerqanda/images/16.jpeg 2x" sizes=auto data-title="图16 图像中的attention" data-alt="图16 图像中的attention" width=638 height=380 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>9.3 Attention是如何实现的呢？</p><p>是通过QKV实现的。</p><p>那么什么是QKV呢？Q是query，K是keys，V是values。如图17所示，举例而言，Q是大脑发出的信号，我口渴了;K是环境信息，眼睛看到的世界;V是对环境中不同的物品赋予不同的比重，水的比重加大。</p><p>总之，Attention就是通过计算QK的相似度，与V相乘得到注意力数值。</p><p>$$\text{Attention}(\mathrm{Query},\mathrm{Source})=\sum\text{Similarity}(\mathrm{Query},\mathrm{Key}<em>\mathrm{i})*\mathrm{Value}</em>\mathrm{i}$$</p><p><img loading=lazy src=images/17.jpeg srcset="/posts/transformerqanda/images/17.jpeg, images/17.jpeg 1.5x, /posts/transformerqanda/images/17.jpeg 2x" sizes=auto data-title=/posts/transformerqanda/images/17.jpeg data-alt=/posts/transformerqanda/images/17.jpeg width=658 height=420 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>9.4 为什么必须要有QKV三者？</p><p>为什么不是只有Q？因为Q1与Q2之间的关系权重，不止需要a12，也需要a21。你可能会问？我们让a12=a21不行吗？也可以尝试，但从原理上讲效果应该没有a12和a21效果好。</p><p>为什么不是只有QK？求得的权重系数需要放到输入中，可以乘Q，也可以乘K，为什么要重新乘V呢？我觉得可能是多了一组可训练参数$W_V$，使网络具有更强的学习能力。</p><h2 id=10-什么是self-attention>10. 什么是Self Attention？</h2><p>10.1 介绍Transformer，为什么要介绍self Attention呢？因为在Transformer中最多的multi head attention和Mask multi head attention来自Scaled dot product attention，而scaled dot product attention来自self attention，如图15所示。</p><p>10.2 什么是Self Attention呢？self attention和local attention、stride attention都是attention的一种;self attention是每一个Q与每一个K依次计算注意力系数，如图18所示，而像local attention是Q只与相邻的K计算注意力系数，stride attention是Q通过跳连的方式与K计算注意力系数。</p><p><img loading=lazy src=images/18.jpeg srcset="/posts/transformerqanda/images/18.jpeg, images/18.jpeg 1.5x, /posts/transformerqanda/images/18.jpeg 2x" sizes=auto data-title=/posts/transformerqanda/images/18.jpeg data-alt=/posts/transformerqanda/images/18.jpeg width=720 height=165 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>10.3 Self attention为什么可以用于处理像机器翻译这种序列数据?</p><p>输入序列中的每一个位置的数据，可以关注其他位置的信息，由此通过Attention score来提取特征或者捕获输入序列每一个token之间的关系。</p><p>10.4 Self attention是如何具体实现的? 总共分为4步，如图19所示</p><p><img loading=lazy src=images/19.jpeg srcset="/posts/transformerqanda/images/19.jpeg, images/19.jpeg 1.5x, /posts/transformerqanda/images/19.jpeg 2x" sizes=auto data-title=/posts/transformerqanda/images/19.jpeg data-alt=/posts/transformerqanda/images/19.jpeg width=720 height=440 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><h2 id=11-什么是scaled-dot-product-attention>11. 什么是Scaled dot product attention？</h2><p>11.1 self attention最常见的有两种，一种是dot product attention、另一种是additive attention，如图20所示，前者的计算效率更高。</p><p><img loading=lazy src=images/20.jpeg srcset="/posts/transformerqanda/images/20.jpeg, images/20.jpeg 1.5x, /posts/transformerqanda/images/20.jpeg 2x" sizes=auto data-title=/posts/transformerqanda/images/20.jpeg data-alt=/posts/transformerqanda/images/20.jpeg width=502 height=376 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>11.2 什么是Scaled ?</p><p>scaled的具体实现方式如图21所示，这一操作的目的是为了防止内积过大，从梯度角度考虑，避免靠近1，易训练;与batch normalization有一些相似的功能。</p><p>$$\text{Attention}(Q,K,V)=\text{softmax}(\frac{QK^T}{\sqrt{d_k}})V$$</p><h2 id=12-什么是multi-head-attention>12. 什么是Multi head attention？</h2><p>12.1 Multi head attention在Transformer架构中的位置如图15所示。</p><p>12.2 提出背景: CNN具有多个channel，可以提取图像不同维度的特征信息，那么Self attention是否可以有类似操作，可以提取不同距离token的多个维度信息呢？</p><p>12.3 什么是group 卷积？如图22所示，将输入的特征多个channel分成几个group单独做卷积，最后再进行con c操作。</p><p><img loading=lazy src=images/21.jpeg srcset="/posts/transformerqanda/images/21.jpeg, images/21.jpeg 1.5x, /posts/transformerqanda/images/21.jpeg 2x" sizes=auto data-title=/posts/transformerqanda/images/21.jpeg data-alt=/posts/transformerqanda/images/21.jpeg width=290 height=290 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>12.4 Multi head attention的实现方式？与self attention根本不同是什么？</p><p>如图23所示，以2个head的为例，将输入的Q、K、V分成两份，每一小份的Q与对应的K、V分别操作，最后计算得到的向量再进行conc操作，由此可以看出，Multi head attention与group卷积有着相似的实现方式。</p><p><img loading=lazy src=images/22.jpeg srcset="/posts/transformerqanda/images/22.jpeg, images/22.jpeg 1.5x, /posts/transformerqanda/images/22.jpeg 2x" sizes=auto data-title=/posts/transformerqanda/images/22.jpeg data-alt=/posts/transformerqanda/images/22.jpeg width=720 height=200 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>12.5 如何从输入输出的维度来理解Multi head attention？如图24所示。</p><p><img loading=lazy src=images/23.jpeg srcset="/posts/transformerqanda/images/23.jpeg, images/23.jpeg 1.5x, /posts/transformerqanda/images/23.jpeg 2x" sizes=auto data-title=/posts/transformerqanda/images/23.jpeg data-alt=/posts/transformerqanda/images/23.jpeg width=720 height=414 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><h2 id=13-什么是mask-multi-head-attention>13. 什么是Mask Multi head attention？</h2><p>13.1 Mask Multi head attention在transformer架构中的位置如图15所示。</p><p>13.2 为什么要有Mask这种操作？</p><p>Transformer预测第T个时刻的输出，不能看到T时刻之后的那些输入，从而保证训练和预测一致。</p><p>通过 Masked 操作可以防止第 i 个单词知道 i+1 个单词之后的信息，如图25所示。</p><p><img loading=lazy src=images/24.jpeg srcset="/posts/transformerqanda/images/24.jpeg, images/24.jpeg 1.5x, /posts/transformerqanda/images/24.jpeg 2x" sizes=auto data-title=/posts/transformerqanda/images/24.jpeg data-alt=/posts/transformerqanda/images/24.jpeg width=720 height=414 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>13.3 Mask操作是如何具体实现的呢？</p><p>Q1只跟K1计算，Q2只跟K1、K2计算，而对于K3、K4等，在softmax之前给一个非常大的负数，由此经过softmax之后变为0，其在矩阵上的计算原理实现如图26所示。</p><p><img loading=lazy src=images/25.jpeg srcset="/posts/transformerqanda/images/25.jpeg, images/25.jpeg 1.5x, /posts/transformerqanda/images/25.jpeg 2x" sizes=auto data-title=/posts/transformerqanda/images/25.jpeg data-alt=/posts/transformerqanda/images/25.jpeg width=768 height=270 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><h2 id=14-什么是add>14. 什么是ADD？</h2><p>14.1 Add就是残差连接，由2015年ResNet这篇文章发扬光大(目前引用量已超过16万)，与Skip connection的区别在于需要大小维度全部相同。</p><p>14.2 作为大道至简想法的极致，几乎每一个深度学习模型都会用到这个技术，可以<strong>防止网络退化</strong>，常用于解决多层网络难训练的问题。</p><p><img loading=lazy src=images/26.jpeg srcset="/posts/transformerqanda/images/26.jpeg, images/26.jpeg 1.5x, /posts/transformerqanda/images/26.jpeg 2x" sizes=auto data-title=/posts/transformerqanda/images/26.jpeg data-alt=/posts/transformerqanda/images/26.jpeg width=720 height=385 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><h2 id=15-什么是norm>15. 什么是Norm？</h2><p>15.1 Norm就是layer normalization。</p><p>15.2 核心作用: 为了训练更加稳定，和batch normalization有相同的作用，都是为了使输入的样本均值为零，方差为1。</p><p>15.3 为什么不使用batch normalization，使用的是layer normalization呢？因为一个时序数据，句子输入长度有长有短，如果使用batch normalization，则很容易造成因样本长短不一造成“训练不稳定”。BN是对同一个batch内的所有数据的同一个特征数据进行操作;而LN是对同一个样本进行操作。</p><p><img loading=lazy src=images/27.jpeg srcset="/posts/transformerqanda/images/27.jpeg, images/27.jpeg 1.5x, /posts/transformerqanda/images/27.jpeg 2x" sizes=auto data-title=/posts/transformerqanda/images/27.jpeg data-alt=/posts/transformerqanda/images/27.jpeg width=720 height=408 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><ol start=16><li>什么是FFN？</li></ol><p>16.1 FFN就是feed forward networks。</p><p>16.2 为什么有了Self attention层，还要有FFN？Attention已经有了想要的序列信息特征，MLP的作用是把信息投影到特定的空间里，再做一次非线性映射，和Self attention交替使用。</p><p>16.3 结构上: 包括两层MLP，第一层的维度为$512<em>2048$，第二层的维度为$2048</em>512$，且第二层MLP没有使用激活函数，如图29所示。</p><p><img loading=lazy src=images/28.jpeg srcset="/posts/transformerqanda/images/28.jpeg, images/28.jpeg 1.5x, /posts/transformerqanda/images/28.jpeg 2x" sizes=auto data-title=/posts/transformerqanda/images/28.jpeg data-alt=/posts/transformerqanda/images/28.jpeg width=720 height=240 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><h2 id=17-transformer是如何训练出来的>17. Transformer是如何训练出来的？</h2><p>17.1 数据上，在Transformer论文中有提到，用到了4.5M和36M的翻译句子对。</p><p>17.2 硬件上，base模型是8个P100 GPU训练了12个小时，大模型是训练了3.5天。</p><p>17.3 模型参数和调参层面:</p><p>第一，可训练的参数包括$W_Q$、$W_K$、$W_V$、$W_O$，换包括$FFN$层的参数。</p><p>第二，可调的参数包括: 每一个token向量表示的维度(d_model)、head的头数、Encoder和Decoder中block重复的次数N、FFN中间层向量的维度、Label smoothing(置信度0.1)和dropout(0.1)。</p><h2 id=18-transformer为什么效果好>18. Transformer为什么效果好？</h2><p>18.1 虽然题目是Attention is all you need，但后续一些研究表明，Attention、残差连接、layer normalization、FFN，这些因素共同成就了Transformer。</p><p>18.2 Transformer优点包括:</p><p>第一，提出深度学习继MLP、CNN、RNN后的第4大特征提取器。</p><p>第二，一开始用在机器翻译，随着GPT和Bert彻底出圈;是一个转折点，在这个点之后，NLP领域快速发展，之后多模态、大模型、视觉Transformer等开始兴起。</p><p>第三，给人们信心，原来CNN和RNN之后，还可以有效果更好的特征提取器。</p><p>18.3 Transformer的不足之处？</p><p>第一，计算量大，对硬件要求高。</p><p>第二，因为无归纳偏置，需要很多数据才可以取得很好的效果。</p><p>Ref:</br>[1]. <a href=https://mp.weixin.qq.com/s/sNyh3SzhIdsk8feYfQlTSA target=_blank rel="external nofollow noopener noreferrer">https://mp.weixin.qq.com/s/sNyh3SzhIdsk8feYfQlTSA<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></p></div><div class=post-reward><div class=comment>Buy me a coffee~</div><input type=checkbox class=reward-input name=reward id=fi-reward hidden>
<label class=reward-button for=fi-reward>赞赏</label><div class=reward-ways data-mode=fixed><div><img loading=lazy src=/images/alipay.png srcset="/images/alipay.png, /images/alipay.png 1.5x, /images/alipay.png 2x" sizes=auto data-title="Jian YE 支付宝" data-alt="Jian YE 支付宝" style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span data-animation>支付宝</span></div><div><img loading=lazy src=/images/wechatpay.png srcset="/images/wechatpay.png, /images/wechatpay.png 1.5x, /images/wechatpay.png 2x" sizes=auto data-title="Jian YE 微信" data-alt="Jian YE 微信" style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span data-animation>微信</span></div></div></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span title="更新于 2023-08-26 13:40:05">更新于 2023-08-26&nbsp;<a class=git-hash href=https://github.com/jianye0428/JianBlog/commit/c8c9755b294b9ed078cc41f77f08b768ce23a708 rel="external nofollow noopener noreferrer" target=_blank title="commit by yejian(18817571704@163.com) c8c9755b294b9ed078cc41f77f08b768ce23a708: feat: add effective stl 31 - 34"><i class="fa-solid fa-hashtag fa-fw" aria-hidden=true></i>c8c9755</a></span></div></div><div class=post-info-line><div class=post-info-md><span><a href=/posts/transformerqanda/index.md title=阅读原始文档 class=link-to-markdown>阅读原始文档</a></span><span><a href=https://github.com/jianye0428/JianBlog/edit/docs/content/posts/ML/Transformer/TransformerQandA/index.md title=编辑此页 target=_blank rel="external nofollow noopener noreferrer" class=link-to-edit>编辑此页</a></span></div><div class=post-info-share><span><a href=javascript:void(0); title="分享到 Twitter" data-sharer=twitter data-url=https://jianye0428.github.io/posts/transformerqanda/ data-title="Transformer Q & A" data-hashtags=Transformer><i class="fa-brands fa-twitter fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 Facebook" data-sharer=facebook data-url=https://jianye0428.github.io/posts/transformerqanda/ data-hashtag=Transformer><i class="fa-brands fa-facebook-square fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 Linkedin" data-sharer=linkedin data-url=https://jianye0428.github.io/posts/transformerqanda/><i class="fa-brands fa-linkedin fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 微博" data-sharer=weibo data-url=https://jianye0428.github.io/posts/transformerqanda/ data-title="Transformer Q & A"><i class="fa-brands fa-weibo fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 百度" data-sharer=baidu data-url=https://jianye0428.github.io/posts/transformerqanda/ data-title="Transformer Q & A"><i data-svg-src=/lib/simple-icons/icons/baidu.min.svg aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fa-solid fa-tags fa-fw me-1" aria-hidden=true></i><a href=/tags/transformer/ class=post-tag>Transformer</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class=post-nav><a href=/posts/attentionaqkv/ class=post-nav-item rel=prev title="Transformer | 如何理解attention中的Q,K,V？"><i class="fa-solid fa-angle-left fa-fw" aria-hidden=true></i>Transformer | 如何理解attention中的Q,K,V？</a>
<a href=/posts/effective_stl_part_six/ class=post-nav-item rel=next title="Effective STL 精度总结 [6] | 仿函数、仿函数类、函数等">Effective STL 精度总结 [6] | 仿函数、仿函数类、函数等<i class="fa-solid fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article></main><footer class=footer><div class=footer-container><div class="footer-line powered">由 <a href=https://gohugo.io/ target=_blank rel="external nofollow noopener noreferrer" title="Hugo 0.123.2">Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/hugo-fixit/FixIt target=_blank rel=external title="FixIt v0.2.18"><img class=fixit-icon src=/fixit.min.svg alt="FixIt logo">&nbsp;FixIt</a></div><div class="footer-line copyright" itemscope itemtype=http://schema.org/CreativeWork><i class="fa-regular fa-copyright fa-fw" aria-hidden=true></i>
<span itemprop=copyrightYear>2018 - 2024</span><span class=author itemprop=copyrightHolder>
<a href=https://github.com/jianye0428 target=_blank rel="external nofollow noopener noreferrer">Jian YE</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div><div class="footer-line statistics order-first"><span class=site-time title=网站运行中……><i class="fa-solid fa-heartbeat fa-fw animate-icon" aria-hidden=true></i><span class="ms-1 d-none">博客已运行</span><span class="run-times ms-1">网站运行中……</span></span></div><div class="footer-line visitor"><span id=busuanzi_container_site_uv title=总访客数><i class="fa-regular fa-user fa-fw" aria-hidden=true></i>&nbsp;<span id=busuanzi_value_site_uv><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden=true></i></span></span><span id=busuanzi_container_site_pv class=footer-divider title=总访问量><i class="fa-regular fa-eye fa-fw" aria-hidden=true></i>&nbsp;<span id=busuanzi_value_site_pv><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden=true></i></span></span></div></div></footer></div><div class=widgets><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role=button aria-label=回到顶部><i class="fa-solid fa-arrow-up fa-fw" aria-hidden=true></i><span class=variant-numeric>0%</span></div></div><a href=https://github.com/jianye0428/JianBlog title="在 GitHub 上查看程式碼，訂閱請點 Watch" target=_blank rel="external nofollow" class="github-corner right d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115h15l12 27L250 250V0z"/><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentcolor" style="transform-origin:130px 106px" class="octo-arm"/><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4l13.9-13.8C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8z" fill="currentcolor" class="octo-body"/></svg></a><div id=mask></div><div class=reading-progress-bar style=left:0;top:0;--bg-progress:#000;--bg-progress-dark:#fff></div><noscript><div class=noscript-warning>FixIt 主题在启用 JavaScript 的情况下效果最佳。</div></noscript></div><link rel=stylesheet href=/lib/katex/katex.min.css><link rel=stylesheet href=/lib/cookieconsent/cookieconsent.min.css><link rel=stylesheet href=/lib/pace/themes/blue/pace-theme-minimal.css><script src=/lib/autocomplete/autocomplete.min.js defer></script><script src=/lib/algoliasearch/algoliasearch-lite.umd.min.js defer></script><script src=/lib/instant-page/instantpage.min.js async defer type=module></script><script src=/lib/twemoji/twemoji.min.js defer></script><script src=/lib/sharer/sharer.min.js async defer></script><script src=/lib/katex/katex.min.js defer></script><script src=/lib/katex/auto-render.min.js defer></script><script src=/lib/katex/mhchem.min.js defer></script><script src=/lib/cookieconsent/cookieconsent.min.js defer></script><script src=/lib/pangu/pangu.min.js defer></script><script src=/lib/cell-watermark/watermark.min.js defer></script><script src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js async defer></script><script src=/lib/pace/pace.min.js async defer></script><script>window.config={autoBookmark:!0,code:{copyTitle:"复制到剪贴板",editLockTitle:"锁定可编辑代码块",editUnLockTitle:"解锁可编辑代码块",editable:!0,maxShownLines:50},comment:{enable:!1},cookieconsent:{content:{dismiss:"同意",link:"了解更多",message:"本网站使用 Cookies 来改善您的浏览体验。"},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},enablePWA:!0,math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},pangu:{enable:!0,selector:"article"},search:{algoliaAppID:"MTJNHU0JVB",algoliaIndex:"index",algoliaSearchKey:"5486225134d99f43826da401ee9bad57",highlightTag:"em",maxResultLength:10,noResultsFound:"没有找到结果",snippetLength:50,type:"algolia"},siteTime:"2018-05-28T20:01:01+08:00",twemoji:!0,watermark:{appendto:".wrapper>main",colspacing:30,content:'<img style="height: 0.85rem;" src="/images/favicon/jian_icon.png" alt="logo" /> jianye',enable:!0,fontfamily:"MMT_LRH,沐目体",fontsize:1.1,height:20,opacity:.0125,rotate:15,rowspacing:60,width:150}}</script><script src=/js/theme.min.js defer></script><script src=/js/custom.min.js defer></script></body></html>