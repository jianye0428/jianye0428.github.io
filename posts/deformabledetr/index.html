<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=2"><meta name=robots content="noodp"><title>Deformable DETR论文精读+代码详解 - yejian's blog</title><meta name=author content="Jian YE">
<meta name=author-link content="https://github.com/jianye0428"><meta name=description content="Abstract DETR消除了目标检任务中的手工设计痕迹，但是存在收敛慢以及Transformer的自注意力造成的特征图分辨率不能太高的问题，这就导致了小目标检测性能很差。我们的Deformable DETR只在参考点附近采样少量的key来计算注意力，因此我们的方法收敛快并且可以用到多尺度特征。 相对于Transfo"><meta name=keywords content='draft'><meta itemprop=name content="Deformable DETR论文精读+代码详解"><meta itemprop=description content="Abstract DETR消除了目标检任务中的手工设计痕迹，但是存在收敛慢以及Transformer的自注意力造成的特征图分辨率不能太高的问题，这就导致了小目标检测性能很差。我们的Deformable DETR只在参考点附近采样少量的key来计算注意力，因此我们的方法收敛快并且可以用到多尺度特征。 相对于Transfo"><meta itemprop=datePublished content="2023-10-27T15:22:03+08:00"><meta itemprop=dateModified content="2024-02-08T10:44:40+08:00"><meta itemprop=wordCount content="23903"><meta itemprop=image content="https://jianye0428.github.io/images/favicon/jian_icon.png"><meta itemprop=keywords content="Draft"><meta property="og:url" content="https://jianye0428.github.io/posts/deformabledetr/"><meta property="og:site_name" content="yejian's blog"><meta property="og:title" content="Deformable DETR论文精读+代码详解"><meta property="og:description" content="Abstract DETR消除了目标检任务中的手工设计痕迹，但是存在收敛慢以及Transformer的自注意力造成的特征图分辨率不能太高的问题，这就导致了小目标检测性能很差。我们的Deformable DETR只在参考点附近采样少量的key来计算注意力，因此我们的方法收敛快并且可以用到多尺度特征。 相对于Transfo"><meta property="og:locale" content="zh-CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-10-27T15:22:03+08:00"><meta property="article:modified_time" content="2024-02-08T10:44:40+08:00"><meta property="article:tag" content="Draft"><meta property="og:image" content="https://jianye0428.github.io/images/favicon/jian_icon.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jianye0428.github.io/images/favicon/jian_icon.png"><meta name=twitter:title content="Deformable DETR论文精读+代码详解"><meta name=twitter:description content="Abstract DETR消除了目标检任务中的手工设计痕迹，但是存在收敛慢以及Transformer的自注意力造成的特征图分辨率不能太高的问题，这就导致了小目标检测性能很差。我们的Deformable DETR只在参考点附近采样少量的key来计算注意力，因此我们的方法收敛快并且可以用到多尺度特征。 相对于Transfo"><meta name=application-name content="菠菜阿九时代峰峻啊；数量可根据；"><meta name=apple-mobile-web-app-title content="菠菜阿九时代峰峻啊；数量可根据；"><meta name=theme-color data-light=#ffffff data-dark=#252627 content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/png href=/jian_icon.png><link rel=icon type=image/png sizes=32x32 href=/jian_icon.png><link rel=icon type=image/png sizes=16x16 href=/jian_icon.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://jianye0428.github.io/posts/deformabledetr/><link rel=prev href=https://jianye0428.github.io/posts/effective_modern_c/><link rel=next href=https://jianye0428.github.io/posts/cmake_introduction/><link rel=stylesheet href=/css/style.min.css><link rel=stylesheet href=/lib/fontawesome-free/all.min.css><link rel=stylesheet href=/lib/animate/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Deformable DETR论文精读+代码详解","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/jianye0428.github.io\/posts\/deformabledetr\/"},"image":["https:\/\/jianye0428.github.io\/images\/favicon\/jian_icon.png"],"genre":"posts","keywords":"draft","wordcount":23903,"url":"https:\/\/jianye0428.github.io\/posts\/deformabledetr\/","datePublished":"2023-10-27T15:22:03+08:00","dateModified":"2024-02-08T10:44:40+08:00","publisher":{"@type":"Organization","name":"Jian YE","logo":"https:\/\/jianye0428.github.io\/images\/favicon\/jian_icon.png"},"author":{"@type":"Person","name":"Jian YE"},"description":""}</script></head><body data-header-desktop=sticky data-header-mobile=auto><script>(window.localStorage?.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("data-theme","dark")</script><div class=wrapper data-page-style=wide><header class="desktop animate__faster" id=header-desktop><div class=header-wrapper data-github-corner=right><div class=header-title><a href=/ title="yejian's blog"><img loading=lazy src=/images/favicon/jian_icon.png srcset="/images/favicon/jian_icon.png, /images/favicon/jian_icon.png 1.5x, /images/favicon/jian_icon.png 2x" sizes=auto data-title="yejian's blog" data-alt="yejian's blog" class=logo style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span class=header-title-text>Jian's Blog</span></a><span class=header-subtitle></span></div><nav><ul class=menu><li class=menu-item><a class=menu-link href=/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> 所有文章</a></li><li class=menu-item><a class=menu-link href=/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> 分类</a></li><li class=menu-item><a class=menu-link href=/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> 标签</a></li><li class=menu-item><a class=menu-link href=/friends/ title=友情链接><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden=true></i> 友链</a></li><li class=menu-item><a class=menu-link href=/guestbook/><i class="fa-solid fa-comments fa-fw fa-sm" aria-hidden=true></i> 留言</a></li><li class="menu-item has-children"><a class=menu-link href=/about/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 关于</a><i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden=true></i><ul class=sub-menu><li class=menu-item><a class=menu-link href=/projects/_index.zh-tw/ title=項目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的項目</a></li><li class=menu-item><a class=menu-link href=/projects/ title=项目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的项目</a></li></ul></li><li class=menu-item><a class=menu-link href=/pilot/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 导航</a></li><li class="menu-item delimiter"></li><li class="menu-item search" id=search-desktop><input type=text placeholder=搜索文章标题或内容…… id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></li><li class="menu-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></li></ul></nav></div></header><header class="mobile animate__faster" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="yejian's blog"><img loading=lazy src=/images/favicon/jian_icon.png srcset="/images/favicon/jian_icon.png, /images/favicon/jian_icon.png 1.5x, /images/favicon/jian_icon.png 2x" sizes=auto data-title=/images/favicon/jian_icon.png data-alt=/images/favicon/jian_icon.png class=logo style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span class=header-title-text>Jian's Blog</span></a><span class=header-subtitle></span></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><nav><ul class=menu id=menu-mobile><li class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索文章标题或内容…… id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></li><li class=menu-item><a class=menu-link href=/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> 所有文章</a></li><li class=menu-item><a class=menu-link href=/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> 分类</a></li><li class=menu-item><a class=menu-link href=/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> 标签</a></li><li class=menu-item><a class=menu-link href=/friends/ title=友情链接><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden=true></i> 友链</a></li><li class=menu-item><a class=menu-link href=/guestbook/><i class="fa-solid fa-comments fa-fw fa-sm" aria-hidden=true></i> 留言</a></li><li class=menu-item><span class=nested-item><a class=menu-link href=/about/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 关于</a>
<i class="dropdown-icon fa-solid fa-chevron-right" aria-hidden=true></i></span><ul class=sub-menu><li class=menu-item><a class=menu-link href=/projects/_index.zh-tw/ title=項目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的項目</a></li><li class=menu-item><a class=menu-link href=/projects/ title=项目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的项目</a></li></ul></li><li class=menu-item><a class=menu-link href=/pilot/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 导航</a></li><li class="menu-item text-center"><a class=menu-link href=https://github.com/jianye0428/ title=GitHub rel="noopener noreferrer" target=_blank><i class='fa-brands fa-github fa-fw' aria-hidden=true></i></a></li><li class="menu-item menu-system"><span class="menu-system-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></span></li></ul></nav></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class="container container-reverse"><aside class=toc id=toc-auto><h2 class=toc-title>目录&nbsp;<i class="toc-icon fa-solid fa-angle-down fa-fw" aria-hidden=true></i></h2><div class=toc-content id=toc-content-auto></div></aside><aside class=aside-custom></aside><article class="page single"><div class=header><h1 class="single-title animate__animated animate__flipInX"><span>Deformable DETR论文精读+代码详解</span></h1></div><div class=post-meta><div class=post-meta-line><span class=post-author><a href=https://github.com/jianye0428 title=作者 target=_blank rel="external nofollow noopener noreferrer author" class=author><img loading=lazy src="https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp" srcset="https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp, https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp 1.5x, https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp 2x" sizes=auto data-title="Jian YE" data-alt="Jian YE" class=avatar style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'>&nbsp;Jian YE</a></span>
<span class=post-category>收录于 <a href=/categories/objectdetection/><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> ObjectDetection</a></span></div><div class=post-meta-line><span title="发布于 2023-10-27 15:22:03"><i class="fa-regular fa-calendar-alt fa-fw me-1" aria-hidden=true></i><time datetime=2023-10-27>2023-10-27</time></span>&nbsp;<span title="更新于 2024-02-08 10:44:40"><i class="fa-regular fa-edit fa-fw me-1" aria-hidden=true></i><time datetime=2024-02-08>2024-02-08</time></span>&nbsp;<span><i class="fa-solid fa-pencil-alt fa-fw me-1" aria-hidden=true></i>约 23903 字</span>&nbsp;<span><i class="fa-regular fa-clock fa-fw me-1" aria-hidden=true></i>预计阅读 48 分钟</span>&nbsp;<span id=busuanzi_container_page_pv class="busuanzi_visitors comment-visitors" data-flag-title="Deformable DETR论文精读+代码详解">
<i class="fa-regular fa-eye fa-fw me-1" aria-hidden=true></i><span id=busuanzi_value_page_pv>-</span>&nbsp;次阅读
</span>&nbsp;</div></div><div class="details toc" id=toc-static data-kept=false><div class="details-summary toc-title"><span>目录</span>
<span><i class="details-icon fa-solid fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#abstract>Abstract</a></li><li><a href=#1introduction>1、Introduction</a></li><li><a href=#2related-work>2、Related work</a></li><li><a href=#3revisiting-transformers-and-detr>3、Revisiting Transformers And DETR</a><ul><li><a href=#31transformer中的multi-head-self-attention>3.1、Transformer中的Multi-Head Self-Attention</a></li><li><a href=#32detr>3.2、DETR</a></li></ul></li><li><a href=#4method>4、Method</a><ul><li><a href=#41deformable-attention-module>4.1、Deformable Attention Module</a></li><li><a href=#42multi-scale-deformable-attention-module>4.2、Multi-Scale Deformable Attention Module</a></li><li><a href=#43-deformable-transformer>4.3 Deformable Transformer</a></li><li><a href=#44encoder>4.4、Encoder</a></li><li><a href=#44decoder>4.4、Decoder</a></li><li><a href=#45deformable-transformer>4.5、Deformable Transformer</a></li></ul></li><li><a href=#5experiment>5、Experiment</a></li><li><a href=#6改进策略>6、改进策略</a></li><li><a href=#7conclusion>7、Conclusion</a></li><li><a href=#8qa>8、Q&amp;A</a></li><li><a href=#9与其它方法比较>9、与其它方法比较</a></li></ul></nav></div></div><div class=content id=content data-end-flag=（完）><h2 id=abstract>Abstract</h2><p>DETR消除了目标检任务中的手工设计痕迹，但是存在<font color=red>收敛慢</font>以及<font color=red>Transformer的自注意力造成的特征图分辨率不能太高</font>的问题，这就导致了小目标检测性能很差。我们的Deformable DETR只在<mark>参考点附近采样少量的key来计算注意力</mark>，因此我们的方法收敛快并且可以用到多尺度特征。</p><p>相对于Transformer那种全局(global)&密集(dense)的注意力机制，这里提出了一种新玩法: <strong>每个参考点仅关注邻域的一组采样点，这些采样点的位置并非固定，而是可学习的</strong>(和可变形卷积一样)，从而实现了一种局部(local)&稀疏(sparse)的高效注意力机制。</p><h2 id=1introduction>1、Introduction</h2><p>传统目标检测任务有很多<strong>手工设计痕迹</strong>，所以不是端到端的网络。DETR运用到了Transformer强大的功能以及全局关系建模能力来取代目标检测中人工设计痕迹来达到端到端的目的。</p><p>DETR 的优势:
(i). 第一个端到端的目标检测器；
(ii). 不需要众多手工设计组件(如anchor、固定规则的标签分配策略、NMS后处理等)
(iii). DETR实质上相当于是给出了一个方法论，犹如“普度众生”，告诉大家Transformer可以拿到目标检测中来玩，并没有过多地追求其它方面的成就。</p><p>DETR的两大缺点:</p><ol><li><strong>收敛速度慢(slow convergence)</strong>: 因为全局像素之间计算注意力要收敛到几个稀疏的像素点需要消耗很长的时间。</li><li><strong>小目标检测差</strong>: 目标检测基本都是在大分辨率的特征图上进行小目标的检测，但是Transformer中的Self Attention的计算复杂度是平方级别的，所以只能利用到最后一层特征图。<ul><li><strong>Transformer在初始化时，分配给所有特征像素的注意力权重几乎是均等的</strong>，这就造成了模型需要长时间去学习关注真正有意义的位置，这些位置应该是稀疏的；</li><li><strong>Transformer在计算注意力权重时，伴随着高计算量与空间复杂度</strong>。特别是在编码器部分，与特征像素点的数量成平方级关系，因此难以处理高分辨率的特征(这点也是DETR检测小目标效果差的原因)</li></ul></li></ol><p><code>可变形卷积DCN</code>是一种注意稀疏空间位置很好的机制，但是其<mark>缺乏元素之间关系的建模能力</mark>。</p><p>综上所述，<font color=red><code>Deformable Attention</code>模块结合了DCN稀疏采样能力和Transformer的全局关系建模能力。这个模块可以聚合多尺度特征，不需要FPN了，我们用这个模块替换了<code>Transformer Encoder</code>中的<code>Multi-Head Self-Attention</code>模块和<code>Transformer Decoder</code>中的<code>Cross Attention</code>模块</font>。</p><p>Deformable DETR的提出可以帮助探索更多端到端目标检测方案，提出了bbox迭代微调策略和两阶段方法，其中iterative bounding box refinement类似Cascade R-CNN方法，two stage类似RPN。</p><h2 id=2related-work>2、Related work</h2><p>Transformer中包含了<strong>多头自注意力</strong>和<strong>交叉注意力机制</strong>，其中多头自注意力机制对key的数量很敏感，平方级别的复杂度导致不能有太多的key，解决方法主要可以分为三类。</p><p>(1)第一类解决方法为在key上使用预定义稀疏注意力模式，例如将注意力限制在一个固定的局部窗口上，这将导致失去了全局信息。</p><p>(2)第二类是通过数据学习到相关的稀疏注意力。</p><p>(3)第三类是寻找自注意力中低等级的属性，类似限制关键元素的尺寸大小。</p><p>图像领域的注意力方法大多数都局限于第一种设计方法，但是因为内存模式原因速度要比传统卷积慢3倍(相同的FLOPs下)。DCN可以看作是一种自注意力机制，它比自注意力机制更加高效有效，但是其缺少元素关系建模的机制。我们的可变形注意力模块来源于DCN，并且属于第二类注意力方法。它只关注从q特征预测得到的一小部分固定数量的采样点。</p><p>目标检测任务一个难点就是高效的表征不同尺度下的物体。现在有的方法比如FPN，PA-FPN，NAS-FPN，Auto-FPN，BiFPN等。我们的多尺度可变形注意力模块可以自然的融合基于注意力机制的多尺度特征图，不需要FPN了。</p><h2 id=3revisiting-transformers-and-detr>3、Revisiting Transformers And DETR</h2><h3 id=31transformer中的multi-head-self-attention>3.1、Transformer中的Multi-Head Self-Attention</h3><p>该模块计算复杂度为: $O(N_qC^2+N_kC^2+N_qN_kC)$ ，其中 $C$ 代表特征图维度，$N_q$ 和 $N_k$ 均为图片中的像素(pixel)，因此有 $N_{q}=N_{k}\gg C$ 。所以计算复杂度可以简化为 $O(N_{q}N_{k}C)$ ，可以得出其与图片像素的数量成平方级别的计算复杂度。</p><h3 id=32detr>3.2、DETR</h3><p><a href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2005.12872v3" target=_blank rel="external nofollow noopener noreferrer">DETR<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>在目标检测领域中引入了Transformer结构并且取得了不错的效果。这套范式摒弃了传统目标检测中的anchor和post processing 机制，而是先预先设定100个object queries然后进行二分图匹配计算loss。其具体流程图(pipeline)如下:</p><p><img loading=lazy src=images/3_1.webp srcset="/posts/deformabledetr/images/3_1.webp, images/3_1.webp 1.5x, /posts/deformabledetr/images/3_1.webp 2x" sizes=auto data-title=/posts/deformabledetr/images/3_1.webp data-alt=/posts/deformabledetr/images/3_1.webp width=720 height=190 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><ol><li><p>输入图片<code>3×800×1066</code>的一张图片，经过卷积神经网络提取特征，长宽32倍下采样后得到<code>2048×25×34</code>，然后通过一个<code>1×1 Conv</code>进行降维最终得到输出shape为<code>256×25×34</code>.</p></li><li><p>positional encoding为绝对位置编码，为了和特征完全匹配形状也为<code>256×25×34</code>，然后和特征进行元素级别的相加后输入到Transformer Encoder中。</p></li><li><p>输入到Encoder的尺寸为<code>(25×34)×256=850×256</code>，代表有850个token，每个token的维度为256，<strong>Encoder不改变输入的Shape</strong>。</p></li><li><p><code>Encoder</code>的输出和<code>object queries</code>输入到Decoder中形成<code>cross attention</code>，<code>object queries</code>的维度设置为<code>anchor数量×token数量</code>。</p></li><li><p><code>Decoder</code>输出到<code>FFN</code>进行分类和框定位，其中<code>FFN</code>是共享参数的。</p></li></ol><p><strong>Tips</strong>: 虽然DETR没有anchor，但是object queries其实就是起到了anchor的作用。</p><h2 id=4method>4、Method</h2><h3 id=41deformable-attention-module>4.1、Deformable Attention Module</h3><p><img loading=lazy src=images/4_1.webp srcset="/posts/deformabledetr/images/4_1.webp, images/4_1.webp 1.5x, /posts/deformabledetr/images/4_1.webp 2x" sizes=auto data-title=/posts/deformabledetr/images/4_1.webp data-alt=/posts/deformabledetr/images/4_1.webp width=720 height=400 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>Deformable Attention Module主要思想是结合了<strong>DCN</strong>和<strong>自注意力</strong>，目的就是<u>为了通过在输入特征图上的参考点(reference point)附近只采样少数点(deformable detr设置为3个点)来作为注意力的 $k$</u>。因此要解决的问题就是:
(1). 确定reference point。
(2). 确定每个reference point的偏移量(offset)。
(3). 确定注意力权重矩阵。</p><p>在Encoder和Decoder中实现方法不太一样，加下来详细叙述。</p><p><strong>Encoder部分</strong></p><p>在Encoder部分，输入的Query Feature $z_q$ 为加入了位置编码的特征图<code>(src+pos)</code>，$value(x)$ 的计算方法只使用了src而没有位置编码(<code>value_proj</code>函数)。</p><p>(1). <strong>reference point</strong>确定方法为用了<code>torch.meshgrid</code>方法，调用的函数如下(get_reference_points)，有一个细节就是参考点归一化到0和1之间，因此取值的时候要用到<strong>双线性插值</strong>的方法。
<strong>不同点:</strong> 在Decoder中，参考点的获取方法为<code>object queries</code>通过一个<code>nn.Linear</code>得到每个对应的<code>reference point</code>。</p><div class=highlight id=id-1><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_reference_points</span><span class=p>(</span><span class=n>spatial_shapes</span><span class=p>,</span> <span class=n>valid_ratios</span><span class=p>,</span> <span class=n>device</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=n>reference_points_list</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>  <span class=k>for</span> <span class=n>lvl</span><span class=p>,</span> <span class=p>(</span><span class=n>H_</span><span class=p>,</span> <span class=n>W_</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>spatial_shapes</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=c1># 从0.5到H-0.5采样H个点，W同理 这个操作的目的也就是为了特征图的对齐</span>
</span></span><span class=line><span class=cl>      <span class=n>ref_y</span><span class=p>,</span> <span class=n>ref_x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>meshgrid</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>H_</span> <span class=o>-</span> <span class=mf>0.5</span><span class=p>,</span> <span class=n>H_</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                                      <span class=n>torch</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>W_</span> <span class=o>-</span> <span class=mf>0.5</span><span class=p>,</span> <span class=n>W_</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>))</span>
</span></span><span class=line><span class=cl>      <span class=n>ref_y</span> <span class=o>=</span> <span class=n>ref_y</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)[</span><span class=kc>None</span><span class=p>]</span> <span class=o>/</span> <span class=p>(</span><span class=n>valid_ratios</span><span class=p>[:,</span> <span class=kc>None</span><span class=p>,</span> <span class=n>lvl</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span> <span class=o>*</span> <span class=n>H_</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=n>ref_x</span> <span class=o>=</span> <span class=n>ref_x</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)[</span><span class=kc>None</span><span class=p>]</span> <span class=o>/</span> <span class=p>(</span><span class=n>valid_ratios</span><span class=p>[:,</span> <span class=kc>None</span><span class=p>,</span> <span class=n>lvl</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=n>W_</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=n>ref</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>((</span><span class=n>ref_x</span><span class=p>,</span> <span class=n>ref_y</span><span class=p>),</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=n>reference_points_list</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>ref</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>reference_points</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>(</span><span class=n>reference_points_list</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>reference_points</span> <span class=o>=</span> <span class=n>reference_points</span><span class=p>[:,</span> <span class=p>:,</span> <span class=kc>None</span><span class=p>]</span> <span class=o>*</span> <span class=n>valid_ratios</span><span class=p>[:,</span> <span class=kc>None</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>reference_points</span></span></span></code></pre></td></tr></table></div></div><p>(2)计算offset的方法为对 $z_q$ 做一个<code>nn.Linear</code>，得到多组偏移量，每组偏移量的维度为参考点的个数，组数为注意力头的数量。</p><p>(3)计算注意力权重矩阵的方法为过一个<code>nn.Linear</code>和一个<code>F.softmax</code>，得到每个头的注意力权重。</p><p><strong>如图2所示</strong>，分头计算完的注意力最终会拼接到一起，然后最后过一个nn.Linear得到输入 $x$ 的最终输出。</p><h3 id=42multi-scale-deformable-attention-module>4.2、Multi-Scale Deformable Attention Module</h3><p><img loading=lazy src=images/4_2.webp srcset="/posts/deformabledetr/images/4_2.webp, images/4_2.webp 1.5x, /posts/deformabledetr/images/4_2.webp 2x" sizes=auto data-title=/posts/deformabledetr/images/4_2.webp data-alt=/posts/deformabledetr/images/4_2.webp width=720 height=278 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p><strong>Multi-Scale Features & Scale-Level Embedding</strong></p><p>多尺度的<code>Deformable Attention</code>模块也是在多尺度特征图上计算的。多尺度的特征融合方法则是取了骨干网络(ResNet)最后三层的特征图C3，C4，C5，并且用了一个Conv3x3 Stride2的卷积得到了一个C6构成了四层特征图。下采样率对应为8、16、32， $C_6$ 由 $C_5$ 经过步长为2的3x3卷积得到。特别的是会通过卷积操作将通道数量统一为256(也就是token的数量)，然后在这四个特征图上运行<code>Deformable Attention Module</code>并且进行直接相加得到最终输出。其中<code>Deformable Attention Module</code>算子的pytorch实现如下:</p><div class=highlight id=id-2><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>ms_deform_attn_core_pytorch</span><span class=p>(</span><span class=n>value</span><span class=p>,</span> <span class=n>value_spatial_shapes</span><span class=p>,</span> <span class=n>sampling_locations</span><span class=p>,</span> <span class=n>attention_weights</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># for debug and test only,</span>
</span></span><span class=line><span class=cl>    <span class=c1># need to use cuda version instead</span>
</span></span><span class=line><span class=cl>    <span class=n>N_</span><span class=p>,</span> <span class=n>S_</span><span class=p>,</span> <span class=n>M_</span><span class=p>,</span> <span class=n>D_</span> <span class=o>=</span> <span class=n>value</span><span class=o>.</span><span class=n>shape</span> <span class=c1># batch size, number token, number head, head dims</span>
</span></span><span class=line><span class=cl>    <span class=c1># Lq_: number query, L_: level number, P_: sampling number采样点数</span>
</span></span><span class=line><span class=cl>    <span class=n>_</span><span class=p>,</span> <span class=n>Lq_</span><span class=p>,</span> <span class=n>M_</span><span class=p>,</span> <span class=n>L_</span><span class=p>,</span> <span class=n>P_</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>sampling_locations</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>    <span class=c1># 按照level划分value</span>
</span></span><span class=line><span class=cl>    <span class=n>value_list</span> <span class=o>=</span> <span class=n>value</span><span class=o>.</span><span class=n>split</span><span class=p>([</span><span class=n>H_</span> <span class=o>*</span> <span class=n>W_</span> <span class=k>for</span> <span class=n>H_</span><span class=p>,</span> <span class=n>W_</span> <span class=ow>in</span> <span class=n>value_spatial_shapes</span><span class=p>],</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># [0, 1] -&gt; [-1, 1] 因为要满足F.grid_sample的输入要求</span>
</span></span><span class=line><span class=cl>    <span class=n>sampling_grids</span> <span class=o>=</span> <span class=mi>2</span> <span class=o>*</span> <span class=n>sampling_locations</span> <span class=o>-</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>    <span class=n>sampling_value_list</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>lid_</span><span class=p>,</span> <span class=p>(</span><span class=n>H_</span><span class=p>,</span> <span class=n>W_</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>value_spatial_shapes</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># N_, H_*W_, M_, D_ -&gt; N_, H_*W_, M_*D_ -&gt; N_, M_*D_, H_*W_ -&gt; N_*M_, D_, H_, W_</span>
</span></span><span class=line><span class=cl>        <span class=n>value_l_</span> <span class=o>=</span> <span class=n>value_list</span><span class=p>[</span><span class=n>lid_</span><span class=p>]</span><span class=o>.</span><span class=n>flatten</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>N_</span><span class=o>*</span><span class=n>M_</span><span class=p>,</span> <span class=n>D_</span><span class=p>,</span> <span class=n>H_</span><span class=p>,</span> <span class=n>W_</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># N_, Lq_, M_, P_, 2 -&gt; N_, M_, Lq_, P_, 2 -&gt; N_*M_, Lq_, P_, 2</span>
</span></span><span class=line><span class=cl>        <span class=n>sampling_grid_l_</span> <span class=o>=</span> <span class=n>sampling_grids</span><span class=p>[:,</span> <span class=p>:,</span> <span class=p>:,</span> <span class=n>lid_</span><span class=p>]</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>flatten</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># N_*M_, D_, Lq_, P_</span>
</span></span><span class=line><span class=cl>        <span class=c1># 用双线性插值从feature map上获取value，因为mask的原因越界所以要zeros的方法进行填充</span>
</span></span><span class=line><span class=cl>        <span class=n>sampling_value_l_</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>grid_sample</span><span class=p>(</span><span class=n>value_l_</span><span class=p>,</span> <span class=n>sampling_grid_l_</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                          <span class=n>mode</span><span class=o>=</span><span class=s1>&#39;bilinear&#39;</span><span class=p>,</span> <span class=n>padding_mode</span><span class=o>=</span><span class=s1>&#39;zeros&#39;</span><span class=p>,</span> <span class=n>align_corners</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>sampling_value_list</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>sampling_value_l_</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># (N_, Lq_, M_, L_, P_) -&gt; (N_, M_, Lq_, L_, P_) -&gt; (N_, M_, 1, Lq_, L_*P_)</span>
</span></span><span class=line><span class=cl>    <span class=n>attention_weights</span> <span class=o>=</span> <span class=n>attention_weights</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>N_</span><span class=o>*</span><span class=n>M_</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>Lq_</span><span class=p>,</span> <span class=n>L_</span><span class=o>*</span><span class=n>P_</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 不同scale计算出的multi head attention 进行相加，返回output后还需要过一个Linear层</span>
</span></span><span class=line><span class=cl>    <span class=n>output</span> <span class=o>=</span> <span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>(</span><span class=n>sampling_value_list</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>flatten</span><span class=p>(</span><span class=o>-</span><span class=mi>2</span><span class=p>)</span> <span class=o>*</span> <span class=n>attention_weights</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>N_</span><span class=p>,</span> <span class=n>M_</span><span class=o>*</span><span class=n>D_</span><span class=p>,</span> <span class=n>Lq_</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>output</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>contiguous</span><span class=p>()</span></span></span></code></pre></td></tr></table></div></div><p>要知道，DETR仅用了单尺度特征，于是对于特征点位置信息的编码，使用的是三角函数，不同位置的特征点会对应不同的编码值，没问题。但是，注意了，这仅能区分位于单尺度特征点的位置！而在多尺度特征中，位于不同特征层的特征点可能拥有相同的(h,w)坐标，这样就无法区分它们的位置编码了。</p><p>针对这个问题，作者增加使用一个称之为<font color=red>scale-level embedding</font>的东东，它<strong>仅用于区分不同的特征层</strong>，也就是同一特征层中的所有特征点会对应相同的scale-level embedding，于是有几层特征就使用几个不同的scale-level embedding。</p><p>另外，不同于三角函数那种固定地利用公式计算出来的编码方式，这个scale-level embedding是随机初始化并且是随网络一起训练的、是可学习的:</p><div class=highlight id=id-3><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># scale-level embedding</span>
</span></span><span class=line><span class=cl><span class=c1># 对4个特征层每层附加256-dim的embedding</span>
</span></span><span class=line><span class=cl><span class=c1># 目的是为了区分query对应到哪个特征层，它会与position embedding相加在一起</span>
</span></span><span class=line><span class=cl><span class=c1># 注意: 位于同一个特征的所有query都会对应到相同的scale-level embedding</span>
</span></span><span class=line><span class=cl><span class=bp>self</span><span class=o>.</span><span class=n>level_embed</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Parameter</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>(</span><span class=n>num_feature_levels</span><span class=p>,</span> <span class=n>d_model</span><span class=p>))</span></span></span></code></pre></td></tr></table></div></div><p>在实际使用时，这个 scale-level embedding 与基于三角函数公式计算的 position embedding 相加在一起作为位置信息的嵌入:</p><div class=highlight id=id-4><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 由于 position embedding仅区分h, w的位置，因此对于不同特征层有相同坐标值的特征点来说，是无法区分的，于是这里附加上scale-level embedding作为特征层的区分信息，这样，所有特征点的位置信息就各不相同了</span>
</span></span><span class=line><span class=cl><span class=c1># (bs, c, h, w) =&gt; (bs, h*w, c)</span>
</span></span><span class=line><span class=cl><span class=n>pos_embed</span> <span class=o>=</span> <span class=n>pos_embed</span><span class=o>.</span><span class=n>flatten</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># (bs, h*w, c) + (1, 1, 256)</span>
</span></span><span class=line><span class=cl><span class=c1># note that c = 256 here</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>lvl_pos_embed</span> <span class=o>=</span> <span class=n>pos_embed</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>level_embed</span><span class=p>[</span><span class=n>lvl</span><span class=p>]</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span></span></span></code></pre></td></tr></table></div></div><p><strong>Deformable Attention(&amp;Multi-Scale)</strong></p><p>可变形注意力的道理用大白话来说很简单: query不是和全局每个位置的key都计算注意力权重，而是<strong>对于每个query，仅在全局位置中采样部分位置的key，并且value也是基于这些位置进行采样插值得到的</strong>，最后将这个<strong>局部&稀疏</strong>的注意力权重施加在对应的value上。</p><p>Transformer中多头注意力的公式如下:</p><p>$$
\text{MultiHeadAttn}(z_q,x)=\sum_{m=1}^MW_m\big[\sum_{k\in\Omega_k}A_{mqk}\cdot W_m^{\prime}x_k\big],
$$</p><p>其中，$z_q$ 看作query，由 $x$ 经过线性变换生成，$q$ 是对应的索引，$k$ 是key的索引, $\Omega_k$ 即所有的 $k$ 集合，$m$ 代表是第几个注意力头部，$W_m$ 是对注意力施加在value后的结果进行线性变换从而得到不同头部的输出结果，$W_m^{&rsquo;}$用于将 $x_k$ 变换成value，$A_{mqk}$ 代表归一化的注意力权重。</p><p>Deformable Attetion公式:</p><p>$$
\text{DeformAttn}(z_q,p_q,x)=\sum_{m=1}^MW_m\big[\sum_{k=1}^KA_{mqk}\cdot W_m&rsquo;x(p_q+\Delta p_{mqk})\big],
$$</p><p>和Transformer的很像是不是？(老师我没有抄作业，别凶..)可以看到，这里多了 $p_q$ 和 $\Delta p_{mqk}$。其中，前者代表 $z_q$ 的位置(理解成坐标即可)，是2d向量，作者称其为参考点(reference points)；而后者是采样集合点相对于参考点的位置偏移(offsets)。</p><p>可以看到，<strong>每个query在每个头部中采样K个位置，只需和这些位置的特征交互</strong>($x(p_q+\Delta p_{mqk})$ 代表基于采样点位置插值出来的value)，并不需要像Transformer般一开始先从全局位置开始学习才能逐渐过渡到关注局部(&稀疏的)的、真正有意义的位置。</p><p>需要注意的是，如可变形卷积一样，<strong>位置偏移 $\Delta p_{mqk}$ 是可学习的，由query经过全连接层得到。并且，注意力权重也一样，直接由query经过全连接层得到(因此，在可变形注意力机制下，其实没有真正所谓的key来与query交互计算，为何可以这样做，后文CW会谈自己的看法)</strong>！同时在K个采样点之间归一化，而非像Transformer般是由query与key交互计算得出的。</p><p>OK，顺着来，看看可变形注意力是如何应用到多尺度特征上的，依旧是公式走起:</p><p>$$
\text{MSDeformAttn}(z_{q},\hat{p}<em>{q},{x^{l}}</em>{l=1}^{L})=\sum_{m=1}^{M}W_{m}\big[\sum_{l=1}^{L}\sum_{k=1}^{K}A_{mlqk}\cdot W_{m}^{\prime}x^{l}(\phi_{l}(\hat{p}<em>{q})+\Delta p</em>{mlqk})\big]
$$</p><p>这个也和上面的非常想是不是！？(老师我真的没有抄作业啊..太难了~)相比于上面，这里多了 ${x^l}<em>{l=1}^{L}$, $\phi</em>{l}$。另外，$p_q$ 头上多了个小尖角，代表归一化到 $[0,1]$，而 $\phi_{l}$ 正是用于将归一化的坐标映射(re-scales)到各个特征层去，这样，每个参考点在所有特征层都会有一个对应的(归一化)坐标，从而方便计算在不同特征层进行采样的那些点的位置。至于 ${x^l}_{l=1}^{L}$ 嘛，当然就是代表多尺度特征咯，$x_l$ 代表第 $l$ 层的特征。</p><p>在这里，每个query在每个特征层都会采样K个点，共有L层特征，从而在每个头部内共采样LK个点，注意力权重也是在这LK个点之间进行归一化。</p><p>另外，作者还提到，当L=K=1且 $W_m^{&rsquo;}$ 是identity矩阵时，该模块就退化成可变形卷积；相对地，当采样所有可能的位置(即全局位置)时，该模块等效于Transfomer中的注意力。</p><p>道理说完，依旧如CW的风格，是时候上代码了:</p><div class=highlight id=id-5><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>MSDeformAtten</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>d_model</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span> <span class=n>n_levels</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>n_heads</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span> <span class=n>n_points</span><span class=o>=</span><span class=mi>4</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Multi-Scale Deformable Attention Module
</span></span></span><span class=line><span class=cl><span class=s2>    :param d_model    hidden dimensions
</span></span></span><span class=line><span class=cl><span class=s2>    :param n_levels   number of feature levels
</span></span></span><span class=line><span class=cl><span class=s2>    :param n_heads    number of attention heads
</span></span></span><span class=line><span class=cl><span class=s2>    :param n_points   number of sampling points per attention head per feature level
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=nb>super</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>d_model</span> <span class=o>%</span> <span class=n>n_heads</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s1>&#39;d_model must be divisible by n_heads, but got </span><span class=si>{}</span><span class=s1> and </span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>n_heads</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>_d_per_head</span> <span class=o>=</span> <span class=n>d_model</span> <span class=o>//</span> <span class=n>n_heads</span>
</span></span><span class=line><span class=cl>    <span class=c1># you&#39;d better set _d_per_heads to a power of 2 which is more efficient in out CUDA implementation</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=ow>not</span> <span class=n>_is_power_of_2</span><span class=p>(</span><span class=n>_d_per_head</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=n>warnings</span><span class=o>.</span><span class=n>warn</span><span class=p>(</span><span class=s2>&#34;You&#39;d better set d_model in MSDeformAttn to make the dimension of each attention head&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;power of 2&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;which is more efficient in out CUDA implementation.&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 用于cuda实现</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>im2col_step</span> <span class=o>=</span> <span class=mi>64</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>d_model</span> <span class=o>=</span> <span class=n>d_model</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>n_levels</span> <span class=o>=</span> <span class=n>n_levels</span> <span class=c1># 4</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span> <span class=o>=</span> <span class=n>n_heads</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>n_points</span> <span class=o>=</span> <span class=n>n_points</span> <span class=c1># 4</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 采样点的坐标偏移， 每个query在每个注意力头和每个特征层都需要采样n_points个</span>
</span></span><span class=line><span class=cl>    <span class=c1># 由于x, y坐标都有对应的偏移量，因此还要*2</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>sampling_offsets</span> <span class=o>=</span>  <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>n_heads</span> <span class=o>*</span> <span class=n>n_levels</span> <span class=o>*</span> <span class=n>n_points</span> <span class=o>*</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 每个query对应的所有采样点的注意力权重</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>attention_weights</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>n_heads</span> <span class=o>*</span> <span class=n>n_levels</span> <span class=o>*</span> <span class=n>n_points</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 线性变换得到value</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>value_proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>d_model</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 最后经过这个线性变换得到输出结果</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>output_proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Liear</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>d_model</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>__reset_parameters</span><span class=p>()</span></span></span></code></pre></td></tr></table></div></div><p>接下来有个亮点，在以上最后的 _reset_parameters() 中，是关于生成初始的采样点位置的:</p><div class=highlight id=id-6><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>_reset_parameters</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=n>constant_</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>sampling_offsets</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;&#34;&#34;初始化偏移量预测的偏置(bias), 使得初始偏移位置犹如不同大小的方形卷积核组合&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1># (8,) [0, pi / 4, pi / 2, 3 * pi / 2, ..., 7 * pi / 4]</span>
</span></span><span class=line><span class=cl>  <span class=n>thetas</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span><span class=p>,</span> <span class=n>dtype</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span><span class=o>.</span><span class=p>(</span><span class=mf>2.0</span> <span class=o>*</span> <span class=n>math</span><span class=o>.</span><span class=n>pi</span> <span class=o>/</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=c1># (8, 2)</span>
</span></span><span class=line><span class=cl>  <span class=n>grid_init</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>([</span><span class=n>thetas</span><span class=o>.</span><span class=n>cos</span><span class=p>(),</span> <span class=n>thetas</span><span class=o>.</span><span class=n>sin</span><span class=p>()],</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=c1># grid_init / grid_init.abs().max(-1, keepdi=True)[0]这步计算得到8个头对应的坐标偏移:</span>
</span></span><span class=line><span class=cl>  <span class=c1># (1, 0), (1, 1), (0, 1), (-1, 1), (-1, 0), (-1, -1), (0, -1), (1, -1)</span>
</span></span><span class=line><span class=cl>  <span class=c1># 从图形视觉上来看， 形成的偏移位置相当于是3x3， 5x5, 7x7, 9x9正方形卷积核(出去中心，中心是参考点本身)</span>
</span></span><span class=line><span class=cl>  <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>n_points</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>grid_init</span><span class=p>[:,</span> <span class=p>:,</span> <span class=n>i</span><span class=p>,</span> <span class=p>:]</span> <span class=o>*=</span> <span class=n>i</span> <span class=o>+</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>  <span class=c1># 注意这里取消了梯度，只是借助nn.Parameter把数值设置进去</span>
</span></span><span class=line><span class=cl>  <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>sampling_offsets</span><span class=o>.</span><span class=n>bias</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Parameters</span><span class=p>(</span><span class=n>grid_init</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>))</span></span></span></code></pre></td></tr></table></div></div><p>具体实现以及道理看以上代码和CW的注释，最终效果就是，初始的采样点位置相当于会分布在参考点3x3、5x5、7x7、9x9方形邻域。在github上有朋友提过相关的issue，CW那时正好逛到，也给予了相应的互动:</p><p><a href=https://github.com/fundamentalvision/Deformable-DETR/issues/38 target=_blank rel="external nofollow noopener noreferrer">github相关issue<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></p><p>另外，对于注意力权重的初始化，CW发现作者的源码实现和paper中描述得有出入:</p><div class=highlight id=id-7><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>constant_</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>attention_weights</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># TODO: 这里与paper描述的有出入， paper中说bias初始化为1/LK, 其中L为特征层数=4， K为每层的采样点数量=4</span>
</span></span><span class=line><span class=cl><span class=c1># paper中说的那样才是在多有采样点之间归一化</span>
</span></span><span class=line><span class=cl><span class=c1># 否则， 这里所示的， weight和bias都是0， 直接导致最终的输出全为0</span>
</span></span><span class=line><span class=cl><span class=n>cosntant_</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>attention_weights</span><span class=o>.</span><span class=n>bias</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># constant_(self.attention_weights.bias.data, 1/(self.n_levels * self.n_points))</span></span></span></code></pre></td></tr></table></div></div><p>若按照以上的实现，感觉明显不合理，这样会导致注意力权重为全0，从而使得这个模块的输出结果也会变为全0。CW在github上提了issue，暂未有回复:</p><p><a href="https://link.zhihu.com/?target=https%3A//github.com/fundamentalvision/Deformable-DETR/issues/44" target=_blank rel="external nofollow noopener noreferrer">issue<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></p><p>接下来看看最重要的前向过程:</p><div class=highlight id=id-8><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>query</span><span class=p>,</span> <span class=n>reference_points</span><span class=p>,</span> <span class=n>input_flatten</span><span class=p>,</span> <span class=n>input_spatial_shapes</span><span class=p>,</span> <span class=n>input_level_start_index</span><span class=p>,</span> <span class=n>input_padding_mask</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>  :param query                    (N, Length_</span><span class=si>{query}</span><span class=s2>, c)
</span></span></span><span class=line><span class=cl><span class=s2>  :param reference_points         (N, Length_</span><span class=si>{query}</span><span class=s2>, n_levels, 2), range in
</span></span></span><span class=line><span class=cl><span class=s2>                                  [0, 1], top-left (0, 0), bottom-right (1, 1)
</span></span></span><span class=line><span class=cl><span class=s2>                                  including padding area or (N, Length_</span><span class=si>{query}</span><span class=s2>, n_levels, 4),
</span></span></span><span class=line><span class=cl><span class=s2>                                  add additional (w, h) to form reference boxes
</span></span></span><span class=line><span class=cl><span class=s2>  :param input_flatten            (N, \sum_{l=0}^{L-1} H_l \cdot W_l, C)
</span></span></span><span class=line><span class=cl><span class=s2>  :param input_spatial_shapes     (n_levels, 2), [(H_0, W_0), (H_1, W_1), ..., (H_{L-1}, W_{L-1})]
</span></span></span><span class=line><span class=cl><span class=s2>  :param input_level_start_index  (n_levels, ), [0, H_0*W_0, H_0*W_0+H_1*W_1, H_0*W_0+H_1*W_1+H_2*W_2, ..., H_0*W_0+H_1*W_1+...+H_{L-1}*W_{L-1}]
</span></span></span><span class=line><span class=cl><span class=s2>  :param input_padding_mask       (N, \sum_{l=0}^{L-1} H_l \cdot W_l), True for padding elements, False for non-padding elements
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>  :return output                  (N, Length_</span><span class=si>{query}</span><span class=s2>, C)
</span></span></span><span class=line><span class=cl><span class=s2>  &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>  <span class=n>N</span><span class=p>,</span> <span class=n>Len_q</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>query</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>  <span class=n>N</span><span class=p>,</span> <span class=n>Len_in</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>input_flatten</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>  <span class=k>assert</span> <span class=p>(</span><span class=n>input_spatial_shapes</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=n>input_spatial_shapes</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>])</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span> <span class=o>==</span> <span class=n>Len_in</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>value</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>value_proj</span><span class=p>(</span><span class=n>input_flatten</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=n>input_padding_mask</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=n>value</span> <span class=o>=</span> <span class=n>value</span><span class=o>.</span><span class=n>masked_fill</span><span class=p>(</span><span class=n>input_padding_mask</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=kc>None</span><span class=p>],</span> <span class=nb>float</span><span class=p>(</span><span class=mi>0</span><span class=p>))</span>
</span></span><span class=line><span class=cl>  <span class=n>value</span> <span class=o>=</span> <span class=n>value</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>N</span><span class=p>,</span> <span class=n>Len_in</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>d_model</span> <span class=o>//</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1># 以下主要是计算出采样点的位置。2-stage模式下，输入到Decoder的参考点是Encoder预测的top-k proposal boxes，也就是说是4d的(非2-stage情况下是2d)，于是需要分情况处理:</span>
</span></span><span class=line><span class=cl>  <span class=n>sampling_offsets</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>sampling_offsets</span><span class=p>(</span><span class=n>query</span><span class=p>)</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>N</span><span class=p>,</span> <span class=n>Len_q</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_levels</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_points</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>attention_weights</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>attention_weights</span><span class=p>(</span><span class=n>query</span><span class=p>)</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>N</span><span class=p>,</span> <span class=n>Len_q</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_levels</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_points</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>attention_weights</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>attention_weights</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>N</span><span class=p>,</span> <span class=n>Len_q</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_levels</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_points</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=c1># N, Len_q, n_heads, n_levels, n_points, 2</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=n>reference_points</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>==</span> <span class=mi>2</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=n>offset_normalizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>([</span><span class=n>input_spatial_shapes</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=n>input_spatial_shapes</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=mi>0</span><span class=p>]],</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=n>sampling_locations</span> <span class=o>=</span> <span class=n>reference_points</span><span class=p>[:,</span> <span class=p>:,</span> <span class=kc>None</span><span class=p>,</span> <span class=p>:,</span> <span class=kc>None</span><span class=p>,</span> <span class=p>:]</span> \
</span></span><span class=line><span class=cl>                            <span class=o>+</span> <span class=n>sampling_offsets</span> <span class=o>/</span> <span class=n>offset_normalizer</span><span class=p>[</span><span class=kc>None</span><span class=p>,</span> <span class=kc>None</span><span class=p>,</span> <span class=kc>None</span><span class=p>,</span> <span class=p>:,</span> <span class=kc>None</span><span class=p>,</span> <span class=p>:]</span>
</span></span><span class=line><span class=cl>  <span class=k>elif</span> <span class=n>reference_points</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>==</span> <span class=mi>4</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># reference_points 最后一维中的前两个事中心坐标xy， 后两个是宽高wh</span>
</span></span><span class=line><span class=cl>    <span class=c1># 由于初始化时，offset的在-k~k(k = n_points)范围，因此这里除以n_points相当于归一化到0~1</span>
</span></span><span class=line><span class=cl>    <span class=c1># 然后乘以宽和高的一半， 加上参考点的中心坐标，这样就是的偏移后采样点位于proposal bbox内</span>
</span></span><span class=line><span class=cl>    <span class=c1># 相当于对采样范围进行了约束，减小了搜索空间</span>
</span></span><span class=line><span class=cl>      <span class=n>sampling_locations</span> <span class=o>=</span> <span class=n>reference_points</span><span class=p>[:,</span> <span class=p>:,</span> <span class=kc>None</span><span class=p>,</span> <span class=p>:,</span> <span class=kc>None</span><span class=p>,</span> <span class=p>:</span><span class=mi>2</span><span class=p>]</span> \
</span></span><span class=line><span class=cl>                            <span class=o>+</span> <span class=n>sampling_offsets</span> <span class=o>/</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_points</span> <span class=o>*</span> <span class=n>reference_points</span><span class=p>[:,</span> <span class=p>:,</span> <span class=kc>None</span><span class=p>,</span> <span class=p>:,</span> <span class=kc>None</span><span class=p>,</span> <span class=mi>2</span><span class=p>:]</span> <span class=o>*</span> <span class=mf>0.5</span>
</span></span><span class=line><span class=cl>  <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span>
</span></span><span class=line><span class=cl>          <span class=s1>&#39;Last dim of reference_points must be 2 or 4, but get </span><span class=si>{}</span><span class=s1> instead.&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>reference_points</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>  <span class=c1># 根据采样点位置拿出对应的value，并且施加预测出来的注意力权重(和value进行weighted sum)</span>
</span></span><span class=line><span class=cl>  <span class=c1># (N, Len_in, 256)</span>
</span></span><span class=line><span class=cl>  <span class=c1># 注意: 实质调用的是基于CUDA实现的版本，需要编译</span>
</span></span><span class=line><span class=cl>  <span class=n>output</span> <span class=o>=</span> <span class=n>MSDeformAttnFunction</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span>
</span></span><span class=line><span class=cl>      <span class=n>value</span><span class=p>,</span> <span class=n>input_spatial_shapes</span><span class=p>,</span> <span class=n>input_level_start_index</span><span class=p>,</span> <span class=n>sampling_locations</span><span class=p>,</span> <span class=n>attention_weights</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>im2col_step</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=c1># (N， Len_in, 256)</span>
</span></span><span class=line><span class=cl>  <span class=n>output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>output_proj</span><span class=p>(</span><span class=n>output</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>output</span></span></span></code></pre></td></tr></table></div></div><p>在这里，将注意力权重与value进行weighted sum的实现是调用了用CUDA来实现的版本，因为Pytorch版性能有点尴尬，不过我们也可以看看Pytorch的实现，了解其中的逻辑。</p><div class=highlight id=id-9><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>ms_deform_attn_core_pytorch</span><span class=p>(</span><span class=n>value</span><span class=p>,</span> <span class=n>value_spatial_shapes</span><span class=p>,</span> <span class=n>sampling_locations</span><span class=p>,</span> <span class=n>attention_weights</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;&#34;&#34;多尺度可变性注意力， 根据采样点的位置在多尺度value中插值采样出对应的特征图，最后和注意力权重进行weighted sum得到输出&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>  <span class=c1># for debug and test only,</span>
</span></span><span class=line><span class=cl>  <span class=c1># need to use cuda version instead</span>
</span></span><span class=line><span class=cl>  <span class=n>N_</span><span class=p>,</span> <span class=n>S_</span><span class=p>,</span> <span class=n>M_</span><span class=p>,</span> <span class=n>D_</span> <span class=o>=</span> <span class=n>value</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>  <span class=n>_</span><span class=p>,</span> <span class=n>Lq_</span><span class=p>,</span> <span class=n>M_</span><span class=p>,</span> <span class=n>L_</span><span class=p>,</span> <span class=n>P_</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>sampling_locations</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>  <span class=c1># 由于以下使用了F.grid_sample()，要求采样位置的坐标是归一化到[-1, 1] ((-1, -1)代表左上角， (1，1)代表右下角)</span>
</span></span><span class=line><span class=cl>  <span class=c1># 因此， 这里是将[0, 1]映射到[-1, 1]</span>
</span></span><span class=line><span class=cl>  <span class=n>value_list</span> <span class=o>=</span> <span class=n>value</span><span class=o>.</span><span class=n>split</span><span class=p>([</span><span class=n>H_</span> <span class=o>*</span> <span class=n>W_</span> <span class=k>for</span> <span class=n>H_</span><span class=p>,</span> <span class=n>W_</span> <span class=ow>in</span> <span class=n>value_spatial_shapes</span><span class=p>],</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>sampling_grids</span> <span class=o>=</span> <span class=mi>2</span> <span class=o>*</span> <span class=n>sampling_locations</span> <span class=o>-</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>  <span class=n>sampling_value_list</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>  <span class=k>for</span> <span class=n>lid_</span><span class=p>,</span> <span class=p>(</span><span class=n>H_</span><span class=p>,</span> <span class=n>W_</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>value_spatial_shapes</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=c1># N_, H_*W_, M_, D_ -&gt; N_, H_*W_, M_*D_ -&gt; N_, M_*D_, H_*W_ -&gt; N_*M_, D_, H_, W_</span>
</span></span><span class=line><span class=cl>      <span class=n>value_l_</span> <span class=o>=</span> <span class=n>value_list</span><span class=p>[</span><span class=n>lid_</span><span class=p>]</span><span class=o>.</span><span class=n>flatten</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>N_</span><span class=o>*</span><span class=n>M_</span><span class=p>,</span> <span class=n>D_</span><span class=p>,</span> <span class=n>H_</span><span class=p>,</span> <span class=n>W_</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=c1># N_, Lq_, M_, P_, 2 -&gt; N_, M_, Lq_, P_, 2 -&gt; N_*M_, Lq_, P_, 2</span>
</span></span><span class=line><span class=cl>      <span class=n>sampling_grid_l_</span> <span class=o>=</span> <span class=n>sampling_grids</span><span class=p>[:,</span> <span class=p>:,</span> <span class=p>:,</span> <span class=n>lid_</span><span class=p>]</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>flatten</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=c1># 根据采样点坐标在value中插值出对应的特征</span>
</span></span><span class=line><span class=cl>      <span class=c1># ps: grid_sample()用法</span>
</span></span><span class=line><span class=cl>      <span class=c1># 这里value_l 充当被插值采样的特征图，是input， 维度需要时 4D/5D</span>
</span></span><span class=line><span class=cl>      <span class=c1># sampling_grid_l则代表采样的位置，是grid，最后一维2对应input中的坐标(可能是小数)</span>
</span></span><span class=line><span class=cl>      <span class=c1># 倒数第2，3维代表采样后输出特征图宽、高</span>
</span></span><span class=line><span class=cl>      <span class=c1># input和grid的第一个维度必须一致，最终输出的通道数与input一致，是不变的</span>
</span></span><span class=line><span class=cl>      <span class=c1># N_*M_, D_, Lq_, P_</span>
</span></span><span class=line><span class=cl>      <span class=n>sampling_value_l_</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>grid_sample</span><span class=p>(</span><span class=n>value_l_</span><span class=p>,</span> <span class=n>sampling_grid_l_</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                        <span class=n>mode</span><span class=o>=</span><span class=s1>&#39;bilinear&#39;</span><span class=p>,</span> <span class=n>padding_mode</span><span class=o>=</span><span class=s1>&#39;zeros&#39;</span><span class=p>,</span> <span class=n>align_corners</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=n>sampling_value_list</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>sampling_value_l_</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=c1># (N_, Lq_, M_, L_, P_) -&gt; (N_, M_, Lq_, L_, P_) -&gt; (N_, M_, 1, Lq_, L_*P_)</span>
</span></span><span class=line><span class=cl>  <span class=n>attention_weights</span> <span class=o>=</span> <span class=n>attention_weights</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>N_</span><span class=o>*</span><span class=n>M_</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>Lq_</span><span class=p>,</span> <span class=n>L_</span><span class=o>*</span><span class=n>P_</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=c1># 最后就是将注意力权重和采样特征进行weighted sum:</span>
</span></span><span class=line><span class=cl>  <span class=n>output</span> <span class=o>=</span> <span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>(</span><span class=n>sampling_value_list</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>flatten</span><span class=p>(</span><span class=o>-</span><span class=mi>2</span><span class=p>)</span> <span class=o>*</span> <span class=n>attention_weights</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>N_</span><span class=p>,</span> <span class=n>M_</span><span class=o>*</span><span class=n>D_</span><span class=p>,</span> <span class=n>Lq_</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>output</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>contiguous</span><span class=p>()</span></span></span></code></pre></td></tr></table></div></div><p>Deformable DETR有2-stage模式，后文会讲到。在2-stage模式下，输入到Decoder的参考点和object query&amp;query embedding会有所不同。</p><div class="details admonition quote"><div class="details-summary admonition-title"><i class="icon fa-solid fa-quote-right fa-fw" aria-hidden=true></i>引用<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class=details-content><div class=admonition-content><p>Multi-Scale Deformable Attention 主要做以下事情:</p><ol><li>将输入input_flatten (对于Encoder就是由backbone输出的特征图变换而来；对于Decoder就是Encoder输出的memory)，通过变换矩阵得到value，同时将padding的部分用0填充；</li><li>将query(对于Encoder就是特征图本身加上position&amp;scale-level embedding);
对于Decoder就是self-attention的输出加上position embedding结果；
2-stage时这个position embedding是由Encoder预测的top-k proposal boxes进行position embedding得来，
而1-stage时是预设的embedding分别通过两个全连接层得到采样点对应的坐标偏移和注意力权重(注意力权重会进行归一化)；</li><li>根据参考点(reference points: 对于Decoder来说， 2-stage时是Encoder预测的top-k proposal boxes；1-stage时是由预设的query embedding经过全连接层得到。两种情况下最终都经过了sigmoid函数归一化；而对于Encoder来说，就是个特征点在所有的特征层对应的归一化中心坐标和预测坐标偏移采样点的坐标)；</li><li>由采样点坐标在value中插值采样处对应的特征向量，然后施加注意力权重，最后将结果经过全连接层得到输出结果。</li></ol></div></div></div><p>完整的<code>Multi-Scale Deformable Attention</code>模块代码如下:</p><div class=highlight id=id-10><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span><span class=lnt>74
</span><span class=lnt>75
</span><span class=lnt>76
</span><span class=lnt>77
</span><span class=lnt>78
</span><span class=lnt>79
</span><span class=lnt>80
</span><span class=lnt>81
</span><span class=lnt>82
</span><span class=lnt>83
</span><span class=lnt>84
</span><span class=lnt>85
</span><span class=lnt>86
</span><span class=lnt>87
</span><span class=lnt>88
</span><span class=lnt>89
</span><span class=lnt>90
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>MSDeformAttn</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>d_model</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span> <span class=n>n_levels</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>n_heads</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span> <span class=n>n_points</span><span class=o>=</span><span class=mi>4</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>      Multi-Scale Deformable Attention Module
</span></span></span><span class=line><span class=cl><span class=s2>      :param d_model      hidden dimension
</span></span></span><span class=line><span class=cl><span class=s2>      :param n_levels     number of feature levels
</span></span></span><span class=line><span class=cl><span class=s2>      :param n_heads      number of attention heads
</span></span></span><span class=line><span class=cl><span class=s2>      :param n_points     number of sampling points per attention head per feature level
</span></span></span><span class=line><span class=cl><span class=s2>      &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>      <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>      <span class=k>if</span> <span class=n>d_model</span> <span class=o>%</span> <span class=n>n_heads</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>          <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s1>&#39;d_model must be divisible by n_heads, but got </span><span class=si>{}</span><span class=s1> and </span><span class=si>{}</span><span class=s1>&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>n_heads</span><span class=p>))</span>
</span></span><span class=line><span class=cl>      <span class=n>_d_per_head</span> <span class=o>=</span> <span class=n>d_model</span> <span class=o>//</span> <span class=n>n_heads</span>
</span></span><span class=line><span class=cl>      <span class=c1># you&#39;d better set _d_per_head to a power of 2 which is more efficient in our CUDA implementation</span>
</span></span><span class=line><span class=cl>      <span class=k>if</span> <span class=ow>not</span> <span class=n>_is_power_of_2</span><span class=p>(</span><span class=n>_d_per_head</span><span class=p>):</span>
</span></span><span class=line><span class=cl>          <span class=n>warnings</span><span class=o>.</span><span class=n>warn</span><span class=p>(</span><span class=s2>&#34;You&#39;d better set d_model in MSDeformAttn to make the dimension of each attention head a power of 2 &#34;</span>
</span></span><span class=line><span class=cl>                        <span class=s2>&#34;which is more efficient in our CUDA implementation.&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>      <span class=bp>self</span><span class=o>.</span><span class=n>im2col_step</span> <span class=o>=</span> <span class=mi>64</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>      <span class=bp>self</span><span class=o>.</span><span class=n>d_model</span> <span class=o>=</span> <span class=n>d_model</span>
</span></span><span class=line><span class=cl>      <span class=bp>self</span><span class=o>.</span><span class=n>n_levels</span> <span class=o>=</span> <span class=n>n_levels</span>
</span></span><span class=line><span class=cl>      <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span> <span class=o>=</span> <span class=n>n_heads</span>
</span></span><span class=line><span class=cl>      <span class=bp>self</span><span class=o>.</span><span class=n>n_points</span> <span class=o>=</span> <span class=n>n_points</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>      <span class=bp>self</span><span class=o>.</span><span class=n>sampling_offsets</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>n_heads</span> <span class=o>*</span> <span class=n>n_levels</span> <span class=o>*</span> <span class=n>n_points</span> <span class=o>*</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=bp>self</span><span class=o>.</span><span class=n>attention_weights</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>n_heads</span> <span class=o>*</span> <span class=n>n_levels</span> <span class=o>*</span> <span class=n>n_points</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=bp>self</span><span class=o>.</span><span class=n>value_proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>d_model</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=bp>self</span><span class=o>.</span><span class=n>output_proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>d_model</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>      <span class=bp>self</span><span class=o>.</span><span class=n>_reset_parameters</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>def</span> <span class=nf>_reset_parameters</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=n>constant_</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>sampling_offsets</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mf>0.</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=n>thetas</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=mf>2.0</span> <span class=o>*</span> <span class=n>math</span><span class=o>.</span><span class=n>pi</span> <span class=o>/</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=n>grid_init</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>([</span><span class=n>thetas</span><span class=o>.</span><span class=n>cos</span><span class=p>(),</span> <span class=n>thetas</span><span class=o>.</span><span class=n>sin</span><span class=p>()],</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=n>grid_init</span> <span class=o>=</span> <span class=p>(</span><span class=n>grid_init</span> <span class=o>/</span> <span class=n>grid_init</span><span class=o>.</span><span class=n>abs</span><span class=p>()</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>keepdim</span><span class=o>=</span><span class=kc>True</span><span class=p>)[</span><span class=mi>0</span><span class=p>])</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>repeat</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_levels</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_points</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>n_points</span><span class=p>):</span>
</span></span><span class=line><span class=cl>          <span class=n>grid_init</span><span class=p>[:,</span> <span class=p>:,</span> <span class=n>i</span><span class=p>,</span> <span class=p>:]</span> <span class=o>*=</span> <span class=n>i</span> <span class=o>+</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>      <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>          <span class=bp>self</span><span class=o>.</span><span class=n>sampling_offsets</span><span class=o>.</span><span class=n>bias</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Parameter</span><span class=p>(</span><span class=n>grid_init</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>      <span class=n>constant_</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>attention_weights</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mf>0.</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=n>constant_</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>attention_weights</span><span class=o>.</span><span class=n>bias</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mf>0.</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=n>xavier_uniform_</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>value_proj</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=n>constant_</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>value_proj</span><span class=o>.</span><span class=n>bias</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mf>0.</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=n>xavier_uniform_</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>output_proj</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=n>constant_</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>output_proj</span><span class=o>.</span><span class=n>bias</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mf>0.</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>query</span><span class=p>,</span> <span class=n>reference_points</span><span class=p>,</span> <span class=n>input_flatten</span><span class=p>,</span> <span class=n>input_spatial_shapes</span><span class=p>,</span> <span class=n>input_level_start_index</span><span class=p>,</span> <span class=n>input_padding_mask</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>      :param query                       (N, Length_</span><span class=si>{query}</span><span class=s2>, C)
</span></span></span><span class=line><span class=cl><span class=s2>      :param reference_points            (N, Length_</span><span class=si>{query}</span><span class=s2>, n_levels, 2), range in [0, 1], top-left (0,0), bottom-right (1, 1), including padding area
</span></span></span><span class=line><span class=cl><span class=s2>                                      or (N, Length_</span><span class=si>{query}</span><span class=s2>, n_levels, 4), add additional (w, h) to form reference boxes
</span></span></span><span class=line><span class=cl><span class=s2>      :param input_flatten               (N, \sum_{l=0}^{L-1} H_l \cdot W_l, C)
</span></span></span><span class=line><span class=cl><span class=s2>      :param input_spatial_shapes        (n_levels, 2), [(H_0, W_0), (H_1, W_1), ..., (H_{L-1}, W_{L-1})]
</span></span></span><span class=line><span class=cl><span class=s2>      :param input_level_start_index     (n_levels, ), [0, H_0*W_0, H_0*W_0+H_1*W_1, H_0*W_0+H_1*W_1+H_2*W_2, ..., H_0*W_0+H_1*W_1+...+H_{L-1}*W_{L-1}]
</span></span></span><span class=line><span class=cl><span class=s2>      :param input_padding_mask          (N, \sum_{l=0}^{L-1} H_l \cdot W_l), True for padding elements, False for non-padding elements
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>      :return output                     (N, Length_</span><span class=si>{query}</span><span class=s2>, C)
</span></span></span><span class=line><span class=cl><span class=s2>      &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>      <span class=c1># query是 src + positional encoding</span>
</span></span><span class=line><span class=cl>      <span class=c1># input_flatten是src，没有位置编码</span>
</span></span><span class=line><span class=cl>      <span class=n>N</span><span class=p>,</span> <span class=n>Len_q</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>query</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>      <span class=n>N</span><span class=p>,</span> <span class=n>Len_in</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>input_flatten</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>      <span class=k>assert</span> <span class=p>(</span><span class=n>input_spatial_shapes</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=n>input_spatial_shapes</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>])</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span> <span class=o>==</span> <span class=n>Len_in</span>
</span></span><span class=line><span class=cl>      <span class=c1># 根据input_flatten得到v</span>
</span></span><span class=line><span class=cl>      <span class=n>value</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>value_proj</span><span class=p>(</span><span class=n>input_flatten</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=k>if</span> <span class=n>input_padding_mask</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>          <span class=n>value</span> <span class=o>=</span> <span class=n>value</span><span class=o>.</span><span class=n>masked_fill</span><span class=p>(</span><span class=n>input_padding_mask</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=kc>None</span><span class=p>],</span> <span class=nb>float</span><span class=p>(</span><span class=mi>0</span><span class=p>))</span>
</span></span><span class=line><span class=cl>      <span class=c1># 多头注意力 根据头的个数将v等分</span>
</span></span><span class=line><span class=cl>      <span class=n>value</span> <span class=o>=</span> <span class=n>value</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>N</span><span class=p>,</span> <span class=n>Len_in</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>d_model</span> <span class=o>//</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=c1># 根据query得到offset偏移量和attention weights注意力权重</span>
</span></span><span class=line><span class=cl>      <span class=n>sampling_offsets</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>sampling_offsets</span><span class=p>(</span><span class=n>query</span><span class=p>)</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>N</span><span class=p>,</span> <span class=n>Len_q</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_levels</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_points</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=n>attention_weights</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>attention_weights</span><span class=p>(</span><span class=n>query</span><span class=p>)</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>N</span><span class=p>,</span> <span class=n>Len_q</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_levels</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_points</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=n>attention_weights</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>attention_weights</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>N</span><span class=p>,</span> <span class=n>Len_q</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_heads</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_levels</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_points</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=c1># N, Len_q, n_heads, n_levels, n_points, 2</span>
</span></span><span class=line><span class=cl>      <span class=k>if</span> <span class=n>reference_points</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>==</span> <span class=mi>2</span><span class=p>:</span>
</span></span><span class=line><span class=cl>          <span class=n>offset_normalizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>([</span><span class=n>input_spatial_shapes</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=mi>1</span><span class=p>],</span> <span class=n>input_spatial_shapes</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=mi>0</span><span class=p>]],</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>          <span class=n>sampling_locations</span> <span class=o>=</span> <span class=n>reference_points</span><span class=p>[:,</span> <span class=p>:,</span> <span class=kc>None</span><span class=p>,</span> <span class=p>:,</span> <span class=kc>None</span><span class=p>,</span> <span class=p>:]</span> \
</span></span><span class=line><span class=cl>                                <span class=o>+</span> <span class=n>sampling_offsets</span> <span class=o>/</span> <span class=n>offset_normalizer</span><span class=p>[</span><span class=kc>None</span><span class=p>,</span> <span class=kc>None</span><span class=p>,</span> <span class=kc>None</span><span class=p>,</span> <span class=p>:,</span> <span class=kc>None</span><span class=p>,</span> <span class=p>:]</span>
</span></span><span class=line><span class=cl>      <span class=k>elif</span> <span class=n>reference_points</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>==</span> <span class=mi>4</span><span class=p>:</span>
</span></span><span class=line><span class=cl>          <span class=n>sampling_locations</span> <span class=o>=</span> <span class=n>reference_points</span><span class=p>[:,</span> <span class=p>:,</span> <span class=kc>None</span><span class=p>,</span> <span class=p>:,</span> <span class=kc>None</span><span class=p>,</span> <span class=p>:</span><span class=mi>2</span><span class=p>]</span> \
</span></span><span class=line><span class=cl>                                <span class=o>+</span> <span class=n>sampling_offsets</span> <span class=o>/</span> <span class=bp>self</span><span class=o>.</span><span class=n>n_points</span> <span class=o>*</span> <span class=n>reference_points</span><span class=p>[:,</span> <span class=p>:,</span> <span class=kc>None</span><span class=p>,</span> <span class=p>:,</span> <span class=kc>None</span><span class=p>,</span> <span class=mi>2</span><span class=p>:]</span> <span class=o>*</span> <span class=mf>0.5</span>
</span></span><span class=line><span class=cl>      <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>          <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span>
</span></span><span class=line><span class=cl>              <span class=s1>&#39;Last dim of reference_points must be 2 or 4, but get </span><span class=si>{}</span><span class=s1> instead.&#39;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>reference_points</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>      <span class=n>output</span> <span class=o>=</span> <span class=n>MSDeformAttnFunction</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span>
</span></span><span class=line><span class=cl>          <span class=n>value</span><span class=p>,</span> <span class=n>input_spatial_shapes</span><span class=p>,</span> <span class=n>input_level_start_index</span><span class=p>,</span> <span class=n>sampling_locations</span><span class=p>,</span> <span class=n>attention_weights</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>im2col_step</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=n>output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>output_proj</span><span class=p>(</span><span class=n>output</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=k>return</span> <span class=n>output</span></span></span></code></pre></td></tr></table></div></div><h3 id=43-deformable-transformer>4.3 Deformable Transformer</h3><p>这里的Transformer和DETR中的大体过程一致，最主要的区别在于用<strong>可变形注意力</strong>替代了Encoder中的自注意力(self-attention)以及Decoder中的交叉注意力(cross-attention)。在分别解析Encoder和Decoder前，CW先向大家梳理下这里Transformer的整个pipeline(有源码解析哦！)。</p><p><strong>1). 为Encoder的输入做准备</strong></p><p>主要是将一些输入元素的维度展平(flatten)，这些输入元素包括: 多尺度特征图、各尺度特征图对应的mask(指示哪些部分属于padding)、各尺度特征图对应的位置信息(position embedding + scale-level embedding)，另外还有些辅助信息，比如: 各尺度特征图的宽高、不同尺度特征对应于被flatten的那个维度的起始索引、各尺度特征图中非padding部分的边长占其边长的比例。</p><div class=highlight id=id-11><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># deformable transformer forward函数</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>srcs</span><span class=p>,</span> <span class=n>masks</span><span class=p>,</span> <span class=n>pos_embeds</span><span class=p>,</span> <span class=n>query_embed</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=bp>self</span><span class=o>.</span><span class=n>two_stage</span> <span class=ow>or</span> <span class=n>query_embed</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;为Encoder的输入作准备:
</span></span></span><span class=line><span class=cl><span class=s2>    (i). 将各层特征图(已映射到c=256维度)flatten并concat到一起: (bs, h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 +..., 256);
</span></span></span><span class=line><span class=cl><span class=s2>    (ii). 将各层特征图对应的mask(指示了哪些位置是padding)flatten并concat: (bs, h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 + ...,)
</span></span></span><span class=line><span class=cl><span class=s2>    (iii). 将各层特征图对应的position embedding加上scale level embedding(用于表明query属于哪个特征层)， 然后flatten并concat: (bs, h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 + ..., 256);
</span></span></span><span class=line><span class=cl><span class=s2>    (iv). 将各层特征图的宽高由list变为tensor: (n_lvl, 2);
</span></span></span><span class=line><span class=cl><span class=s2>    (v). 由于将所有特征图的特征点concat在了一起 (h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 + ...), 因此为了区分各层，需要计算对应于被flatten那个维度的起始index(第一层当然是0，后面就是累加...)
</span></span></span><span class=line><span class=cl><span class=s2>    (vi). 计算各层特征层中非padding的部分边长(高&amp;宽)占特征图边长的比例(bs, n_lvl, 2)
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># prepare input for encoder</span>
</span></span><span class=line><span class=cl>    <span class=c1># 以下的flatten指的是将h，w两个维度展平为h * w</span>
</span></span><span class=line><span class=cl>    <span class=n>src_flatten</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>mask_flatten</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=c1># 各层特征图对应的position embedding + scale-level embedding</span>
</span></span><span class=line><span class=cl>    <span class=n>lvl_pos_embed_flatten</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=c1># 各层特征图的尺寸(h, w)</span>
</span></span><span class=line><span class=cl>    <span class=n>spatial_shapes</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>lvl</span><span class=p>,</span> <span class=p>(</span><span class=n>src</span><span class=p>,</span> <span class=n>mask</span><span class=p>,</span> <span class=n>pos_embed</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=nb>zip</span><span class=p>(</span><span class=n>srcs</span><span class=p>,</span> <span class=n>masks</span><span class=p>,</span> <span class=n>pos_embeds</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>        <span class=n>bs</span><span class=p>,</span> <span class=n>c</span><span class=p>,</span> <span class=n>h</span><span class=p>,</span> <span class=n>w</span> <span class=o>=</span> <span class=n>src</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>        <span class=n>spatial_shape</span> <span class=o>=</span> <span class=p>(</span><span class=n>h</span><span class=p>,</span> <span class=n>w</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>spatial_shapes</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>spatial_shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># (bs, c, h, w) =&gt; (bs, h*w, c)</span>
</span></span><span class=line><span class=cl>        <span class=n>src</span> <span class=o>=</span> <span class=n>src</span><span class=o>.</span><span class=n>flatten</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># (bs, h, w) =&gt; (bs, h*w)</span>
</span></span><span class=line><span class=cl>        <span class=n>mask</span> <span class=o>=</span> <span class=n>mask</span><span class=o>.</span><span class=n>flatten</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        由于position embedding仅区分h，w的位置
</span></span></span><span class=line><span class=cl><span class=s2>        因此对于不同特征层有相同坐标值的特征点来说，是无法区分的，于是这里附加上scale-level embedding作为特征层的区分信息
</span></span></span><span class=line><span class=cl><span class=s2>        这样，所有特征点的位置信息就各不相同了
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=c1># (bs, c, h, w) =&gt; (bs, h * w, c)</span>
</span></span><span class=line><span class=cl>        <span class=n>pos_embed</span> <span class=o>=</span> <span class=n>pos_embed</span><span class=o>.</span><span class=n>flatten</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># (bs, h*w, c) + (1, 1, 256)\</span>
</span></span><span class=line><span class=cl>        <span class=c1># note that c = 256 here</span>
</span></span><span class=line><span class=cl>        <span class=n>lvl_pos_embed</span> <span class=o>=</span> <span class=n>pos_embed</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>level_embed</span><span class=p>[</span><span class=n>lvl</span><span class=p>]</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>lvl_pos_embed_flatten</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>lvl_pos_embed</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>src_flatten</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>src</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>mask_flatten</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># (bs, h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 + ..., c)</span>
</span></span><span class=line><span class=cl>    <span class=n>src_flatten</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>(</span><span class=n>src_flatten</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># (bs, h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 + ...)</span>
</span></span><span class=line><span class=cl>    <span class=n>mask_flatten</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>(</span><span class=n>mask_flatten</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># (bs, h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 + ..., c)</span>
</span></span><span class=line><span class=cl>    <span class=n>lvl_pos_embed_flatten</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>(</span><span class=n>lvl_pos_embed_flatten</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># (n_lvl,2)</span>
</span></span><span class=line><span class=cl>    <span class=n>spatial_shapes</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>as_tensor</span><span class=p>(</span><span class=n>spatial_shapes</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>src_flatten</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># .prod(dim=1)是将dim1的各个元素相乘，在这里就会得到各特征层点数量: h * w</span>
</span></span><span class=line><span class=cl>    <span class=c1># .cumsum(0)代表在dim=0进行累加，在这里就会得到h_lvl1 * w_lvl1, h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2, ...</span>
</span></span><span class=line><span class=cl>    <span class=c1># 因此这里得到的level_start_index是各特征层起始的index(这个索引对应到被flatten的维度)</span>
</span></span><span class=line><span class=cl>    <span class=c1># (n_lvl,)</span>
</span></span><span class=line><span class=cl>    <span class=n>level_start_index</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>((</span><span class=n>spatial_shapes</span><span class=o>.</span><span class=n>new_zeros</span><span class=p>((</span><span class=mi>1</span><span class=p>,</span> <span class=p>)),</span> <span class=n>spatial_shapes</span><span class=o>.</span><span class=n>prod</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>cumsum</span><span class=p>(</span><span class=mi>0</span><span class=p>)[:</span><span class=o>-</span><span class=mi>1</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>    <span class=c1># (bs, n_lvl, 2) 各特征层中非padding部分的边长(高&amp;宽)占特征图边长的比例</span>
</span></span><span class=line><span class=cl>    <span class=n>valid_ratios</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>([</span><span class=bp>self</span><span class=o>.</span><span class=n>get_valid_ratio</span><span class=p>(</span><span class=n>m</span><span class=p>)</span> <span class=k>for</span> <span class=n>m</span> <span class=ow>in</span> <span class=n>masks</span><span class=p>],</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># encoder</span>
</span></span><span class=line><span class=cl>    <span class=n>memory</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>encoder</span><span class=p>(</span><span class=n>src_flatten</span><span class=p>,</span> <span class=n>spatial_shapes</span><span class=p>,</span> <span class=n>level_start_index</span><span class=p>,</span> <span class=n>valid_ratios</span><span class=p>,</span> <span class=n>lvl_pos_embed_flatten</span><span class=p>,</span> <span class=n>mask_flatten</span><span class=p>)</span></span></span></code></pre></td></tr></table></div></div><p>2). Encoder编码特征</p><p>源码对应上图最后一句。</p><p>encoder部分，输出memory(编码后的特征表示)，shape是 (bs, h_lvl1<em>w_lvl1+h_lvl2</em>w_lvl2+.., c=256)，其中h_lvli和w_lvli分别代表第i层特征图的高和宽，于是第二个维度就是所有特征点的数量。编码后，特征的最后一个维度(hidden_dim)为256。</p><p>3). 处理Encoder的输出，为Decoder的输入做准备</p><p>这一步<strong>主要是得到参考点(reference points)</strong>。需要说明下，在2-stage模式下，参考点和输入到Decoder的object query及query embedding的生成方式和形式会有所不同:</p><p>&ndash;如果是2-stage模式，那么参考点就是由Encoder预测的top-k得分最高的proposal boxes(注意，这时参考点是4d的，是bbox形式)。然后通过对参考点进行位置嵌入(position embedding)来生成Decoder的object query(target) 和对应的 query embedding；</p><p>&ndash;否则，Decoder的 object query(target )和 query embedding 就是预设的embedding，然后将query embedding经过全连接层输出2d参考点，这时的参考点是归一化的中心坐标形式。</p><p>另外，两种情况下生成的参考点数量可能不同: 2-stage时是有top-k(作者设置为300)个，而1-stage时是num_queries(作者也设置为300)个，也就是和object query的数量一致(可以理解为，此时参考点就是object query本身的位置)。</p><div class=highlight id=id-12><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>    <span class=c1># prepare input for decoder</span>
</span></span><span class=line><span class=cl>    <span class=c1># c = 256 中间那一维等于(所有层)特征点的数量</span>
</span></span><span class=line><span class=cl>    <span class=n>bs</span><span class=p>,</span> <span class=n>_</span><span class=p>,</span> <span class=n>c</span> <span class=o>=</span> <span class=n>memory</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>    <span class=c1># 根据是否2-stage分情况进行处理，因为生成的reference points不同</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>two_stage</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=c1># 生成proposals， 并且对Encoder的输出(memory)进行处理(全连接层 + 归一化)</span>
</span></span><span class=line><span class=cl>      <span class=c1>#(bs, h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 + ..., 256), (bs, h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 + ..., 4)</span>
</span></span><span class=line><span class=cl>      <span class=c1># 其中proposals每个都是xywh形式， 并且是经过inverse-sigmoid函数后的结果</span>
</span></span><span class=line><span class=cl>      <span class=c1># (其实这里的output_proposals对应的就是各层特征图各个特征点的位置(相当于anchor的形式，是固定的)，</span>
</span></span><span class=line><span class=cl>      <span class=c1># 因此还需要借助Decoder最后一层的bbox head来预测一个偏移(offset)来得到一个更加灵活的结果，</span>
</span></span><span class=line><span class=cl>      <span class=c1># 这才是第一阶段预测的proposal boxes)</span>
</span></span><span class=line><span class=cl>      <span class=n>output_memory</span><span class=p>,</span> <span class=n>output_proposals</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>gen_encoder_output_proposals</span><span class=p>(</span><span class=n>memory</span><span class=p>,</span> <span class=n>mask_flatten</span><span class=p>,</span> <span class=n>spatial_shapes</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>      <span class=c1># hack implementation for two-stage Deformable DETR</span>
</span></span><span class=line><span class=cl>      <span class=c1># 注意: 这里维度对应的是多分类，并非二分类</span>
</span></span><span class=line><span class=cl>      <span class=n>enc_outputs_class</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>decoder</span><span class=o>.</span><span class=n>class_embed</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>decoder</span><span class=o>.</span><span class=n>num_layers</span><span class=p>](</span><span class=n>output_memory</span><span class=p>)</span>
</span></span><span class=line><span class=cl>      <span class=c1># bbox head预测的是相对proposals的偏移，因此这里要相加， 后续还要经过sigmoid函数才得到真正的bbox预测结果(归一化形式)</span>
</span></span><span class=line><span class=cl>      <span class=c1>#(bs， h_lvl1 * w_lvl1 + h_lvl2 * w_lvl2 + .., 4)</span>
</span></span><span class=line><span class=cl>      <span class=n>enc_outputs_coord_unact</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>decoder</span><span class=o>.</span><span class=n>bbox_embed</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>decoder</span><span class=o>.</span><span class=n>num_layers</span><span class=p>](</span><span class=n>output_memory</span><span class=p>)</span> <span class=o>+</span> <span class=n>output_proposals</span></span></span></code></pre></td></tr></table></div></div><p>在阅读源码的过程中，发现这里有个小问题，貌似不妥。由于分类预测头部的输出维度是多分类的，而proposals仅需二分类就足够了，作者在取top-k得分时直接用第一个类别预测的结果来计算:</p><div class=highlight id=id-13><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>      <span class=c1># 300</span>
</span></span><span class=line><span class=cl>      <span class=n>topk</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>two_stage_num_proposals</span>
</span></span><span class=line><span class=cl>      <span class=c1># 选取得分最高的top分类预测，最后的[1]代表取得返回top对应的索引</span>
</span></span><span class=line><span class=cl>      <span class=c1># (bs， k = 300)</span>
</span></span><span class=line><span class=cl>      <span class=c1># TODO: 取第一个类别的预测结果算top-k，代表二分类</span>
</span></span><span class=line><span class=cl>      <span class=c1># 当不适用iterative bbox refine时， 所有class_embed参数共享，这样会使得在第二阶段对解码输出进行分类时都偏向于第一个类别</span>
</span></span><span class=line><span class=cl>      <span class=c1># 这样貌似不妥</span>
</span></span><span class=line><span class=cl>      <span class=n>topk_proposals</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>topk</span><span class=p>(</span><span class=n>enc_outputs_class</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=n>topk</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)[</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>      <span class=c1># 拿出top-k得分最高的对应的预测bbox:  (bs, k = 300, 4)</span>
</span></span><span class=line><span class=cl>      <span class=n>topk_coords_unact</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>gather</span><span class=p>(</span><span class=n>enc_outputs_coord_unact</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>topk_proposals</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>repeat</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>4</span><span class=p>))</span>
</span></span><span class=line><span class=cl>      <span class=c1># 注意: 这里取消了梯度</span>
</span></span><span class=line><span class=cl>      <span class=n>topk_coords_unact</span> <span class=o>=</span> <span class=n>topk_coords_unact</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span>
</span></span><span class=line><span class=cl>      <span class=c1># 经过sigmoid，变成了归一化形式，这个结果会送到decoder中作为初始的bboxes估计</span>
</span></span><span class=line><span class=cl>      <span class=n>reference_points</span> <span class=o>=</span> <span class=n>topk_coords_unact</span><span class=o>.</span><span class=n>sigmoid</span><span class=p>()</span>
</span></span><span class=line><span class=cl>      <span class=c1># init_reference_out = reference_points</span>
</span></span><span class=line><span class=cl>      <span class=n>init_reference_out</span> <span class=o>=</span> <span class=n>reference_points</span></span></span></code></pre></td></tr></table></div></div><p>同时，在不使用iterative bbox refine策略的情况下，会使得在第二阶段对解码输出进行分类时都倾向于预测第一个类别(使用iterative bbox refine时，对Decoder每层都有不同的分类预测头部实例，参数不共享，并且在这里会额外使用一个独立的分类预测头部，与应用到Decoder中的不相关)。关于检测头部的设置，代码如下:</p><div class=highlight id=id-14><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 如果使用2-stage， 那么在Decoder 中多加一层(变为7层)，用于第一阶段中proposal的预测输出</span>
</span></span><span class=line><span class=cl><span class=c1># (预测输出实际上由Encoder输出，只不过这里借用一层Decoder来解码形成预测结果，也就是借用了分类和回归预测的头部)</span>
</span></span><span class=line><span class=cl><span class=n>num_pred</span> <span class=o>=</span> <span class=p>(</span><span class=n>transformer</span><span class=o>.</span><span class=n>decoder</span><span class=o>.</span><span class=n>num_layers</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=k>if</span> <span class=n>two_stage</span> <span class=k>else</span> <span class=n>transformer</span><span class=o>.</span><span class=n>decoder</span><span class=o>.</span><span class=n>num_layers</span>
</span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;在iterative box refine策略下，_get_clones得到的每个模块都是不同的实例，参数不共享；
</span></span></span><span class=line><span class=cl><span class=s2>  而不使用该策略时， nn.ModuleList中每个都是相同的实例，即参数共享&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=c1># TODO: 以下bbox head的bias的后两个初始化为-2.0是为何？</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>with_box_refine</span><span class=p>:</span>
</span></span><span class=line><span class=cl>  <span class=c1># 如果使用迭代的bbox校正策略，则Decoder各层参数不共享，因此这里用_get_clones(deepcopy)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=bp>self</span><span class=o>.</span><span class=n>class_embed</span> <span class=o>=</span> <span class=n>_get_clones</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>class_embed</span><span class=p>,</span> <span class=n>num_pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=bp>self</span><span class=o>.</span><span class=n>bbox_embed</span> <span class=o>=</span> <span class=n>_get_clones</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>bbox_embed</span><span class=p>,</span> <span class=n>num_pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>constant_</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>bbox_embed</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>layers</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>bias</span><span class=o>.</span><span class=n>data</span><span class=p>[</span><span class=mi>2</span><span class=p>:],</span> <span class=o>-</span><span class=mf>2.0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=c1># hack implementation for iterative bounding box refinement</span>
</span></span><span class=line><span class=cl>  <span class=c1># 默认情况下， Decoder的bbox_embed设置为None，因此只有使用iterative bbox refinement策略时，</span>
</span></span><span class=line><span class=cl>  <span class=c1># 其bbox_embed才不是None； 在使用iterative bbox refine时，Decoder每层都会预测bbox偏移量，</span>
</span></span><span class=line><span class=cl>  <span class=c1># 使用这个偏移量对上一层的预测输出进行校正</span>
</span></span><span class=line><span class=cl>  <span class=bp>self</span><span class=o>.</span><span class=n>transformer</span><span class=o>.</span><span class=n>decoder</span><span class=o>.</span><span class=n>bbox_embed</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>bbox_embed</span>
</span></span><span class=line><span class=cl><span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>  <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>contant_</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>bbox_embed</span><span class=o>.</span><span class=n>layers</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>bias</span><span class=o>.</span><span class=n>data</span><span class=p>[</span><span class=mi>2</span><span class=p>:],</span> <span class=o>-</span><span class=mf>2.0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=c1># 不使用iterative bbox refine 策略，则各层参数共享</span>
</span></span><span class=line><span class=cl>  <span class=bp>self</span><span class=o>.</span><span class=n>class_embed</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ModuleList</span><span class=p>([</span><span class=bp>self</span><span class=o>.</span><span class=n>class_embed</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_pred</span><span class=p>)])</span>
</span></span><span class=line><span class=cl>  <span class=bp>self</span><span class=o>.</span><span class=n>bbox_embed</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ModuleList</span><span class=p>([</span><span class=bp>self</span><span class=o>.</span><span class=n>bbox_embed</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_pred</span><span class=p>)])</span>
</span></span><span class=line><span class=cl>  <span class=c1># 不用iterative bbox refine策略， 则Decoder的bbox_embed设置为None</span>
</span></span><span class=line><span class=cl>  <span class=bp>self</span><span class=o>.</span><span class=n>transofmer</span><span class=o>.</span><span class=n>decoder</span><span class=o>.</span><span class=n>bbox_embed</span> <span class=o>=</span> <span class=kc>None</span></span></span></code></pre></td></tr></table></div></div><p>紧接着pipeline:</p><div class=highlight id=id-15><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>  <span class=n>reference_points</span> <span class=o>=</span> <span class=n>topk_coords_unact</span><span class=o>.</span><span class=n>sigmoid</span><span class=p>()</span>
</span></span><span class=line><span class=cl>  <span class=c1># init_reference_out = reference_points</span>
</span></span><span class=line><span class=cl>  <span class=n>init_reference_out</span> <span class=o>=</span> <span class=n>reference_points</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>  生成的Decoder的query(target)和query embedding:
</span></span></span><span class=line><span class=cl><span class=s2>    - 对于top-k proposal boxes进行位置编码，编码方式是给xywh每个都赋予128维，
</span></span></span><span class=line><span class=cl><span class=s2>    其中每128维中，偶数维度用sin函数，奇数维度用cos函数编码；
</span></span></span><span class=line><span class=cl><span class=s2>    然后经过全连接层和归一化处理；
</span></span></span><span class=line><span class=cl><span class=s2>    最终， 前256维结果对应xy作为Decoder 的query embedding(因为xy代表的是位置信息)
</span></span></span><span class=line><span class=cl><span class=s2>  &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>  <span class=c1>#(bs, k = 300, 4 x 128 = 512)</span>
</span></span><span class=line><span class=cl>  <span class=n>pos_trans_out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>pos_trans_norm</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>pos_trans</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>get_proposal_pos_embed</span><span class=p>(</span><span class=n>topk_coords_unact</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>  <span class=c1># (bs, k = 300, 256), (bs, k = 300, 256)</span>
</span></span><span class=line><span class=cl>  <span class=n>query_embed</span><span class=p>,</span> <span class=n>tgt</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=n>pos_trans_out</span><span class=p>,</span> <span class=n>c</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>  <span class=c1># 仅为了与2-stage的情况兼容</span>
</span></span><span class=line><span class=cl>  <span class=n>enc_output_class</span> <span class=o>=</span> <span class=n>enc_outputs_coord_unact</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>  <span class=c1># (n_query = 300, 256) (n_query = 300, 256)</span>
</span></span><span class=line><span class=cl>  <span class=n>query_embed</span><span class=p>,</span> <span class=n>tgt</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=n>query_embed</span><span class=p>,</span> <span class=n>c</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=c1># (bs, n_query = 300, 256)</span>
</span></span><span class=line><span class=cl>  <span class=n>query_embed</span> <span class=o>=</span> <span class=n>query_embed</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span><span class=o>.</span><span class=n>expand</span><span class=p>(</span><span class=n>bs</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=c1># (bs, n_query = 300, 256)</span>
</span></span><span class=line><span class=cl>  <span class=n>tgt</span> <span class=o>=</span> <span class=n>tgt</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span><span class=o>.</span><span class=n>expand</span><span class=p>(</span><span class=n>bs</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=c1># 通过全连接层生成proposal参考点的归一化坐标(cx, cy) : (bs, n_query = 300, 2)</span>
</span></span><span class=line><span class=cl>  <span class=n>reference_points</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>reference_points</span><span class=p>(</span><span class=n>query_embed</span><span class=p>)</span><span class=o>.</span><span class=n>sigmoid</span><span class=p>()</span>
</span></span><span class=line><span class=cl>  <span class=n>init_reference_out</span> <span class=o>=</span> <span class=n>reference_points</span></span></span></code></pre></td></tr></table></div></div><p><strong>4). Decoder解码特征并输出参考点</strong></p><p>若使用了iterative bbox refine策略，则Decoder每层都会预测bbox，这些bbox就会作为新一轮的参考点供下一层使用，相当于coarse-to-fine的过程，不断地对参考点进行校正，最终会返回最后一层的校正结果。</p><p>由此可知，即便不是2-stage模式，只要使用了iterative bbox refine策略，这里返回的参考点也会变为4d的形式。因为检测头部的回归分支预测出来的结果是4d(xywh)形式的，而且是相对于参考点的偏移量(并非绝对坐标位置)。如果初始进来的参考点是2d的，那么wh就仅由检测头部的预测结果决定。</p><p>相对地，如果没有使用iterative bbox refine策略，那么这里返回的参考点和初始输进来的一样，保持不变。</p><div class=highlight id=id-16><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>  <span class=c1># decoder</span>
</span></span><span class=line><span class=cl>  <span class=c1># hs: (n_dec_layers, bs, n_query=300, d_model=256);</span>
</span></span><span class=line><span class=cl>  <span class=c1># itner_references: with iterative bbox refine - (n_dec_layers, bs, k = 300, 4)</span>
</span></span><span class=line><span class=cl>  <span class=c1># otherwise - (n_dec_layers, bs, k = 300, 2)</span>
</span></span><span class=line><span class=cl>  <span class=n>hs</span><span class=p>,</span> <span class=n>inter_references</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>decoder</span><span class=p>(</span><span class=n>tgt</span><span class=p>,</span> <span class=n>reference_points</span><span class=p>,</span> <span class=n>memory</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                      <span class=n>spatial_shapes</span><span class=p>,</span> <span class=n>level_start_index</span><span class=p>,</span> <span class=n>valid_ratios</span><span class=p>,</span> <span class=n>query_embed</span><span class=p>,</span> <span class=n>mask_flatten</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>inter_references_out</span> <span class=o>=</span> <span class=n>inter_references</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>two_stage</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=k>return</span> <span class=n>hs</span><span class=p>,</span> <span class=n>init_reference_out</span><span class=p>,</span> <span class=n>inter_references_out</span><span class=p>,</span> <span class=n>enc_outputs_class</span><span class=p>,</span> <span class=n>enc_outputs_coord_unact</span>
</span></span><span class=line><span class=cl>  <span class=c1># 1-stage情况下:  enc_outputs_class 和 enc_outputs_coord_unact 都是None</span>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>hs</span><span class=p>,</span> <span class=n>init_reference_out</span><span class=p>,</span> <span class=n>inter_references_out</span><span class=p>,</span> <span class=kc>None</span><span class=p>,</span> <span class=kc>None</span></span></span></code></pre></td></tr></table></div></div><p><strong>5). 输出解码特征和参考点</strong></p><p>这里输出的参考点有两个，包括初始进入Decoder前的和Decoder返回的。在上一步也说过，如果没有使用iterative bbox refine策略，则两者是一样的。</p><h3 id=44encoder>4.4、Encoder</h3><p>这里的Encoder与Transformer中最主要的区别在于使用<strong>可变形注意力</strong>替代了原生的自注意力。类似地，在每层编码时会将上一层输出的编码特征作为下一层的输入，这个输入与position emebdding结合作为query、而经过线性变换则作为value。</p><div class=highlight id=id-17><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>src</span><span class=p>,</span> <span class=n>spatial_shapes</span><span class=p>,</span> <span class=n>level_start_index</span><span class=p>,</span> <span class=n>valid_ratios</span><span class=p>,</span> <span class=n>pos</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>padding_mask</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=c1># 这里的pos是position embedding + scale-level embedding</span>
</span></span><span class=line><span class=cl>  <span class=n>output</span> <span class=o>=</span> <span class=n>src</span>
</span></span><span class=line><span class=cl>  <span class=c1># 将各特征点在其所在特征层的归一化坐标映射到所有特征层，使得每个特征点在所有特征层上都会得到一个归一化的坐标</span>
</span></span><span class=line><span class=cl>  <span class=c1># 这个reference_points 相当于key的角色， 从而每个query都会和其在所有特征层的位置(也就是以下计算出来的坐标)进行交互</span>
</span></span><span class=line><span class=cl>  <span class=c1># 实现了跨尺度融合的效果，因此不需要FPN</span>
</span></span><span class=line><span class=cl>  <span class=c1># (bs, H_lvl1 * W_lvl1 + H_lvl2 * W_lvl2 + ..., n_lvl, 2)</span>
</span></span><span class=line><span class=cl>  <span class=n>reference_points</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>get_reference_points</span><span class=p>(</span><span class=n>spatial_shapes</span><span class=p>,</span> <span class=n>valid_ratios</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>src</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=k>for</span> <span class=n>_</span><span class=p>,</span> <span class=n>layer</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>layers</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=n>output</span> <span class=o>=</span> <span class=n>layer</span><span class=p>(</span><span class=n>output</span><span class=p>,</span> <span class=n>pos</span><span class=p>,</span> <span class=n>reference_points</span><span class=p>,</span> <span class=n>spatial_shapes</span><span class=p>,</span> <span class=n>level_start_index</span><span class=p>,</span> <span class=n>padding_mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>output</span></span></span></code></pre></td></tr></table></div></div><p>现在具体来看看主要有哪些过程:</p><p><strong>i). 计算参考点的位置</strong></p><p>这里的参考点实质就是多尺度特征点的归一化坐标。注意，每个特征点在所有特征层都会计算出一个对应的归一化坐标(后文会谈到为何这样做)。</p><div class=highlight id=id-18><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_reference_points</span><span class=p>(</span><span class=n>spatial_shapes</span><span class=p>,</span> <span class=n>valid_ratios</span><span class=p>,</span> <span class=n>device</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=n>reference_points_list</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>  <span class=k>for</span> <span class=n>lvl</span><span class=p>,</span> <span class=p>(</span><span class=n>H_</span><span class=p>,</span> <span class=n>W_</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>spatial_shapes</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># (H_, W_), (H_, W_)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 0.5 是为对应到特征点中心</span>
</span></span><span class=line><span class=cl>    <span class=n>ref_y</span><span class=p>,</span> <span class=n>ref_x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>meshgrid</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>H_</span> <span class=o>-</span> <span class=mf>0.5</span><span class=p>,</span> <span class=n>H_</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                                  <span class=n>torch</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>W_</span> <span class=o>-</span> <span class=mf>0.5</span><span class=p>,</span> <span class=n>W_</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;将各层特征图每个特征点中心坐标根据特征图非padding的边长进行归一化(可能大于1)&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># (1, H_*W_) / (bs, 1) 后一项是特征图有效(非padding)部分的高</span>
</span></span><span class=line><span class=cl>    <span class=n>ref_y</span> <span class=o>=</span> <span class=n>ref_y</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)[</span><span class=kc>None</span><span class=p>]</span> <span class=o>/</span> <span class=p>(</span><span class=n>valid_ratios</span><span class=p>[:,</span> <span class=kc>None</span><span class=p>,</span> <span class=n>lvl</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span> <span class=o>*</span> <span class=n>H_</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># (1, H_*W_) / (bs, 1) 后一项是特征图有效(非padding)部分的宽</span>
</span></span><span class=line><span class=cl>    <span class=n>ref_x</span> <span class=o>=</span> <span class=n>ref_x</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)[</span><span class=kc>None</span><span class=p>]</span> <span class=o>/</span> <span class=p>(</span><span class=n>valid_ratios</span><span class=p>[:,</span> <span class=kc>None</span><span class=p>,</span> <span class=n>lvl</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=n>W_</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># (bs, H_*W_, 2) 每一项是xy</span>
</span></span><span class=line><span class=cl>    <span class=n>ref</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>((</span><span class=n>ref_x</span><span class=p>,</span> <span class=n>ref_y</span><span class=p>),</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>reference_points_list</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>ref</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=c1># (bs, H_lvl1 * W_lvl1 + H_lvl2 * W_lvl2 + ..., 2)</span>
</span></span><span class=line><span class=cl>  <span class=n>reference_points</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>(</span><span class=n>reference_points_list</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;&#34;&#34;将各特征点在其所在特征层的归一化坐标映射(扩散)到所有特征层， 这样每个特征点在所有特征层上都会得到一个归一化坐标&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>  <span class=c1># TODO: 以下这样貌似不妥， 如果各特征层对应的valid_ratio不一致，</span>
</span></span><span class=line><span class=cl>  <span class=c1># TODO: 则坐标值有可能大于1， 而后续没有再对这里的reference_points进行归一化到 0~1</span>
</span></span><span class=line><span class=cl>  <span class=c1># (bs, H_lvl1 * W_lvl1 + H_lvl2 * W_lvl2 + ..., 1, 2) * (bs, 1, n_lvl, 2)</span>
</span></span><span class=line><span class=cl>  <span class=n>reference_points</span> <span class=o>=</span> <span class=n>reference_points</span><span class=p>[:,</span> <span class=p>:,</span> <span class=kc>None</span><span class=p>]</span> <span class=o>*</span> <span class=n>valid_ratios</span><span class=p>[:,</span> <span class=kc>None</span><span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=c1># (bs, H_lvl1 * W_lvl1 + H_lvl2 * W_lvl2 + ..., n_lvl, 2)</span>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>reference_points</span></span></span></code></pre></td></tr></table></div></div><p>通过源码发现有个小问题: <strong>这里在对坐标归一化时使用的是非padding部分的特征图边长</strong>，而不同层非padding部分的边长比例有可能由于计算时的舍入误差而不一致，从而导致最终归一化后的坐标值大于1。</p><p>ii). self-attention</p><p>使用(多尺度)可变形注意力模块替代原生的Transformer自注意力，query和value均来自特征图，只不过query要结合position embedding，注意，<strong>这里的position embedding实质是position emebedding + scale-level emebedding</strong>。</p><p>iii). feed-forward network</p><p>前向反馈网络，和Transformer中的一致: 由全连接层、激活函数、Dropout、残差连接以及层归一化(LayerNorm)组成。</p><div class=highlight id=id-19><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>src</span><span class=p>,</span> <span class=n>pos</span><span class=p>,</span> <span class=n>reference_points</span><span class=p>,</span> <span class=n>spatial_shapes</span><span class=p>,</span> <span class=n>level_start_index</span><span class=p>,</span> <span class=n>padding_mask</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;&#34;&#34;Deformable DETR的Encoder也是由self-attention + FNN组成
</span></span></span><span class=line><span class=cl><span class=s2>    只不过这里self-attention使用Multi-Scale Deformable Attention， 并且位置编码加入了scale-level embedding
</span></span></span><span class=line><span class=cl><span class=s2>  &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>  <span class=c1># self attention</span>
</span></span><span class=line><span class=cl>  <span class=c1># 这里的pos是position embedding + scale-level embedding</span>
</span></span><span class=line><span class=cl>  <span class=c1># padding_mask 就是指示各特征图哪些位置是原图padding的</span>
</span></span><span class=line><span class=cl>  <span class=c1># reference_points 就是每个特征点本身中心的位置(归一化坐标): (bs, H_lvl1 * W_lvl1 + H_lvl2 * W_lvl2 + ..., n_lvl, 2)</span>
</span></span><span class=line><span class=cl>  <span class=c1># 注意一个特征点不仅在其所有特征层有个坐标， 而且还在其他特征层也都分别映射了一个坐标</span>
</span></span><span class=line><span class=cl>  <span class=c1># self attention</span>
</span></span><span class=line><span class=cl>  <span class=n>src2</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>self_attn</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>with_pos_embed</span><span class=p>(</span><span class=n>src</span><span class=p>,</span> <span class=n>pos</span><span class=p>),</span> <span class=n>reference_points</span><span class=p>,</span> <span class=n>src</span><span class=p>,</span> <span class=n>spatial_shapes</span><span class=p>,</span> <span class=n>level_start_index</span><span class=p>,</span> <span class=n>padding_mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>src</span> <span class=o>=</span> <span class=n>src</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout1</span><span class=p>(</span><span class=n>src2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>src</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm1</span><span class=p>(</span><span class=n>src</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1># ffn</span>
</span></span><span class=line><span class=cl>  <span class=n>src</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>forward_ffn</span><span class=p>(</span><span class=n>src</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>src</span></span></span></code></pre></td></tr></table></div></div><p><strong>DECODER</strong>详细代码注释如下，iterative bounding box refinement和two stage改进方法的Encoder不变。</p><div class=highlight id=id-20><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>DeformableTransformerEncoderLayer</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                 <span class=n>d_model</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span> <span class=n>d_ffn</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                 <span class=n>dropout</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s2>&#34;relu&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                 <span class=n>n_levels</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>n_heads</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span> <span class=n>n_points</span><span class=o>=</span><span class=mi>4</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># self attention</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>self_attn</span> <span class=o>=</span> <span class=n>MSDeformAttn</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>n_levels</span><span class=p>,</span> <span class=n>n_heads</span><span class=p>,</span> <span class=n>n_points</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>dropout1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>dropout</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>norm1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>d_model</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># ffn</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>linear1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>d_ffn</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>activation</span> <span class=o>=</span> <span class=n>_get_activation_fn</span><span class=p>(</span><span class=n>activation</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>dropout2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>dropout</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>linear2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_ffn</span><span class=p>,</span> <span class=n>d_model</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>dropout3</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>dropout</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>norm2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>d_model</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@staticmethod</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>with_pos_embed</span><span class=p>(</span><span class=n>tensor</span><span class=p>,</span> <span class=n>pos</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>tensor</span> <span class=k>if</span> <span class=n>pos</span> <span class=ow>is</span> <span class=kc>None</span> <span class=k>else</span> <span class=n>tensor</span> <span class=o>+</span> <span class=n>pos</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward_ffn</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>src</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>src2</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>linear2</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>dropout2</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>activation</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>linear1</span><span class=p>(</span><span class=n>src</span><span class=p>))))</span>
</span></span><span class=line><span class=cl>        <span class=n>src</span> <span class=o>=</span> <span class=n>src</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout3</span><span class=p>(</span><span class=n>src2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>src</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm2</span><span class=p>(</span><span class=n>src</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>src</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>src</span><span class=p>,</span> <span class=n>pos</span><span class=p>,</span> <span class=n>reference_points</span><span class=p>,</span> <span class=n>spatial_shapes</span><span class=p>,</span> <span class=n>level_start_index</span><span class=p>,</span> <span class=n>padding_mask</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># self attention</span>
</span></span><span class=line><span class=cl>        <span class=n>src2</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>self_attn</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>with_pos_embed</span><span class=p>(</span><span class=n>src</span><span class=p>,</span> <span class=n>pos</span><span class=p>),</span> <span class=n>reference_points</span><span class=p>,</span> <span class=n>src</span><span class=p>,</span> <span class=n>spatial_shapes</span><span class=p>,</span> <span class=n>level_start_index</span><span class=p>,</span> <span class=n>padding_mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>src</span> <span class=o>=</span> <span class=n>src</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout1</span><span class=p>(</span><span class=n>src2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>src</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm1</span><span class=p>(</span><span class=n>src</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># ffn</span>
</span></span><span class=line><span class=cl>        <span class=n>src</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>forward_ffn</span><span class=p>(</span><span class=n>src</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>src</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>DeformableTransformerEncoder</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>encoder_layer</span><span class=p>,</span> <span class=n>num_layers</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>layers</span> <span class=o>=</span> <span class=n>_get_clones</span><span class=p>(</span><span class=n>encoder_layer</span><span class=p>,</span> <span class=n>num_layers</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>num_layers</span> <span class=o>=</span> <span class=n>num_layers</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@staticmethod</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>get_reference_points</span><span class=p>(</span><span class=n>spatial_shapes</span><span class=p>,</span> <span class=n>valid_ratios</span><span class=p>,</span> <span class=n>device</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>reference_points_list</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>lvl</span><span class=p>,</span> <span class=p>(</span><span class=n>H_</span><span class=p>,</span> <span class=n>W_</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>spatial_shapes</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=c1># 从0.5到H-0.5采样H个点，W同理 这个操作的目的也就是为了特征图的对齐</span>
</span></span><span class=line><span class=cl>            <span class=n>ref_y</span><span class=p>,</span> <span class=n>ref_x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>meshgrid</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>H_</span> <span class=o>-</span> <span class=mf>0.5</span><span class=p>,</span> <span class=n>H_</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                                          <span class=n>torch</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>W_</span> <span class=o>-</span> <span class=mf>0.5</span><span class=p>,</span> <span class=n>W_</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=n>ref_y</span> <span class=o>=</span> <span class=n>ref_y</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)[</span><span class=kc>None</span><span class=p>]</span> <span class=o>/</span> <span class=p>(</span><span class=n>valid_ratios</span><span class=p>[:,</span> <span class=kc>None</span><span class=p>,</span> <span class=n>lvl</span><span class=p>,</span> <span class=mi>1</span><span class=p>]</span> <span class=o>*</span> <span class=n>H_</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>ref_x</span> <span class=o>=</span> <span class=n>ref_x</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)[</span><span class=kc>None</span><span class=p>]</span> <span class=o>/</span> <span class=p>(</span><span class=n>valid_ratios</span><span class=p>[:,</span> <span class=kc>None</span><span class=p>,</span> <span class=n>lvl</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>*</span> <span class=n>W_</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>ref</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>((</span><span class=n>ref_x</span><span class=p>,</span> <span class=n>ref_y</span><span class=p>),</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>reference_points_list</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>ref</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>reference_points</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>(</span><span class=n>reference_points_list</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>reference_points</span> <span class=o>=</span> <span class=n>reference_points</span><span class=p>[:,</span> <span class=p>:,</span> <span class=kc>None</span><span class=p>]</span> <span class=o>*</span> <span class=n>valid_ratios</span><span class=p>[:,</span> <span class=kc>None</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>reference_points</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>src</span><span class=p>,</span> <span class=n>spatial_shapes</span><span class=p>,</span> <span class=n>level_start_index</span><span class=p>,</span> <span class=n>valid_ratios</span><span class=p>,</span> <span class=n>pos</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>padding_mask</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>output</span> <span class=o>=</span> <span class=n>src</span>
</span></span><span class=line><span class=cl>        <span class=n>reference_points</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>get_reference_points</span><span class=p>(</span><span class=n>spatial_shapes</span><span class=p>,</span> <span class=n>valid_ratios</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>src</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>_</span><span class=p>,</span> <span class=n>layer</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>layers</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>output</span> <span class=o>=</span> <span class=n>layer</span><span class=p>(</span><span class=n>output</span><span class=p>,</span> <span class=n>pos</span><span class=p>,</span> <span class=n>reference_points</span><span class=p>,</span> <span class=n>spatial_shapes</span><span class=p>,</span> <span class=n>level_start_index</span><span class=p>,</span> <span class=n>padding_mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>output</span></span></span></code></pre></td></tr></table></div></div><h3 id=44decoder>4.4、Decoder</h3><p>这里与Transformer中主要的区别在于使用可变形注意力替代了原生的交叉注意力。类似地，每层的解码过程是self-attention+cross-attention+ffn，下一层输入的object query是上一层输出的解码特征。</p><div class=highlight id=id-21><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 每一层输入的output是上一层输出的结果，而reference_points_input在使用iterative bbox refine策略时，</span>
</span></span><span class=line><span class=cl><span class=c1># 每层都会对齐进行校正， 因此下一层用到的也是上一层的输出结果</span>
</span></span><span class=line><span class=cl><span class=c1># (bs， n_query=300，hidden_dim=256)</span>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=o>=</span> <span class=n>layer</span><span class=p>(</span><span class=n>output</span><span class=p>,</span> <span class=n>query_pos</span><span class=p>,</span> <span class=n>reference_points_input</span><span class=p>,</span> <span class=n>src</span><span class=p>,</span> <span class=n>src_spatial_shapes</span><span class=p>,</span> <span class=n>src_level_start_index</span><span class=p>,</span> <span class=n>src_padding_mask</span><span class=p>)</span></span></span></code></pre></td></tr></table></div></div><p>一起具体来看看每层的主要过程:</p><p>i). 将参考点坐标映射(re-scales)到各尺度特征层</p><p>将每个参考点的坐标分别都乘以各特征层非padding部分边长的比例，使得一个参考点在所有尺度特征层上都有相应的归一化坐标值(后文会谈到为何这样做)。</p><div class=highlight id=id-22><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>tgt</span><span class=p>,</span> <span class=n>reference_points</span><span class=p>,</span> <span class=n>src</span><span class=p>,</span> <span class=n>src_spatial_shapes</span><span class=p>,</span> <span class=n>src_level_start_index</span><span class=p>,</span> <span class=n>src_valid_ratios</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>query_pos</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>src_padding_mask</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=c1># 说明一下Decoder一开始得到的tgt, query_pos和reference_points, 分为两种情况:</span>
</span></span><span class=line><span class=cl>  <span class=c1># 1. 2-stage 模式下，reference_points 是Encoder输出的top-k proposal boxes(并归一化)，最后一维为4</span>
</span></span><span class=line><span class=cl>  <span class=c1># 而tgt和query_pos由其经过position embedding得到；</span>
</span></span><span class=line><span class=cl>  <span class=c1># 2. 1-stage 模式下， tgt和query_pos是预设的embedding， reference_points通过这个query_pos经全连接层得到，</span>
</span></span><span class=line><span class=cl>  <span class=c1># 最后一维为2</span>
</span></span><span class=line><span class=cl>  <span class=c1># 另外，src是Encoder最终编码输出的特征图，即 memory</span>
</span></span><span class=line><span class=cl>  <span class=n>output</span> <span class=o>=</span> <span class=n>tgt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1># 中间各层(包括头尾)的解码输出</span>
</span></span><span class=line><span class=cl>  <span class=n>intermediate</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>  <span class=c1># 中间各层(包括头尾)校正的参考点</span>
</span></span><span class=line><span class=cl>  <span class=n>intermediate_reference_points</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>  <span class=k>for</span> <span class=n>lid</span><span class=p>,</span> <span class=n>layer</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>layers</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># 2-stage 模式下， 参考点是proposal boxes， 因此最后一维是4</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>reference_points</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>==</span> <span class=mi>4</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=c1># (bs, k = 300, n_lvl, 4)</span>
</span></span><span class=line><span class=cl>      <span class=c1># (bs, k = 300, 1, 4) * (bs, 1, n_lvl, 4)</span>
</span></span><span class=line><span class=cl>      <span class=n>reference_points_input</span> <span class=o>=</span> <span class=n>reference_points</span><span class=p>[:,</span> <span class=p>:,</span> <span class=kc>None</span><span class=p>]</span> \
</span></span><span class=line><span class=cl>                                <span class=o>*</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>src_valid_ratios</span><span class=p>,</span> <span class=n>src_valid_ratios</span><span class=p>],</span> <span class=o>-</span><span class=mi>1</span><span class=p>)[:,</span> <span class=kc>None</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=c1># 1-stage 模式下 参考点就是通过query embedding 变换而来的中心坐标形式，因此最后一维是2</span>
</span></span><span class=line><span class=cl>      <span class=k>assert</span> <span class=n>reference_points</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>==</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>      <span class=c1># (bs, k=300, n_lvl, 2)</span>
</span></span><span class=line><span class=cl>      <span class=c1># (bs, k=300, 1, 2) * (bs, 1, n_lvl, 2)</span>
</span></span><span class=line><span class=cl>      <span class=n>reference_points_input</span> <span class=o>=</span> <span class=n>reference_points</span><span class=p>[:,</span> <span class=p>:,</span> <span class=kc>None</span><span class=p>]</span> <span class=o>*</span> <span class=n>src_valid_ratios</span><span class=p>[:,</span> <span class=kc>None</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>output</span> <span class=o>=</span> <span class=n>layer</span><span class=p>(</span><span class=n>output</span><span class=p>,</span> <span class=n>query_pos</span><span class=p>,</span> <span class=n>reference_points_input</span><span class=p>,</span> <span class=n>src</span><span class=p>,</span> <span class=n>src_spatial_shapes</span><span class=p>,</span> <span class=n>src_level_start_index</span><span class=p>,</span> <span class=n>src_padding_mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># hack implementation for iterative bounding box refinement</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>bbox_embed</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>tmp</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>bbox_embed</span><span class=p>[</span><span class=n>lid</span><span class=p>](</span><span class=n>output</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>reference_points</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>==</span> <span class=mi>4</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>new_reference_points</span> <span class=o>=</span> <span class=n>tmp</span> <span class=o>+</span> <span class=n>inverse_sigmoid</span><span class=p>(</span><span class=n>reference_points</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>new_reference_points</span> <span class=o>=</span> <span class=n>new_reference_points</span><span class=o>.</span><span class=n>sigmoid</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>assert</span> <span class=n>reference_points</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>==</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>            <span class=n>new_reference_points</span> <span class=o>=</span> <span class=n>tmp</span>
</span></span><span class=line><span class=cl>            <span class=n>new_reference_points</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=p>:</span><span class=mi>2</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=p>:</span><span class=mi>2</span><span class=p>]</span> <span class=o>+</span> <span class=n>inverse_sigmoid</span><span class=p>(</span><span class=n>reference_points</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>new_reference_points</span> <span class=o>=</span> <span class=n>new_reference_points</span><span class=o>.</span><span class=n>sigmoid</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>reference_points</span> <span class=o>=</span> <span class=n>new_reference_points</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>return_intermediate</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>intermediate</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>output</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>intermediate_reference_points</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>reference_points</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>return_intermediate</span><span class=p>:</span>
</span></span><span class=line><span class=cl>      <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>(</span><span class=n>intermediate</span><span class=p>),</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>(</span><span class=n>intermediate_reference_points</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>output</span><span class=p>,</span> <span class=n>reference_points</span></span></span></code></pre></td></tr></table></div></div><p>ii). self-attention</p><p>这一步是为了学习各个目标之间的关系，query和key都是object query+query embedding，value就是object query(注意不需要位置嵌入哦)。</p><div class=highlight id=id-23><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>tgt</span><span class=p>,</span> <span class=n>query_pos</span><span class=p>,</span> <span class=n>reference_points</span><span class=p>,</span> <span class=n>src</span><span class=p>,</span> <span class=n>src_spatial_shapes</span><span class=p>,</span> <span class=n>level_start_index</span><span class=p>,</span> <span class=n>src_padding_mask</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=c1># 若是2-stage， 则tgt 和 query_pos来自Encoder输出的top-k proposal boxes(经过位置嵌入)</span>
</span></span><span class=line><span class=cl>  <span class=c1># 而reference_points 就是这个top-k proposal boxes(归一化)</span>
</span></span><span class=line><span class=cl>  <span class=c1># 否则， tgt和query_pos由预设的embedding产生， 而reference_points由query_pos经过全连接层生成</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c1># self attention</span>
</span></span><span class=line><span class=cl>  <span class=c1># (bs, k = 300, d_model=256)</span>
</span></span><span class=line><span class=cl>  <span class=n>q</span> <span class=o>=</span> <span class=n>k</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>with_pos_embed</span><span class=p>(</span><span class=n>tgt</span><span class=p>,</span> <span class=n>query_pos</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=c1># (bs, k = 300, d_model=256) 注意: value就是target本身不需要， 不需要位置编码</span>
</span></span><span class=line><span class=cl>  <span class=n>tgt2</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>self_attn</span><span class=p>(</span><span class=n>q</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span> <span class=n>k</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span> <span class=n>tgt</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>))[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>tgt</span> <span class=o>=</span> <span class=n>tgt</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout2</span><span class=p>(</span><span class=n>tgt2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>tgt</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm2</span><span class=p>(</span><span class=n>tgt</span><span class=p>)</span></span></span></code></pre></td></tr></table></div></div><p>iii). cross-attention</p><p>使用(多尺度)可变形注意力模块替代原生的Transformer交叉注意力，object query来自self-attention层的输出，同时也要加上query embedding；value由Encoder编码的特征经过线性变换得到。</p><div class=highlight id=id-24><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 上续 decoder的 decoder layer forward</span>
</span></span><span class=line><span class=cl><span class=c1># cross attention</span>
</span></span><span class=line><span class=cl><span class=c1># src是Encoder输出的memory， 即编码后的特征(bs, n_feat_points, d_model=256), 其会经过线性变换得到value,</span>
</span></span><span class=line><span class=cl><span class=c1># 这里的tgt来自self-attention的输出，而query_pos依旧如刚传进来Decoder时一样，不变</span>
</span></span><span class=line><span class=cl><span class=c1># reference_points: (bs, k=300, n_feat_lvl, 4 or 2) 在cross-attention中代表key的位置信息</span>
</span></span><span class=line><span class=cl><span class=n>tgt2</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>cross_attn</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>with_pos_embed</span><span class=p>(</span><span class=n>tgt</span><span class=p>,</span> <span class=n>query_pos</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                        <span class=n>reference_points</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=n>src</span><span class=p>,</span> <span class=n>src_spatial_shapes</span><span class=p>,</span> <span class=n>level_start_index</span><span class=p>,</span> <span class=n>src_padding_mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>tgt</span> <span class=o>=</span> <span class=n>tgt</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout1</span><span class=p>(</span><span class=n>tgt2</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>tgt</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm1</span><span class=p>(</span><span class=n>tgt</span><span class=p>)</span></span></span></code></pre></td></tr></table></div></div><p>iv). feed-forward network
输入来自cross-attention的输出，详细过程就不再阐述了，都是老朋友了~</p><div class=highlight id=id-25><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># ffn</span>
</span></span><span class=line><span class=cl><span class=n>tgt</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>forward_ffn</span><span class=p>(</span><span class=n>tgt</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=n>tgt</span></span></span></code></pre></td></tr></table></div></div><p>v). iterative bounding box refinement</p><p>仅当使用了iterative bbox refine策略时有这一步: 使用bbox检测头部对解码特征进行预测，得到相对于参考点(boxes or points)的偏移量，然后加上参考点坐标(先经过反sigmoid处理，即先从归一化的空间从还原出来)，最后这个结果再经过sigmoid(归一化)得到校正的参考点，供下一层使用(在输入下一层之前会取消梯度，因为这个参考点在各层相当于作为先验的角色)。</p><div class=highlight id=id-26><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># hack implementation for iterative bounding box refinement</span>
</span></span><span class=line><span class=cl><span class=c1># 当使用了iterative bbox refine策略，则这里的bbox_embed就不是None</span>
</span></span><span class=line><span class=cl><span class=c1># 并且会对reference points进行refine， 之后每层的reference points都是前一层校正后的结果(取消了梯度)</span>
</span></span><span class=line><span class=cl><span class=c1># 否则，即没有使用iterative bbox refine的话， 那么reference points将永远是一样的</span>
</span></span><span class=line><span class=cl><span class=c1># (来自Encoder输出的proposal boxes或由预设的embedding通过位置编码，需要根据是2-stage还是1-stage的情况而定)</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>bbox_embed</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>  <span class=c1># (bs， n_query=300, 4)</span>
</span></span><span class=line><span class=cl>  <span class=n>tmp</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>bbox_embed</span><span class=p>[</span><span class=n>lid</span><span class=p>](</span><span class=n>output</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=c1># 2-stage 模式</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=n>reference_points</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>==</span> <span class=mi>4</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># tmp是bbox head输出的(相对参考点也就是proposal boxes)预测偏移量</span>
</span></span><span class=line><span class=cl>    <span class=n>new_reference_points</span> <span class=o>=</span> <span class=n>tmp</span> <span class=o>+</span> <span class=n>inverse_sigmoid</span><span class=p>(</span><span class=n>reference_points</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># (bs，k=300， 4)</span>
</span></span><span class=line><span class=cl>    <span class=n>new_reference_points</span> <span class=o>=</span> <span class=n>new_reference_points</span><span class=o>.</span><span class=n>sigmoid</span><span class=p>()</span>
</span></span><span class=line><span class=cl>  <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>assert</span> <span class=n>reference_points</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>==</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>    <span class=c1># 注意: 即使是1-stage， 在iterative bbox refine策略下，这里</span>
</span></span><span class=line><span class=cl>    <span class=c1># 也将reference points最后一维变成4</span>
</span></span><span class=line><span class=cl>    <span class=n>new_reference_points</span> <span class=o>=</span> <span class=n>tmp</span>
</span></span><span class=line><span class=cl>    <span class=c1># 1-stage模式下，参考点是特征点中心坐标(最后一维是2)， 因此这里预测的偏移量只需要去前面两维做加法</span>
</span></span><span class=line><span class=cl>    <span class=n>new_reference_points</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=p>:</span><span class=mi>2</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=p>:</span><span class=mi>2</span><span class=p>]</span> <span class=o>+</span> <span class=n>inverse_sigmoid</span><span class=p>(</span><span class=n>reference_points</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># (bs， k=300, 4)</span>
</span></span><span class=line><span class=cl>    <span class=n>new_reference_points</span> <span class=o>=</span> <span class=n>new_reference_points</span><span class=o>.</span><span class=n>sigmoid</span><span class=p>()</span>
</span></span><span class=line><span class=cl>  <span class=c1># (bs, k=300, 4)</span>
</span></span><span class=line><span class=cl>  <span class=c1># 注意:  这里取消了梯度！</span>
</span></span><span class=line><span class=cl>  <span class=n>reference_points</span> <span class=o>=</span> <span class=n>new_reference_points</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span></span></span></code></pre></td></tr></table></div></div><p>vi). 输出各层的解码特征和参考点</p><div class=highlight id=id-27><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># DECODER forward()</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>return_intermediate</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>intermediate</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>output</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>intermediate_reference_points</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>reference_points</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>return_intermediate</span><span class=p>:</span>
</span></span><span class=line><span class=cl>  <span class=c1># (n_layers, bs, n_query=300, d_model), (n_layers, bs, k=300, 4 or 2)</span>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>(</span><span class=n>intermediate</span><span class=p>),</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>(</span><span class=n>intermediate_reference_points</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 这里应该是[output] [reference_points] 这样才兼容return_intermediate的情况，第一个维度对应Decoder的层数</span>
</span></span><span class=line><span class=cl><span class=c1># return output, reference_points</span>
</span></span><span class=line><span class=cl><span class=k>return</span> <span class=n>output</span><span class=p>,</span> <span class=n>reference_points</span></span></span></code></pre></td></tr></table></div></div><p><strong>DECODER</strong>详细代码注释如下，这里要控制是否使用iterative bounding box refinement和two stage技巧。iterative bounding box refinement其实就是对参考点的位置进行微调。two stage方法其实就是通过参考点直接生成anchor但是只取最高置信度的前几个，然后再送入decoder进行调整。intermediate数组是一个trick，每层Decoder都是可以输出bbox和分类信息的，如果都利用起来算损失则成为auxiliary loss。</p><div class=highlight id=id-28><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>DeformableTransformerDecoderLayer</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>d_model</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span> <span class=n>d_ffn</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                 <span class=n>dropout</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span> <span class=n>activation</span><span class=o>=</span><span class=s2>&#34;relu&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                 <span class=n>n_levels</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>n_heads</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span> <span class=n>n_points</span><span class=o>=</span><span class=mi>4</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># cross attention</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>cross_attn</span> <span class=o>=</span> <span class=n>MSDeformAttn</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>n_levels</span><span class=p>,</span> <span class=n>n_heads</span><span class=p>,</span> <span class=n>n_points</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>dropout1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>dropout</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>norm1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>d_model</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># self attention</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>self_attn</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>MultiheadAttention</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>n_heads</span><span class=p>,</span> <span class=n>dropout</span><span class=o>=</span><span class=n>dropout</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>dropout2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>dropout</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>norm2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>d_model</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># ffn</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>linear1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>d_ffn</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>activation</span> <span class=o>=</span> <span class=n>_get_activation_fn</span><span class=p>(</span><span class=n>activation</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>dropout3</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>dropout</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>linear2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_ffn</span><span class=p>,</span> <span class=n>d_model</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>dropout4</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>dropout</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>norm3</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>d_model</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@staticmethod</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>with_pos_embed</span><span class=p>(</span><span class=n>tensor</span><span class=p>,</span> <span class=n>pos</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>tensor</span> <span class=k>if</span> <span class=n>pos</span> <span class=ow>is</span> <span class=kc>None</span> <span class=k>else</span> <span class=n>tensor</span> <span class=o>+</span> <span class=n>pos</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward_ffn</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>tgt</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>tgt2</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>linear2</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>dropout3</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>activation</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>linear1</span><span class=p>(</span><span class=n>tgt</span><span class=p>))))</span>
</span></span><span class=line><span class=cl>        <span class=n>tgt</span> <span class=o>=</span> <span class=n>tgt</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout4</span><span class=p>(</span><span class=n>tgt2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>tgt</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm3</span><span class=p>(</span><span class=n>tgt</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>tgt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>tgt</span><span class=p>,</span> <span class=n>query_pos</span><span class=p>,</span> <span class=n>reference_points</span><span class=p>,</span> <span class=n>src</span><span class=p>,</span> <span class=n>src_spatial_shapes</span><span class=p>,</span> <span class=n>level_start_index</span><span class=p>,</span> <span class=n>src_padding_mask</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># self attention</span>
</span></span><span class=line><span class=cl>        <span class=n>q</span> <span class=o>=</span> <span class=n>k</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>with_pos_embed</span><span class=p>(</span><span class=n>tgt</span><span class=p>,</span> <span class=n>query_pos</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>tgt2</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>self_attn</span><span class=p>(</span><span class=n>q</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span> <span class=n>k</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span> <span class=n>tgt</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>))[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>tgt</span> <span class=o>=</span> <span class=n>tgt</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout2</span><span class=p>(</span><span class=n>tgt2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>tgt</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm2</span><span class=p>(</span><span class=n>tgt</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># cross attention</span>
</span></span><span class=line><span class=cl>        <span class=n>tgt2</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>cross_attn</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>with_pos_embed</span><span class=p>(</span><span class=n>tgt</span><span class=p>,</span> <span class=n>query_pos</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                               <span class=n>reference_points</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                               <span class=n>src</span><span class=p>,</span> <span class=n>src_spatial_shapes</span><span class=p>,</span> <span class=n>level_start_index</span><span class=p>,</span> <span class=n>src_padding_mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>tgt</span> <span class=o>=</span> <span class=n>tgt</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout1</span><span class=p>(</span><span class=n>tgt2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>tgt</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm1</span><span class=p>(</span><span class=n>tgt</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># ffn</span>
</span></span><span class=line><span class=cl>        <span class=n>tgt</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>forward_ffn</span><span class=p>(</span><span class=n>tgt</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>tgt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>DeformableTransformerDecoder</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>decoder_layer</span><span class=p>,</span> <span class=n>num_layers</span><span class=p>,</span> <span class=n>return_intermediate</span><span class=o>=</span><span class=kc>False</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>layers</span> <span class=o>=</span> <span class=n>_get_clones</span><span class=p>(</span><span class=n>decoder_layer</span><span class=p>,</span> <span class=n>num_layers</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>num_layers</span> <span class=o>=</span> <span class=n>num_layers</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>return_intermediate</span> <span class=o>=</span> <span class=n>return_intermediate</span>
</span></span><span class=line><span class=cl>        <span class=c1># hack implementation for iterative bounding box refinement and two-stage Deformable DETR</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>bbox_embed</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>class_embed</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>tgt</span><span class=p>,</span> <span class=n>reference_points</span><span class=p>,</span> <span class=n>src</span><span class=p>,</span> <span class=n>src_spatial_shapes</span><span class=p>,</span> <span class=n>src_level_start_index</span><span class=p>,</span> <span class=n>src_valid_ratios</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>query_pos</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>src_padding_mask</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>output</span> <span class=o>=</span> <span class=n>tgt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 用来存储中间decoder输出的 可以考虑是否用auxiliary loss</span>
</span></span><span class=line><span class=cl>        <span class=n>intermediate</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=n>intermediate_reference_points</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>lid</span><span class=p>,</span> <span class=n>layer</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>layers</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>reference_points</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>==</span> <span class=mi>4</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>reference_points_input</span> <span class=o>=</span> <span class=n>reference_points</span><span class=p>[:,</span> <span class=p>:,</span> <span class=kc>None</span><span class=p>]</span> \
</span></span><span class=line><span class=cl>                                         <span class=o>*</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>src_valid_ratios</span><span class=p>,</span> <span class=n>src_valid_ratios</span><span class=p>],</span> <span class=o>-</span><span class=mi>1</span><span class=p>)[:,</span> <span class=kc>None</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>assert</span> <span class=n>reference_points</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>==</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>                <span class=n>reference_points_input</span> <span class=o>=</span> <span class=n>reference_points</span><span class=p>[:,</span> <span class=p>:,</span> <span class=kc>None</span><span class=p>]</span> <span class=o>*</span> <span class=n>src_valid_ratios</span><span class=p>[:,</span> <span class=kc>None</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>output</span> <span class=o>=</span> <span class=n>layer</span><span class=p>(</span><span class=n>output</span><span class=p>,</span> <span class=n>query_pos</span><span class=p>,</span> <span class=n>reference_points_input</span><span class=p>,</span> <span class=n>src</span><span class=p>,</span> <span class=n>src_spatial_shapes</span><span class=p>,</span> <span class=n>src_level_start_index</span><span class=p>,</span> <span class=n>src_padding_mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># hack implementation for iterative bounding box refinement</span>
</span></span><span class=line><span class=cl>            <span class=c1># iterative refinement是对decoder中的参考点进行微调，类似cascade rcnn思想</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>bbox_embed</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>tmp</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>bbox_embed</span><span class=p>[</span><span class=n>lid</span><span class=p>](</span><span class=n>output</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=n>reference_points</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>==</span> <span class=mi>4</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>new_reference_points</span> <span class=o>=</span> <span class=n>tmp</span> <span class=o>+</span> <span class=n>inverse_sigmoid</span><span class=p>(</span><span class=n>reference_points</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>new_reference_points</span> <span class=o>=</span> <span class=n>new_reference_points</span><span class=o>.</span><span class=n>sigmoid</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=k>assert</span> <span class=n>reference_points</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span> <span class=o>==</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>                    <span class=n>new_reference_points</span> <span class=o>=</span> <span class=n>tmp</span>
</span></span><span class=line><span class=cl>                    <span class=n>new_reference_points</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=p>:</span><span class=mi>2</span><span class=p>]</span> <span class=o>=</span> <span class=n>tmp</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=p>:</span><span class=mi>2</span><span class=p>]</span> <span class=o>+</span> <span class=n>inverse_sigmoid</span><span class=p>(</span><span class=n>reference_points</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=n>new_reference_points</span> <span class=o>=</span> <span class=n>new_reference_points</span><span class=o>.</span><span class=n>sigmoid</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=n>reference_points</span> <span class=o>=</span> <span class=n>new_reference_points</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>return_intermediate</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>intermediate</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>output</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>intermediate_reference_points</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>reference_points</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>return_intermediate</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>(</span><span class=n>intermediate</span><span class=p>),</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>(</span><span class=n>intermediate_reference_points</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>output</span><span class=p>,</span> <span class=n>reference_points</span></span></span></code></pre></td></tr></table></div></div><h3 id=45deformable-transformer>4.5、Deformable Transformer</h3><p>综合模块代码如下</p><div class=highlight id=id-29><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>  1
</span><span class=lnt>  2
</span><span class=lnt>  3
</span><span class=lnt>  4
</span><span class=lnt>  5
</span><span class=lnt>  6
</span><span class=lnt>  7
</span><span class=lnt>  8
</span><span class=lnt>  9
</span><span class=lnt> 10
</span><span class=lnt> 11
</span><span class=lnt> 12
</span><span class=lnt> 13
</span><span class=lnt> 14
</span><span class=lnt> 15
</span><span class=lnt> 16
</span><span class=lnt> 17
</span><span class=lnt> 18
</span><span class=lnt> 19
</span><span class=lnt> 20
</span><span class=lnt> 21
</span><span class=lnt> 22
</span><span class=lnt> 23
</span><span class=lnt> 24
</span><span class=lnt> 25
</span><span class=lnt> 26
</span><span class=lnt> 27
</span><span class=lnt> 28
</span><span class=lnt> 29
</span><span class=lnt> 30
</span><span class=lnt> 31
</span><span class=lnt> 32
</span><span class=lnt> 33
</span><span class=lnt> 34
</span><span class=lnt> 35
</span><span class=lnt> 36
</span><span class=lnt> 37
</span><span class=lnt> 38
</span><span class=lnt> 39
</span><span class=lnt> 40
</span><span class=lnt> 41
</span><span class=lnt> 42
</span><span class=lnt> 43
</span><span class=lnt> 44
</span><span class=lnt> 45
</span><span class=lnt> 46
</span><span class=lnt> 47
</span><span class=lnt> 48
</span><span class=lnt> 49
</span><span class=lnt> 50
</span><span class=lnt> 51
</span><span class=lnt> 52
</span><span class=lnt> 53
</span><span class=lnt> 54
</span><span class=lnt> 55
</span><span class=lnt> 56
</span><span class=lnt> 57
</span><span class=lnt> 58
</span><span class=lnt> 59
</span><span class=lnt> 60
</span><span class=lnt> 61
</span><span class=lnt> 62
</span><span class=lnt> 63
</span><span class=lnt> 64
</span><span class=lnt> 65
</span><span class=lnt> 66
</span><span class=lnt> 67
</span><span class=lnt> 68
</span><span class=lnt> 69
</span><span class=lnt> 70
</span><span class=lnt> 71
</span><span class=lnt> 72
</span><span class=lnt> 73
</span><span class=lnt> 74
</span><span class=lnt> 75
</span><span class=lnt> 76
</span><span class=lnt> 77
</span><span class=lnt> 78
</span><span class=lnt> 79
</span><span class=lnt> 80
</span><span class=lnt> 81
</span><span class=lnt> 82
</span><span class=lnt> 83
</span><span class=lnt> 84
</span><span class=lnt> 85
</span><span class=lnt> 86
</span><span class=lnt> 87
</span><span class=lnt> 88
</span><span class=lnt> 89
</span><span class=lnt> 90
</span><span class=lnt> 91
</span><span class=lnt> 92
</span><span class=lnt> 93
</span><span class=lnt> 94
</span><span class=lnt> 95
</span><span class=lnt> 96
</span><span class=lnt> 97
</span><span class=lnt> 98
</span><span class=lnt> 99
</span><span class=lnt>100
</span><span class=lnt>101
</span><span class=lnt>102
</span><span class=lnt>103
</span><span class=lnt>104
</span><span class=lnt>105
</span><span class=lnt>106
</span><span class=lnt>107
</span><span class=lnt>108
</span><span class=lnt>109
</span><span class=lnt>110
</span><span class=lnt>111
</span><span class=lnt>112
</span><span class=lnt>113
</span><span class=lnt>114
</span><span class=lnt>115
</span><span class=lnt>116
</span><span class=lnt>117
</span><span class=lnt>118
</span><span class=lnt>119
</span><span class=lnt>120
</span><span class=lnt>121
</span><span class=lnt>122
</span><span class=lnt>123
</span><span class=lnt>124
</span><span class=lnt>125
</span><span class=lnt>126
</span><span class=lnt>127
</span><span class=lnt>128
</span><span class=lnt>129
</span><span class=lnt>130
</span><span class=lnt>131
</span><span class=lnt>132
</span><span class=lnt>133
</span><span class=lnt>134
</span><span class=lnt>135
</span><span class=lnt>136
</span><span class=lnt>137
</span><span class=lnt>138
</span><span class=lnt>139
</span><span class=lnt>140
</span><span class=lnt>141
</span><span class=lnt>142
</span><span class=lnt>143
</span><span class=lnt>144
</span><span class=lnt>145
</span><span class=lnt>146
</span><span class=lnt>147
</span><span class=lnt>148
</span><span class=lnt>149
</span><span class=lnt>150
</span><span class=lnt>151
</span><span class=lnt>152
</span><span class=lnt>153
</span><span class=lnt>154
</span><span class=lnt>155
</span><span class=lnt>156
</span><span class=lnt>157
</span><span class=lnt>158
</span><span class=lnt>159
</span><span class=lnt>160
</span><span class=lnt>161
</span><span class=lnt>162
</span><span class=lnt>163
</span><span class=lnt>164
</span><span class=lnt>165
</span><span class=lnt>166
</span><span class=lnt>167
</span><span class=lnt>168
</span><span class=lnt>169
</span><span class=lnt>170
</span><span class=lnt>171
</span><span class=lnt>172
</span><span class=lnt>173
</span><span class=lnt>174
</span><span class=lnt>175
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>DeformableTransformer</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>d_model</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span> <span class=n>nhead</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                 <span class=n>num_encoder_layers</span><span class=o>=</span><span class=mi>6</span><span class=p>,</span> <span class=n>num_decoder_layers</span><span class=o>=</span><span class=mi>6</span><span class=p>,</span> <span class=n>dim_feedforward</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span> <span class=n>dropout</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                 <span class=n>activation</span><span class=o>=</span><span class=s2>&#34;relu&#34;</span><span class=p>,</span> <span class=n>return_intermediate_dec</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                 <span class=n>num_feature_levels</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span> <span class=n>dec_n_points</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span>  <span class=n>enc_n_points</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                 <span class=n>two_stage</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>two_stage_num_proposals</span><span class=o>=</span><span class=mi>300</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>d_model</span> <span class=o>=</span> <span class=n>d_model</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>nhead</span> <span class=o>=</span> <span class=n>nhead</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>two_stage</span> <span class=o>=</span> <span class=n>two_stage</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>two_stage_num_proposals</span> <span class=o>=</span> <span class=n>two_stage_num_proposals</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>encoder_layer</span> <span class=o>=</span> <span class=n>DeformableTransformerEncoderLayer</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>dim_feedforward</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                                          <span class=n>dropout</span><span class=p>,</span> <span class=n>activation</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                                          <span class=n>num_feature_levels</span><span class=p>,</span> <span class=n>nhead</span><span class=p>,</span> <span class=n>enc_n_points</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>encoder</span> <span class=o>=</span> <span class=n>DeformableTransformerEncoder</span><span class=p>(</span><span class=n>encoder_layer</span><span class=p>,</span> <span class=n>num_encoder_layers</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>decoder_layer</span> <span class=o>=</span> <span class=n>DeformableTransformerDecoderLayer</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>dim_feedforward</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                                          <span class=n>dropout</span><span class=p>,</span> <span class=n>activation</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                                          <span class=n>num_feature_levels</span><span class=p>,</span> <span class=n>nhead</span><span class=p>,</span> <span class=n>dec_n_points</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>decoder</span> <span class=o>=</span> <span class=n>DeformableTransformerDecoder</span><span class=p>(</span><span class=n>decoder_layer</span><span class=p>,</span> <span class=n>num_decoder_layers</span><span class=p>,</span> <span class=n>return_intermediate_dec</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>level_embed</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Parameter</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>Tensor</span><span class=p>(</span><span class=n>num_feature_levels</span><span class=p>,</span> <span class=n>d_model</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>two_stage</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>enc_output</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=n>d_model</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>enc_output_norm</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>d_model</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>pos_trans</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_model</span> <span class=o>*</span> <span class=mi>2</span><span class=p>,</span> <span class=n>d_model</span> <span class=o>*</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>pos_trans_norm</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>d_model</span> <span class=o>*</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>reference_points</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>d_model</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>_reset_parameters</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_reset_parameters</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>parameters</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>p</span><span class=o>.</span><span class=n>dim</span><span class=p>()</span> <span class=o>&gt;</span> <span class=mi>1</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>nn</span><span class=o>.</span><span class=n>init</span><span class=o>.</span><span class=n>xavier_uniform_</span><span class=p>(</span><span class=n>p</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>m</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>modules</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>m</span><span class=p>,</span> <span class=n>MSDeformAttn</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=n>m</span><span class=o>.</span><span class=n>_reset_parameters</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=ow>not</span> <span class=bp>self</span><span class=o>.</span><span class=n>two_stage</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>xavier_uniform_</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>reference_points</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=n>gain</span><span class=o>=</span><span class=mf>1.0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>constant_</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>reference_points</span><span class=o>.</span><span class=n>bias</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=mf>0.</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>normal_</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>level_embed</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>get_proposal_pos_embed</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>proposals</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>num_pos_feats</span> <span class=o>=</span> <span class=mi>128</span>
</span></span><span class=line><span class=cl>        <span class=n>temperature</span> <span class=o>=</span> <span class=mi>10000</span>
</span></span><span class=line><span class=cl>        <span class=n>scale</span> <span class=o>=</span> <span class=mi>2</span> <span class=o>*</span> <span class=n>math</span><span class=o>.</span><span class=n>pi</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>dim_t</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>num_pos_feats</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>proposals</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>dim_t</span> <span class=o>=</span> <span class=n>temperature</span> <span class=o>**</span> <span class=p>(</span><span class=mi>2</span> <span class=o>*</span> <span class=p>(</span><span class=n>dim_t</span> <span class=o>//</span> <span class=mi>2</span><span class=p>)</span> <span class=o>/</span> <span class=n>num_pos_feats</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># N, L, 4</span>
</span></span><span class=line><span class=cl>        <span class=n>proposals</span> <span class=o>=</span> <span class=n>proposals</span><span class=o>.</span><span class=n>sigmoid</span><span class=p>()</span> <span class=o>*</span> <span class=n>scale</span>
</span></span><span class=line><span class=cl>        <span class=c1># N, L, 4, 128</span>
</span></span><span class=line><span class=cl>        <span class=n>pos</span> <span class=o>=</span> <span class=n>proposals</span><span class=p>[:,</span> <span class=p>:,</span> <span class=p>:,</span> <span class=kc>None</span><span class=p>]</span> <span class=o>/</span> <span class=n>dim_t</span>
</span></span><span class=line><span class=cl>        <span class=c1># N, L, 4, 64, 2</span>
</span></span><span class=line><span class=cl>        <span class=n>pos</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>((</span><span class=n>pos</span><span class=p>[:,</span> <span class=p>:,</span> <span class=p>:,</span> <span class=mi>0</span><span class=p>::</span><span class=mi>2</span><span class=p>]</span><span class=o>.</span><span class=n>sin</span><span class=p>(),</span> <span class=n>pos</span><span class=p>[:,</span> <span class=p>:,</span> <span class=p>:,</span> <span class=mi>1</span><span class=p>::</span><span class=mi>2</span><span class=p>]</span><span class=o>.</span><span class=n>cos</span><span class=p>()),</span> <span class=n>dim</span><span class=o>=</span><span class=mi>4</span><span class=p>)</span><span class=o>.</span><span class=n>flatten</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>pos</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>gen_encoder_output_proposals</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>memory</span><span class=p>,</span> <span class=n>memory_padding_mask</span><span class=p>,</span> <span class=n>spatial_shapes</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>N_</span><span class=p>,</span> <span class=n>S_</span><span class=p>,</span> <span class=n>C_</span> <span class=o>=</span> <span class=n>memory</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>        <span class=n>base_scale</span> <span class=o>=</span> <span class=mf>4.0</span>
</span></span><span class=line><span class=cl>        <span class=n>proposals</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=n>_cur</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>lvl</span><span class=p>,</span> <span class=p>(</span><span class=n>H_</span><span class=p>,</span> <span class=n>W_</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>spatial_shapes</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>mask_flatten_</span> <span class=o>=</span> <span class=n>memory_padding_mask</span><span class=p>[:,</span> <span class=n>_cur</span><span class=p>:(</span><span class=n>_cur</span> <span class=o>+</span> <span class=n>H_</span> <span class=o>*</span> <span class=n>W_</span><span class=p>)]</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>N_</span><span class=p>,</span> <span class=n>H_</span><span class=p>,</span> <span class=n>W_</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>valid_H</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=o>~</span><span class=n>mask_flatten_</span><span class=p>[:,</span> <span class=p>:,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>valid_W</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=o>~</span><span class=n>mask_flatten_</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>,</span> <span class=p>:,</span> <span class=mi>0</span><span class=p>],</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>grid_y</span><span class=p>,</span> <span class=n>grid_x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>meshgrid</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>H_</span> <span class=o>-</span> <span class=mi>1</span><span class=p>,</span> <span class=n>H_</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>memory</span><span class=o>.</span><span class=n>device</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                                            <span class=n>torch</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>W_</span> <span class=o>-</span> <span class=mi>1</span><span class=p>,</span> <span class=n>W_</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float32</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>memory</span><span class=o>.</span><span class=n>device</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=n>grid</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>grid_x</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>),</span> <span class=n>grid_y</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)],</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>scale</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>valid_W</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>),</span> <span class=n>valid_H</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)],</span> <span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>N_</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>grid</span> <span class=o>=</span> <span class=p>(</span><span class=n>grid</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span><span class=o>.</span><span class=n>expand</span><span class=p>(</span><span class=n>N_</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span> <span class=o>+</span> <span class=mf>0.5</span><span class=p>)</span> <span class=o>/</span> <span class=n>scale</span>
</span></span><span class=line><span class=cl>            <span class=n>wh</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>ones_like</span><span class=p>(</span><span class=n>grid</span><span class=p>)</span> <span class=o>*</span> <span class=mf>0.05</span> <span class=o>*</span> <span class=p>(</span><span class=mf>2.0</span> <span class=o>**</span> <span class=n>lvl</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>proposal</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>((</span><span class=n>grid</span><span class=p>,</span> <span class=n>wh</span><span class=p>),</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>N_</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>4</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>proposals</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>proposal</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>_cur</span> <span class=o>+=</span> <span class=p>(</span><span class=n>H_</span> <span class=o>*</span> <span class=n>W_</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>output_proposals</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>(</span><span class=n>proposals</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>output_proposals_valid</span> <span class=o>=</span> <span class=p>((</span><span class=n>output_proposals</span> <span class=o>&gt;</span> <span class=mf>0.01</span><span class=p>)</span> <span class=o>&amp;</span> <span class=p>(</span><span class=n>output_proposals</span> <span class=o>&lt;</span> <span class=mf>0.99</span><span class=p>))</span><span class=o>.</span><span class=n>all</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>keepdim</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>output_proposals</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>output_proposals</span> <span class=o>/</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>output_proposals</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>output_proposals</span> <span class=o>=</span> <span class=n>output_proposals</span><span class=o>.</span><span class=n>masked_fill</span><span class=p>(</span><span class=n>memory_padding_mask</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>),</span> <span class=nb>float</span><span class=p>(</span><span class=s1>&#39;inf&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>output_proposals</span> <span class=o>=</span> <span class=n>output_proposals</span><span class=o>.</span><span class=n>masked_fill</span><span class=p>(</span><span class=o>~</span><span class=n>output_proposals_valid</span><span class=p>,</span> <span class=nb>float</span><span class=p>(</span><span class=s1>&#39;inf&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>output_memory</span> <span class=o>=</span> <span class=n>memory</span>
</span></span><span class=line><span class=cl>        <span class=n>output_memory</span> <span class=o>=</span> <span class=n>output_memory</span><span class=o>.</span><span class=n>masked_fill</span><span class=p>(</span><span class=n>memory_padding_mask</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>),</span> <span class=nb>float</span><span class=p>(</span><span class=mi>0</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>output_memory</span> <span class=o>=</span> <span class=n>output_memory</span><span class=o>.</span><span class=n>masked_fill</span><span class=p>(</span><span class=o>~</span><span class=n>output_proposals_valid</span><span class=p>,</span> <span class=nb>float</span><span class=p>(</span><span class=mi>0</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>output_memory</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>enc_output_norm</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>enc_output</span><span class=p>(</span><span class=n>output_memory</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>output_memory</span><span class=p>,</span> <span class=n>output_proposals</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>get_valid_ratio</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>mask</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>_</span><span class=p>,</span> <span class=n>H</span><span class=p>,</span> <span class=n>W</span> <span class=o>=</span> <span class=n>mask</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>        <span class=n>valid_H</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=o>~</span><span class=n>mask</span><span class=p>[:,</span> <span class=p>:,</span> <span class=mi>0</span><span class=p>],</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>valid_W</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=o>~</span><span class=n>mask</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>,</span> <span class=p>:],</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>valid_ratio_h</span> <span class=o>=</span> <span class=n>valid_H</span><span class=o>.</span><span class=n>float</span><span class=p>()</span> <span class=o>/</span> <span class=n>H</span>
</span></span><span class=line><span class=cl>        <span class=n>valid_ratio_w</span> <span class=o>=</span> <span class=n>valid_W</span><span class=o>.</span><span class=n>float</span><span class=p>()</span> <span class=o>/</span> <span class=n>W</span>
</span></span><span class=line><span class=cl>        <span class=n>valid_ratio</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>([</span><span class=n>valid_ratio_w</span><span class=p>,</span> <span class=n>valid_ratio_h</span><span class=p>],</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>valid_ratio</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>srcs</span><span class=p>,</span> <span class=n>masks</span><span class=p>,</span> <span class=n>pos_embeds</span><span class=p>,</span> <span class=n>query_embed</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>assert</span> <span class=bp>self</span><span class=o>.</span><span class=n>two_stage</span> <span class=ow>or</span> <span class=n>query_embed</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># prepare input for encoder</span>
</span></span><span class=line><span class=cl>        <span class=n>src_flatten</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=n>mask_flatten</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=n>lvl_pos_embed_flatten</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=n>spatial_shapes</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>lvl</span><span class=p>,</span> <span class=p>(</span><span class=n>src</span><span class=p>,</span> <span class=n>mask</span><span class=p>,</span> <span class=n>pos_embed</span><span class=p>)</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=nb>zip</span><span class=p>(</span><span class=n>srcs</span><span class=p>,</span> <span class=n>masks</span><span class=p>,</span> <span class=n>pos_embeds</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>            <span class=c1># 得到每一层feature map的batch size 通道数量 高宽</span>
</span></span><span class=line><span class=cl>            <span class=n>bs</span><span class=p>,</span> <span class=n>c</span><span class=p>,</span> <span class=n>h</span><span class=p>,</span> <span class=n>w</span> <span class=o>=</span> <span class=n>src</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>            <span class=n>spatial_shape</span> <span class=o>=</span> <span class=p>(</span><span class=n>h</span><span class=p>,</span> <span class=n>w</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>spatial_shapes</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>spatial_shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=c1># 将每层的feature map、mask、位置编码拉平，并且加入到相关数组中</span>
</span></span><span class=line><span class=cl>            <span class=n>src</span> <span class=o>=</span> <span class=n>src</span><span class=o>.</span><span class=n>flatten</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>mask</span> <span class=o>=</span> <span class=n>mask</span><span class=o>.</span><span class=n>flatten</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>pos_embed</span> <span class=o>=</span> <span class=n>pos_embed</span><span class=o>.</span><span class=n>flatten</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=c1># 位置编码和可学习的每层编码相加，表征类似 3D position</span>
</span></span><span class=line><span class=cl>            <span class=n>lvl_pos_embed</span> <span class=o>=</span> <span class=n>pos_embed</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>level_embed</span><span class=p>[</span><span class=n>lvl</span><span class=p>]</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>lvl_pos_embed_flatten</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>lvl_pos_embed</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>src_flatten</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>src</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>mask_flatten</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># 在hidden_dim维度上进行拼接，也就是number token数量一样的那个维度</span>
</span></span><span class=line><span class=cl>        <span class=n>src_flatten</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>(</span><span class=n>src_flatten</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>mask_flatten</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>(</span><span class=n>mask_flatten</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>lvl_pos_embed_flatten</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>(</span><span class=n>lvl_pos_embed_flatten</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>spatial_shapes</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>as_tensor</span><span class=p>(</span><span class=n>spatial_shapes</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>long</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=n>src_flatten</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># 记录每个level开始的索引以及有效的长宽(因为有mask存在，raw image的分辨率可能不统一) 具体查看get_valid_ratio函数</span>
</span></span><span class=line><span class=cl>        <span class=c1># prod(1)计算h*w，cumsum(0)计算前缀和</span>
</span></span><span class=line><span class=cl>        <span class=n>level_start_index</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>((</span><span class=n>spatial_shapes</span><span class=o>.</span><span class=n>new_zeros</span><span class=p>((</span><span class=mi>1</span><span class=p>,</span> <span class=p>)),</span> <span class=n>spatial_shapes</span><span class=o>.</span><span class=n>prod</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>cumsum</span><span class=p>(</span><span class=mi>0</span><span class=p>)[:</span><span class=o>-</span><span class=mi>1</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>        <span class=n>valid_ratios</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>([</span><span class=bp>self</span><span class=o>.</span><span class=n>get_valid_ratio</span><span class=p>(</span><span class=n>m</span><span class=p>)</span> <span class=k>for</span> <span class=n>m</span> <span class=ow>in</span> <span class=n>masks</span><span class=p>],</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># encoder</span>
</span></span><span class=line><span class=cl>        <span class=n>memory</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>encoder</span><span class=p>(</span><span class=n>src_flatten</span><span class=p>,</span> <span class=n>spatial_shapes</span><span class=p>,</span> <span class=n>level_start_index</span><span class=p>,</span> <span class=n>valid_ratios</span><span class=p>,</span> <span class=n>lvl_pos_embed_flatten</span><span class=p>,</span> <span class=n>mask_flatten</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># prepare input for decoder</span>
</span></span><span class=line><span class=cl>        <span class=n>bs</span><span class=p>,</span> <span class=n>_</span><span class=p>,</span> <span class=n>c</span> <span class=o>=</span> <span class=n>memory</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>        <span class=c1># 是否使用两阶段模式</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>two_stage</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>output_memory</span><span class=p>,</span> <span class=n>output_proposals</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>gen_encoder_output_proposals</span><span class=p>(</span><span class=n>memory</span><span class=p>,</span> <span class=n>mask_flatten</span><span class=p>,</span> <span class=n>spatial_shapes</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># hack implementation for two-stage Deformable DETR</span>
</span></span><span class=line><span class=cl>            <span class=n>enc_outputs_class</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>decoder</span><span class=o>.</span><span class=n>class_embed</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>decoder</span><span class=o>.</span><span class=n>num_layers</span><span class=p>](</span><span class=n>output_memory</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>enc_outputs_coord_unact</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>decoder</span><span class=o>.</span><span class=n>bbox_embed</span><span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>decoder</span><span class=o>.</span><span class=n>num_layers</span><span class=p>](</span><span class=n>output_memory</span><span class=p>)</span> <span class=o>+</span> <span class=n>output_proposals</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>topk</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>two_stage_num_proposals</span>
</span></span><span class=line><span class=cl>            <span class=n>topk_proposals</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>topk</span><span class=p>(</span><span class=n>enc_outputs_class</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=mi>0</span><span class=p>],</span> <span class=n>topk</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)[</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>topk_coords_unact</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>gather</span><span class=p>(</span><span class=n>enc_outputs_coord_unact</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>topk_proposals</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>repeat</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>4</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=n>topk_coords_unact</span> <span class=o>=</span> <span class=n>topk_coords_unact</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>reference_points</span> <span class=o>=</span> <span class=n>topk_coords_unact</span><span class=o>.</span><span class=n>sigmoid</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>init_reference_out</span> <span class=o>=</span> <span class=n>reference_points</span>
</span></span><span class=line><span class=cl>            <span class=n>pos_trans_out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>pos_trans_norm</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>pos_trans</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>get_proposal_pos_embed</span><span class=p>(</span><span class=n>topk_coords_unact</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>            <span class=n>query_embed</span><span class=p>,</span> <span class=n>tgt</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=n>pos_trans_out</span><span class=p>,</span> <span class=n>c</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># 这是非双阶段版本的Deformable DETR</span>
</span></span><span class=line><span class=cl>            <span class=c1># 将query_embed划分为query_embed和tgt两部分</span>
</span></span><span class=line><span class=cl>            <span class=n>query_embed</span><span class=p>,</span> <span class=n>tgt</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=n>query_embed</span><span class=p>,</span> <span class=n>c</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=c1># 复制bs份</span>
</span></span><span class=line><span class=cl>            <span class=n>query_embed</span> <span class=o>=</span> <span class=n>query_embed</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span><span class=o>.</span><span class=n>expand</span><span class=p>(</span><span class=n>bs</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>tgt</span> <span class=o>=</span> <span class=n>tgt</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span><span class=o>.</span><span class=n>expand</span><span class=p>(</span><span class=n>bs</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=c1># nn.Linear得到每个object queries对应的reference point, 这是decoder参考点的方法!!!</span>
</span></span><span class=line><span class=cl>            <span class=n>reference_points</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>reference_points</span><span class=p>(</span><span class=n>query_embed</span><span class=p>)</span><span class=o>.</span><span class=n>sigmoid</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>init_reference_out</span> <span class=o>=</span> <span class=n>reference_points</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># decoder</span>
</span></span><span class=line><span class=cl>        <span class=n>hs</span><span class=p>,</span> <span class=n>inter_references</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>decoder</span><span class=p>(</span><span class=n>tgt</span><span class=p>,</span> <span class=n>reference_points</span><span class=p>,</span> <span class=n>memory</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                            <span class=n>spatial_shapes</span><span class=p>,</span> <span class=n>level_start_index</span><span class=p>,</span> <span class=n>valid_ratios</span><span class=p>,</span> <span class=n>query_embed</span><span class=p>,</span> <span class=n>mask_flatten</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>inter_references_out</span> <span class=o>=</span> <span class=n>inter_references</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>two_stage</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>hs</span><span class=p>,</span> <span class=n>init_reference_out</span><span class=p>,</span> <span class=n>inter_references_out</span><span class=p>,</span> <span class=n>enc_outputs_class</span><span class=p>,</span> <span class=n>enc_outputs_coord_unact</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>hs</span><span class=p>,</span> <span class=n>init_reference_out</span><span class=p>,</span> <span class=n>inter_references_out</span><span class=p>,</span> <span class=kc>None</span><span class=p>,</span> <span class=kc>None</span></span></span></code></pre></td></tr></table></div></div><h2 id=5experiment>5、Experiment</h2><p><img loading=lazy src=images/5_1.webp srcset="/posts/deformabledetr/images/5_1.webp, images/5_1.webp 1.5x, /posts/deformabledetr/images/5_1.webp 2x" sizes=auto data-title=/posts/deformabledetr/images/5_1.webp data-alt=/posts/deformabledetr/images/5_1.webp width=720 height=464 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>由图4可知，Deformable DETR不仅收敛速率比DETR快并且小目标精度也高了许多。</p><h2 id=6改进策略>6、改进策略</h2><p>Deformable DETR是怎么让DCN和Transformer一起玩的，CW在上述已基本解析完毕。无奈作者还研究了“高配版”的Deformable DETR，涉及两个提升性能的策略: iterative bounding box refinement & two-stage。</p><p><strong>a. Iterative Bounding Box Refinement</strong></p><p>字面意思就是迭代地对bbox进行校正，类似于cascaded head，实质上也是coarse-to-fine不断校正的一个过程。第d层Decoder校正后归一化的bbox用公式表示如下:</p><p>$$\hat{b}<em>q^d={\sigma(\Delta b</em>{qx}^d+\sigma^{-1}(\hat{b}<em>{qx}^{d-1})),\sigma(\Delta b</em>{qy}^d+\sigma^{-1}(\hat{b}<em>{qy}^{d-1})),\sigma(\Delta b</em>{qw}^d+\sigma^{-1}(\hat{b}<em>{qw}^{d-1})),\sigma(\Delta b</em>{qh}^d+\sigma^{-1}(\hat{b}_{qh}^{d-1}))}$$</p><p>其中 $\Delta b_{q{x,y,w,h}}^d$ 是第d层Decoder利用检测头部的回归分支预测的结果(偏移量)，$\sigma$，$\sigma^{-1}$分别代表sigmoid和反sigmoid函数。</p><p>在这里需要注意两点:</p><ol><li>各层的检测头部是不共享参数的；</li><li>校正后的bbox梯度会被阻断(detach)，不会跨层传播</li></ol><p>具体实现和解析在上一节讲Decoder的时候已详细说明。</p><p><strong>Two-Stage Deformable DETR</strong></p><p>2-stage模式下，Encoder会输出一批proposals(<strong>并不是基于网络预测，而是像anchor一样计算出来的</strong>)，boxes中心就是各特征点的中心，而宽、高的设置则与所在的特征层相关，base值设置为0.05。<strong>这时的proposals相对于anchors的角色。</strong></p><p>然后，使用检测头部的分类分支对Encoder编码的特征(memory)进行预测，对应各个proposals的分类结果；同时使用回归分支也对编码特征也进行预测，得到相对于proposals(xywh)的偏移量，接着将偏移量加在proposals的中心坐标和宽、高上得到第一阶段预测的proposals。</p><p>最后，<strong>取top-k分数最高的那批预测proposals作为Decoder的参考点</strong>。并且，<strong>Decoder的object query和query embedding都由参考点通过位置嵌入(position embedding)来生成。</strong></p><h2 id=7conclusion>7、Conclusion</h2><p>Deformable DETR效率高并且收敛快，核心是Multi-Scale Deformable Attention Module。解决了DETR中收敛慢以及小目标性能低的问题。</p><h2 id=8qa>8、Q&amp;A</h2><p>如果认真思考，会发现Deformable DETR中有许多值得考量的地方。</p><p><strong>1. 为何不需要FPN也能达到跨层融合的效果？</strong></p><p>作者在paper中说到，多尺度可变形注意力可以在不同尺度的特征之间交换信息，因此不需要FPN:</p><blockquote><p>Note that the top-down structure in FPN (Lin et al., 2017a) is not used, because our proposed multi-scale deformable attention in itself can exchange information among multi-scale feature maps.</p></blockquote><p>那么到底是为何？具体是怎么做到的呢？</p><p>其实前文也提到了，每个参考点在各尺度特征层都会进行采样。而且在上述处理参考点坐标的过程中，我们也可以看到，无论在Encoder还是Decoder，都会对参考点进行处理，使得一个参考点在所有尺度特征层上都有相应的归一化坐标值。为什么这样做呢？这样做其实就是为了计算出每个参考点在各尺度特征层对应的采样点位置。</p><p>那么你可能又会奇怪了，一个参考点明明是只处于某个特定的特征层，怎么能够把它放到另一个特征层去呢？这样合理吗？</p><p>合理不合理由网络去进行学习，基于最终的匹配效果来证明。但是可不可行我们倒是可分析的，可以这么看: 我们知道，由于特征图是经过原图下采样得到，因此一个像素点无论是处于原图还是各层特征图中，其坐标的归一化值应该是一致的(忽略细微的计算误差)。那么，既然这里参考点坐标是归一化的，它就能够映射(re-scales)到各尺度特征中去，这部分对应以下公式中的 $\phi_l$ 函数:</p><p>$$\text{MSDeformAttn}(z_{q},\hat{p}<em>{q},{x^{l}}</em>{l=1}^{L})=\sum_{m=1}^{M}W_{m}\bigl[\sum_{l=1}^{L}\sum_{k=1}^{K}A_{mlqk}\cdot W_{m}^{\prime}x^{l}\bigl[\phi_{l}(\hat{p}<em>{q})\bigr]+\Delta p</em>{mlqk}\bigr)\bigr],$$</p><p>作者在paper中是这么描述的:</p><blockquote><p>Function $\phi_l$ re-scales the normalized coordinates $\hat{p}_{q}$ to the input feature map of the l-th level.</p></blockquote><p><strong>2. 为何注意力权重可由query直接通过全连接层预测得到？</strong></p><p>我们知道，<strong>在Transformer中，注意力权重是由query和key交互计算得到的。然而，在这里却像开挂般直接通过query经全连接层输出得到</strong>(好家伙~！)，这节奏是不是不对劲呢？要分析这个问题，不妨先来看看Deformable DETR中参考点(reference points)和query之间的关系。</p><p>在Encoder中: 参考点是特征点本身的位置，query embedding是特征图对应的position emebdding(其实还加上了scale-level embedding)，object query则来自于特征图，最终注意力机制中的query就是object query + query embedding。</p><p>在Decoder中: 2-stage时，由参考点经过位置嵌入生成query embedding和object query；而1-stage时，object query和query embedding都是预设的embedding，参考点则由query embedding经全连接层生成，最终注意力机制中的query也是object query + query embedding。</p><p>综上可知，<strong>参考点(reference points)和query之间是存在着对应关系的</strong>(就有点“你生我、我生你”的feel~)。</p><p>OK，既然这样，那么基于参考点位置采样插值出来的特征(value)自然就能够和通过query经过线性变换得到的注意力权重对应起来了，这就是为什么可变形注意力模块中不需要key与query来交互计算注意力权重了。</p><p>打个比方: A与B已建立起了对应关系，之后A再通过某种映射关系得到C，B也通过某种映射关系得到D，那么C与D之间必然会有某种程度的耦合与对应关系。这里A、B、C、D就分别指代query、reference points、attention weights以及value。</p><p>还有个问题值得思考，为何在Decoder中，2-stage时由reference points生成query embedding是通过position embedding，而1-stage时由query embedding生成reference points时却用全连接层呢？</p><p>对此，CW是这么想的: 2-stage时，参考点是由Encoder预测出来的proposals，本身一定程度上代表着物体的位置信息了(虽然这个位置可能并不精确)，因此有必要用位置嵌入将这“宝贵"的信息给记录下来；而1-stage时，预设的query embedding本身就是一个抽象体，盲猜的东西，因此用线性变换来做维度映射得到参考点比较合理，因为毕竟其本身并没有实际意义的位置信息。</p><p><strong>3. 为何检测头部的回归分支预测的是偏移量而非绝对坐标值？</strong></p><p>这个问题估计很多人会提出，<strong>为何这里不像DETR一样直接预测bbox的坐标而是预测偏移量呢？</strong> 请你想想，Deformable DETR相比于DETR多了一个很显眼的东西是什么？是参考点 <strong>(reference points)</strong> 啊！(感觉通篇它都在秀存在感..)</p><p>采样点的位置是基于参考点和对应的坐标偏移量计算出来的，也就是说采样特征是分布在参考点附近的，既然这里需要由采样特征回归出bbox的位置，那么<strong>预测相对于参考点的偏移量就会比直接预测绝对坐标更易优化，更有利于模型学习</strong>。</p><blockquote><p>Because the multi-scale deformable attention module extracts image features around the reference point, we let the detection head predict the bounding box as relative offsets w.r.t. the reference point to further reduce the optimization difficulty.</p></blockquote><p>另外，由于采样特征中注入了注意力，而预测框是基于采样特征回归得到的，loss是基于回归结果计算的，梯度是通过loss反向传播的，因此最终学习到的注意力权重就会和预测框有相对较强的联系，这也起到了加速收敛的效果。</p><blockquote><p>In this way, the learned decoder attention will have strong correlation with the predicted bounding boxes, which also accelerates the training convergence.</p></blockquote><h2 id=9与其它方法比较>9、与其它方法比较</h2><p>Deformable DETR是在DETR基础上提出的，因此，在这最后一部分CW打算将其与DETR作个比较；另外，CW觉得其与Sparse R-CNN也有值得比较的地方，之前CW也写过一篇文章(目前还在简书，后续会同步到知乎这边来)分析过说Sparse R-CNN像是DETR的小弟哈哈哈。</p><p>以下列出的点都是仅出现在 Deformable DETR 中而在 DETR / Sparse R-CNN 中是没有的。</p><p><strong>i). vs DETR</strong></p><ol><li>多尺度特征；</li><li>新增scale-level embedding，用于区分不同特征层(由于第1点)；</li><li>使用了多尺度可变形注意力替代Encoder中的自注意力和Decoder中的交叉注意力；</li><li>引入了参考点，某种程度上起到先验的作用；</li><li>为自己开发了“高配”版: 迭代的框校正策略 和 两阶段模式；</li><li>检测头部的回归分支预测的是bbox偏移量而非绝对坐标值</li></ol><p><strong>ii). vs Sparse R-CNN</strong></p><ol><li>没有使用FPN；</li><li>使用了位置嵌入；</li><li>2-stage时，proposals是predicted的(而非Sparse R-CNN直接使用learnable embedding)；</li><li>使用了Transformer；</li><li>注意力机制是one-to-many iteraction(Sparse R-CNN由于‘Sparse’偶像包袱太重，是彻底的sparse，是one-to-one实例级别的交互)；</li><li>检测头部的回归分支预测的是bbox偏移量而非绝对坐标值</li></ol><p><strong>最后:</strong></p><p>DETR收敛慢和小目标检测效果差的原因在于Transformer的注意力计算模块——它对全局密集的关系进行建模，这使得模型需要长时间去学习(关注)真正有意义的稀疏位置，同时还带来了高复杂度的计算与空间资源消耗。</p><p>联想到稀疏空间位置的学习是DCN的强项，但其又缺乏关系建模能力，于是作者机智地将DCN与Transformer结合在一起，最终提出 Deformable DETR。</p><p>ref:
[1]. <a href=https://zhuanlan.zhihu.com/p/372116181 target=_blank rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/372116181<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>
[2]. <a href=https://blog.csdn.net/qq_38253797/article/details/127668593 target=_blank rel="external nofollow noopener noreferrer">https://blog.csdn.net/qq_38253797/article/details/127668593<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>
[3]. <a href=https://zhuanlan.zhihu.com/p/596303361 target=_blank rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/596303361<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></p></div><div class=post-reward><div class=comment>Buy me a coffee~</div><input type=checkbox class=reward-input name=reward id=fi-reward hidden>
<label class=reward-button for=fi-reward>赞赏</label><div class=reward-ways data-mode=fixed><div><img loading=lazy src=/images/alipay.png srcset="/images/alipay.png, /images/alipay.png 1.5x, /images/alipay.png 2x" sizes=auto data-title="Jian YE 支付宝" data-alt="Jian YE 支付宝" style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span data-animation>支付宝</span></div><div><img loading=lazy src=/images/wechatpay.png srcset="/images/wechatpay.png, /images/wechatpay.png 1.5x, /images/wechatpay.png 2x" sizes=auto data-title="Jian YE 微信" data-alt="Jian YE 微信" style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span data-animation>微信</span></div></div></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span title="更新于 2024-02-08 10:44:40">更新于 2024-02-08&nbsp;<a class=git-hash href=https://github.com/jianye0428/JianBlog/commit/f503d4e006beb480be78a9e746289f957615dbfa rel="external nofollow noopener noreferrer" target=_blank title="commit by yejian(18817571704@163.com) f503d4e006beb480be78a9e746289f957615dbfa: feat: add all"><i class="fa-solid fa-hashtag fa-fw" aria-hidden=true></i>f503d4e</a></span></div></div><div class=post-info-line><div class=post-info-md><span><a href=/posts/deformabledetr/index.md title=阅读原始文档 class=link-to-markdown>阅读原始文档</a></span><span><a href=https://github.com/jianye0428/JianBlog/edit/docs/content/posts/Robotics/AutonomousDriving/Perception/ObjectDetection/DeformableDETR/index.md title=编辑此页 target=_blank rel="external nofollow noopener noreferrer" class=link-to-edit>编辑此页</a></span></div><div class=post-info-share><span><a href=javascript:void(0); title="分享到 Twitter" data-sharer=twitter data-url=https://jianye0428.github.io/posts/deformabledetr/ data-title="Deformable DETR论文精读+代码详解" data-hashtags=draft><i class="fa-brands fa-twitter fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 Facebook" data-sharer=facebook data-url=https://jianye0428.github.io/posts/deformabledetr/ data-hashtag=draft><i class="fa-brands fa-facebook-square fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 Linkedin" data-sharer=linkedin data-url=https://jianye0428.github.io/posts/deformabledetr/><i class="fa-brands fa-linkedin fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 微博" data-sharer=weibo data-url=https://jianye0428.github.io/posts/deformabledetr/ data-title="Deformable DETR论文精读+代码详解"><i class="fa-brands fa-weibo fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 百度" data-sharer=baidu data-url=https://jianye0428.github.io/posts/deformabledetr/ data-title="Deformable DETR论文精读+代码详解"><i data-svg-src=/lib/simple-icons/icons/baidu.min.svg aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fa-solid fa-tags fa-fw me-1" aria-hidden=true></i><a href=/tags/draft/ class=post-tag>Draft</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class=post-nav><a href=/posts/effective_modern_c/ class=post-nav-item rel=prev title="Effective Modern C++ 阅读笔记"><i class="fa-solid fa-angle-left fa-fw" aria-hidden=true></i>Effective Modern C++ 阅读笔记</a>
<a href=/posts/cmake_introduction/ class=post-nav-item rel=next title="CMake 简介">CMake 简介<i class="fa-solid fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article></main><footer class=footer><div class=footer-container><div class="footer-line powered">由 <a href=https://gohugo.io/ target=_blank rel="external nofollow noopener noreferrer" title="Hugo 0.125.3">Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/hugo-fixit/FixIt target=_blank rel=external title="FixIt v0.2.18"><img class=fixit-icon src=/fixit.min.svg alt="FixIt logo">&nbsp;FixIt</a></div><div class="footer-line copyright" itemscope itemtype=http://schema.org/CreativeWork><i class="fa-regular fa-copyright fa-fw" aria-hidden=true></i>
<span itemprop=copyrightYear>2018 - 2024</span><span class=author itemprop=copyrightHolder>
<a href=https://github.com/jianye0428 target=_blank rel="external nofollow noopener noreferrer">Jian YE</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div><div class="footer-line statistics order-first"><span class=site-time title=网站运行中……><i class="fa-solid fa-heartbeat fa-fw animate-icon" aria-hidden=true></i><span class="ms-1 d-none">博客已运行</span><span class="run-times ms-1">网站运行中……</span></span></div><div class="footer-line visitor"><span id=busuanzi_container_site_uv title=总访客数><i class="fa-regular fa-user fa-fw" aria-hidden=true></i>&nbsp;<span id=busuanzi_value_site_uv><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden=true></i></span></span><span id=busuanzi_container_site_pv class=footer-divider title=总访问量><i class="fa-regular fa-eye fa-fw" aria-hidden=true></i>&nbsp;<span id=busuanzi_value_site_pv><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden=true></i></span></span></div></div></footer></div><div class=widgets><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role=button aria-label=回到顶部><i class="fa-solid fa-arrow-up fa-fw" aria-hidden=true></i><span class=variant-numeric>0%</span></div></div><a href=https://github.com/jianye0428/JianBlog title="在 GitHub 上查看程式碼，訂閱請點 Watch" target=_blank rel="external nofollow" class="github-corner right d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115h15l12 27L250 250V0z"/><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentcolor" style="transform-origin:130px 106px" class="octo-arm"/><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4l13.9-13.8C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8z" fill="currentcolor" class="octo-body"/></svg></a><div id=mask></div><div class=reading-progress-bar style=left:0;top:0;--bg-progress:#000;--bg-progress-dark:#fff></div><noscript><div class=noscript-warning>FixIt 主题在启用 JavaScript 的情况下效果最佳。</div></noscript></div><link rel=stylesheet href=/lib/katex/katex.min.css><link rel=stylesheet href=/lib/cookieconsent/cookieconsent.min.css><link rel=stylesheet href=/lib/pace/themes/blue/pace-theme-minimal.css><script src=/lib/autocomplete/autocomplete.min.js defer></script><script src=/lib/algoliasearch/algoliasearch-lite.umd.min.js defer></script><script src=/lib/instant-page/instantpage.min.js async defer type=module></script><script src=/lib/twemoji/twemoji.min.js defer></script><script src=/lib/sharer/sharer.min.js async defer></script><script src=/lib/katex/katex.min.js defer></script><script src=/lib/katex/auto-render.min.js defer></script><script src=/lib/katex/mhchem.min.js defer></script><script src=/lib/cookieconsent/cookieconsent.min.js defer></script><script src=/lib/pangu/pangu.min.js defer></script><script src=/lib/cell-watermark/watermark.min.js defer></script><script src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js async defer></script><script src=/lib/pace/pace.min.js async defer></script><script>window.config={autoBookmark:!0,code:{copyTitle:"复制到剪贴板",editLockTitle:"锁定可编辑代码块",editUnLockTitle:"解锁可编辑代码块",editable:!0,maxShownLines:50},comment:{enable:!1},cookieconsent:{content:{dismiss:"同意",link:"了解更多",message:"本网站使用 Cookies 来改善您的浏览体验。"},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},enablePWA:!0,math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},pangu:{enable:!0,selector:"article"},search:{algoliaAppID:"MTJNHU0JVB",algoliaIndex:"index",algoliaSearchKey:"5486225134d99f43826da401ee9bad57",highlightTag:"em",maxResultLength:10,noResultsFound:"没有找到结果",snippetLength:50,type:"algolia"},siteTime:"2018-05-28T20:01:01+08:00",twemoji:!0,watermark:{appendto:".wrapper>main",colspacing:30,content:'<img style="height: 0.85rem;" src="/images/favicon/jian_icon.png" alt="logo" /> jianye',enable:!0,fontfamily:"MMT_LRH,沐目体",fontsize:1.1,height:20,opacity:.0125,rotate:15,rowspacing:60,width:150}}</script><script src=/js/theme.min.js defer></script><script src=/js/custom.min.js defer></script></body></html>