<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=2"><meta name=robots content="noodp"><title>强化学习笔记 [17] | 基于模型的强化学习与Dyna算法框架 - yejian's blog</title><meta name=author content="Jian YE">
<meta name=author-link content="https://github.com/jianye0428"><meta name=description content="强化学习(十七) 基于模型的强化学习与Dyna算法框架 在前面我们讨论了基于价值的强化学习(Value Based RL)和基于策略的强化学习模型(Policy Based RL)，本篇我们讨论最后一种强化学习流派，基于模型的强化学习(Model Based RL)，以及基于模型的强化学习算法框架Dyna。 本篇主要参考了UCL强化学习课程"><meta name=keywords content='RL'><meta itemprop=name content="强化学习笔记 [17] | 基于模型的强化学习与Dyna算法框架"><meta itemprop=description content="强化学习(十七) 基于模型的强化学习与Dyna算法框架 在前面我们讨论了基于价值的强化学习(Value Based RL)和基于策略的强化学习模型(Policy Based RL)，本篇我们讨论最后一种强化学习流派，基于模型的强化学习(Model Based RL)，以及基于模型的强化学习算法框架Dyna。 本篇主要参考了UCL强化学习课程"><meta itemprop=datePublished content="2024-02-25T19:53:15+08:00"><meta itemprop=dateModified content="2024-02-25T21:12:29+08:00"><meta itemprop=wordCount content="2640"><meta itemprop=image content="https://jianye0428.github.io/images/favicon/jian_icon.png"><meta itemprop=keywords content="RL"><meta property="og:url" content="https://jianye0428.github.io/posts/rl_learning_note_17/"><meta property="og:site_name" content="yejian's blog"><meta property="og:title" content="强化学习笔记 [17] | 基于模型的强化学习与Dyna算法框架"><meta property="og:description" content="强化学习(十七) 基于模型的强化学习与Dyna算法框架 在前面我们讨论了基于价值的强化学习(Value Based RL)和基于策略的强化学习模型(Policy Based RL)，本篇我们讨论最后一种强化学习流派，基于模型的强化学习(Model Based RL)，以及基于模型的强化学习算法框架Dyna。 本篇主要参考了UCL强化学习课程"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-02-25T19:53:15+08:00"><meta property="article:modified_time" content="2024-02-25T21:12:29+08:00"><meta property="article:tag" content="RL"><meta property="og:image" content="https://jianye0428.github.io/images/favicon/jian_icon.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jianye0428.github.io/images/favicon/jian_icon.png"><meta name=twitter:title content="强化学习笔记 [17] | 基于模型的强化学习与Dyna算法框架"><meta name=twitter:description content="强化学习(十七) 基于模型的强化学习与Dyna算法框架 在前面我们讨论了基于价值的强化学习(Value Based RL)和基于策略的强化学习模型(Policy Based RL)，本篇我们讨论最后一种强化学习流派，基于模型的强化学习(Model Based RL)，以及基于模型的强化学习算法框架Dyna。 本篇主要参考了UCL强化学习课程"><meta name=application-name content="菠菜阿九时代峰峻啊；数量可根据；"><meta name=apple-mobile-web-app-title content="菠菜阿九时代峰峻啊；数量可根据；"><meta name=theme-color data-light=#ffffff data-dark=#252627 content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/png href=/jian_icon.png><link rel=icon type=image/png sizes=32x32 href=/jian_icon.png><link rel=icon type=image/png sizes=16x16 href=/jian_icon.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://jianye0428.github.io/posts/rl_learning_note_17/><link rel=prev href=https://jianye0428.github.io/posts/rl_learning_note_16/><link rel=next href=https://jianye0428.github.io/posts/rl_learning_note_18/><link rel=stylesheet href=/css/style.min.css><link rel=stylesheet href=/lib/fontawesome-free/all.min.css><link rel=stylesheet href=/lib/animate/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"强化学习笔记 [17] | 基于模型的强化学习与Dyna算法框架","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/jianye0428.github.io\/posts\/rl_learning_note_17\/"},"image":["https:\/\/jianye0428.github.io\/images\/favicon\/jian_icon.png"],"genre":"posts","keywords":"RL","wordcount":2640,"url":"https:\/\/jianye0428.github.io\/posts\/rl_learning_note_17\/","datePublished":"2024-02-25T19:53:15+08:00","dateModified":"2024-02-25T21:12:29+08:00","publisher":{"@type":"Organization","name":"Jian YE","logo":"https:\/\/jianye0428.github.io\/images\/favicon\/jian_icon.png"},"author":{"@type":"Person","name":"Jian YE"},"description":""}</script></head><body data-header-desktop=sticky data-header-mobile=auto><script>(window.localStorage?.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("data-theme","dark")</script><div class=wrapper data-page-style=wide><header class="desktop animate__faster" id=header-desktop><div class=header-wrapper data-github-corner=right><div class=header-title><a href=/ title="yejian's blog"><img loading=lazy src=/images/favicon/jian_icon.png srcset="/images/favicon/jian_icon.png, /images/favicon/jian_icon.png 1.5x, /images/favicon/jian_icon.png 2x" sizes=auto data-title="yejian's blog" data-alt="yejian's blog" class=logo style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span class=header-title-text>Jian's Blog</span></a><span class=header-subtitle></span></div><nav><ul class=menu><li class=menu-item><a class=menu-link href=/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> 所有文章</a></li><li class=menu-item><a class=menu-link href=/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> 分类</a></li><li class=menu-item><a class=menu-link href=/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> 标签</a></li><li class=menu-item><a class=menu-link href=/friends/ title=友情链接><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden=true></i> 友链</a></li><li class=menu-item><a class=menu-link href=/guestbook/><i class="fa-solid fa-comments fa-fw fa-sm" aria-hidden=true></i> 留言</a></li><li class="menu-item has-children"><a class=menu-link href=/about/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 关于</a><i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden=true></i><ul class=sub-menu><li class=menu-item><a class=menu-link href=/projects/_index.zh-tw/ title=項目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的項目</a></li><li class=menu-item><a class=menu-link href=/projects/ title=项目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的项目</a></li></ul></li><li class=menu-item><a class=menu-link href=/pilot/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 导航</a></li><li class="menu-item delimiter"></li><li class="menu-item search" id=search-desktop><input type=text placeholder=搜索文章标题或内容…… id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></li><li class="menu-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></li></ul></nav></div></header><header class="mobile animate__faster" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="yejian's blog"><img loading=lazy src=/images/favicon/jian_icon.png srcset="/images/favicon/jian_icon.png, /images/favicon/jian_icon.png 1.5x, /images/favicon/jian_icon.png 2x" sizes=auto data-title=/images/favicon/jian_icon.png data-alt=/images/favicon/jian_icon.png class=logo style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span class=header-title-text>Jian's Blog</span></a><span class=header-subtitle></span></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><nav><ul class=menu id=menu-mobile><li class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索文章标题或内容…… id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></li><li class=menu-item><a class=menu-link href=/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> 所有文章</a></li><li class=menu-item><a class=menu-link href=/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> 分类</a></li><li class=menu-item><a class=menu-link href=/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> 标签</a></li><li class=menu-item><a class=menu-link href=/friends/ title=友情链接><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden=true></i> 友链</a></li><li class=menu-item><a class=menu-link href=/guestbook/><i class="fa-solid fa-comments fa-fw fa-sm" aria-hidden=true></i> 留言</a></li><li class=menu-item><span class=nested-item><a class=menu-link href=/about/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 关于</a>
<i class="dropdown-icon fa-solid fa-chevron-right" aria-hidden=true></i></span><ul class=sub-menu><li class=menu-item><a class=menu-link href=/projects/_index.zh-tw/ title=項目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的項目</a></li><li class=menu-item><a class=menu-link href=/projects/ title=项目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的项目</a></li></ul></li><li class=menu-item><a class=menu-link href=/pilot/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 导航</a></li><li class="menu-item text-center"><a class=menu-link href=https://github.com/jianye0428/ title=GitHub rel="noopener noreferrer" target=_blank><i class='fa-brands fa-github fa-fw' aria-hidden=true></i></a></li><li class="menu-item menu-system"><span class="menu-system-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></span></li></ul></nav></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class="container container-reverse"><aside class=toc id=toc-auto></aside><aside class=aside-custom></aside><article class="page single"><div class=header><h1 class="single-title animate__animated animate__flipInX"><span>强化学习笔记 [17] | 基于模型的强化学习与Dyna算法框架</span></h1></div><div class=post-meta><div class=post-meta-line><span class=post-author><a href=https://github.com/jianye0428 title=作者 target=_blank rel="external nofollow noopener noreferrer author" class=author><img loading=lazy src="https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp" srcset="https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp, https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp 1.5x, https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp 2x" sizes=auto data-title="Jian YE" data-alt="Jian YE" class=avatar style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'>&nbsp;Jian YE</a></span>
<span class=post-category>收录于 <a href=/categories/rl/><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> RL</a></span></div><div class=post-meta-line><span title="发布于 2024-02-25 19:53:15"><i class="fa-regular fa-calendar-alt fa-fw me-1" aria-hidden=true></i><time datetime=2024-02-25>2024-02-25</time></span>&nbsp;<span title="更新于 2024-02-25 21:12:29"><i class="fa-regular fa-edit fa-fw me-1" aria-hidden=true></i><time datetime=2024-02-25>2024-02-25</time></span>&nbsp;<span><i class="fa-solid fa-pencil-alt fa-fw me-1" aria-hidden=true></i>约 2640 字</span>&nbsp;<span><i class="fa-regular fa-clock fa-fw me-1" aria-hidden=true></i>预计阅读 6 分钟</span>&nbsp;<span id=busuanzi_container_page_pv class="busuanzi_visitors comment-visitors" data-flag-title="强化学习笔记 [17] | 基于模型的强化学习与Dyna算法框架">
<i class="fa-regular fa-eye fa-fw me-1" aria-hidden=true></i><span id=busuanzi_value_page_pv>-</span>&nbsp;次阅读
</span>&nbsp;</div></div><div class=content id=content data-end-flag=（完）><div class="details admonition note open"><div class="details-summary admonition-title"><i class="icon fa-solid fa-pencil-alt fa-fw" aria-hidden=true></i>注意<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class=details-content><div class=admonition-content>本文最后更新于 2024-02-25，文中内容可能已过时。</div></div></div><h1 id=强化学习十七-基于模型的强化学习与dyna算法框架httpswwwcnblogscompinardp10384424html><a href=https://www.cnblogs.com/pinard/p/10384424.html target=_blank rel="external nofollow noopener noreferrer">强化学习(十七) 基于模型的强化学习与Dyna算法框架<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></h1><p>在前面我们讨论了基于价值的强化学习(Value Based RL)和基于策略的强化学习模型(Policy Based RL)，本篇我们讨论最后一种强化学习流派，基于模型的强化学习(Model Based RL)，以及基于模型的强化学习算法框架Dyna。</p><p>本篇主要参考了UCL强化学习课程的第8讲和Dyna-2的<a href=https://www.davidsilver.uk/wp-content/uploads/2020/03/dyna2_compressed.pdf target=_blank rel="external nofollow noopener noreferrer">论文<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>。</p><h1 id=1-基于模型的强化学习简介>1. 基于模型的强化学习简介</h1><p>基于价值的强化学习模型和基于策略的强化学习模型都不是基于模型的，它们从价值函数，策略函数中直接去学习，不用学习环境的状态转化概率模型，即在状态 $s$ 下采取动作 $a$,转到下一个状态 $s&rsquo;$ 的概率 $P^a_{ss&rsquo;}$。</p><p>而基于模型的强化学习则会尝试从环境的模型去学习，一般是下面两个相互独立的模型：</p><ul><li>一个是状态转化预测模型，输入当前状态 $s$和动作 $a$，预测下一个状态 $s&rsquo;$。</li><li>另一个是奖励预测模型，输入当前状态 $s$和动作 $a$，预测环境的奖励 $r$。</li></ul><p>即模型可以描述为下面两个式子：</p><p>$$\begin{gathered}S_{t+1}\sim P(S_{t+1}|S_t,A_t)\\R_{t+1}\sim R(R_{t+1}|S_t,A_t)\end{gathered}$$</p><p>如果模型 $P$, $R$ 可以准确的描述真正的环境的转化模型，那么我们就可以基于模型来预测，当有一个新的状态 $S$ 和动作 $A$到来时，我们可以直接基于模型预测得到新的状态和动作奖励，不需要和环境交互。当然如果我们的模型不好，那么基于模型预测的新状态和动作奖励可能错的离谱。</p><p>从上面的描述我们可以看出基于模型的强化学习和不基于模型的强化学习的主要区别：即基于模型的强化学习是从模型中学习，而不基于模型的强化学习是从和环境交互的经历去学习。</p><p>下面这张图描述了基于模型的强化学习的思路：</p><br><center><img src=images/1_01.png width=640 height=320 align=center style="border-radius:.3125em;box-shadow:0 2px 4px rgba(34,36,38,.12),0 2px 10px rgba(34,36,38,8%)"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">Model-based RL</div></center><br><h1 id=2-基于模型的强化学习算法训练流程>2. 基于模型的强化学习算法训练流程</h1><p>这里我们看看基于模型的强化学习算法训练流程，其流程和我们监督学习算法是非常类似的。</p><p>假设训练数据是若干组这样的经历：</p><p>$$S_1,A_1,R_2,S_2,A_2,R_2,\ldots,S_T$$</p><p>对于每组经历，我们可以将其转化为 $T−1$ 组训练样本，即：</p><p>$$\begin{gathered}
S_1,A_1\to S_2,S_1,A_1\to R_2 \\
S_2,A_2\to S_3,S_2,A_2\to R_3 \\
&mldr;&mldr; \\
S_{T-1},A_{T-1}\rightarrow S_T,~S_{T_1},A_{T-1}\rightarrow R_T
\end{gathered}$$</p><p>右边的训练样本一起组成了一个分类模型或密度估计模型，输入状态和动作，输出下一个状态。 右边的训练样本一起组成了一个回归模型训练集，输入状态和动作，输出动作奖励值。</p><p>至此我们的强化学习求解过程和传统的监督学习算法没有太多区别了，可以使用传统的监督学习算法来求解这两个模型。</p><p>当然还可以更简单，即通过对训练样本进行查表法进行统计，直接得到 $P(S_{t+1}|S_t,A_t)$ 的概率和 $R(R_{t+1}|S_t,A_t)$ 的平均值，这样就可以直接预测。比使用模型更简单。</p><p>此外，还有其他的方法可以用来得到 $P(S_{t+1}|S_t,A_t)$和 $R(R_{t+1}|S_t,A_t)$，这个我们后面再讲。</p><p>虽然基于模型的强化学习思路很清晰，而且还有不要和环境持续交互优化的优点，但是用于实际产品还是有很多差距的。主要是我们的模型绝大多数时候不能准确的描述真正的环境的转化模型，那么使用基于模型的强化学习算法得到的解大多数时候也不是很实用。那么是不是基于模型的强化学习就不能用了呢？也不是，我们可以将基于模型的强化学习和不基于模型的强化学习集合起来，取长补短，这样做最常见的就是Dyna算法框架。</p><h1 id=3-dyna算法框架>3. Dyna算法框架</h1><p>Dyna算法框架并不是一个具体的强化学习算法，而是一类算法框架的总称。Dyna将基于模型的强化学习和不基于模型的强化学习集合起来，既从模型中学习，也从和环境交互的经历去学习，从而更新价值函数和（或）策略函数。如果用和第一节类似的图，可以表示如下图，和第一节的图相比，多了一个“Direct RL“的箭头，这正是不基于模型的强化学习的思路。</p><br><center><img src=images/3_01.png width=640 height=320 align=center style="border-radius:.3125em;box-shadow:0 2px 4px rgba(34,36,38,.12),0 2px 10px rgba(34,36,38,8%)"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">Dyna算法示意图</div></center><br><p>Dyna算法框架和不同的具体的不基于模型的强化学习一起，可以得到具体的不同算法。如果我们使用基于价值函数的Q-Learning，那么我们就得到了Dyna-Q算法。我们基于Dyna-Q来看看Dyna算法框架的一般流程.</p><h1 id=4-dyna-q算法流程>4. Dyna-Q算法流程</h1><p>这里我们给出基于价值函数的Dyna-Q算法的概要流程。假设模型使用的是查表法。</p><ul><li>(1). 初始化任意一个状态 $s$,和任意一个动作 $a$ 对应的状态价值 $Q(s,a)$, 初始化奖励模型 $R(s,a)$和状态模型 $P(s,a)$</li><li>(2). for $i=1$ to 最大迭代次数T：<ul><li>(a) $S \leftarrow \text{current state}$</li><li>(b) $A \leftarrow \text{ϵ−greedy(S,Q)}$</li><li>(c) 执行动作 $A$,得到新状态 $S&rsquo;$ 和奖励 $R$</li><li>(d) 使用Q-Learning更新价值函数：$Q(S,A)=Q(S,A)+\alpha[R+\gamma\max_aQ(S^{\prime},a)-Q(S,A)]$</li><li>(e) 使用 $S,A,S^{\prime}$ 更新状态模型 $P(s,a)$，使用 $S,A,R$ 更新状态模型 $R(s,a)$</li><li>(f) $\text{for} \space \space j=1 \space \space \text{to} \text{最大次数}n$：<ul><li>(i) 随机选择一个之前出现过的状态 $S$ , 在状态 $S$ 上出现过的动作中随机选择一个动作 $A$</li><li>(ii) 基于模型 $P(S,A)$ 得到 $S&rsquo;$, 基于模型 $R(S,A)$ 得到 $R$</li><li>(iii) 使用Q-Learning更新价值函数: $Q(S,A)=Q(S,A)+\alpha[R+\gamma\max_aQ(S^{\prime},a)-Q(S,A)]$</li></ul></li></ul></li></ul><p>从上面的流程可以看出，Dyna框架在每个迭代轮中，会先和环境交互，并更新价值函数和（或）策略函数，接着进行n次模型的预测，同样更新价值函数和（或）策略函数。这样同时利用上了和环境交互的经历以及模型的预测。</p><h1 id=5-dyna-2算法框架>5. Dyna-2算法框架</h1><p>在Dyna算法框架的基础上后来又发展出了Dyna-2算法框架。和Dyna相比，Dyna-2将和和环境交互的经历以及模型的预测这两部分使用进行了分离。还是以Q函数为例，Dyna-2将记忆分为<strong>永久性记忆</strong>（permanent memory）和<strong>瞬时记忆</strong>（transient memory）, 其中永久性记忆利用实际的经验来更新，瞬时记忆利用模型模拟经验来更新。</p><p>永久性记忆的Q函数定义为：</p><p>$$Q(S,A)=\phi(S,A)^T\theta $$</p><p>瞬时记忆的Q函数定义为：</p><p>$$Q^{\prime}(S,A)=\overline{\phi}(S,A)^T\overline{\theta}$$</p><p>组合起来后记忆的Q函数定义为：</p><p>$$\overline{Q}(S,A)=\phi(S,A)^T\theta+\overline{\phi}(S,A)^T\overline{\theta}$$</p><p>Dyna-2的基本思想是在选择实际的执行动作前，智能体先执行一遍从当前状态开始的基于模型的模拟，该模拟将仿真完整的轨迹，以便评估当前的动作值函数。智能体会根据模拟得到的动作值函数加上实际经验得到的值函数共同选择实际要执行的动作。价值函数的更新方式类似于 $SARSA(λ)$</p><p>以下是Dyna-2的算法流程：</p><br><center><img src=images/5_01.png width=640 height=320 align=center style="border-radius:.3125em;box-shadow:0 2px 4px rgba(34,36,38,.12),0 2px 10px rgba(34,36,38,8%)"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">Dyna-2 算法流程</div></center><br><h1 id=6-基于模型的强化学习总结>6. 基于模型的强化学习总结</h1><p>基于模型的强化学习一般不单独使用，而是和不基于模型的强化学习结合起来，因此使用Dyna算法框架是常用的做法。对于模型部分，我们可以用查表法和监督学习法等方法，预测或者采样得到模拟的经历。而对于非模型部分，使用前面的Q-Learning系列的价值函数近似，或者基于Actor-Critic的策略函数的近似都是可以的。</p><p>除了Dyna算法框架，我们还可以使用基于模拟的搜索(simulation-based search)来结合基于模型的强化学习和不基于模型的强化学习,并求解问题。这部分我们在后面再讨论。</p></div><div class=post-reward><div class=comment>Buy me a coffee~</div><input type=checkbox class=reward-input name=reward id=fi-reward hidden>
<label class=reward-button for=fi-reward>赞赏</label><div class=reward-ways data-mode=fixed><div><img loading=lazy src=/images/alipay.png srcset="/images/alipay.png, /images/alipay.png 1.5x, /images/alipay.png 2x" sizes=auto data-title="Jian YE 支付宝" data-alt="Jian YE 支付宝" style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span data-animation>支付宝</span></div><div><img loading=lazy src=/images/wechatpay.png srcset="/images/wechatpay.png, /images/wechatpay.png 1.5x, /images/wechatpay.png 2x" sizes=auto data-title="Jian YE 微信" data-alt="Jian YE 微信" style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span data-animation>微信</span></div></div></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span title="更新于 2024-02-25 21:12:29">更新于 2024-02-25&nbsp;<a class=git-hash href=https://github.com/jianye0428/JianBlog/commit/23cd7c478708235ece71456fee411313e37ef46b rel="external nofollow noopener noreferrer" target=_blank title="commit by yejian(18817571704@163.com) 23cd7c478708235ece71456fee411313e37ef46b: feat: add rl learning note to 19"><i class="fa-solid fa-hashtag fa-fw" aria-hidden=true></i>23cd7c4</a></span></div></div><div class=post-info-line><div class=post-info-md><span><a href=/posts/rl_learning_note_17/index.md title=阅读原始文档 class=link-to-markdown>阅读原始文档</a></span><span><a href=https://github.com/jianye0428/JianBlog/edit/docs/content/posts/RL/RL_Learning_Notes/rl_learning_note_17/index.md title=编辑此页 target=_blank rel="external nofollow noopener noreferrer" class=link-to-edit>编辑此页</a></span></div><div class=post-info-share><span><a href=javascript:void(0); title="分享到 Twitter" data-sharer=twitter data-url=https://jianye0428.github.io/posts/rl_learning_note_17/ data-title="强化学习笔记 [17] | 基于模型的强化学习与Dyna算法框架" data-hashtags=RL><i class="fa-brands fa-twitter fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 Facebook" data-sharer=facebook data-url=https://jianye0428.github.io/posts/rl_learning_note_17/ data-hashtag=RL><i class="fa-brands fa-facebook-square fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 Linkedin" data-sharer=linkedin data-url=https://jianye0428.github.io/posts/rl_learning_note_17/><i class="fa-brands fa-linkedin fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 微博" data-sharer=weibo data-url=https://jianye0428.github.io/posts/rl_learning_note_17/ data-title="强化学习笔记 [17] | 基于模型的强化学习与Dyna算法框架"><i class="fa-brands fa-weibo fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 百度" data-sharer=baidu data-url=https://jianye0428.github.io/posts/rl_learning_note_17/ data-title="强化学习笔记 [17] | 基于模型的强化学习与Dyna算法框架"><i data-svg-src=/lib/simple-icons/icons/baidu.min.svg aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fa-solid fa-tags fa-fw me-1" aria-hidden=true></i><a href=/tags/rl/ class=post-tag>RL</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class=post-nav><a href=/posts/rl_learning_note_16/ class=post-nav-item rel=prev title="强化学习笔记 [16] | 深度确定性策略梯度(DDPG)"><i class="fa-solid fa-angle-left fa-fw" aria-hidden=true></i>强化学习笔记 [16] | 深度确定性策略梯度(DDPG)</a>
<a href=/posts/rl_learning_note_18/ class=post-nav-item rel=next title="强化学习笔记 [18] | 基于模拟的搜索与蒙特卡罗树搜索(MCTS)">强化学习笔记 [18] | 基于模拟的搜索与蒙特卡罗树搜索(MCTS)<i class="fa-solid fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article></main><footer class=footer><div class=footer-container><div class="footer-line powered">由 <a href=https://gohugo.io/ target=_blank rel="external nofollow noopener noreferrer" title="Hugo 0.128.1">Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/hugo-fixit/FixIt target=_blank rel=external title="FixIt v0.2.18"><img class=fixit-icon src=/fixit.min.svg alt="FixIt logo">&nbsp;FixIt</a></div><div class="footer-line copyright" itemscope itemtype=http://schema.org/CreativeWork><i class="fa-regular fa-copyright fa-fw" aria-hidden=true></i>
<span itemprop=copyrightYear>2018 - 2024</span><span class=author itemprop=copyrightHolder>
<a href=https://github.com/jianye0428 target=_blank rel="external nofollow noopener noreferrer">Jian YE</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div><div class="footer-line statistics order-first"><span class=site-time title=网站运行中……><i class="fa-solid fa-heartbeat fa-fw animate-icon" aria-hidden=true></i><span class="ms-1 d-none">博客已运行</span><span class="run-times ms-1">网站运行中……</span></span></div><div class="footer-line visitor"><span id=busuanzi_container_site_uv title=总访客数><i class="fa-regular fa-user fa-fw" aria-hidden=true></i>&nbsp;<span id=busuanzi_value_site_uv><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden=true></i></span></span><span id=busuanzi_container_site_pv class=footer-divider title=总访问量><i class="fa-regular fa-eye fa-fw" aria-hidden=true></i>&nbsp;<span id=busuanzi_value_site_pv><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden=true></i></span></span></div></div></footer></div><div class=widgets><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role=button aria-label=回到顶部><i class="fa-solid fa-arrow-up fa-fw" aria-hidden=true></i><span class=variant-numeric>0%</span></div></div><a href=https://github.com/jianye0428/JianBlog title="在 GitHub 上查看程式碼，訂閱請點 Watch" target=_blank rel="external nofollow" class="github-corner right d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115h15l12 27L250 250V0z"/><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentcolor" style="transform-origin:130px 106px" class="octo-arm"/><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4l13.9-13.8C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8z" fill="currentcolor" class="octo-body"/></svg></a><div id=mask></div><div class=reading-progress-bar style=left:0;top:0;--bg-progress:#000;--bg-progress-dark:#fff></div><noscript><div class=noscript-warning>FixIt 主题在启用 JavaScript 的情况下效果最佳。</div></noscript></div><link rel=stylesheet href=/lib/katex/katex.min.css><link rel=stylesheet href=/lib/cookieconsent/cookieconsent.min.css><link rel=stylesheet href=/lib/pace/themes/blue/pace-theme-minimal.css><script src=/lib/autocomplete/autocomplete.min.js defer></script><script src=/lib/algoliasearch/algoliasearch-lite.umd.min.js defer></script><script src=/lib/instant-page/instantpage.min.js async defer type=module></script><script src=/lib/twemoji/twemoji.min.js defer></script><script src=/lib/sharer/sharer.min.js async defer></script><script src=/lib/katex/katex.min.js defer></script><script src=/lib/katex/auto-render.min.js defer></script><script src=/lib/katex/mhchem.min.js defer></script><script src=/lib/cookieconsent/cookieconsent.min.js defer></script><script src=/lib/pangu/pangu.min.js defer></script><script src=/lib/cell-watermark/watermark.min.js defer></script><script src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js async defer></script><script src=/lib/pace/pace.min.js async defer></script><script>window.config={autoBookmark:!0,code:{copyTitle:"复制到剪贴板",editLockTitle:"锁定可编辑代码块",editUnLockTitle:"解锁可编辑代码块",editable:!0,maxShownLines:50},comment:{enable:!1},cookieconsent:{content:{dismiss:"同意",link:"了解更多",message:"本网站使用 Cookies 来改善您的浏览体验。"},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},enablePWA:!0,math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},pangu:{enable:!0,selector:"article"},search:{algoliaAppID:"MTJNHU0JVB",algoliaIndex:"index",algoliaSearchKey:"5486225134d99f43826da401ee9bad57",highlightTag:"em",maxResultLength:10,noResultsFound:"没有找到结果",snippetLength:50,type:"algolia"},siteTime:"2018-05-28T20:01:01+08:00",twemoji:!0,watermark:{appendto:".wrapper>main",colspacing:30,content:'<img style="height: 0.85rem;" src="/images/favicon/jian_icon.png" alt="logo" /> jianye',enable:!0,fontfamily:"MMT_LRH,沐目体",fontsize:1.1,height:20,opacity:.0125,rotate:15,rowspacing:60,width:150}}</script><script src=/js/theme.min.js defer></script><script src=/js/custom.min.js defer></script></body></html>