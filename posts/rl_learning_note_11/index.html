<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=2"><meta name=robots content="noodp"><title>强化学习笔记 [11] | Prioritized Replay DQN - yejian's blog</title><meta name=author content="Jian YE">
<meta name=author-link content="https://github.com/jianye0428"><meta name=description content="0. 引言 在强化学习（十）Double DQN (DDQN)中，我们讲到了DDQN使用两个Q网络，用当前Q网络计算最大Q值对应的动作，用目标Q网络计算这个最大动作对应的目标Q值，进而消除贪婪法带来的偏差。今天我们在DDQN的基础上，对经验回放部分的逻辑做优化。对应的算法是Prioritized Replay DQN。 本章内容"><meta name=keywords content='RL'><meta itemprop=name content="强化学习笔记 [11] | Prioritized Replay DQN"><meta itemprop=description content="0. 引言 在强化学习（十）Double DQN (DDQN)中，我们讲到了DDQN使用两个Q网络，用当前Q网络计算最大Q值对应的动作，用目标Q网络计算这个最大动作对应的目标Q值，进而消除贪婪法带来的偏差。今天我们在DDQN的基础上，对经验回放部分的逻辑做优化。对应的算法是Prioritized Replay DQN。 本章内容"><meta itemprop=datePublished content="2024-02-25T11:16:48+08:00"><meta itemprop=dateModified content="2024-02-28T09:10:39+08:00"><meta itemprop=wordCount content="3777"><meta itemprop=image content="https://jianye0428.github.io/images/favicon/jian_icon.png"><meta itemprop=keywords content="RL,"><meta property="og:title" content="强化学习笔记 [11] | Prioritized Replay DQN"><meta property="og:description" content="0. 引言 在强化学习（十）Double DQN (DDQN)中，我们讲到了DDQN使用两个Q网络，用当前Q网络计算最大Q值对应的动作，用目标Q网络计算这个最大动作对应的目标Q值，进而消除贪婪法带来的偏差。今天我们在DDQN的基础上，对经验回放部分的逻辑做优化。对应的算法是Prioritized Replay DQN。 本章内容"><meta property="og:type" content="article"><meta property="og:url" content="https://jianye0428.github.io/posts/rl_learning_note_11/"><meta property="og:image" content="https://jianye0428.github.io/images/favicon/jian_icon.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-02-25T11:16:48+08:00"><meta property="article:modified_time" content="2024-02-28T09:10:39+08:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jianye0428.github.io/images/favicon/jian_icon.png"><meta name=twitter:title content="强化学习笔记 [11] | Prioritized Replay DQN"><meta name=twitter:description content="0. 引言 在强化学习（十）Double DQN (DDQN)中，我们讲到了DDQN使用两个Q网络，用当前Q网络计算最大Q值对应的动作，用目标Q网络计算这个最大动作对应的目标Q值，进而消除贪婪法带来的偏差。今天我们在DDQN的基础上，对经验回放部分的逻辑做优化。对应的算法是Prioritized Replay DQN。 本章内容"><meta name=application-name content="菠菜阿九时代峰峻啊；数量可根据；"><meta name=apple-mobile-web-app-title content="菠菜阿九时代峰峻啊；数量可根据；"><meta name=theme-color data-light=#ffffff data-dark=#252627 content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/png href=/jian_icon.png><link rel=icon type=image/png sizes=32x32 href=/jian_icon.png><link rel=icon type=image/png sizes=16x16 href=/jian_icon.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://jianye0428.github.io/posts/rl_learning_note_11/><link rel=prev href=https://jianye0428.github.io/posts/rl_learning_note_10/><link rel=next href=https://jianye0428.github.io/posts/rl_learning_note_12/><link rel=stylesheet href=/css/style.min.css><link rel=stylesheet href=/lib/fontawesome-free/all.min.css><link rel=stylesheet href=/lib/animate/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"强化学习笔记 [11] | Prioritized Replay DQN","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/jianye0428.github.io\/posts\/rl_learning_note_11\/"},"image":["https:\/\/jianye0428.github.io\/images\/favicon\/jian_icon.png"],"genre":"posts","keywords":"RL","wordcount":3777,"url":"https:\/\/jianye0428.github.io\/posts\/rl_learning_note_11\/","datePublished":"2024-02-25T11:16:48+08:00","dateModified":"2024-02-28T09:10:39+08:00","publisher":{"@type":"Organization","name":"Jian YE","logo":"https:\/\/jianye0428.github.io\/images\/favicon\/jian_icon.png"},"author":{"@type":"Person","name":"Jian YE"},"description":""}</script></head><body data-header-desktop=sticky data-header-mobile=auto><script>(window.localStorage?.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("data-theme","dark")</script><div class=wrapper data-page-style=wide><header class="desktop animate__faster" id=header-desktop><div class=header-wrapper data-github-corner=right><div class=header-title><a href=/ title="yejian's blog"><img loading=lazy src=/images/favicon/jian_icon.png srcset="/images/favicon/jian_icon.png, /images/favicon/jian_icon.png 1.5x, /images/favicon/jian_icon.png 2x" sizes=auto data-title="yejian's blog" data-alt="yejian's blog" class=logo style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span class=header-title-text>Jian's Blog</span></a><span class=header-subtitle></span></div><nav><ul class=menu><li class=menu-item><a class=menu-link href=/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> 所有文章</a></li><li class=menu-item><a class=menu-link href=/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> 分类</a></li><li class=menu-item><a class=menu-link href=/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> 标签</a></li><li class=menu-item><a class=menu-link href=/friends/ title=友情链接><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden=true></i> 友链</a></li><li class=menu-item><a class=menu-link href=/guestbook/><i class="fa-solid fa-comments fa-fw fa-sm" aria-hidden=true></i> 留言</a></li><li class="menu-item has-children"><a class=menu-link href=/about/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 关于</a><i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden=true></i><ul class=sub-menu><li class=menu-item><a class=menu-link href=/projects/_index.zh-tw/ title=項目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的項目</a></li><li class=menu-item><a class=menu-link href=/projects/ title=项目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的项目</a></li></ul></li><li class=menu-item><a class=menu-link href=/pilot/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 导航</a></li><li class="menu-item delimiter"></li><li class="menu-item search" id=search-desktop><input type=text placeholder=搜索文章标题或内容…… id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></li><li class="menu-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></li></ul></nav></div></header><header class="mobile animate__faster" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="yejian's blog"><img loading=lazy src=/images/favicon/jian_icon.png srcset="/images/favicon/jian_icon.png, /images/favicon/jian_icon.png 1.5x, /images/favicon/jian_icon.png 2x" sizes=auto data-title=/images/favicon/jian_icon.png data-alt=/images/favicon/jian_icon.png class=logo style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span class=header-title-text>Jian's Blog</span></a><span class=header-subtitle></span></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><nav><ul class=menu id=menu-mobile><li class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索文章标题或内容…… id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></li><li class=menu-item><a class=menu-link href=/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> 所有文章</a></li><li class=menu-item><a class=menu-link href=/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> 分类</a></li><li class=menu-item><a class=menu-link href=/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> 标签</a></li><li class=menu-item><a class=menu-link href=/friends/ title=友情链接><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden=true></i> 友链</a></li><li class=menu-item><a class=menu-link href=/guestbook/><i class="fa-solid fa-comments fa-fw fa-sm" aria-hidden=true></i> 留言</a></li><li class=menu-item><span class=nested-item><a class=menu-link href=/about/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 关于</a>
<i class="dropdown-icon fa-solid fa-chevron-right" aria-hidden=true></i></span><ul class=sub-menu><li class=menu-item><a class=menu-link href=/projects/_index.zh-tw/ title=項目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的項目</a></li><li class=menu-item><a class=menu-link href=/projects/ title=项目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的项目</a></li></ul></li><li class=menu-item><a class=menu-link href=/pilot/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 导航</a></li><li class="menu-item text-center"><a class=menu-link href=https://github.com/jianye0428/ title=GitHub rel="noopener noreferrer" target=_blank><i class='fa-brands fa-github fa-fw' aria-hidden=true></i></a></li><li class="menu-item menu-system"><span class="menu-system-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></span></li></ul></nav></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class="container container-reverse"><aside class=toc id=toc-auto></aside><aside class=aside-custom></aside><article class="page single"><div class=header><h1 class="single-title animate__animated animate__flipInX"><span>强化学习笔记 [11] | Prioritized Replay DQN</span></h1></div><div class=post-meta><div class=post-meta-line><span class=post-author><a href=https://github.com/jianye0428 title=作者 target=_blank rel="external nofollow noopener noreferrer author" class=author><img loading=lazy src="https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp" srcset="https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp, https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp 1.5x, https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp 2x" sizes=auto data-title="Jian YE" data-alt="Jian YE" class=avatar style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'>&nbsp;Jian YE</a></span>
<span class=post-category>收录于 <a href=/categories/rl/><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> RL</a></span></div><div class=post-meta-line><span title="发布于 2024-02-25 11:16:48"><i class="fa-regular fa-calendar-alt fa-fw me-1" aria-hidden=true></i><time datetime=2024-02-25>2024-02-25</time></span>&nbsp;<span title="更新于 2024-02-28 09:10:39"><i class="fa-regular fa-edit fa-fw me-1" aria-hidden=true></i><time datetime=2024-02-28>2024-02-28</time></span>&nbsp;<span><i class="fa-solid fa-pencil-alt fa-fw me-1" aria-hidden=true></i>约 3777 字</span>&nbsp;<span><i class="fa-regular fa-clock fa-fw me-1" aria-hidden=true></i>预计阅读 8 分钟</span>&nbsp;<span id=busuanzi_container_page_pv class="busuanzi_visitors comment-visitors" data-flag-title="强化学习笔记 [11] | Prioritized Replay DQN">
<i class="fa-regular fa-eye fa-fw me-1" aria-hidden=true></i><span id=busuanzi_value_page_pv>-</span>&nbsp;次阅读
</span>&nbsp;</div></div><div class=content id=content data-end-flag=（完）><h1 id=0-引言>0. 引言</h1><p>在<a href=https://www.cnblogs.com/pinard/p/9778063.html target=_blank rel="external nofollow noopener noreferrer">强化学习（十）Double DQN (DDQN)<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>中，我们讲到了DDQN使用两个Q网络，用当前Q网络计算最大Q值对应的动作，用目标Q网络计算这个最大动作对应的目标Q值，进而消除贪婪法带来的偏差。今天我们在DDQN的基础上，对经验回放部分的逻辑做优化。对应的算法是Prioritized Replay DQN。</p><p>本章内容主要参考了ICML 2016的<a href=https://icml.cc/2016/tutorials/deep_rl_tutorial.pdf target=_blank rel="external nofollow noopener noreferrer">deep RL tutorial<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>和Prioritized Replay DQN的论文(Prioritized Experience Replay)(ICLR 2016)。</p><h1 id=1-prioritized-replay-dqn之前算法的问题>1. Prioritized Replay DQN之前算法的问题</h1><p>在Prioritized Replay DQN之前，我们已经讨论了很多种DQN，比如Nature DQN， DDQN等，他们都是通过经验回放来采样，进而做目标Q值的计算的。在采样的时候，我们是一视同仁，在经验回放池里面的所有的样本都有相同的被采样到的概率。</p><p>但是注意到在经验回放池里面的不同的样本由于TD误差的不同，对我们反向传播的作用是不一样的。TD误差越大，那么对我们反向传播的作用越大。而TD误差小的样本，由于TD误差小，对反向梯度的计算影响不大。在Q网络中，TD误差就是目标Q网络计算的目标Q值和当前Q网络计算的Q值之间的差距。</p><p>这样如果TD误差的绝对值 $|δ(t)|$较大的样本更容易被采样，则我们的算法会比较容易收敛。下面我们看看Prioritized Replay DQN的算法思路。</p><h1 id=2-prioritized-replay-dqn算法的建模>2. Prioritized Replay DQN算法的建模</h1><p>Prioritized Replay DQN根据每个样本的TD误差绝对值 $|δ(t)|$，给定该样本的优先级正比于 $|δ(t)|$，将这个优先级的值存入经验回放池。回忆下之前的DQN算法，我们仅仅只保存和环境交互得到的样本状态，动作，奖励等数据，没有优先级这个说法。</p><p>由于引入了经验回放的优先级，那么Prioritized Replay DQN的经验回放池和之前的其他DQN算法的经验回放池就不一样了。因为这个优先级大小会影响它被采样的概率。在实际使用中，我们通常使用SumTree这样的二叉树结构来做我们的带优先级的经验回放池样本的存储。</p><p>具体的SumTree树结构如下图：</p><br><center><img src=images/2_01.png width=640 height=320 align=center style="border-radius:.3125em;box-shadow:0 2px 4px rgba(34,36,38,.12),0 2px 10px rgba(34,36,38,8%)"><br><div style="color:orange;border-bottom:1px solid #d9d9d9;display:inline-block;color:#999;padding:2px">sum_tree 结构图</div></center><br><p>所有的经验回放样本只保存在最下面的叶子节点上面，一个节点一个样本。内部节点不保存样本数据。而叶子节点除了保存数据以外，还要保存该样本的优先级，就是图中的显示的数字。对于内部节点每个节点只保存自己的儿子节点的优先级值之和，如图中内部节点上显示的数字。</p><p>这样保存有什么好处呢？主要是方便采样。以上面的树结构为例，根节点是42，如果要采样一个样本，那么我们可以在[0,42]之间做均匀采样，采样到哪个区间，就是哪个样本。比如我们采样到了26， 在（25-29）这个区间，那么就是第四个叶子节点被采样到。而注意到第三个叶子节点优先级最高，是12，它的区间13-25也是最长的，会比其他节点更容易被采样到。</p><p>如果要采样两个样本，我们可以在[0,21],[21,42]两个区间做均匀采样，方法和上面采样一个样本类似。</p><p>类似的采样算法思想我们在<a href=https://www.cnblogs.com/pinard/p/7249903.html target=_blank rel="external nofollow noopener noreferrer">word2vec原理(三) 基于Negative Sampling的模型<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>第四节中也有讲到。</p><p>除了经验回放池，现在我们的Q网络的算法损失函数也有优化，之前我们的损失函数是：</p><p>$$\frac1m\sum_{j=1}^m(y_j-Q(\phi(S_j),A_j,w))^2$$</p><p>现在我们新的考虑了样本优先级的损失函数是</p><p>$$\frac1m\sum_{j=1}^mw_j(y_j-Q(\phi(S_j),A_j,w))^2$$</p><p>其中 $w_j$是第j个样本的优先级权重，由TD误差 $|δ(t)|$归一化得到。</p><p>第三个要注意的点就是当我们对Q网络参数进行了梯度更新后，需要重新计算TD误差，并将TD误差更新到SunTree上面。</p><p>除了以上三个部分，Prioritized Replay DQN和DDQN的算法流程相同。</p><h1 id=3-prioritized-replay-dqn算法流程>3. Prioritized Replay DQN算法流程</h1><p>下面我们总结下Prioritized Replay DQN的算法流程，基于上一节的DDQN，因此这个算法我们应该叫做Prioritized Replay DDQN。主流程参考论文(Prioritized Experience Replay)(ICLR 2016)。</p><ul><li>算法输入：迭代轮数 $T$，状态特征维度 $n$, 动作集 $A$, 步长 $α$，采样权重系数 $β$，衰减因子 $γ$, 探索率 $ϵ$, 当前Q网络 $Q$，目标Q网络 $Q&rsquo;$, 批量梯度下降的样本数 $m$,目标Q网络参数更新频率 $C$, SumTree的叶子节点数 $S$。</li><li>输出：Q网络参数。</li><li><ol><li>随机初始化所有的状态和动作对应的价值 $Q$. 随机初始化当前Q网络的所有参数 $w$,初始化目标Q网络 $Q&rsquo;$的参数 $w&rsquo;=w$。初始化经验回放SumTree的默认数据结构，所有SumTree的S个叶子节点的优先级 $p_j$为1。</li></ol></li><li><ol start=2><li>for i from 1 to T，进行迭代。</li></ol><ul><li>a) 初始化S为当前状态序列的第一个状态, 拿到其特征向量 $ϕ(S)$</li><li>b) 在Q网络中使用 $ϕ(S)$ 作为输入，得到Q网络的所有动作对应的Q值输出。用 $ϵ−$贪婪法在当前Q值输出中选择对应的动作 $A$</li><li>c) 在状态 $S$ 执行当前动作 $A$,得到新状态 $S&rsquo;$ 对应的特征向量 $ϕ(S&rsquo;)$和奖励 $R$,是否终止状态 <code>is_end</code></li><li>d) 将 ${ϕ(S),A,R,ϕ(S&rsquo;),is_end}$这个五元组存入SumTree</li><li>e) $S=S'$</li><li>f) 从SumTree中采样 $m$ 个样本 ${ϕ(S_j),A_j,R_j,ϕ(S&rsquo;_j),is_end_j},j=1,2.,,,m$，每个样本被采样的概率基于 $P(j)=\frac{p_j}{\sum_i(p_i)}$，损失函数权重 $w_j=(N*P(j))^{-\beta}/\max_i(w_i)$，计算当前目标Q值 $y_j$:<ul><li>$$\left.y_j=\left\\{\begin{matrix}R_j&amp;is_end_j\textit{is true}\\\\R_j+\gamma Q^{\prime}(\phi(S_j^{\prime}),\arg\max_{a^{\prime}}Q(\phi(S_j^{\prime}),a,w),w^{\prime})&amp;is_end_j\textit{is false}\end{matrix}\right.\right.$$</li></ul></li><li>g) 使用均方差损失函数$\begin{aligned}\frac{1}{m}\sum_{j=1}^mw_j(y_j-Q(\phi(S_j),A_j,w))^2\end{aligned}$，通过神经网络的梯度反向传播来更新Q网络的所有参数 $w$</li><li>h) 重新计算所有样本的TD误差 $\delta_j=y_j-Q(\phi(S_j),A_j,w)$，更新SumTree中所有节点的优先级 $p_j=|\delta_j|$</li><li>i) 如果i%C=1,则更新目标Q网络参数 $w&rsquo;=w$</li><li>j) 如果 $S&rsquo;$是终止状态，当前轮迭代完毕，否则转到步骤b)</li></ul></li></ul><p>注意，上述第二步的f步和g步的Q值计算也都需要通过Q网络计算得到。另外，实际应用中，为了算法较好的收敛，探索率$ϵ$需要随着迭代的进行而变小。</p><h1 id=4-prioritized-replay-ddqn算法流程>4. Prioritized Replay DDQN算法流程</h1><p>下面我们给出Prioritized Replay DDQN算法的实例代码。仍然使用了OpenAI Gym中的CartPole-v0游戏来作为我们算法应用。CartPole-v0游戏的介绍参见<a href=https://github.com/openai/gym/wiki/CartPole-v0 target=_blank rel="external nofollow noopener noreferrer">这里<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>。它比较简单，基本要求就是控制下面的cart移动使连接在上面的pole保持垂直不倒。这个任务只有两个离散动作，要么向左用力，要么向右用力。而state状态就是这个cart的位置和速度， pole的角度和角速度，4维的特征。坚持到200分的奖励则为过关。</p><p>完整的代码参见我的github: <a href=https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/ddqn_prioritised_replay.py target=_blank rel="external nofollow noopener noreferrer">https://github.com/ljpzzz/machinelearning/blob/master/reinforcement-learning/ddqn_prioritised_replay.py<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>， 代码中的SumTree的结构和经验回放池的结构参考了morvanzhou的<a href=https://github.com/MorvanZhou/Reinforcement-learning-with-tensorflow/blob/master/contents/5.2_Prioritized_Replay_DQN/RL_brain.py target=_blank rel="external nofollow noopener noreferrer">github代码<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>。</p><p>这里重点讲下和第三节中算法描述不同的地方，主要是 $w_j$的计算。注意到：</p><p>$$w_j=\frac{(N<em>P(j))^{-\beta}}{\max_i(w_i)}=\frac{(N</em>P(j))^{-\beta}}{\max_i((N*P(i))^{-\beta})}=\frac{(P(j))^{-\beta}}{\max_i((P(i))^{-\beta})}=(\frac{P_j}{\min_iP(i)})^{-\beta}$$</p><p>因此代码里面$w_j$，即ISWeights的计算代码是这样的：</p><p><a href=javascript:void%280%29;><img loading=lazy src=https://common.cnblogs.com/images/copycode.gif srcset="https://common.cnblogs.com/images/copycode.gif, https://common.cnblogs.com/images/copycode.gif 1.5x, https://common.cnblogs.com/images/copycode.gif 2x" sizes=auto data-title=复制代码 data-alt=复制代码 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></a></p><div class=highlight id=id-1><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>sample</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>n</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=n>b_idx</span><span class=p>,</span> <span class=n>b_memory</span><span class=p>,</span> <span class=n>ISWeights</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>empty</span><span class=p>((</span><span class=n>n</span><span class=p>,),</span> <span class=n>dtype</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>int32</span><span class=p>),</span> <span class=n>np</span><span class=o>.</span><span class=n>empty</span><span class=p>((</span><span class=n>n</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>tree</span><span class=o>.</span><span class=n>data</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>size</span><span class=p>)),</span> <span class=n>np</span><span class=o>.</span><span class=n>empty</span><span class=p>((</span><span class=n>n</span><span class=p>,</span> <span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>  <span class=n>pri_seg</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>tree</span><span class=o>.</span><span class=n>total_p</span> <span class=o>/</span> <span class=n>n</span>       <span class=c1># priority segment</span>
</span></span><span class=line><span class=cl>  <span class=bp>self</span><span class=o>.</span><span class=n>beta</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>min</span><span class=p>([</span><span class=mf>1.</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>beta</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>beta_increment_per_sampling</span><span class=p>])</span>  <span class=c1># max = 1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>min_prob</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>min</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>tree</span><span class=o>.</span><span class=n>tree</span><span class=p>[</span><span class=o>-</span><span class=bp>self</span><span class=o>.</span><span class=n>tree</span><span class=o>.</span><span class=n>capacity</span><span class=p>:])</span> <span class=o>/</span> <span class=bp>self</span><span class=o>.</span><span class=n>tree</span><span class=o>.</span><span class=n>total_p</span>     <span class=c1># for later calculate ISweight</span>
</span></span><span class=line><span class=cl>  <span class=k>if</span> <span class=n>min_prob</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>min_prob</span> <span class=o>=</span> <span class=mf>0.00001</span>
</span></span><span class=line><span class=cl>  <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>a</span><span class=p>,</span> <span class=n>b</span> <span class=o>=</span> <span class=n>pri_seg</span> <span class=o>*</span> <span class=n>i</span><span class=p>,</span> <span class=n>pri_seg</span> <span class=o>*</span> <span class=p>(</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>v</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>uniform</span><span class=p>(</span><span class=n>a</span><span class=p>,</span> <span class=n>b</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>idx</span><span class=p>,</span> <span class=n>p</span><span class=p>,</span> <span class=n>data</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>tree</span><span class=o>.</span><span class=n>get_leaf</span><span class=p>(</span><span class=n>v</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>prob</span> <span class=o>=</span> <span class=n>p</span> <span class=o>/</span> <span class=bp>self</span><span class=o>.</span><span class=n>tree</span><span class=o>.</span><span class=n>total_p</span>
</span></span><span class=line><span class=cl>    <span class=n>ISWeights</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=mi>0</span><span class=p>]</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>power</span><span class=p>(</span><span class=n>prob</span><span class=o>/</span><span class=n>min_prob</span><span class=p>,</span> <span class=o>-</span><span class=bp>self</span><span class=o>.</span><span class=n>beta</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>b_idx</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>b_memory</span><span class=p>[</span><span class=n>i</span><span class=p>,</span> <span class=p>:]</span> <span class=o>=</span> <span class=n>idx</span><span class=p>,</span> <span class=n>data</span>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>b_idx</span><span class=p>,</span> <span class=n>b_memory</span><span class=p>,</span> <span class=n>ISWeights</span></span></span></code></pre></td></tr></table></div></div><p>上述代码的采样在第二节已经讲到。根据树的优先级的和total_p和采样数n，将要采样的区间划分为n段，每段来进行均匀采样，根据采样到的值落到的区间，决定被采样到的叶子节点。当我们拿到第i段的均匀采样值v以后，就可以去SumTree中找对应的叶子节点拿样本数据，样本叶子节点序号以及样本优先级了。代码如下：</p><div class=highlight id=id-2><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_leaf</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>v</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>  Tree structure and array storage:
</span></span></span><span class=line><span class=cl><span class=s2>  Tree index:
</span></span></span><span class=line><span class=cl><span class=s2>        0         -&gt; storing priority sum
</span></span></span><span class=line><span class=cl><span class=s2>      / </span><span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span><span class=s2>    1     2
</span></span></span><span class=line><span class=cl><span class=s2>    / \   / </span><span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span><span class=s2>  3   4 5   6    -&gt; storing priority for transitions
</span></span></span><span class=line><span class=cl><span class=s2>  Array type for storing:
</span></span></span><span class=line><span class=cl><span class=s2>  [0,1,2,3,4,5,6]
</span></span></span><span class=line><span class=cl><span class=s2>  &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>  <span class=n>parent_idx</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>  <span class=k>while</span> <span class=kc>True</span><span class=p>:</span>     <span class=c1># the while loop is faster than the method in the reference code</span>
</span></span><span class=line><span class=cl>    <span class=n>cl_idx</span> <span class=o>=</span> <span class=mi>2</span> <span class=o>*</span> <span class=n>parent_idx</span> <span class=o>+</span> <span class=mi>1</span>         <span class=c1># this leaf&#39;s left and right kids</span>
</span></span><span class=line><span class=cl>    <span class=n>cr_idx</span> <span class=o>=</span> <span class=n>cl_idx</span> <span class=o>+</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>cl_idx</span> <span class=o>&gt;=</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>tree</span><span class=p>):</span>        <span class=c1># reach bottom, end search</span>
</span></span><span class=line><span class=cl>      <span class=n>leaf_idx</span> <span class=o>=</span> <span class=n>parent_idx</span>
</span></span><span class=line><span class=cl>      <span class=k>break</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>       <span class=c1># downward search, always search for a higher priority node</span>
</span></span><span class=line><span class=cl>      <span class=k>if</span> <span class=n>v</span> <span class=o>&lt;=</span> <span class=bp>self</span><span class=o>.</span><span class=n>tree</span><span class=p>[</span><span class=n>cl_idx</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=n>parent_idx</span> <span class=o>=</span> <span class=n>cl_idx</span>
</span></span><span class=line><span class=cl>      <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>v</span> <span class=o>-=</span> <span class=bp>self</span><span class=o>.</span><span class=n>tree</span><span class=p>[</span><span class=n>cl_idx</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>parent_idx</span> <span class=o>=</span> <span class=n>cr_idx</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=n>data_idx</span> <span class=o>=</span> <span class=n>leaf_idx</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>capacity</span> <span class=o>+</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>leaf_idx</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>tree</span><span class=p>[</span><span class=n>leaf_idx</span><span class=p>],</span> <span class=bp>self</span><span class=o>.</span><span class=n>data</span><span class=p>[</span><span class=n>data_idx</span><span class=p>]</span></span></span></code></pre></td></tr></table></div></div><p>除了采样部分，要注意的就是当梯度更新完毕后，我们要去更新SumTree的权重，代码如下，注意叶子节点的权重更新后，要向上回溯，更新所有祖先节点的权重。</p><div class=highlight id=id-3><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>  <span class=bp>self</span><span class=o>.</span><span class=n>memory</span><span class=o>.</span><span class=n>batch_update</span><span class=p>(</span><span class=n>tree_idx</span><span class=p>,</span> <span class=n>abs_errors</span><span class=p>)</span>  <span class=c1># update priority</span></span></span></code></pre></td></tr></table></div></div><div class=highlight id=id-4><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>  <span class=k>def</span> <span class=nf>batch_update</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>tree_idx</span><span class=p>,</span> <span class=n>abs_errors</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>abs_errors</span> <span class=o>+=</span> <span class=bp>self</span><span class=o>.</span><span class=n>epsilon</span>  <span class=c1># convert to abs and avoid 0</span>
</span></span><span class=line><span class=cl>    <span class=n>clipped_errors</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>minimum</span><span class=p>(</span><span class=n>abs_errors</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>abs_err_upper</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>ps</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>power</span><span class=p>(</span><span class=n>clipped_errors</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>ti</span><span class=p>,</span> <span class=n>p</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>tree_idx</span><span class=p>,</span> <span class=n>ps</span><span class=p>):</span>
</span></span><span class=line><span class=cl>      <span class=bp>self</span><span class=o>.</span><span class=n>tree</span><span class=o>.</span><span class=n>update</span><span class=p>(</span><span class=n>ti</span><span class=p>,</span> <span class=n>p</span><span class=p>)</span></span></span></code></pre></td></tr></table></div></div><div class=highlight id=id-5><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl>  <span class=k>def</span> <span class=nf>update</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>tree_idx</span><span class=p>,</span> <span class=n>p</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>change</span> <span class=o>=</span> <span class=n>p</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>tree</span><span class=p>[</span><span class=n>tree_idx</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=bp>self</span><span class=o>.</span><span class=n>tree</span><span class=p>[</span><span class=n>tree_idx</span><span class=p>]</span> <span class=o>=</span> <span class=n>p</span>
</span></span><span class=line><span class=cl>    <span class=c1># then propagate the change through tree</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span> <span class=n>tree_idx</span> <span class=o>!=</span> <span class=mi>0</span><span class=p>:</span>    <span class=c1># this method is faster than the recursive loop in the reference code</span>
</span></span><span class=line><span class=cl>      <span class=n>tree_idx</span> <span class=o>=</span> <span class=p>(</span><span class=n>tree_idx</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)</span> <span class=o>//</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>      <span class=bp>self</span><span class=o>.</span><span class=n>tree</span><span class=p>[</span><span class=n>tree_idx</span><span class=p>]</span> <span class=o>+=</span> <span class=n>change</span></span></span></code></pre></td></tr></table></div></div><p>除了上面这部分的区别，和DDQN比，TensorFlow的网络结构流程中多了一个TD误差的计算节点，以及损失函数多了一个ISWeights系数。此外，区别不大。</p><h1 id=5-prioritized-replay-dqn小结>5. Prioritized Replay DQN小结</h1><p>Prioritized Replay DQN和DDQN相比，收敛速度有了很大的提高，避免了一些没有价值的迭代，因此是一个不错的优化点。同时它也可以直接集成DDQN算法，所以是一个比较常用的DQN算法。</p><p>下一篇我们讨论DQN家族的另一个优化算法Duel DQN，它将价值Q分解为两部分，第一部分是仅仅受状态但不受动作影响的部分，第二部分才是同时受状态和动作影响的部分，算法的效果也很好。</p></div><div class=post-reward><div class=comment>Buy me a coffee~</div><input type=checkbox class=reward-input name=reward id=fi-reward hidden>
<label class=reward-button for=fi-reward>赞赏</label><div class=reward-ways data-mode=fixed><div><img loading=lazy src=/images/alipay.png srcset="/images/alipay.png, /images/alipay.png 1.5x, /images/alipay.png 2x" sizes=auto data-title="Jian YE 支付宝" data-alt="Jian YE 支付宝" style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span data-animation>支付宝</span></div><div><img loading=lazy src=/images/wechatpay.png srcset="/images/wechatpay.png, /images/wechatpay.png 1.5x, /images/wechatpay.png 2x" sizes=auto data-title="Jian YE 微信" data-alt="Jian YE 微信" style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span data-animation>微信</span></div></div></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span title="更新于 2024-02-28 09:10:39">更新于 2024-02-28&nbsp;<a class=git-hash href=https://github.com/jianye0428/JianBlog/commit/d426456642d56dc3ffe2ec26e60d7ea7c402054d rel="external nofollow noopener noreferrer" target=_blank title="commit by yejian(18817571704@163.com) d426456642d56dc3ffe2ec26e60d7ea7c402054d: feat: update post default setting"><i class="fa-solid fa-hashtag fa-fw" aria-hidden=true></i>d426456</a></span></div></div><div class=post-info-line><div class=post-info-md><span><a href=/posts/rl_learning_note_11/index.md title=阅读原始文档 class=link-to-markdown>阅读原始文档</a></span><span><a href=https://github.com/jianye0428/JianBlog/edit/docs/content/posts/RL/RL_Learning_Notes/rl_learning_note_11/index.md title=编辑此页 target=_blank rel="external nofollow noopener noreferrer" class=link-to-edit>编辑此页</a></span></div><div class=post-info-share><span><a href=javascript:void(0); title="分享到 Twitter" data-sharer=twitter data-url=https://jianye0428.github.io/posts/rl_learning_note_11/ data-title="强化学习笔记 [11] | Prioritized Replay DQN" data-hashtags=RL><i class="fa-brands fa-twitter fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 Facebook" data-sharer=facebook data-url=https://jianye0428.github.io/posts/rl_learning_note_11/ data-hashtag=RL><i class="fa-brands fa-facebook-square fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 Linkedin" data-sharer=linkedin data-url=https://jianye0428.github.io/posts/rl_learning_note_11/><i class="fa-brands fa-linkedin fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 微博" data-sharer=weibo data-url=https://jianye0428.github.io/posts/rl_learning_note_11/ data-title="强化学习笔记 [11] | Prioritized Replay DQN"><i class="fa-brands fa-weibo fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 百度" data-sharer=baidu data-url=https://jianye0428.github.io/posts/rl_learning_note_11/ data-title="强化学习笔记 [11] | Prioritized Replay DQN"><i data-svg-src=/lib/simple-icons/icons/baidu.min.svg aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fa-solid fa-tags fa-fw me-1" aria-hidden=true></i><a href=/tags/rl/ class=post-tag>RL</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class=post-nav><a href=/posts/rl_learning_note_10/ class=post-nav-item rel=prev title="强化学习笔记 [10] | Double DQN (DDQN)"><i class="fa-solid fa-angle-left fa-fw" aria-hidden=true></i>强化学习笔记 [10] | Double DQN (DDQN)</a>
<a href=/posts/rl_learning_note_12/ class=post-nav-item rel=next title="强化学习笔记 [12] | Dueling DQN">强化学习笔记 [12] | Dueling DQN<i class="fa-solid fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article></main><footer class=footer><div class=footer-container><div class="footer-line powered">由 <a href=https://gohugo.io/ target=_blank rel="external nofollow noopener noreferrer" title="Hugo 0.123.7">Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/hugo-fixit/FixIt target=_blank rel=external title="FixIt v0.2.18"><img class=fixit-icon src=/fixit.min.svg alt="FixIt logo">&nbsp;FixIt</a></div><div class="footer-line copyright" itemscope itemtype=http://schema.org/CreativeWork><i class="fa-regular fa-copyright fa-fw" aria-hidden=true></i>
<span itemprop=copyrightYear>2018 - 2024</span><span class=author itemprop=copyrightHolder>
<a href=https://github.com/jianye0428 target=_blank rel="external nofollow noopener noreferrer">Jian YE</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div><div class="footer-line statistics order-first"><span class=site-time title=网站运行中……><i class="fa-solid fa-heartbeat fa-fw animate-icon" aria-hidden=true></i><span class="ms-1 d-none">博客已运行</span><span class="run-times ms-1">网站运行中……</span></span></div><div class="footer-line visitor"><span id=busuanzi_container_site_uv title=总访客数><i class="fa-regular fa-user fa-fw" aria-hidden=true></i>&nbsp;<span id=busuanzi_value_site_uv><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden=true></i></span></span><span id=busuanzi_container_site_pv class=footer-divider title=总访问量><i class="fa-regular fa-eye fa-fw" aria-hidden=true></i>&nbsp;<span id=busuanzi_value_site_pv><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden=true></i></span></span></div></div></footer></div><div class=widgets><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role=button aria-label=回到顶部><i class="fa-solid fa-arrow-up fa-fw" aria-hidden=true></i><span class=variant-numeric>0%</span></div></div><a href=https://github.com/jianye0428/JianBlog title="在 GitHub 上查看程式碼，訂閱請點 Watch" target=_blank rel="external nofollow" class="github-corner right d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115h15l12 27L250 250V0z"/><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentcolor" style="transform-origin:130px 106px" class="octo-arm"/><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4l13.9-13.8C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8z" fill="currentcolor" class="octo-body"/></svg></a><div id=mask></div><div class=reading-progress-bar style=left:0;top:0;--bg-progress:#000;--bg-progress-dark:#fff></div><noscript><div class=noscript-warning>FixIt 主题在启用 JavaScript 的情况下效果最佳。</div></noscript></div><link rel=stylesheet href=/lib/katex/katex.min.css><link rel=stylesheet href=/lib/cookieconsent/cookieconsent.min.css><link rel=stylesheet href=/lib/pace/themes/blue/pace-theme-minimal.css><script src=/lib/autocomplete/autocomplete.min.js defer></script><script src=/lib/algoliasearch/algoliasearch-lite.umd.min.js defer></script><script src=/lib/instant-page/instantpage.min.js async defer type=module></script><script src=/lib/twemoji/twemoji.min.js defer></script><script src=/lib/sharer/sharer.min.js async defer></script><script src=/lib/katex/katex.min.js defer></script><script src=/lib/katex/auto-render.min.js defer></script><script src=/lib/katex/mhchem.min.js defer></script><script src=/lib/cookieconsent/cookieconsent.min.js defer></script><script src=/lib/pangu/pangu.min.js defer></script><script src=/lib/cell-watermark/watermark.min.js defer></script><script src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js async defer></script><script src=/lib/pace/pace.min.js async defer></script><script>window.config={autoBookmark:!0,code:{copyTitle:"复制到剪贴板",editLockTitle:"锁定可编辑代码块",editUnLockTitle:"解锁可编辑代码块",editable:!0,maxShownLines:50},comment:{enable:!1},cookieconsent:{content:{dismiss:"同意",link:"了解更多",message:"本网站使用 Cookies 来改善您的浏览体验。"},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},enablePWA:!0,math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},pangu:{enable:!0,selector:"article"},search:{algoliaAppID:"MTJNHU0JVB",algoliaIndex:"index",algoliaSearchKey:"5486225134d99f43826da401ee9bad57",highlightTag:"em",maxResultLength:10,noResultsFound:"没有找到结果",snippetLength:50,type:"algolia"},siteTime:"2018-05-28T20:01:01+08:00",twemoji:!0,watermark:{appendto:".wrapper>main",colspacing:30,content:'<img style="height: 0.85rem;" src="/images/favicon/jian_icon.png" alt="logo" /> jianye',enable:!0,fontfamily:"MMT_LRH,沐目体",fontsize:1.1,height:20,opacity:.0125,rotate:15,rowspacing:60,width:150}}</script><script src=/js/theme.min.js defer></script><script src=/js/custom.min.js defer></script></body></html>