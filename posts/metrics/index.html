<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=2"><meta name=robots content="noodp"><title>Classification and Regression Metrics - yejian's blog</title><meta name=author content="Jian YE">
<meta name=author-link content="https://github.com/jianye0428"><meta name=description content="ref: [1] https://www.cnblogs.com/rushup0930/p/13359513.html [2] https://blog.csdn.net/u013250861/article/details/123029585#t12 [3] https://blog.csdn.net/wf592523813/article/details/95202448 [4] https://zhuanlan.zhihu.com/p/69101372 classification 分类 主要涉及的知识点： 混淆矩阵、Precision(精准率)、Recall(召回率)、Accuracy(准确率)、F1-score （包括二分类和多分类问题） ROC、AUC 最常见的指标Accuracy到底有哪些不足？ 解: Accuracy是分类问题中最常用的指标，它计算了分类正确的预"><meta name=keywords content='draft'><meta itemprop=name content="Classification and Regression Metrics"><meta itemprop=description content="ref: [1] https://www.cnblogs.com/rushup0930/p/13359513.html [2] https://blog.csdn.net/u013250861/article/details/123029585#t12 [3] https://blog.csdn.net/wf592523813/article/details/95202448 [4] https://zhuanlan.zhihu.com/p/69101372 classification 分类 主要涉及的知识点： 混淆矩阵、Precision(精准率)、Recall(召回率)、Accuracy(准确率)、F1-score （包括二分类和多分类问题） ROC、AUC 最常见的指标Accuracy到底有哪些不足？ 解: Accuracy是分类问题中最常用的指标，它计算了分类正确的预"><meta itemprop=datePublished content="2023-07-15T17:47:13+08:00"><meta itemprop=dateModified content="2023-07-15T17:57:25+08:00"><meta itemprop=wordCount content="5035"><meta itemprop=image content="https://jianye0428.github.io/images/favicon/jian_icon.png"><meta itemprop=keywords content="draft,"><meta property="og:title" content="Classification and Regression Metrics"><meta property="og:description" content="ref: [1] https://www.cnblogs.com/rushup0930/p/13359513.html [2] https://blog.csdn.net/u013250861/article/details/123029585#t12 [3] https://blog.csdn.net/wf592523813/article/details/95202448 [4] https://zhuanlan.zhihu.com/p/69101372 classification 分类 主要涉及的知识点： 混淆矩阵、Precision(精准率)、Recall(召回率)、Accuracy(准确率)、F1-score （包括二分类和多分类问题） ROC、AUC 最常见的指标Accuracy到底有哪些不足？ 解: Accuracy是分类问题中最常用的指标，它计算了分类正确的预"><meta property="og:type" content="article"><meta property="og:url" content="https://jianye0428.github.io/posts/metrics/"><meta property="og:image" content="https://jianye0428.github.io/images/favicon/jian_icon.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-07-15T17:47:13+08:00"><meta property="article:modified_time" content="2023-07-15T17:57:25+08:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jianye0428.github.io/images/favicon/jian_icon.png"><meta name=twitter:title content="Classification and Regression Metrics"><meta name=twitter:description content="ref: [1] https://www.cnblogs.com/rushup0930/p/13359513.html [2] https://blog.csdn.net/u013250861/article/details/123029585#t12 [3] https://blog.csdn.net/wf592523813/article/details/95202448 [4] https://zhuanlan.zhihu.com/p/69101372 classification 分类 主要涉及的知识点： 混淆矩阵、Precision(精准率)、Recall(召回率)、Accuracy(准确率)、F1-score （包括二分类和多分类问题） ROC、AUC 最常见的指标Accuracy到底有哪些不足？ 解: Accuracy是分类问题中最常用的指标，它计算了分类正确的预"><meta name=application-name content="菠菜阿九时代峰峻啊；数量可根据；"><meta name=apple-mobile-web-app-title content="菠菜阿九时代峰峻啊；数量可根据；"><meta name=theme-color data-light=#ffffff data-dark=#252627 content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/png href=/jian_icon.png><link rel=icon type=image/png sizes=32x32 href=/jian_icon.png><link rel=icon type=image/png sizes=16x16 href=/jian_icon.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://jianye0428.github.io/posts/metrics/><link rel=prev href=https://jianye0428.github.io/posts/notes_1/><link rel=next href=https://jianye0428.github.io/posts/pytorchnotes/><link rel=stylesheet href=/css/style.min.css><link rel=stylesheet href=/lib/fontawesome-free/all.min.css><link rel=stylesheet href=/lib/animate/animate.min.css><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Classification and Regression Metrics","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/jianye0428.github.io\/posts\/metrics\/"},"image":["https:\/\/jianye0428.github.io\/images\/favicon\/jian_icon.png"],"genre":"posts","keywords":"draft","wordcount":5035,"url":"https:\/\/jianye0428.github.io\/posts\/metrics\/","datePublished":"2023-07-15T17:47:13+08:00","dateModified":"2023-07-15T17:57:25+08:00","publisher":{"@type":"Organization","name":"Jian YE","logo":"https:\/\/jianye0428.github.io\/images\/favicon\/jian_icon.png"},"author":{"@type":"Person","name":"Jian YE"},"description":""}</script></head><body data-header-desktop=sticky data-header-mobile=auto><script>(window.localStorage?.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("data-theme","dark")</script><div class=wrapper data-page-style=normal><header class="desktop animate__faster" id=header-desktop><div class=header-wrapper data-github-corner=right><div class=header-title><a href=/ title="yejian's blog"><img loading=lazy src=/images/favicon/jian_icon.png srcset="/images/favicon/jian_icon.png, /images/favicon/jian_icon.png 1.5x, /images/favicon/jian_icon.png 2x" sizes=auto data-title="yejian's blog" data-alt="yejian's blog" class=logo style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span class=header-title-text>Jian's Blog</span></a><span class=header-subtitle></span></div><nav><ul class=menu><li class=menu-item><a class=menu-link href=/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> 所有文章</a></li><li class=menu-item><a class=menu-link href=/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> 分类</a></li><li class=menu-item><a class=menu-link href=/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> 标签</a></li><li class=menu-item><a class=menu-link href=/friends/ title=友情链接><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden=true></i> 友链</a></li><li class=menu-item><a class=menu-link href=/guestbook/><i class="fa-solid fa-comments fa-fw fa-sm" aria-hidden=true></i> 留言</a></li><li class="menu-item has-children"><a class=menu-link href=/about/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 关于</a><i class="dropdown-icon fa-solid fa-chevron-down" aria-hidden=true></i><ul class=sub-menu><li class=menu-item><a class=menu-link href=/projects/_index.zh-tw/ title=項目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的項目</a></li><li class=menu-item><a class=menu-link href=/projects/ title=项目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的项目</a></li></ul></li><li class=menu-item><a class=menu-link href=/pilot/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 导航</a></li><li class="menu-item delimiter"></li><li class="menu-item search" id=search-desktop><input type=text placeholder=搜索文章标题或内容…… id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></li><li class="menu-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></li></ul></nav></div></header><header class="mobile animate__faster" id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="yejian's blog"><img loading=lazy src=/images/favicon/jian_icon.png srcset="/images/favicon/jian_icon.png, /images/favicon/jian_icon.png 1.5x, /images/favicon/jian_icon.png 2x" sizes=auto data-title=/images/favicon/jian_icon.png data-alt=/images/favicon/jian_icon.png class=logo style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span class=header-title-text>Jian's Blog</span></a><span class=header-subtitle></span></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><nav><ul class=menu id=menu-mobile><li class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索文章标题或内容…… id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fa-solid fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fa-solid fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fa-solid fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></li><li class=menu-item><a class=menu-link href=/posts/><i class="fa-solid fa-archive fa-fw fa-sm" aria-hidden=true></i> 所有文章</a></li><li class=menu-item><a class=menu-link href=/categories/><i class="fa-solid fa-th fa-fw fa-sm" aria-hidden=true></i> 分类</a></li><li class=menu-item><a class=menu-link href=/tags/><i class="fa-solid fa-tags fa-fw fa-sm" aria-hidden=true></i> 标签</a></li><li class=menu-item><a class=menu-link href=/friends/ title=友情链接><i class="fa-solid fa-users fa-fw fa-sm" aria-hidden=true></i> 友链</a></li><li class=menu-item><a class=menu-link href=/guestbook/><i class="fa-solid fa-comments fa-fw fa-sm" aria-hidden=true></i> 留言</a></li><li class=menu-item><span class=nested-item><a class=menu-link href=/about/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 关于</a>
<i class="dropdown-icon fa-solid fa-chevron-right" aria-hidden=true></i></span><ul class=sub-menu><li class=menu-item><a class=menu-link href=/projects/_index.zh-tw/ title=項目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的項目</a></li><li class=menu-item><a class=menu-link href=/projects/ title=项目><i class="fa-solid fa-laptop-code fa-fw fa-sm" aria-hidden=true></i> 我的项目</a></li></ul></li><li class=menu-item><a class=menu-link href=/pilot/><i class="fa-solid fa-user-tie fa-fw fa-sm" aria-hidden=true></i> 导航</a></li><li class="menu-item text-center"><a class=menu-link href=https://github.com/jianye0428/ title=GitHub rel="noopener noreferrer" target=_blank><i class='fa-brands fa-github fa-fw' aria-hidden=true></i></a></li><li class="menu-item menu-system"><span class="menu-system-item theme-switch" title=切换主题><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></span></li></ul></nav></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class="container container-reverse"><aside class=toc id=toc-auto><h2 class=toc-title>目录&nbsp;<i class="toc-icon fa-solid fa-angle-down fa-fw" aria-hidden=true></i></h2><div class=toc-content id=toc-content-auto></div></aside><aside class=aside-custom></aside><article class="page single"><div class=header><h1 class="single-title animate__animated animate__flipInX"><span>Classification and Regression Metrics</span></h1></div><div class=post-meta><div class=post-meta-line><span class=post-author><a href=https://github.com/jianye0428 title=作者 target=_blank rel="external nofollow noopener noreferrer author" class=author><img loading=lazy src="https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp" srcset="https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp, https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp 1.5x, https://gravatar.loli.net/avatar/75a41975a5281767bf6bdba838de4238?s=32&amp;d=mp 2x" sizes=auto data-title="Jian YE" data-alt="Jian YE" class=avatar style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'>&nbsp;Jian YE</a></span>
<span class=post-category>收录于 <a href=/categories/ml/><i class="fa-regular fa-folder fa-fw" aria-hidden=true></i> ML</a></span></div><div class=post-meta-line><span title="发布于 2023-07-15 17:47:13"><i class="fa-regular fa-calendar-alt fa-fw me-1" aria-hidden=true></i><time datetime=2023-07-15>2023-07-15</time></span>&nbsp;<span title="更新于 2023-07-15 17:57:25"><i class="fa-regular fa-edit fa-fw me-1" aria-hidden=true></i><time datetime=2023-07-15>2023-07-15</time></span>&nbsp;<span><i class="fa-solid fa-pencil-alt fa-fw me-1" aria-hidden=true></i>约 5035 字</span>&nbsp;<span><i class="fa-regular fa-clock fa-fw me-1" aria-hidden=true></i>预计阅读 11 分钟</span>&nbsp;<span id=busuanzi_container_page_pv class="busuanzi_visitors comment-visitors" data-flag-title="Classification and Regression Metrics">
<i class="fa-regular fa-eye fa-fw me-1" aria-hidden=true></i><span id=busuanzi_value_page_pv>-</span>&nbsp;次阅读
</span>&nbsp;</div></div><div class="details toc" id=toc-static data-kept=false><div class="details-summary toc-title"><span>目录</span>
<span><i class="details-icon fa-solid fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#二分类模型的常见指标>二分类模型的常见指标</a></li><li><a href=#aoc--auc>AOC / AUC</a></li><li><a href=#多分类模型的常见指标详细解析>多分类模型的常见指标详细解析</a></li></ul></nav></div></div><div class=content id=content data-end-flag=（完）><div class="details admonition warning open"><div class="details-summary admonition-title"><i class="icon fa-solid fa-exclamation-triangle fa-fw" aria-hidden=true></i>警告<i class="details-icon fa-solid fa-angle-right fa-fw" aria-hidden=true></i></div><div class=details-content><div class=admonition-content>本文最后更新于 2023-07-15，文中内容可能已过时。</div></div></div><p>ref:</br>[1] <a href=https://www.cnblogs.com/rushup0930/p/13359513.html target=_blank rel="external nofollow noopener noreferrer">https://www.cnblogs.com/rushup0930/p/13359513.html<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></br>[2] <a href=https://blog.csdn.net/u013250861/article/details/123029585#t12 target=_blank rel="external nofollow noopener noreferrer">https://blog.csdn.net/u013250861/article/details/123029585#t12<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></br>[3] <a href=https://blog.csdn.net/wf592523813/article/details/95202448 target=_blank rel="external nofollow noopener noreferrer">https://blog.csdn.net/wf592523813/article/details/95202448<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></br>[4] <a href=https://zhuanlan.zhihu.com/p/69101372 target=_blank rel="external nofollow noopener noreferrer">https://zhuanlan.zhihu.com/p/69101372<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a></br></p><h1 id=classification-分类>classification 分类</h1><p>主要涉及的知识点：</p><ul><li>混淆矩阵、Precision(精准率)、Recall(召回率)、Accuracy(准确率)、F1-score （包括二分类和多分类问题）</li><li>ROC、AUC</li></ul><blockquote><p>最常见的指标Accuracy到底有哪些不足？
解: Accuracy是分类问题中最常用的指标，它计算了分类正确的预测数与总预测数的比值。但是，<font color=red>对于不平衡数据集而言，Accuracy并不是一个好指标</font>。
假设我们有100张图片，其中91张图片是「狗」，5张是「猫」，4张是「猪」，我们希望训练一个三分类器，能正确识别图片里动物的类别。其中，狗这个类别就是大多数类 (majority class)。当大多数类中样本（狗）的数量远超过其他类别（猫、猪）时，如果采用Accuracy来评估分类器的好坏，那么即便模型性能很差 (如无论输入什么图片，都预测为「狗」)，也可以得到较高的Accuracy Score (如91%)。此时，虽然Accuracy Score很高，但是意义不大。当数据异常不平衡时，Accuracy评估方法的缺陷尤为显著。</p></blockquote><h2 id=二分类模型的常见指标>二分类模型的常见指标</h2><p>在二分类问题中，假设该样本一共有两种类别：Positive和Negative。当分类器预测结束，我们可以绘制出混淆矩阵（confusion matrix）。其中分类结果分为如下几种：</p><p><img loading=lazy src=images/classify_confusion_matrix.png srcset="/posts/metrics/images/classify_confusion_matrix.png, images/classify_confusion_matrix.png 1.5x, /posts/metrics/images/classify_confusion_matrix.png 2x" sizes=auto data-title="Confusion Matrix" data-alt="Confusion Matrix" width=526 height=262 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><ul><li>True Positive (TP): 把正样本成功预测为正。</li><li>True Negative (TN)：把负样本成功预测为负。</li><li>False Positive (FP)：把负样本错误地预测为正。</li><li>False Negative (FN)：把正样本错误的预测为负。</li></ul><blockquote><p>一个小技巧， <font color=red>第一个字母表示划分正确与否</font>， T 表示判定正确（判定正确）， F表示判定错误(False)； <font color=red>第二个字母表示分类器判定结果</font>， P表示判定为正例， N表示判定为负例。</p></blockquote><p>在二分类模型中，Accuracy，Precision，Recall和F1 score的定义如下：</p><p>$$\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}$$</p><blockquote><blockquote><p>Accuracy 能够清晰的判断我们模型的表现，但有一个严重的缺陷： 在正负样本不均衡的情况下，占比大的类别往往会成为影响 Accuracy 的最主要因素，此时的 Accuracy 并不能很好的反映模型的整体情况。</p></blockquote></blockquote><p>$$\text{Precision} = \frac{TP}{TP + FP}$$</p><blockquote><blockquote><p>Precision着重评估在预测为Positive的所有数据中，真实Positve的数据到底占多少？</p></blockquote></blockquote><p>精确率高，意味着分类器要尽量在 “更有把握” 的情况下才将样本预测为正样本， 这意味着精确率能够很好的体现模型对于负样本的区分能力，精确率越高，则模型对负样本区分能力越强。</p><p>$$\text{Recall} = \frac{TP}{TP + FN}$$</p><blockquote><blockquote><p>Recall着重评估：在所有的Positive数据中，到底有多少数据被成功预测为Positive</p></blockquote></blockquote><p>召回率高，意味着分类器尽可能将有可能为正样本的样本预测为正样本，这意味着<font color=red>召回率能够很好的体现模型对于正样本的区分能力，召回率越高，则模型对正样本的区分能力越强</font>。</p><p><strong>举例</strong>:</p><p>一个医院新开发了一套癌症AI诊断系统，想评估其性能好坏。我们把病人得了癌症定义为Positive，没得癌症定义为Negative。那么， 到底该用什么指标进行评估呢？</p><ul><li>如用Precision对系统进行评估，那么其回答的问题就是：<blockquote><p>在诊断为癌症的一堆人中，到底有多少人真得了癌症？</p></blockquote></li><li>如用Recall对系统进行评估，那么其回答的问题就是：<blockquote><p>在一堆得了癌症的病人中，到底有多少人能被成功检测出癌症？</p></blockquote></li><li>如用Accuracy对系统进行评估，那么其回答的问题就是：<blockquote><p>在一堆癌症病人和正常人中，有多少人被系统给出了正确诊断结果（患癌或没患癌）？</p></blockquote></li></ul><p><font color=red>那啥时候应该更注重Recall而不是Precision呢？</font></p><blockquote><p>当False Negative (FN)的成本代价很高 (后果很严重)，希望尽量避免产生FN时，应该着重考虑提高Recall指标。</p></blockquote><p><font color=red>那啥时候应该更注重Precision而不是Recall呢？</font></p><blockquote><p>当False Positive (FP)的成本代价很高 (后果很严重)时，即期望尽量避免产生FP时，应该着重考虑提高Precision指标。</p></blockquote><p>$$\text{F1-score} = \frac{2 \times Precision \times Recall}{Precision + Recall}$$</p><p>而F1-score是Precision和Recall两者的综合。</p><p>举个更有意思的例子（我拍脑袋想出来的，绝对原创哈），假设检察机关想将罪犯捉拿归案，需要对所有人群进行分析，以判断某人犯了罪（Positive），还是没犯罪（Negative）。显然，检察机关希望不漏掉一个罪人（提高recall），也不错怪一个好人（提高precision），所以就需要同时权衡recall和precision两个指标。</p><p>尤其在上个世纪，中国司法体制会更偏向Recall，即「天网恢恢，疏而不漏，任何罪犯都插翅难飞」。而西方司法系统会更偏向Precision，即「绝不冤枉一个好人，但是难免有罪犯成为漏网之鱼，逍遥法外」。到底是哪种更好呢？显然，极端并不可取。Precision和Recall都应该越高越好，也就是F1应该越高越好。</p><p><strong><font color=green>如何通俗的解释召回率与精确率？</font></strong></p><blockquote><p>例：公园里有50只皮卡丘和10只臭臭泥。有正常审美的人都会想要用精灵球把尽可能多的皮卡丘抓回来，同时尽可能少地抓住臭臭泥。 最终我们的精灵球成功抓回来了45只皮卡丘和10只臭臭泥。
我们就可以说50只皮卡丘中有45只被召唤 (call) 回来 (re) 了，所以 recall = 45 / 50。
但同时，这台机器还误把5只臭臭泥识别为皮卡丘，在它抓回来的所有55只神奇宝贝中，精灵球对皮卡丘判断的精准性 (precision) = 45 / 55。
在上面的例子中，精灵球=预测模型，皮卡丘=正样本，臭臭泥=负样本。
总结这两个概念的用处：描述模型对正样本的预测性能
1、recall描述模型“把正样本叫 (call) 回来(re)”的能力。
2、precision描述模型“叫回来的正样本”有多少是精确的。</p></blockquote><h2 id=aoc--auc>AOC / AUC</h2><p>混淆矩阵中有着Positive、Negative、True、False的概念，其意义如下：</p><ul><li>称预测类别为1的为Positive（阳性），预测类别为0的为Negative（阴性）。</li><li>预测正确的为True（真），预测错误的为False（伪）。</li></ul><p>对上述概念进行组合，就产生了如下的混淆矩阵:</p><p><img loading=lazy src=images/classify_confusion_matrix.png srcset="/posts/metrics/images/classify_confusion_matrix.png, images/classify_confusion_matrix.png 1.5x, /posts/metrics/images/classify_confusion_matrix.png 2x" sizes=auto data-title="Confusion Matrix" data-alt="Confusion Matrix" width=526 height=262 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>然后，由此引出True Positive Rate（真阳率）、False Positive（伪阳率）两个概念：</p><p>$$TP Rate = \frac{TP}{TP + FN}$$
$$FP Rate = \frac{FP}{FP + TN}$$</p><p>仔细看这两个公式，发现其实TPRate就是TP除以TP所在的列，FPRate就是FP除以FP所在的列，二者意义如下：</p><ul><li>TPRate的意义是所有真实类别为1的样本中，预测类别为1的比例。</li><li>FPRate的意义是所有真实类别为0的样本中，预测类别为1的比例。</li></ul><p>如果上述概念都弄懂了，那么ROC曲线和AUC就so easy了：</p><p>按照定义，AUC即ROC曲线下的面积，而ROC曲线的横轴是FPRate，纵轴是TPRate，当二者相等时，即y=x，如下图:</p><p><img loading=lazy src=images/classify_auc_roc.png srcset="/posts/metrics/images/classify_auc_roc.png, images/classify_auc_roc.png 1.5x, /posts/metrics/images/classify_auc_roc.png 2x" sizes=auto data-title="Confusion Matrix" data-alt="Confusion Matrix" width=456 height=326 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>表示的意义是：对于不论真实类别是1还是0的样本，分类器预测为1的概率是相等的。</p><p>换句话说，分类器对于正例和负例毫无区分能力，和抛硬币没什么区别，一个抛硬币的分类器是我们能想象的最差的情况，因此一般来说我们认为AUC的最小值为0.5（当然也存在预测相反这种极端的情况，AUC小于0.5，这种情况相当于分类器总是把对的说成错的，错的认为是对的，那么只要把预测类别取反，便得到了一个AUC大于0.5的分类器）。</p><p>而我们希望分类器达到的效果是：对于真实类别为1的样本，分类器预测为1的概率（即TPRate），要大于真实类别为0而预测类别为1的概率（即FPRate），即y＞x，因此大部分的ROC曲线长成下面这个样子：</p><p><img loading=lazy src=images/classify_auc_roc_normal.png srcset="/posts/metrics/images/classify_auc_roc_normal.png, images/classify_auc_roc_normal.png 1.5x, /posts/metrics/images/classify_auc_roc_normal.png 2x" sizes=auto data-title="Confusion Matrix" data-alt="Confusion Matrix" width=426 height=330 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>说了这么多还是不够直观，不妨举个简单的例子。</p><p>首先对于硬分类器（例如SVM，NB），预测类别为离散标签，对于8个样本的预测情况如下：</p><p><img loading=lazy src=images/classify_auc_roc_example_1.png srcset="/posts/metrics/images/classify_auc_roc_example_1.png, images/classify_auc_roc_example_1.png 1.5x, /posts/metrics/images/classify_auc_roc_example_1.png 2x" sizes=auto data-title="AUC ROC EXAMPLE" data-alt="AUC ROC EXAMPLE" width=744 height=102 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>得到混淆矩阵如下：</p><p><img loading=lazy src=images/classify_auc_roc_example_3.png srcset="/posts/metrics/images/classify_auc_roc_example_3.png, images/classify_auc_roc_example_3.png 1.5x, /posts/metrics/images/classify_auc_roc_example_3.png 2x" sizes=auto data-title="AUC ROC Confusion Matrix" data-alt="AUC ROC Confusion Matrix" width=359 height=200 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>进而算得TPRate=3/4，FPRate=2/4，得到ROC曲线：</p><p><img loading=lazy src=images/classify_auc_roc_example_2.png srcset="/posts/metrics/images/classify_auc_roc_example_2.png, images/classify_auc_roc_example_2.png 1.5x, /posts/metrics/images/classify_auc_roc_example_2.png 2x" sizes=auto data-title="AUC ROC Confusion Matrix" data-alt="AUC ROC Confusion Matrix" width=427 height=311 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>最终得到AUC为0.625。</p><p>对于LR等预测类别为概率的分类器，依然用上述例子，假设预测结果如下：</p><p><img loading=lazy src=images/classify_auc_roc_example_4.png srcset="/posts/metrics/images/classify_auc_roc_example_4.png, images/classify_auc_roc_example_4.png 1.5x, /posts/metrics/images/classify_auc_roc_example_4.png 2x" sizes=auto data-title="AUC ROC Confusion Matrix" data-alt="AUC ROC Confusion Matrix" width=733 height=102 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>这时，需要设置阈值来得到混淆矩阵，不同的阈值会影响得到的TPRate，FPRate，如果阈值取0.5，小于0.5的为0，否则为1，那么我们就得到了与之前一样的混淆矩阵。其他的阈值就不再啰嗦了。依次使用所有预测值作为阈值，得到一系列TPRate，FPRate，描点，求面积，即可得到AUC。</p><p>最后说说AUC的优势，AUC的计算方法同时考虑了分类器对于正例和负例的分类能力，在样本不平衡的情况下，依然能够对分类器作出合理的评价。</p><p>例如在反欺诈场景，设欺诈类样本为正例，正例占比很少（假设0.1%），如果使用准确率评估，把所有的样本预测为负例，便可以获得99.9%的准确率。</p><p>但是如果使用AUC，把所有样本预测为负例，TPRate和FPRate同时为0（没有Positive），与(0,0) (1,1)连接，得出AUC仅为0.5，成功规避了样本不均匀带来的问题。</p><h2 id=多分类模型的常见指标详细解析>多分类模型的常见指标详细解析</h2><p>在多分类（大于两个类）问题中，假设我们要开发一个动物识别系统，来区分输入图片是猫，狗还是猪。给定分类器一堆动物图片，产生了如下结果混淆矩阵。</p><p><img loading=lazy src=images/classify_multiclass_confusion_matrix.png srcset="/posts/metrics/images/classify_multiclass_confusion_matrix.png, images/classify_multiclass_confusion_matrix.png 1.5x, /posts/metrics/images/classify_multiclass_confusion_matrix.png 2x" sizes=auto data-title="Mulitclass Confusion Matrix" data-alt="Mulitclass Confusion Matrix" width=426 height=314 style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>在混淆矩阵中，正确的分类样本（Actual label = Predicted label）分布在左上到右下的对角线上。其中，Accuracy的定义为分类正确（对角线上）的样本数与总样本数的比值。<strong>Accuracy度量的是全局样本预测情况。而对于Precision和Recall而言，每个类都需要单独计算其Precision和Recall。</strong>
classify_multiclass_prediction
<img loading=lazy src=https://github.com/jianye0428/**hello**-hugo/raw/master/img/posts/notes/2022-08-16_classification_metrics/classify_multiclass_prediction.png srcset="https://github.com/jianye0428/**hello**-hugo/raw/master/img/posts/notes/2022-08-16_classification_metrics/classify_multiclass_prediction.png, https://github.com/jianye0428/**hello**-hugo/raw/master/img/posts/notes/2022-08-16_classification_metrics/classify_multiclass_prediction.png 1.5x, https://github.com/jianye0428/**hello**-hugo/raw/master/img/posts/notes/2022-08-16_classification_metrics/classify_multiclass_prediction.png 2x" sizes=auto data-title="Mulitclass Confusion Matrix" data-alt="Mulitclass Confusion Matrix" style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'></p><p>比如，对类别「猪」而言，其Precision和Recall分别为:</p><p>$$\text{Precision} = \frac{TP}{TP + FP} = \frac{20}{20 + 50} = \frac{2}{7}$$</p><p>$$\text{Recall} = \frac{TP}{TP + FN} = \frac{20}{10} = \frac{2}{3}$$</p><p>也就是:
$$P_{cat} = \frac{8}{15}, P_{dog} = \frac{17}{23}, P_{pig} = \frac{2}{7}, (P代表Precision) $$
$$R_{cat} = \frac{4}{7}, R_{dog} = \frac{17}{32}, R_{pig} = \frac{2}{3}, (R代表Recall) $$</p><p>如果想评估该识别系统的总体功能，必须考虑猫、狗、猪三个类别的综合预测性能。那么，到底要怎么综合这三个类别的Precision呢？是简单加起来做平均吗？通常来说， 我们有如下几种解决方案（<a href="https://link.zhihu.com/?target=https%3A//scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html" target=_blank rel="external nofollow noopener noreferrer">也可参考scikit-learn官网<i class="fa-solid fa-external-link-alt fa-fw fa-xs ms-1 text-secondary" aria-hidden=true></i></a>）：</p><p><strong>1. Macro-average方法</strong>
该方法最简单，直接将不同类别的评估指标（Precision/ Recall/ F1-score）加起来求平均，给所有类别相同的权重。该方法能够平等看待每个类别，但是它的值会受<strong>稀有类别</strong>影响。</p><p>$$\text{Macro-Precision} = \frac{P_{cat} + P_{dog} + P_{pig}}{3} = 0.5194$$
$$\text{Macro-Recall} = \frac{R_{cat} + R_{dog} + R_{pig}}{3} = 0.5898$$</p><p><strong>2. Weighted-average方法</strong></p><p>该方法给不同类别不同权重（权重根据该类别的真实分布比例确定），每个类别乘权重后再进行相加。该方法考虑了类别不平衡情况，它的值更容易受到常见类（majority class）的影响。</p><p>$$W_{cat} : W_{dog} : W_{pig} = N_{cat} : N_{dog} : N_{pig} = \frac{7}{26} : \frac{16}{26} : \frac{3}{26} (W代表权重，N代表样本在该类别下的真实数目)$$
$$\text{Weighted-Precision} = P_{cat} \times W_{cat} + P_{dog} \times W_{dog} + P_{pig} \times W_{pig} = 0.6314$$
$$\text{Weighted-Recall} = {R_{cat} \times W_{cat} + R_{dog} \times W_{dog} + R_{pig} \times W_{pig}}= 0.5577$$</p><p><strong>3. Micro-average方法</strong></p><p>该方法把每个类别的TP, FP, FN先相加之后，在根据二分类的公式进行计算。</p><p>$$\text{Micro-Precision} = \frac{TP_{cat} + TP_{dog} + TP_{pig}}{TP_{cat} + TP_{dog} + TP_{pig} + FP_{cat} + FP_{dog} + FP_{pig}} = 0.5577$$
$$\text{Micro-Recall} = \frac{TP_{cat} + TP_{dog} + TP_{pig}}{TP_{cat} + TP_{dog} + TP_{pig} + FN_{cat} + FN_{dog} + FN_{pig}} = 0.5577$$</p><p>其中，特别有意思的是，<u>Micro-precision 和 Micro-recall竟然始终相同！</u>这是为啥呢？</p><p>这是因为在某一类中的False Positive样本，一定是其他某类别的False Negative样本。听起来有点抽象？举个例子，比如说系统错把「狗」预测成「猫」，那么对于狗而言，其错误类型就是False Negative，对于猫而言，其错误类型就是False Positive。于此同时，Micro-precision和Micro-recall的数值都等于Accuracy，因为它们计算了对角线样本数和总样本数的比值，总结就是</p><p>$$\text{Micro-Precision} = \text{Micro-Recall} = \text{Micro-F1 score} = \text{Accuracy}$$</p><p>demo示例:</p><div class=highlight id=id-1><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>seaborn</span> <span class=k>as</span> <span class=nn>sns</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=kn>import</span> <span class=n>confusion_matrix</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=kn>import</span> <span class=n>accuracy_score</span><span class=p>,</span> <span class=n>average_precision_score</span><span class=p>,</span><span class=n>precision_score</span><span class=p>,</span><span class=n>f1_score</span><span class=p>,</span><span class=n>recall_score</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># create confusion matrix</span>
</span></span><span class=line><span class=cl><span class=n>y_true</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>*</span><span class=mi>70</span> <span class=o>+</span> <span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>*</span><span class=mi>160</span> <span class=o>+</span> <span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>*</span><span class=mi>30</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>y_pred</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>*</span><span class=mi>40</span> <span class=o>+</span> <span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>*</span><span class=mi>20</span> <span class=o>+</span> <span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>*</span><span class=mi>20</span> <span class=o>+</span>
</span></span><span class=line><span class=cl>                  <span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>*</span><span class=mi>30</span> <span class=o>+</span> <span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>*</span><span class=mi>80</span> <span class=o>+</span> <span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>*</span><span class=mi>30</span> <span class=o>+</span>
</span></span><span class=line><span class=cl>                  <span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>*</span><span class=mi>5</span> <span class=o>+</span> <span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>*</span><span class=mi>15</span> <span class=o>+</span> <span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>*</span><span class=mi>20</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>cm</span> <span class=o>=</span> <span class=n>confusion_matrix</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>conf_matrix</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>cm</span><span class=p>,</span> <span class=n>index</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;Cat&#39;</span><span class=p>,</span><span class=s1>&#39;Dog&#39;</span><span class=p>,</span><span class=s1>&#39;Pig&#39;</span><span class=p>],</span> <span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;Cat&#39;</span><span class=p>,</span><span class=s1>&#39;Dog&#39;</span><span class=p>,</span><span class=s1>&#39;Pig&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># plot size setting</span>
</span></span><span class=line><span class=cl><span class=n>fig</span><span class=p>,</span> <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>figsize</span> <span class=o>=</span> <span class=p>(</span><span class=mf>4.5</span><span class=p>,</span><span class=mf>3.5</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>sns</span><span class=o>.</span><span class=n>heatmap</span><span class=p>(</span><span class=n>conf_matrix</span><span class=p>,</span> <span class=n>annot</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>annot_kws</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;size&#34;</span><span class=p>:</span> <span class=mi>19</span><span class=p>},</span> <span class=n>cmap</span><span class=o>=</span><span class=s2>&#34;Blues&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;True label&#39;</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>18</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Predicted label&#39;</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>18</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xticks</span><span class=p>(</span><span class=n>fontsize</span><span class=o>=</span><span class=mi>18</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>yticks</span><span class=p>(</span><span class=n>fontsize</span><span class=o>=</span><span class=mi>18</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>savefig</span><span class=p>(</span><span class=s1>&#39;confusion.pdf&#39;</span><span class=p>,</span> <span class=n>bbox_inches</span><span class=o>=</span><span class=s1>&#39;tight&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;------Weighted------&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Weighted precision&#39;</span><span class=p>,</span> <span class=n>precision_score</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>,</span> <span class=n>average</span><span class=o>=</span><span class=s1>&#39;weighted&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Weighted recall&#39;</span><span class=p>,</span> <span class=n>recall_score</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>,</span> <span class=n>average</span><span class=o>=</span><span class=s1>&#39;weighted&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Weighted f1-score&#39;</span><span class=p>,</span> <span class=n>f1_score</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>,</span> <span class=n>average</span><span class=o>=</span><span class=s1>&#39;weighted&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;------Macro------&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Macro precision&#39;</span><span class=p>,</span> <span class=n>precision_score</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>,</span> <span class=n>average</span><span class=o>=</span><span class=s1>&#39;macro&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Macro recall&#39;</span><span class=p>,</span> <span class=n>recall_score</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>,</span> <span class=n>average</span><span class=o>=</span><span class=s1>&#39;macro&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Macro f1-score&#39;</span><span class=p>,</span> <span class=n>f1_score</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>,</span> <span class=n>average</span><span class=o>=</span><span class=s1>&#39;macro&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;------Micro------&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Micro precision&#39;</span><span class=p>,</span> <span class=n>precision_score</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>,</span> <span class=n>average</span><span class=o>=</span><span class=s1>&#39;micro&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Micro recall&#39;</span><span class=p>,</span> <span class=n>recall_score</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>,</span> <span class=n>average</span><span class=o>=</span><span class=s1>&#39;micro&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s1>&#39;Micro f1-score&#39;</span><span class=p>,</span> <span class=n>f1_score</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>,</span> <span class=n>average</span><span class=o>=</span><span class=s1>&#39;micro&#39;</span><span class=p>))</span></span></span></code></pre></td></tr></table></div></div><h1 id=regression-回归>Regression 回归</h1><p>回归算法的评价指标就是MSE，RMSE，MAE、R-Squared。</p><p>　　MSE和MAE适用于误差相对明显的时候，大的误差也有比较高的权重，RMSE则是针对误差不是很明显的时候；MAE是一个线性的指标，所有个体差异在平均值上均等加权，所以它更加凸显出异常值，相比MSE；</p><p>　　RMSLE: 主要针对数据集中有一个特别大的异常值，这种情况下，data会被skew，RMSE会被明显拉大，这时候就需要先对数据log下，再求RMSE，这个过程就是RMSLE。对低估值（under-predicted）的判罚明显多于估值过高(over-predicted)的情况（RMSE则相反）</p></div><div class=post-reward><div class=comment>Buy me a coffee~</div><input type=checkbox class=reward-input name=reward id=fi-reward hidden>
<label class=reward-button for=fi-reward>赞赏</label><div class=reward-ways data-mode=fixed><div><img loading=lazy src=/images/alipay.png srcset="/images/alipay.png, /images/alipay.png 1.5x, /images/alipay.png 2x" sizes=auto data-title="Jian YE 支付宝" data-alt="Jian YE 支付宝" style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span data-animation>支付宝</span></div><div><img loading=lazy src=/images/wechatpay.png srcset="/images/wechatpay.png, /images/wechatpay.png 1.5x, /images/wechatpay.png 2x" sizes=auto data-title="Jian YE 微信" data-alt="Jian YE 微信" style="background:url(/svg/loading.min.svg)no-repeat 50%" onload='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e);this.dataset.lazyloaded=""' onerror='this.title=this.dataset.title,this.alt=this.dataset.alt;for(const e of["style","data-title","data-alt","onerror","onload"])this.removeAttribute(e)'><span data-animation>微信</span></div></div></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span title="更新于 2023-07-15 17:57:25">更新于 2023-07-15&nbsp;<a class=git-hash href=https://github.com/jianye0428/JianBlog/commit/395c1643b956924d5c99d51a88eb6636bda9fad0 rel="external nofollow noopener noreferrer" target=_blank title="commit by yejian(yejian@zhito.com) 395c1643b956924d5c99d51a88eb6636bda9fad0: feat: add ML Notes"><i class="fa-solid fa-hashtag fa-fw" aria-hidden=true></i>395c164</a></span></div></div><div class=post-info-line><div class=post-info-md><span><a href=/posts/metrics/index.md title=阅读原始文档 class=link-to-markdown>阅读原始文档</a></span><span><a href=https://github.com/jianye0428/JianBlog/edit/docs/content/posts/ML/ClassificationAndRegression/Metrics/index.md title=编辑此页 target=_blank rel="external nofollow noopener noreferrer" class=link-to-edit>编辑此页</a></span></div><div class=post-info-share><span><a href=javascript:void(0); title="分享到 Twitter" data-sharer=twitter data-url=https://jianye0428.github.io/posts/metrics/ data-title="Classification and Regression Metrics" data-hashtags=draft><i class="fa-brands fa-twitter fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 Facebook" data-sharer=facebook data-url=https://jianye0428.github.io/posts/metrics/ data-hashtag=draft><i class="fa-brands fa-facebook-square fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 Linkedin" data-sharer=linkedin data-url=https://jianye0428.github.io/posts/metrics/><i class="fa-brands fa-linkedin fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 微博" data-sharer=weibo data-url=https://jianye0428.github.io/posts/metrics/ data-title="Classification and Regression Metrics"><i class="fa-brands fa-weibo fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); title="分享到 百度" data-sharer=baidu data-url=https://jianye0428.github.io/posts/metrics/ data-title="Classification and Regression Metrics"><i data-svg-src=/lib/simple-icons/icons/baidu.min.svg aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fa-solid fa-tags fa-fw me-1" aria-hidden=true></i><a href=/tags/draft/ class=post-tag>Draft</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class=post-nav><a href=/posts/notes_1/ class=post-nav-item rel=prev title="Maching Learning Notes 1"><i class="fa-solid fa-angle-left fa-fw" aria-hidden=true></i>Maching Learning Notes 1</a>
<a href=/posts/pytorchnotes/ class=post-nav-item rel=next title="PyTorch Notes">PyTorch Notes<i class="fa-solid fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article></main><footer class=footer><div class=footer-container><div class="footer-line powered">由 <a href=https://gohugo.io/ target=_blank rel="external nofollow noopener noreferrer" title="Hugo 0.124.1">Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/hugo-fixit/FixIt target=_blank rel=external title="FixIt v0.2.18"><img class=fixit-icon src=/fixit.min.svg alt="FixIt logo">&nbsp;FixIt</a></div><div class="footer-line copyright" itemscope itemtype=http://schema.org/CreativeWork><i class="fa-regular fa-copyright fa-fw" aria-hidden=true></i>
<span itemprop=copyrightYear>2018 - 2024</span><span class=author itemprop=copyrightHolder>
<a href=https://github.com/jianye0428 target=_blank rel="external nofollow noopener noreferrer">Jian YE</a></span><span class="license footer-divider"><a rel="license external nofollow noopener noreferrer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div><div class="footer-line statistics order-first"><span class=site-time title=网站运行中……><i class="fa-solid fa-heartbeat fa-fw animate-icon" aria-hidden=true></i><span class="ms-1 d-none">博客已运行</span><span class="run-times ms-1">网站运行中……</span></span></div><div class="footer-line visitor"><span id=busuanzi_container_site_uv title=总访客数><i class="fa-regular fa-user fa-fw" aria-hidden=true></i>&nbsp;<span id=busuanzi_value_site_uv><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden=true></i></span></span><span id=busuanzi_container_site_pv class=footer-divider title=总访问量><i class="fa-regular fa-eye fa-fw" aria-hidden=true></i>&nbsp;<span id=busuanzi_value_site_pv><i class="fa-solid fa-spinner fa-spin fa-fw" aria-hidden=true></i></span></span></div></div></footer></div><div class=widgets><div class="fixed-buttons animate__faster d-none"><div class="fixed-button back-to-top" role=button aria-label=回到顶部><i class="fa-solid fa-arrow-up fa-fw" aria-hidden=true></i><span class=variant-numeric>0%</span></div></div><a href=https://github.com/jianye0428/JianBlog title="在 GitHub 上查看程式碼，訂閱請點 Watch" target=_blank rel="external nofollow" class="github-corner right d-none-mobile"><svg viewBox="0 0 250 250" aria-hidden="true"><path d="M0 0 115 115h15l12 27L250 250V0z"/><path d="M128.3 109C113.8 99.7 119 89.6 119 89.6 122 82.7 120.5 78.6 120.5 78.6 119.2 72 123.4 76.3 123.4 76.3 127.3 80.9 125.5 87.3 125.5 87.3 122.9 97.6 130.6 101.9 134.4 103.2" fill="currentcolor" style="transform-origin:130px 106px" class="octo-arm"/><path d="M115 115C114.9 115.1 118.7 116.5 119.8 115.4l13.9-13.8C136.9 99.2 139.9 98.4 142.2 98.6 133.8 88 127.5 74.4 143.8 58 148.5 53.4 154 51.2 159.7 51 160.3 49.4 163.2 43.6 171.4 40.1 171.4 40.1 176.1 42.5 178.8 56.2 183.1 58.6 187.2 61.8 190.9 65.4 194.5 69 197.7 73.2 200.1 77.6 213.8 80.2 216.3 84.9 216.3 84.9 212.7 93.1 206.9 96 205.4 96.6 205.1 102.4 203 107.8 198.3 112.5 181.9 128.9 168.3 122.5 157.7 114.1 157.9 116.9 156.7 120.9 152.7 124.9L141 136.5C139.8 137.7 141.6 141.9 141.8 141.8z" fill="currentcolor" class="octo-body"/></svg></a><div id=mask></div><div class=reading-progress-bar style=left:0;top:0;--bg-progress:#000;--bg-progress-dark:#fff></div><noscript><div class=noscript-warning>FixIt 主题在启用 JavaScript 的情况下效果最佳。</div></noscript></div><link rel=stylesheet href=/lib/cookieconsent/cookieconsent.min.css><link rel=stylesheet href=/lib/pace/themes/blue/pace-theme-minimal.css><script src=/lib/autocomplete/autocomplete.min.js defer></script><script src=/lib/algoliasearch/algoliasearch-lite.umd.min.js defer></script><script src=/lib/instant-page/instantpage.min.js async defer type=module></script><script src=/lib/twemoji/twemoji.min.js defer></script><script src=/lib/sharer/sharer.min.js async defer></script><script src=/lib/cookieconsent/cookieconsent.min.js defer></script><script src=/lib/pangu/pangu.min.js defer></script><script src=/lib/cell-watermark/watermark.min.js defer></script><script src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js async defer></script><script src=/lib/pace/pace.min.js async defer></script><script>window.config={autoBookmark:!0,code:{copyTitle:"复制到剪贴板",editLockTitle:"锁定可编辑代码块",editUnLockTitle:"解锁可编辑代码块",editable:!0,maxShownLines:50},comment:{enable:!1},cookieconsent:{content:{dismiss:"同意",link:"了解更多",message:"本网站使用 Cookies 来改善您的浏览体验。"},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},enablePWA:!0,pangu:{enable:!0,selector:"article"},search:{algoliaAppID:"MTJNHU0JVB",algoliaIndex:"index",algoliaSearchKey:"5486225134d99f43826da401ee9bad57",highlightTag:"em",maxResultLength:10,noResultsFound:"没有找到结果",snippetLength:50,type:"algolia"},siteTime:"2018-05-28T20:01:01+08:00",twemoji:!0,watermark:{appendto:".wrapper>main",colspacing:30,content:'<img style="height: 0.85rem;" src="/images/favicon/jian_icon.png" alt="logo" /> jianye',enable:!0,fontfamily:"MMT_LRH,沐目体",fontsize:1.1,height:20,opacity:.0125,rotate:15,rowspacing:60,width:150}}</script><script src=/js/theme.min.js defer></script><script src=/js/custom.min.js defer></script></body></html>